<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9932075</article-id>
    <article-id pub-id-type="pmid">36792716</article-id>
    <article-id pub-id-type="publisher-id">29574</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-023-29574-0</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepAction: a MATLAB toolbox for automated classification of animal behavior in video</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Harris</surname>
          <given-names>Carl</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Finn</surname>
          <given-names>Kelly R.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kieseler</surname>
          <given-names>Marie-Luise</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Maechler</surname>
          <given-names>Marvin R.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Tse</surname>
          <given-names>Peter U.</given-names>
        </name>
        <address>
          <email>Peter.U.Tse@dartmouth.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.254880.3</institution-id><institution-id institution-id-type="ISNI">0000 0001 2179 2404</institution-id><institution>Department of Psychological and Brain Science, </institution><institution>Dartmouth College, </institution></institution-wrap>Hanover, NH 03755 USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.254880.3</institution-id><institution-id institution-id-type="ISNI">0000 0001 2179 2404</institution-id><institution>Neukom Institute, Dartmouth College, </institution></institution-wrap>Hanover, NH 03755 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>2688</elocation-id>
    <history>
      <date date-type="received">
        <day>3</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>7</day>
        <month>2</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The identification of animal behavior in video is a critical but time-consuming task in many areas of research. Here, we introduce DeepAction, a deep learning-based toolbox for automatically annotating animal behavior in video. Our approach uses features extracted from raw video frames by a pretrained convolutional neural network to train a recurrent neural network classifier. We evaluate the classifier on two benchmark rodent datasets and one octopus dataset. We show that it achieves high accuracy, requires little training data, and surpasses both human agreement and most comparable existing methods. We also create a confidence score for classifier output, and show that our method provides an accurate estimate of classifier performance and reduces the time required by human annotators to review and correct automatically-produced annotations. We release our system and accompanying annotation interface as an open-source MATLAB toolbox.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Computational neuroscience</kwd>
      <kwd>Behavioural methods</kwd>
      <kwd>Software</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Neukom Institute for Computational Science</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>1632738</award-id>
        <principal-award-recipient>
          <name>
            <surname>Kieseler</surname>
            <given-names>Marie-Luise</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">The classification and analysis of animal behavior in video is a ubiquitous but often laborious process in life sciences research. Traditionally, such analyses have been performed manually. This approach, however, suffers from several limitations. Most obvious is that it requires researchers to allocate much of their time to the tedious work of behavioral annotation, limiting or slowing the progress of downstream analyses. Particularly for labs without research assistants or paid annotators, the opportunity cost of annotating video can be quite high. Manual annotation also suffers from relatively poor reproducibility and reliability<sup><xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR3">3</xref></sup>, largely due to the limited attentional capacity of human annotators. This issue is particularly salient in studies involving rodents. Due to their nocturnal nature, rodents are preferably studied under dimmed or infrared light<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>, which makes the identification of behaviors more difficult due to more limited light and color cues. This, in turn, increases annotators’ fatigue and reduces their capacity to pay attention for extended periods, introducing variation in annotation quality, thereby decreasing the quality of behavioral data<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>.</p>
    <p id="Par3">Given the time and accuracy limitations of manual annotation, increasing work has focused on creating methods to automate the annotation process. Many such methods rely on tracking animals’ bodies<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR6">6</xref>–<xref ref-type="bibr" rid="CR9">9</xref></sup> or body parts<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, from which higher-level features (e.g., velocity, acceleration, and posture) are extrapolated and used to classify behavior. Jhuang et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, for example, used motion and trajectory features to train a hidden Markov support vector machine to categorize eight classes of mouse behavior. Burgos-Artizzu et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> used spatiotemporal and trajectory features and a temporal context model to classify the social behavior of mice using two camera views. However, approaches using these “hand-crafted features” are limited in several ways<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. First, they require that researchers identify sets of features that both encompass a given animal’s entire behavioral repertoire and can distinguish between visually similar behaviors. For example, “eating” and “grooming snout” behaviors in rodents do not have a well-defined difference in posture or movement<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>, making crafting features to differentiate them difficult. Second, after features have been selected, detecting and tracking them is difficult and imperfect. Subtle changes in video illumination, animal movement, and environment can result in inaccurate keypoint detection, decreasing the fidelity of extracted features. And third, selected feature sets are often experiment-specific. Those optimal for a singly housed rodent study, for example, likely differ from those optimal for a social rodent study. This increases the complexity of the feature-selection task, impeding experimental progress and annotation accuracy.
</p>
    <p id="Par4">To address these limitations, Bohnslav et al.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> proposed an alternative to hand-crafted approaches, instead using hidden two-stream networks<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> and temporal gaussian mixture networks<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, and achieved high classification accuracy on a diverse collection of animal behavior datasets. Here, we expand on this work by introducing DeepAction, a MATLAB toolbox for the automated annotation of animal behavior in video. Our approach utilizes a two-stream<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> convolutional and recurrent neural network architecture<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup> to generate behavioral labels from raw video frames. We use convolutional neural networks (CNNs) and dense optical flow to extract spatial and temporal features from video<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>, which are then used to train a long short-term memory network classifier to predict behavior. We evaluate our approach on two benchmark datasets of laboratory mouse video and one dataset of octopus video. We show that it outperforms existing methods and reaches human-level performance with little training data. In addition to outputting behavior labels for each video frame, we also introduce a classification confidence system that generates a measure of how “confident” the classifier is about each label. This allows researchers to estimate the quality of automatically-produced annotations without having to review them, and reduces the time required to review annotations by allowing users to selectively correct ambiguous ones, while omitting those that the classifier produced with high confidence. We show that this confidence score accurately differentiates low quality annotations from high quality ones and improves the efficiency of reviewing and correcting video. Finally, we release the code and annotation GUI as an open-source MATLAB project.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>The DeepAction workflow</title>
      <p id="Par5">The toolbox workflow (Fig. <xref rid="Fig1" ref-type="fig">1</xref>A) begins with the importation of unlabeled video into a new DeepAction project and ends with the export of annotations for all the videos in that project. The workflow consists of two parts: a classification component (steps 2–8) and a review component (steps 9 and 10). In the classification portion, we adopt a supervised learning approach in which a portion of project videos are labeled and used to train a classifier. This classifier learns to associate the content in the video frames with a set of user-defined behavior labels (e.g., “walk” or “drink”). After the classifier is trained, it can then be used to predict behaviors in the <italic>unlabeled</italic> video. In addition to predicting behaviors occurring in the unlabeled video, the classifier outputs a “confidence score,” representing an estimate of the agreement between classifier-produced labels and human-produced ones. This confidence score is used during the review component of the workflow, in which low-confidence annotations can be preferentially reviewed and corrected, while those with high confidence are omitted. After this confidence-based review, annotations are exported for use in the researcher’s given analysis.
<fig id="Fig1"><label>Figure 1</label><caption><p>Toolbox workflow and data selection process. (<bold>A</bold>) Workflow for the DeepAction toolbox. Arrows indicate the flow of project actions, with the dashed arrow denoting that, following training of the classifier, additional training data can be annotated and used to re-train the classifier. (<bold>B</bold>) An overview of the clip selection process. Long videos are divided into clips of a user-specified length, from which a user-specified proportion (<inline-formula id="IEq273"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq273.gif"/></alternatives></inline-formula>) are randomly selected for annotation (<inline-formula id="IEq274"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M4"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq274.gif"/></alternatives></inline-formula>). The selected video clips are then annotated, and these annotations are used in combination with their corresponding features to train the classifier. The trained classifier is used to generate predictions and confidence scores for the non-selected clips (<inline-formula id="IEq275"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M6"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq275.gif"/></alternatives></inline-formula>), which the user can then review and correct as necessary. (<bold>C</bold>) Labeled data are further divided into training (<inline-formula id="IEq276"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{train}}$$\end{document}</tex-math><mml:math id="M8"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">train</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq276.gif"/></alternatives></inline-formula>) and validation (<inline-formula id="IEq277"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{validate}}$$\end{document}</tex-math><mml:math id="M10"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">validate</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq277.gif"/></alternatives></inline-formula>) data. (<bold>D</bold>) Process for simulating clip-selection using our benchmark datasets, where we simulate selecting <inline-formula id="IEq278"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq278.gif"/></alternatives></inline-formula> of the data for labeling (<inline-formula id="IEq279"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M14"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq279.gif"/></alternatives></inline-formula>) and evaluate it on the unselected data (<inline-formula id="IEq280"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{test}}$$\end{document}</tex-math><mml:math id="M16"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">test</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq280.gif"/></alternatives></inline-formula>). (<bold>E</bold>) Process to generate spatiotemporal features from video frames. Raw video frames are extracted from the video file (“frame extraction”). The movement between frames is calculated using TV-L1 optical flow and then represented visually as the temporal frames. Spatial and temporal frames are input into their corresponding pretrained CNN (“spatial ResNet18” and “flow Resnet18,” respectively), from which spatial and temporal features are extracted. The spatial and temporal features are then concatenated, and then their dimensionality is reduced to generate the final spatiotemporal features that are used to train the classifier. Dimensionality is shown in italicized brackets.</p></caption><graphic xlink:href="41598_2023_29574_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par6">To represent the video for input to the classifier, we opt for a “two-stream” model<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, where the first stream (“spatial stream”) captures the spatial information of the video frames, and the second stream (“temporal stream”) captures the motion between frames (Fig. <xref rid="Fig1" ref-type="fig">1</xref>E). We first extract video frames representing the spatial and temporal information (“spatial frames” and “temporal frames,” respectively) in the underlying video (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec18" ref-type="sec">Frame Extraction</xref>” sections). To generate spatial frames, which contain information about the scenes and objects in the video, we extract the raw video frames from each video file. To generate temporal frames, which contain information about the movement of the camera and objects in the video, we use dense optical flow to calculate the movement of individual pixels between <italic>pairs</italic> of sequential frames. Dense optical flow generates a two-dimensional vector field for each pixel in the image, where each vector represents the estimated movement of a pixel from one image to the next<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. We then express this entire vector field visually as an image, where a given pixel’s color is governed by the orientation and magnitude of its corresponding flow vector.</p>
      <p id="Par7">We then generate a low-dimensional representation of the spatial and temporal frames by extracting their salient visual features<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> using the ResNet18 pretrained convolutional neural network (CNN; see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec19" ref-type="sec">Feature extraction</xref>” sections). For each spatial and temporal frame, the feature extractors generate a <inline-formula id="IEq1"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$512$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mn>512</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq1.gif"/></alternatives></inline-formula>-dimensional vector representing the high-level visual information contained in that frame. We then concatenate these spatial and temporal features (dimensionality of <inline-formula id="IEq2"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1024$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mn>1024</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq2.gif"/></alternatives></inline-formula>) to create the initial spatiotemporal features, and then use reconstruction independent component analysis to reduce the dimensionality to <inline-formula id="IEq3"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$512$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mn>512</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq3.gif"/></alternatives></inline-formula>, forming the final spatiotemporal features used to train the classifier.</p>
      <p id="Par8">Training the classifier requires a portion of video be manually labeled so it can learn the associations between the video’s corresponding spatiotemporal features (input) and behavior labels (output). Rather than annotating whole videos at a time, we instead split each video into short “clips,” where each clip is a short segment of the longer video, and then select a subset of these clips to annotate (Fig. <xref rid="Fig1" ref-type="fig">1</xref>B). This approach is preferable, as compared to annotating full videos, because it better captures the substantial variation in features and the feature-to-label relationship <italic>across</italic> videos, improving the generalizability of the classifier. That is, annotating short clips reduces dataset shift<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup> between the training set (i.e., the annotated videos) and the unlabeled videos.</p>
      <p id="Par9">After the set of videos has been split into clips, a subset of these user-specified clips, <inline-formula id="IEq4"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{validate}}$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">validate</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq4.gif"/></alternatives></inline-formula>, is randomly selected for manual annotation (Fig. <xref rid="Fig1" ref-type="fig">1</xref>B) using a GUI included in the toolbox release (Fig. <xref rid="Fig6" ref-type="fig">6</xref>B). After annotation, labeled clip data (video, features, and annotations), <inline-formula id="IEq5"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M26"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq5.gif"/></alternatives></inline-formula>, is used to train a recurrent neural network classifier (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec20" ref-type="sec">Classifier architecture</xref>” sections) and the confidence-based review system. To do so, we first further split <inline-formula id="IEq6"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M28"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq6.gif"/></alternatives></inline-formula> into a training set and a validation set (Fig. <xref rid="Fig1" ref-type="fig">1</xref>C). The training set, <inline-formula id="IEq7"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{train}}$$\end{document}</tex-math><mml:math id="M30"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">train</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq7.gif"/></alternatives></inline-formula>, comprises most of the labeled data and is directly used to train the classifier. For a given clip in <inline-formula id="IEq8"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{train}}$$\end{document}</tex-math><mml:math id="M32"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">train</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq8.gif"/></alternatives></inline-formula> with <inline-formula id="IEq9"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M34"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq9.gif"/></alternatives></inline-formula> frames, a spatiotemporal feature array of size <inline-formula id="IEq10"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[n, 512]$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>512</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq10.gif"/></alternatives></inline-formula> is input into a recurrent neural network classifier, along with a series of <inline-formula id="IEq11"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M38"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq11.gif"/></alternatives></inline-formula> manually annotated behavior labels. The network then tries to predict the manual annotations using the features; training iteratively reduces the difference between classifier-predicted and human annotations. The spatiotemporal features for a given segment of video represent the visual content of that segment; so, by predicting labels using these features, the classifier is indirectly generating predictions for the underlying video data. The independent validation set, <inline-formula id="IEq12"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{validate}}$$\end{document}</tex-math><mml:math id="M40"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">validate</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq12.gif"/></alternatives></inline-formula>, is used to tune the model training process and confidence-based review (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec21" ref-type="sec">Classifier training</xref>” sections). The trained classifier and confidence-based review system are then used to generate annotations and confidence scores for the remaining, unlabeled data,<inline-formula id="IEq13"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}.$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq13.gif"/></alternatives></inline-formula></p>
      <p id="Par10">We then introduce a confidence-based review system. Recall that, after the classifier has been trained, it can be used to predict behaviors in unlabeled data, <inline-formula id="IEq14"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}.$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq14.gif"/></alternatives></inline-formula> In addition, we output a confidence score for each clip in <inline-formula id="IEq15"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M46"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq15.gif"/></alternatives></inline-formula> corresponding the estimated accuracy of the labels produced for that clip (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec23" ref-type="sec">Confidence score definition</xref>” sections). In an ideal metric, a clip’s confidence score should correspond to the ground truth likelihood of the classifier-predicted behaviors being correct. The purpose of the confidence score is two-fold (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec25" ref-type="sec">Confidence-based review</xref>” sections). First, by generating estimated accuracies for each clip in <inline-formula id="IEq16"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M48"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq16.gif"/></alternatives></inline-formula>, we can estimate the <italic>overall</italic> accuracy of <inline-formula id="IEq17"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M50"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq17.gif"/></alternatives></inline-formula>. Just as there is variability in annotations between researchers, we can expect that even a well-performing classifier’s annotations will not exactly match those that would be produced if the unlabeled data was manually annotated. But, by providing an estimate of the agreement between human- and classifier-produced labels in <inline-formula id="IEq18"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M52"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq18.gif"/></alternatives></inline-formula> automatically, users can easily decide whether the classifier’s performance is sufficient for their given application. The second purpose is to enable researchers to preferentially review and correct clips where the classifier is less accurate over those where annotations are highly accurate. Rather than reviewing each clip in <inline-formula id="IEq19"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M54"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq19.gif"/></alternatives></inline-formula>, researchers can review and correct only the subset of clips where the classifier is uncertain about its predictions. If the confidence score is a precise estimate of accuracy, then the clips with a low confidence score will be the clips that the classifier performs poorly on, allowing for labels to be corrected more efficiently.</p>
    </sec>
    <sec id="Sec4">
      <title>Datasets</title>
      <p id="Par11">In our primary analyses, we evaluate our approach on two publicly available “benchmark” datasets of mice in a laboratory setting (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec14" ref-type="sec">Datasets</xref>” sectin). Both datasets are fully annotated, allowing us to test and evaluate our model. The first dataset, referred to as the “home-cage dataset,” was collected by Jhuang et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, and features 12 videos (10.5 h total; Fig. <xref rid="Fig2" ref-type="fig">2</xref>D) of singly housed mice in their home cages performing eight stereotypical, mutually-exclusive behaviors recorded from the side of the cage (Fig. <xref rid="MOESM1" ref-type="media">S1</xref>A). The second dataset, called “CRIM13,”<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> consists of 237 pairs of videos, recorded with synchronized side and top views, of pairs of mice engaging in social behavior, categorized into 13 distinct, mutually-exclusive actions (Fig. <xref rid="MOESM1" ref-type="media">S1</xref>B). Each video is approximately 10 min in duration, for a total of approximately 88 h of video and annotations (Fig. <xref rid="Fig2" ref-type="fig">2</xref>D). In addition to these benchmark datasets, we challenge the classifier by evaluating it on an “exploratory” unpublished dataset of octopus bimaculoides behavior during a habituation task (see “<xref rid="Sec13" ref-type="sec">Methods</xref><xref rid="Sec14" ref-type="sec">: Datasets</xref>” section).<fig id="Fig2"><label>Figure 2</label><caption><p>Classifier performance. (<bold>A</bold>) Test set accuracy and overall F1 score of the classifier on the home-cage dataset as a function of the proportion of the dataset used to train it. The proportion of data denoted on the <italic>x</italic>-axis is used to train the classifier, which is then evaluated on the remainder of the dataset. (<bold>B</bold>) Sample ethogram of classifier labels and ground-truth annotations from 10 randomly selected home-cage clips. Each colored line indicates the label of that behavior at the corresponding time stamp. Vertical black lines denote the divisions of the video into clips (one minute in duration). (<bold>C</bold>) Test set accuracy on the home-cage dataset as a function of the proportion of data used to train the classifier, for clips of varying length (clip duration denoted in minutes). (<bold>D</bold>) Total number of annotated frames in each dataset. (<bold>E</bold>–<bold>G</bold>) Same as (<bold>A</bold>–<bold>C</bold>)<bold>,</bold> but for the CRIM13 dataset. (<bold>H</bold>) Test set accuracy on the CRIM13 dataset as a function of the amount of training data for classifiers trained with features from the side camera, top camera, and both the side and top cameras. Lines and shaded regions in (<bold>A,C,E,G,H</bold>) indicate mean and standard error, respectively, across 10 random splits of the data.</p></caption><graphic xlink:href="41598_2023_29574_Fig2_HTML" id="MO3"/></fig></p>
      <p id="Par12">For the benchmark datasets, because they are already fully labeled, we evaluate our method by simulating the labeling process (see “<xref rid="Sec13" ref-type="sec">Methods</xref><xref rid="Sec16" ref-type="sec">: Simulating labeled data</xref>” section). We assume a user has chosen to annotate some proportion of the data and uses that data to train a classifier and obtain predictions for the remaining data. In practice, the user would run the classifier over the remaining data to automatically generate labels and use the confidence-based review system to review those labels as desired. Here, however, since the data have been annotated, we know the true labels for the “unlabeled” data. This allows us to test the performance of the method <italic>as if it were being used</italic> to produce labels for the remaining <inline-formula id="IEq20"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq20.gif"/></alternatives></inline-formula> data. This approach allows us to simulate performance across a range of labeling proportions, which in turn provides a measure of how a model can be expected to perform for a given amount of manual annotation time. So, for a given <inline-formula id="IEq21"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq21.gif"/></alternatives></inline-formula>, we train the classifier and confidence-based review using the “labeled data,” and then test how the approach performs on the remaining data (Fig. <xref rid="Fig1" ref-type="fig">1</xref>D).</p>
    </sec>
    <sec id="Sec5">
      <title>High classification accuracy with little training data</title>
      <p id="Par13">We first evaluate the performance of the classifier (i.e., accuracy and F1; see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec22" ref-type="sec">Classifier evaluation</xref>” section) with varying amounts of training data (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A,E), and show that it requires remarkably little manual annotation to achieve high accuracy. For a given proportion labeled (i.e., <inline-formula id="IEq22"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq22.gif"/></alternatives></inline-formula> above), a corresponding proportion of project clips are randomly selected from all the clips in the dataset and used to train the classifier, which is then evaluated on the remaining data (i.e., the test set). For both datasets, accuracy and F1 improve as more training data is used, with steep increases for the first ten percent of the data, and more gradual increases after twenty percent. Example classifier output and ground truth annotations are shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>B,F.</p>
      <p id="Par14">We then compare the performance of our model with existing ones (Table <xref rid="Tab1" ref-type="table">1</xref>; see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec17" ref-type="sec">Comparison with existing methods</xref>” section). On the home-cage dataset, in addition to showing higher accuracy than the agreement between human annotators, our classifier outperforms existing commercial options (HomeCageScan 2.0, CleverSys Inc., evaluated by Jhuang et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>), as well as approaches based on hand-crafted features<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> and 3D convolutional neural networks<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. We do note, however, that the hidden Markov model approach detailed in Jiang et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> performed marginally better on the home-cage dataset than DeepAction. The classifier demonstrates above-human performance and surpasses the sparse spatio-temporal feature approach detailed in Burgos-Artizzu et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> on the CRIM13 dataset. It also performs better than prior methods based on temporal features<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, independent component analysis<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, hierarchical sparse coding<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>, integrated sparse and dense trajectory features<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Performance comparison with existing methods Shown is the accuracy of various annotation methods on both datasets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model</th><th align="left">Accuracy (%)</th></tr></thead><tbody><tr><td align="left" colspan="2">Home-cage</td></tr><tr><td align="left">Human</td><td char="." align="char">71.6</td></tr><tr><td align="left">CleverSys commercial system<sup><xref ref-type="bibr" rid="CR7">7</xref></sup></td><td char="." align="char">61.0</td></tr><tr><td align="left">Jhuang et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup></td><td char="." align="char">78.3</td></tr><tr><td align="left">Le and Murari<sup><xref ref-type="bibr" rid="CR23">23</xref></sup></td><td char="." align="char">73.5</td></tr><tr><td align="left">Jiang et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup></td><td char="." align="char">81.5</td></tr><tr><td align="left">DeepAction</td><td char="." align="char">79.5</td></tr><tr><td align="left" colspan="2">CRIM13</td></tr><tr><td align="left">Human</td><td char="." align="char">69.7</td></tr><tr><td align="left">Burgos-Artizzu et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup></td><td char="." align="char">62.6</td></tr><tr><td align="left">Eyjolfsdottir et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup></td><td char="." align="char">37.2</td></tr><tr><td align="left">Zhang et al.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup></td><td char="." align="char">61.9</td></tr><tr><td align="left">Meng et al.<sup><xref ref-type="bibr" rid="CR27">27</xref></sup></td><td char="." align="char">68.6</td></tr><tr><td align="left">DeepAction</td><td char="." align="char">73.9%</td></tr></tbody></table><table-wrap-foot><p>“Human” denotes the agreement between two human annotator groups (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec15" ref-type="sec">Inter-observer reliability</xref>” section). The accuracy for DeepAction on the home-cage and CRIM13 datasets is the mean accuracy from 12-fold and two-fold cross-validation, respectively, to provide a comparable reference to Jhuang et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> and Burgos-Artizzu et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec17" ref-type="sec">Comparison with existing methods</xref>” section).</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec6">
      <title>Data input process improves performance</title>
      <p id="Par15">Next, we consider how unique aspects of our data preparation process affect the performance of the classifier. Specifically, we investigate our hypothesis that, given equal annotation time (i.e., an equal labeled proportion), our classifier shows superior performance when it is trained using relatively short clips rather than longer ones. As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>C,G, this is indeed the case. While presumably there is a limit to this phenomenon (i.e., if the clip length were to be only a handful of frames, the classifier would fail to gain enough context to accurately predict its labels), in the clip durations tested here, varying between one and 20 min, shorter clips are both more accurate for a given level of annotation and demonstrate a more rapid improvement as training data increases. The CRIM13 dataset is recorded using synchronized top- and side-view cameras. In our main analysis we combine the features from both cameras (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec19" ref-type="sec">Feature extraction</xref>” section); in Fig. <xref rid="Fig2" ref-type="fig">2</xref>H we confirm that this is advantageous. The classifier trained using features from both views demonstrates superior performance to one trained only features from the side camera or only those from the top camera, indicating our method effectively integrates information from multiple cameras.</p>
    </sec>
    <sec id="Sec7">
      <title>DeepAction performs well across behaviors</title>
      <p id="Par16">An important consideration, in addition to overall classifier performance, is classifier performance on specific behaviors. In highly imbalanced datasets (i.e., those in which a small number of behaviors are disproportionately common), high accuracy can be achieved by a classifier with poor discriminative capacity if its predictions are the most common classes. The home-cage dataset, except for the “drink” behavior (0.26 percent of labels), is relatively well-balanced (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A). For non-drinking behaviors, the classifier shows consistently high performance (Fig. <xref rid="Fig3" ref-type="fig">3</xref>B), despite modest variation in the prevalence of each label. The CRIM13 dataset displays significantly less balance (Fig. <xref rid="Fig3" ref-type="fig">3</xref>D), with a high proportion of behaviors classified as “other” (denoting non-social behavior). The high incidence of the “other” behavior accounts for the high performance of the classifier at near-zero training data proportions (approximately 55 percent accuracy; Fig. <xref rid="Fig2" ref-type="fig">2</xref>E), and a disproportionately large number of social behaviors being incorrectly labeled as “other” by the classifier (Fig. <xref rid="Fig3" ref-type="fig">3</xref>E). We also note that the distribution of bout lengths (i.e., the number of frames for which a behavior consecutively occurs) predicted by the classifier is qualitatively similar to the true distribution of bout length for most behaviors (Fig. <xref rid="Fig3" ref-type="fig">3</xref>C,F). In the home-cage dataset we see that the classifier underpredicts bout lengths for the “rest” behavior, which has an exceptionally long average bout length (2,563 frames vs. an average of 88 frames for all other behaviors), despite its high performance in predicting the rest behavior overall (recall: 0.95, precision: 0.98) on the same test set. In the CRIM13 dataset, we observe that the classifier underpredicts bout lengths for the behaviors it performs worst on: “eat,” “human,” and “drink.”<fig id="Fig3"><label>Figure 3</label><caption><p>Dataset behavior characteristics and classifier performance. (<bold>A</bold>) Ground-truth distribution of behavior labels (i.e., the number of frames in which each behavior occurs as a proportion of the total number of frames in the dataset) for the home-cage dataset. (<bold>B</bold>) Example confusion matrix showing the classifier performance by behavior on the home-cage dataset, with cell values normalized relative to the true class. (<bold>C</bold>) True bout lengths and example predicted bout lengths for the home-cage dataset, grouped by behavior. A single “bout” refers to a period of continuously occurring behavior, and the corresponding bout length to the length of that period in number of frames. Median bout length is marked by the solid black lines, and each dot corresponds to a single bout. (<bold>D</bold>–<bold>F</bold>) Similar to (<bold>A</bold>–<bold>C</bold>), but for the CRIM13 dataset.</p></caption><graphic xlink:href="41598_2023_29574_Fig3_HTML" id="MO4"/></fig></p>
      <p id="Par17">To examine classifier performance as a function of the amount of data used to train it, we calculate the precision, recall, and F1 score (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec22" ref-type="sec">Classifier evaluation</xref>” section) for each behavior with varying labeled data proportions (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). In the home-cage dataset, for non-drinking behaviors, we observe a similar pattern in behavior-level improvement as we do to overall accuracy—a rapid increase at low training data proportions, followed by a more gradual one at 10 to 20 percent training data (Fig. <xref rid="Fig4" ref-type="fig">4</xref>A–G). This pattern holds even given the relatively large difference in incidence between the least common (eat, at 7.5 percent of labels) and most common (micromovement, 24.8 percent of labels) non-drink behaviors. For drinking behavior, however, due to its exceptionally low incidence, we observe a more inconsistent, non-gradual improvement in performance across training set proportions (Fig. <xref rid="Fig4" ref-type="fig">4</xref>H).<fig id="Fig4"><label>Figure 4</label><caption><p>Home-cage behavior-level classifier performance. (<bold>A</bold>–<bold>H</bold>) Precision, recall, and F1 scores for each behavior in the home-cage dataset as a function of the proportion of data used to train the classifier. Lines and shaded regions indicate mean and standard error, respectively, across 10 random splits of the data.</p></caption><graphic xlink:href="41598_2023_29574_Fig4_HTML" id="MO5"/></fig></p>
      <p id="Par18">This pattern generally applies in the CRIM13 dataset as well (Fig. <xref rid="MOESM1" ref-type="media">S3</xref>). For most behaviors we observe a rapid increase in recall, precision, and F1, followed by a relative slowdown in improvement as a function of training proportion at a training proportion of approximately 0.3. There are notable exceptions to this pattern. First, we observe that, as compared to very low training proportions, the recall of “other” decreases slightly as the classifier defaulted to predicting “other” with disproportionate frequency (Fig. <xref rid="MOESM1" ref-type="media">S3</xref>A). The F1 score, however, increased, indicating an improved balance between recall and accuracy. And second, we observe that “eat,” “circle,” and “drink” show sporadic improvements in recall, precision, and F1 as a function of training proportion (Fig. <xref rid="MOESM1" ref-type="media">S3</xref>I,L,M). As with “drink” in the home-cage dataset, these are all low-incidence behaviors (approximately 2 percent of ground-truth labels or less), particularly in the case of “circle” and “drink” (approximately 0.3 percent of ground-truth labels).</p>
    </sec>
    <sec id="Sec8">
      <title>DeepAction performs well on the exploratory dataset</title>
      <p id="Par19">On the exploratory dataset, we evaluated the classifier on a six-behavior dataset of seven octopus bimaculoides behavior videos collected in-house (see Fig. <xref rid="Fig5" ref-type="fig">5</xref>D). Overall, the classifier performs relatively well, with an accuracy of 73.1 percent; see the sample ethogram in Fig. <xref rid="Fig5" ref-type="fig">5</xref>C. This is much lower than human-level performance, however, given that manual annotators reached an agreement of 88.7 percent on the same, independently annotated video (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec14" ref-type="sec">Dataset</xref>” section). In terms of behavior-level performance, the classifier performs well on crawling, none (indicating behavior of interest) and fixed pattern, but poorly on relaxation, jetting, and expanding (Fig. <xref rid="Fig5" ref-type="fig">5</xref>B). The poor performance on these behaviors is likely due to their infrequency (Fig. <xref rid="Fig5" ref-type="fig">5</xref>A), particularly in the case of jetting and expanding.<fig id="Fig5"><label>Figure 5</label><caption><p>Exploratory dataset behavior characteristics and classifier performance. (<bold>A</bold>) Ground-truth distribution of behavior labels for the exploratory (octopus) dataset. (<bold>B</bold>) Confusion matrix of the classifier’s performance on the test fold from tenfold cross validation. (<bold>C</bold>) Example ethogram of classifier labels and ground-truth annotations from 30 randomly selected octopus behavior clips (each one minute in duration, sampled at 10 frames per second). (<bold>D)</bold> Frame from an example octopus video. The red inset square in the top frame indicates the location of the animal, which is shown magnified below.</p></caption><graphic xlink:href="41598_2023_29574_Fig5_HTML" id="MO6"/></fig></p>
    </sec>
    <sec id="Sec9">
      <title>Calibrated confidence scores accurately predict classification accuracy</title>
      <p id="Par20">Next, we turn our focus from the performance of the classifier to the performance of the confidence-based review. Recall that we generate a confidence score for each clip that represents the classifier’s prediction of the accuracy of its predicted labels (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec23" ref-type="sec">Confidence score definition</xref>” section). In Fig. <xref rid="Fig6" ref-type="fig">6</xref>A,D we demonstrate that there is a strong correlation between confidence score and accuracy, for both confidence scores based on maximum softmax probability and those derived using temperature scaling (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec24" ref-type="sec">Confidence score calculation</xref>” section). We next consider the mean absolute error (MAE; see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec26" ref-type="sec">Evaluating confidence score calibration</xref>” section) between clips’ predicted accuracy (i.e., confidence score) and actual accuracy across training data proportions. Here, the MAE expresses the amount by which a randomly selected clip’s confidence score differs (whether positively or negatively) from its accuracy. The MAE derived using temperature scaling performs slightly better than the one derived using softmax probabilities on the CRIM13 dataset (Fig. <xref rid="Fig6" ref-type="fig">6</xref>E) but not the home-cage dataset (Fig. <xref rid="Fig6" ref-type="fig">6</xref>B). While the MAE for both methods improves initially, it plateaus after the proportion of data labeled reaches about 20 percent, indicating that exact estimates of clip accuracy remain elusive.<fig id="Fig6"><label>Figure 6</label><caption><p>Confidence measure improvements across training proportions. (<bold>A</bold>) Example of the correlation between clip confidence score and clip accuracy. Dashed lines indicating the line of best-fit with r-squared values inset. (<bold>B</bold>) Mean absolute error (MAE) and (<bold>C</bold>) mean signed difference (MSD) between clip confidence score and clip accuracy as a function of the amount of data used to train the classifier. (<bold>D</bold>–<bold>F</bold>) Similar to (<bold>A</bold>–<bold>C</bold>), but for the CRIM13 dataset. (<bold>G</bold>) Example relationship between the proportion of test clips reviewed (and corrected) and test set accuracy from the home-cage dataset, where clips are reviewed in an order determined by the confidence scoring method, for various scoring methods (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec25" ref-type="sec">Confidence-based review</xref>” section). (<bold>H</bold>) Review efficiency metric, quantifying how effectively a given confidence scoring method performs when low-confidence clips are reviewed first (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec27" ref-type="sec">Evaluating review efficiency</xref>” section) as a function of the amount of training data, for the home-cage dataset. (<bold>I</bold>) Same as (<bold>H</bold>)<bold>,</bold> but for CRIM13. Lines and shaded regions in (<bold>B,C,E,F,H,I</bold>) indicate mean and standard error across 10 random splits of the data.</p></caption><graphic xlink:href="41598_2023_29574_Fig6_HTML" id="MO2"/></fig></p>
      <p id="Par21">Perhaps more important than predicting the accuracy of classifications on a single clip is predicting the accuracy of classifications across all unlabeled clips. While the absolute error of individual clips might fluctuate, if the differences cancel out (i.e., if predictions are just as likely to be overconfident as they are to be underconfident), the estimated accuracy of the set as whole will be accurate. This is useful in practice: if the confidence score is biased (e.g., it consistently over-estimates accuracy), then the estimated accuracy of the unlabeled data will systematically differ from its true accuracy. If the score is unbiased, however, then it is useful for evaluating whether the predicted agreement between classifier-produced and manually-produced annotations is sufficient for a given application. To investigate this, we consider the mean signed difference (MSD; see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec26" ref-type="sec">Evaluating confidence score calibration</xref>” section), which quantifies the difference between the predicted accuracy of all predictions in the test set and the actual accuracy of the test set. As shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>C,F, the temperature scaling-based confidence score has a lower MSD than the softmax-based one, demonstrating that confidence scores derived from temperature scaling are less (positively) biased. While the softmax score consistently overestimates the average accuracy of its predictions by approximately 6–8 percent regardless of training proportion, temperature scaling generally is generally overconfident by only 1–2 percent.</p>
    </sec>
    <sec id="Sec10">
      <title>Uncertainty-based review reduces correction time</title>
      <p id="Par22">Having established the high correspondence between clip confidence score and clip accuracy, we investigate how well our confidence-based review system leverages those confidence scores to reduce the time it takes to review and correct classifier-produced labels. A viable confidence measure would allow clips with a lower confidence score (i.e., lower predicted accuracy) to be preferentially reviewed over those with a higher confidence score, decreasing the manual review time required to obtain acceptably high-quality annotations. Rather than reviewing all the classifier-produced labels, the user could instead review only a portion with the lowest accuracy (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec25" ref-type="sec">Confidence-based review</xref>” section). We provide an example of this process in practice in Fig. <xref rid="Fig6" ref-type="fig">6</xref>G, which simulates the relationship between the proportion of test video reviewed and the overall accuracy of the labels in the test set. If no video is reviewed, the average accuracy of the test set is the agreement between the classifier produced labels and the ground truth annotations. If one then begins to review and correct videos, the total accuracy increases, since we assume that incorrect classifier-produced labels are corrected. If videos are selected randomly, the relationship between the proportion of the test set reviewed and the test set accuracy is approximately linear—if each video selected is equally likely to have the same number of incorrect labels, then the increase in overall accuracy from correcting those labels is the same for all videos.</p>
      <p id="Par23">If, however, one sorts by confidence measure and reviews the lowest confidence clips first, then, ideally, the subset of videos reviewed will tend to be those with relatively lower accuracy than those not reviewed. The upper bound on the performance of the confidence-based review is a review where the clips are sorted by their actual accuracy (which is what the confidence score approximates). While this is unknown in practice (since the data being reviewed are unlabeled) we simulate it here to provide an upper bound for the performance of the confidence-based review. To compare the performance of the confidence-based review across labeled data proportions, we calculate a metric called “review efficiency” for each split of the data, which expresses the performance of the confidence score bounded by the best (optimal selection, review efficiency of <inline-formula id="IEq23"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq23.gif"/></alternatives></inline-formula>) and worst (random selection, review efficiency of <inline-formula id="IEq24"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq24.gif"/></alternatives></inline-formula>) possible performance (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec27" ref-type="sec">Evaluating review efficiency</xref>” section). As shown in F<xref rid="Fig6" ref-type="fig">i</xref>g. <xref rid="Fig6" ref-type="fig">6</xref>H,I, as the proportion of data labeled increases, both confidence scores become closer to optimal in sorting videos for review. The softmax- and temperature scaling-based scores perform approximately the same.</p>
    </sec>
    <sec id="Sec11">
      <title>Annotation GUI improves annotation and review</title>
      <p id="Par24">While we evaluate our method here using fully annotated datasets, the central purpose of this work is to improve the annotation of behavior in experimental settings. For this reason, we release the entire system as a MATLAB toolbox as a GitHub repository that includes example projects and GUI interfaces for defining the behavior set of interest (Fig. <xref rid="Fig7" ref-type="fig">7</xref>A) and conducting manual annotation and confidence-based review (Fig. <xref rid="Fig7" ref-type="fig">7</xref>B). For example, we integrate clip-wise annotation by pre-dividing project videos into clips and presenting clips, rather than videos, for users to annotate. In addition, we incorporate the confidence-based review process into the GUI: incomplete (i.e., unreviewed annotations) are shown in a table, with low-confidence clips (and their corresponding confidence scores) appearing at the top so that users can select them for review first. We also include information about the status of the project (e.g., number and duration of videos annotated, video and clip information, etc.) within the GUI. During confidence-based review, we also provide an estimate of <inline-formula id="IEq25"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}({\mathcal{D}}^{\mathrm{unlabeled}})$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq25.gif"/></alternatives></inline-formula> directly, updating it as more annotations are completed. Users can easily load videos, annotate them using the keyboard, add or remove behaviors, and export the results entirely within the GUI.<fig id="Fig7"><label>Figure 7</label><caption><p>Example usage of the MATLAB apps included in the toolbox. (<bold>A</bold>) GUI for defining the set of behaviors in a dataset. Each behavior label corresponds to a unique keyboard key (“key”), which is used to designate the start and stop of behaviors during manual annotation. (<bold>B</bold>) An example of the annotation GUI used in confidence-based review to correct false classifier-produced predictions. It features tables of the complete (i.e., human annotated or reviewed) and unreviewed (i.e., classifier-annotated) clips in the project. During review, the tables include a confidence score for each clip (“score”) as well as an estimated overall accuracy for all unannotated data. Users select clips to review from the annotation tables, which are then shown in the video viewer box (top left) along with their predicted labels. Users create or correct the labels of the behaviors appearing in the video, with both annotation and video playback controlled via keyboard. Behaviors and their corresponding keystrokes are shown in the “Behavior Labels” panel. After completing the annotation of each clip, users press the “Mark Complete” button to save their progress.</p></caption><graphic xlink:href="41598_2023_29574_Fig7_HTML" id="MO7"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Discussion</title>
    <p id="Par25">Here we present a method for the automatic annotation of laboratory animal behavior from video. Our classifier produces high accuracy annotations, rivaling or surpassing human-level agreement, while requiring relatively little human annotation time, and performs well across behaviors of varying incidence and timescale. Our confidence scores accurately predict accuracy and are useful in reducing the time required for human annotators to review and correct classifier-produced annotations. Finally, we release the system as an open-source GitHub repository, complete with an annotation GUI and example projects.</p>
    <p id="Par26">The primary strength of our method is the classifier’s capacity to generate accurate classifications from raw video frames. By classifying behavior using raw frame information, DeepAction removes the need to annotate keypoints and create hand-crafted features that adequately encapsulate a given animals’ behavioral repertoire. This removes both a tedious aspect of manual annotation (i.e., keypoint annotation in addition to behavioral annotation), and alleviates the need for researchers to construct behavior-encapsulating features, which is both time-consuming and often suboptimal. We also note that the performance of DeepAction surpasses that of approaches developed using hand-crafted features on both rodent datasets analyzed (Table <xref rid="Tab1" ref-type="table">1</xref>), indicating that the automated feature extraction approach does not compromise performance. On the benchmark octopus dataset, we demonstrate the generalizability of the classifier to non-rodent animal models. We do, however, note that its performance is not as strong as on the rodent datasets. This is likely due either to the smaller amount of training data (6.15 h total), or the fact that the size of the octopus was smaller, relative to the field of view, than in the rodent datasets.</p>
    <p id="Par27">The base level performance of the classifier has the potential to significantly expedite the behavioral research process. Here, a useful benchmark is to compare the accuracy of the classifier (defined as the agreement between classifier-produced labels and the primary set of annotations; see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec15" ref-type="sec">Inter-observer reliability</xref>” section) to the agreement between independent annotators (agreement between the primary set of annotations and a second, independent set used to evaluate inter-observer reliability). In our analysis, we find that the classifier requires that only 18 percent of data be annotated to surpass the agreement (71.6 percent) between human annotators on the home-cage dataset (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>A). Given that the home-cage dataset took 264 h to manually annotate<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, if human-level agreement is defined as the threshold for acceptable annotations, our method would reduce this time to 47 h, saving researchers 82% of the time required to carry out the tedious step of video annotation. Similarly, DeepAction surpasses human-level agreement (69.7 percent) on the CRIM13 dataset with 25 percent of data annotated (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>E), saving researchers 75% of their time. Since CRIM13 took 350 h to annotate<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, using our method instead of manual annotation would have reduced this time to 88 h, while maintaining annotation quality at the level of human annotators.</p>
    <p id="Par28">Our confidence-scoring system is important for two reasons. The first is a modest increase in review efficiency—if one is to manually review and check some number of automatically-generated behavioral labels, selecting those with the lowest confidence scores is preferable to doing so randomly. We show that this is true across training dataset sizes, and that review using confidence scores becomes closer to optimal as more data is annotated. The second, and perhaps more important, reason is that the temperature scaling-based confidence score generates an accurate estimate of the overall agreement between classifier- and human-produced labels on unlabeled data (i.e., where the “human-produced labels” are unknown). This means that researchers could annotate data until the estimated accuracy of the unlabeled data reached a given threshold of acceptable agreement for their given behavioral analysis, and then export the automated annotations without having to review and correct them.</p>
    <p id="Par29">Our tool has several practical advantages. First is a GUI for annotation and confidence-based review. Second is adaptability; in our GitHub release we provide additional pretrained CNNs (e.g., ResNet50 and Inception ResNetv2) with which potentially more useful features could be extracted, a computationally faster optical flow algorithm<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>, and options to parallelize a number of the computationally intensive project functions (e.g., temporal frame generation and feature extraction). A final advantage is modularity: users can use the classification portion of the workflow without the review component, the annotator can for its interface alone, etc.</p>
    <p id="Par30">Though the toolbox presented here represents a significant advancement as compared to entirely manual annotation, there are several avenues for further exploration and potential improvement. While our clip selection process demonstrates superior performance to whole-video annotation, in the results here we select clips randomly. In practice, the confidence-based review system can be used to iteratively train the classifier (Fig. <xref rid="Fig1" ref-type="fig">1</xref>A), where low-confidence clips are reviewed, corrected, and used to re-train the classifier (though we do not explore whether this is preferable to random selection here). An alternative approach would be to adapt methods used in video summarization to cluster video clips by their similarity, and then select the subset of clips best representative of the overall dataset<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>. While our classifier is based on a LSTM with bidirectional layers, it is possible that alternate architectures would demonstrate superior performance<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR32">32</xref></sup>. Relatedly, the classifier described here assumes behaviors are mutually exclusive; that is, none of the behaviors can occur at the same time. However, for datasets in which this is not the case, the cross-entropy loss function used here could easily be adjusted to allow for co-occurring behaviors. A final avenue for further exploration is our approach to calculating confidence scores. Though our system is already close to optimal, given enough training data (Fig. <xref rid="Fig6" ref-type="fig">6</xref>H,I), there are a number of density-based metrics<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> or those that utilize Bayesian dropout<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> that might provide superior performance to the temperature scaling-based one employ here.</p>
  </sec>
  <sec id="Sec13">
    <title>Methods</title>
    <sec id="Sec14">
      <title>Datasets</title>
      <p id="Par31">Given that rodents are widely used in behavioral research, and mice are the most studied rodents<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, we chose two publicly-available datasets featuring mice engaging in a range of behaviors in our main analysis. The first dataset, referred to as the “home-cage dataset,” was collected by Jhuang et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> and features 12 videos (approximately 10.5 h and 1.13 million frames in total) of singly housed mice in their home cages, recorded from the side view. Video resolution is <inline-formula id="IEq26"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$320\times 240$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mn>320</mml:mn><mml:mo>×</mml:mo><mml:mn>240</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq26.gif"/></alternatives></inline-formula> pixels. The authors annotate each video in full and identify eight mutually exclusive behaviors (Fig. <xref rid="MOESM1" ref-type="media">S1</xref>A) of varying incidence (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A). This dataset allows us to benchmark our approach against existing methods, allows us to evaluate our method on a common use-case, and is relatively well-balanced in terms of the incidence of each behavior.</p>
      <p id="Par32">The second dataset used is the Caltech Resident-Intruder Mouse dataset (CRIM13), collected by Burgos-Artizzu et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. It consists of 237 pairs of videos, recorded from synchronized top- and side-view cameras, at 25 frames per second and an 8-bit pixel depth. Videos are approximately 10 min long, and the authors label 13 mutually exclusive actions (Fig. <xref rid="MOESM1" ref-type="media">S1</xref>B). Of these actions, 12 are social behaviors, and the remaining action is the category “other,” which denotes periods where no behavior of interest occurs<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. This dataset features a number of challenges absent from the Jhuang et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> dataset. In addition to including social behavior (in contrast to the home-cage dataset, which features singly-housed mice), it presents two algorithmic challenges. First, videos are recorded using a pair of synchronized cameras. This allows us to test multiple-camera integration functionality (see “<xref rid="Sec13" ref-type="sec">Methods</xref>: <xref rid="Sec19" ref-type="sec">Feature extraction</xref>” section), to evaluate classifier performance using features from multiple cameras. And second, it is highly unbalanced, with a slight majority of all annotations being the category “other” (periods during which no social behavior occurred; Fig. <xref rid="Fig3" ref-type="fig">3</xref>D).</p>
      <p id="Par33">We also include an exploratory dataset, to demonstrate the applicability of our model to non-rodent models, comprised of seven unique videos of single-housed octopus bimaculoides during a study of octopus habituation behaviors in the Dartmouth octopus lab. One video (approximately 62 min in length) was annotated by two different annotators, allowing us to assess inter-observer reliability by calculating the agreement between these two independent annotations. The videos span approximately 6.75 h in total, with 6.15 h annotated. Video was recorded at 10 frames per second with a resolution of <inline-formula id="IEq27"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$640\times 436$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mn>640</mml:mn><mml:mo>×</mml:mo><mml:mn>436</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq27.gif"/></alternatives></inline-formula> pixels. We define five behaviors of interest: crawling, fixed pattern (crawling in fixed formation along the tank wall), relaxation, jetting (quick acceleration away from stimuli), and expanding (tentacle spread in alarm reaction or aggressive display), and an indicator for when none of these behaviors occur (none). In the original dataset, there were three additional behaviors (inking/jetting, display of dominance, color change), comprising a very small number of the total frames, which could co-occur with the other six behaviors (crawling, fixed pattern, relaxation, jetting, expanding, none). However, because our classification model can only predict mutually-exclusive classes at the current time, we removed these three behaviors from our input annotations.</p>
    </sec>
    <sec id="Sec15">
      <title>Inter-observer reliability</title>
      <p id="Par34">Both datasets include a set of annotations performed by two groups of annotators. The primary set of annotations was produced by the first group of annotators and includes all video in the dataset. The secondary set of annotations was performed by a second, independent set of annotators on a subset of videos. We use the primary set of annotations to train and evaluate our method, and the secondary set to establish inter-observer reliability; that is, how much two, independent human annotator’s annotations can be expected to differ. Given this, classifier-produced labels can be most precisely interpreted as the predicted behavior <italic>if the video was annotated by the first group of annotators</italic>. This distinction becomes important because we benchmark the accuracy of our method (i.e., the agreement between the classifier’s predictions and the primary set of annotations) relative to the inter-observer agreement (i.e., the agreement between the first and second group of annotators, on the subset of video labeled by both groups). So, for example, when we note that our model achieves accuracy “above human agreement,” we mean that our classifier predicts the labels from the first human annotator group better than the second human annotator group does. In the case of the home-cage dataset, the agreement between the primary and secondary sets was 78.3 percent, compared on a 1.6 h subset of all dataset video<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. For CRIM13, agreement was 69.7 percent, evaluated on a random selection of 12 videos<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>.</p>
    </sec>
    <sec id="Sec16">
      <title>Simulating labeled data</title>
      <p id="Par35">To simulate our approach’s performance with varying amount of training data, in our primary analyses we train the classifier using the following amounts of labeling:<disp-formula id="Equa"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{labeled}}=\left[0.02:0.02:0.2, 0.2:0.05:0.9\right].$$\end{document}</tex-math><mml:math id="M72" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mn>0.02</mml:mn><mml:mo>:</mml:mo><mml:mn>0.02</mml:mn><mml:mo>:</mml:mo><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mn>0.2</mml:mn><mml:mo>:</mml:mo><mml:mn>0.05</mml:mn><mml:mo>:</mml:mo><mml:mn>0.9</mml:mn></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par36">That is, we use a proportion of all data, <inline-formula id="IEq28"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{prop}}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M74"><mml:msub><mml:mi mathvariant="normal">prop</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq28.gif"/></alternatives></inline-formula>, to construct our training and validation sets (i.e., <inline-formula id="IEq29"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}})$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq29.gif"/></alternatives></inline-formula>, and the remaining <inline-formula id="IEq30"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${1-\mathrm{prop}}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M78"><mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi mathvariant="normal">prop</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq30.gif"/></alternatives></inline-formula> data to create our test set, <inline-formula id="IEq31"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{test}}$$\end{document}</tex-math><mml:math id="M80"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">test</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq31.gif"/></alternatives></inline-formula> (Fig. <xref rid="Fig1" ref-type="fig">1</xref>B,D). We use an increment of <inline-formula id="IEq32"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.02$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:mn>0.02</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq32.gif"/></alternatives></inline-formula> for low training proportions (up to <inline-formula id="IEq33"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.20$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:mn>0.20</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq33.gif"/></alternatives></inline-formula>), because that is when we see the greatest change relative to a small change in added training data (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A,E). We increment values from <inline-formula id="IEq34"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.25$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:mn>0.25</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq34.gif"/></alternatives></inline-formula> to <inline-formula id="IEq35"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.90$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:mn>0.90</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq35.gif"/></alternatives></inline-formula> by <inline-formula id="IEq36"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.05$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:mn>0.05</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq36.gif"/></alternatives></inline-formula>. This gives us a set of 24 training proportions per analysis. Additionally, for each training proportion, unless otherwise noted, we evaluate the model on 10 random splits of the data. In our main analyses, we use a clip length of one minute for both datasets.</p>
    </sec>
    <sec id="Sec17">
      <title>Comparison with existing methods</title>
      <p id="Par37">When comparing our model to existing methods, we employ <italic>k</italic>-fold validation instead of evaluating on random splits of the data. In the case of the home-cage dataset, the existent methods cited employ a “leave one out” approach—using 11 of the 12 videos to train their methods, and the remaining video to test it. In our approach, however, we rely on splitting the data into clips, so instead we use 12-fold cross-validation, where we randomly split the dataset clips into 12 folds and then employ cross-validation on the clips, rather than entire videos. In evaluating their approach’s performance on the CRIM13 dataset, Burgos-Artizzu et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> selected 104 videos for training and 133 for testing, meaning that they trained their program on 44 percent of the data, and tested it on 56 percent. Here, we evaluate our method relative to theirs using two-fold cross validation (50 percent test and 50 percent train split) to retain similar levels of training data.</p>
    </sec>
    <sec id="Sec18">
      <title>Frame extraction</title>
      <p id="Par38">To generate spatial frames, we extract raw video frames from each video file. Rather than save each image as an image file in a directory, we save the entire sequence of images corresponding to a single video to a sequence file, using the implementation provided by Dollár<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> with JPG compression. This has the advantage of making the video frames easier to transfer between file systems and readable on any operating system (which is useful for users running the toolbox on high performance computing clusters). To generate the temporal component, we use the TV-L1 algorithm<sup><xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup>, which shows superior performance to alternate optical flow algorithms<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, to calculate the dense optical flow between pairs of sequential video frames and represent it visually via the MATLAB implementation by Cun<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>. In the visual representation of optical flow fields, hue and brightness of a pixel represent the orientation and magnitude of that pixel’s motion between sequential frames. By representing motion information of the video as a set of images, we can use a similar feature extraction method for both spatial and temporal frames. Just as the features derived from the spatial images represent the spatial information in the video, the features derived from the temporal images should provide a representation of the motion information in the video.</p>
    </sec>
    <sec id="Sec19">
      <title>Feature extraction</title>
      <p id="Par39">We utilize the pretrained ResNet18 convolutional neural network (CNN) to extract high-level features from the spatial and temporal video frames. Often used in image processing applications, CNNs consist of a series of layers that take an image as an input and generate an output based on the content of that image. Intuitively, classification CNNs can be broken down into two components: feature extraction and classification. In the feature extraction component, the network uses a series of layers to extract increasingly complex features from the image. In the classification component, the network uses the highest-level features to generate a final classification for the image (e.g., “dog” or “cat”). In the case of pretrained CNNs, the network learns to extract important features from the input image through training—by generating predictions for a set of images for which the ground truth is known, and then modifying the network based on the deviation of the predicted classification from the true classification, the network learns which features in the image are important in discriminating one object class from another. In pretrained CNNs, such as the ResNet18, which was trained to categorize millions of images from the ImageNet database into one thousand distinct classes<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, early layers detect generic features (e.g., edges, textures, and simple patterns) and later layers represent image data more abstractly<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>.</p>
      <p id="Par40">Here, we leverage transfer learning—where a network trained for one context is used in another—to extract a low-dimensional representation of the data in the spatial and temporal video frames. The idea is that, since the ResNet18 is trained on a large, general object dataset, the generality of the network allows us to obtain an abstract representation of the salient visual features in the underlying video by extracting activations from the later layers of the network in response to a completely different set of images (in this case, laboratory video of animal behavior). To extract features from the ResNet18 network for a given image, we input the image into the network and record the response (“activations”) from a specified layer of the network. In this work, we chose to extract activations from the global average pooling layer (“pool5” in MATLAB) of the ResNet18, close to the end of the network (to obtain high-level feature representations). This generates a feature vector of length <inline-formula id="IEq37"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$512$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:mn>512</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq37.gif"/></alternatives></inline-formula>, representing high level CNN features for each image.</p>
      <p id="Par41">By default, the ResNet18 accepts input images of size <inline-formula id="IEq38"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[224, 224, 3]$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq38.gif"/></alternatives></inline-formula> (i.e., images with a width and height of 224 pixels and three color channels), so we preprocess frames by first resizing them to a width and height of 224 pixels. In the case of spatial frames, the resized images are input directly into the unmodified network. For temporal frames, however, rather than inputting frames into the network individually, we “stack” each input frame to the CNN with the five frames preceding it and the five frames following it, resulting in an input size of <inline-formula id="IEq39"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[224, 224, 33]$$\end{document}</tex-math><mml:math id="M96"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>33</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq39.gif"/></alternatives></inline-formula>. This approach allows the network to extract features with longer-term motion information and has been shown to improve discriminative performance<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>. We select a stack size of 11 based on the findings from Simonyan and Zisserman<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. By default, the ResNet18 network only accepts inputs of size <inline-formula id="IEq40"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[224, 224, 3]$$\end{document}</tex-math><mml:math id="M98"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq40.gif"/></alternatives></inline-formula>, so to modify it so that it accepts inputs of size <inline-formula id="IEq41"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[224, 224, 33]$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>224</mml:mn><mml:mo>,</mml:mo><mml:mn>33</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq41.gif"/></alternatives></inline-formula> we replicate the weights of the first convolutional layer (normally three channels) 11 times. This allows the modified “flow ResNet18” to accept stacks of images as inputs, while retaining the pretrained weights to extract salient image features.</p>
      <p id="Par42">After spatial features and temporal features have been separately extracted from the spatial and temporal frames, respectively, we combine them to produce the <italic>spatiotemporal</italic> features that will be used to train the classifier (Fig. <xref rid="Fig1" ref-type="fig">1</xref>E). To do so, we simply concatenate the spatial and temporal features for each frame. That is, for a given segment of video with <inline-formula id="IEq42"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M102"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq42.gif"/></alternatives></inline-formula> frames, the initial spatiotemporal features are a matrix of size <inline-formula id="IEq43"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left[n, 512\times 2\right]=[n, 1024]$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mfenced close="]" open="["><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>512</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1024</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq43.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq44"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$512$$\end{document}</tex-math><mml:math id="M106"><mml:mrow><mml:mn>512</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq44.gif"/></alternatives></inline-formula> represents the dimensionality of the features extracted from the ResNet18. If multiple synchronized cameras are used (as is the case in one of our benchmark datasets), we employ the same process, concatenating the spatial and temporal features for each frame <italic>and each camera</italic>. In the case of two cameras, for example, this implies the initial spatiotemporal features is a matrix of size <inline-formula id="IEq45"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left[n,512\times 2\times 2\right]=\left[n,2048\right]$$\end{document}</tex-math><mml:math id="M108"><mml:mrow><mml:mfenced close="]" open="["><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>512</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>2048</mml:mn></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq45.gif"/></alternatives></inline-formula>. To decrease training time, memory requirements, and improve performance<sup><xref ref-type="bibr" rid="CR41">41</xref>,<xref ref-type="bibr" rid="CR42">42</xref></sup>, we utilize dimensionality reduction to decrease the size of the <italic>initial</italic> spatiotemporal features to generate <italic>final</italic> spatiotemporal features of size <inline-formula id="IEq46"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left[n,512\right]$$\end{document}</tex-math><mml:math id="M110"><mml:mfenced close="]" open="["><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>512</mml:mn></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq46.gif"/></alternatives></inline-formula>. We selected reconstruction independent component analysis<sup><xref ref-type="bibr" rid="CR43">43</xref>,<xref ref-type="bibr" rid="CR44">44</xref></sup> as our dimensionality reduction method, which creates a linear transformation by minimizing an objective function that balances the independence of output features with the capacity to reconstruct input features from output features.</p>
    </sec>
    <sec id="Sec20">
      <title>Classifier architecture</title>
      <p id="Par43">The labeled and unlabeled data consist of a set of clips, generated from project video, which the classifier uses to predict behavior. Clips in <inline-formula id="IEq47"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M112"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq47.gif"/></alternatives></inline-formula> and <inline-formula id="IEq48"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M114"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq48.gif"/></alternatives></inline-formula> are both constituted of a segment of video and a corresponding array of spatiotemporal features extracted from that video. Clips in <inline-formula id="IEq49"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M116"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq49.gif"/></alternatives></inline-formula> also include an accompanying set of manual annotations (Fig. <xref rid="Fig1" ref-type="fig">1</xref>B). For a given clip in <inline-formula id="IEq50"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M118"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq50.gif"/></alternatives></inline-formula> with <inline-formula id="IEq51"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq51.gif"/></alternatives></inline-formula> frames, the classifier takes a <inline-formula id="IEq52"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[{n}_{\mathrm{labeled}},512]$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>512</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq52.gif"/></alternatives></inline-formula>-dimensional vector of spatiotemporal features (Fig. <xref rid="Fig1" ref-type="fig">1</xref>E) and a one-dimensional array of <inline-formula id="IEq53"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq53.gif"/></alternatives></inline-formula> manually-produced labels (e.g., “eat,” “drink,” etc.) as inputs, and learns to predict the <inline-formula id="IEq54"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M126"><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">labeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq54.gif"/></alternatives></inline-formula> labels from the features. After training, for a given clip in <inline-formula id="IEq55"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M128"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq55.gif"/></alternatives></inline-formula> with <inline-formula id="IEq56"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M130"><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq56.gif"/></alternatives></inline-formula> frames, the classifier takes as an input a <inline-formula id="IEq57"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[{n}_{\mathrm{unlabeled}},512]$$\end{document}</tex-math><mml:math id="M132"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>512</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq57.gif"/></alternatives></inline-formula>-dimensional vector of spatiotemporal features and outputs a set of <inline-formula id="IEq58"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M134"><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq58.gif"/></alternatives></inline-formula> behavioral labels, corresponding to the predicted behavior in each of the <inline-formula id="IEq59"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M136"><mml:msub><mml:mi>n</mml:mi><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq59.gif"/></alternatives></inline-formula> frames. To implement this transformation from features to labels, we rely on recurrent neural networks (RNNs). Prior to inputting clips into the RNN, we further divide them into shorter “sequences,” corresponding to 15 s of video to reduce overfitting<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> and sequence padding<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>. Unlike traditional neural networks, recurrent neural networks contain cyclical connections which allows information to persist over time, enabling them to learn dependencies in sequential data<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. Given that predicting behavior accurately requires the integration of information over time (i.e., annotators generally must view more than one frame to classify most behavior, since behaviors are often distinguished by movement over time), this persistence is critical.</p>
      <p id="Par44">We opt for a long short-term memory (LSTM) network with bidirectional LSTM layers (BiLSTM) as the core of our classification model. LSTMs are better able to learn long-term dependencies in data than traditional RNNs in practice<sup><xref ref-type="bibr" rid="CR48">48</xref>,<xref ref-type="bibr" rid="CR49">49</xref></sup>, and the use of bidirectional layers allows the network to process information in both temporal directions<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> (i.e., forward and backward in time, rather than forward only in the case of a traditional LSTM layer). As shown in Figure <xref rid="MOESM1" ref-type="media">S4</xref>, our network’s architecture begins with a sequence input layer, which accepts a two-dimensional array corresponding to spatiotemporal video features (with one row per frame and one column per feature). We then apply two BiLSTM layers, which increases model complexity and allows the model to learn more abstract relationships between input sequences and correct output labels<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>. To reduce the likelihood of model overfitting, we use a dropout layer after each BiLSTM layer, which randomly sets some proportion of input units (here, <inline-formula id="IEq60"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$50$$\end{document}</tex-math><mml:math id="M138"><mml:mrow><mml:mn>50</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq60.gif"/></alternatives></inline-formula> percent) to <inline-formula id="IEq61"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0$$\end{document}</tex-math><mml:math id="M140"><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq61.gif"/></alternatives></inline-formula>, which reduces overfitting by curbing the power of any individual neuron to generate the output<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. The second dropout layer is followed by a fully-connected layer with an output size of <inline-formula id="IEq62"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[n,K$$\end{document}</tex-math><mml:math id="M142"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq62.gif"/></alternatives></inline-formula>], where <inline-formula id="IEq63"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M144"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq63.gif"/></alternatives></inline-formula> is the number of classes and <inline-formula id="IEq64"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M146"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq64.gif"/></alternatives></inline-formula> is the number of frames in the input clip. The softmax layer then normalizes the fully-connected layer’s output into a set of class probabilities with shape <inline-formula id="IEq65"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[n,K]$$\end{document}</tex-math><mml:math id="M148"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq65.gif"/></alternatives></inline-formula>, where the sum of each row is <inline-formula id="IEq66"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1$$\end{document}</tex-math><mml:math id="M150"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq66.gif"/></alternatives></inline-formula> and the softmax probability of class <inline-formula id="IEq67"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M152"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq67.gif"/></alternatives></inline-formula> in frame <inline-formula id="IEq68"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M154"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq68.gif"/></alternatives></inline-formula> is given by the entry <inline-formula id="IEq69"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$jk$$\end{document}</tex-math><mml:math id="M156"><mml:mrow><mml:mi mathvariant="italic">jk</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq69.gif"/></alternatives></inline-formula>. Following the softmax layer, the sequence-to-sequence classification layer generates a one-dimensional categorical array of <inline-formula id="IEq70"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M158"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq70.gif"/></alternatives></inline-formula> labels corresponding to the behavior with the highest softmax probability in each frame. We select cross-entropy loss for <inline-formula id="IEq71"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M160"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq71.gif"/></alternatives></inline-formula> mutually exclusive classes<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> as our loss function, since the behaviors in both datasets are mutually exclusive. All classifiers were trained using a single Nvidia Tesla K80 GPU running on the Dartmouth College high performance computing cluster.</p>
    </sec>
    <sec id="Sec21">
      <title>Classifier training</title>
      <p id="Par45">In this analysis, we use the hyperparameters specified in Table <xref rid="Tab2" ref-type="table">2</xref> when training the network. To avoid overfitting, we select 20 percent of <inline-formula id="IEq72"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{labeled}}$$\end{document}</tex-math><mml:math id="M162"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">labeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq72.gif"/></alternatives></inline-formula> to use in our validation set (i.e., <inline-formula id="IEq73"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${prop}_{train}=0.20$$\end{document}</tex-math><mml:math id="M164"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">prop</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">train</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.20</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq73.gif"/></alternatives></inline-formula>; see Fig. <xref rid="Fig1" ref-type="fig">1</xref>C). We then evaluate the network on this validation set every epoch (where “epoch” is defined as a single pass of the entire training set through the network) and record its cross-entropy loss. If the loss on the validation set after a given epoch is larger than or equal to the smallest previous loss on the validation set more than twice, training terminates.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Default hyperparameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Hyperparameter</th><th align="left">Value</th></tr></thead><tbody><tr><td align="left">Maximum epochs</td><td align="left">16</td></tr><tr><td align="left">Validation frequency (per epoch)</td><td align="left">1</td></tr><tr><td align="left">Validation patience</td><td align="left">2</td></tr><tr><td align="left">Initial learning rate</td><td align="left">0.001</td></tr><tr><td align="left">Learning rate drop period</td><td align="left">4</td></tr><tr><td align="left">Learning rate drop factor</td><td align="left">0.1</td></tr><tr><td align="left">Minibatch size</td><td align="left">8</td></tr></tbody></table><table-wrap-foot><p>The maximum number of epochs the network can be trained for is 16. The cross-entropy loss of the validation dataset is calculated for each epoch, and if this value is less than the prior minimum validation loss for more than two epochs, training terminates. The initial learning rate is 0.001, and every four epochs the learning rate drops by a factor of ten. We use a minibatch size of eight to minimize deficits in generalizability that could occur at larger values<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>.</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec22">
      <title>Classifier evaluation</title>
      <p id="Par46">To evaluate the classifier, we consider its performance on the test set, <inline-formula id="IEq74"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{test}}$$\end{document}</tex-math><mml:math id="M166"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">test</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq74.gif"/></alternatives></inline-formula> (Fig. <xref rid="Fig1" ref-type="fig">1</xref>B,D). For each clip, the classifier outputs a set of predicted labels for each frame, corresponding to the predicted behavior in that frame. In evaluating the classifier, we are interested in how closely these predicted labels match the true ones. We first consider overall prediction accuracy. We let <inline-formula id="IEq75"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{correct}$$\end{document}</tex-math><mml:math id="M168"><mml:mi mathvariant="normal">correct</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq75.gif"/></alternatives></inline-formula> denote the number labels in which the network’s prediction is the same as the true label and <inline-formula id="IEq76"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{incorrect}$$\end{document}</tex-math><mml:math id="M170"><mml:mi mathvariant="normal">incorrect</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq76.gif"/></alternatives></inline-formula> the number of labels in which the network’s prediction is not the same as the true label. Then accuracy can be quantified as the following proportion:<disp-formula id="Equb"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{accuracy}=\frac{\mathrm{correct}}{\mathrm{correct}+\mathrm{incorrect}}.$$\end{document}</tex-math><mml:math id="M172" display="block"><mml:mrow><mml:mi mathvariant="normal">accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="normal">correct</mml:mi><mml:mrow><mml:mi mathvariant="normal">correct</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">incorrect</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par47">Next, we consider the performance of the network by behavior. To do so, we let <inline-formula id="IEq77"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{TP}}_{k}$$\end{document}</tex-math><mml:math id="M174"><mml:msub><mml:mi mathvariant="normal">TP</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq77.gif"/></alternatives></inline-formula> denote the number of true positives (predicted class <inline-formula id="IEq78"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M176"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq78.gif"/></alternatives></inline-formula> and true class <inline-formula id="IEq79"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M178"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq79.gif"/></alternatives></inline-formula>), <inline-formula id="IEq80"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{FP}}_{k}$$\end{document}</tex-math><mml:math id="M180"><mml:msub><mml:mi mathvariant="normal">FP</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq80.gif"/></alternatives></inline-formula> the number of false positives (predicted class <inline-formula id="IEq81"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M182"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq81.gif"/></alternatives></inline-formula>, but true label not class <inline-formula id="IEq82"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M184"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq82.gif"/></alternatives></inline-formula>), and <inline-formula id="IEq83"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{FN}}_{k}$$\end{document}</tex-math><mml:math id="M186"><mml:msub><mml:mi mathvariant="normal">FN</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq83.gif"/></alternatives></inline-formula> the number of false negatives (true class <inline-formula id="IEq84"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M188"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq84.gif"/></alternatives></inline-formula>, predicted not class <inline-formula id="IEq85"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M190"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq85.gif"/></alternatives></inline-formula>) for class <inline-formula id="IEq86"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M192"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq86.gif"/></alternatives></inline-formula> (where <inline-formula id="IEq87"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M194"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq87.gif"/></alternatives></inline-formula> is between <inline-formula id="IEq88"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1$$\end{document}</tex-math><mml:math id="M196"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq88.gif"/></alternatives></inline-formula> and the total number of classes, <inline-formula id="IEq89"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M198"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq89.gif"/></alternatives></inline-formula>).</p>
      <p id="Par48">We then calculate the precision, recall, and F1 score for each label<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR55">55</xref></sup>, where the precision and recall for class <inline-formula id="IEq90"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M200"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq90.gif"/></alternatives></inline-formula> are defined as follows:<disp-formula id="Equc"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{precision}}_{k}=\frac{{\mathrm{TP}}_{k}}{{{\mathrm{TP}}_{k}+\mathrm{FP}}_{k}},$$\end{document}</tex-math><mml:math id="M202" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="normal">precision</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">TP</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mrow><mml:msub><mml:mi mathvariant="normal">TP</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FP</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equc.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equd"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{recall}}_{k}=\frac{{\mathrm{TP}}_{k}}{{{\mathrm{TP}}_{k}+\mathrm{FN}}_{k}}.$$\end{document}</tex-math><mml:math id="M204" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="normal">recall</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">TP</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mrow><mml:msub><mml:mi mathvariant="normal">TP</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FN</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equd.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par49">Precision is the proportion of correct predictions out of all cases in which the <italic>predicted class</italic> is class <inline-formula id="IEq91"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M206"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq91.gif"/></alternatives></inline-formula>. Recall, meanwhile, denotes the proportion of correct predictions out of all the cases in which the <italic>true class</italic> is class <inline-formula id="IEq92"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M208"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq92.gif"/></alternatives></inline-formula>. From the precision and recall, we calculate the F1 score for class <inline-formula id="IEq93"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M210"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq93.gif"/></alternatives></inline-formula>. The F1 score is the harmonic mean of precision and recall, where a high F1 score indicates both high precision and recall, and deficits in either decrease it:<disp-formula id="Eque"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{F}1}_{k}=2\cdot \frac{{\mathrm{precision}}_{k}\cdot  {\mathrm{recall}}_{k}}{{\mathrm{precision}}_{k}+{\mathrm{recall}}_{k}}$$\end{document}</tex-math><mml:math id="M212" display="block"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>·</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi mathvariant="normal">precision</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi mathvariant="normal">recall</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">precision</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">recall</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Eque.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par50">After calculating the F1 score for each class, we calculate the average F1 score, <inline-formula id="IEq94"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{F}1}_{\mathrm{all}}$$\end{document}</tex-math><mml:math id="M214"><mml:msub><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq94.gif"/></alternatives></inline-formula> as follows: <inline-formula id="IEq95"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{F}1}_{\mathrm{all}}=\frac{1}{K}\sum_{k=1}^{K}{\mathrm{F}1}_{k}$$\end{document}</tex-math><mml:math id="M216"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq95.gif"/></alternatives></inline-formula>.</p>
    </sec>
    <sec id="Sec23">
      <title>Confidence score definition</title>
      <p id="Par51">For each input clip, the classifier returns a set of predicted annotations corresponding to the predicted behavior (e.g., “walk,” “drink,” “rest,” etc.) occurring in each frame of that clip. We denote the set of classifier-predicted labels for clip number <inline-formula id="IEq96"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M218"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq96.gif"/></alternatives></inline-formula>, <inline-formula id="IEq97"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M220"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq97.gif"/></alternatives></inline-formula>, as <inline-formula id="IEq98"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{{\widehat{y}}_{j} | j\in {\text{clip}}_{i}\right\}$$\end{document}</tex-math><mml:math id="M222"><mml:mfenced close="}" open="{"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo></mml:mrow><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq98.gif"/></alternatives></inline-formula>. Each clip also has a set of “true” labels, corresponding to those that would be produced if the clip was manually annotated. In the case of the labeled data, the true labels are known (and used to train the classifier). In the case of unlabeled data, they are not known (prior to manual review). We denote the set of true labels for <inline-formula id="IEq99"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{i}$$\end{document}</tex-math><mml:math id="M224"><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq99.gif"/></alternatives></inline-formula> as <inline-formula id="IEq100"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{{y}_{j} | j\in {\text{clip}}_{i}\right\}$$\end{document}</tex-math><mml:math id="M226"><mml:mfenced close="}" open="{"><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo></mml:mrow><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq100.gif"/></alternatives></inline-formula>. For each frame in a clip, in addition to outputting a prediction for the behavior occurring in that frame, we also generate an estimate of how likely that frame’s classifier-assigned label is correct. That is, for each clip, we generate a set of predicted probabilities <inline-formula id="IEq101"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{{\widehat{p}}_{j} | j\in {\text{clip}}_{i}\right\}$$\end{document}</tex-math><mml:math id="M228"><mml:mfenced close="}" open="{"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo></mml:mrow><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq101.gif"/></alternatives></inline-formula> such that <inline-formula id="IEq102"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M230"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq102.gif"/></alternatives></inline-formula> denotes the estimated likelihood that <inline-formula id="IEq103"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{y}}_{j}$$\end{document}</tex-math><mml:math id="M232"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq103.gif"/></alternatives></inline-formula> is equal to <inline-formula id="IEq104"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{j}$$\end{document}</tex-math><mml:math id="M234"><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq104.gif"/></alternatives></inline-formula>. In an optimal classifier, <inline-formula id="IEq105"><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb{P}}\left({\widehat{y}}_{j}={y}_{j}\right)={\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M236"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq105.gif"/></alternatives></inline-formula>. That is, <inline-formula id="IEq106"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M238"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq106.gif"/></alternatives></inline-formula> is an estimate of the probability the classification is correct; and, in an optimal confidence-scorer, the estimated probability the classification is correct will be the ground truth likelihood the classification is correct<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>.</p>
      <p id="Par52">Now that we have established an estimated probability that a given <italic>frame</italic> in a clip is correct, we extend the confidence score to an entire clip. As in training data annotation, the review process is conducted at the level of an entire clip, not individual video frames. That is, even if there are a handful of frames in a clip that the classifier is relatively unconfident about, we assume that a human reviewer would need to see the entire clip to have enough context to accurately correct any misclassified frames. Since <inline-formula id="IEq107"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M240"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq107.gif"/></alternatives></inline-formula> is the estimated probability a given frame <inline-formula id="IEq108"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M242"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq108.gif"/></alternatives></inline-formula> is correct, it follows that the average <inline-formula id="IEq109"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M244"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq109.gif"/></alternatives></inline-formula> for <inline-formula id="IEq110"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j\in {\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M246"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq110.gif"/></alternatives></inline-formula> is the estimated probability a randomly selected frame in <inline-formula id="IEq111"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{i}$$\end{document}</tex-math><mml:math id="M248"><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq111.gif"/></alternatives></inline-formula> is correct. We define this quantity to be the clip confidence score; formally, <inline-formula id="IEq112"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\text{clip}}_{i}\right)=\frac{1}{\left|{\text{clip}}_{i}\right|}\sum_{j\in {\text{clip}}_{i}}{\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M250"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mfrac><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq112.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq113"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathrm{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M252"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq113.gif"/></alternatives></inline-formula> is the clip confidence score of <inline-formula id="IEq114"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M254"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq114.gif"/></alternatives></inline-formula> and <inline-formula id="IEq115"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left|{\text{clip}}_{i}\right|$$\end{document}</tex-math><mml:math id="M256"><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq115.gif"/></alternatives></inline-formula> is the number of frames in <inline-formula id="IEq116"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M258"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq116.gif"/></alternatives></inline-formula>. We then consider that accuracy is the true probability a randomly selected frame in <inline-formula id="IEq117"><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M260"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq117.gif"/></alternatives></inline-formula> is correct by definition. That is, <inline-formula id="IEq118"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\text{clip}}_{i}\right)=\frac{1}{\left|{\text{clip}}_{i}\right|}\sum_{j\in {\text{clip}}_{i}}\mathbf{I}({\widehat{y}}_{j}={y}_{j})$$\end{document}</tex-math><mml:math id="M262"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mfrac><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi mathvariant="bold">I</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq118.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq119"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M264"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq119.gif"/></alternatives></inline-formula> is the accuracy of <inline-formula id="IEq120"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M266"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq120.gif"/></alternatives></inline-formula> and <inline-formula id="IEq121"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf{I}$$\end{document}</tex-math><mml:math id="M268"><mml:mi mathvariant="bold">I</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq121.gif"/></alternatives></inline-formula> is the indicator function. In the case of an optimal confidence score, we’ll have that <inline-formula id="IEq122"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\text{clip}}_{i}\right)=\mathrm{acc}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M270"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq122.gif"/></alternatives></inline-formula>. If we compare <inline-formula id="IEq123"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({{\text{cli}}{\text{p}}}_{i}\right)$$\end{document}</tex-math><mml:math id="M272"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq123.gif"/></alternatives></inline-formula> with <inline-formula id="IEq124"><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M274"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq124.gif"/></alternatives></inline-formula> on our test data, we can establish how well the confidence score can be expected to perform when the ground truth accuracy, <inline-formula id="IEq125"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M276"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq125.gif"/></alternatives></inline-formula>, is unknown. In Methods: Confidence score calculation, we discuss our approach for obtaining <inline-formula id="IEq126"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M278"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq126.gif"/></alternatives></inline-formula>, after which finding clip-wise confidence scores is trivial.</p>
    </sec>
    <sec id="Sec24">
      <title>Confidence score calculation</title>
      <p id="Par53">Here, we first examine how to calculate the frame-wise confidence score <inline-formula id="IEq127"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M280"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq127.gif"/></alternatives></inline-formula>. To do so, we consider the classifier structure (Fig. <xref rid="MOESM1" ref-type="media">S4</xref>) in more detail. In particular, we focus on the last three layers: the fully-connected layer, the softmax layer, and the classification layer. To generate a classification for a given frame, the softmax layer takes in a logits vector from the fully-connected layer. This logits vector represents the raw (unnormalized) predictions of the model. The softmax layer then normalizes these predictions into a set of probabilities, where each probability is proportional to the exponential of the input. That is, given <inline-formula id="IEq128"><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M282"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq128.gif"/></alternatives></inline-formula> classes, the <inline-formula id="IEq129"><alternatives><tex-math id="M283">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M284"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq129.gif"/></alternatives></inline-formula>-dimensional vector from the fully-connected layer is normalized to a set of probabilities, representing the probability of each class. The class with the highest probability is then returned as the network’s predicted label (e.g., “eat” or “walk”) for that frame. We can then interpret this probability as a confidence score derived from the softmax function<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. Formally, if we let logits vector <inline-formula id="IEq130"><alternatives><tex-math id="M285">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\varvec{z}}}_{j}$$\end{document}</tex-math><mml:math id="M286"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq130.gif"/></alternatives></inline-formula> represent the output from the fully-connected layer corresponding to frame <inline-formula id="IEq131"><alternatives><tex-math id="M287">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M288"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq131.gif"/></alternatives></inline-formula>, the softmax-estimated probability that the predicted label of frame <inline-formula id="IEq132"><alternatives><tex-math id="M289">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M290"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq132.gif"/></alternatives></inline-formula> is correct is <inline-formula id="IEq133"><alternatives><tex-math id="M291">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}^{\mathrm{SM}}=\underset{k}{\mathrm{max}}{\sigma \left({{\varvec{z}}}_{j}\right)}^{(k)}$$\end{document}</tex-math><mml:math id="M292"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mi mathvariant="normal">max</mml:mi><mml:mi>k</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq133.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq134"><alternatives><tex-math id="M293">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma $$\end{document}</tex-math><mml:math id="M294"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq134.gif"/></alternatives></inline-formula> is the softmax function. We refer to this confidence score as the “max softmax score,” since it is derived from the maximum softmax probability.</p>
      <p id="Par54">One of the challenges with using the max softmax probability as a confidence score, however, is that it is often poorly scaled. Ideally, estimated accuracy for a prediction would closely match its actual expected accuracy, but in practice the softmax function tends to be “overconfident”<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. That is, <inline-formula id="IEq135"><alternatives><tex-math id="M295">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}^{\mathrm{SM}}$$\end{document}</tex-math><mml:math id="M296"><mml:msubsup><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq135.gif"/></alternatives></inline-formula> tends to be larger than <inline-formula id="IEq136"><alternatives><tex-math id="M297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb{P}}({\widehat{y}}_{j}={y}_{j})$$\end{document}</tex-math><mml:math id="M298"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq136.gif"/></alternatives></inline-formula>. To generate a more well-calibrated confidence score (i.e., one in which <inline-formula id="IEq137"><alternatives><tex-math id="M299">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M300"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq137.gif"/></alternatives></inline-formula> is closer to <inline-formula id="IEq138"><alternatives><tex-math id="M301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb{P}}({\widehat{y}}_{j}={y}_{j})$$\end{document}</tex-math><mml:math id="M302"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq138.gif"/></alternatives></inline-formula>, we use an approach called temperature scaling. Temperature scaling uses a learned parameter <inline-formula id="IEq139"><alternatives><tex-math id="M303">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T$$\end{document}</tex-math><mml:math id="M304"><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq139.gif"/></alternatives></inline-formula> (where <inline-formula id="IEq140"><alternatives><tex-math id="M305">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T&gt;1$$\end{document}</tex-math><mml:math id="M306"><mml:mrow><mml:mi>T</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq140.gif"/></alternatives></inline-formula> indicates decreased confidence and <inline-formula id="IEq141"><alternatives><tex-math id="M307">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T&lt;1$$\end{document}</tex-math><mml:math id="M308"><mml:mrow><mml:mi>T</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq141.gif"/></alternatives></inline-formula> increased confidence) to rescale class probabilities so that the confidence score more closely matches the true accuracy of a prediction<sup><xref ref-type="bibr" rid="CR57">57</xref></sup>. We define the temperature scaling-based confidence for frame <inline-formula id="IEq142"><alternatives><tex-math id="M309">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M310"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq142.gif"/></alternatives></inline-formula> as <inline-formula id="IEq143"><alternatives><tex-math id="M311">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}^{\mathrm{TS}}=\underset{k}{\mathrm{max}}{\sigma ({{\varvec{z}}}_{j}/T)}^{(k)}$$\end{document}</tex-math><mml:math id="M312"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi mathvariant="normal">TS</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mi mathvariant="normal">max</mml:mi><mml:mi>k</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">/</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq143.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq144"><alternatives><tex-math id="M313">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T$$\end{document}</tex-math><mml:math id="M314"><mml:mi>T</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq144.gif"/></alternatives></inline-formula> is selected to minimize the negative log likelihood on the validation set. Now that we have established the process for generating a frame-wise confidence score, we can generate the clip-wise confidence score that is used in the confidence-based review. As previously described, for <inline-formula id="IEq145"><alternatives><tex-math id="M315">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M316"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq145.gif"/></alternatives></inline-formula> this is simply <inline-formula id="IEq146"><alternatives><tex-math id="M317">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\text{clip}}_{i}\right)=\frac{1}{\left|{\text{clip}}_{i}\right|}\sum_{j\in {\text{clip}}_{i}}{\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M318"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mfrac><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq146.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq147"><alternatives><tex-math id="M319">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}$$\end{document}</tex-math><mml:math id="M320"><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq147.gif"/></alternatives></inline-formula> is either generated via the softmax function (<inline-formula id="IEq148"><alternatives><tex-math id="M321">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}={\widehat{p}}_{j}^{\mathrm{SM}}$$\end{document}</tex-math><mml:math id="M322"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi mathvariant="normal">SM</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq148.gif"/></alternatives></inline-formula>) or temperature scaling (<inline-formula id="IEq149"><alternatives><tex-math id="M323">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{p}}_{j}={\widehat{p}}_{j}^{\mathrm{TS}}$$\end{document}</tex-math><mml:math id="M324"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi mathvariant="normal">TS</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq149.gif"/></alternatives></inline-formula>).</p>
    </sec>
    <sec id="Sec25">
      <title>Confidence-based review</title>
      <p id="Par55">Now that we have generated a confidence score for a given clip, we use it in two ways. First, recall that one of the purposes of the confidence-based review is to estimate the accuracy of the unlabeled data, <inline-formula id="IEq150"><alternatives><tex-math id="M325">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M326"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq150.gif"/></alternatives></inline-formula>. If, for example, a user decided that an accuracy of 80 percent was acceptable for their given behavior analysis application (i.e., <inline-formula id="IEq151"><alternatives><tex-math id="M327">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}({\mathcal{D}}^{\mathrm{unlabeled}})\ge 0.8$$\end{document}</tex-math><mml:math id="M328"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq151.gif"/></alternatives></inline-formula>), then given an acceptably reliable confidence score, unlabeled data for which <inline-formula id="IEq152"><alternatives><tex-math id="M329">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathcal{D}}^{\mathrm{unlabeled}}\right)\ge 0.8$$\end{document}</tex-math><mml:math id="M330"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mfenced><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq152.gif"/></alternatives></inline-formula> would be sufficient for export and use in their given analysis without manual review. Before obtaining an estimate for <inline-formula id="IEq153"><alternatives><tex-math id="M331">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathcal{D}}^{\mathrm{unlabeled}}\right)$$\end{document}</tex-math><mml:math id="M332"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq153.gif"/></alternatives></inline-formula>, we first consider that the true (unknown) accuracy of the annotations in <inline-formula id="IEq154"><alternatives><tex-math id="M333">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M334"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq154.gif"/></alternatives></inline-formula> is the weighted sum of the accuracies of the clips in <inline-formula id="IEq155"><alternatives><tex-math id="M335">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M336"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq155.gif"/></alternatives></inline-formula>, where weight is determined by the number of frames in each clip. Formally, we can express the accuracy of <inline-formula id="IEq156"><alternatives><tex-math id="M337">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M338"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq156.gif"/></alternatives></inline-formula> as:<disp-formula id="Equf"><alternatives><tex-math id="M339">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathcal{D}}^{\mathrm{unlabeled}}\right)={\sum }_{i\in {\mathcal{D}}^{\mathrm{unlabeled}}}(\mathrm{acc}\left({\text{clip}}_{i}\right)\times \frac{\left|{\text{clip}}_{i}\right|}{\sum_{j\in {\mathcal{D}}^{\mathrm{unlabeled}}}\left|{\text{clip}}_{j}\right|}),$$\end{document}</tex-math><mml:math id="M340" display="block"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equf.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq157"><alternatives><tex-math id="M341">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{\left|{\text{clip}}_{i}\right|}{\sum_{j\in {\mathcal{D}}^{\mathrm{unlabeled}}}\left|{\mathrm{clip}}_{j}\right|}$$\end{document}</tex-math><mml:math id="M342"><mml:mfrac><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mfenced close="|" open="|"><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq157.gif"/></alternatives></inline-formula> weights the accuracy of <inline-formula id="IEq158"><alternatives><tex-math id="M343">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M344"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq158.gif"/></alternatives></inline-formula> by the number of frames in <inline-formula id="IEq159"><alternatives><tex-math id="M345">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{clip}}_{i}$$\end{document}</tex-math><mml:math id="M346"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq159.gif"/></alternatives></inline-formula> (i.e., <inline-formula id="IEq160"><alternatives><tex-math id="M347">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left|{\text{clip}}_{i}\right|$$\end{document}</tex-math><mml:math id="M348"><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq160.gif"/></alternatives></inline-formula>) relative to the total number of clips (i.e., <inline-formula id="IEq161"><alternatives><tex-math id="M349">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sum_{j\in {\mathcal{D}}^{\mathrm{unlabeled}}}\left|{\mathrm{clip}}_{j}\right|$$\end{document}</tex-math><mml:math id="M350"><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mfenced close="|" open="|"><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq161.gif"/></alternatives></inline-formula>). We then estimate the accuracy of the unlabeled data by substituting the known <inline-formula id="IEq162"><alternatives><tex-math id="M351">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}({\text{clip}}_{i})$$\end{document}</tex-math><mml:math id="M352"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq162.gif"/></alternatives></inline-formula> for the unknown <inline-formula id="IEq163"><alternatives><tex-math id="M353">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}({\text{clip}}_{i})$$\end{document}</tex-math><mml:math id="M354"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq163.gif"/></alternatives></inline-formula>:<disp-formula id="Equg"><alternatives><tex-math id="M355">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathcal{D}}^{\mathrm{unlabeled}}\right)={\sum }_{i\in {\mathcal{D}}^{\mathrm{unlabeled}}}(\mathrm{conf}\left({\text{clip}}_{i}\right)\times \frac{\left|{\text{clip}}_{i}\right|}{\sum_{j\in {\mathcal{D}}^{\mathrm{unlabeled}}}\left|{\mathrm{clip}}_{j}\right|}).$$\end{document}</tex-math><mml:math id="M356" display="block"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mfenced close="|" open="|"><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equg.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par57">In this way, <inline-formula id="IEq164"><alternatives><tex-math id="M357">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathcal{D}}^{\mathrm{unlabeled}}\right)$$\end{document}</tex-math><mml:math id="M358"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq164.gif"/></alternatives></inline-formula> represents the approximate accuracy of the classifier on unlabeled data. If the confidence score functions well, then <inline-formula id="IEq165"><alternatives><tex-math id="M359">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathcal{D}}^{\mathrm{unlabeled}}\right)$$\end{document}</tex-math><mml:math id="M360"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq165.gif"/></alternatives></inline-formula> will closely match <inline-formula id="IEq166"><alternatives><tex-math id="M361">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathcal{D}}^{\mathrm{unlabeled}}\right)$$\end{document}</tex-math><mml:math id="M362"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq166.gif"/></alternatives></inline-formula>.</p>
      <p id="Par58">Next, we consider the confidence-based review. In this component of the workflow, user can review and correct labels automatically generated by the classifier for <inline-formula id="IEq167"><alternatives><tex-math id="M363">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M364"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq167.gif"/></alternatives></inline-formula>. A naïve approach would be to review all the video clips contained in <inline-formula id="IEq168"><alternatives><tex-math id="M365">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M366"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq168.gif"/></alternatives></inline-formula>. While this would indeed ensure all the labels produced by the classifier are correct, if <inline-formula id="IEq169"><alternatives><tex-math id="M367">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M368"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq169.gif"/></alternatives></inline-formula> is large it can prove quite time-consuming. So instead, we leverage confidence scores to allow users to only annotate the subset of clips with relatively low confidence scores (i.e., relatively low predicted accuracy), for which review is most productive, while omitting those with relatively high confidence scores.</p>
      <p id="Par59">If a user reviews only a portion of the clips, it should be the portion with the lowest accuracy, for which correction is the most important. To express this formally, consider an ordered sequence of the <inline-formula id="IEq170"><alternatives><tex-math id="M369">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M370"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq170.gif"/></alternatives></inline-formula> clips in <inline-formula id="IEq171"><alternatives><tex-math id="M371">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M372"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq171.gif"/></alternatives></inline-formula>, <inline-formula id="IEq172"><alternatives><tex-math id="M373">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\mathrm{clip}}_{1}, {\mathrm{clip}}_{2}, \dots , {\mathrm{clip}}_{n})$$\end{document}</tex-math><mml:math id="M374"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq172.gif"/></alternatives></inline-formula>, sorted in ascending order by accuracy (i.e., <inline-formula id="IEq173"><alternatives><tex-math id="M375">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathrm{clip}}_{i}\right)\le \mathrm{acc}\left({\mathrm{clip}}_{j}\right)$$\end{document}</tex-math><mml:math id="M376"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>≤</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq173.gif"/></alternatives></inline-formula>, for <inline-formula id="IEq174"><alternatives><tex-math id="M377">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i&lt;j$$\end{document}</tex-math><mml:math id="M378"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq174.gif"/></alternatives></inline-formula> and all <inline-formula id="IEq175"><alternatives><tex-math id="M379">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i,j\le n$$\end{document}</tex-math><mml:math id="M380"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq175.gif"/></alternatives></inline-formula>). If we review only <inline-formula id="IEq176"><alternatives><tex-math id="M381">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M382"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq176.gif"/></alternatives></inline-formula> of the <inline-formula id="IEq177"><alternatives><tex-math id="M383">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M384"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq177.gif"/></alternatives></inline-formula> clips, where <inline-formula id="IEq178"><alternatives><tex-math id="M385">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k\le n$$\end{document}</tex-math><mml:math id="M386"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq178.gif"/></alternatives></inline-formula>, we are best off reviewing clips <inline-formula id="IEq179"><alternatives><tex-math id="M387">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{1}, {\mathrm{clip}}_{2}, \dots , {\mathrm{clip}}_{k}$$\end{document}</tex-math><mml:math id="M388"><mml:mrow><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq179.gif"/></alternatives></inline-formula> from the list since they have the lowest accuracy. For unlabeled data, however, recall that we can’t precisely sort clips by accuracy, since without ground truth annotations <inline-formula id="IEq180"><alternatives><tex-math id="M389">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M390"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq180.gif"/></alternatives></inline-formula> is unknown. However, since <inline-formula id="IEq181"><alternatives><tex-math id="M391">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M392"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq181.gif"/></alternatives></inline-formula> approximates <inline-formula id="IEq182"><alternatives><tex-math id="M393">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\text{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M394"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq182.gif"/></alternatives></inline-formula>, we can instead sort unlabeled clips by their (known) confidence scores, and then select the clips with the lowest confidence scores to review first. This forms the basis of the confidence-based review. Given a set of clips in <inline-formula id="IEq183"><alternatives><tex-math id="M395">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M396"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq183.gif"/></alternatives></inline-formula>, we simply create a sequence of clips <inline-formula id="IEq184"><alternatives><tex-math id="M397">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\mathrm{clip}}_{1}, {\mathrm{clip}}_{2}, \dots , {\mathrm{clip}}_{n})$$\end{document}</tex-math><mml:math id="M398"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq184.gif"/></alternatives></inline-formula> sorted by confidence score (i.e., such that <inline-formula id="IEq185"><alternatives><tex-math id="M399">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\text{clip}}_{i}\right)\le \mathrm{conf}({\mathrm{clip}}_{j})$$\end{document}</tex-math><mml:math id="M400"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mtext>clip</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>≤</mml:mo><mml:mi mathvariant="normal">conf</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq185.gif"/></alternatives></inline-formula>, for all <inline-formula id="IEq186"><alternatives><tex-math id="M401">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i&lt;j$$\end{document}</tex-math><mml:math id="M402"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq186.gif"/></alternatives></inline-formula>) and then have users review clips in ascending order. If the confidence score is an effective estimate of the clip accuracies, sorting based on confidence score will approximate sorting by accuracy.</p>
    </sec>
    <sec id="Sec26">
      <title>Evaluating confidence score calibration</title>
      <p id="Par60">To examine the relationship between confidence scores and accuracy, we first consider the relationship between individual clips’ predicted accuracy (as derived from confidence cores) and actual accuracy. The prediction error (PE) for a given clip is defined as the signed difference between its predicted accuracy and its actual accuracy. For <inline-formula id="IEq187"><alternatives><tex-math id="M403">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{i}$$\end{document}</tex-math><mml:math id="M404"><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq187.gif"/></alternatives></inline-formula>, the PE is then <inline-formula id="IEq188"><alternatives><tex-math id="M405">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{PE}({\mathrm{clip}}_{i})=\mathrm{conf}\left({\mathrm{clip}}_{i}\right)-\mathrm{acc}({\mathrm{clip}}_{i})$$\end{document}</tex-math><mml:math id="M406"><mml:mrow><mml:mi mathvariant="normal">PE</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>-</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq188.gif"/></alternatives></inline-formula>. Positive values indicate an overconfident score, and negative value and underconfident one. The absolute error (AE) is the magnitude of the prediction error and is defined as <inline-formula id="IEq189"><alternatives><tex-math id="M407">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{AE}\left({\mathrm{clip}}_{i}\right)=\left|\mathrm{PE}({\mathrm{clip}}_{i})\right|$$\end{document}</tex-math><mml:math id="M408"><mml:mrow><mml:mi mathvariant="normal">AE</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="|" open="|"><mml:mi mathvariant="normal">PE</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq189.gif"/></alternatives></inline-formula>. The AE is always positive, with a higher <inline-formula id="IEq190"><alternatives><tex-math id="M409">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{AE}\left({\mathrm{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M410"><mml:mrow><mml:mi mathvariant="normal">AE</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq190.gif"/></alternatives></inline-formula> indicating a greater absolute deviation between <inline-formula id="IEq191"><alternatives><tex-math id="M411">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathrm{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M412"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq191.gif"/></alternatives></inline-formula> and <inline-formula id="IEq192"><alternatives><tex-math id="M413">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}({\mathrm{clip}}_{i})$$\end{document}</tex-math><mml:math id="M414"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq192.gif"/></alternatives></inline-formula>.</p>
      <p id="Par61">While PE and AE are defined for a single clip, we also consider the mean absolute error and mean prediction error across all the clips in <inline-formula id="IEq193"><alternatives><tex-math id="M415">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{unlabeled}}$$\end{document}</tex-math><mml:math id="M416"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">unlabeled</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq193.gif"/></alternatives></inline-formula>. Here, we let <inline-formula id="IEq194"><alternatives><tex-math id="M417">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{1}, {\mathrm{clip}}_{2},\dots ,{\mathrm{clip}}_{n}$$\end{document}</tex-math><mml:math id="M418"><mml:mrow><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq194.gif"/></alternatives></inline-formula> denote a set of <inline-formula id="IEq195"><alternatives><tex-math id="M419">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M420"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq195.gif"/></alternatives></inline-formula> clips. The mean absolute error (MAE) is defined as <inline-formula id="IEq196"><alternatives><tex-math id="M421">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{MAE}=\frac{1}{n}\sum_{i=1}^{n}\mathrm{AE}({\mathrm{clip}}_{i})$$\end{document}</tex-math><mml:math id="M422"><mml:mrow><mml:mi mathvariant="normal">MAE</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mi mathvariant="normal">AE</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq196.gif"/></alternatives></inline-formula>. MAE expresses the average magnitude of the difference between predicted accuracy and actual accuracy for a randomly selected clip in the set. So, for example, if <inline-formula id="IEq197"><alternatives><tex-math id="M423">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{MAE}=0.1$$\end{document}</tex-math><mml:math id="M424"><mml:mrow><mml:mi mathvariant="normal">MAE</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq197.gif"/></alternatives></inline-formula>, then a randomly selected clip’s confidence score will differ from its accuracy score by about 10 percent, in expectation. The mean signed difference (MSD), meanwhile, is defined as <inline-formula id="IEq198"><alternatives><tex-math id="M425">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{MSD}=\frac{1}{n}\sum_{i=1}^{n}\mathrm{PE}({\mathrm{clip}}_{i})$$\end{document}</tex-math><mml:math id="M426"><mml:mrow><mml:mi mathvariant="normal">MSD</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mi mathvariant="normal">PE</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq198.gif"/></alternatives></inline-formula>. MSD expresses the signed difference between the total expected accuracy across clips and the total actual accuracy. So, for example, is <inline-formula id="IEq199"><alternatives><tex-math id="M427">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{MSD}=-0.05$$\end{document}</tex-math><mml:math id="M428"><mml:mrow><mml:mi mathvariant="normal">MSD</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq199.gif"/></alternatives></inline-formula>, then the total estimated accuracy of annotations for the set <inline-formula id="IEq200"><alternatives><tex-math id="M429">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{1}, {\mathrm{clip}}_{2},\dots ,{\mathrm{clip}}_{n}$$\end{document}</tex-math><mml:math id="M430"><mml:mrow><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq200.gif"/></alternatives></inline-formula> is five percent lower than the true accuracy.</p>
    </sec>
    <sec id="Sec27">
      <title>Evaluating review efficiency</title>
      <p id="Par62">To develop a metric for the performance of the confidence-based review, we first consider a case where a user has generated predicted labels for <inline-formula id="IEq201"><alternatives><tex-math id="M431">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M432"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq201.gif"/></alternatives></inline-formula> clips, which have not been manually labeled, and selects <inline-formula id="IEq202"><alternatives><tex-math id="M433">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M434"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq202.gif"/></alternatives></inline-formula> of them to review, where <inline-formula id="IEq203"><alternatives><tex-math id="M435">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k\le n$$\end{document}</tex-math><mml:math id="M436"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq203.gif"/></alternatives></inline-formula>. The remaining <inline-formula id="IEq204"><alternatives><tex-math id="M437">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n-k$$\end{document}</tex-math><mml:math id="M438"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq204.gif"/></alternatives></inline-formula> clips are not reviewed and are exported with unrevised classifier-generated labels. Then, for each of the <inline-formula id="IEq205"><alternatives><tex-math id="M439">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M440"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq205.gif"/></alternatives></inline-formula> clips the user has selected, he or she reviews the clip and corrects any incorrect classifier-generated labels. In this formation, after reviewing a given clip, that clip’s accuracy (defined as the agreement between a clip’s labels and the labels produced by manual annotation), is <inline-formula id="IEq206"><alternatives><tex-math id="M441">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1$$\end{document}</tex-math><mml:math id="M442"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq206.gif"/></alternatives></inline-formula>, since any incorrect classifier-produced labels would have been corrected.</p>
      <p id="Par63">Next, we assume that we have been provided with a <italic>sequence</italic> of <inline-formula id="IEq207"><alternatives><tex-math id="M443">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M444"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq207.gif"/></alternatives></inline-formula> clips, <inline-formula id="IEq208"><alternatives><tex-math id="M445">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}={(\mathrm{clip}}_{1}, {\mathrm{clip}}_{2}, \dots , {\mathrm{clip}}_{n})$$\end{document}</tex-math><mml:math id="M446"><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">clip</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq208.gif"/></alternatives></inline-formula>, from which we select the first <inline-formula id="IEq209"><alternatives><tex-math id="M447">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M448"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq209.gif"/></alternatives></inline-formula> clips in the sequence to review. If we denote <inline-formula id="IEq210"><alternatives><tex-math id="M449">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{i}^{\mathrm{unrev}}$$\end{document}</tex-math><mml:math id="M450"><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq210.gif"/></alternatives></inline-formula> as clip <inline-formula id="IEq211"><alternatives><tex-math id="M451">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M452"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq211.gif"/></alternatives></inline-formula> prior to being reviewed, and <inline-formula id="IEq212"><alternatives><tex-math id="M453">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{i}^{\mathrm{rev}}$$\end{document}</tex-math><mml:math id="M454"><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq212.gif"/></alternatives></inline-formula> as clip <inline-formula id="IEq213"><alternatives><tex-math id="M455">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M456"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq213.gif"/></alternatives></inline-formula> after being reviewed, then we can express the sequence of the first <inline-formula id="IEq214"><alternatives><tex-math id="M457">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M458"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq214.gif"/></alternatives></inline-formula> clips after they have been reviewed as <inline-formula id="IEq215"><alternatives><tex-math id="M459">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}_{k}^{\mathrm{rev}}=({\mathrm{clip}}_{1}^{\mathrm{rev}}, {\mathrm{clip}}_{2}^{\mathrm{rev}}, \dots , {\mathrm{clip}}_{k}^{\mathrm{rev}})$$\end{document}</tex-math><mml:math id="M460"><mml:mrow><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq215.gif"/></alternatives></inline-formula>. We then express the remaining <inline-formula id="IEq216"><alternatives><tex-math id="M461">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n-k$$\end{document}</tex-math><mml:math id="M462"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq216.gif"/></alternatives></inline-formula> clips as the sequence <inline-formula id="IEq217"><alternatives><tex-math id="M463">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}_{k}^{\mathrm{unrev}}=({\mathrm{clip}}_{k+1}^{\mathrm{unrev}}, {\mathrm{clip}}_{k+2}^{\mathrm{unrev}}, \dots , {\mathrm{clip}}_{n}^{\mathrm{unrev}})$$\end{document}</tex-math><mml:math id="M464"><mml:mrow><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq217.gif"/></alternatives></inline-formula>. We then consider that the overall accuracy of the sequence of clips, <inline-formula id="IEq218"><alternatives><tex-math id="M465">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}(\mathcal{D})$$\end{document}</tex-math><mml:math id="M466"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq218.gif"/></alternatives></inline-formula>, is simply weighted average of the accuracy of the reviewed videos, <inline-formula id="IEq219"><alternatives><tex-math id="M467">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}_{k}^{\mathrm{rev}}$$\end{document}</tex-math><mml:math id="M468"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq219.gif"/></alternatives></inline-formula>, and the unreviewed ones, <inline-formula id="IEq220"><alternatives><tex-math id="M469">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}_{k}^{\mathrm{unrev}}$$\end{document}</tex-math><mml:math id="M470"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq220.gif"/></alternatives></inline-formula>, where the weight is a function of the number of frames in each clip. Formally,<disp-formula id="Equh"><alternatives><tex-math id="M471">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathcal{D}}_{k}\right)=\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{rev}}\right)\times \frac{\left|{\mathcal{D}}_{k}^{\mathrm{rev}}\right|}{\left|\mathcal{D}\right|}+\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{unrev}}\right)\times \frac{\left|{\mathcal{D}}_{k}^{\mathrm{unrev}}\right|}{\left|\mathcal{D}\right|},$$\end{document}</tex-math><mml:math id="M472" display="block"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi mathvariant="script">D</mml:mi></mml:mfenced></mml:mfrac><mml:mo>+</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi mathvariant="script">D</mml:mi></mml:mfenced></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equh.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq221"><alternatives><tex-math id="M473">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left|\mathcal{D}\right|$$\end{document}</tex-math><mml:math id="M474"><mml:mfenced close="|" open="|"><mml:mi mathvariant="script">D</mml:mi></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq221.gif"/></alternatives></inline-formula> is the total number of video frames in the clips in set <inline-formula id="IEq222"><alternatives><tex-math id="M475">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}$$\end{document}</tex-math><mml:math id="M476"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq222.gif"/></alternatives></inline-formula> (i.e., <inline-formula id="IEq223"><alternatives><tex-math id="M477">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left|\mathcal{D}\right|={\sum }_{i\in \mathcal{D}}\left|{\mathrm{clip}}_{i}\right|$$\end{document}</tex-math><mml:math id="M478"><mml:mrow><mml:mfenced close="|" open="|"><mml:mi mathvariant="script">D</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:msub><mml:mfenced close="|" open="|"><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq223.gif"/></alternatives></inline-formula>). We then consider that, after reviewing and correcting the first <inline-formula id="IEq224"><alternatives><tex-math id="M479">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M480"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq224.gif"/></alternatives></inline-formula> clips, the accuracy of each reviewed clip is now <inline-formula id="IEq225"><alternatives><tex-math id="M481">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1$$\end{document}</tex-math><mml:math id="M482"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq225.gif"/></alternatives></inline-formula>. That is, <inline-formula id="IEq226"><alternatives><tex-math id="M483">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathrm{clip}}_{i}^{\mathrm{rev}}\right)=1$$\end{document}</tex-math><mml:math id="M484"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq226.gif"/></alternatives></inline-formula> for all <inline-formula id="IEq227"><alternatives><tex-math id="M485">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{clip}}_{i}^{\mathrm{rev}}\in {\mathcal{D}}_{k}^{\mathrm{rev}}$$\end{document}</tex-math><mml:math id="M486"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">clip</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq227.gif"/></alternatives></inline-formula>. Therefore, the total accuracy of sequence <inline-formula id="IEq228"><alternatives><tex-math id="M487">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}$$\end{document}</tex-math><mml:math id="M488"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq228.gif"/></alternatives></inline-formula>, after reviewing the first <inline-formula id="IEq229"><alternatives><tex-math id="M489">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M490"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq229.gif"/></alternatives></inline-formula> clips, is<disp-formula id="Equi"><alternatives><tex-math id="M491">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathcal{D}}_{k}\right)=\frac{\left|{\mathcal{D}}_{k}^{\mathrm{rev}}\right|}{\left|\mathcal{D}\right|}+\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{unrev}}\right)\times \frac{\left|{\mathcal{D}}_{k}^{\mathrm{unrev}}\right|}{\left|\mathcal{D}\right|}.$$\end{document}</tex-math><mml:math id="M492" display="block"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rev</mml:mi></mml:msubsup></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi mathvariant="script">D</mml:mi></mml:mfenced></mml:mfrac><mml:mo>+</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup></mml:mfenced><mml:mo>×</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">unrev</mml:mi></mml:msubsup></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi mathvariant="script">D</mml:mi></mml:mfenced></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equi.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par65">This method for calculating the accuracy of dataset <inline-formula id="IEq230"><alternatives><tex-math id="M493">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}$$\end{document}</tex-math><mml:math id="M494"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq230.gif"/></alternatives></inline-formula> after reviewing the first <inline-formula id="IEq231"><alternatives><tex-math id="M495">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M496"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq231.gif"/></alternatives></inline-formula> clips becomes useful for analyzing the performance of the confidence-based review. To see why, we first consider the lower bound on <inline-formula id="IEq232"><alternatives><tex-math id="M497">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathcal{D}}_{k}\right)$$\end{document}</tex-math><mml:math id="M498"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq232.gif"/></alternatives></inline-formula>. In the worst case, our confidence score will convey no information about the relative accuracies of the clips in <inline-formula id="IEq233"><alternatives><tex-math id="M499">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}$$\end{document}</tex-math><mml:math id="M500"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq233.gif"/></alternatives></inline-formula>. Without a relationship between <inline-formula id="IEq234"><alternatives><tex-math id="M501">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathrm{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M502"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq234.gif"/></alternatives></inline-formula> and <inline-formula id="IEq235"><alternatives><tex-math id="M503">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}\left({\mathrm{clip}}_{i}\right)$$\end{document}</tex-math><mml:math id="M504"><mml:mrow><mml:mi mathvariant="normal">conf</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">clip</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq235.gif"/></alternatives></inline-formula>, sorting based on confidence score is effectively the same as randomly selecting clips. In this way, we can compare the accuracy after labeling the first <inline-formula id="IEq236"><alternatives><tex-math id="M505">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M506"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq236.gif"/></alternatives></inline-formula> clips via confidence-score with the accuracy that <italic>would have been obtained if the first</italic>
<inline-formula id="IEq237"><alternatives><tex-math id="M507">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{k}$$\end{document}</tex-math><mml:math id="M508"><mml:mi mathvariant="normal">k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq237.gif"/></alternatives></inline-formula>
<italic>clips were reviewed</italic>. We denote this improvement in accuracy using confidence metric <inline-formula id="IEq238"><alternatives><tex-math id="M509">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}$$\end{document}</tex-math><mml:math id="M510"><mml:mi mathvariant="normal">conf</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq238.gif"/></alternatives></inline-formula> as the “improvement over random” and formalize it as <inline-formula id="IEq239"><alternatives><tex-math id="M511">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{IOR}}_{k}^{\mathrm{conf}}=\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{conf}}\right)-\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{rand}}\right)$$\end{document}</tex-math><mml:math id="M512"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">IOR</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup></mml:mfenced><mml:mo>-</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rand</mml:mi></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq239.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq240"><alternatives><tex-math id="M513">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}_{k}^{\mathrm{conf}}$$\end{document}</tex-math><mml:math id="M514"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq240.gif"/></alternatives></inline-formula> and <inline-formula id="IEq241"><alternatives><tex-math id="M515">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}_{k}^{\mathrm{rand}}$$\end{document}</tex-math><mml:math id="M516"><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rand</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq241.gif"/></alternatives></inline-formula> denote dataset <inline-formula id="IEq242"><alternatives><tex-math id="M517">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}$$\end{document}</tex-math><mml:math id="M518"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq242.gif"/></alternatives></inline-formula> sorted by confidence score and randomly, respectively.</p>
      <p id="Par66">Next, we place an upper bound on <inline-formula id="IEq243"><alternatives><tex-math id="M519">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{IOR}}_{k}$$\end{document}</tex-math><mml:math id="M520"><mml:msub><mml:mi mathvariant="normal">IOR</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq243.gif"/></alternatives></inline-formula> by considering the maximum accuracy that <inline-formula id="IEq244"><alternatives><tex-math id="M521">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}$$\end{document}</tex-math><mml:math id="M522"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq244.gif"/></alternatives></inline-formula> could have after reviewing <inline-formula id="IEq245"><alternatives><tex-math id="M523">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M524"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq245.gif"/></alternatives></inline-formula> clips. In the best case, the first <inline-formula id="IEq246"><alternatives><tex-math id="M525">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M526"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq246.gif"/></alternatives></inline-formula> clips reviewed would be the <inline-formula id="IEq247"><alternatives><tex-math id="M527">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M528"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq247.gif"/></alternatives></inline-formula> clips with the lowest accuracy. Here, since we’re evaluating on <inline-formula id="IEq248"><alternatives><tex-math id="M529">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{test}}$$\end{document}</tex-math><mml:math id="M530"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">test</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq248.gif"/></alternatives></inline-formula>, where accuracy is known, we can calculate this. If we let <inline-formula id="IEq249"><alternatives><tex-math id="M531">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{D}}^{\mathrm{acc}}$$\end{document}</tex-math><mml:math id="M532"><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mi mathvariant="normal">acc</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq249.gif"/></alternatives></inline-formula> denote the sequence of clips sorted in ascending order by their true accuracy, then the maximum accuracy of <inline-formula id="IEq250"><alternatives><tex-math id="M533">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathcal{D}$$\end{document}</tex-math><mml:math id="M534"><mml:mi mathvariant="script">D</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq250.gif"/></alternatives></inline-formula> after reviewing <inline-formula id="IEq251"><alternatives><tex-math id="M535">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M536"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq251.gif"/></alternatives></inline-formula> clips is <inline-formula id="IEq252"><alternatives><tex-math id="M537">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{acc}}\right)$$\end{document}</tex-math><mml:math id="M538"><mml:mrow><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">acc</mml:mi></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq252.gif"/></alternatives></inline-formula>. Then, similar to the analysis above, we calculate the improvement of optimal review (i.e., review based on true accuracy) over random review as <inline-formula id="IEq253"><alternatives><tex-math id="M539">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{IOR}}_{k}^{\mathrm{opt}}=\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{acc}}\right)-\mathrm{acc}\left({\mathcal{D}}_{k}^{\mathrm{rand}}\right).$$\end{document}</tex-math><mml:math id="M540"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">IOR</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">opt</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">acc</mml:mi></mml:msubsup></mml:mfenced><mml:mo>-</mml:mo><mml:mi mathvariant="normal">acc</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">rand</mml:mi></mml:msubsup></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq253.gif"/></alternatives></inline-formula> Semantically, <inline-formula id="IEq254"><alternatives><tex-math id="M541">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{IOR}}_{k}^{\mathrm{opt}}$$\end{document}</tex-math><mml:math id="M542"><mml:msubsup><mml:mi mathvariant="normal">IOR</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">opt</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq254.gif"/></alternatives></inline-formula> expresses how much higher the accuracy of the test set it after reviewing <inline-formula id="IEq255"><alternatives><tex-math id="M543">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M544"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq255.gif"/></alternatives></inline-formula> clips in the optimal order than it would be if clips had been reviewed randomly.</p>
      <p id="Par67">We can then derive a series of global measures for the confidence-based review. While <inline-formula id="IEq256"><alternatives><tex-math id="M545">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{IOR}}_{k}$$\end{document}</tex-math><mml:math id="M546"><mml:msub><mml:mi mathvariant="normal">IOR</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq256.gif"/></alternatives></inline-formula> is defined for a single number of clips reviewed, <inline-formula id="IEq257"><alternatives><tex-math id="M547">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M548"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq257.gif"/></alternatives></inline-formula>, we look to generate a measure that expresses <inline-formula id="IEq258"><alternatives><tex-math id="M549">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{IOR}}_{k}$$\end{document}</tex-math><mml:math id="M550"><mml:msub><mml:mi mathvariant="normal">IOR</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq258.gif"/></alternatives></inline-formula> across a range of <inline-formula id="IEq259"><alternatives><tex-math id="M551">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M552"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq259.gif"/></alternatives></inline-formula> values. To do so, we calculate the average improvement over random across the number of clips reviewed, from <inline-formula id="IEq260"><alternatives><tex-math id="M553">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0$$\end{document}</tex-math><mml:math id="M554"><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq260.gif"/></alternatives></inline-formula> to the total number, <inline-formula id="IEq261"><alternatives><tex-math id="M555">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M556"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq261.gif"/></alternatives></inline-formula>, as follows:<disp-formula id="Equj"><alternatives><tex-math id="M557">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathrm{IOR}} }_{n}^{\mathrm{method}}=\frac{1}{n}{\sum }_{k=0}^{n}{\mathrm{IOR}}_{k}^{\mathrm{method}}.$$\end{document}</tex-math><mml:math id="M558" display="block"><mml:mrow><mml:msubsup><mml:mover><mml:mi mathvariant="normal">IOR</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">method</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">IOR</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi mathvariant="normal">method</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equj.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq262"><alternatives><tex-math id="M559">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathrm{IOR}} }_{n}^{\mathrm{method}}$$\end{document}</tex-math><mml:math id="M560"><mml:msubsup><mml:mover><mml:mi mathvariant="normal">IOR</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">method</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq262.gif"/></alternatives></inline-formula> expresses the mean improvement over random of method <inline-formula id="IEq263"><alternatives><tex-math id="M561">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{method}$$\end{document}</tex-math><mml:math id="M562"><mml:mi mathvariant="normal">method</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq263.gif"/></alternatives></inline-formula> over <inline-formula id="IEq264"><alternatives><tex-math id="M563">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M564"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq264.gif"/></alternatives></inline-formula> clips. After calculating <inline-formula id="IEq265"><alternatives><tex-math id="M565">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathrm{IOR}} }_{n}^{\mathrm{conf}}$$\end{document}</tex-math><mml:math id="M566"><mml:msubsup><mml:mover><mml:mi mathvariant="normal">IOR</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq265.gif"/></alternatives></inline-formula> and <inline-formula id="IEq266"><alternatives><tex-math id="M567">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathrm{IOR}} }_{n}^{\mathrm{opt}}$$\end{document}</tex-math><mml:math id="M568"><mml:msubsup><mml:mover><mml:mi mathvariant="normal">IOR</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">opt</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq266.gif"/></alternatives></inline-formula> (i.e., <inline-formula id="IEq267"><alternatives><tex-math id="M569">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{IOR} }_{n}$$\end{document}</tex-math><mml:math id="M570"><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="italic">IOR</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq267.gif"/></alternatives></inline-formula> for confidence-based and optimal sorting), we can generate a final measure for the review efficiency by expressing the average improvement of confidence score <inline-formula id="IEq268"><alternatives><tex-math id="M571">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}$$\end{document}</tex-math><mml:math id="M572"><mml:mi mathvariant="normal">conf</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq268.gif"/></alternatives></inline-formula> over random relative to the maximum possible improvement over random (optimal review):<disp-formula id="Equk"><alternatives><tex-math id="M573">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{review}\_\mathrm{efficiency}}_{n}^{\mathrm{conf}}=\frac{ {\overline{\mathrm{IOR}} }_{n}^{\mathrm{conf}}}{{\overline{\mathrm{IOR}} }_{n}^{\mathrm{opt}}}.$$\end{document}</tex-math><mml:math id="M574" display="block"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">review</mml:mi><mml:mi>_</mml:mi><mml:mi mathvariant="normal">efficiency</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mover><mml:mi mathvariant="normal">IOR</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup><mml:msubsup><mml:mover><mml:mi mathvariant="normal">IOR</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">opt</mml:mi></mml:msubsup></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2023_29574_Article_Equk.gif" position="anchor"/></alternatives></disp-formula>
This metric expresses how close review using metric <inline-formula id="IEq269"><alternatives><tex-math id="M575">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}$$\end{document}</tex-math><mml:math id="M576"><mml:mi mathvariant="normal">conf</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq269.gif"/></alternatives></inline-formula> is to optimal. If sort order based on <inline-formula id="IEq270"><alternatives><tex-math id="M577">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{conf}$$\end{document}</tex-math><mml:math id="M578"><mml:mi mathvariant="normal">conf</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq270.gif"/></alternatives></inline-formula> exactly matches that of sorting by accuracy, <inline-formula id="IEq271"><alternatives><tex-math id="M579">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{review}\_\mathrm{efficiency}}_{n}^{\mathrm{conf}}=1$$\end{document}</tex-math><mml:math id="M580"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">review</mml:mi><mml:mi>_</mml:mi><mml:mi mathvariant="normal">efficiency</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq271.gif"/></alternatives></inline-formula>. If the sort order is no better than random, <inline-formula id="IEq272"><alternatives><tex-math id="M581">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{review}\_\mathrm{efficiency}}_{n}^{\mathrm{conf}}=0$$\end{document}</tex-math><mml:math id="M582"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">review</mml:mi><mml:mi>_</mml:mi><mml:mi mathvariant="normal">efficiency</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi mathvariant="normal">conf</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_29574_Article_IEq272.gif"/></alternatives></inline-formula>.</p>
    </sec>
    <sec id="Sec28">
      <title>Implementation details and code availability</title>
      <p id="Par70">We implement the toolbox in MATLAB version 2020b. The GUI for annotation and confidence-based review is included in the toolbox as a MATLAB application. Figures are produced using Prism9 and OmniGraffle. The entire toolbox, along with example scripts, documentation, and additional implementation details is hosted via a public GitHub repository at: <ext-link ext-link-type="uri" xlink:href="https://github.com/carlwharris/DeepAction">https://github.com/carlwharris/DeepAction</ext-link>. We provide the intermediary data generated for the home-cage dataset (e.g., spatial and temporal frames and features, annotations, etc.) as an example project linked in the GitHub repository. Data produced to generate results for the CRIM13 project is available upon request, but not provided as an example project due to its large file sizes. Full data (i.e., results for each test split in both projects) needed to replicate the results is also available on request. Data for the exploratory data set is proprietary.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec29">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41598_2023_29574_MOESM1_ESM.docx">
            <caption>
              <p>Supplementary Information.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary Information</title>
    <p>The online version contains supplementary material available at 10.1038/s41598-023-29574-0.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>Supported by National Science Foundation Award #1632738 (PUT), the Neukom Institute for Computational Science at Dartmouth College (Neukom Scholars award to CH and Neukom Post-doctoral Fellowship to KF), and the David C. Hodgson Endowment for Undergraduate Research Award (to CH). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>C.H. conceived of the project, developed the approach and software, and analyzed the results with input from K.F. C.H. wrote the manuscript with input from P.T. and K.F. M.K. and M.M. procured the exploratory dataset.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>Supplementary information is available for this paper. Correspondence and requests for materials should be addressed to the corresponding author.</p>
  </notes>
  <notes id="FPar1" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par71">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crabbe</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Wahlsten</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dudek</surname>
            <given-names>BC</given-names>
          </name>
        </person-group>
        <article-title>Genetics of mouse behavior: Interactions with laboratory environment</article-title>
        <source>Science</source>
        <year>1999</year>
        <volume>284</volume>
        <fpage>1670</fpage>
        <lpage>1672</lpage>
        <pub-id pub-id-type="doi">10.1126/science.284.5420.1670</pub-id>
        <?supplied-pmid 10356397?>
        <pub-id pub-id-type="pmid">10356397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wahlsten</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Different data from different labs: Lessons from studies of gene–environment interaction</article-title>
        <source>J. Neurobiol.</source>
        <year>2003</year>
        <volume>54</volume>
        <fpage>283</fpage>
        <lpage>311</lpage>
        <pub-id pub-id-type="doi">10.1002/neu.10173</pub-id>
        <?supplied-pmid 12486710?>
        <pub-id pub-id-type="pmid">12486710</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Würbel</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Behavioral phenotyping enhanced–beyond (environmental) standardization</article-title>
        <source>Genes Brain Behav.</source>
        <year>2002</year>
        <volume>1</volume>
        <fpage>3</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1046/j.1601-1848.2001.00006.x</pub-id>
        <?supplied-pmid 12886944?>
        <pub-id pub-id-type="pmid">12886944</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>van Dam</surname>
            <given-names>EA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An automated system for the recognition of various specific rat behaviours</article-title>
        <source>J. Neurosci. Methods</source>
        <year>2013</year>
        <volume>218</volume>
        <fpage>214</fpage>
        <lpage>224</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2013.05.012</pub-id>
        <?supplied-pmid 23769769?>
        <pub-id pub-id-type="pmid">23769769</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Drai</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Kafkafi</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Benjamini</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Elmer</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Golani</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Rats and mice share common ethologically relevant parameters of exploratory behavior</article-title>
        <source>Behav. Brain Res.</source>
        <year>2001</year>
        <volume>125</volume>
        <fpage>133</fpage>
        <lpage>140</lpage>
        <pub-id pub-id-type="doi">10.1016/S0166-4328(01)00290-X</pub-id>
        <?supplied-pmid 11682104?>
        <pub-id pub-id-type="pmid">11682104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Burgos-Artizzu, X. P., Dollár, P., Lin, D., Anderson, D. J. &amp; Perona, P. In <italic>2012 IEEE Conference on Computer Vision and Pattern Recognition.</italic> 1322–1329 (IEEE).</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jhuang</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Automated home-cage behavioural phenotyping of mice</article-title>
        <source>Nat. Commun.</source>
        <year>2010</year>
        <volume>1</volume>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1038/ncomms1064</pub-id>
        <pub-id pub-id-type="pmid">20975674</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kabra</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Robie</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Rivera-Alba</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Branson</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Branson</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>JAABA: Interactive machine learning for automatic annotation of animal behavior</article-title>
        <source>Nat. Methods</source>
        <year>2013</year>
        <volume>10</volume>
        <fpage>64</fpage>
        <lpage>67</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2281</pub-id>
        <?supplied-pmid 23202433?>
        <pub-id pub-id-type="pmid">23202433</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Lorbach, M., Poppe, R., Dam, E. A. V., Noldus, L. P. &amp; Veltkamp, R. C. in <italic>International Conference on Image Analysis and Processing.</italic> 565–574 (Springer).</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lorbach</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Learning to recognize rat social behavior: Novel dataset and cross-dataset application</article-title>
        <source>J. Neurosci. Methods</source>
        <year>2018</year>
        <volume>300</volume>
        <fpage>166</fpage>
        <lpage>172</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.05.006</pub-id>
        <?supplied-pmid 28495372?>
        <pub-id pub-id-type="pmid">28495372</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bohnslav</surname>
            <given-names>JP</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepEthogram, a machine learning pipeline for supervised behavior classification from raw pixels</article-title>
        <source>Elife</source>
        <year>2021</year>
        <volume>10</volume>
        <fpage>e63377</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.63377</pub-id>
        <?supplied-pmid 34473051?>
        <pub-id pub-id-type="pmid">34473051</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Zhu, Y., Lan, Z., Newsam, S. &amp; Hauptmann, A. in <italic>Asian conference on computer vision.</italic> 363–378 (Springer).</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Piergiovanni, A. &amp; Ryoo, M. in <italic>International Conference on Machine learning.</italic> 5152–5161 (PMLR).</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Feichtenhofer, C., Pinz, A. &amp; Zisserman, A. in <italic>Proceedings of the IEEE conference on computer vision and pattern recognition.</italic> 1933–1941.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>C-Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>M-H</given-names>
          </name>
          <name>
            <surname>Kira</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>AlRegib</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>TS-LSTM and temporal-inception: Exploiting spatiotemporal dynamics for activity recognition</article-title>
        <source>Signal Process. Image Commun.</source>
        <year>2019</year>
        <volume>71</volume>
        <fpage>76</fpage>
        <lpage>87</lpage>
        <pub-id pub-id-type="doi">10.1016/j.image.2018.09.003</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Wang, L. <italic>et al.</italic> Temporal segment networks: Towards good practices for deep action recognition. in <italic>European conference on computer vision.</italic> 20–36 (Springer).</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Kramida, G. <italic>et al.</italic> in <italic>Proc. Vis. Observ. Anal. Vertebrate Insect Behav. Workshop (VAIB).</italic> 1–3.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Simonyan, K. &amp; Zisserman, A. Two-stream convolutional networks for action recognition in videos. <italic>Adv. Neural Inf. Process. Syst.</italic><bold>27</bold> (2014).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Zach, C., Pock, T. &amp; Bischof, H. in <italic>Joint pattern recognition symposium.</italic> 214–223 (Springer).</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eroglu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yildirim</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Çinar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yildirim</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Diagnosis and grading of vesicoureteral reflux on voiding cystourethrography images in children using a deep hybrid model</article-title>
        <source>Comput. Methods Programs Biomed.</source>
        <year>2021</year>
        <volume>210</volume>
        <fpage>106369</fpage>
        <pub-id pub-id-type="doi">10.1016/j.cmpb.2021.106369</pub-id>
        <?supplied-pmid 34474195?>
        <pub-id pub-id-type="pmid">34474195</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Moreno-Torres</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Raeder</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Alaiz-Rodríguez</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Chawla</surname>
            <given-names>NV</given-names>
          </name>
          <name>
            <surname>Herrera</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A unifying view on dataset shift in classification</article-title>
        <source>Pattern Recogn.</source>
        <year>2012</year>
        <volume>45</volume>
        <fpage>521</fpage>
        <lpage>530</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2011.06.019</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Quinonero-Candela, J., Sugiyama, M., Schwaighofer, A. &amp; Lawrence, N. D. <italic>Dataset shift in machine learning</italic>. (Mit Press, 2008).</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Le, V. A. &amp; Murari, K. Recurrent 3D convolutional network for rodent behavior recognition. In <italic>ICASSP 2019–2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</italic>, 1174–1178 (2019).</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiang</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Context-aware mouse behavior recognition using hidden markov models</article-title>
        <source>IEEE Trans. Image Process.</source>
        <year>2018</year>
        <volume>28</volume>
        <fpage>1133</fpage>
        <lpage>1148</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2018.2875335</pub-id>
        <?supplied-pmid 30307863?>
        <pub-id pub-id-type="pmid">30307863</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Eyjolfsdottir, E. <italic>et al.</italic> Learning animal social behavior from trajectory features. Hosted by the School of Informatics at the University of Edinburgh (Scotland). <ext-link ext-link-type="uri" xlink:href="https://homepages.inf.ed.ac.uk/rbf/VAIB12PAPERS/eyjolfsdottir.pdf">https://homepages.inf.ed.ac.uk/rbf/VAIB12PAPERS/eyjolfsdottir.pdf</ext-link> (2012).</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Action recognition based on overcomplete independent components analysis</article-title>
        <source>Inf. Sci.</source>
        <year>2014</year>
        <volume>281</volume>
        <fpage>635</fpage>
        <lpage>647</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ins.2013.12.052</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meng</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Piao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Action recognition using form and motion modalities</article-title>
        <source>ACM Trans. Multimed. Comput. Commun. Appl. (TOMM)</source>
        <year>2020</year>
        <volume>16</volume>
        <fpage>1</fpage>
        <lpage>16</lpage>
        <pub-id pub-id-type="doi">10.1145/3350840</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Chen, W. Human and Animal Behavior Understanding. <italic>Graduate Theses, Dissertations, and Problem Reports, West Virginia University</italic> (2014). 10.33915/etd.192</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Farnebäck, G. in <italic>Scandinavian conference on Image analysis.</italic> 363–370 (Springer).</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gianluigi</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Raimondo</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>An innovative algorithm for key frame extraction in video summarization</article-title>
        <source>J. Real Time Image Proc.</source>
        <year>2006</year>
        <volume>1</volume>
        <fpage>69</fpage>
        <lpage>88</lpage>
        <pub-id pub-id-type="doi">10.1007/s11554-006-0001-1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>S-H</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A novel clustering method for static video summarization</article-title>
        <source>Multimed. Tools Appl.</source>
        <year>2017</year>
        <volume>76</volume>
        <fpage>9625</fpage>
        <lpage>9641</lpage>
        <pub-id pub-id-type="doi">10.1007/s11042-016-3569-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Batty, E. <italic>et al.</italic> BehaveNet: nonlinear embedding and Bayesian neural decoding of behavioral videos. <italic>Adv. Neural Inf. Process. Syst.</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Papernot, N. &amp; McDaniel, P. Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning. <italic>arXiv preprint </italic><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1803.04765">arXiv:1803.04765</ext-link> (2018).</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Gal, Y. &amp; Ghahramani, Z. in <italic>international conference on machine learning.</italic> 1050–1059 (PMLR).</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cryan</surname>
            <given-names>JF</given-names>
          </name>
          <name>
            <surname>Holmes</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The ascent of mouse: Advances in modelling human depression and anxiety</article-title>
        <source>Nat. Rev. Drug Discov.</source>
        <year>2005</year>
        <volume>4</volume>
        <fpage>775</fpage>
        <lpage>790</lpage>
        <pub-id pub-id-type="doi">10.1038/nrd1825</pub-id>
        <?supplied-pmid 16138108?>
        <pub-id pub-id-type="pmid">16138108</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Dollár, P. (software reference): "Piotr's Computer Vision Matlab Toolbox (PMT)" by Piotr Dollar in 2016. Available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/pdollar/toolbox">https://github.com/pdollar/toolbox</ext-link> (2014).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pérez-González</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jaramillo-Duque</surname>
            <given-names>Á</given-names>
          </name>
          <name>
            <surname>Cano-Quintero</surname>
            <given-names>JB</given-names>
          </name>
        </person-group>
        <article-title>Automatic boundary extraction for photovoltaic plants using the deep learning U-net model</article-title>
        <source>Appl. Sci.</source>
        <year>2021</year>
        <volume>11</volume>
        <fpage>6524</fpage>
        <pub-id pub-id-type="doi">10.3390/app11146524</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Cun, S. Dual TVL1 Optical Flow. (software reference): "Dual TV-L1 Optical Flow" by Xiaodong Cun in 2017. Available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/vinthony/Dual_TVL1_Optical_Flow">https://github.com/vinthony/Dual_TVL1_Optical_Flow</ext-link> (2017).</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Deng, J. <italic>et al.</italic> in <italic>2009 IEEE conference on computer vision and pattern recognition.</italic> 248–255 (IEEE).</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Hussain, M., Bird, J. J. &amp; Faria, D. R. in <italic>UK Workshop on computational Intelligence.</italic> 191–202 (Springer).</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Duda, R. O., Hart, P. E. &amp; Stork, D. G. Pattern classification 2nd edition. <italic>New York, USA: John Wiley&amp;Sons</italic>, 35 (2001).</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Murphy, K. P. <italic>Machine learning: a probabilistic perspective</italic>. (MIT press, 2012).</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Le, Q., Karpenko, A., Ngiam, J. &amp; Ng, A. ICA with reconstruction cost for efficient overcomplete feature learning. <italic>Adv. Neural Inf. Process. Syst.</italic> (2011).</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Nocedal</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wright</surname>
            <given-names>SJ</given-names>
          </name>
        </person-group>
        <source>Numerical optimization</source>
        <year>1999</year>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Merity, S., Keskar, N. S. &amp; Socher, R. Regularizing and optimizing LSTM language models. <italic>arXiv preprint </italic><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1708.02182">arXiv:1708.02182</ext-link> (2017).</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Dwarampudi, M. &amp; Reddy, N. Effects of padding on LSTMs and CNNs. <italic>arXiv preprint </italic><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1903.07288">arXiv:1903.07288</ext-link> (2019).</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">Graves, A. in <italic>Supervised sequence labelling with recurrent neural networks</italic> 5–13 (Springer, 2012).</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Graves, A., Mohamed, A.-r. &amp; Hinton, G. in <italic>2013 IEEE international conference on acoustics, speech and signal processing.</italic> 6645–6649 (IEEE).</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput.</source>
        <year>1997</year>
        <volume>9</volume>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <?supplied-pmid 9377276?>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ogawa</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hori</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Error detection and accuracy estimation in automatic speech recognition using deep bidirectional recurrent neural networks</article-title>
        <source>Speech Commun.</source>
        <year>2017</year>
        <volume>89</volume>
        <fpage>70</fpage>
        <lpage>83</lpage>
        <pub-id pub-id-type="doi">10.1016/j.specom.2017.02.009</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Beaufays, F., Sak, H. &amp; Senior, A. in <italic>Interspeech.</italic> 338–342.</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J. Mach. Learn. Res.</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bishop</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Nasrabadi</surname>
            <given-names>NM</given-names>
          </name>
        </person-group>
        <source>Pattern Recognition and Machine Learning</source>
        <year>2006</year>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Keskar, N. S., Mudigere, D., Nocedal, J., Smelyanskiy, M. &amp; Tang, P. T. P. On large-batch training for deep learning: Generalization gap and sharp minima. <italic>arXiv preprint </italic><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1609.04836">arXiv:1609.04836</ext-link> (2016).</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yildirim</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Çinar</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A new model for classification of human movements on videos using convolutional neural networks: MA-Net</article-title>
        <source>Comput. Methods Biomech. Biomed. Eng. Imaging Vis.</source>
        <year>2021</year>
        <volume>9</volume>
        <fpage>651</fpage>
        <lpage>659</lpage>
        <pub-id pub-id-type="doi">10.1080/21681163.2021.1922315</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Guo, C., Pleiss, G., Sun, Y. &amp; Weinberger, K. Q. in <italic>International Conference on Machine Learning.</italic> 1321–1330 (PMLR).</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Kull, M. <italic>et al.</italic> Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration. <italic>Adv. Neural Inf. Process. Syst.</italic> (2019).</mixed-citation>
    </ref>
  </ref-list>
</back>
