<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9825763</article-id>
    <article-id pub-id-type="pmid">36477794</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac788</article-id>
    <article-id pub-id-type="publisher-id">btac788</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TCRconv: predicting recognition between T cell receptors and epitopes using contextualized motifs</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0060-6868</contrib-id>
        <name>
          <surname>Jokinen</surname>
          <given-names>Emmi</given-names>
        </name>
        <aff><institution>Department of Computer Science, Aalto University</institution>, Espoo 02150, <country country="FI">Finland</country></aff>
        <xref rid="btac788-cor1" ref-type="corresp"/>
        <!--emmi.jokinen@aalto.fi-->
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-0909-9484</contrib-id>
        <name>
          <surname>Dumitrescu</surname>
          <given-names>Alexandru</given-names>
        </name>
        <aff><institution>Department of Computer Science, Aalto University</institution>, Espoo 02150, <country country="FI">Finland</country></aff>
        <aff><institution>Helsinki Institute of Life Science, University of Helsinki</institution>, Helsinki 00014, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huuhtanen</surname>
          <given-names>Jani</given-names>
        </name>
        <aff><institution>Department of Clinical Chemistry and Hematology, Translational Immunology Research Program, University of Helsinki</institution>, Helsinki 00290, <country country="FI">Finland</country></aff>
        <aff><institution>Hematology Research Unit Helsinki, Helsinki University Hospital Comprehensive Cancer Center</institution>, Helsinki 00290, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gligorijević</surname>
          <given-names>Vladimir</given-names>
        </name>
        <aff><institution>Center for Computational Biology (CCB), Flatiron Institute, Simons Foundation</institution>, New York, NY 10010, <country country="US">USA</country></aff>
        <aff><institution>Prescient Design, Genentech</institution>, New York, NY, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mustjoki</surname>
          <given-names>Satu</given-names>
        </name>
        <aff><institution>Department of Clinical Chemistry and Hematology, Translational Immunology Research Program, University of Helsinki</institution>, Helsinki 00290, <country country="FI">Finland</country></aff>
        <aff><institution>Hematology Research Unit Helsinki, Helsinki University Hospital Comprehensive Cancer Center</institution>, Helsinki 00290, <country country="FI">Finland</country></aff>
        <aff><institution>iCAN Digital Precision Cancer Medicine Flagship</institution>, Helsinki, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bonneau</surname>
          <given-names>Richard</given-names>
        </name>
        <aff><institution>Center for Computational Biology (CCB), Flatiron Institute, Simons Foundation</institution>, New York, NY 10010, <country country="US">USA</country></aff>
        <aff><institution>Prescient Design, Genentech</institution>, New York, NY, <country country="US">USA</country></aff>
        <aff><institution>Center for Data Science, New York University</institution>, New York, NY 10011, <country country="US">USA</country></aff>
        <aff><institution>Department of Computer Science, New York University, Courant Institute of Mathematical Sciences</institution>, New York, NY 10012, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Heinonen</surname>
          <given-names>Markus</given-names>
        </name>
        <aff><institution>Department of Computer Science, Aalto University</institution>, Espoo 02150, <country country="FI">Finland</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Lähdesmäki</surname>
          <given-names>Harri</given-names>
        </name>
        <aff><institution>Department of Computer Science, Aalto University</institution>, Espoo 02150, <country country="FI">Finland</country></aff>
        <xref rid="btac788-cor1" ref-type="corresp"/>
        <!--harri.lahdesmaki@aalto.fi-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Birol</surname>
          <given-names>Inanc</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac788-cor1">To whom correspondence should be addressed. <email>emmi.jokinen@aalto.fi</email> or <email>harri.lahdesmaki@aalto.fi</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-12-07">
      <day>07</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>07</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac788</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>02</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>06</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>19</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac788.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>T cells use T cell receptors (TCRs) to recognize small parts of antigens, called epitopes, presented by major histocompatibility complexes. Once an epitope is recognized, an immune response is initiated and T cell activation and proliferation by clonal expansion begin. Clonal populations of T cells with identical TCRs can remain in the body for years, thus forming immunological memory and potentially mappable immunological signatures, which could have implications in clinical applications including infectious diseases, autoimmunity and tumor immunology.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We introduce TCRconv, a deep learning model for predicting recognition between TCRs and epitopes. TCRconv uses a deep protein language model and convolutions to extract contextualized motifs and provides state-of-the-art TCR-epitope prediction accuracy. Using TCR repertoires from COVID-19 patients, we demonstrate that TCRconv can provide insight into T cell dynamics and phenotypes during the disease.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>TCRconv is available at <ext-link xlink:href="http://github.com/emmijokinen/tcrconv" ext-link-type="uri">https://github.com/emmijokinen/tcrconv</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Academy of Finland</institution>
            <institution-id institution-id-type="DOI">10.13039/501100002341</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>313271</award-id>
        <award-id>314445</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>T cell receptors (TCRs) form diverse repertoires through V(D)J recombination, which allows T cells to recognize a large variety of antigens. Short peptide sequences from the antigens, called epitopes, are presented to T cells via major histocompatibility complex (MHC) molecules, and successful recognition of an epitope–MHC complex by a TCR results in T cell activation and immune response against the antigen. Discovering epitope-specific TCRs holds the potential to provide clinically relevant insights into TCR repertoires in fields ranging from vaccine design and diagnostics to immunotherapy biomarker identification.</p>
    <p>Latest high-throughput sequencing technologies have enabled profiling large quantities of TCR sequences. Concurrently, several methods have been proposed for predicting TCR-epitope recognition that include Gaussian processes (TCRGP by <xref rid="btac788-B9" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>), deep learning methods [DeepTCR by <xref rid="btac788-B15" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic> (2021)</xref>, and ERGO-II by <xref rid="btac788-B17" ref-type="bibr">Springer <italic toggle="yes">et al.</italic> (2021)</xref>], gradient boosting decision trees [SETE by <xref rid="btac788-B18" ref-type="bibr">Tong <italic toggle="yes">et al.</italic> (2020)</xref>] and TCRdist by <xref rid="btac788-B2" ref-type="bibr">Dash <italic toggle="yes">et al.</italic> (2017)</xref>. Apart from ERGO-II all these methods use epitopes as class information to predict if a TCR would recognize one of the predetermined epitopes, which may still be more reliable with the limited amount of epitope-specific TCR data available. TCRGP is a Gaussian process-based classifier that can utilize complementarity determining region 3 (CDR3) or additionally any other CDRs from either α- or β-chain or both, depending on what information is available. DeepTCR uses convolutional neural networks (CNNs) with trainable embedding layers for the CDR3 and V/D/J genes. SETE on the other hand computes the PCA of 3-mer occurrences in CDR3 regions and uses gradient boosting decision trees to classify CDR3 sequences. TCRdist uses a BLOSUM62-based distance measure between selected CDRs to determine if a new test TCR is closer to TCRs specific to a certain epitope or to some non-specific control TCRs. ERGO-II learns long short-term memory encodings for both CDR3s and epitopes (or autoencoder embeddings for CDR3s) and uses both the TCR and the epitope as inputs to predict if a given TCR and epitope bind.</p>
    <p>Previous work has shown that while the CDR3 is crucial for the prediction, it is beneficial to utilize also other TCR regions as well as the paired TCRαβ sequences (<xref rid="btac788-B2" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac788-B9" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac788-B15" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac788-B17" ref-type="bibr">Springer <italic toggle="yes">et al.</italic>, 2021</xref>). We focus on major open questions in TCR-epitope prediction: how to (i) utilize efficiently all TCR regions that determine epitope-specificity, (ii) handle TCR cross-reactivity and (iii) use TCR-epitope prediction methods for unsupervised analysis of TCR-repertoires.</p>
    <p>Here, we present TCRconv, a CNN that utilizes rich contextualized transformer embeddings of TCRs to predict epitope recognition (see <xref rid="btac788-F1" ref-type="fig">Fig. 1</xref>). Unlike the previous methods, TCRconv models TCR specificity with a multilabel predictor that naturally accounts for TCR cross-reactivity. Transformer-based language models, such as BERT (Bidirectional Encoder Representations from Transformers), have been adapted for proteins and can capture protein folding as well as learn useful representations of binding sites and complex biophysical properties (<xref rid="btac788-B19" ref-type="bibr">Vig <italic toggle="yes">et al.</italic>, 2020</xref>). They have been successfully used in various tasks, including protein family and protein interaction prediction (<xref rid="btac788-B12" ref-type="bibr">Nambiar <italic toggle="yes">et al.</italic>, 2020</xref>) and protein-specific drug generation (<xref rid="btac788-B7" ref-type="bibr">Grechishnikova, 2021</xref>), making them a plausible candidate for TCR-epitope prediction. We utilize the transformer model protBERT (<xref rid="btac788-B3" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic>, 2020</xref>), which transfers information from the complete TCR sequence to the CDR3 embedding from which the convolutional networks then extract and utilize contextualized motifs.</p>
    <fig position="float" id="btac788-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>TCRconv pipeline. (<bold>A</bold>) The TCR sequence determined by V(D)J recombination contains the complementarity-determining regions. TCRα and/or TCRβ sequences can be used, here TCRβ is shown. (<bold>B</bold>) ProtBERT embedding is created for each TCR sequence and the CDR3 embedding, transfused with information from its context, is extracted. (<bold>C</bold>) The multilabel predictor produces simultaneously separate predictions for each epitope</p>
      </caption>
      <graphic xlink:href="btac788f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>Lets assume that we have <italic toggle="yes">N</italic> TCRs that are represented by their amino acid sequences <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">N</mml:mi><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">V</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> represents one of the 20 naturally occurring amino acids and <italic toggle="yes">L<sub>n</sub></italic> is the length of the <italic toggle="yes">n</italic><sup>th</sup> TCR. Each of the <italic toggle="yes">N</italic> TCRs is paired with a multihot encoding. For TCR <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the encoding <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> defines which of the <italic toggle="yes">C</italic> epitopes the TCR recognizes:
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if TCR</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>recognizes epitope</mml:mtext><mml:mo> </mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise</mml:mtext><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
    <p>The labeled data are denoted collectively as <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
    <sec>
      <title>2.1 Data</title>
      <p>For training and testing our model, we have constructed three datasets of human TCR sequences from the data available in the VDJdb database by <xref rid="btac788-B1" ref-type="bibr">Bagaev <italic toggle="yes">et al.</italic> (2020)</xref> (vdjdb.cdr3.net). VDJdb gives confidence scores from 0 to 3 for each of its entries (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1</xref>). For a comprehensive dataset VDJdbβ-large, we selected TCRβs with all confidence scores and with at least 50 unique TCRβs for each epitope (a TCR is considered as unique if the combination of its CDR3 and V- and J-genes is unique). This resulted in a dataset with 51 distinct epitopes and 30 503 unique TCRβs. For a high-quality dataset VDJdbβ-small we chose TCRβs with at least a confidence score of 1 and at least 40 unique TCRs per epitope, which resulted in 1977 unique TCRs specific for 21 epitopes. Finally, dataset VDJdbαβ-large consists of paired TCRαβ sequences with all confidence scores and at least 50 unique TCRαβs per epitope, resulting in total 20 200 unique TCRs and 18 epitopes. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref> summarizes these datasets and the cross-reactivities of the TCRs are visualized in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. As the requirements for the datasets overlap, so do the datasets: e.g. VDJdbβ-large contains the complete VDJdbβ-small dataset.</p>
      <p>All presented model evaluations are conducted using a stratified 10-fold cross-validation, where TCRs specific to each epitope are distributed to the folds as evenly as possible. As our dataset only consists of unique TCRs, the same TCR can never be both in training and test folds. To illustrate the difficulty of predicting the epitope specificity of TCRs with the chosen data, we visualized the CDR3 edit-distances from each TCR specific to an epitope to TCRs with the same specificity and to TCRs with other specificity (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). For example, in VDJdbβ-large dataset, for 37 of the 51 epitopes the nearest TCRs are more often specific to another epitope than to the same epitope. Further, <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref> shows the edit distances from TCRs specific to the chosen epitope to all TCRs with the same and other specificity, illustrating that a simple measure such as an edit-distance is not sufficient for assessing if TCRs share the same epitope-specificity. The corresponding edit-distance plots for VDJdbβ-small are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S5</xref>. The difficulty of classifying epitope-specific TCRs is further highlighted by the UMAP visualizations of the BERT embeddings for TCRs in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S6 and S7</xref>. With most epitopes the TCRs recognizing them are scattered with no defined clusters. With a few epitopes, such as IAV M<sub>GILGFVFTL</sub>, there are several small clusters, but a large part of the epitope-specific TCRs are still scattered.</p>
    </sec>
    <sec>
      <title>2.2 TCR embeddings</title>
      <p>For constructing the TCR embeddings, we used protBERT (<xref rid="btac788-B3" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic>, 2020</xref>) which is trained on 216 million UniRef100 sequences. The model was trained with a token-prediction task and during the training phase 15% of the tokens (amino acids) in the sequences were replaced by a MASK token. The model contains 16 attention heads in each multi-head attention block on 30 layers, with 420 million parameters in total. The embedding dimension for each amino acid is 1024. The embeddings are contextualized, which means that the representation of an amino acid depends on the TCR sequence surrounding it and thus contains information from its context.</p>
      <p>Given an amino acid sequence <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> of a TCR, protBERT computes a corresponding embeddings <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The length of the TCR sequences, <italic toggle="yes">L<sub>n</sub></italic>, defined by V-genes, CDR3 sequences and J-genes, varies roughly between 100 and 140 amino acids. We extract the part of the embedding corresponding to the CDR3, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. The CDR3 embedding provides a more compact presentation of the TCR that is still transfused with information from its context.</p>
      <p>We also experimented with a protBERT model fine-tuned with TCR sequences, two different ELMO (Embeddings from Language Models) architectures, and one-hot encodings for the CDR3 and TCR sequences, but the original protBERT model had the best performance. See <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref> for details.</p>
    </sec>
    <sec>
      <title>2.3 CNN predictor</title>
      <p>Once the protBERT embeddings are computed for the TCRs, our training data consists of pairs <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> that are used for training our predictor network <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> with parameters <italic toggle="yes">W</italic>. Our multilabel classifier consists of a parallel convolutional unit and a simple linear unit for each TCR chain and was motivated by the CNN classifier presented by <xref rid="btac788-B6" ref-type="bibr">Gligorijević <italic toggle="yes">et al.</italic> (2021)</xref> (see <xref rid="btac788-F2" ref-type="fig">Fig. 2</xref>). The convolutional unit consists of parallel convolutional layers with varying kernel sizes (5, 9, 15 and 21, with 120, 100, 80 and 60 filters, respectively) that can capture different length motifs. The outputs from these layers are concatenated and fed through batch normalization, rectified linear unit (ReLU) activation, and a dropout layer with 0.1 dropping probability. Those are followed by another convolutional layer (kernel size 3, 60 filters) that can extract higher level features based on the outputs from the previous convolutional layers. Finally, max pooling is performed over the sequence lengths, which provides fixed sized outputs regardless of the sequences’ lengths. As our input embeddings are contextualized, the convolutional unit extracts contextualized motifs where the surroundings of the motif even outside the CDR3 also affect how it is perceived. The linear unit can more flexibly utilize the expressive features of the BERT embeddings. It consists of a max pooling layer, a linear layer, and a ReLU activation. The outputs of the convolutional and linear units are concatenated and put through a dropout layer with dropping probability 0.1, batch normalization and ReLU. The final linear layer gives predictions simultaneously for each class that are separately squashed between 0 and 1 by a sigmoid layer.</p>
      <fig position="float" id="btac788-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>TCRconv multilabel predictor. TCRconv can utilize one or two inputs, i.e. embedding for TCRβ and/or TCRα. Each sequence embedding goes through a convolutional and a linear unit in parallel. The outputs from these units (for each TCR chain) are concatenated and go through a final linear layer. During training, weighted binary cross-entropy with logits loss (BCEWithLogitsLoss which includes a sigmoid function) is utilized, and the predictions are squashed between 0 and 1 by a sigmoid layer, separately for each epitope</p>
        </caption>
        <graphic xlink:href="btac788f2" position="float"/>
      </fig>
      <p>To optimize the parameters <italic toggle="yes">W</italic> of the network, we minimize the binary cross-entropy (BCE) with logits loss between the true labels <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and predicted labels <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, simultaneously for all epitopes. For TCR <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and label <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, the loss is defined as
<disp-formula id="E2"><label>(1)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the weight for positive samples from class <italic toggle="yes">c</italic> of size <italic toggle="yes">m<sub>c</sub></italic>, and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the sigmoid function. Loss over all TCRs and labels is then defined as
<disp-formula id="E3"><label>(2)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mtext>Loss</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>ℓ</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>This multilabel formulation and usage of BCE loss allows us to account for also cross-reacting TCRs that can recognize multiple epitopes.</p>
      <p>For training the models, we use stochastic weight averaging (SWA) with learning rate scheduling (<xref rid="btac788-B8" ref-type="bibr">Izmailov <italic toggle="yes">et al.</italic>, 2018</xref>). The models are first trained for 2500 iterations (mini-batches) without weight averaging but with cosine annealing for the learning rates, so that the learning rates gradually decrease. After that, the training is continued for another 500 iterations with SWA on every iteration and again a decreasing learning rate is used. The learning rate is 0.0002, except for the linear unit, for which the learning rate is set to 0.01.</p>
    </sec>
    <sec>
      <title>2.4 Comparison to other methods</title>
      <p>We compared TCRconv to recently published methods for predicting TCR epitope-specificities, TCRGP (<xref rid="btac788-B9" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>), DeepTCR (<xref rid="btac788-B15" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic>, 2021</xref>), SETE (<xref rid="btac788-B18" ref-type="bibr">Tong <italic toggle="yes">et al.</italic>, 2020</xref>), TCRdist (<xref rid="btac788-B2" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>) and ERGO-II (<xref rid="btac788-B17" ref-type="bibr">Springer <italic toggle="yes">et al.</italic>, 2021</xref>). While our TCRconv can be trained simultaneously for all epitopes using the multi-hot labels, with TCRGP, DeepTCR, SETE, and TCRdist we trained separate binary classifiers for each epitope, so that TCRs known to recognize the epitope in question are considered as positive data points and TCRs specific to other epitopes are considered as negative data points. DeepTCR and SETE have options for multiclass classification, but they do not provide support for cross-reactive TCRs that our data contains. Therefore, they would have had a disadvantage if trained as multiclass classifiers as they then would have operated with either conflicted or missing class labels. ERGO-II takes TCR-epitope pairs as inputs and predicts if the pairs bind. Non-binding TCR-epitope pairs then need to be generated for its training.</p>
      <p>We compared the above methods on our two TCRβ datasets, VDJdbβ-large and VDJdbβ-small, using stratified 10-fold cross-validation. The folds used in the cross-validation were the same for each of these methods. As suggested by the authors, with DeepTCR 25% and with ERGO-II 20% of the training data were used as validation data for determining early stopping when training the classifiers. With ERGO-II, we used all the binding TCR-epitope pairs in our data, but additionally sampled five times more non-binding data, replicating their training procedure. Therefore, when with TCRconv e.g. TCR CASLSGRAPQHF, TRBV27*01 occurs once in VDJdbβ-small with a multi-hot encoding indicating that it can recognize epitopes GTSGPIINR and GTSGPIVNR, with ERGO-II it is repeated 12 times, twice in a positive pair with both GTSGPIINR and GTSGPIVNR, and 10 times in negative pairs formed by randomly selecting 10 of the other 19 epitopes in the dataset.</p>
    </sec>
    <sec>
      <title>2.5 TCR diversity</title>
      <p>To estimate the diversity of <italic toggle="yes">N</italic> TCRs specific to a certain epitope, we utilized a diversity measure similar to measures used in previous studies (<xref rid="btac788-B2" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac788-B9" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>). These measures are based on Simpson’s diversity index, but due to the large variety of TCRs, they measure similarities between TCRs instead of exact matches. Here, the similarity between TCRs <italic toggle="yes">n</italic> and <italic toggle="yes">j</italic> is computed based on the used embeddings <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> that have been <italic toggle="yes">aligned</italic> based on IMGT numbering:
<disp-formula id="E4"><label>(3)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtext>diversity</mml:mtext><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mtext>Fro</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo> </mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">d</mml:mi><mml:msup><mml:mrow><mml:mo>.</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="true">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true">)</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mtext>Fro</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denotes the Frobenius norm of <bold>X</bold>, and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">d</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> is set to 10.4 (maximum feature-wise standard deviations multiplied by the median sequence length 14).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Comparison to other methods</title>
      <p>We first compared the prediction accuracies of TCRconv and previous methods, TCRGP, deepTCR, TCRdist, SETE and ERGO-II, on the two epitope-specific datasets: a comprehensive VDJdbβ-large consisting of data with all confidence levels, and a smaller high-quality VDJdbβ-small (see Section 2.1 and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). Prediction accuracies are quantified using the average precision (AP), which accounts for class imbalances, and the area under the receiver operating characteristic curve (AUROC). TCRconv achieves the highest AP and AUROC scores on VDJdbβ-large (33% and 3% improvement to the second best DeepTCR) (<xref rid="btac788-F3" ref-type="fig">Fig. 3A</xref>). High AP scores are essential as minimizing false positive predictions with large TCR repertoires and small TCR clones (<xref rid="btac788-B14" ref-type="bibr">Qi <italic toggle="yes">et al.</italic>, 2014</xref>) is crucial. Overall, all methods performed better on the higher confidence, albeit smaller, VDJdbβ-small dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref> and <xref rid="sup1" ref-type="supplementary-material">Table S2</xref>).</p>
      <fig position="float" id="btac788-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>TCRconv evaluation. Results are obtained using stratified 10-fold cross-validation on VDJdbβ-large dataset. (<bold>A</bold>) Comparing TCRconv to other methods using average AUROC and AP scores. (<bold>B</bold>) The AUROC scores for TCRconv predictions correlate negatively with the diversity of the epitope specific TCRs (Pearson correlation −0.72). (<bold>C</bold>) Increasing the embedding context size increases the predictive AUROC score. The schematics on top show the approximate sections included in different context sizes. CDR3 + X refers to CDR3 embeddings with context size X and complete TCR to embeddings for complete TCRs without extracting only the CDR3 parts. TCRconv uses CDR3 + full (bolded)</p>
        </caption>
        <graphic xlink:href="btac788f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 TCR cross-reactivity and diversity</title>
      <p>As TCRs can be cross-reactive (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>), TCRconv benefits from using a single multilabel predictor that can predict a TCR to recognize several epitopes. Whereas, to account for cross-reactivity with previous binary (<xref rid="btac788-B2" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac788-B9" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>) and multiclass classifiers (<xref rid="btac788-B15" ref-type="bibr">Sidhom <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac788-B18" ref-type="bibr">Tong <italic toggle="yes">et al.</italic>, 2020</xref>), a large set of separate (one-vs-all) classifiers had to be trained, one for each epitope. TCRconv performs well also with cross-reacting TCRs (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>). Further, consistent with previous results (<xref rid="btac788-B2" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac788-B9" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>), we confirmed that prediction accuracy across epitopes correlates negatively with the diversity of the TCRs recognizing these epitopes (<xref rid="btac788-F3" ref-type="fig">Fig. 3B</xref>, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S9A</xref>).</p>
    </sec>
    <sec>
      <title>3.3 Effect of the CDR3 context size and αβ-chain usage</title>
      <p>CDR3 is essential in epitope recognition, but structural (<xref rid="btac788-B5" ref-type="bibr">Glanville <italic toggle="yes">et al.</italic>, 2017</xref>) and computational (<xref rid="btac788-B2" ref-type="bibr">Dash <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac788-B9" ref-type="bibr">Jokinen <italic toggle="yes">et al.</italic>, 2021</xref>) evidence suggests that CDR1 and CDR2, which mainly contact the MHC, may also interact with the epitope and aid the prediction. We next evaluated how much of the TCR sequence around the CDR3 should be used as context when computing the protBERT embedding. The prediction AUROC score improves gradually from 0.68 to 0.77 when the context size is increased from no context to full context (i.e. the full-length TCRβ sequence, or VDJ-sequence) on VDJdbβ-large (<xref rid="btac788-F3" ref-type="fig">Fig. 3C</xref>), indicating that protBERT successfully conveys relevant information from the context to the CDR3 embedding. Using the CDR3 with full context corresponds to using both V- and J-genes in addition to the CDR3, since the region before the CDR3 is encoded by the V-gene and the region after CDR3 by the J-gene. With both datasets the AUROC and AP scores improve or remain the same when using context as far as before CDR1 (<xref rid="btac788-F3" ref-type="fig">Fig. 3C</xref>, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S9B</xref>). Remarkably, the entire TCR embedding is not needed, but using the CDR3 embedding with full context provides similar or slightly better results.</p>
      <p>TCR is a dimeric molecule that consists of α and β chains. While TCRβ is more often in close proximity to an epitope than TCRα, usually both chains are within 5 Å of the epitope (<xref rid="btac788-B5" ref-type="bibr">Glanville <italic toggle="yes">et al.</italic>, 2017</xref>). We studied the effect of TCRα and TCRβ on TCR-epitope prediction on VDJdbαβ-large dataset of paired TCRαβ sequences (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). We found substantial performance improvement from using both chains over either chain individually (<xref rid="btac788-F4" ref-type="fig">Fig. 4</xref>). Further, when using either chain individually, it varies which chain provides the best accuracy. With most epitopes, the accuracy is better when using the β-chain, but with some epitopes using the α-chain is clearly more beneficial. When using both chains, the increase in accuracy when compared to either chain individually is more systematic.</p>
      <fig position="float" id="btac788-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>TCRconv performs best when using both α- and β-chains. Results are obtained on VDJdbαβ-large dataset in terms of average AUROC and AP scores over stratified 10-fold cross-validation. Each circle corresponds to TCRs specific to one epitope as described in the legend. Above boxplots show the distribution of the prediction accuracies when the TCRconv model is trained using embeddings for CDR3α, CDR3β or both (always with the full context, meaning that an embedding is first computed for the complete TCR determined by the CDR3, and V- and J-genes, and then the part corresponding to the CDR3 is extracted). Mean metrics are shown on top of each boxplot. Below the circles from the three models are connected by lines, illustrating how for most epitopes the best results are obtained when using both chains and that using β-chains is better than using α-chains, although there are exceptions</p>
        </caption>
        <graphic xlink:href="btac788f4" position="float"/>
      </fig>
      <p>With complex models such as protBERT and multiple convolutional layers, each with several filters, it can be challenging to identify any clear motifs that would be important for the predictions. In <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S3</xref>, we discuss how saliency maps can be used for this purpose.</p>
    </sec>
    <sec>
      <title>3.4 The effect of HLA-type</title>
      <p>As the TCR regions outside the CDR3 do not often interact with an epitope but may interact with the MHC molecule presenting the epitope, the HLA-type of the MHC can affect the recognition between the TCR and the epitope. Therefore, utilizing these regions could introduce a bias in the epitope-specificity prediction. Although the available TCR-epitope-MHC complexes in VDJdb contain various HLA-types, most of the data are restricted to HLA-A*02 and almost all the epitopes are presented by a single HLA-group (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S10A</xref>). This makes it difficult to model or even assess how different HLA-types affect the TCRs’ ability to bind certain epitopes. To ensure that our multilabel predictor is predicting a TCR’s ability to bind to an epitope and not to the HLA presenting it, we examined how much the results differ between different HLA-genes as well as between TCRconv models trained on data restricted by any HLA type or only with HLA-A*02 restricted data. The number of epitopes restricted by each HLA-gene is limited and the prediction accuracy varies considerably between epitopes, but <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S10B</xref> indicates that differences between HLA-genes are modest (AUROC across genes varies from 0.743 to 0.810, while AUROC across epitopes varies from 0.532 to 0.996). Further, <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S10C</xref> shows that the accuracy is similar when TCRconv is trained on all data or only with HLA-A*02 restricted epitopes. These results suggest that TCRconv predicts TCR’s ability to bind epitopes and not the HLAs.</p>
    </sec>
    <sec>
      <title>3.5 Dynamics and phenotypes of SARS-CoV-2-specific TCRs in COVID-19</title>
      <p>Finally, we demonstrate how to utilize TCRconv in repertoire data analysis to track T cell dynamics (<xref rid="btac788-B16" ref-type="bibr">Snyder <italic toggle="yes">et al.</italic>, 2020</xref>) during coronavirus disease 2019 (COVID-19) and to reveal the phenotypes of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) specific T cells in moderate and severe COVID-19. We first trained a TCRconv model specifically for SARS-CoV-2 epitopes using ImmuneCODE (<xref rid="btac788-B13" ref-type="bibr">Nolan <italic toggle="yes">et al.</italic>, 2020</xref>) and VDJdbβ-large data.</p>
      <sec>
        <title>3.5.1 TCRconv model for SARS-CoV-2 epitopes</title>
        <p>For training TCRconv models for SARS-CoV-2 epitopes, we utilized ImmuneCODE MIRA-data of TCRs specific to MHC-I restricted peptides. To fully exploit the data, we did the following preprocessing with three options for the TCR sequences: (i) If the V- and J-genes and their alleles could be determined from the nucleotide sequence (length 29 nucleotides), we used the exact TCR amino acid sequence determined by the CDR3β, V- and J-genes. (ii) If a V- or J- gene could be determined but not its allele, we set the allele to 01 and used it for constructing the amino acid sequence. (iii) If a gene could not be determined, we utilized a partial amino acid sequence that we could uniquely determine based on the nucleotide sequence. BERT embeddings were computed for these TCRβ sequences and the parts of the embeddings corresponding to the CDR3s were extracted and used with the CNN predictor. TCR uniqueness was determined by these longest amino acid sequences that we could obtain. We selected 139 099 unique TCRβs specific to 188 peptide groups with at least 50 unique TCRβs specific to them (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>) and used stratified 10-fold cross-validation with these TCRs to evaluate TCRconv on this data. The performance in terms of AP scores for the TCRs specific to each peptide group is shown by the peptide group’s genomic location in <xref rid="btac788-F5" ref-type="fig">Figure 5</xref>, and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S11A</xref> additionally shows the AUROC scores and diversity of these TCRs. The mean AUROC and AP scores are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S11B</xref>. We then selected the twenty peptide groups that performed best in terms of weighted mean of AUROC and AP scores (both scores were scaled into range [0,1]) and used the corresponding TCRs together with VDJdbβ-large dataset to construct the final predictor (performance using stratified 10-fold cross-validation is shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S11C</xref>).</p>
        <fig position="float" id="btac788-F5">
          <label>Fig. 5.</label>
          <caption>
            <p>TCRconv prediction performance for SARS-CoV-2 epitopes by the peptides’ genome location in terms of AP scores. The ORF1ab region has been compressed</p>
          </caption>
          <graphic xlink:href="btac788f5" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.5.2 Dynamics of SARS-CoV-2-specific TCRs</title>
        <p>To track the T cell dynamics during COVID-19, we selected 493 COVID-19 patients from ImmuneCODE repertoires and 110 healthy controls from (<xref rid="btac788-B4" ref-type="bibr">Emerson <italic toggle="yes">et al.</italic>, 2017</xref>). We utilized TCR repertoires from ImmuneCODE that contain at least 250 000 TCRs and the number of days between diagnosing the patient and collecting the sample is reported. For the control repertoires, we also required at least 250 000 TCRs and only selected subjects with age at least 18 years (which is the age of the youngest subject in ImmunoCode data). The data are described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>. The sequences were preprocessed in the same way as the ImmuneCODE MIRA-data and each sample was downsampled to 250 000 TCRs. Using the TCRconv model for SARS-CoV-2 epitopes, we predicted the specificity for each of the approx. 150M T cells within these repertoires. We chose a threshold separately for each epitope that corresponds to false positive rate of 0.001. With thresholds this strict we are not likely to find all TCRs specific to the selected epitopes but have a high confidence in that the TCRs predicted to recognize these epitopes are true positives. We computed the frequency of SARS-CoV-2-specific TCRs in each repertoire and normalized it by the number of SARS-CoV-2 epitopes (20) to be better able to compare to responses for other viruses.</p>
        <p><xref rid="btac788-F6" ref-type="fig">Figure 6A</xref> shows that the frequency of SARS-CoV-2-specific T cells is highest during the first two days after diagnosis and starts to decrease later after the infection. In contrast, with influenza A virus (IAV), cytomegalovirus (CMV), Epstein-Barr virus (EBV) and hepatitis C virus (HCV) (<xref rid="btac788-F6" ref-type="fig">Fig. 6</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S12</xref>), the normalized frequency remains lower.</p>
        <fig position="float" id="btac788-F6">
          <label>Fig. 6.</label>
          <caption>
            <p>Analyzing TCR repertoires of COVID-19 patients with TCRconv. Dynamics of (<bold>A</bold>) SARS-CoV-2 (<bold>B</bold>) IAV and (<bold>C</bold>) CMV-specific T cells in terms of frequency normalized by the number of virus-related epitopes. There are 20 epitopes for SARS-CoV-2, 8 for IAV and 9 for CMV. Each data point corresponds to a repertoire and is colored by its dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>). Symbols “*” indicate statistically significant increase in frequency compared to healthy samples (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref>)</p>
          </caption>
          <graphic xlink:href="btac788f6" position="float"/>
        </fig>
        <p>To assess if the COVID-19 patients have significantly higher frequency of virus-specific T cells than healthy control subjects, and if the frequencies are positively correlated with subjects’ age, a linear regression analysis was performed. This was done separately for each time interval using linear model <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mtext>cc</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>cc</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mtext>age</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>age</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">y</italic> is the observed frequency, <italic toggle="yes">a</italic> is offset, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mtext>cc</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is parameter for case-control covariate <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>cc</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> which is zero for control samples and one for case samples of the considered time interval and <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mtext>age</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is parameter for age covariate <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>age</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. This analysis showed that the case-control difference is significant for time intervals 3–7, 8–14 and 15–28, as quantified by the Benjamini–Hochberg corrected one-tailed <italic toggle="yes">t</italic>-test (see <xref rid="btac788-F6" ref-type="fig">Fig. 6A</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref>).</p>
      </sec>
      <sec>
        <title>3.5.3 Phenotypes of SARS-CoV-2-specific TCRs</title>
        <p>To link TCR-specificity to T cell phenotype, we utilized scRNA+TCRαβ-seq of CD8+ T cells from bronchoalveolar lavage samples of nine COVID-19 patients with moderate or severe disease (<xref rid="btac788-B10" ref-type="bibr">Liao <italic toggle="yes">et al.</italic>, 2020</xref>). The scRNA-seq data were analyzed mainly with Python package scVI tools and R package Seurat (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S4</xref> for details). The T cell clustering colored by disease severity, phenotype and predicted epitope specificity is shown in <xref rid="btac788-F7" ref-type="fig">Figures 7A–C</xref> As expected, SARS-CoV-2-specific T cells were highly abundant in these samples (<xref rid="btac788-F7" ref-type="fig">Fig. 7D</xref>). Interestingly, consistent with slightly elevated frequency of EBV-specific T cells in COVID-19 repertoires (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S12C</xref>), T cells specific to EBV epitopes were also abundant in bronchoalveolar lavage samples. Moreover, in patients with moderate disease (<italic toggle="yes">n</italic> = 3) the SARS-CoV-2-specific T cells most often had tissue-resident memory phenotype (overexpression of ZNF683, CD69, TCF7) (<xref rid="btac788-F7" ref-type="fig">Fig. 7A–C</xref>). In patients with severe disease (<italic toggle="yes">n</italic> = 6), we found SARS-CoV-2-specific T cells to have possibly overtly proliferating (MKI67) and exhausted (HAVCR2/TIM3, CTLA4) phenotype, with high expression of co-stimulatory signals (ICOS, TNFRSF4/OX40R, GITR) and IFNG (<xref rid="btac788-F7" ref-type="fig">Fig. 7A–C and E</xref>). These findings refine previous findings of <xref rid="btac788-B11" ref-type="bibr">Moss (2022)</xref> by suggesting that patients with a moderate disease course form T cells capable of eliminating SARS-CoV-2 with minimal tissue damage while T cell overactivation in patients with a severe disease leads to an inappropriate tissue damage. The patient from which the T cells originate, and the frequency of epitope-specific TCRs per patient are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S13</xref>.</p>
        <fig position="float" id="btac788-F7">
          <label>Fig. 7.</label>
          <caption>
            <p>Characteristics of SARS-CoV-2-specific CD8+ T cells from bronchoalveolar lavage samples from patients with moderate (<italic toggle="yes">n</italic> = 3) or severe (<italic toggle="yes">n</italic> = 6) COVID-19 disease. UMAP presentations colored by (<bold>A</bold>) disease severity and (<bold>B</bold>) phenotypes. Panel (<bold>C</bold>) shows clustering with epitope-specific T cells marked, (<bold>D</bold>) proportions of epitope specific T cells and (<bold>E</bold>) phenotype distribution of virus specific T cells</p>
          </caption>
          <graphic xlink:href="btac788f7" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>3.6 Experimental validation of TCRconv predictions</title>
      <p>To estimate how well TCRconv performs compared to experimental measurements, we again utilized ImmuneCODE samples (<xref rid="btac788-B13" ref-type="bibr">Nolan <italic toggle="yes">et al.</italic>, 2020</xref>) for which both a TCRβ repertoire sequencing and a MIRA experiment were reported. We opted to focus on the Spike<sub>YLQPRTFLL</sub> epitope that was the only SARS-CoV-2 epitope in our VDJdbβ-large dataset, and used the TCRconv predictor trained on that dataset to make predictions for the TCR repertoires. One of the peptide groups used in the MIRA experiments consisted of peptides YLQPRTFL, YLQPRTFLL and YYVGYLQPRTF. Here we assume that a TCR that is found to recognize one of these peptides in the MIRA experiment is likely to recognize Spike<sub>YLQPRTFLL</sub>. We only focused on the TCR clones from the repertoires with size two or larger, so that there would be a reasonable chance of capturing the exact same TCR both in the repertoire and the MIRA experiment (see <xref rid="btac788-F8" ref-type="fig">Fig. 8</xref>). To be able to evaluate TCRconv’s prediction accuracies, we analyzed repertoire and MIRA sample pairs, where at least five TCR clones from the repertoire (with size two or larger) were validated in the corresponding MIRA experiment.</p>
      <fig position="float" id="btac788-F8">
        <label>Fig. 8.</label>
        <caption>
          <p>Predicted and experimentally validated specificity of TCRs for SARS-CoV-2 epitope Spike<sub>YLQPRTFLL</sub>. Each TCR clone in the repertoire sample ADIRP0000466_20200518 is represented as a circle that is colored red if it has been validated in the MIRA experiment eJL158 and grey if not. Each circle is positioned by it’s productive frequency (<italic toggle="yes">y</italic>-axis) and TCRconv prediction score (<italic toggle="yes">x</italic>-axis). The two vertical black lines show prediction thresholds 0.643 and 0.944 that correspond to false positive rates of 0.001 and 0.0001 obtained from the 10-fold cross-validation with VDJdbβ-large dataset. The TCRs with clone size one are shaded. The table below shows the true positive rate (TPR), false positive rate (FPR), false discovery rate (FDR) and positive predictive value (PPV) for the two thresholds and for clones of size at least two or at least three (A color version of this figure appears in the online version of this article)</p>
        </caption>
        <graphic xlink:href="btac788f8" position="float"/>
      </fig>
      <p><xref rid="btac788-F8" ref-type="fig">Figure 8</xref> shows the TCRconv predictions for each TCR clone in a repertoire together with the experimentally validated Spike<sub>YLQPRTFLL</sub>-specific TCRs. We computed four metrics for evaluating this performance: true positive rate (TPR), false positive rate (FPR), false discovery rate (FDR) and positive predictive value (PPV). These results show that TCRconv is able to identify a large portion of the Spike<sub>YLQPRTFLL</sub>-specific TCR clones that are validated in the matched MIRA experiment. Furthermore, the proportion of false positive predictions is small, especially when only larger clone sizes are considered. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S14</xref> results for another pair of matched repertoire and MIRA experiments.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion and conclusions</title>
    <p>Here, we have presented TCRconv, a novel deep learning method that combines transformer embeddings for TCR sequences and a CNN predictor. The protBERT model transfers useful information to the CDR3 embedding from the TCR regions surrounding it, making a compact and rich presentation of the TCR. Unlike previous methods, it has been formulated as a multilabel predictor that can make predictions simultaneously for multiple epitopes and account for cross-reacting TCRs. We have demonstrated that TCRconv has state-of-the-art accuracy in terms of AUROC and AP scores. We have also demonstrated how TCRconv can be applied for unsupervised analysis of TCR-repertoires as well as to link T cell phenotypes and epitope-specificity with single-cell RNA+TCR-seq data.</p>
    <p>Machine learning methods in general benefit from having ample data for training the models. As the amount of epitope-specific data increases the accuracy of existing methods such as TCRconv will further improve. Similarly, having sufficiently long sequencing reads that allows the recovery of the complete V(D)J sequences can clearly benefit the predictors, as we showed with the varying context sizes. As also the number of unique epitopes increases, it can become more productive to also incorporate the epitope sequence into TCR-epitope prediction models and predict TCRs’ specificity to previously unseen epitopes.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac788_Supplementary_Data</label>
      <media xlink:href="btac788_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We would like to acknowledge the computational resources provided by the Aalto Science-IT.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the Academy of Finland [313271 and 314445 to H.L. and 335432 and 335527 to S.M.]; ERA PerMed (JAKSTAT-TARGET consortium) [S.M.]; and by the Sigrid Juselius Foundation [S.M.].</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>Implementation for TCRconv and the epitope-specific TCR datasets are available at <ext-link xlink:href="https://github.com/emmijokinen/tcrconv" ext-link-type="uri">https://github.com/emmijokinen/tcrconv</ext-link>. The VDJdbβ-large, VDJdbβ-small, and VDJdbαβ-large datasets were obtained from the VDJdb database by <xref rid="btac788-B1" ref-type="bibr">Bagaev et al. (2020)</xref> (<ext-link xlink:href="https://vdjdb.cdr3.net" ext-link-type="uri">https://vdjdb.cdr3.net</ext-link>). Additional SARS-COV-2 specific TCRs and COVID-19 patient repertoires are available in the immuneACCESS database at <ext-link xlink:href="https://clients.adaptivebiotech.com/pub/covid-2020" ext-link-type="uri">https://clients.adaptivebiotech.com/pub/covid-2020</ext-link>. Control repertoires from <xref rid="btac788-B4" ref-type="bibr">Emerson et al. (2017</xref>) are available in the immuneACCESS database at <ext-link xlink:href="https://doi.org/10.21417/B7001Z" ext-link-type="uri">https://doi.org/10.21417/B7001Z</ext-link>. Implementation for the scRNA+TCRab-seq data analysis is available at <ext-link xlink:href="https://github.com/janihuuh/tcrconv_manu" ext-link-type="uri">https://github.com/janihuuh/tcrconv_manu</ext-link>. Count matrices, TCRαβ-seq results, and metadata from <xref rid="btac788-B10" ref-type="bibr">Liao et al. (2020</xref>) are available at GEO GSE145926.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac788-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bagaev</surname><given-names>D.V.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>VDJdb in 2019: database extension, new analysis infrastructure and a T-cell receptor motif compendium</article-title>. <source>Nucleic Acids Res</source>., <volume>48</volume>, <fpage>D1057</fpage>–<lpage>D1062</lpage>.<pub-id pub-id-type="pmid">31588507</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dash</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Quantifiable predictive features define epitope-specific T cell receptor repertoires</article-title>. <source>Nature</source>, <volume>547</volume>, <fpage>89</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">28636592</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) ProtTrans: towards cracking the language of life’s code through self-supervised learning. <italic toggle="yes">arXiv</italic>. <pub-id pub-id-type="doi">10.48550/arXiv.2007.06225</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac788-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emerson</surname><given-names>R.O.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Immunosequencing identifies signatures of cytomegalovirus exposure history and HLA-mediated effects on the T cell repertoire</article-title>. <source>Nat. Genet</source>., <volume>49</volume>, <fpage>659</fpage>–<lpage>665</lpage>.<pub-id pub-id-type="pmid">28369038</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glanville</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Identifying specificity groups in the T cell receptor repertoire</article-title>. <source>Nature</source>, <volume>547</volume>, <fpage>94</fpage>–<lpage>98</lpage>.<pub-id pub-id-type="pmid">28636589</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gligorijević</surname><given-names>V.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Structure-based protein function prediction using graph convolutional networks</article-title>. <source>Nat. Commun</source>., <volume>12</volume>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">33397941</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grechishnikova</surname><given-names>D.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Transformer neural network for protein-specific de novo drug generation as a machine translation problem</article-title>. <source>Sci. Rep</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Izmailov</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) Averaging weights leads to wider optima and better generalization. In: <italic toggle="yes">34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018</italic>. Association For Uncertainty in Artificial Intelligence (AUAI), Monterey, CA, USA, pp. <fpage>876</fpage>–<lpage>885</lpage>.</mixed-citation>
    </ref>
    <ref id="btac788-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jokinen</surname><given-names>E.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>. <source>PLoS Comput. Biol</source>., <volume>17</volume>, <fpage>e1008814</fpage>.<pub-id pub-id-type="pmid">33764977</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liao</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Single-cell landscape of bronchoalveolar immune cells in patients with COVID-19</article-title>. <source>Nat. Med</source>., <volume>26</volume>, <fpage>842</fpage>–<lpage>844</lpage>.<pub-id pub-id-type="pmid">32398875</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moss</surname><given-names>P.</given-names></string-name></person-group> (<year>2022</year>) <article-title>The T cell immune response against SARS-CoV-2</article-title>. <source>Nat. Immunol</source>., <volume>23</volume>, <fpage>186</fpage>–<lpage>193</lpage>.<pub-id pub-id-type="pmid">35105982</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Nambiar</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Transforming the language of life: transformer neural networks for protein prediction tasks. In: <italic toggle="yes">Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics</italic>. Association for Computing Machinery, New York, NY, USA. pp. <fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btac788-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Nolan</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) A large-scale database of T-cell receptor beta (TCR<italic toggle="yes">β</italic>) sequences and binding associations from natural and synthetic exposure to SARS-CoV-2. <italic toggle="yes">Research square</italic>. <pub-id pub-id-type="doi">10.21203/rs.3.rs-51964/v1</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac788-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qi</surname><given-names>Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Diversity and clonal selection in the human T-cell repertoire</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>111</volume>, <fpage>13139</fpage>–<lpage>13144</lpage>.<pub-id pub-id-type="pmid">25157137</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sidhom</surname><given-names>J.-W.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>DeepTCR is a deep learning framework for revealing sequence concepts within T-cell repertoires</article-title>. <source>Nat. Commun</source>., <volume>12</volume>, <fpage>1</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">33397941</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Snyder</surname><given-names>T.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Magnitude and dynamics of the T-cell response to SARS-CoV-2 infection at both individual and population levels. <italic toggle="yes">MedRxiv</italic>. <pub-id pub-id-type="doi">10.1101/2020.07.31.20165647</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac788-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Springer</surname><given-names>I.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Contribution of T cell receptor alpha and beta CDR3, MHC typing, V and J genes to peptide binding prediction</article-title>. <source>Front. Immunol</source>., <volume>12</volume>, <fpage>664514</fpage>.<pub-id pub-id-type="pmid">33981311</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tong</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>SETE: sequence-based ensemble learning approach for TCR epitope binding prediction</article-title>. <source>Comput. Biol. Chem</source>., <volume>87</volume>, <fpage>107281</fpage>.<pub-id pub-id-type="pmid">32623023</pub-id></mixed-citation>
    </ref>
    <ref id="btac788-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vig</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Bertology meets biology: Interpreting attention in protein language models. <italic toggle="yes">arXiv</italic>. <pub-id pub-id-type="doi">10.48550/arXiv.2006.15222</pub-id>.</mixed-citation>
    </ref>
  </ref-list>
</back>
