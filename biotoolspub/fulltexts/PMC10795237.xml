<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10795237</article-id>
    <article-id pub-id-type="pmid">38233745</article-id>
    <article-id pub-id-type="publisher-id">5649</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-024-05649-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MSCAN: multi-scale self- and cross-attention network for RNA methylation site prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Honglei</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Dong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zeng</surname>
          <given-names>Wenliang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Sun</surname>
          <given-names>Yanjing</given-names>
        </name>
        <address>
          <email>yjsun@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhang</surname>
          <given-names>Lin</given-names>
        </name>
        <address>
          <email>lin.zhang@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01xt2dr21</institution-id><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>School of Information and Control Engineering, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01xt2dr21</institution-id><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>School of Computer Science and Technology, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff3"><label>3</label>School of Information Engineering, Xuzhou College of Industrial Technology, Xuzhou, 221400 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <elocation-id>32</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Epi-transcriptome regulation through post-transcriptional RNA modifications is essential for all RNA types. Precise recognition of RNA modifications is critical for understanding their functions and regulatory mechanisms. However, wet experimental methods are often costly and time-consuming, limiting their wide range of applications. Therefore, recent research has focused on developing computational methods, particularly deep learning (DL). Bidirectional long short-term memory (BiLSTM), convolutional neural network (CNN), and the transformer have demonstrated achievements in modification site prediction. However, BiLSTM cannot achieve parallel computation, leading to a long training time, CNN cannot learn the dependencies of the long distance of the sequence, and the Transformer lacks information interaction with sequences at different scales. This insight underscores the necessity for continued research and development in natural language processing (NLP) and DL to devise an enhanced prediction framework that can effectively address the challenges presented.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">This study presents a multi-scale self- and cross-attention network (MSCAN) to identify the RNA methylation site using an NLP and DL way. Experiment results on twelve RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um) reveal that the area under the receiver operating characteristic of MSCAN obtains respectively 98.34%, 85.41%, 97.29%, 96.74%, 99.04%, 79.94%, 76.22%, 65.69%, 92.92%, 92.03%, 95.77%, 89.66%, which is better than the state-of-the-art prediction model. This indicates that the model has strong generalization capabilities. Furthermore, MSCAN reveals a strong association among different types of RNA modifications from an experimental perspective. A user-friendly web server for predicting twelve widely occurring human RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um) is available at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">A predictor framework has been developed through binary classification to predict RNA methylation sites.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>RNA methylation</kwd>
      <kwd>Transformer</kwd>
      <kwd>Predictor</kwd>
      <kwd>Multi-scale</kwd>
      <kwd>Self-attention</kwd>
      <kwd>Cross-attention</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the National Natural Science Foundation of China</institution>
        </funding-source>
        <award-id>31871337</award-id>
        <award-id>31871337</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Tao</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>Wenliang</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the "333 Project" of Jiangsu</institution>
        </funding-source>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Dong</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Yanjing</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec2">
    <title>Background</title>
    <p id="Par36">RNA modification plays a fundamental role in regulating RNA function [<xref ref-type="bibr" rid="CR1">1</xref>] and has become a hotspot in epigenetics research [<xref ref-type="bibr" rid="CR2">2</xref>]. Nearly 200 RNA modifications have been discovered, most of which are methylation modifications [<xref ref-type="bibr" rid="CR3">3</xref>]. Common RNA methylation types include N<sup>1</sup>-methyladenosine (m<sup>1</sup>A), N<sup>2</sup>-methylguanosine (m<sup>2</sup>G), 5-methylcytosine (m<sup>5</sup>C), 5-methyluridine (m<sup>5</sup>U), 2′-<italic>O</italic>-methyladensine (Am), 2′-<italic>O</italic>-methylcytidine (Cm), 2′-<italic>O</italic>-methylguanosine (Gm), 2′-<italic>O</italic>-methyluridine (Um), Pseudouridine (Ψ), N<sup>6</sup>-methyladenosine(m<sup>6</sup>A), N<sup>7</sup>-methylguanine (m<sup>7</sup>G), inosine (I), and N6,2′-<italic>O</italic>-dimethyladenosine(m<sup>6</sup>Am), etc. Among them, m<sup>6</sup>A refers to methylation modification occurring at the nitrogen atom in position 6 of the RNA molecule adenine, which is the most abundant mRNA methylation, and is known to affect mRNA stability, splicing, and translation. In addition to m<sup>6</sup>A, m<sup>1</sup>A RNA methylation is a recently discovered one, which is evolutionarily conserved and ubiquitous in humans, rodents, and yeast. It can significantly enhance the protein translation of transcripts [<xref ref-type="bibr" rid="CR4">4</xref>], block the Watson–Crick interface, and is essential for tRNA stability [<xref ref-type="bibr" rid="CR5">5</xref>].</p>
    <p id="Par37">In the last decade, dozens of experimental methods have been developed to identify the precise location of methylation sites on RNA, such as miCLIP [<xref ref-type="bibr" rid="CR6">6</xref>], m<sup>1</sup>A-seq [<xref ref-type="bibr" rid="CR7">7</xref>], PA-m6A-seq [<xref ref-type="bibr" rid="CR8">8</xref>], m<sup>1</sup>A-ID-seq [<xref ref-type="bibr" rid="CR9">9</xref>], m5C-RIP [<xref ref-type="bibr" rid="CR10">10</xref>], m<sup>1</sup>A-MAP [<xref ref-type="bibr" rid="CR11">11</xref>], and m<sup>1</sup>A-IP-seq [<xref ref-type="bibr" rid="CR12">12</xref>]. Despite their effectiveness, these experimental techniques are usually both time-consuming and costly, limiting their use in different biological contexts [<xref ref-type="bibr" rid="CR4">4</xref>], and making them inadequate for large-scale genomic data [<xref ref-type="bibr" rid="CR13">13</xref>]. Consequently, there is strong motivation to explore computational methods that can accurately and efficiently identify methylation sites based on sequence information alone.</p>
    <p id="Par38">As there are more vailable base-resolution datasets, researchers have designed some computational methods for RNA modification site prediction. These approaches formulate RNA methylation identification as a binary prediction task, and some machine learning models are trained to distinguish between truly methylated and non-methylated sites. These computational methods have been powerful additions for RNA methylation site prediction.</p>
    <p id="Par39">Traditional methods designed for sequence-based prediction usually first extract features based on human-understandable feature methods and then use a classifier to identify if the site is methylated based on the preceding extracted features. Specifically, RAMPred [<xref ref-type="bibr" rid="CR14">14</xref>] adopts the support vector machine(SVM) to predict the m<sup>1</sup>A modification site, extracting features based on nucleotide composition(NC) and nucleotide chemical properties(NCP). iRNA-3typeA [<xref ref-type="bibr" rid="CR15">15</xref>] adopts SVM to predict m<sup>1</sup>A, A-to-I, and m<sup>6</sup>A modification sites, which extracts features based on accumulated nucleotide frequency(ANF) and NCP. iMRM [<xref ref-type="bibr" rid="CR16">16</xref>] extracts features based on NCP, NC, Nucleotide Density(ND), Dinucleotide physicochemical properties(DPCP), and Dinucleotide Binary Encoding(DBE) and employs XGboost to predict m<sup>1</sup>A, m<sup>6</sup>A, m<sup>5</sup>C, ψ, and A-to-I modification sites. The above sequence features are artificially extracted, and inevitably important features of the sequences are missed due to human cognitive limitations.</p>
    <p id="Par40">Analyzing biological sequences and interpreting biological information are the key challenges in achieving biological discovery. The application of natural language processing(NLP) to sequence analysis has attracted considerable attention in processing biological sequences [<xref ref-type="bibr" rid="CR17">17</xref>]. As biological sequences can be considered sentences, and k-mer subsequences are regarded as words [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>], NLP can be used to understand the structure and function encoded in these sequences [<xref ref-type="bibr" rid="CR17">17</xref>]. Unlike traditional machine learning, deep learning (DL) methods follow an end-to-end design. Features are extracted directly based on the input sequence and the final labeling/prediction task. For example, EDLm6Apred [<xref ref-type="bibr" rid="CR20">20</xref>] employs bidirectional long short-term memory (BiLSTM) to predict m<sup>6</sup>A sites, extracting features based on Word2vec, RNA word embedding [<xref ref-type="bibr" rid="CR21">21</xref>], and one-hot encoding [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. However, LSTM, BiLSTM, and RNN cannot achieve parallel computation, leading to a long training time.</p>
    <p id="Par41">CNN can achieve parallel computation and learn local dependencies. For instance, m6A-word2vec [<xref ref-type="bibr" rid="CR24">24</xref>] adopts CNN to identify m<sup>6</sup>A sites, extracting features based on Word2vec. Deeppromise [<xref ref-type="bibr" rid="CR25">25</xref>] employs CNN to identify m<sup>1</sup>A and m<sup>6</sup>A sites, extracting features based on integrated enhanced nucleic acid composition (ENAC) [<xref ref-type="bibr" rid="CR26">26</xref>], one-hot encoding, and RNA word embedding. However, These CNN structures only consider the contextual relationships of neighboring bases without considering the dependencies over long distances in the sequence. DeepM6ASeq [<xref ref-type="bibr" rid="CR27">27</xref>] combines the advantages of CNN and BiLSTM by using two layers of CNN and one layer of BiLSTM to predict m<sup>6</sup>A sites. This approach may extract redundant features that interfere with prediction performance [<xref ref-type="bibr" rid="CR28">28</xref>]. The attention mechanism can quantify the degree of code-to-code dependency [<xref ref-type="bibr" rid="CR29">29</xref>]. Therefore, the application of the attention mechanism can capture the focused codes that affect the classification results. Plant6mA [<xref ref-type="bibr" rid="CR30">30</xref>] utilizes a Transformer encoder to determine whether the input sequence contains an m6A site. However, due to the unique feature representation of transformers, these networks are primarily employed at a single scale. Although a single-scale self-attentive mechanism can focus on essential features of sequence context, it lacks information interaction with sequences at different scales. It isn't easy to learn complex word context relationships.</p>
    <p id="Par42">At present, most prediction model studies focus only on a single methylation modification, and few share the same binary classification model framework to achieve different methylation modification predictions. Even fewer cross-modification validation studies have been performed with different methylation test sets and trained models. Accounting for potential interactions between various RNA modifications, it would be interesting to use the same model to conduct cross-modification validation studies across different methylation test sets.</p>
    <p id="Par43">We present the Multi-scale Self- and Cross-attention Network (MSCAN), a novel approach designed to identify RNA methylation sites, addressing the challenges associated with current methods. Our model supports identifying twelve RNA modification types, including m<sup>6</sup>A, Ψ, m<sup>1</sup>A, m<sup>6</sup>Am, Am, Cm, m<sup>7</sup>G, Gm, Um, I, m<sup>5</sup>U, and m<sup>5</sup>C.</p>
    <p id="Par44">The MSCAN employs a unique multi-scale approach for analyzing RNA sequences. Specifically, we extracted the input 41-nucleotides (nt) sample sequence into multiple smaller subsequences centered around the sequence midpoint. To ensure accurate identification of methylation sites, the MSCAN analyzes these smaller subsequences at two distinct scales: 21-nt and 31-nt. This multi-scale analysis allows for a more comprehensive understanding of the RNA sequence context, ultimately leading to improved prediction performance. Secondly, word2vec was used to encode the three sets of sequences. Third, the three sets of sequences add positional information due to the correlation between nucleotide positions in the sequence. Four, the three sets of sequences were fed into the encoding module, which was constructed with a multi-scale self- and cross-attention network and a feed-forward network(FFN) to extract potential contributing features for methylation site prediction. Finally, methylation predicted probabilities were obtained through a linear layer and the sigmoid function. The findings demonstrated that the MSCAN model surpassed the performance of state-of-the-art methods, including m6A-word2vec, DeepM6ASeq, and Plant6mA in independent tests. A user-friendly web server for MSCAN is available at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
  </sec>
  <sec id="Sec3">
    <title>Result</title>
    <sec id="Sec4">
      <title>Evaluation metrics</title>
      <p id="Par45">In this study, we used eight common classification indicators to evaluate the prediction of the model, including Accuracy (Acc), Sensitivity (Sen), Precision (Pre), Matthews correlation coefficient (MCC), Specificity (Sp), and F1 score (F1). The formulas of these metrics are as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sensitivity,\;Recall = \frac{TP}{{TP + FN}}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.277778em"/><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Specificity = \frac{TN}{{TN + FP}}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Accuracy = \frac{TP + TN}{{TP + TN + FP + FN}}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Precision = \frac{TP}{{TP + FP}}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1 \, score = 2 \times \frac{Precision \times Recall}{{Precision + Recall}}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mspace width="0.166667em"/><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MCC = \frac{TP \times TN - FP \times FN}{{\sqrt {(TP + FP) \times (TP + FN) \times (TN + FP) \times (TN + FN)} }}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par46">Here, the true positive, true negative, false positive, and false negative are represented as TP, TN, FP, and FN, respectively. Moreover, the area under the receiver operating characteristic (AUROC) and the area under the precision-recall curve (AUPRC) are used to visually evaluate the model's overall performance.</p>
    </sec>
    <sec id="Sec5">
      <title>Results analysis</title>
      <p id="Par47">MSCAN completed model training and experimental parameter optimization based on the dataset of Chen et al. [<xref ref-type="bibr" rid="CR25">25</xref>]. Subsequently, MSCAN completed the model's generalization ability evaluation based on the dataset of Song et al. [<xref ref-type="bibr" rid="CR5">5</xref>]. Specifically, based on the dataset of Chen et al., this paper first compared the performance of MSCAN with different combinations of input sequences on the training data. Second, the performance of MSCAN with different feature encoding was compared. Third, we compared the performance of different MSCAN model variants. Fourth, the MSCAN was compared with state-of-the-art models based on the training data and the independent dataset of Chen et al. Fifth, the statistical significance of AUPRC values between the four models is compared. Sixth, MSCAN completed a generalization ability evaluation based on the dataset of Song et al., and MSCAN outperformed the state-of-the-art predictors for twelve modification sites. Finally, We designed a cross-modification validation experiment in which twelve models with different methylation types were compared for prediction performance based on twelve test sets, respectively. Our experiments were conducted with two Intel(R) 5218 CPUs, two RTX2080Ti GPUs, and Pytorch version 1.4.0+cu92.</p>
      <p id="Par48">Based on the training data of Chen et al., we first tried optimizing the input sequences' length according to AUPRC on the training data. Using the Word2vec embedding, we evaluated the Transformer model with 11-nt, 21-nt, 31-nt, 41-nt,51-nt,61-nt,71-nt,81-nt,91-nt,and 101-nt RNA sequences as the input on the five-fold cross-validation [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR25">25</xref>]. As shown in Table <xref rid="Tab1" ref-type="table">1</xref>, the input of the 11-nt sequence obtained the worst performance. The reason may be that too few bases in the 11-nt sequence affect feature extraction. The input of the 41-bp sequence obtained the best average performance of all the modifications, It may be worth mentioning that the 41-nt of the input sequence is also optimal for the XGboost and SVM method [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], so we choose 21-nt, 31-nt, and 41-nt RNA sequences as input sequences to achieve different combinations of input sequences.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Evaluation results of five-fold cross-validation of transformer based on the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Length(nt)</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">11</td><td char="." align="char">0.8955</td><td char="." align="char">93.55</td><td char="." align="char">44.26</td><td char="." align="char"><bold>77.14</bold></td><td char="." align="char">55.44</td><td char="." align="char"><bold>98.65</bold></td><td char="." align="char">56.25</td><td char="." align="char">0.6389</td></tr><tr><td align="left">21</td><td char="." align="char">0.9213</td><td char="." align="char"><bold>95.01</bold></td><td char="." align="char">59.81</td><td char="." align="char">74.42</td><td char="." align="char">64.11</td><td char="." align="char">98.16</td><td char="." align="char">66.32</td><td char="." align="char">0.7189</td></tr><tr><td align="left">31</td><td char="." align="char">0.9361</td><td char="." align="char">93.55</td><td char="." align="char">64.80</td><td char="." align="char">66.94</td><td char="." align="char">62.31</td><td char="." align="char">96.61</td><td char="." align="char">65.85</td><td char="." align="char">0.7390</td></tr><tr><td align="left">41</td><td char="." align="char"><bold>0.9484</bold></td><td char="." align="char">93.48</td><td char="." align="char"><bold>74.36</bold></td><td char="." align="char">61.27</td><td char="." align="char">63.97</td><td char="." align="char">95.37</td><td char="." align="char">67.18</td><td char="." align="char"><bold>0.7469</bold></td></tr><tr><td align="left">51</td><td char="." align="char">0.9401</td><td char="." align="char">94.63</td><td char="." align="char">61.54</td><td char="." align="char">74.23</td><td char="." align="char">64.73</td><td char="." align="char">97.89</td><td char="." align="char">67.29</td><td char="." align="char">0.7401</td></tr><tr><td align="left">61</td><td char="." align="char">0.9430</td><td char="." align="char">94.56</td><td char="." align="char">67.27</td><td char="." align="char">67.89</td><td char="." align="char">64.61</td><td char="." align="char">97.07</td><td char="." align="char">67.58</td><td char="." align="char">0.7078</td></tr><tr><td align="left">71</td><td char="." align="char">0.9249</td><td char="." align="char">93.64</td><td char="." align="char">67.21</td><td char="." align="char">65.60</td><td char="." align="char">62.89</td><td char="." align="char">96.36</td><td char="." align="char">66.40</td><td char="." align="char">0.7272</td></tr><tr><td align="left">81</td><td char="." align="char">0.9440</td><td char="." align="char">94.94</td><td char="." align="char">70.00</td><td char="." align="char">66.04</td><td char="." align="char"><bold>65.25</bold></td><td char="." align="char">97.01</td><td char="." align="char"><bold>67.96</bold></td><td char="." align="char">0.7170</td></tr><tr><td align="left">91</td><td char="." align="char">0.9327</td><td char="." align="char">94.93</td><td char="." align="char">60.19</td><td char="." align="char">73.86</td><td char="." align="char">64.01</td><td char="." align="char">98.08</td><td char="." align="char">66.33</td><td char="." align="char">0.7119</td></tr><tr><td align="left">101</td><td char="." align="char">0.9230</td><td char="." align="char">93.33</td><td char="." align="char">70.94</td><td char="." align="char">61.03</td><td char="." align="char">62.16</td><td char="." align="char">95.53</td><td char="." align="char">65.61</td><td char="." align="char">0.7449</td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par49">The combination of input sequences with different scale order is an important parameter that affects the performance of the training model. The performance of the MSCAN model with the different combinations of input sequences on the training data is shown in Table <xref rid="Tab2" ref-type="table">2</xref>. MSCAN shows the best prediction performance when the combination is “21-nt + 41-nt + 31-nt”. According to the MSCAN model design, “21-nt + 41-nt + 31-nt” input sequences are entered into the model to implement three attention mechanisms, including the self-attention calculation mechanism for the 21-nt sequence, and the cross-attention calculation mechanisms for both “21-nt + 41-nt” and “21-nt + 31-nt” combinatorial sequences.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Evaluation results of MSCAN on five-fold cross-validation with different input sequences based on the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">combinations of sequences(nt)</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">21 + 31 + 41</td><td char="." align="char">0.9491</td><td char="." align="char"><bold>95.24</bold></td><td char="." align="char">58.59</td><td char="." align="char">73.42</td><td char="." align="char">63.11</td><td char="." align="char">98.26</td><td char="." align="char">65.17</td><td char="." align="char">0.7695</td></tr><tr><td align="left">21 + 41 + 31</td><td char="." align="char"><bold>0.9618</bold></td><td char="." align="char">94.86</td><td char="." align="char">59.69</td><td char="." align="char"><bold>83.70</bold></td><td char="." align="char"><bold>68.11</bold></td><td char="." align="char"><bold>98.72</bold></td><td char="." align="char">69.68</td><td char="." align="char"><bold>0.7949</bold></td></tr><tr><td align="left">31 + 21 + 41</td><td char="." align="char">0.9257</td><td char="." align="char">94.63</td><td char="." align="char">55.93</td><td char="." align="char">78.57</td><td char="." align="char">63.59</td><td char="." align="char">98.48</td><td char="." align="char">65.34</td><td char="." align="char">0.7419</td></tr><tr><td align="left">31 + 41 + 21</td><td char="." align="char">0.9463</td><td char="." align="char">95.09</td><td char="." align="char"><bold>68.47</bold></td><td char="." align="char">72.38</td><td char="." align="char">67.73</td><td char="." align="char">97.57</td><td char="." align="char"><bold>70.37</bold></td><td char="." align="char">0.7632</td></tr><tr><td align="left">41 + 21 + 31</td><td char="." align="char">0.9318</td><td char="." align="char">94.55</td><td char="." align="char">63.87</td><td char="." align="char">73.08</td><td char="." align="char">65.38</td><td char="." align="char">97.64</td><td char="." align="char">68.17</td><td char="." align="char">0.7617</td></tr><tr><td align="left">41 + 31 + 21</td><td char="." align="char">0.9427</td><td char="." align="char">93.86</td><td char="." align="char">65.41</td><td char="." align="char">71.90</td><td char="." align="char">65.20</td><td char="." align="char">97.10</td><td char="." align="char">68.50</td><td char="." align="char">0.7642</td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec6">
      <title>Comparison analysis of different feature encoding methods</title>
      <p id="Par50">In this section, we evaluate the performance of three distinct feature encoding methods—Word2vec, One-hot, and ENAC—utilizing the same MSCAN model for predicting m<sup>1</sup>A sites on the test data of Chen et al. The outcomes of this comparison are presented in Fig. <xref rid="Fig1" ref-type="fig">1</xref> and Table <xref rid="Tab3" ref-type="table">3</xref>, demonstrating that Word2vec consistently surpasses the other two encoding methods across all performance indices.<fig id="Fig1"><label>Fig. 1</label><caption><p>Performance of the MSCAN model based on the different feature encoding</p></caption><graphic xlink:href="12859_2024_5649_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>MSCAN model evaluation results with different feature encodings based on the test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Encoding</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">One-hot</td><td char="." align="char">0.9089</td><td char="." align="char">95.13</td><td char="." align="char">55.26</td><td char="." align="char">86.30</td><td char="." align="char">66.77</td><td char="." align="char">99.12</td><td char="." align="char">67.38</td><td char="." align="char">0.7294</td></tr><tr><td align="left">ENAC</td><td char="." align="char">0.9212</td><td char="." align="char">94.81</td><td char="." align="char">55.26</td><td char="." align="char">81.82</td><td char="." align="char">64.71</td><td char="." align="char">98.77</td><td char="." align="char">65.97</td><td char="." align="char">0.7322</td></tr><tr><td align="left">Word2vec</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char"><bold>58.77</bold></td><td char="." align="char"><bold>90.54</bold></td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char"><bold>99.39</bold></td><td char="." align="char"><bold>71.28</bold></td><td char="." align="char"><bold>0.7890</bold></td></tr></tbody></table><table-wrap-foot><p>Bold Indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par51">The superior performance of Word2vec can be attributed to the limitations of the One-hot and ENAC encoding methods. While One-hot encoding focuses on the local information of individual bases, and ENAC encoding considers both nucleic acid composition and position information, both methods neglect the semantic information inherent in the sequence context. In contrast, Word2vec prioritizes the contextual relationships between bases, resulting in a more effective representation of the sequence.</p>
      <p id="Par52">Our findings highlight the importance of selecting appropriate feature encoding methods for improved prediction accuracy, with Word2vec emerging as a particularly advantageous choice for the MSCAN model in the context of RNA methylation site prediction.</p>
    </sec>
    <sec id="Sec7">
      <title>Comparison with different variants of the MSCAN model</title>
      <p id="Par53">We conducted ablation experiments to assess the contribution of key components within our proposed MSCAN model based on the test data of Chen et al. Utilizing Word2vec for RNA sequence encoding, we constructed four sub-networks: self- and cross-attention network (SCAN), self-attention network (SAN), multi-scale cross-attention network (MCAN), and cross-attention network (CAN). SCAN represents MSCAN with one cross-attention module removed, SAN is SCAN devoid of cross-attention, MCAN is MSCAN without self-attention, and CAN is MCAN with one cross-attention module removed. The outcomes of these experiments are depicted in Fig. <xref rid="Fig2" ref-type="fig">2</xref> and summarized in Table <xref rid="Tab4" ref-type="table">4</xref>.<fig id="Fig2"><label>Fig. 2</label><caption><p>Performance of MSCAN and variant model on the test data</p></caption><graphic xlink:href="12859_2024_5649_Fig2_HTML" id="MO2"/></fig><table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparing MSCAN and variant model evaluation results based on test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">SAN</td><td char="." align="char">0.9321</td><td char="." align="char">95.05</td><td char="." align="char">55.26</td><td char="." align="char">85.14</td><td char="." align="char">66.24</td><td char="." align="char">99.04</td><td char="." align="char">67.02</td><td char="." align="char">0.7604</td></tr><tr><td align="left">SCAN</td><td char="." align="char">0.9277</td><td char="." align="char">95.29</td><td char="." align="char">53.51</td><td char="." align="char"><bold>91.04</bold></td><td char="." align="char">67.73</td><td char="." align="char"><bold>99.47</bold></td><td char="." align="char">67.40</td><td char="." align="char">0.7613</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char"><bold>58.77</bold></td><td char="." align="char">90.54</td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char">99.39</td><td char="." align="char"><bold>71.28</bold></td><td char="." align="char"><bold>0.7890</bold></td></tr><tr><td align="left">CAN</td><td char="." align="char">0.9299</td><td char="." align="char">94.89</td><td char="." align="char">52.63</td><td char="." align="char">85.71</td><td char="." align="char">64.81</td><td char="." align="char">99.12</td><td char="." align="char">65.21</td><td char="." align="char">0.7688</td></tr><tr><td align="left">MCAN</td><td char="." align="char">0.9270</td><td char="." align="char">94.81</td><td char="." align="char">55.26</td><td char="." align="char">81.82</td><td char="." align="char">64.71</td><td char="." align="char">98.77</td><td char="." align="char">65.97</td><td char="." align="char">0.7586</td></tr></tbody></table><table-wrap-foot><p>Bold Indicates the best performance</p><p>SAN contains only self-attention; SCAN, and MSCAN are combinations of self- and cross-attention; CAN and MCAN are combinations of only cross-attention</p></table-wrap-foot></table-wrap></p>
      <p id="Par54">SAN serves as the baseline model in this comparison. Upon the integration of cross-attention modules, the area under the precision-recall curve (AUPRC) for SCAN and MSCAN models increased by 0.09% and 2.86%, respectively. These results highlight the importance of incorporating cross-attention mechanisms within the MSCAN model for improved performance in predicting RNA methylation sites. Consequently, our findings emphasize the value of the multi-scale self- and cross-attention approach employed by MSCAN in advancing the understanding of RNA modifications and their functional implications.</p>
    </sec>
    <sec id="Sec8">
      <title>Comparison with state-of-the-art approaches</title>
      <p id="Par55">We compared MSCAN with several state-of-the-art models, including m6A-word2vec, DeepM6ASeq, and Plant6mA. To ensure robust evaluation, we employed a fivefold cross-validation on the training data of Chen et al. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref> and Table <xref rid="Tab5" ref-type="table">5</xref>, Our results demonstrate that MSCAN outperforms the other models, substantially improving prediction accuracy.<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance of the different models on the training data</p></caption><graphic xlink:href="12859_2024_5649_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab5"><label>Table 5</label><caption><p>Evaluation results of MSCAN and other state-of-the-art models based on five-fold cross-validation using the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9001</td><td char="." align="char">93.30</td><td char="." align="char">53.79</td><td char="." align="char">66.18</td><td char="." align="char">56.10</td><td char="." align="char">97.25</td><td char="." align="char">59.35</td><td char="." align="char">0.6505</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.8735</td><td char="." align="char">93.38</td><td char="." align="char">46.49</td><td char="." align="char">70.67</td><td char="." align="char">54.02</td><td char="." align="char">98.07</td><td char="." align="char">56.08</td><td char="." align="char">0.6279</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.9482</td><td char="." align="char">93.48</td><td char="." align="char"><bold>74.36</bold></td><td char="." align="char">61.27</td><td char="." align="char">63.97</td><td char="." align="char">95.37</td><td char="." align="char">67.18</td><td char="." align="char">0.7465</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9618</bold></td><td char="." align="char"><bold>94.86</bold></td><td char="." align="char">59.69</td><td char="." align="char"><bold>83.70</bold></td><td char="." align="char"><bold>68.11</bold></td><td char="." align="char"><bold>98.72</bold></td><td char="." align="char"><bold>69.68</bold></td><td char="." align="char"><bold>0.7949</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par56">In particular, MSCAN achieves a 4.84% enhancement in the AUPRC metric compared to the second-best performing model, Plant6mA. This superior performance can be attributed to utilizing the multi-scale self- and cross-attention mechanisms in MSCAN, as opposed to the self-attention mechanism employed by Plant6mA. The results underscore the effectiveness of MSCAN in identifying RNA methylation sites.</p>
      <p id="Par57">Next, we compare the performance of MSCAN with other state-of-the-art models using the test data of Chen et al. The results, as illustrated in Fig. <xref rid="Fig4" ref-type="fig">4</xref> and summarized in Table <xref rid="Tab6" ref-type="table">6</xref>, demonstrate the superior performance of MSCAN in predicting RNA methylation sites.<fig id="Fig4"><label>Fig. 4</label><caption><p>The ROC and PRC of MSCAN and other state-of-the-art models on the test data</p></caption><graphic xlink:href="12859_2024_5649_Fig4_HTML" id="MO4"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption><p>Evaluation results of MSCAN and other state-of-the-art models based on the test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9327</td><td char="." align="char">93.62</td><td char="." align="char"><bold>67.54</bold></td><td char="." align="char">64.17</td><td char="." align="char">62.32</td><td char="." align="char">90.43</td><td char="." align="char">65.81</td><td char="." align="char">0.7650</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.9257</td><td char="." align="char">95.37</td><td char="." align="char">65.79</td><td char="." align="char">79.79</td><td char="." align="char">70.00</td><td char="." align="char">98.33</td><td char="." align="char"><bold>72.12</bold></td><td char="." align="char">0.7743</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.9298</td><td char="." align="char">95.13</td><td char="." align="char">56.14</td><td char="." align="char">85.33</td><td char="." align="char">66.89</td><td char="." align="char">99.04</td><td char="." align="char">67.72</td><td char="." align="char">0.7676</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char">58.77</td><td char="." align="char"><bold>90.54</bold></td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char"><bold>99.39</bold></td><td char="." align="char">71.28</td><td char="." align="char"><bold>0.7890</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par58">MSCAN outperforms DeepM6ASeq and m6A-word2vec by 1.47% and 2.4% in terms of AUPRC, respectively. This enhanced performance can be attributed to the multi-scale self- and cross-attention network's ability to capture meaningful sequence encodings for more accurate classification. Furthermore, MSCAN surpasses Plant6mA by 2.14% in AUPRC, which may further verify the limitations of the single-scale self-attention mechanism in learning complex contextual relationships between sequence elements. The integration of the cross-attention mechanism enables the model to discern deeper sequence meanings, thus improving its performance.</p>
    </sec>
    <sec id="Sec9">
      <title>Assessing model reliability</title>
      <p id="Par59">To evaluate the reliability of our proposed model, we performed one hundred replications of experiments using the test data from Chen et al., evaluating the m6A-word2vec, DeepM6ASeq, Plant6mA, and MSCAN models. In each replication, we used the same test data and ran each model under identical conditions to ensure experimental consistency.</p>
      <p id="Par60">To evaluate the statistical significance of AUPRC values between different methods, we employed Student's t-test [<xref ref-type="bibr" rid="CR31">31</xref>]. This statistical method helps determine whether performance differences between different methods are significant. Table <xref rid="Tab7" ref-type="table">7</xref> below shows the <italic>p</italic> values for the difference in the performance of the four classifiers.
<table-wrap id="Tab7"><label>Table 7</label><caption><p>A statistically significant correlation matrix for the difference in the performance of the four classifiers</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Classifiers</th><th align="left" colspan="4">Classifiers</th></tr><tr><th align="left">m6A-word2vec</th><th align="left">DeepM6ASeq</th><th align="left">Plant6mA</th><th align="left">MSCAN</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">DeepM6ASeq</td><td align="left">0.001243</td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">Plant6mA</td><td align="left">2.905E−44</td><td align="left">8.01217E−35</td><td align="left"/><td align="left"/></tr><tr><td align="left">MSCAN</td><td align="left">4.71415E−64</td><td align="left">1.25245E−58</td><td align="left">0</td><td align="left"/></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec10">
      <title>Assessing model generalization ability</title>
      <p id="Par61">Based on the data set of Song et al., the generalization ability of MSCAN was evaluated by training the model individually for each methylation type. As presented in Table <xref rid="Tab8" ref-type="table">8</xref>, the MSCAN model consistently outperforms state-of-the-art models, including m6A-word2vec, DeepM6ASeq, and Plant6mA. This result provides empirical evidence of the model's generalizability across diverse methylation site prediction tasks.
<table-wrap id="Tab8"><label>Table 8</label><caption><p>Compare MSCAN to other methods under AUC</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">m<sup>6</sup>A</th><th align="left">Ψ</th><th align="left">m<sup>1</sup>A</th><th align="left">m<sup>6</sup>Am</th><th align="left">Am</th><th align="left">Cm</th><th align="left">Gm</th><th align="left">Um</th><th align="left">m<sup>5</sup>C</th><th align="left">m<sup>7</sup>G</th><th align="left">m<sup>5</sup>U</th><th align="left">I</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9773</td><td char="." align="char">0.7060</td><td char="." align="char">0.8385</td><td char="." align="char">0.9867</td><td char="." align="char">0.9174</td><td char="." align="char">0.9120</td><td char="." align="char">0.9554</td><td char="." align="char">0.8467</td><td char="." align="char">0.9611</td><td char="." align="char">0.7505</td><td char="." align="char">0.9499</td><td char="." align="char">0.6180</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.9752</td><td char="." align="char">0.7510</td><td char="." align="char">0.8289</td><td char="." align="char">0.9837</td><td char="." align="char">0.9213</td><td char="." align="char">0.9173</td><td char="." align="char">0.9538</td><td char="." align="char">0.8716</td><td char="." align="char">0.9675</td><td char="." align="char">0.7527</td><td char="." align="char">0.9584</td><td char="." align="char">0.5872</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.5964</td><td char="." align="char">0.5478</td><td char="." align="char">0.7268</td><td char="." align="char">0.7826</td><td char="." align="char">0.8110</td><td char="." align="char">0.8016</td><td char="." align="char">0.8279</td><td char="." align="char">0.7847</td><td char="." align="char">0.6806</td><td char="." align="char">0.6690</td><td char="." align="char">0.9528</td><td char="." align="char">0.5137</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9834</bold></td><td char="." align="char"><bold>0.7622</bold></td><td char="." align="char"><bold>0.8541</bold></td><td char="." align="char"><bold>0.9904</bold></td><td char="." align="char"><bold>0.9292</bold></td><td char="." align="char"><bold>0.9203</bold></td><td char="." align="char"><bold>0.9577</bold></td><td char="." align="char"><bold>0.8966</bold></td><td char="." align="char"><bold>0.9729</bold></td><td char="." align="char"><bold>0.7994</bold></td><td char="." align="char"><bold>0.9674</bold></td><td char="." align="char"><bold>0.6569</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par62">Theoretically, the self- and cross-attention mechanism employed by the MSCAN model enables it to capture long-range dependencies and complex interactions between input features more effectively than other models, such as Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). This characteristic is particularly advantageous in discerning biologically relevant patterns in methylation site prediction, which may contribute to the model's enhanced generalizability.</p>
    </sec>
    <sec id="Sec11">
      <title>Comparison with cross-modification validation approaches</title>
      <p id="Par63">Thus far, our results have demonstrated the model's robust classification performance. Notably, a significant advantage of the proposed MSCAN model is its ability to learn the underlying associations among different RNA modifications. Previous studies have revealed clear evolutionary and functional cross-talk among various post-translational modifications of proteins [<xref ref-type="bibr" rid="CR32">32</xref>] and histone and chromatin modifications [<xref ref-type="bibr" rid="CR33">33</xref>]. Such associations might also exist at the epi-transcriptome level among different RNA modifications.</p>
      <p id="Par64">To better understand the inherent shared structures among different RNA modifications, we performed cross-modification validation on the second dataset. The resulting AUROC values are displayed in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. As the figure shows, cross-modification validation yielded poorer prediction results than those obtained using modification-consistent data and models, indicating the specificity of our method for a particular modification.<fig id="Fig5"><label>Fig. 5</label><caption><p>Heat map of different AUROC values in cross-methylation validation. The horizontal axis is the model type, and the vertical axis is the test data type</p></caption><graphic xlink:href="12859_2024_5649_Fig5_HTML" id="MO5"/></fig></p>
      <p id="Par65">Interestingly, in experiments where the test dataset and model were inconsistent, some groups achieved high AUROC values greater than 0.85, suggesting strong and significant positive associations among certain RNA modifications, even those originating from different nucleotides. This observation implies the existence of regions intensively modified by multiple RNA modifications, which likely serve as key regulatory components for the epi-transcriptome layer of gene regulation. Notably, the sequence signatures of these key regulatory regions are largely shared among different RNA modifications (including those that modify different nucleotides) and were successfully captured by our model. As presented in Table <xref rid="Tab9" ref-type="table">9</xref>, the most strongly associated modifications originated from the same type of base, with A and G belonging to purine-like bases, and C and U belonging to pyrimidine bases.
<table-wrap id="Tab9"><label>Table 9</label><caption><p>Association of RNA modifications revealed by MSCAN</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Model</th><th align="left">AUROC</th><th align="left">AUPRC</th><th align="left">ACC</th><th align="left">Dataset</th><th align="left">Model</th><th align="left">AUROC</th><th align="left">AUPRC</th><th align="left">ACC</th></tr></thead><tbody><tr><td align="left">Am</td><td align="left">Am</td><td char="." align="char">0.9292</td><td char="." align="char">0.9231</td><td char="." align="char">86.36</td><td align="left">Gm</td><td align="left">Gm</td><td char="." align="char">0.9577</td><td char="." align="char">0.9637</td><td char="." align="char">88.33</td></tr><tr><td align="left">Gm</td><td align="left">Am</td><td char="." align="char">0.9082</td><td char="." align="char">0.9233</td><td char="." align="char">81.11</td><td align="left">Am</td><td align="left">Gm</td><td char="." align="char">0.8695</td><td char="." align="char">0.8809</td><td char="." align="char">80.16</td></tr><tr><td align="left">Cm</td><td align="left">Am</td><td char="." align="char">0.8724</td><td char="." align="char">0.8906</td><td char="." align="char">73.51</td><td align="left">Cm</td><td align="left">Gm</td><td char="." align="char">0.8083</td><td char="." align="char">0.8280</td><td char="." align="char">72.18</td></tr><tr><td align="left">Um</td><td align="left">Am</td><td char="." align="char">0.7884</td><td char="." align="char">0.7839</td><td char="." align="char">60.00</td><td align="left">Um</td><td align="left">Gm</td><td char="." align="char">0.7387</td><td char="." align="char">0.7659</td><td char="." align="char">66.34</td></tr><tr><td align="left">Cm</td><td align="left">Cm</td><td char="." align="char">0.9203</td><td char="." align="char">0.9273</td><td char="." align="char">83.44</td><td align="left">Um</td><td align="left">Um</td><td char="." align="char">0.8966</td><td char="." align="char">0.8756</td><td char="." align="char">82.92</td></tr><tr><td align="left">Um</td><td align="left">Cm</td><td char="." align="char">0.8647</td><td char="." align="char">0.8514</td><td char="." align="char">79.75</td><td align="left">Cm</td><td align="left">Um</td><td char="." align="char">0.8859</td><td char="." align="char">0.8739</td><td char="." align="char">81.78</td></tr><tr><td align="left">Am</td><td align="left">Cm</td><td char="." align="char">0.8830</td><td char="." align="char">0.8862</td><td char="." align="char">72.31</td><td align="left">Am</td><td align="left">Um</td><td char="." align="char">0.8458</td><td char="." align="char">0.8282</td><td char="." align="char">78.51</td></tr><tr><td align="left">Gm</td><td align="left">Cm</td><td char="." align="char">0.8865</td><td char="." align="char">0.9070</td><td char="." align="char">69.44</td><td align="left">Gm</td><td align="left">Um</td><td char="." align="char">0.8480</td><td char="." align="char">0.8589</td><td char="." align="char">76.66</td></tr></tbody></table></table-wrap></p>
      <p id="Par66">To further verify this finding, we compared Am, Gm, Cm, and Um correlations through local BLAST [<xref ref-type="bibr" rid="CR34">34</xref>] software. First, the Am, Gm, and Cm comparison libraries are established based on the Am data set, Gm data set, and Cm data set respectively. Secondly, the Am, Gm, Cm, and Um data sets are used to compare the comparison libraries with different methylation in pairs. Then, the BLAST output table is obtained. Finally, compare the average value of the comparison result "bit-score". As shown in Table <xref rid="Tab10" ref-type="table">10</xref>, the average bit-score value of the Gm sequence compared to the Am comparison library is high, indicating that the Am sequence and the Gm sequence are highly similar. Similarly, the average bit-score value of the Um sequence compared to the Cm comparison library is high, indicating that the Um sequence and Cm sequence similarity is high, which may validate the idea that the most closely related modifications originate from the same type of bases.
<table-wrap id="Tab10"><label>Table 10</label><caption><p>Compare the average bit-score of various methylated sequences</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Query subject</th><th align="left">Am</th><th align="left">Gm</th><th align="left">Cm</th><th align="left">Um</th></tr></thead><tbody><tr><td align="left">Am</td><td align="left"/><td char="." align="char">9.679614</td><td char="." align="char">5.866832</td><td char="." align="char">3.30773</td></tr><tr><td align="left">Gm</td><td align="left"/><td char="." align="char"/><td char="." align="char">3.357072</td><td char="." align="char">1.639136</td></tr><tr><td align="left">Cm</td><td align="left"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char">8.793488</td></tr><tr><td align="left">Um</td><td align="left"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char"/></tr></tbody></table></table-wrap></p>
      <p id="Par67">Our model provides experimental verification of the existence of an inherent shared structure between different RNA modifications. These findings underscore the potential of the MSCAN model in advancing our understanding of the complex interplay between various RNA modifications and their functional implications.</p>
    </sec>
    <sec id="Sec12">
      <title>Web server</title>
      <p id="Par68">We have developed a user-friendly web server for predicting twelve widely occurring human RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um), accessible at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>, to facilitate the use of the MSCAN model for RNA methylation site prediction. Take the step of predicting the m<sup>1</sup>A methylation site as an example. First, click the “Prediction” button and select the “m<sup>1</sup>A” successively. Next, type or paste the RNA sequence, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>a. Third, leave your email address in the input box and click the “submit” button. After a calculation period, the prediction results will be displayed in a table, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>b. This intuitive web server offers researchers an efficient and convenient platform for employing the MSCAN model in their investigations of RNA modifications and their functional implications.<fig id="Fig6"><label>Fig. 6</label><caption><p>Webserver interface. a. Input interface. b. Prediction result</p></caption><graphic xlink:href="12859_2024_5649_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Discussion</title>
    <p id="Par69">First, based on the test data of Chen et al., we compared the performance of various features based on the MSCAN model, including One-hot encoding, ENAC, and Word2vec. The results reveal that Word2vec outperforms One-hot and ENAC in predicting AUROC and AUPRC. Specifically, the AUPRC of MSCAN<sub>word2vec</sub> is 5.96% and 5.68% higher than that of MSCAN<sub>One-hot</sub> and MSCAN<sub>ENAC</sub>, respectively. These findings are in line with Zhang et al.'s study [<xref ref-type="bibr" rid="CR20">20</xref>], which highlights that One-hot focuses on local semantic information while ENAC only considers the sequence's nucleic acid composition and position, neglecting more profound semantic information. Conversely, Word2vec captures the contextual semantic information of the sequence, significantly enhancing the model's predictive capability.</p>
    <p id="Par70">Second, based on the test data of Chen et al., we assessed the impact of various MSCAN components by comparing the performance of different MSCAN variants, such as SCAN, SAN, MCAN, and CAN. Experimental results show that MSCAN reduces AUPRC by 3.04% and 2.77% respectively after deleting a self-attention module or a cross-attention module. This finding is consistent with Sun et al.'s study [<xref ref-type="bibr" rid="CR35">35</xref>], which posits that the removal of self- or cross-attention modules leads to diminished model performance. When both the Multi-Scale and cross-attention modules are removed, the AUPRC of MSCAN decreases by 2.86%. This result aligns with Chen et al.'s study [<xref ref-type="bibr" rid="CR36">36</xref>], which emphasizes that cross-attention effectively learns multi-scale transformer features for data recognition.</p>
    <p id="Par71">Third, we compared the performance of m6A-word2vec, DeepM6ASeq, Plant6mA, and MSCAN based on the test data of Chen et al. MSCAN's AUROC and AUPRC outperformed the other three state-of-the-art models. In particular, MSCAN surpassed Plant6mA by 2.14% in terms of AUPRC. This study substantiates that the utilization of multi-scale input and cross-attention allows the model to extract diverse features and provide deep semantics, which Plant6mA cannot achieve through information fusion from multiple scales. This conclusion is supported by Guo et al.'s study [<xref ref-type="bibr" rid="CR37">37</xref>], which demonstrated that multi-scale transformers could extract rich and robust features from different scale inputs.</p>
    <p id="Par72">Four, To make fair comparisons with m6A-word2vec, DeepM6ASeq, Plant6mA methods, we tested MSCAN on twelve RNA modification datasets(m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um). The results show that MSCAN outperforms all other competing methods. our predicted results may also be consistent with biological insights, which illustrates that MSCAN has good robustness.</p>
    <p id="Par73">Five, based on the dataset of Song et al., we designed a cross-modification validation experiment in which twelve different methylation models were tested using twelve sets of methylation test datasets, respectively. We discovered that the most strongly associated modifications originated from the same base class, such as A and G belonging to purine-like bases. The AUROC and AUPRC metrics of the Am test set on the Gm prediction model are second only to the Am test set on the similar Am prediction model. This finding is consistent with Song et al.'s study [<xref ref-type="bibr" rid="CR5">5</xref>], which proposed the existence of an inherent shared structure between different RNA modifications.</p>
    <p id="Par74">Lastly, we compared Am, Gm, Cm, and Um correlations through local BLAST software. We found the average bit-score value of the Gm sequence compared to the Am comparison library is high, indicating that the Am sequence and the Gm sequence are highly similar. Similarly, the average bit-score value of the Um sequence compared to the Cm comparison library is high, indicating that the Um sequence and Cm sequence similarity is high, which may validate the idea that the most closely related modifications originate from the same type of bases.These findings underscore the potential of the MSCAN model in advancing our understanding of the complex interplay between some RNA modifications and their functional implications.</p>
  </sec>
  <sec id="Sec14">
    <title>Conclusions</title>
    <p id="Par75">This study presents a novel multi-scale cross-attention network (MSCAN) for predicting RNA methylation sites. By combining multi-scale, self-, and cross-attention mechanisms, MSCAN effectively extracts in-depth features from 41 base pair sequences at various scales. The model outperforms state-of-the-art predictors for all twelve modification sites, demonstrating its strong generalization ability.</p>
    <p id="Par76">Crucially, through the cross-modification validation experiments, our model unveils significant associations among different types of RNA modifications in terms of their related sequence contexts. This finding offers valuable insights into the complex relationships between RNA modifications and their respective sequence environments.</p>
    <p id="Par77">It is worth noting that the data set samples of the MSCAN model have the following conditions: (1) The sample is a 41-nt fixed-length sequence, (2) The methylation site must be in the center of the sequence, (3) The sample sequence must have a label. It may seem that MSCAN may only be tested by this method.We hope that in the future, targeting the characteristics of RNA sequences of different lengths, the model structure is adjusted to better capture and utilize these characteristics, and focusing particularly on studies that investigate the biological functions and regulatory mechanisms of different RNA sequence lengths.</p>
  </sec>
  <sec id="Sec15">
    <title>Materials and methods</title>
    <sec id="Sec16">
      <title>Datasets</title>
      <p id="Par78">In the present study, the benchmark datasets employed to train and test the proposed methods were gathered from previous works [5, 25]. These datasets encompass twelve distinct types of RNA modifications, namely m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um from H. sapiens. They can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>, and detailed information is provided in Table <xref rid="Tab11" ref-type="table">11</xref>. To maintain consistency, all sequence samples were adjusted to a length of 41-nt, with the modified or unmodified site positioned at the center. In cases where the original sequence length fell short of 41-nt, we employed a padding technique, appending “−” to the head or tail of the sequence, to ensure a uniform length of 41-nt across all samples. The raw RNA datasets are represented as <inline-formula id="IEq1"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_{0} = \left\{ {x^{n} } \right\}_{n = 1}^{N}$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mfenced close="}" open="{"><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mfenced><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>N</italic> is the sequence number, and each <inline-formula id="IEq2"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x^{n} \in {\mathbb{R}}^{L}$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq2.gif"/></alternatives></inline-formula> is an RNA sequence. Each entry <inline-formula id="IEq3"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i}^{n} \in \left\{ {A,C,G,U,` - ^{\prime}} \right\}\;or\;x_{i}^{n} \in \left\{ {A,C,G,U} \right\},i = 1,2,3, \ldots ,L$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mo>`</mml:mo><mml:msup><mml:mo>-</mml:mo><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfenced><mml:mspace width="0.277778em"/><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.277778em"/><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq3.gif"/></alternatives></inline-formula>, where <italic>L</italic> is the fixed sequence length. The model training and experimental parameter optimization of MSCAN are based on the dataset of Chen et al., and the evaluation of MSCAN generalization capability is based on the dataset of Song et al. The ratio of positive-to-negative samples of Chen's and Song's datasets was 1:10 and 1:1, respectively, as shown in Table <xref rid="Tab11" ref-type="table">11</xref>. The corresponding sequences were followed by aligning of the sequences according to sequence-logo representations rendered using the WebLogo program [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>], As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>.
<table-wrap id="Tab11"><label>Table 11</label><caption><p>A statistic of the training and test datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Full name</th><th align="left">Dataset</th><th align="left">Original base</th><th align="left">Number of positive</th><th align="left">Number of negative</th><th align="left">Source of data</th></tr></thead><tbody><tr><td align="left" rowspan="2">1-Methyladenosine</td><td align="left">m<sup>1</sup>A_train0</td><td align="left">A</td><td char="." align="char">593</td><td char="." align="char">5930</td><td align="left">Chen et al.[<xref ref-type="bibr" rid="CR25">25</xref>]</td></tr><tr><td align="left">m<sup>1</sup>A_test0</td><td align="left">A</td><td char="." align="char">114</td><td char="." align="char">1140</td><td align="left"/></tr><tr><td align="left" rowspan="2">N6-methyladenosine</td><td align="left">m<sup>6</sup>A_ train</td><td align="left">A</td><td char="." align="char">41,307</td><td char="." align="char">41,307</td><td align="left">Song et al.[<xref ref-type="bibr" rid="CR5">5</xref>]</td></tr><tr><td align="left">m<sup>6</sup>A_test</td><td align="left"> A</td><td char="." align="char">5901</td><td char="." align="char">5901</td><td align="left"/></tr><tr><td align="left" rowspan="2">1-Methyladenosine</td><td align="left">m<sup>1</sup>A_train</td><td align="left">A</td><td char="." align="char">7357</td><td char="." align="char">7357</td><td align="left"/></tr><tr><td align="left">m<sup>1</sup>A_test</td><td align="left">A</td><td char="." align="char">1051</td><td char="." align="char">1051</td><td align="left"/></tr><tr><td align="left" rowspan="2">5-Methylcytidine</td><td align="left">m<sup>5</sup>C_train</td><td align="left">C</td><td char="." align="char">5953</td><td char="." align="char">5953</td><td align="left"/></tr><tr><td align="left">m<sup>5</sup>C_test</td><td align="left">C</td><td char="." align="char">850</td><td char="." align="char">850</td><td align="left"/></tr><tr><td align="left" rowspan="2">5-Methyluridine</td><td align="left">m<sup>5</sup>U_train</td><td align="left">U</td><td char="." align="char">863</td><td char="." align="char">863</td><td align="left"/></tr><tr><td align="left">m<sup>5</sup>U_test</td><td align="left">U</td><td char="." align="char">123</td><td char="." align="char">123</td><td align="left"/></tr><tr><td align="left" rowspan="2">N6,2′-<italic>O</italic>-dimethyl adenosine</td><td align="left">m<sup>6</sup>Am_train</td><td align="left">A</td><td char="." align="char">1172</td><td char="." align="char">1172</td><td align="left"/></tr><tr><td align="left">m<sup>6</sup>Am_test</td><td align="left">A</td><td char="." align="char">167</td><td char="." align="char">167</td><td align="left"/></tr><tr><td align="left" rowspan="2">7-Methylguanosine</td><td align="left">m<sup>7</sup>G_train</td><td align="left">G</td><td char="." align="char">605</td><td char="." align="char">605</td><td align="left"/></tr><tr><td align="left">m<sup>7</sup>G_test</td><td align="left">G</td><td char="." align="char">86</td><td char="." align="char">86</td><td align="left"/></tr><tr><td align="left" rowspan="2">Pseudouridine</td><td align="left">Pse_train</td><td align="left">U</td><td char="." align="char">1989</td><td char="." align="char">1989</td><td align="left"/></tr><tr><td align="left">Pse_test</td><td align="left">U</td><td char="." align="char">284</td><td char="." align="char">284</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methyladenosine</td><td align="left">Am_train</td><td align="left">A</td><td char="." align="char">848</td><td char="." align="char">848</td><td align="left"/></tr><tr><td align="left">Am_test</td><td align="left">A</td><td char="." align="char">121</td><td char="." align="char">121</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methylcytidine</td><td align="left">Cm_train</td><td align="left">C</td><td char="." align="char">1058</td><td char="." align="char">1058</td><td align="left"/></tr><tr><td align="left">Cm_test</td><td align="left">C</td><td char="." align="char">151</td><td char="." align="char">151</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methylguanosine</td><td align="left">Gm_train</td><td align="left">G</td><td char="." align="char">636</td><td char="." align="char">636</td><td align="left"/></tr><tr><td align="left">Gm_test</td><td align="left">G</td><td char="." align="char">90</td><td char="." align="char">90</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methyluridine</td><td align="left">Um_train</td><td align="left">U</td><td char="." align="char">1438</td><td char="." align="char">1438</td><td align="left"/></tr><tr><td align="left">Um_test</td><td align="left">U</td><td char="." align="char">205</td><td char="." align="char">205</td><td align="left"/></tr><tr><td align="left" rowspan="2">Inosine</td><td align="left">I_train</td><td align="left">A</td><td char="." align="char">5164</td><td char="." align="char">5164</td><td align="left"/></tr><tr><td align="left">I_test</td><td align="left">A</td><td char="." align="char">737</td><td char="." align="char">737</td><td align="left"/></tr></tbody></table></table-wrap><fig id="Fig7"><label>Fig. 7</label><caption><p>The motif of methylation sites. <bold>a</bold> m<sup>1</sup>A in the dataset of Chen et al. <bold>b</bold> m<sup>6</sup>A. <bold>c</bold> Ψ. <bold>d</bold> m<sup>1</sup>A. <bold>e</bold> m<sup>6</sup>Am. <bold>f</bold> Am. <bold>g</bold> Cm. <bold>h</bold> Gm. <bold>i</bold> Um. <bold>j</bold> m<sup>5</sup>C. <bold>k</bold> m<sup>5</sup>U. <bold>l</bold> m<sup>7</sup>G. <bold>m</bold> I in the dataset of Song et al.</p></caption><graphic xlink:href="12859_2024_5649_Fig7a_HTML" id="d32e3256"/><graphic xlink:href="12859_2024_5649_Fig7b_HTML" id="d32e3257"/></fig></p>
    </sec>
    <sec id="Sec17">
      <title>Feature encoding representation</title>
      <p id="Par79">Achieving an effective feature encoding representation of the sequence is crucial for improving the evaluation metrics of a model. This study uses Word2vec to transform the sequence into embedded vector representations. Since its introduction in 2013, Word2vec has significantly advanced the performance of a wide array of natural language processing (NLP) tasks.</p>
      <p id="Par80">The Word2vec methodology offers two different frameworks for encoding: Skip-gram and Continuous Bag of Words (CBOW). The Skip-gram approach predicts contextual information surrounding a given word, whereas the CBOW model generates an embedding for the target word based on its contextual associations. These embeddings are derived through a neural network application, adeptly capturing the inherent relationships within the data.</p>
      <p id="Par81">We developed an RNA embedding approach by treating RNA sequences as sentences and k consecutive RNA nucleotides (k-mers) as words within these sentences. Mathematically, we define the mapping from single nucleotides to the vector representation of k-mers <inline-formula id="IEq4"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f:\sum\nolimits_{{}}^{L} { \mapsto Y^{L - k + 1} }$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow/></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:mo>↦</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq4.gif"/></alternatives></inline-formula>, which is subsequently fed into the neural network for training. This process results in d-dimensional embedded vectors, denoted by <inline-formula id="IEq5"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{m}^{n} \in {\mathbb{R}}^{{m \times d_{m} }}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq5.gif"/></alternatives></inline-formula>, where <italic>m</italic> = <italic>L</italic> − <italic>k</italic> + 1, and <italic>d</italic><sub><italic>m</italic></sub> represents the embedding dimension. Gene2vec [<xref ref-type="bibr" rid="CR21">21</xref>] demonstrated that 3-mers provide the optimal prediction performance. Consequently, we adopted a 3-mers encoding strategy for the input data. Specifically, we employed a sliding window of size 3-nt to slide 41-nt sample sequences with one stride, generating a sequence of 39 words. Each word corresponds to an index in all possible 3-mer combinations(105 or 65 types). Given the relatively large dataset and limited word types in our corpus, we chose the Continuous Bag of Words (CBOW) model for encoding, as it offers faster training times than the Skip-gram model. We used the grid-search strategy for the optimization of the parameters for the experiments, word vector dimension in [100,3 00]. Feature encoding with a word vector dimension of 100 achieved the best performance. In summary, each 3-mer is converted into a word vector, transforming a 41-nt sequence into a 39 × 100 matrix, where 100 represents the word vector dimension.</p>
    </sec>
    <sec id="Sec18">
      <title>Model</title>
      <p id="Par82">As shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>, MSCAN represents an innovative DL architecture that employs a combination of multi-scale self- and cross-attention mechanisms and point-wise, fully connected layers in the encoder. This innovative approach enables the effective modeling of both intra- and inter-sequence interactions across a wide range of scales within RNA-seq data by transforming local RNA sequences into high-dimensional vectors via representations through its multi-scale self- and cross-attention networks. MSCAN efficiently extracts crucial RNA sequence features, thereby facilitating the accurate prediction of m<sup>1</sup>A modifications.<fig id="Fig8"><label>Fig. 8</label><caption><p>Structure of our computational framework based on multi-scale self- and cross-attention network to predict m<sup>1</sup>A methylation site</p></caption><graphic xlink:href="12859_2024_5649_Fig8_HTML" id="MO8"/></fig></p>
      <p id="Par83">The results of this study indicate that the nucleotide base neighboring the methylation site is instrumental in determining the specific type of methylation site and its potential functional consequences [<xref ref-type="bibr" rid="CR40">40</xref>–<xref ref-type="bibr" rid="CR42">42</xref>]. Therefore, the original sample sequence was extracted with two subsequences. These subsequences were centered on the sequence midpoint. One subsequence was 21-nt long, and the other was 31-nt long, as shown in Fig. <xref rid="Fig9" ref-type="fig">9</xref>.<fig id="Fig9"><label>Fig. 9</label><caption><p>Schematic diagram of the obtained subsequences</p></caption><graphic xlink:href="12859_2024_5649_Fig9_HTML" id="MO9"/></fig></p>
      <p id="Par84">In this paper, we represent the dataset as a collection of sample sequences, each consisting of a main sequence and two subsequences. The dataset can be expressed as  <inline-formula id="IEq6"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\{({\text{x}}}_{s0}^{1}, {\text{x}}_{s1}^{1} ,{\text{x}}_{s2}^{1} ,{\text{y}}^{1} )$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq6.gif"/></alternatives></inline-formula>, <inline-formula id="IEq7"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\text{x}}_{s0}^{2}, {\text{x}}_{s1}^{2}, {\text{x}}_{s2}^{2}, {\text{y}}^{2} )$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq7.gif"/></alternatives></inline-formula>, ⋯, <inline-formula id="IEq8"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{(x}}_{s0}^{n} , {\text{x}}_{s1}^{n}, {\text{x}}_{s2}^{n} ,{\text{y}}^{n} )\}$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:msubsup><mml:mtext>(x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq8.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq9"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{n} \in \left\{ {0,1} \right\}$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq9.gif"/></alternatives></inline-formula>, <inline-formula id="IEq10"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s0}^{i} ,x_{s1}^{i} ,x_{s2}^{i}$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq10.gif"/></alternatives></inline-formula> are the three sequences of the i-th sample, <inline-formula id="IEq11"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s0}^{i}$$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq11.gif"/></alternatives></inline-formula> is the main sequence, with s0 = 41, <inline-formula id="IEq12"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s1}^{i} ,x_{s2}^{i}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq12.gif"/></alternatives></inline-formula> is the subsequence, with s1 = 21, and s2 = 31. Experiments show that the performance of trained models exhibits variability when the order of input sample sequences is altered, as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. MSCAN employs the Word2vec encoder to encode word vectors for these sequences. For example, sequences with lengths 21-nt, 41-nt, and 31-nt are transformed into three distinct matrices of varying dimensions: 19 × 100, 39 × 100, and 29 × 100, respectively.</p>
      <p id="Par85">To account for the lack of recursion or convolution in the model, it is necessary to incorporate information about the relative positions of tokens within sequences so that the model can utilize sequence order effectively. To achieve this, "position encoding" is added to the Word2vec embedding output, forming the input for the encoder. The positional encoding method employed in this work was first introduced by Vaswani et al. [<xref ref-type="bibr" rid="CR43">43</xref>] in a machine translation task.</p>
      <p id="Par86">The encoder is composed of a stack of N = 3 identical layers. Each layer has two sub-layers. The first sub-layer is a multi-scale self- and cross-attention network, while the second is a position-wise, fully connected feed-forward network. To facilitate effective information flow, each of these sub-layers incorporates a residual connection in conjunction with layer normalization.</p>
      <p id="Par87">The output generated by each sub-layer can be expressed as LayerNorm(x + sublayer(x)), where sublayer(x) represents the function associated with the sub-layer in question. Both the embedding layer and all model sub-layers yield outputs with a dimension of <inline-formula id="IEq13"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{model} = 64$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq13.gif"/></alternatives></inline-formula>, allowing for seamless residual connections.</p>
      <p id="Par88">Upon completion of the classification process, a linear transformation followed by a sigmoid function is employed to convert the encoder output into predicted probabilities. We used grid-search to choose the hyperparameters on the training data of Chen et al., specifically, epoch in [50, 100], learning_rate in [5e−4, 5e−2], batch in [5, 10, 20, 60], and dropout in [0.2, 0.5]. Final epoch = 100, learning_rate = 5e−4, batch = 10, and dropout = 0.2 is the optimal hyperparameters.</p>
    </sec>
    <sec id="Sec19">
      <title>Multi-scale self- and cross-attention network</title>
      <p id="Par89">The multi-scale self and cross-attention network constitutes the initial layer of the encoder, designed to handle linguistic input at various scales. Utilizing word2vec embeddings, matrices at three distinct scales (take <inline-formula id="IEq14"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}} ,X_{s1}^{{}} ,X_{s2}^{{}}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq14.gif"/></alternatives></inline-formula> as an example) are introduced into the self-attention and cross-attention modules for simultaneous computation. Specifically, <inline-formula id="IEq15"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq15.gif"/></alternatives></inline-formula> is incorporated into the self-attention module, while the two combinations (<inline-formula id="IEq16"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq16.gif"/></alternatives></inline-formula> and <inline-formula id="IEq17"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq17.gif"/></alternatives></inline-formula>, <inline-formula id="IEq18"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq18.gif"/></alternatives></inline-formula> and <inline-formula id="IEq19"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s2}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq19.gif"/></alternatives></inline-formula>) are integrated into the cross-attention module. Subsequently, the outputs from these modules are directly added and relayed to the subsequent layer, as shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>.<fig id="Fig10"><label>Fig. 10</label><caption><p>The internal structure of the multi-scale self- and cross-attention network</p></caption><graphic xlink:href="12859_2024_5649_Fig10_HTML" id="MO10"/></fig></p>
    </sec>
    <sec id="Sec20">
      <title>Cross-attention network</title>
      <p id="Par90">The cross-attention network is designed to extract and learn relationships between words in sequences of varying scales, effectively capturing associations across different sequences. Using sequences <inline-formula id="IEq20"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M52"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq20.gif"/></alternatives></inline-formula> and <inline-formula id="IEq21"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M54"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq21.gif"/></alternatives></inline-formula> as examples, we first transform each sequence into three different terms, which are query, key, and value. This is achieved through the application of linear projections.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{s0} = X_{s0} W_{s0}^{Q} ,K_{s0} = X_{s0} W_{s0}^{K} ,V_{s0} = X_{s0} W_{s0}^{V}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{s1} = X_{s1} W_{s1}^{Q} ,K_{s1} = X_{s1} W_{s1}^{K} ,V_{s1} = X_{s1} W_{s1}^{V}$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq22"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{m} \in {\mathbb{R}}^{{m \times d_{model} }}$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq22.gif"/></alternatives></inline-formula> is the output of the sequence embedding module, <italic>m</italic> represents the length of the input sequence <inline-formula id="IEq23"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m \in \left\{ {s_{0} ,s_{1} ,s_{2} } \right\}$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq23.gif"/></alternatives></inline-formula>. <inline-formula id="IEq24"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{m}^{Q} ,W_{m}^{K} \in {\mathbb{R}}^{{d_{model} \times d_{k} }}$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq24.gif"/></alternatives></inline-formula>, <inline-formula id="IEq25"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{m}^{V} \in {\mathbb{R}}^{{d_{model} \times d_{v} }}$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq25.gif"/></alternatives></inline-formula>. <italic>X</italic><sub><italic>m</italic></sub> is transformed into the query matrix <inline-formula id="IEq26"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{m} \in {\mathbb{R}}^{{m \times d_{k} }}$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq26.gif"/></alternatives></inline-formula>, the key matrix <inline-formula id="IEq27"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K_{m} \in {\mathbb{R}}^{{m \times d_{k} }}$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq27.gif"/></alternatives></inline-formula>, and the value matrix <inline-formula id="IEq28"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{m} \in {\mathbb{R}}^{{m \times d_{v} }}$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq28.gif"/></alternatives></inline-formula>, in which <italic>d</italic><sub><italic>k</italic></sub> is the dimension of matrices <italic>Q</italic><sub><italic>m</italic></sub>, <italic>K</italic><sub><italic>m</italic></sub>, and <italic>d</italic><sub><italic>v</italic></sub> is the dimension of matrix <italic>V</italic><sub><italic>m</italic></sub>.</p>
      <p id="Par91">Second, we compute the cross-modal dot product between the query vector of <inline-formula id="IEq29"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M74"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq29.gif"/></alternatives></inline-formula> and the key vector of <inline-formula id="IEq30"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M76"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq30.gif"/></alternatives></inline-formula>, dividing the result value by <inline-formula id="IEq31"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sqrt {d_{k} }$$\end{document}</tex-math><mml:math id="M78"><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq31.gif"/></alternatives></inline-formula>, to estimate the association between the <inline-formula id="IEq32"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M80"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq32.gif"/></alternatives></inline-formula> and <inline-formula id="IEq33"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M82"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq33.gif"/></alternatives></inline-formula>. These results are subsequently refined and normalized utilizing the softmax function, yielding attention weight coefficients. Lastly, we leverage these coefficients to aggregate the corresponding value vectors from each feature sequence, thereby facilitating that the associated information between the two sequences is obtained. The cross-attention function can be described as follows:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Cross - Attention(Q_{s0} ,K_{s1} ,V_{s1} ) = softmax\left( {\frac{{Q_{s0} K_{s1}^{T} }}{{\sqrt {d_{k} } }}} \right)V_{s1}$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec21">
      <title>Self-attention network</title>
      <p id="Par92">In contrast to the cross-attention module, which primarily focuses on inter-sequence interactions, the self-attention module identifies and elucidates intra-sequence associations. The self-attention function is described as<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Self - Attention(Q_{s0} ,K_{s0} ,V_{s0} ) = softmax\left( {\frac{{Q_{s0} K_{s0}^{T} }}{{\sqrt {d_{k} } }}} \right)V_{s0}$$\end{document}</tex-math><mml:math id="M86" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec22">
      <title>Multi-head multi-scale self- and cross-attention</title>
      <p id="Par93">The above elucidation pertains to single-headed attention, a fundamental mechanism in attention-based models. However, multi-headed attention is commonly employed in practice to augment model efficacy and expedite training. This technique entails conducting single-headed attention in parallel across multiple instances, known as "heads", and subsequently integrating the outcomes derived from each head. By incorporating multi-headed attention, the model can effectively capture diverse contextual information and intricate relationships inherent in the input data. The function of cross-attention is described as:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; MultiHead(Q,K,V) = Concat\left( {head_{1} ,...,head_{h} } \right)W^{O} \\ &amp; \quad where^{{}} head_{i} = Attention\left( {Q_{s0} W_{s0s0i}^{{Q_{s0} }} ,K_{s0} W_{s0s0i}^{{K_{s0} }} ,V_{s0} W_{s0s0i}^{{V_{s0} }} } \right) \\ &amp; \quad + Attention\left( {Q_{s0} W_{s0s1i}^{{Q_{s0} }} ,K_{s1} W_{s0s1i}^{{K_{s1} }} ,V_{s1} W_{s0s1i}^{{V_{s1} }} } \right) \\ &amp; \quad + Attention\left( {Q_{s0} W_{s0s2i}^{{Q_{s0} }} ,K_{s2} W_{s0s2i}^{{K_{s2} }} ,V_{s2} W_{s0s2i}^{{V_{s2} }} } \right) \\ \end{aligned}$$\end{document}</tex-math><mml:math id="M88" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>M</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:msup><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow/></mml:msup><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where the <inline-formula id="IEq34"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{s0s0i}^{{Q_{s0} }} ,W_{s0s0i}^{{K_{s0} }} ,W_{s0s1i}^{{Q_{s0} }} ,W_{s0s1i}^{{K_{s1} }} ,W_{s0s2i}^{{Q_{s0} }} ,W_{s0s2i}^{{K_{s2} }} , \in {\mathbb{R}}^{{d_{model} \times d_{k} }}$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq34.gif"/></alternatives></inline-formula>, <inline-formula id="IEq35"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{s0s0i}^{{V_{s0} }} ,W_{s0s1i}^{{V_{s1} }} ,W_{s0s2i}^{{V_{s2} }} \in {\mathbb{R}}^{{d_{model} \times d_{v} }}$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq35.gif"/></alternatives></inline-formula> and <inline-formula id="IEq36"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W^{O} \in {\mathbb{R}}^{{hd_{v} \times d_{model} }}$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq36.gif"/></alternatives></inline-formula></p>
      <p id="Par94">In this task, we employ h = 8 parallel attention layers. For each layer,we use <italic>d</italic><sub><italic>k</italic></sub> = <italic>d</italic><sub><italic>v</italic></sub> = <italic>d</italic><sub><italic>model</italic></sub>/h = 8.</p>
    </sec>
    <sec id="Sec23">
      <title>Position-wise feed-forward networks</title>
      <p id="Par95">After the multi-headed, multi-scale self- and cross-attention layer, a second sub-layer is incorporated to augment the representative capacity of the model further. This additional component comprises a position-wise, fully connected feed-forward network, enhancing the overall model performance. The architecture of this network entails two successive linear transformations, with an intervening rectified linear unit (ReLU) activation function, ensuring a non-linear and expressive representation of the input data. It is defined as:<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$FFN(x) = \max (0,xW_{1} + b_{1} )W_{2} + b_{2}$$\end{document}</tex-math><mml:math id="M96" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true">max</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par96">The input and output have dimensionality d<sub>model</sub> = 64, while the inner layer's dimensionality is d<sub>ff</sub> = 256.</p>
    </sec>
    <sec id="Sec24">
      <title>Classification module</title>
      <p id="Par97">To accomplish the classification task, the initial step involves computing the average of the encoder output. Subsequently, a linear transformation is applied, followed by implementing a sigmoid activation function. The optimization of the model is facilitated by employing cross-entropy loss as the primary objective. Finally, the methylation site probabilities are acquired, providing a robust and comprehensive representation of the underlying biological processes.</p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>RNA</term>
        <def>
          <p id="Par4">Ribonucleic acid</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>1</sup>A</term>
        <def>
          <p id="Par5">N1-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>6</sup>A</term>
        <def>
          <p id="Par6">N6-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Ψ</term>
        <def>
          <p id="Par7">Pseudouridine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>6</sup>Am</term>
        <def>
          <p id="Par8">N6,2′-<italic>O</italic>-dimethyl adenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Am</term>
        <def>
          <p id="Par9">2′-<italic>O</italic>-Methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Cm</term>
        <def>
          <p id="Par10">2′-<italic>O</italic>-Methylcytidine</p>
        </def>
      </def-item>
      <def-item>
        <term>Gm</term>
        <def>
          <p id="Par11">2′-<italic>O</italic>-Methylguanosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Um</term>
        <def>
          <p id="Par12">2′-<italic>O</italic>-Methyluridine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>5</sup>C</term>
        <def>
          <p id="Par13">5-Methylcytidine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>7</sup>G</term>
        <def>
          <p id="Par14">7-Methylguanosine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>5</sup>U</term>
        <def>
          <p id="Par15">5-Methyluridine</p>
        </def>
      </def-item>
      <def-item>
        <term>I</term>
        <def>
          <p id="Par16">Inosine</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par17">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>BiLSTM</term>
        <def>
          <p id="Par18">Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p id="Par19">Long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par20">Recurrent neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>NLP</term>
        <def>
          <p id="Par21">Natural language processing</p>
        </def>
      </def-item>
      <def-item>
        <term>DL</term>
        <def>
          <p id="Par22">Deep learning</p>
        </def>
      </def-item>
      <def-item>
        <term>MSCAN</term>
        <def>
          <p id="Par23">Multi-scale self- and cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>MCAN</term>
        <def>
          <p id="Par24">Multi-scale cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>SCAN</term>
        <def>
          <p id="Par25">Self- and cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>CAN</term>
        <def>
          <p id="Par26">Cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>SAN</term>
        <def>
          <p id="Par27">Self-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>Sn</term>
        <def>
          <p id="Par28">Sensitivity</p>
        </def>
      </def-item>
      <def-item>
        <term>Sp</term>
        <def>
          <p id="Par29">Specificity</p>
        </def>
      </def-item>
      <def-item>
        <term>ACC</term>
        <def>
          <p id="Par30">Accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>Pre</term>
        <def>
          <p id="Par31">Precision</p>
        </def>
      </def-item>
      <def-item>
        <term>MCC</term>
        <def>
          <p id="Par32">Matthews correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>AUROC</term>
        <def>
          <p id="Par33">Area under the receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>AUPRC</term>
        <def>
          <p id="Par34">Area under the precision-recall curve</p>
        </def>
      </def-item>
      <def-item>
        <term>ENAC</term>
        <def>
          <p id="Par35">Enhanced nucleic acid composition</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>HW built the architecture for MSCAN, designed and implemented the experiments, analyzed the results, and wrote the paper. LZ and TH conducted the experiments and revised the paper. DW conducted the experiments, analyzed the results, and revised the paper. LZ and YS supervised the project, analyzed the result, and revised the paper. All authors read, critically revised, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work has been supported by the National Natural Science Foundation of China (31871337 and 61971422 to LZ), and the "333 Project" of Jiangsu(BRA2020328 to WHL). The funding body did not play any roles in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The data supporting the findings of the article is available at the web server <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par98">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par99">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par100">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>El Allali</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Elhamraoui</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Daoud</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Machine learning applications in RNA modification sites prediction</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>5510</fpage>
        <lpage>5524</lpage>
        <pub-id pub-id-type="pmid">34712397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>SY</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bi</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>XL</given-names>
          </name>
        </person-group>
        <article-title>A brief review of machine learning methods for RNA methylation sites prediction</article-title>
        <source>Methods</source>
        <year>2022</year>
        <volume>203</volume>
        <fpage>399</fpage>
        <lpage>421</lpage>
        <pub-id pub-id-type="pmid">35248693</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Bioinformatics approaches for deciphering the epitranscriptome: recent progress and emerging topics</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2020</year>
        <volume>18</volume>
        <fpage>1587</fpage>
        <lpage>1604</lpage>
        <pub-id pub-id-type="pmid">32670500</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>LF</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>XQ</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>FS</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>XH</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>TB</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>XM</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>KX</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>MY</given-names>
          </name>
        </person-group>
        <article-title>TransformerCPI: improving compound–protein interaction prediction by sequence-based deep learning with self-attention mechanism and label reversal experiments</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>16</issue>
        <fpage>4406</fpage>
        <lpage>4414</lpage>
        <pub-id pub-id-type="pmid">32428219</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>ZT</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>BW</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>KQ</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>de Magalhaes</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Rigden</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Attention-based multi-label neural networks for integrated prediction and interpretation of twelve widely occurring RNA modifications</article-title>
        <source>Nat Commun</source>
        <year>2021</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="pmid">33397941</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grozhik</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Olarerin-George</surname>
            <given-names>AO</given-names>
          </name>
          <name>
            <surname>Sindelar</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Jaffrey</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Antibody cross-reactivity accounts for widespread appearance of m1A in 5' UTRs</article-title>
        <source>Nat Commun</source>
        <year>2019</year>
        <volume>11</volume>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dominissini</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The dynamic N(1)-methyladenosine methylome in eukaryotic messenger RNA</article-title>
        <source>Nature</source>
        <year>2016</year>
        <volume>530</volume>
        <issue>7591</issue>
        <fpage>1</fpage>
        <lpage>39</lpage>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>ZK</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>GZ</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Dominissini</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High-resolution N-6-methyladenosine (m(6)A) map using photo-crosslinking-assisted m(6)A sequencing</article-title>
        <source>Angew Chem Int Ed</source>
        <year>2015</year>
        <volume>54</volume>
        <issue>5</issue>
        <fpage>1587</fpage>
        <lpage>1590</lpage>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Transcriptome-wide mapping reveals reversible and dynamic N(1)-methyladenosine methylome</article-title>
        <source>Nat Chem Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>5</issue>
        <fpage>311</fpage>
        <lpage>316</lpage>
        <pub-id pub-id-type="pmid">26863410</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Masiello</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Biggiogera</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Ultrastructural localization of 5-methylcytosine on DNA and RNA</article-title>
        <source>Cell Mol Life Sci</source>
        <year>2017</year>
        <volume>74</volume>
        <issue>16</issue>
        <fpage>3057</fpage>
        <lpage>3064</lpage>
        <pub-id pub-id-type="pmid">28391361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiaoyu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xushen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Meiling</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Kun</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ying</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Base-resolution mapping reveals distinct m1A methylome in nuclear- and mitochondrial-encoded transcripts</article-title>
        <source>Mol Cell</source>
        <year>2017</year>
        <volume>68</volume>
        <issue>5</issue>
        <fpage>993</fpage>
        <lpage>1005</lpage>
        <pub-id pub-id-type="pmid">29107537</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rauch</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Dickinson</surname>
            <given-names>BC</given-names>
          </name>
        </person-group>
        <article-title>Evolution of a reverse transcriptase to map N1-methyladenosine in human messenger RNA</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>12</issue>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">30573832</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y-H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>SRAMP: prediction of mammalian N6-methyladenosine (m6A) sites based on sequence-derived features</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>10</issue>
        <fpage>e91</fpage>
        <lpage>e91</lpage>
        <pub-id pub-id-type="pmid">26896799</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>RAMPred: identifying the N(1)-methyladenosine sites in eukaryotic transcriptomes</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">28442746</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>iRNA-3typeA: identifying three types of modification at RNA's adenosine sites</article-title>
        <source>Mol Ther Nucleic Acids</source>
        <year>2018</year>
        <volume>11</volume>
        <fpage>468</fpage>
        <lpage>474</lpage>
        <pub-id pub-id-type="pmid">29858081</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>iMRM: a platform for simultaneously identifying multiple kinds of RNA modifications</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>11</issue>
        <fpage>3336</fpage>
        <lpage>3342</lpage>
        <pub-id pub-id-type="pmid">32134472</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Iuchi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Matsutani</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yamada</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Iwano</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Sumi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hosoda</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Fukunaga</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hamada</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Representation learning applications in biological sequence analysis</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>3198</fpage>
        <lpage>3208</lpage>
        <pub-id pub-id-type="pmid">34141139</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Angermueller</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Pärnamaa</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Parts</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Stegle</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for computational biology</article-title>
        <source>Mol Syst Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>7</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huss</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Abid</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mohammadi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Torkamani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Telenti</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A primer on deep learning in genomics</article-title>
        <source>Nat Genet</source>
        <year>2019</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>12</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">30478442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>EDLm(6)APred: ensemble deep learning approach for mRNA m(6)A site prediction</article-title>
        <source>BMC Bioinform</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>PW</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>LY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N-6-methyladenosine sites from mRNA</article-title>
        <source>RNA</source>
        <year>2019</year>
        <volume>25</volume>
        <issue>2</issue>
        <fpage>205</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="pmid">30425123</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>AthMethPre: a web server for the prediction and query of mRNA m(6)A sites in <italic>Arabidopsis</italic>
<italic>thaliana</italic></article-title>
        <source>Mol Biosyst</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>11</issue>
        <fpage>3333</fpage>
        <lpage>3337</lpage>
        <pub-id pub-id-type="pmid">27550167</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lv</surname>
            <given-names>ZB</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>A convolutional neural network using dinucleotide one-hot encoder for identifying DNA N6-methyladenine sites in the rice genome</article-title>
        <source>Neurocomputing</source>
        <year>2021</year>
        <volume>422</volume>
        <fpage>214</fpage>
        <lpage>221</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tahir</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hayat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>KT</given-names>
          </name>
        </person-group>
        <article-title>Prediction of N6-methyladenosine sites using convolution neural network model based on distributed feature representations</article-title>
        <source>Neural Netw</source>
        <year>2020</year>
        <volume>129</volume>
        <fpage>385</fpage>
        <lpage>391</lpage>
        <pub-id pub-id-type="pmid">32593932</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AI</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Baggag</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bensmail</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive review and assessment of computational methods for predicting RNA post-transcriptional modification sites from RNA sequences</article-title>
        <source>Brief Bioinform</source>
        <year>2019</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>1676</fpage>
        <lpage>1696</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>NN</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>BERMP: a cross-species classifier for predicting m(6)A sites by integrating a deep learning algorithm and a random forest approach</article-title>
        <source>Int J Biol Sci</source>
        <year>2018</year>
        <volume>14</volume>
        <issue>12</issue>
        <fpage>1669</fpage>
        <lpage>1677</lpage>
        <pub-id pub-id-type="pmid">30416381</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hamada</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>DeepM6ASeq: prediction and characterization of m6A-containing sequences using deep learning</article-title>
        <source>BMC Bioinform</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Rp</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sw</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Gan</surname>
            <given-names>WA</given-names>
          </name>
        </person-group>
        <article-title>DeepFusion: a deep learning based multi-scale feature fusion method for predicting drug–target interactions</article-title>
        <source>Methods</source>
        <year>2022</year>
        <volume>204</volume>
        <fpage>269</fpage>
        <lpage>277</lpage>
        <pub-id pub-id-type="pmid">35219861</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Kim Y, Denton C, Hoang L, Rush AM. Structured attention networks. 2017, p. 1–21.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Plant6mA: a predictor for predicting N6-methyladenine sites with lightweight structure in plant genomes</article-title>
        <source>Methods (San Diego, Calif)</source>
        <year>2022</year>
        <volume>204</volume>
        <fpage>1</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="pmid">35483547</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>FY</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>DX</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>YZ</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Daly</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>QZ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iLearnPlus: a comprehensive and automated machine-learning platform for nucleic acid and protein sequence analysis, prediction and visualization</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>10</issue>
        <fpage>e60</fpage>
        <pub-id pub-id-type="pmid">33660783</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>KY</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>TY</given-names>
          </name>
          <name>
            <surname>Kao</surname>
            <given-names>HJ</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>WC</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>HD</given-names>
          </name>
        </person-group>
        <article-title>dbPTM in 2019: exploring disease association and cross-talk of post-translational modifications</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>D298</fpage>
        <lpage>D308</lpage>
        <pub-id pub-id-type="pmid">30418626</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shilatifard</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The language of histone crosstalk</article-title>
        <source>Cell</source>
        <year>2010</year>
        <volume>142</volume>
        <issue>5</issue>
        <fpage>682</fpage>
        <lpage>685</lpage>
        <pub-id pub-id-type="pmid">20813257</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boratyn</surname>
            <given-names>GM</given-names>
          </name>
          <name>
            <surname>Camacho</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>PS</given-names>
          </name>
          <name>
            <surname>Coulouris</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Fong</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Matten</surname>
            <given-names>WT</given-names>
          </name>
          <name>
            <surname>McGinnis</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Merezhuk</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BLAST: a more efficient report with usability improvements</article-title>
        <source>Nucleic Acids Res</source>
        <year>2013</year>
        <volume>41</volume>
        <issue>W1</issue>
        <fpage>W29</fpage>
        <lpage>W33</lpage>
        <pub-id pub-id-type="pmid">23609542</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Sun LC, Liu B, Tao JH, Lian Z. IEEE: multimodal cross- and self-attention network for speech emotion recognition. In: IEEE international conference on acoustics, speech and signal processing (ICASSP): Jun 06–11 2021; Electr Network. 2021, p. 4275–4279.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Chen CF, Fan Q, Panda R. CrossViT: cross-attention multi-scale vision transformer for image classification. In: ICCV. 2021, p. 1–12.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Guo Q, Qiu X, Liu P, Xue X, Zhang Z. Multi-scale self-attention for text classification. In: Proceedings of the AAAI conference on artificial intelligence, 2020, p. 7847–7854.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crooks</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Chandonia</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>SE</given-names>
          </name>
        </person-group>
        <article-title>WebLogo: a sequence logo generator</article-title>
        <source>Genome Res</source>
        <year>2004</year>
        <volume>14</volume>
        <issue>6</issue>
        <fpage>1188</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="pmid">15173120</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schneider</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Stephens</surname>
            <given-names>RM</given-names>
          </name>
        </person-group>
        <article-title>Sequence logos: a new way to display consensus sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>1990</year>
        <volume>18</volume>
        <issue>20</issue>
        <fpage>6097</fpage>
        <lpage>6100</lpage>
        <pub-id pub-id-type="pmid">2172928</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lister</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Mukamel</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Nery</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Urich</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Puddifoot</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Johnson</surname>
            <given-names>ND</given-names>
          </name>
          <name>
            <surname>Lucero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Dwork</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Schultz</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ecker</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>Global epigenomic reconfiguration during mammalian brain development</article-title>
        <source>Science</source>
        <year>2013</year>
        <volume>341</volume>
        <issue>6146</issue>
        <fpage>629</fpage>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>JU</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Distribution, recognition and regulation of non-CpG methylation in the adult mammalian brain</article-title>
        <source>Nat Neurosci</source>
        <year>2014</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>215</fpage>
        <lpage>222</lpage>
        <pub-id pub-id-type="pmid">24362762</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ziller</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bock</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Boyle</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Epstein</surname>
            <given-names>CB</given-names>
          </name>
          <name>
            <surname>Bernstein</surname>
            <given-names>BE</given-names>
          </name>
          <name>
            <surname>Lengauer</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Genomic distribution and inter-sample variation of non-CpG methylation across human cell types</article-title>
        <source>PLoS Genet</source>
        <year>2011</year>
        <volume>7</volume>
        <issue>12</issue>
        <fpage>e1002389</fpage>
        <pub-id pub-id-type="pmid">22174693</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. Attention is all you need. arXiv. 2017, p. 1–15.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10795237</article-id>
    <article-id pub-id-type="pmid">38233745</article-id>
    <article-id pub-id-type="publisher-id">5649</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-024-05649-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MSCAN: multi-scale self- and cross-attention network for RNA methylation site prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Honglei</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Dong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zeng</surname>
          <given-names>Wenliang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Sun</surname>
          <given-names>Yanjing</given-names>
        </name>
        <address>
          <email>yjsun@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhang</surname>
          <given-names>Lin</given-names>
        </name>
        <address>
          <email>lin.zhang@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01xt2dr21</institution-id><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>School of Information and Control Engineering, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01xt2dr21</institution-id><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>School of Computer Science and Technology, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff3"><label>3</label>School of Information Engineering, Xuzhou College of Industrial Technology, Xuzhou, 221400 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <elocation-id>32</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Epi-transcriptome regulation through post-transcriptional RNA modifications is essential for all RNA types. Precise recognition of RNA modifications is critical for understanding their functions and regulatory mechanisms. However, wet experimental methods are often costly and time-consuming, limiting their wide range of applications. Therefore, recent research has focused on developing computational methods, particularly deep learning (DL). Bidirectional long short-term memory (BiLSTM), convolutional neural network (CNN), and the transformer have demonstrated achievements in modification site prediction. However, BiLSTM cannot achieve parallel computation, leading to a long training time, CNN cannot learn the dependencies of the long distance of the sequence, and the Transformer lacks information interaction with sequences at different scales. This insight underscores the necessity for continued research and development in natural language processing (NLP) and DL to devise an enhanced prediction framework that can effectively address the challenges presented.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">This study presents a multi-scale self- and cross-attention network (MSCAN) to identify the RNA methylation site using an NLP and DL way. Experiment results on twelve RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um) reveal that the area under the receiver operating characteristic of MSCAN obtains respectively 98.34%, 85.41%, 97.29%, 96.74%, 99.04%, 79.94%, 76.22%, 65.69%, 92.92%, 92.03%, 95.77%, 89.66%, which is better than the state-of-the-art prediction model. This indicates that the model has strong generalization capabilities. Furthermore, MSCAN reveals a strong association among different types of RNA modifications from an experimental perspective. A user-friendly web server for predicting twelve widely occurring human RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um) is available at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">A predictor framework has been developed through binary classification to predict RNA methylation sites.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>RNA methylation</kwd>
      <kwd>Transformer</kwd>
      <kwd>Predictor</kwd>
      <kwd>Multi-scale</kwd>
      <kwd>Self-attention</kwd>
      <kwd>Cross-attention</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the National Natural Science Foundation of China</institution>
        </funding-source>
        <award-id>31871337</award-id>
        <award-id>31871337</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Tao</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>Wenliang</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the "333 Project" of Jiangsu</institution>
        </funding-source>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Dong</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Yanjing</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec2">
    <title>Background</title>
    <p id="Par36">RNA modification plays a fundamental role in regulating RNA function [<xref ref-type="bibr" rid="CR1">1</xref>] and has become a hotspot in epigenetics research [<xref ref-type="bibr" rid="CR2">2</xref>]. Nearly 200 RNA modifications have been discovered, most of which are methylation modifications [<xref ref-type="bibr" rid="CR3">3</xref>]. Common RNA methylation types include N<sup>1</sup>-methyladenosine (m<sup>1</sup>A), N<sup>2</sup>-methylguanosine (m<sup>2</sup>G), 5-methylcytosine (m<sup>5</sup>C), 5-methyluridine (m<sup>5</sup>U), 2′-<italic>O</italic>-methyladensine (Am), 2′-<italic>O</italic>-methylcytidine (Cm), 2′-<italic>O</italic>-methylguanosine (Gm), 2′-<italic>O</italic>-methyluridine (Um), Pseudouridine (Ψ), N<sup>6</sup>-methyladenosine(m<sup>6</sup>A), N<sup>7</sup>-methylguanine (m<sup>7</sup>G), inosine (I), and N6,2′-<italic>O</italic>-dimethyladenosine(m<sup>6</sup>Am), etc. Among them, m<sup>6</sup>A refers to methylation modification occurring at the nitrogen atom in position 6 of the RNA molecule adenine, which is the most abundant mRNA methylation, and is known to affect mRNA stability, splicing, and translation. In addition to m<sup>6</sup>A, m<sup>1</sup>A RNA methylation is a recently discovered one, which is evolutionarily conserved and ubiquitous in humans, rodents, and yeast. It can significantly enhance the protein translation of transcripts [<xref ref-type="bibr" rid="CR4">4</xref>], block the Watson–Crick interface, and is essential for tRNA stability [<xref ref-type="bibr" rid="CR5">5</xref>].</p>
    <p id="Par37">In the last decade, dozens of experimental methods have been developed to identify the precise location of methylation sites on RNA, such as miCLIP [<xref ref-type="bibr" rid="CR6">6</xref>], m<sup>1</sup>A-seq [<xref ref-type="bibr" rid="CR7">7</xref>], PA-m6A-seq [<xref ref-type="bibr" rid="CR8">8</xref>], m<sup>1</sup>A-ID-seq [<xref ref-type="bibr" rid="CR9">9</xref>], m5C-RIP [<xref ref-type="bibr" rid="CR10">10</xref>], m<sup>1</sup>A-MAP [<xref ref-type="bibr" rid="CR11">11</xref>], and m<sup>1</sup>A-IP-seq [<xref ref-type="bibr" rid="CR12">12</xref>]. Despite their effectiveness, these experimental techniques are usually both time-consuming and costly, limiting their use in different biological contexts [<xref ref-type="bibr" rid="CR4">4</xref>], and making them inadequate for large-scale genomic data [<xref ref-type="bibr" rid="CR13">13</xref>]. Consequently, there is strong motivation to explore computational methods that can accurately and efficiently identify methylation sites based on sequence information alone.</p>
    <p id="Par38">As there are more vailable base-resolution datasets, researchers have designed some computational methods for RNA modification site prediction. These approaches formulate RNA methylation identification as a binary prediction task, and some machine learning models are trained to distinguish between truly methylated and non-methylated sites. These computational methods have been powerful additions for RNA methylation site prediction.</p>
    <p id="Par39">Traditional methods designed for sequence-based prediction usually first extract features based on human-understandable feature methods and then use a classifier to identify if the site is methylated based on the preceding extracted features. Specifically, RAMPred [<xref ref-type="bibr" rid="CR14">14</xref>] adopts the support vector machine(SVM) to predict the m<sup>1</sup>A modification site, extracting features based on nucleotide composition(NC) and nucleotide chemical properties(NCP). iRNA-3typeA [<xref ref-type="bibr" rid="CR15">15</xref>] adopts SVM to predict m<sup>1</sup>A, A-to-I, and m<sup>6</sup>A modification sites, which extracts features based on accumulated nucleotide frequency(ANF) and NCP. iMRM [<xref ref-type="bibr" rid="CR16">16</xref>] extracts features based on NCP, NC, Nucleotide Density(ND), Dinucleotide physicochemical properties(DPCP), and Dinucleotide Binary Encoding(DBE) and employs XGboost to predict m<sup>1</sup>A, m<sup>6</sup>A, m<sup>5</sup>C, ψ, and A-to-I modification sites. The above sequence features are artificially extracted, and inevitably important features of the sequences are missed due to human cognitive limitations.</p>
    <p id="Par40">Analyzing biological sequences and interpreting biological information are the key challenges in achieving biological discovery. The application of natural language processing(NLP) to sequence analysis has attracted considerable attention in processing biological sequences [<xref ref-type="bibr" rid="CR17">17</xref>]. As biological sequences can be considered sentences, and k-mer subsequences are regarded as words [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>], NLP can be used to understand the structure and function encoded in these sequences [<xref ref-type="bibr" rid="CR17">17</xref>]. Unlike traditional machine learning, deep learning (DL) methods follow an end-to-end design. Features are extracted directly based on the input sequence and the final labeling/prediction task. For example, EDLm6Apred [<xref ref-type="bibr" rid="CR20">20</xref>] employs bidirectional long short-term memory (BiLSTM) to predict m<sup>6</sup>A sites, extracting features based on Word2vec, RNA word embedding [<xref ref-type="bibr" rid="CR21">21</xref>], and one-hot encoding [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. However, LSTM, BiLSTM, and RNN cannot achieve parallel computation, leading to a long training time.</p>
    <p id="Par41">CNN can achieve parallel computation and learn local dependencies. For instance, m6A-word2vec [<xref ref-type="bibr" rid="CR24">24</xref>] adopts CNN to identify m<sup>6</sup>A sites, extracting features based on Word2vec. Deeppromise [<xref ref-type="bibr" rid="CR25">25</xref>] employs CNN to identify m<sup>1</sup>A and m<sup>6</sup>A sites, extracting features based on integrated enhanced nucleic acid composition (ENAC) [<xref ref-type="bibr" rid="CR26">26</xref>], one-hot encoding, and RNA word embedding. However, These CNN structures only consider the contextual relationships of neighboring bases without considering the dependencies over long distances in the sequence. DeepM6ASeq [<xref ref-type="bibr" rid="CR27">27</xref>] combines the advantages of CNN and BiLSTM by using two layers of CNN and one layer of BiLSTM to predict m<sup>6</sup>A sites. This approach may extract redundant features that interfere with prediction performance [<xref ref-type="bibr" rid="CR28">28</xref>]. The attention mechanism can quantify the degree of code-to-code dependency [<xref ref-type="bibr" rid="CR29">29</xref>]. Therefore, the application of the attention mechanism can capture the focused codes that affect the classification results. Plant6mA [<xref ref-type="bibr" rid="CR30">30</xref>] utilizes a Transformer encoder to determine whether the input sequence contains an m6A site. However, due to the unique feature representation of transformers, these networks are primarily employed at a single scale. Although a single-scale self-attentive mechanism can focus on essential features of sequence context, it lacks information interaction with sequences at different scales. It isn't easy to learn complex word context relationships.</p>
    <p id="Par42">At present, most prediction model studies focus only on a single methylation modification, and few share the same binary classification model framework to achieve different methylation modification predictions. Even fewer cross-modification validation studies have been performed with different methylation test sets and trained models. Accounting for potential interactions between various RNA modifications, it would be interesting to use the same model to conduct cross-modification validation studies across different methylation test sets.</p>
    <p id="Par43">We present the Multi-scale Self- and Cross-attention Network (MSCAN), a novel approach designed to identify RNA methylation sites, addressing the challenges associated with current methods. Our model supports identifying twelve RNA modification types, including m<sup>6</sup>A, Ψ, m<sup>1</sup>A, m<sup>6</sup>Am, Am, Cm, m<sup>7</sup>G, Gm, Um, I, m<sup>5</sup>U, and m<sup>5</sup>C.</p>
    <p id="Par44">The MSCAN employs a unique multi-scale approach for analyzing RNA sequences. Specifically, we extracted the input 41-nucleotides (nt) sample sequence into multiple smaller subsequences centered around the sequence midpoint. To ensure accurate identification of methylation sites, the MSCAN analyzes these smaller subsequences at two distinct scales: 21-nt and 31-nt. This multi-scale analysis allows for a more comprehensive understanding of the RNA sequence context, ultimately leading to improved prediction performance. Secondly, word2vec was used to encode the three sets of sequences. Third, the three sets of sequences add positional information due to the correlation between nucleotide positions in the sequence. Four, the three sets of sequences were fed into the encoding module, which was constructed with a multi-scale self- and cross-attention network and a feed-forward network(FFN) to extract potential contributing features for methylation site prediction. Finally, methylation predicted probabilities were obtained through a linear layer and the sigmoid function. The findings demonstrated that the MSCAN model surpassed the performance of state-of-the-art methods, including m6A-word2vec, DeepM6ASeq, and Plant6mA in independent tests. A user-friendly web server for MSCAN is available at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
  </sec>
  <sec id="Sec3">
    <title>Result</title>
    <sec id="Sec4">
      <title>Evaluation metrics</title>
      <p id="Par45">In this study, we used eight common classification indicators to evaluate the prediction of the model, including Accuracy (Acc), Sensitivity (Sen), Precision (Pre), Matthews correlation coefficient (MCC), Specificity (Sp), and F1 score (F1). The formulas of these metrics are as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sensitivity,\;Recall = \frac{TP}{{TP + FN}}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.277778em"/><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Specificity = \frac{TN}{{TN + FP}}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Accuracy = \frac{TP + TN}{{TP + TN + FP + FN}}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Precision = \frac{TP}{{TP + FP}}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1 \, score = 2 \times \frac{Precision \times Recall}{{Precision + Recall}}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mspace width="0.166667em"/><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MCC = \frac{TP \times TN - FP \times FN}{{\sqrt {(TP + FP) \times (TP + FN) \times (TN + FP) \times (TN + FN)} }}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par46">Here, the true positive, true negative, false positive, and false negative are represented as TP, TN, FP, and FN, respectively. Moreover, the area under the receiver operating characteristic (AUROC) and the area under the precision-recall curve (AUPRC) are used to visually evaluate the model's overall performance.</p>
    </sec>
    <sec id="Sec5">
      <title>Results analysis</title>
      <p id="Par47">MSCAN completed model training and experimental parameter optimization based on the dataset of Chen et al. [<xref ref-type="bibr" rid="CR25">25</xref>]. Subsequently, MSCAN completed the model's generalization ability evaluation based on the dataset of Song et al. [<xref ref-type="bibr" rid="CR5">5</xref>]. Specifically, based on the dataset of Chen et al., this paper first compared the performance of MSCAN with different combinations of input sequences on the training data. Second, the performance of MSCAN with different feature encoding was compared. Third, we compared the performance of different MSCAN model variants. Fourth, the MSCAN was compared with state-of-the-art models based on the training data and the independent dataset of Chen et al. Fifth, the statistical significance of AUPRC values between the four models is compared. Sixth, MSCAN completed a generalization ability evaluation based on the dataset of Song et al., and MSCAN outperformed the state-of-the-art predictors for twelve modification sites. Finally, We designed a cross-modification validation experiment in which twelve models with different methylation types were compared for prediction performance based on twelve test sets, respectively. Our experiments were conducted with two Intel(R) 5218 CPUs, two RTX2080Ti GPUs, and Pytorch version 1.4.0+cu92.</p>
      <p id="Par48">Based on the training data of Chen et al., we first tried optimizing the input sequences' length according to AUPRC on the training data. Using the Word2vec embedding, we evaluated the Transformer model with 11-nt, 21-nt, 31-nt, 41-nt,51-nt,61-nt,71-nt,81-nt,91-nt,and 101-nt RNA sequences as the input on the five-fold cross-validation [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR25">25</xref>]. As shown in Table <xref rid="Tab1" ref-type="table">1</xref>, the input of the 11-nt sequence obtained the worst performance. The reason may be that too few bases in the 11-nt sequence affect feature extraction. The input of the 41-bp sequence obtained the best average performance of all the modifications, It may be worth mentioning that the 41-nt of the input sequence is also optimal for the XGboost and SVM method [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], so we choose 21-nt, 31-nt, and 41-nt RNA sequences as input sequences to achieve different combinations of input sequences.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Evaluation results of five-fold cross-validation of transformer based on the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Length(nt)</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">11</td><td char="." align="char">0.8955</td><td char="." align="char">93.55</td><td char="." align="char">44.26</td><td char="." align="char"><bold>77.14</bold></td><td char="." align="char">55.44</td><td char="." align="char"><bold>98.65</bold></td><td char="." align="char">56.25</td><td char="." align="char">0.6389</td></tr><tr><td align="left">21</td><td char="." align="char">0.9213</td><td char="." align="char"><bold>95.01</bold></td><td char="." align="char">59.81</td><td char="." align="char">74.42</td><td char="." align="char">64.11</td><td char="." align="char">98.16</td><td char="." align="char">66.32</td><td char="." align="char">0.7189</td></tr><tr><td align="left">31</td><td char="." align="char">0.9361</td><td char="." align="char">93.55</td><td char="." align="char">64.80</td><td char="." align="char">66.94</td><td char="." align="char">62.31</td><td char="." align="char">96.61</td><td char="." align="char">65.85</td><td char="." align="char">0.7390</td></tr><tr><td align="left">41</td><td char="." align="char"><bold>0.9484</bold></td><td char="." align="char">93.48</td><td char="." align="char"><bold>74.36</bold></td><td char="." align="char">61.27</td><td char="." align="char">63.97</td><td char="." align="char">95.37</td><td char="." align="char">67.18</td><td char="." align="char"><bold>0.7469</bold></td></tr><tr><td align="left">51</td><td char="." align="char">0.9401</td><td char="." align="char">94.63</td><td char="." align="char">61.54</td><td char="." align="char">74.23</td><td char="." align="char">64.73</td><td char="." align="char">97.89</td><td char="." align="char">67.29</td><td char="." align="char">0.7401</td></tr><tr><td align="left">61</td><td char="." align="char">0.9430</td><td char="." align="char">94.56</td><td char="." align="char">67.27</td><td char="." align="char">67.89</td><td char="." align="char">64.61</td><td char="." align="char">97.07</td><td char="." align="char">67.58</td><td char="." align="char">0.7078</td></tr><tr><td align="left">71</td><td char="." align="char">0.9249</td><td char="." align="char">93.64</td><td char="." align="char">67.21</td><td char="." align="char">65.60</td><td char="." align="char">62.89</td><td char="." align="char">96.36</td><td char="." align="char">66.40</td><td char="." align="char">0.7272</td></tr><tr><td align="left">81</td><td char="." align="char">0.9440</td><td char="." align="char">94.94</td><td char="." align="char">70.00</td><td char="." align="char">66.04</td><td char="." align="char"><bold>65.25</bold></td><td char="." align="char">97.01</td><td char="." align="char"><bold>67.96</bold></td><td char="." align="char">0.7170</td></tr><tr><td align="left">91</td><td char="." align="char">0.9327</td><td char="." align="char">94.93</td><td char="." align="char">60.19</td><td char="." align="char">73.86</td><td char="." align="char">64.01</td><td char="." align="char">98.08</td><td char="." align="char">66.33</td><td char="." align="char">0.7119</td></tr><tr><td align="left">101</td><td char="." align="char">0.9230</td><td char="." align="char">93.33</td><td char="." align="char">70.94</td><td char="." align="char">61.03</td><td char="." align="char">62.16</td><td char="." align="char">95.53</td><td char="." align="char">65.61</td><td char="." align="char">0.7449</td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par49">The combination of input sequences with different scale order is an important parameter that affects the performance of the training model. The performance of the MSCAN model with the different combinations of input sequences on the training data is shown in Table <xref rid="Tab2" ref-type="table">2</xref>. MSCAN shows the best prediction performance when the combination is “21-nt + 41-nt + 31-nt”. According to the MSCAN model design, “21-nt + 41-nt + 31-nt” input sequences are entered into the model to implement three attention mechanisms, including the self-attention calculation mechanism for the 21-nt sequence, and the cross-attention calculation mechanisms for both “21-nt + 41-nt” and “21-nt + 31-nt” combinatorial sequences.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Evaluation results of MSCAN on five-fold cross-validation with different input sequences based on the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">combinations of sequences(nt)</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">21 + 31 + 41</td><td char="." align="char">0.9491</td><td char="." align="char"><bold>95.24</bold></td><td char="." align="char">58.59</td><td char="." align="char">73.42</td><td char="." align="char">63.11</td><td char="." align="char">98.26</td><td char="." align="char">65.17</td><td char="." align="char">0.7695</td></tr><tr><td align="left">21 + 41 + 31</td><td char="." align="char"><bold>0.9618</bold></td><td char="." align="char">94.86</td><td char="." align="char">59.69</td><td char="." align="char"><bold>83.70</bold></td><td char="." align="char"><bold>68.11</bold></td><td char="." align="char"><bold>98.72</bold></td><td char="." align="char">69.68</td><td char="." align="char"><bold>0.7949</bold></td></tr><tr><td align="left">31 + 21 + 41</td><td char="." align="char">0.9257</td><td char="." align="char">94.63</td><td char="." align="char">55.93</td><td char="." align="char">78.57</td><td char="." align="char">63.59</td><td char="." align="char">98.48</td><td char="." align="char">65.34</td><td char="." align="char">0.7419</td></tr><tr><td align="left">31 + 41 + 21</td><td char="." align="char">0.9463</td><td char="." align="char">95.09</td><td char="." align="char"><bold>68.47</bold></td><td char="." align="char">72.38</td><td char="." align="char">67.73</td><td char="." align="char">97.57</td><td char="." align="char"><bold>70.37</bold></td><td char="." align="char">0.7632</td></tr><tr><td align="left">41 + 21 + 31</td><td char="." align="char">0.9318</td><td char="." align="char">94.55</td><td char="." align="char">63.87</td><td char="." align="char">73.08</td><td char="." align="char">65.38</td><td char="." align="char">97.64</td><td char="." align="char">68.17</td><td char="." align="char">0.7617</td></tr><tr><td align="left">41 + 31 + 21</td><td char="." align="char">0.9427</td><td char="." align="char">93.86</td><td char="." align="char">65.41</td><td char="." align="char">71.90</td><td char="." align="char">65.20</td><td char="." align="char">97.10</td><td char="." align="char">68.50</td><td char="." align="char">0.7642</td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec6">
      <title>Comparison analysis of different feature encoding methods</title>
      <p id="Par50">In this section, we evaluate the performance of three distinct feature encoding methods—Word2vec, One-hot, and ENAC—utilizing the same MSCAN model for predicting m<sup>1</sup>A sites on the test data of Chen et al. The outcomes of this comparison are presented in Fig. <xref rid="Fig1" ref-type="fig">1</xref> and Table <xref rid="Tab3" ref-type="table">3</xref>, demonstrating that Word2vec consistently surpasses the other two encoding methods across all performance indices.<fig id="Fig1"><label>Fig. 1</label><caption><p>Performance of the MSCAN model based on the different feature encoding</p></caption><graphic xlink:href="12859_2024_5649_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>MSCAN model evaluation results with different feature encodings based on the test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Encoding</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">One-hot</td><td char="." align="char">0.9089</td><td char="." align="char">95.13</td><td char="." align="char">55.26</td><td char="." align="char">86.30</td><td char="." align="char">66.77</td><td char="." align="char">99.12</td><td char="." align="char">67.38</td><td char="." align="char">0.7294</td></tr><tr><td align="left">ENAC</td><td char="." align="char">0.9212</td><td char="." align="char">94.81</td><td char="." align="char">55.26</td><td char="." align="char">81.82</td><td char="." align="char">64.71</td><td char="." align="char">98.77</td><td char="." align="char">65.97</td><td char="." align="char">0.7322</td></tr><tr><td align="left">Word2vec</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char"><bold>58.77</bold></td><td char="." align="char"><bold>90.54</bold></td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char"><bold>99.39</bold></td><td char="." align="char"><bold>71.28</bold></td><td char="." align="char"><bold>0.7890</bold></td></tr></tbody></table><table-wrap-foot><p>Bold Indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par51">The superior performance of Word2vec can be attributed to the limitations of the One-hot and ENAC encoding methods. While One-hot encoding focuses on the local information of individual bases, and ENAC encoding considers both nucleic acid composition and position information, both methods neglect the semantic information inherent in the sequence context. In contrast, Word2vec prioritizes the contextual relationships between bases, resulting in a more effective representation of the sequence.</p>
      <p id="Par52">Our findings highlight the importance of selecting appropriate feature encoding methods for improved prediction accuracy, with Word2vec emerging as a particularly advantageous choice for the MSCAN model in the context of RNA methylation site prediction.</p>
    </sec>
    <sec id="Sec7">
      <title>Comparison with different variants of the MSCAN model</title>
      <p id="Par53">We conducted ablation experiments to assess the contribution of key components within our proposed MSCAN model based on the test data of Chen et al. Utilizing Word2vec for RNA sequence encoding, we constructed four sub-networks: self- and cross-attention network (SCAN), self-attention network (SAN), multi-scale cross-attention network (MCAN), and cross-attention network (CAN). SCAN represents MSCAN with one cross-attention module removed, SAN is SCAN devoid of cross-attention, MCAN is MSCAN without self-attention, and CAN is MCAN with one cross-attention module removed. The outcomes of these experiments are depicted in Fig. <xref rid="Fig2" ref-type="fig">2</xref> and summarized in Table <xref rid="Tab4" ref-type="table">4</xref>.<fig id="Fig2"><label>Fig. 2</label><caption><p>Performance of MSCAN and variant model on the test data</p></caption><graphic xlink:href="12859_2024_5649_Fig2_HTML" id="MO2"/></fig><table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparing MSCAN and variant model evaluation results based on test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">SAN</td><td char="." align="char">0.9321</td><td char="." align="char">95.05</td><td char="." align="char">55.26</td><td char="." align="char">85.14</td><td char="." align="char">66.24</td><td char="." align="char">99.04</td><td char="." align="char">67.02</td><td char="." align="char">0.7604</td></tr><tr><td align="left">SCAN</td><td char="." align="char">0.9277</td><td char="." align="char">95.29</td><td char="." align="char">53.51</td><td char="." align="char"><bold>91.04</bold></td><td char="." align="char">67.73</td><td char="." align="char"><bold>99.47</bold></td><td char="." align="char">67.40</td><td char="." align="char">0.7613</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char"><bold>58.77</bold></td><td char="." align="char">90.54</td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char">99.39</td><td char="." align="char"><bold>71.28</bold></td><td char="." align="char"><bold>0.7890</bold></td></tr><tr><td align="left">CAN</td><td char="." align="char">0.9299</td><td char="." align="char">94.89</td><td char="." align="char">52.63</td><td char="." align="char">85.71</td><td char="." align="char">64.81</td><td char="." align="char">99.12</td><td char="." align="char">65.21</td><td char="." align="char">0.7688</td></tr><tr><td align="left">MCAN</td><td char="." align="char">0.9270</td><td char="." align="char">94.81</td><td char="." align="char">55.26</td><td char="." align="char">81.82</td><td char="." align="char">64.71</td><td char="." align="char">98.77</td><td char="." align="char">65.97</td><td char="." align="char">0.7586</td></tr></tbody></table><table-wrap-foot><p>Bold Indicates the best performance</p><p>SAN contains only self-attention; SCAN, and MSCAN are combinations of self- and cross-attention; CAN and MCAN are combinations of only cross-attention</p></table-wrap-foot></table-wrap></p>
      <p id="Par54">SAN serves as the baseline model in this comparison. Upon the integration of cross-attention modules, the area under the precision-recall curve (AUPRC) for SCAN and MSCAN models increased by 0.09% and 2.86%, respectively. These results highlight the importance of incorporating cross-attention mechanisms within the MSCAN model for improved performance in predicting RNA methylation sites. Consequently, our findings emphasize the value of the multi-scale self- and cross-attention approach employed by MSCAN in advancing the understanding of RNA modifications and their functional implications.</p>
    </sec>
    <sec id="Sec8">
      <title>Comparison with state-of-the-art approaches</title>
      <p id="Par55">We compared MSCAN with several state-of-the-art models, including m6A-word2vec, DeepM6ASeq, and Plant6mA. To ensure robust evaluation, we employed a fivefold cross-validation on the training data of Chen et al. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref> and Table <xref rid="Tab5" ref-type="table">5</xref>, Our results demonstrate that MSCAN outperforms the other models, substantially improving prediction accuracy.<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance of the different models on the training data</p></caption><graphic xlink:href="12859_2024_5649_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab5"><label>Table 5</label><caption><p>Evaluation results of MSCAN and other state-of-the-art models based on five-fold cross-validation using the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9001</td><td char="." align="char">93.30</td><td char="." align="char">53.79</td><td char="." align="char">66.18</td><td char="." align="char">56.10</td><td char="." align="char">97.25</td><td char="." align="char">59.35</td><td char="." align="char">0.6505</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.8735</td><td char="." align="char">93.38</td><td char="." align="char">46.49</td><td char="." align="char">70.67</td><td char="." align="char">54.02</td><td char="." align="char">98.07</td><td char="." align="char">56.08</td><td char="." align="char">0.6279</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.9482</td><td char="." align="char">93.48</td><td char="." align="char"><bold>74.36</bold></td><td char="." align="char">61.27</td><td char="." align="char">63.97</td><td char="." align="char">95.37</td><td char="." align="char">67.18</td><td char="." align="char">0.7465</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9618</bold></td><td char="." align="char"><bold>94.86</bold></td><td char="." align="char">59.69</td><td char="." align="char"><bold>83.70</bold></td><td char="." align="char"><bold>68.11</bold></td><td char="." align="char"><bold>98.72</bold></td><td char="." align="char"><bold>69.68</bold></td><td char="." align="char"><bold>0.7949</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par56">In particular, MSCAN achieves a 4.84% enhancement in the AUPRC metric compared to the second-best performing model, Plant6mA. This superior performance can be attributed to utilizing the multi-scale self- and cross-attention mechanisms in MSCAN, as opposed to the self-attention mechanism employed by Plant6mA. The results underscore the effectiveness of MSCAN in identifying RNA methylation sites.</p>
      <p id="Par57">Next, we compare the performance of MSCAN with other state-of-the-art models using the test data of Chen et al. The results, as illustrated in Fig. <xref rid="Fig4" ref-type="fig">4</xref> and summarized in Table <xref rid="Tab6" ref-type="table">6</xref>, demonstrate the superior performance of MSCAN in predicting RNA methylation sites.<fig id="Fig4"><label>Fig. 4</label><caption><p>The ROC and PRC of MSCAN and other state-of-the-art models on the test data</p></caption><graphic xlink:href="12859_2024_5649_Fig4_HTML" id="MO4"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption><p>Evaluation results of MSCAN and other state-of-the-art models based on the test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9327</td><td char="." align="char">93.62</td><td char="." align="char"><bold>67.54</bold></td><td char="." align="char">64.17</td><td char="." align="char">62.32</td><td char="." align="char">90.43</td><td char="." align="char">65.81</td><td char="." align="char">0.7650</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.9257</td><td char="." align="char">95.37</td><td char="." align="char">65.79</td><td char="." align="char">79.79</td><td char="." align="char">70.00</td><td char="." align="char">98.33</td><td char="." align="char"><bold>72.12</bold></td><td char="." align="char">0.7743</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.9298</td><td char="." align="char">95.13</td><td char="." align="char">56.14</td><td char="." align="char">85.33</td><td char="." align="char">66.89</td><td char="." align="char">99.04</td><td char="." align="char">67.72</td><td char="." align="char">0.7676</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char">58.77</td><td char="." align="char"><bold>90.54</bold></td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char"><bold>99.39</bold></td><td char="." align="char">71.28</td><td char="." align="char"><bold>0.7890</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par58">MSCAN outperforms DeepM6ASeq and m6A-word2vec by 1.47% and 2.4% in terms of AUPRC, respectively. This enhanced performance can be attributed to the multi-scale self- and cross-attention network's ability to capture meaningful sequence encodings for more accurate classification. Furthermore, MSCAN surpasses Plant6mA by 2.14% in AUPRC, which may further verify the limitations of the single-scale self-attention mechanism in learning complex contextual relationships between sequence elements. The integration of the cross-attention mechanism enables the model to discern deeper sequence meanings, thus improving its performance.</p>
    </sec>
    <sec id="Sec9">
      <title>Assessing model reliability</title>
      <p id="Par59">To evaluate the reliability of our proposed model, we performed one hundred replications of experiments using the test data from Chen et al., evaluating the m6A-word2vec, DeepM6ASeq, Plant6mA, and MSCAN models. In each replication, we used the same test data and ran each model under identical conditions to ensure experimental consistency.</p>
      <p id="Par60">To evaluate the statistical significance of AUPRC values between different methods, we employed Student's t-test [<xref ref-type="bibr" rid="CR31">31</xref>]. This statistical method helps determine whether performance differences between different methods are significant. Table <xref rid="Tab7" ref-type="table">7</xref> below shows the <italic>p</italic> values for the difference in the performance of the four classifiers.
<table-wrap id="Tab7"><label>Table 7</label><caption><p>A statistically significant correlation matrix for the difference in the performance of the four classifiers</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Classifiers</th><th align="left" colspan="4">Classifiers</th></tr><tr><th align="left">m6A-word2vec</th><th align="left">DeepM6ASeq</th><th align="left">Plant6mA</th><th align="left">MSCAN</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">DeepM6ASeq</td><td align="left">0.001243</td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">Plant6mA</td><td align="left">2.905E−44</td><td align="left">8.01217E−35</td><td align="left"/><td align="left"/></tr><tr><td align="left">MSCAN</td><td align="left">4.71415E−64</td><td align="left">1.25245E−58</td><td align="left">0</td><td align="left"/></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec10">
      <title>Assessing model generalization ability</title>
      <p id="Par61">Based on the data set of Song et al., the generalization ability of MSCAN was evaluated by training the model individually for each methylation type. As presented in Table <xref rid="Tab8" ref-type="table">8</xref>, the MSCAN model consistently outperforms state-of-the-art models, including m6A-word2vec, DeepM6ASeq, and Plant6mA. This result provides empirical evidence of the model's generalizability across diverse methylation site prediction tasks.
<table-wrap id="Tab8"><label>Table 8</label><caption><p>Compare MSCAN to other methods under AUC</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">m<sup>6</sup>A</th><th align="left">Ψ</th><th align="left">m<sup>1</sup>A</th><th align="left">m<sup>6</sup>Am</th><th align="left">Am</th><th align="left">Cm</th><th align="left">Gm</th><th align="left">Um</th><th align="left">m<sup>5</sup>C</th><th align="left">m<sup>7</sup>G</th><th align="left">m<sup>5</sup>U</th><th align="left">I</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9773</td><td char="." align="char">0.7060</td><td char="." align="char">0.8385</td><td char="." align="char">0.9867</td><td char="." align="char">0.9174</td><td char="." align="char">0.9120</td><td char="." align="char">0.9554</td><td char="." align="char">0.8467</td><td char="." align="char">0.9611</td><td char="." align="char">0.7505</td><td char="." align="char">0.9499</td><td char="." align="char">0.6180</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.9752</td><td char="." align="char">0.7510</td><td char="." align="char">0.8289</td><td char="." align="char">0.9837</td><td char="." align="char">0.9213</td><td char="." align="char">0.9173</td><td char="." align="char">0.9538</td><td char="." align="char">0.8716</td><td char="." align="char">0.9675</td><td char="." align="char">0.7527</td><td char="." align="char">0.9584</td><td char="." align="char">0.5872</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.5964</td><td char="." align="char">0.5478</td><td char="." align="char">0.7268</td><td char="." align="char">0.7826</td><td char="." align="char">0.8110</td><td char="." align="char">0.8016</td><td char="." align="char">0.8279</td><td char="." align="char">0.7847</td><td char="." align="char">0.6806</td><td char="." align="char">0.6690</td><td char="." align="char">0.9528</td><td char="." align="char">0.5137</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9834</bold></td><td char="." align="char"><bold>0.7622</bold></td><td char="." align="char"><bold>0.8541</bold></td><td char="." align="char"><bold>0.9904</bold></td><td char="." align="char"><bold>0.9292</bold></td><td char="." align="char"><bold>0.9203</bold></td><td char="." align="char"><bold>0.9577</bold></td><td char="." align="char"><bold>0.8966</bold></td><td char="." align="char"><bold>0.9729</bold></td><td char="." align="char"><bold>0.7994</bold></td><td char="." align="char"><bold>0.9674</bold></td><td char="." align="char"><bold>0.6569</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par62">Theoretically, the self- and cross-attention mechanism employed by the MSCAN model enables it to capture long-range dependencies and complex interactions between input features more effectively than other models, such as Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). This characteristic is particularly advantageous in discerning biologically relevant patterns in methylation site prediction, which may contribute to the model's enhanced generalizability.</p>
    </sec>
    <sec id="Sec11">
      <title>Comparison with cross-modification validation approaches</title>
      <p id="Par63">Thus far, our results have demonstrated the model's robust classification performance. Notably, a significant advantage of the proposed MSCAN model is its ability to learn the underlying associations among different RNA modifications. Previous studies have revealed clear evolutionary and functional cross-talk among various post-translational modifications of proteins [<xref ref-type="bibr" rid="CR32">32</xref>] and histone and chromatin modifications [<xref ref-type="bibr" rid="CR33">33</xref>]. Such associations might also exist at the epi-transcriptome level among different RNA modifications.</p>
      <p id="Par64">To better understand the inherent shared structures among different RNA modifications, we performed cross-modification validation on the second dataset. The resulting AUROC values are displayed in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. As the figure shows, cross-modification validation yielded poorer prediction results than those obtained using modification-consistent data and models, indicating the specificity of our method for a particular modification.<fig id="Fig5"><label>Fig. 5</label><caption><p>Heat map of different AUROC values in cross-methylation validation. The horizontal axis is the model type, and the vertical axis is the test data type</p></caption><graphic xlink:href="12859_2024_5649_Fig5_HTML" id="MO5"/></fig></p>
      <p id="Par65">Interestingly, in experiments where the test dataset and model were inconsistent, some groups achieved high AUROC values greater than 0.85, suggesting strong and significant positive associations among certain RNA modifications, even those originating from different nucleotides. This observation implies the existence of regions intensively modified by multiple RNA modifications, which likely serve as key regulatory components for the epi-transcriptome layer of gene regulation. Notably, the sequence signatures of these key regulatory regions are largely shared among different RNA modifications (including those that modify different nucleotides) and were successfully captured by our model. As presented in Table <xref rid="Tab9" ref-type="table">9</xref>, the most strongly associated modifications originated from the same type of base, with A and G belonging to purine-like bases, and C and U belonging to pyrimidine bases.
<table-wrap id="Tab9"><label>Table 9</label><caption><p>Association of RNA modifications revealed by MSCAN</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Model</th><th align="left">AUROC</th><th align="left">AUPRC</th><th align="left">ACC</th><th align="left">Dataset</th><th align="left">Model</th><th align="left">AUROC</th><th align="left">AUPRC</th><th align="left">ACC</th></tr></thead><tbody><tr><td align="left">Am</td><td align="left">Am</td><td char="." align="char">0.9292</td><td char="." align="char">0.9231</td><td char="." align="char">86.36</td><td align="left">Gm</td><td align="left">Gm</td><td char="." align="char">0.9577</td><td char="." align="char">0.9637</td><td char="." align="char">88.33</td></tr><tr><td align="left">Gm</td><td align="left">Am</td><td char="." align="char">0.9082</td><td char="." align="char">0.9233</td><td char="." align="char">81.11</td><td align="left">Am</td><td align="left">Gm</td><td char="." align="char">0.8695</td><td char="." align="char">0.8809</td><td char="." align="char">80.16</td></tr><tr><td align="left">Cm</td><td align="left">Am</td><td char="." align="char">0.8724</td><td char="." align="char">0.8906</td><td char="." align="char">73.51</td><td align="left">Cm</td><td align="left">Gm</td><td char="." align="char">0.8083</td><td char="." align="char">0.8280</td><td char="." align="char">72.18</td></tr><tr><td align="left">Um</td><td align="left">Am</td><td char="." align="char">0.7884</td><td char="." align="char">0.7839</td><td char="." align="char">60.00</td><td align="left">Um</td><td align="left">Gm</td><td char="." align="char">0.7387</td><td char="." align="char">0.7659</td><td char="." align="char">66.34</td></tr><tr><td align="left">Cm</td><td align="left">Cm</td><td char="." align="char">0.9203</td><td char="." align="char">0.9273</td><td char="." align="char">83.44</td><td align="left">Um</td><td align="left">Um</td><td char="." align="char">0.8966</td><td char="." align="char">0.8756</td><td char="." align="char">82.92</td></tr><tr><td align="left">Um</td><td align="left">Cm</td><td char="." align="char">0.8647</td><td char="." align="char">0.8514</td><td char="." align="char">79.75</td><td align="left">Cm</td><td align="left">Um</td><td char="." align="char">0.8859</td><td char="." align="char">0.8739</td><td char="." align="char">81.78</td></tr><tr><td align="left">Am</td><td align="left">Cm</td><td char="." align="char">0.8830</td><td char="." align="char">0.8862</td><td char="." align="char">72.31</td><td align="left">Am</td><td align="left">Um</td><td char="." align="char">0.8458</td><td char="." align="char">0.8282</td><td char="." align="char">78.51</td></tr><tr><td align="left">Gm</td><td align="left">Cm</td><td char="." align="char">0.8865</td><td char="." align="char">0.9070</td><td char="." align="char">69.44</td><td align="left">Gm</td><td align="left">Um</td><td char="." align="char">0.8480</td><td char="." align="char">0.8589</td><td char="." align="char">76.66</td></tr></tbody></table></table-wrap></p>
      <p id="Par66">To further verify this finding, we compared Am, Gm, Cm, and Um correlations through local BLAST [<xref ref-type="bibr" rid="CR34">34</xref>] software. First, the Am, Gm, and Cm comparison libraries are established based on the Am data set, Gm data set, and Cm data set respectively. Secondly, the Am, Gm, Cm, and Um data sets are used to compare the comparison libraries with different methylation in pairs. Then, the BLAST output table is obtained. Finally, compare the average value of the comparison result "bit-score". As shown in Table <xref rid="Tab10" ref-type="table">10</xref>, the average bit-score value of the Gm sequence compared to the Am comparison library is high, indicating that the Am sequence and the Gm sequence are highly similar. Similarly, the average bit-score value of the Um sequence compared to the Cm comparison library is high, indicating that the Um sequence and Cm sequence similarity is high, which may validate the idea that the most closely related modifications originate from the same type of bases.
<table-wrap id="Tab10"><label>Table 10</label><caption><p>Compare the average bit-score of various methylated sequences</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Query subject</th><th align="left">Am</th><th align="left">Gm</th><th align="left">Cm</th><th align="left">Um</th></tr></thead><tbody><tr><td align="left">Am</td><td align="left"/><td char="." align="char">9.679614</td><td char="." align="char">5.866832</td><td char="." align="char">3.30773</td></tr><tr><td align="left">Gm</td><td align="left"/><td char="." align="char"/><td char="." align="char">3.357072</td><td char="." align="char">1.639136</td></tr><tr><td align="left">Cm</td><td align="left"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char">8.793488</td></tr><tr><td align="left">Um</td><td align="left"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char"/></tr></tbody></table></table-wrap></p>
      <p id="Par67">Our model provides experimental verification of the existence of an inherent shared structure between different RNA modifications. These findings underscore the potential of the MSCAN model in advancing our understanding of the complex interplay between various RNA modifications and their functional implications.</p>
    </sec>
    <sec id="Sec12">
      <title>Web server</title>
      <p id="Par68">We have developed a user-friendly web server for predicting twelve widely occurring human RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um), accessible at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>, to facilitate the use of the MSCAN model for RNA methylation site prediction. Take the step of predicting the m<sup>1</sup>A methylation site as an example. First, click the “Prediction” button and select the “m<sup>1</sup>A” successively. Next, type or paste the RNA sequence, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>a. Third, leave your email address in the input box and click the “submit” button. After a calculation period, the prediction results will be displayed in a table, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>b. This intuitive web server offers researchers an efficient and convenient platform for employing the MSCAN model in their investigations of RNA modifications and their functional implications.<fig id="Fig6"><label>Fig. 6</label><caption><p>Webserver interface. a. Input interface. b. Prediction result</p></caption><graphic xlink:href="12859_2024_5649_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Discussion</title>
    <p id="Par69">First, based on the test data of Chen et al., we compared the performance of various features based on the MSCAN model, including One-hot encoding, ENAC, and Word2vec. The results reveal that Word2vec outperforms One-hot and ENAC in predicting AUROC and AUPRC. Specifically, the AUPRC of MSCAN<sub>word2vec</sub> is 5.96% and 5.68% higher than that of MSCAN<sub>One-hot</sub> and MSCAN<sub>ENAC</sub>, respectively. These findings are in line with Zhang et al.'s study [<xref ref-type="bibr" rid="CR20">20</xref>], which highlights that One-hot focuses on local semantic information while ENAC only considers the sequence's nucleic acid composition and position, neglecting more profound semantic information. Conversely, Word2vec captures the contextual semantic information of the sequence, significantly enhancing the model's predictive capability.</p>
    <p id="Par70">Second, based on the test data of Chen et al., we assessed the impact of various MSCAN components by comparing the performance of different MSCAN variants, such as SCAN, SAN, MCAN, and CAN. Experimental results show that MSCAN reduces AUPRC by 3.04% and 2.77% respectively after deleting a self-attention module or a cross-attention module. This finding is consistent with Sun et al.'s study [<xref ref-type="bibr" rid="CR35">35</xref>], which posits that the removal of self- or cross-attention modules leads to diminished model performance. When both the Multi-Scale and cross-attention modules are removed, the AUPRC of MSCAN decreases by 2.86%. This result aligns with Chen et al.'s study [<xref ref-type="bibr" rid="CR36">36</xref>], which emphasizes that cross-attention effectively learns multi-scale transformer features for data recognition.</p>
    <p id="Par71">Third, we compared the performance of m6A-word2vec, DeepM6ASeq, Plant6mA, and MSCAN based on the test data of Chen et al. MSCAN's AUROC and AUPRC outperformed the other three state-of-the-art models. In particular, MSCAN surpassed Plant6mA by 2.14% in terms of AUPRC. This study substantiates that the utilization of multi-scale input and cross-attention allows the model to extract diverse features and provide deep semantics, which Plant6mA cannot achieve through information fusion from multiple scales. This conclusion is supported by Guo et al.'s study [<xref ref-type="bibr" rid="CR37">37</xref>], which demonstrated that multi-scale transformers could extract rich and robust features from different scale inputs.</p>
    <p id="Par72">Four, To make fair comparisons with m6A-word2vec, DeepM6ASeq, Plant6mA methods, we tested MSCAN on twelve RNA modification datasets(m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um). The results show that MSCAN outperforms all other competing methods. our predicted results may also be consistent with biological insights, which illustrates that MSCAN has good robustness.</p>
    <p id="Par73">Five, based on the dataset of Song et al., we designed a cross-modification validation experiment in which twelve different methylation models were tested using twelve sets of methylation test datasets, respectively. We discovered that the most strongly associated modifications originated from the same base class, such as A and G belonging to purine-like bases. The AUROC and AUPRC metrics of the Am test set on the Gm prediction model are second only to the Am test set on the similar Am prediction model. This finding is consistent with Song et al.'s study [<xref ref-type="bibr" rid="CR5">5</xref>], which proposed the existence of an inherent shared structure between different RNA modifications.</p>
    <p id="Par74">Lastly, we compared Am, Gm, Cm, and Um correlations through local BLAST software. We found the average bit-score value of the Gm sequence compared to the Am comparison library is high, indicating that the Am sequence and the Gm sequence are highly similar. Similarly, the average bit-score value of the Um sequence compared to the Cm comparison library is high, indicating that the Um sequence and Cm sequence similarity is high, which may validate the idea that the most closely related modifications originate from the same type of bases.These findings underscore the potential of the MSCAN model in advancing our understanding of the complex interplay between some RNA modifications and their functional implications.</p>
  </sec>
  <sec id="Sec14">
    <title>Conclusions</title>
    <p id="Par75">This study presents a novel multi-scale cross-attention network (MSCAN) for predicting RNA methylation sites. By combining multi-scale, self-, and cross-attention mechanisms, MSCAN effectively extracts in-depth features from 41 base pair sequences at various scales. The model outperforms state-of-the-art predictors for all twelve modification sites, demonstrating its strong generalization ability.</p>
    <p id="Par76">Crucially, through the cross-modification validation experiments, our model unveils significant associations among different types of RNA modifications in terms of their related sequence contexts. This finding offers valuable insights into the complex relationships between RNA modifications and their respective sequence environments.</p>
    <p id="Par77">It is worth noting that the data set samples of the MSCAN model have the following conditions: (1) The sample is a 41-nt fixed-length sequence, (2) The methylation site must be in the center of the sequence, (3) The sample sequence must have a label. It may seem that MSCAN may only be tested by this method.We hope that in the future, targeting the characteristics of RNA sequences of different lengths, the model structure is adjusted to better capture and utilize these characteristics, and focusing particularly on studies that investigate the biological functions and regulatory mechanisms of different RNA sequence lengths.</p>
  </sec>
  <sec id="Sec15">
    <title>Materials and methods</title>
    <sec id="Sec16">
      <title>Datasets</title>
      <p id="Par78">In the present study, the benchmark datasets employed to train and test the proposed methods were gathered from previous works [5, 25]. These datasets encompass twelve distinct types of RNA modifications, namely m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um from H. sapiens. They can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>, and detailed information is provided in Table <xref rid="Tab11" ref-type="table">11</xref>. To maintain consistency, all sequence samples were adjusted to a length of 41-nt, with the modified or unmodified site positioned at the center. In cases where the original sequence length fell short of 41-nt, we employed a padding technique, appending “−” to the head or tail of the sequence, to ensure a uniform length of 41-nt across all samples. The raw RNA datasets are represented as <inline-formula id="IEq1"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_{0} = \left\{ {x^{n} } \right\}_{n = 1}^{N}$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mfenced close="}" open="{"><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mfenced><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>N</italic> is the sequence number, and each <inline-formula id="IEq2"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x^{n} \in {\mathbb{R}}^{L}$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq2.gif"/></alternatives></inline-formula> is an RNA sequence. Each entry <inline-formula id="IEq3"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i}^{n} \in \left\{ {A,C,G,U,` - ^{\prime}} \right\}\;or\;x_{i}^{n} \in \left\{ {A,C,G,U} \right\},i = 1,2,3, \ldots ,L$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mo>`</mml:mo><mml:msup><mml:mo>-</mml:mo><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfenced><mml:mspace width="0.277778em"/><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.277778em"/><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq3.gif"/></alternatives></inline-formula>, where <italic>L</italic> is the fixed sequence length. The model training and experimental parameter optimization of MSCAN are based on the dataset of Chen et al., and the evaluation of MSCAN generalization capability is based on the dataset of Song et al. The ratio of positive-to-negative samples of Chen's and Song's datasets was 1:10 and 1:1, respectively, as shown in Table <xref rid="Tab11" ref-type="table">11</xref>. The corresponding sequences were followed by aligning of the sequences according to sequence-logo representations rendered using the WebLogo program [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>], As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>.
<table-wrap id="Tab11"><label>Table 11</label><caption><p>A statistic of the training and test datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Full name</th><th align="left">Dataset</th><th align="left">Original base</th><th align="left">Number of positive</th><th align="left">Number of negative</th><th align="left">Source of data</th></tr></thead><tbody><tr><td align="left" rowspan="2">1-Methyladenosine</td><td align="left">m<sup>1</sup>A_train0</td><td align="left">A</td><td char="." align="char">593</td><td char="." align="char">5930</td><td align="left">Chen et al.[<xref ref-type="bibr" rid="CR25">25</xref>]</td></tr><tr><td align="left">m<sup>1</sup>A_test0</td><td align="left">A</td><td char="." align="char">114</td><td char="." align="char">1140</td><td align="left"/></tr><tr><td align="left" rowspan="2">N6-methyladenosine</td><td align="left">m<sup>6</sup>A_ train</td><td align="left">A</td><td char="." align="char">41,307</td><td char="." align="char">41,307</td><td align="left">Song et al.[<xref ref-type="bibr" rid="CR5">5</xref>]</td></tr><tr><td align="left">m<sup>6</sup>A_test</td><td align="left"> A</td><td char="." align="char">5901</td><td char="." align="char">5901</td><td align="left"/></tr><tr><td align="left" rowspan="2">1-Methyladenosine</td><td align="left">m<sup>1</sup>A_train</td><td align="left">A</td><td char="." align="char">7357</td><td char="." align="char">7357</td><td align="left"/></tr><tr><td align="left">m<sup>1</sup>A_test</td><td align="left">A</td><td char="." align="char">1051</td><td char="." align="char">1051</td><td align="left"/></tr><tr><td align="left" rowspan="2">5-Methylcytidine</td><td align="left">m<sup>5</sup>C_train</td><td align="left">C</td><td char="." align="char">5953</td><td char="." align="char">5953</td><td align="left"/></tr><tr><td align="left">m<sup>5</sup>C_test</td><td align="left">C</td><td char="." align="char">850</td><td char="." align="char">850</td><td align="left"/></tr><tr><td align="left" rowspan="2">5-Methyluridine</td><td align="left">m<sup>5</sup>U_train</td><td align="left">U</td><td char="." align="char">863</td><td char="." align="char">863</td><td align="left"/></tr><tr><td align="left">m<sup>5</sup>U_test</td><td align="left">U</td><td char="." align="char">123</td><td char="." align="char">123</td><td align="left"/></tr><tr><td align="left" rowspan="2">N6,2′-<italic>O</italic>-dimethyl adenosine</td><td align="left">m<sup>6</sup>Am_train</td><td align="left">A</td><td char="." align="char">1172</td><td char="." align="char">1172</td><td align="left"/></tr><tr><td align="left">m<sup>6</sup>Am_test</td><td align="left">A</td><td char="." align="char">167</td><td char="." align="char">167</td><td align="left"/></tr><tr><td align="left" rowspan="2">7-Methylguanosine</td><td align="left">m<sup>7</sup>G_train</td><td align="left">G</td><td char="." align="char">605</td><td char="." align="char">605</td><td align="left"/></tr><tr><td align="left">m<sup>7</sup>G_test</td><td align="left">G</td><td char="." align="char">86</td><td char="." align="char">86</td><td align="left"/></tr><tr><td align="left" rowspan="2">Pseudouridine</td><td align="left">Pse_train</td><td align="left">U</td><td char="." align="char">1989</td><td char="." align="char">1989</td><td align="left"/></tr><tr><td align="left">Pse_test</td><td align="left">U</td><td char="." align="char">284</td><td char="." align="char">284</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methyladenosine</td><td align="left">Am_train</td><td align="left">A</td><td char="." align="char">848</td><td char="." align="char">848</td><td align="left"/></tr><tr><td align="left">Am_test</td><td align="left">A</td><td char="." align="char">121</td><td char="." align="char">121</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methylcytidine</td><td align="left">Cm_train</td><td align="left">C</td><td char="." align="char">1058</td><td char="." align="char">1058</td><td align="left"/></tr><tr><td align="left">Cm_test</td><td align="left">C</td><td char="." align="char">151</td><td char="." align="char">151</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methylguanosine</td><td align="left">Gm_train</td><td align="left">G</td><td char="." align="char">636</td><td char="." align="char">636</td><td align="left"/></tr><tr><td align="left">Gm_test</td><td align="left">G</td><td char="." align="char">90</td><td char="." align="char">90</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methyluridine</td><td align="left">Um_train</td><td align="left">U</td><td char="." align="char">1438</td><td char="." align="char">1438</td><td align="left"/></tr><tr><td align="left">Um_test</td><td align="left">U</td><td char="." align="char">205</td><td char="." align="char">205</td><td align="left"/></tr><tr><td align="left" rowspan="2">Inosine</td><td align="left">I_train</td><td align="left">A</td><td char="." align="char">5164</td><td char="." align="char">5164</td><td align="left"/></tr><tr><td align="left">I_test</td><td align="left">A</td><td char="." align="char">737</td><td char="." align="char">737</td><td align="left"/></tr></tbody></table></table-wrap><fig id="Fig7"><label>Fig. 7</label><caption><p>The motif of methylation sites. <bold>a</bold> m<sup>1</sup>A in the dataset of Chen et al. <bold>b</bold> m<sup>6</sup>A. <bold>c</bold> Ψ. <bold>d</bold> m<sup>1</sup>A. <bold>e</bold> m<sup>6</sup>Am. <bold>f</bold> Am. <bold>g</bold> Cm. <bold>h</bold> Gm. <bold>i</bold> Um. <bold>j</bold> m<sup>5</sup>C. <bold>k</bold> m<sup>5</sup>U. <bold>l</bold> m<sup>7</sup>G. <bold>m</bold> I in the dataset of Song et al.</p></caption><graphic xlink:href="12859_2024_5649_Fig7a_HTML" id="d32e3256"/><graphic xlink:href="12859_2024_5649_Fig7b_HTML" id="d32e3257"/></fig></p>
    </sec>
    <sec id="Sec17">
      <title>Feature encoding representation</title>
      <p id="Par79">Achieving an effective feature encoding representation of the sequence is crucial for improving the evaluation metrics of a model. This study uses Word2vec to transform the sequence into embedded vector representations. Since its introduction in 2013, Word2vec has significantly advanced the performance of a wide array of natural language processing (NLP) tasks.</p>
      <p id="Par80">The Word2vec methodology offers two different frameworks for encoding: Skip-gram and Continuous Bag of Words (CBOW). The Skip-gram approach predicts contextual information surrounding a given word, whereas the CBOW model generates an embedding for the target word based on its contextual associations. These embeddings are derived through a neural network application, adeptly capturing the inherent relationships within the data.</p>
      <p id="Par81">We developed an RNA embedding approach by treating RNA sequences as sentences and k consecutive RNA nucleotides (k-mers) as words within these sentences. Mathematically, we define the mapping from single nucleotides to the vector representation of k-mers <inline-formula id="IEq4"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f:\sum\nolimits_{{}}^{L} { \mapsto Y^{L - k + 1} }$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow/></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:mo>↦</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq4.gif"/></alternatives></inline-formula>, which is subsequently fed into the neural network for training. This process results in d-dimensional embedded vectors, denoted by <inline-formula id="IEq5"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{m}^{n} \in {\mathbb{R}}^{{m \times d_{m} }}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq5.gif"/></alternatives></inline-formula>, where <italic>m</italic> = <italic>L</italic> − <italic>k</italic> + 1, and <italic>d</italic><sub><italic>m</italic></sub> represents the embedding dimension. Gene2vec [<xref ref-type="bibr" rid="CR21">21</xref>] demonstrated that 3-mers provide the optimal prediction performance. Consequently, we adopted a 3-mers encoding strategy for the input data. Specifically, we employed a sliding window of size 3-nt to slide 41-nt sample sequences with one stride, generating a sequence of 39 words. Each word corresponds to an index in all possible 3-mer combinations(105 or 65 types). Given the relatively large dataset and limited word types in our corpus, we chose the Continuous Bag of Words (CBOW) model for encoding, as it offers faster training times than the Skip-gram model. We used the grid-search strategy for the optimization of the parameters for the experiments, word vector dimension in [100,3 00]. Feature encoding with a word vector dimension of 100 achieved the best performance. In summary, each 3-mer is converted into a word vector, transforming a 41-nt sequence into a 39 × 100 matrix, where 100 represents the word vector dimension.</p>
    </sec>
    <sec id="Sec18">
      <title>Model</title>
      <p id="Par82">As shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>, MSCAN represents an innovative DL architecture that employs a combination of multi-scale self- and cross-attention mechanisms and point-wise, fully connected layers in the encoder. This innovative approach enables the effective modeling of both intra- and inter-sequence interactions across a wide range of scales within RNA-seq data by transforming local RNA sequences into high-dimensional vectors via representations through its multi-scale self- and cross-attention networks. MSCAN efficiently extracts crucial RNA sequence features, thereby facilitating the accurate prediction of m<sup>1</sup>A modifications.<fig id="Fig8"><label>Fig. 8</label><caption><p>Structure of our computational framework based on multi-scale self- and cross-attention network to predict m<sup>1</sup>A methylation site</p></caption><graphic xlink:href="12859_2024_5649_Fig8_HTML" id="MO8"/></fig></p>
      <p id="Par83">The results of this study indicate that the nucleotide base neighboring the methylation site is instrumental in determining the specific type of methylation site and its potential functional consequences [<xref ref-type="bibr" rid="CR40">40</xref>–<xref ref-type="bibr" rid="CR42">42</xref>]. Therefore, the original sample sequence was extracted with two subsequences. These subsequences were centered on the sequence midpoint. One subsequence was 21-nt long, and the other was 31-nt long, as shown in Fig. <xref rid="Fig9" ref-type="fig">9</xref>.<fig id="Fig9"><label>Fig. 9</label><caption><p>Schematic diagram of the obtained subsequences</p></caption><graphic xlink:href="12859_2024_5649_Fig9_HTML" id="MO9"/></fig></p>
      <p id="Par84">In this paper, we represent the dataset as a collection of sample sequences, each consisting of a main sequence and two subsequences. The dataset can be expressed as  <inline-formula id="IEq6"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\{({\text{x}}}_{s0}^{1}, {\text{x}}_{s1}^{1} ,{\text{x}}_{s2}^{1} ,{\text{y}}^{1} )$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq6.gif"/></alternatives></inline-formula>, <inline-formula id="IEq7"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\text{x}}_{s0}^{2}, {\text{x}}_{s1}^{2}, {\text{x}}_{s2}^{2}, {\text{y}}^{2} )$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq7.gif"/></alternatives></inline-formula>, ⋯, <inline-formula id="IEq8"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{(x}}_{s0}^{n} , {\text{x}}_{s1}^{n}, {\text{x}}_{s2}^{n} ,{\text{y}}^{n} )\}$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:msubsup><mml:mtext>(x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq8.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq9"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{n} \in \left\{ {0,1} \right\}$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq9.gif"/></alternatives></inline-formula>, <inline-formula id="IEq10"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s0}^{i} ,x_{s1}^{i} ,x_{s2}^{i}$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq10.gif"/></alternatives></inline-formula> are the three sequences of the i-th sample, <inline-formula id="IEq11"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s0}^{i}$$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq11.gif"/></alternatives></inline-formula> is the main sequence, with s0 = 41, <inline-formula id="IEq12"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s1}^{i} ,x_{s2}^{i}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq12.gif"/></alternatives></inline-formula> is the subsequence, with s1 = 21, and s2 = 31. Experiments show that the performance of trained models exhibits variability when the order of input sample sequences is altered, as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. MSCAN employs the Word2vec encoder to encode word vectors for these sequences. For example, sequences with lengths 21-nt, 41-nt, and 31-nt are transformed into three distinct matrices of varying dimensions: 19 × 100, 39 × 100, and 29 × 100, respectively.</p>
      <p id="Par85">To account for the lack of recursion or convolution in the model, it is necessary to incorporate information about the relative positions of tokens within sequences so that the model can utilize sequence order effectively. To achieve this, "position encoding" is added to the Word2vec embedding output, forming the input for the encoder. The positional encoding method employed in this work was first introduced by Vaswani et al. [<xref ref-type="bibr" rid="CR43">43</xref>] in a machine translation task.</p>
      <p id="Par86">The encoder is composed of a stack of N = 3 identical layers. Each layer has two sub-layers. The first sub-layer is a multi-scale self- and cross-attention network, while the second is a position-wise, fully connected feed-forward network. To facilitate effective information flow, each of these sub-layers incorporates a residual connection in conjunction with layer normalization.</p>
      <p id="Par87">The output generated by each sub-layer can be expressed as LayerNorm(x + sublayer(x)), where sublayer(x) represents the function associated with the sub-layer in question. Both the embedding layer and all model sub-layers yield outputs with a dimension of <inline-formula id="IEq13"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{model} = 64$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq13.gif"/></alternatives></inline-formula>, allowing for seamless residual connections.</p>
      <p id="Par88">Upon completion of the classification process, a linear transformation followed by a sigmoid function is employed to convert the encoder output into predicted probabilities. We used grid-search to choose the hyperparameters on the training data of Chen et al., specifically, epoch in [50, 100], learning_rate in [5e−4, 5e−2], batch in [5, 10, 20, 60], and dropout in [0.2, 0.5]. Final epoch = 100, learning_rate = 5e−4, batch = 10, and dropout = 0.2 is the optimal hyperparameters.</p>
    </sec>
    <sec id="Sec19">
      <title>Multi-scale self- and cross-attention network</title>
      <p id="Par89">The multi-scale self and cross-attention network constitutes the initial layer of the encoder, designed to handle linguistic input at various scales. Utilizing word2vec embeddings, matrices at three distinct scales (take <inline-formula id="IEq14"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}} ,X_{s1}^{{}} ,X_{s2}^{{}}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq14.gif"/></alternatives></inline-formula> as an example) are introduced into the self-attention and cross-attention modules for simultaneous computation. Specifically, <inline-formula id="IEq15"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq15.gif"/></alternatives></inline-formula> is incorporated into the self-attention module, while the two combinations (<inline-formula id="IEq16"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq16.gif"/></alternatives></inline-formula> and <inline-formula id="IEq17"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq17.gif"/></alternatives></inline-formula>, <inline-formula id="IEq18"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq18.gif"/></alternatives></inline-formula> and <inline-formula id="IEq19"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s2}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq19.gif"/></alternatives></inline-formula>) are integrated into the cross-attention module. Subsequently, the outputs from these modules are directly added and relayed to the subsequent layer, as shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>.<fig id="Fig10"><label>Fig. 10</label><caption><p>The internal structure of the multi-scale self- and cross-attention network</p></caption><graphic xlink:href="12859_2024_5649_Fig10_HTML" id="MO10"/></fig></p>
    </sec>
    <sec id="Sec20">
      <title>Cross-attention network</title>
      <p id="Par90">The cross-attention network is designed to extract and learn relationships between words in sequences of varying scales, effectively capturing associations across different sequences. Using sequences <inline-formula id="IEq20"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M52"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq20.gif"/></alternatives></inline-formula> and <inline-formula id="IEq21"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M54"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq21.gif"/></alternatives></inline-formula> as examples, we first transform each sequence into three different terms, which are query, key, and value. This is achieved through the application of linear projections.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{s0} = X_{s0} W_{s0}^{Q} ,K_{s0} = X_{s0} W_{s0}^{K} ,V_{s0} = X_{s0} W_{s0}^{V}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{s1} = X_{s1} W_{s1}^{Q} ,K_{s1} = X_{s1} W_{s1}^{K} ,V_{s1} = X_{s1} W_{s1}^{V}$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq22"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{m} \in {\mathbb{R}}^{{m \times d_{model} }}$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq22.gif"/></alternatives></inline-formula> is the output of the sequence embedding module, <italic>m</italic> represents the length of the input sequence <inline-formula id="IEq23"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m \in \left\{ {s_{0} ,s_{1} ,s_{2} } \right\}$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq23.gif"/></alternatives></inline-formula>. <inline-formula id="IEq24"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{m}^{Q} ,W_{m}^{K} \in {\mathbb{R}}^{{d_{model} \times d_{k} }}$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq24.gif"/></alternatives></inline-formula>, <inline-formula id="IEq25"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{m}^{V} \in {\mathbb{R}}^{{d_{model} \times d_{v} }}$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq25.gif"/></alternatives></inline-formula>. <italic>X</italic><sub><italic>m</italic></sub> is transformed into the query matrix <inline-formula id="IEq26"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{m} \in {\mathbb{R}}^{{m \times d_{k} }}$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq26.gif"/></alternatives></inline-formula>, the key matrix <inline-formula id="IEq27"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K_{m} \in {\mathbb{R}}^{{m \times d_{k} }}$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq27.gif"/></alternatives></inline-formula>, and the value matrix <inline-formula id="IEq28"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{m} \in {\mathbb{R}}^{{m \times d_{v} }}$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq28.gif"/></alternatives></inline-formula>, in which <italic>d</italic><sub><italic>k</italic></sub> is the dimension of matrices <italic>Q</italic><sub><italic>m</italic></sub>, <italic>K</italic><sub><italic>m</italic></sub>, and <italic>d</italic><sub><italic>v</italic></sub> is the dimension of matrix <italic>V</italic><sub><italic>m</italic></sub>.</p>
      <p id="Par91">Second, we compute the cross-modal dot product between the query vector of <inline-formula id="IEq29"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M74"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq29.gif"/></alternatives></inline-formula> and the key vector of <inline-formula id="IEq30"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M76"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq30.gif"/></alternatives></inline-formula>, dividing the result value by <inline-formula id="IEq31"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sqrt {d_{k} }$$\end{document}</tex-math><mml:math id="M78"><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq31.gif"/></alternatives></inline-formula>, to estimate the association between the <inline-formula id="IEq32"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M80"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq32.gif"/></alternatives></inline-formula> and <inline-formula id="IEq33"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M82"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq33.gif"/></alternatives></inline-formula>. These results are subsequently refined and normalized utilizing the softmax function, yielding attention weight coefficients. Lastly, we leverage these coefficients to aggregate the corresponding value vectors from each feature sequence, thereby facilitating that the associated information between the two sequences is obtained. The cross-attention function can be described as follows:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Cross - Attention(Q_{s0} ,K_{s1} ,V_{s1} ) = softmax\left( {\frac{{Q_{s0} K_{s1}^{T} }}{{\sqrt {d_{k} } }}} \right)V_{s1}$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec21">
      <title>Self-attention network</title>
      <p id="Par92">In contrast to the cross-attention module, which primarily focuses on inter-sequence interactions, the self-attention module identifies and elucidates intra-sequence associations. The self-attention function is described as<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Self - Attention(Q_{s0} ,K_{s0} ,V_{s0} ) = softmax\left( {\frac{{Q_{s0} K_{s0}^{T} }}{{\sqrt {d_{k} } }}} \right)V_{s0}$$\end{document}</tex-math><mml:math id="M86" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec22">
      <title>Multi-head multi-scale self- and cross-attention</title>
      <p id="Par93">The above elucidation pertains to single-headed attention, a fundamental mechanism in attention-based models. However, multi-headed attention is commonly employed in practice to augment model efficacy and expedite training. This technique entails conducting single-headed attention in parallel across multiple instances, known as "heads", and subsequently integrating the outcomes derived from each head. By incorporating multi-headed attention, the model can effectively capture diverse contextual information and intricate relationships inherent in the input data. The function of cross-attention is described as:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; MultiHead(Q,K,V) = Concat\left( {head_{1} ,...,head_{h} } \right)W^{O} \\ &amp; \quad where^{{}} head_{i} = Attention\left( {Q_{s0} W_{s0s0i}^{{Q_{s0} }} ,K_{s0} W_{s0s0i}^{{K_{s0} }} ,V_{s0} W_{s0s0i}^{{V_{s0} }} } \right) \\ &amp; \quad + Attention\left( {Q_{s0} W_{s0s1i}^{{Q_{s0} }} ,K_{s1} W_{s0s1i}^{{K_{s1} }} ,V_{s1} W_{s0s1i}^{{V_{s1} }} } \right) \\ &amp; \quad + Attention\left( {Q_{s0} W_{s0s2i}^{{Q_{s0} }} ,K_{s2} W_{s0s2i}^{{K_{s2} }} ,V_{s2} W_{s0s2i}^{{V_{s2} }} } \right) \\ \end{aligned}$$\end{document}</tex-math><mml:math id="M88" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>M</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:msup><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow/></mml:msup><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where the <inline-formula id="IEq34"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{s0s0i}^{{Q_{s0} }} ,W_{s0s0i}^{{K_{s0} }} ,W_{s0s1i}^{{Q_{s0} }} ,W_{s0s1i}^{{K_{s1} }} ,W_{s0s2i}^{{Q_{s0} }} ,W_{s0s2i}^{{K_{s2} }} , \in {\mathbb{R}}^{{d_{model} \times d_{k} }}$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq34.gif"/></alternatives></inline-formula>, <inline-formula id="IEq35"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{s0s0i}^{{V_{s0} }} ,W_{s0s1i}^{{V_{s1} }} ,W_{s0s2i}^{{V_{s2} }} \in {\mathbb{R}}^{{d_{model} \times d_{v} }}$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq35.gif"/></alternatives></inline-formula> and <inline-formula id="IEq36"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W^{O} \in {\mathbb{R}}^{{hd_{v} \times d_{model} }}$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq36.gif"/></alternatives></inline-formula></p>
      <p id="Par94">In this task, we employ h = 8 parallel attention layers. For each layer,we use <italic>d</italic><sub><italic>k</italic></sub> = <italic>d</italic><sub><italic>v</italic></sub> = <italic>d</italic><sub><italic>model</italic></sub>/h = 8.</p>
    </sec>
    <sec id="Sec23">
      <title>Position-wise feed-forward networks</title>
      <p id="Par95">After the multi-headed, multi-scale self- and cross-attention layer, a second sub-layer is incorporated to augment the representative capacity of the model further. This additional component comprises a position-wise, fully connected feed-forward network, enhancing the overall model performance. The architecture of this network entails two successive linear transformations, with an intervening rectified linear unit (ReLU) activation function, ensuring a non-linear and expressive representation of the input data. It is defined as:<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$FFN(x) = \max (0,xW_{1} + b_{1} )W_{2} + b_{2}$$\end{document}</tex-math><mml:math id="M96" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true">max</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par96">The input and output have dimensionality d<sub>model</sub> = 64, while the inner layer's dimensionality is d<sub>ff</sub> = 256.</p>
    </sec>
    <sec id="Sec24">
      <title>Classification module</title>
      <p id="Par97">To accomplish the classification task, the initial step involves computing the average of the encoder output. Subsequently, a linear transformation is applied, followed by implementing a sigmoid activation function. The optimization of the model is facilitated by employing cross-entropy loss as the primary objective. Finally, the methylation site probabilities are acquired, providing a robust and comprehensive representation of the underlying biological processes.</p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>RNA</term>
        <def>
          <p id="Par4">Ribonucleic acid</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>1</sup>A</term>
        <def>
          <p id="Par5">N1-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>6</sup>A</term>
        <def>
          <p id="Par6">N6-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Ψ</term>
        <def>
          <p id="Par7">Pseudouridine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>6</sup>Am</term>
        <def>
          <p id="Par8">N6,2′-<italic>O</italic>-dimethyl adenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Am</term>
        <def>
          <p id="Par9">2′-<italic>O</italic>-Methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Cm</term>
        <def>
          <p id="Par10">2′-<italic>O</italic>-Methylcytidine</p>
        </def>
      </def-item>
      <def-item>
        <term>Gm</term>
        <def>
          <p id="Par11">2′-<italic>O</italic>-Methylguanosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Um</term>
        <def>
          <p id="Par12">2′-<italic>O</italic>-Methyluridine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>5</sup>C</term>
        <def>
          <p id="Par13">5-Methylcytidine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>7</sup>G</term>
        <def>
          <p id="Par14">7-Methylguanosine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>5</sup>U</term>
        <def>
          <p id="Par15">5-Methyluridine</p>
        </def>
      </def-item>
      <def-item>
        <term>I</term>
        <def>
          <p id="Par16">Inosine</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par17">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>BiLSTM</term>
        <def>
          <p id="Par18">Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p id="Par19">Long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par20">Recurrent neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>NLP</term>
        <def>
          <p id="Par21">Natural language processing</p>
        </def>
      </def-item>
      <def-item>
        <term>DL</term>
        <def>
          <p id="Par22">Deep learning</p>
        </def>
      </def-item>
      <def-item>
        <term>MSCAN</term>
        <def>
          <p id="Par23">Multi-scale self- and cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>MCAN</term>
        <def>
          <p id="Par24">Multi-scale cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>SCAN</term>
        <def>
          <p id="Par25">Self- and cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>CAN</term>
        <def>
          <p id="Par26">Cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>SAN</term>
        <def>
          <p id="Par27">Self-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>Sn</term>
        <def>
          <p id="Par28">Sensitivity</p>
        </def>
      </def-item>
      <def-item>
        <term>Sp</term>
        <def>
          <p id="Par29">Specificity</p>
        </def>
      </def-item>
      <def-item>
        <term>ACC</term>
        <def>
          <p id="Par30">Accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>Pre</term>
        <def>
          <p id="Par31">Precision</p>
        </def>
      </def-item>
      <def-item>
        <term>MCC</term>
        <def>
          <p id="Par32">Matthews correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>AUROC</term>
        <def>
          <p id="Par33">Area under the receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>AUPRC</term>
        <def>
          <p id="Par34">Area under the precision-recall curve</p>
        </def>
      </def-item>
      <def-item>
        <term>ENAC</term>
        <def>
          <p id="Par35">Enhanced nucleic acid composition</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>HW built the architecture for MSCAN, designed and implemented the experiments, analyzed the results, and wrote the paper. LZ and TH conducted the experiments and revised the paper. DW conducted the experiments, analyzed the results, and revised the paper. LZ and YS supervised the project, analyzed the result, and revised the paper. All authors read, critically revised, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work has been supported by the National Natural Science Foundation of China (31871337 and 61971422 to LZ), and the "333 Project" of Jiangsu(BRA2020328 to WHL). The funding body did not play any roles in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The data supporting the findings of the article is available at the web server <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par98">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par99">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par100">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>El Allali</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Elhamraoui</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Daoud</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Machine learning applications in RNA modification sites prediction</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>5510</fpage>
        <lpage>5524</lpage>
        <pub-id pub-id-type="pmid">34712397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>SY</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bi</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>XL</given-names>
          </name>
        </person-group>
        <article-title>A brief review of machine learning methods for RNA methylation sites prediction</article-title>
        <source>Methods</source>
        <year>2022</year>
        <volume>203</volume>
        <fpage>399</fpage>
        <lpage>421</lpage>
        <pub-id pub-id-type="pmid">35248693</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Bioinformatics approaches for deciphering the epitranscriptome: recent progress and emerging topics</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2020</year>
        <volume>18</volume>
        <fpage>1587</fpage>
        <lpage>1604</lpage>
        <pub-id pub-id-type="pmid">32670500</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>LF</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>XQ</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>FS</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>XH</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>TB</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>XM</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>KX</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>MY</given-names>
          </name>
        </person-group>
        <article-title>TransformerCPI: improving compound–protein interaction prediction by sequence-based deep learning with self-attention mechanism and label reversal experiments</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>16</issue>
        <fpage>4406</fpage>
        <lpage>4414</lpage>
        <pub-id pub-id-type="pmid">32428219</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>ZT</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>BW</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>KQ</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>de Magalhaes</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Rigden</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Attention-based multi-label neural networks for integrated prediction and interpretation of twelve widely occurring RNA modifications</article-title>
        <source>Nat Commun</source>
        <year>2021</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="pmid">33397941</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grozhik</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Olarerin-George</surname>
            <given-names>AO</given-names>
          </name>
          <name>
            <surname>Sindelar</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Jaffrey</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Antibody cross-reactivity accounts for widespread appearance of m1A in 5' UTRs</article-title>
        <source>Nat Commun</source>
        <year>2019</year>
        <volume>11</volume>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dominissini</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The dynamic N(1)-methyladenosine methylome in eukaryotic messenger RNA</article-title>
        <source>Nature</source>
        <year>2016</year>
        <volume>530</volume>
        <issue>7591</issue>
        <fpage>1</fpage>
        <lpage>39</lpage>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>ZK</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>GZ</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Dominissini</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High-resolution N-6-methyladenosine (m(6)A) map using photo-crosslinking-assisted m(6)A sequencing</article-title>
        <source>Angew Chem Int Ed</source>
        <year>2015</year>
        <volume>54</volume>
        <issue>5</issue>
        <fpage>1587</fpage>
        <lpage>1590</lpage>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Transcriptome-wide mapping reveals reversible and dynamic N(1)-methyladenosine methylome</article-title>
        <source>Nat Chem Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>5</issue>
        <fpage>311</fpage>
        <lpage>316</lpage>
        <pub-id pub-id-type="pmid">26863410</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Masiello</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Biggiogera</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Ultrastructural localization of 5-methylcytosine on DNA and RNA</article-title>
        <source>Cell Mol Life Sci</source>
        <year>2017</year>
        <volume>74</volume>
        <issue>16</issue>
        <fpage>3057</fpage>
        <lpage>3064</lpage>
        <pub-id pub-id-type="pmid">28391361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiaoyu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xushen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Meiling</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Kun</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ying</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Base-resolution mapping reveals distinct m1A methylome in nuclear- and mitochondrial-encoded transcripts</article-title>
        <source>Mol Cell</source>
        <year>2017</year>
        <volume>68</volume>
        <issue>5</issue>
        <fpage>993</fpage>
        <lpage>1005</lpage>
        <pub-id pub-id-type="pmid">29107537</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rauch</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Dickinson</surname>
            <given-names>BC</given-names>
          </name>
        </person-group>
        <article-title>Evolution of a reverse transcriptase to map N1-methyladenosine in human messenger RNA</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>12</issue>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">30573832</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y-H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>SRAMP: prediction of mammalian N6-methyladenosine (m6A) sites based on sequence-derived features</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>10</issue>
        <fpage>e91</fpage>
        <lpage>e91</lpage>
        <pub-id pub-id-type="pmid">26896799</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>RAMPred: identifying the N(1)-methyladenosine sites in eukaryotic transcriptomes</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">28442746</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>iRNA-3typeA: identifying three types of modification at RNA's adenosine sites</article-title>
        <source>Mol Ther Nucleic Acids</source>
        <year>2018</year>
        <volume>11</volume>
        <fpage>468</fpage>
        <lpage>474</lpage>
        <pub-id pub-id-type="pmid">29858081</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>iMRM: a platform for simultaneously identifying multiple kinds of RNA modifications</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>11</issue>
        <fpage>3336</fpage>
        <lpage>3342</lpage>
        <pub-id pub-id-type="pmid">32134472</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Iuchi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Matsutani</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yamada</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Iwano</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Sumi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hosoda</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Fukunaga</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hamada</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Representation learning applications in biological sequence analysis</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>3198</fpage>
        <lpage>3208</lpage>
        <pub-id pub-id-type="pmid">34141139</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Angermueller</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Pärnamaa</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Parts</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Stegle</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for computational biology</article-title>
        <source>Mol Syst Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>7</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huss</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Abid</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mohammadi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Torkamani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Telenti</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A primer on deep learning in genomics</article-title>
        <source>Nat Genet</source>
        <year>2019</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>12</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">30478442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>EDLm(6)APred: ensemble deep learning approach for mRNA m(6)A site prediction</article-title>
        <source>BMC Bioinform</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>PW</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>LY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N-6-methyladenosine sites from mRNA</article-title>
        <source>RNA</source>
        <year>2019</year>
        <volume>25</volume>
        <issue>2</issue>
        <fpage>205</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="pmid">30425123</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>AthMethPre: a web server for the prediction and query of mRNA m(6)A sites in <italic>Arabidopsis</italic>
<italic>thaliana</italic></article-title>
        <source>Mol Biosyst</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>11</issue>
        <fpage>3333</fpage>
        <lpage>3337</lpage>
        <pub-id pub-id-type="pmid">27550167</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lv</surname>
            <given-names>ZB</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>A convolutional neural network using dinucleotide one-hot encoder for identifying DNA N6-methyladenine sites in the rice genome</article-title>
        <source>Neurocomputing</source>
        <year>2021</year>
        <volume>422</volume>
        <fpage>214</fpage>
        <lpage>221</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tahir</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hayat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>KT</given-names>
          </name>
        </person-group>
        <article-title>Prediction of N6-methyladenosine sites using convolution neural network model based on distributed feature representations</article-title>
        <source>Neural Netw</source>
        <year>2020</year>
        <volume>129</volume>
        <fpage>385</fpage>
        <lpage>391</lpage>
        <pub-id pub-id-type="pmid">32593932</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AI</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Baggag</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bensmail</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive review and assessment of computational methods for predicting RNA post-transcriptional modification sites from RNA sequences</article-title>
        <source>Brief Bioinform</source>
        <year>2019</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>1676</fpage>
        <lpage>1696</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>NN</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>BERMP: a cross-species classifier for predicting m(6)A sites by integrating a deep learning algorithm and a random forest approach</article-title>
        <source>Int J Biol Sci</source>
        <year>2018</year>
        <volume>14</volume>
        <issue>12</issue>
        <fpage>1669</fpage>
        <lpage>1677</lpage>
        <pub-id pub-id-type="pmid">30416381</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hamada</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>DeepM6ASeq: prediction and characterization of m6A-containing sequences using deep learning</article-title>
        <source>BMC Bioinform</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Rp</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sw</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Gan</surname>
            <given-names>WA</given-names>
          </name>
        </person-group>
        <article-title>DeepFusion: a deep learning based multi-scale feature fusion method for predicting drug–target interactions</article-title>
        <source>Methods</source>
        <year>2022</year>
        <volume>204</volume>
        <fpage>269</fpage>
        <lpage>277</lpage>
        <pub-id pub-id-type="pmid">35219861</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Kim Y, Denton C, Hoang L, Rush AM. Structured attention networks. 2017, p. 1–21.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Plant6mA: a predictor for predicting N6-methyladenine sites with lightweight structure in plant genomes</article-title>
        <source>Methods (San Diego, Calif)</source>
        <year>2022</year>
        <volume>204</volume>
        <fpage>1</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="pmid">35483547</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>FY</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>DX</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>YZ</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Daly</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>QZ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iLearnPlus: a comprehensive and automated machine-learning platform for nucleic acid and protein sequence analysis, prediction and visualization</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>10</issue>
        <fpage>e60</fpage>
        <pub-id pub-id-type="pmid">33660783</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>KY</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>TY</given-names>
          </name>
          <name>
            <surname>Kao</surname>
            <given-names>HJ</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>WC</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>HD</given-names>
          </name>
        </person-group>
        <article-title>dbPTM in 2019: exploring disease association and cross-talk of post-translational modifications</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>D298</fpage>
        <lpage>D308</lpage>
        <pub-id pub-id-type="pmid">30418626</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shilatifard</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The language of histone crosstalk</article-title>
        <source>Cell</source>
        <year>2010</year>
        <volume>142</volume>
        <issue>5</issue>
        <fpage>682</fpage>
        <lpage>685</lpage>
        <pub-id pub-id-type="pmid">20813257</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boratyn</surname>
            <given-names>GM</given-names>
          </name>
          <name>
            <surname>Camacho</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>PS</given-names>
          </name>
          <name>
            <surname>Coulouris</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Fong</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Matten</surname>
            <given-names>WT</given-names>
          </name>
          <name>
            <surname>McGinnis</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Merezhuk</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BLAST: a more efficient report with usability improvements</article-title>
        <source>Nucleic Acids Res</source>
        <year>2013</year>
        <volume>41</volume>
        <issue>W1</issue>
        <fpage>W29</fpage>
        <lpage>W33</lpage>
        <pub-id pub-id-type="pmid">23609542</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Sun LC, Liu B, Tao JH, Lian Z. IEEE: multimodal cross- and self-attention network for speech emotion recognition. In: IEEE international conference on acoustics, speech and signal processing (ICASSP): Jun 06–11 2021; Electr Network. 2021, p. 4275–4279.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Chen CF, Fan Q, Panda R. CrossViT: cross-attention multi-scale vision transformer for image classification. In: ICCV. 2021, p. 1–12.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Guo Q, Qiu X, Liu P, Xue X, Zhang Z. Multi-scale self-attention for text classification. In: Proceedings of the AAAI conference on artificial intelligence, 2020, p. 7847–7854.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crooks</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Chandonia</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>SE</given-names>
          </name>
        </person-group>
        <article-title>WebLogo: a sequence logo generator</article-title>
        <source>Genome Res</source>
        <year>2004</year>
        <volume>14</volume>
        <issue>6</issue>
        <fpage>1188</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="pmid">15173120</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schneider</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Stephens</surname>
            <given-names>RM</given-names>
          </name>
        </person-group>
        <article-title>Sequence logos: a new way to display consensus sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>1990</year>
        <volume>18</volume>
        <issue>20</issue>
        <fpage>6097</fpage>
        <lpage>6100</lpage>
        <pub-id pub-id-type="pmid">2172928</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lister</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Mukamel</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Nery</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Urich</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Puddifoot</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Johnson</surname>
            <given-names>ND</given-names>
          </name>
          <name>
            <surname>Lucero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Dwork</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Schultz</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ecker</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>Global epigenomic reconfiguration during mammalian brain development</article-title>
        <source>Science</source>
        <year>2013</year>
        <volume>341</volume>
        <issue>6146</issue>
        <fpage>629</fpage>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>JU</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Distribution, recognition and regulation of non-CpG methylation in the adult mammalian brain</article-title>
        <source>Nat Neurosci</source>
        <year>2014</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>215</fpage>
        <lpage>222</lpage>
        <pub-id pub-id-type="pmid">24362762</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ziller</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bock</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Boyle</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Epstein</surname>
            <given-names>CB</given-names>
          </name>
          <name>
            <surname>Bernstein</surname>
            <given-names>BE</given-names>
          </name>
          <name>
            <surname>Lengauer</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Genomic distribution and inter-sample variation of non-CpG methylation across human cell types</article-title>
        <source>PLoS Genet</source>
        <year>2011</year>
        <volume>7</volume>
        <issue>12</issue>
        <fpage>e1002389</fpage>
        <pub-id pub-id-type="pmid">22174693</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. Attention is all you need. arXiv. 2017, p. 1–15.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10795237</article-id>
    <article-id pub-id-type="pmid">38233745</article-id>
    <article-id pub-id-type="publisher-id">5649</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-024-05649-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MSCAN: multi-scale self- and cross-attention network for RNA methylation site prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Honglei</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Dong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zeng</surname>
          <given-names>Wenliang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Sun</surname>
          <given-names>Yanjing</given-names>
        </name>
        <address>
          <email>yjsun@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhang</surname>
          <given-names>Lin</given-names>
        </name>
        <address>
          <email>lin.zhang@cumt.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01xt2dr21</institution-id><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>School of Information and Control Engineering, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01xt2dr21</institution-id><institution-id institution-id-type="GRID">grid.411510.0</institution-id><institution-id institution-id-type="ISNI">0000 0000 9030 231X</institution-id><institution>School of Computer Science and Technology, </institution><institution>China University of Mining and Technology, </institution></institution-wrap>Xuzhou, 221116 China </aff>
      <aff id="Aff3"><label>3</label>School of Information Engineering, Xuzhou College of Industrial Technology, Xuzhou, 221400 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2024</year>
    </pub-date>
    <volume>25</volume>
    <elocation-id>32</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Epi-transcriptome regulation through post-transcriptional RNA modifications is essential for all RNA types. Precise recognition of RNA modifications is critical for understanding their functions and regulatory mechanisms. However, wet experimental methods are often costly and time-consuming, limiting their wide range of applications. Therefore, recent research has focused on developing computational methods, particularly deep learning (DL). Bidirectional long short-term memory (BiLSTM), convolutional neural network (CNN), and the transformer have demonstrated achievements in modification site prediction. However, BiLSTM cannot achieve parallel computation, leading to a long training time, CNN cannot learn the dependencies of the long distance of the sequence, and the Transformer lacks information interaction with sequences at different scales. This insight underscores the necessity for continued research and development in natural language processing (NLP) and DL to devise an enhanced prediction framework that can effectively address the challenges presented.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">This study presents a multi-scale self- and cross-attention network (MSCAN) to identify the RNA methylation site using an NLP and DL way. Experiment results on twelve RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um) reveal that the area under the receiver operating characteristic of MSCAN obtains respectively 98.34%, 85.41%, 97.29%, 96.74%, 99.04%, 79.94%, 76.22%, 65.69%, 92.92%, 92.03%, 95.77%, 89.66%, which is better than the state-of-the-art prediction model. This indicates that the model has strong generalization capabilities. Furthermore, MSCAN reveals a strong association among different types of RNA modifications from an experimental perspective. A user-friendly web server for predicting twelve widely occurring human RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um) is available at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">A predictor framework has been developed through binary classification to predict RNA methylation sites.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>RNA methylation</kwd>
      <kwd>Transformer</kwd>
      <kwd>Predictor</kwd>
      <kwd>Multi-scale</kwd>
      <kwd>Self-attention</kwd>
      <kwd>Cross-attention</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the National Natural Science Foundation of China</institution>
        </funding-source>
        <award-id>31871337</award-id>
        <award-id>31871337</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <award-id>61971422</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Tao</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>Wenliang</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the "333 Project" of Jiangsu</institution>
        </funding-source>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <award-id>BRA2020328</award-id>
        <principal-award-recipient>
          <name>
            <surname>Wang</surname>
            <given-names>Honglei</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Dong</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Yanjing</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Lin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2024</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec2">
    <title>Background</title>
    <p id="Par36">RNA modification plays a fundamental role in regulating RNA function [<xref ref-type="bibr" rid="CR1">1</xref>] and has become a hotspot in epigenetics research [<xref ref-type="bibr" rid="CR2">2</xref>]. Nearly 200 RNA modifications have been discovered, most of which are methylation modifications [<xref ref-type="bibr" rid="CR3">3</xref>]. Common RNA methylation types include N<sup>1</sup>-methyladenosine (m<sup>1</sup>A), N<sup>2</sup>-methylguanosine (m<sup>2</sup>G), 5-methylcytosine (m<sup>5</sup>C), 5-methyluridine (m<sup>5</sup>U), 2′-<italic>O</italic>-methyladensine (Am), 2′-<italic>O</italic>-methylcytidine (Cm), 2′-<italic>O</italic>-methylguanosine (Gm), 2′-<italic>O</italic>-methyluridine (Um), Pseudouridine (Ψ), N<sup>6</sup>-methyladenosine(m<sup>6</sup>A), N<sup>7</sup>-methylguanine (m<sup>7</sup>G), inosine (I), and N6,2′-<italic>O</italic>-dimethyladenosine(m<sup>6</sup>Am), etc. Among them, m<sup>6</sup>A refers to methylation modification occurring at the nitrogen atom in position 6 of the RNA molecule adenine, which is the most abundant mRNA methylation, and is known to affect mRNA stability, splicing, and translation. In addition to m<sup>6</sup>A, m<sup>1</sup>A RNA methylation is a recently discovered one, which is evolutionarily conserved and ubiquitous in humans, rodents, and yeast. It can significantly enhance the protein translation of transcripts [<xref ref-type="bibr" rid="CR4">4</xref>], block the Watson–Crick interface, and is essential for tRNA stability [<xref ref-type="bibr" rid="CR5">5</xref>].</p>
    <p id="Par37">In the last decade, dozens of experimental methods have been developed to identify the precise location of methylation sites on RNA, such as miCLIP [<xref ref-type="bibr" rid="CR6">6</xref>], m<sup>1</sup>A-seq [<xref ref-type="bibr" rid="CR7">7</xref>], PA-m6A-seq [<xref ref-type="bibr" rid="CR8">8</xref>], m<sup>1</sup>A-ID-seq [<xref ref-type="bibr" rid="CR9">9</xref>], m5C-RIP [<xref ref-type="bibr" rid="CR10">10</xref>], m<sup>1</sup>A-MAP [<xref ref-type="bibr" rid="CR11">11</xref>], and m<sup>1</sup>A-IP-seq [<xref ref-type="bibr" rid="CR12">12</xref>]. Despite their effectiveness, these experimental techniques are usually both time-consuming and costly, limiting their use in different biological contexts [<xref ref-type="bibr" rid="CR4">4</xref>], and making them inadequate for large-scale genomic data [<xref ref-type="bibr" rid="CR13">13</xref>]. Consequently, there is strong motivation to explore computational methods that can accurately and efficiently identify methylation sites based on sequence information alone.</p>
    <p id="Par38">As there are more vailable base-resolution datasets, researchers have designed some computational methods for RNA modification site prediction. These approaches formulate RNA methylation identification as a binary prediction task, and some machine learning models are trained to distinguish between truly methylated and non-methylated sites. These computational methods have been powerful additions for RNA methylation site prediction.</p>
    <p id="Par39">Traditional methods designed for sequence-based prediction usually first extract features based on human-understandable feature methods and then use a classifier to identify if the site is methylated based on the preceding extracted features. Specifically, RAMPred [<xref ref-type="bibr" rid="CR14">14</xref>] adopts the support vector machine(SVM) to predict the m<sup>1</sup>A modification site, extracting features based on nucleotide composition(NC) and nucleotide chemical properties(NCP). iRNA-3typeA [<xref ref-type="bibr" rid="CR15">15</xref>] adopts SVM to predict m<sup>1</sup>A, A-to-I, and m<sup>6</sup>A modification sites, which extracts features based on accumulated nucleotide frequency(ANF) and NCP. iMRM [<xref ref-type="bibr" rid="CR16">16</xref>] extracts features based on NCP, NC, Nucleotide Density(ND), Dinucleotide physicochemical properties(DPCP), and Dinucleotide Binary Encoding(DBE) and employs XGboost to predict m<sup>1</sup>A, m<sup>6</sup>A, m<sup>5</sup>C, ψ, and A-to-I modification sites. The above sequence features are artificially extracted, and inevitably important features of the sequences are missed due to human cognitive limitations.</p>
    <p id="Par40">Analyzing biological sequences and interpreting biological information are the key challenges in achieving biological discovery. The application of natural language processing(NLP) to sequence analysis has attracted considerable attention in processing biological sequences [<xref ref-type="bibr" rid="CR17">17</xref>]. As biological sequences can be considered sentences, and k-mer subsequences are regarded as words [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>], NLP can be used to understand the structure and function encoded in these sequences [<xref ref-type="bibr" rid="CR17">17</xref>]. Unlike traditional machine learning, deep learning (DL) methods follow an end-to-end design. Features are extracted directly based on the input sequence and the final labeling/prediction task. For example, EDLm6Apred [<xref ref-type="bibr" rid="CR20">20</xref>] employs bidirectional long short-term memory (BiLSTM) to predict m<sup>6</sup>A sites, extracting features based on Word2vec, RNA word embedding [<xref ref-type="bibr" rid="CR21">21</xref>], and one-hot encoding [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. However, LSTM, BiLSTM, and RNN cannot achieve parallel computation, leading to a long training time.</p>
    <p id="Par41">CNN can achieve parallel computation and learn local dependencies. For instance, m6A-word2vec [<xref ref-type="bibr" rid="CR24">24</xref>] adopts CNN to identify m<sup>6</sup>A sites, extracting features based on Word2vec. Deeppromise [<xref ref-type="bibr" rid="CR25">25</xref>] employs CNN to identify m<sup>1</sup>A and m<sup>6</sup>A sites, extracting features based on integrated enhanced nucleic acid composition (ENAC) [<xref ref-type="bibr" rid="CR26">26</xref>], one-hot encoding, and RNA word embedding. However, These CNN structures only consider the contextual relationships of neighboring bases without considering the dependencies over long distances in the sequence. DeepM6ASeq [<xref ref-type="bibr" rid="CR27">27</xref>] combines the advantages of CNN and BiLSTM by using two layers of CNN and one layer of BiLSTM to predict m<sup>6</sup>A sites. This approach may extract redundant features that interfere with prediction performance [<xref ref-type="bibr" rid="CR28">28</xref>]. The attention mechanism can quantify the degree of code-to-code dependency [<xref ref-type="bibr" rid="CR29">29</xref>]. Therefore, the application of the attention mechanism can capture the focused codes that affect the classification results. Plant6mA [<xref ref-type="bibr" rid="CR30">30</xref>] utilizes a Transformer encoder to determine whether the input sequence contains an m6A site. However, due to the unique feature representation of transformers, these networks are primarily employed at a single scale. Although a single-scale self-attentive mechanism can focus on essential features of sequence context, it lacks information interaction with sequences at different scales. It isn't easy to learn complex word context relationships.</p>
    <p id="Par42">At present, most prediction model studies focus only on a single methylation modification, and few share the same binary classification model framework to achieve different methylation modification predictions. Even fewer cross-modification validation studies have been performed with different methylation test sets and trained models. Accounting for potential interactions between various RNA modifications, it would be interesting to use the same model to conduct cross-modification validation studies across different methylation test sets.</p>
    <p id="Par43">We present the Multi-scale Self- and Cross-attention Network (MSCAN), a novel approach designed to identify RNA methylation sites, addressing the challenges associated with current methods. Our model supports identifying twelve RNA modification types, including m<sup>6</sup>A, Ψ, m<sup>1</sup>A, m<sup>6</sup>Am, Am, Cm, m<sup>7</sup>G, Gm, Um, I, m<sup>5</sup>U, and m<sup>5</sup>C.</p>
    <p id="Par44">The MSCAN employs a unique multi-scale approach for analyzing RNA sequences. Specifically, we extracted the input 41-nucleotides (nt) sample sequence into multiple smaller subsequences centered around the sequence midpoint. To ensure accurate identification of methylation sites, the MSCAN analyzes these smaller subsequences at two distinct scales: 21-nt and 31-nt. This multi-scale analysis allows for a more comprehensive understanding of the RNA sequence context, ultimately leading to improved prediction performance. Secondly, word2vec was used to encode the three sets of sequences. Third, the three sets of sequences add positional information due to the correlation between nucleotide positions in the sequence. Four, the three sets of sequences were fed into the encoding module, which was constructed with a multi-scale self- and cross-attention network and a feed-forward network(FFN) to extract potential contributing features for methylation site prediction. Finally, methylation predicted probabilities were obtained through a linear layer and the sigmoid function. The findings demonstrated that the MSCAN model surpassed the performance of state-of-the-art methods, including m6A-word2vec, DeepM6ASeq, and Plant6mA in independent tests. A user-friendly web server for MSCAN is available at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
  </sec>
  <sec id="Sec3">
    <title>Result</title>
    <sec id="Sec4">
      <title>Evaluation metrics</title>
      <p id="Par45">In this study, we used eight common classification indicators to evaluate the prediction of the model, including Accuracy (Acc), Sensitivity (Sen), Precision (Pre), Matthews correlation coefficient (MCC), Specificity (Sp), and F1 score (F1). The formulas of these metrics are as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sensitivity,\;Recall = \frac{TP}{{TP + FN}}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.277778em"/><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Specificity = \frac{TN}{{TN + FP}}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Accuracy = \frac{TP + TN}{{TP + TN + FP + FN}}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Precision = \frac{TP}{{TP + FP}}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1 \, score = 2 \times \frac{Precision \times Recall}{{Precision + Recall}}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mspace width="0.166667em"/><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MCC = \frac{TP \times TN - FP \times FN}{{\sqrt {(TP + FP) \times (TP + FN) \times (TN + FP) \times (TN + FN)} }}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par46">Here, the true positive, true negative, false positive, and false negative are represented as TP, TN, FP, and FN, respectively. Moreover, the area under the receiver operating characteristic (AUROC) and the area under the precision-recall curve (AUPRC) are used to visually evaluate the model's overall performance.</p>
    </sec>
    <sec id="Sec5">
      <title>Results analysis</title>
      <p id="Par47">MSCAN completed model training and experimental parameter optimization based on the dataset of Chen et al. [<xref ref-type="bibr" rid="CR25">25</xref>]. Subsequently, MSCAN completed the model's generalization ability evaluation based on the dataset of Song et al. [<xref ref-type="bibr" rid="CR5">5</xref>]. Specifically, based on the dataset of Chen et al., this paper first compared the performance of MSCAN with different combinations of input sequences on the training data. Second, the performance of MSCAN with different feature encoding was compared. Third, we compared the performance of different MSCAN model variants. Fourth, the MSCAN was compared with state-of-the-art models based on the training data and the independent dataset of Chen et al. Fifth, the statistical significance of AUPRC values between the four models is compared. Sixth, MSCAN completed a generalization ability evaluation based on the dataset of Song et al., and MSCAN outperformed the state-of-the-art predictors for twelve modification sites. Finally, We designed a cross-modification validation experiment in which twelve models with different methylation types were compared for prediction performance based on twelve test sets, respectively. Our experiments were conducted with two Intel(R) 5218 CPUs, two RTX2080Ti GPUs, and Pytorch version 1.4.0+cu92.</p>
      <p id="Par48">Based on the training data of Chen et al., we first tried optimizing the input sequences' length according to AUPRC on the training data. Using the Word2vec embedding, we evaluated the Transformer model with 11-nt, 21-nt, 31-nt, 41-nt,51-nt,61-nt,71-nt,81-nt,91-nt,and 101-nt RNA sequences as the input on the five-fold cross-validation [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR25">25</xref>]. As shown in Table <xref rid="Tab1" ref-type="table">1</xref>, the input of the 11-nt sequence obtained the worst performance. The reason may be that too few bases in the 11-nt sequence affect feature extraction. The input of the 41-bp sequence obtained the best average performance of all the modifications, It may be worth mentioning that the 41-nt of the input sequence is also optimal for the XGboost and SVM method [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], so we choose 21-nt, 31-nt, and 41-nt RNA sequences as input sequences to achieve different combinations of input sequences.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Evaluation results of five-fold cross-validation of transformer based on the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Length(nt)</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">11</td><td char="." align="char">0.8955</td><td char="." align="char">93.55</td><td char="." align="char">44.26</td><td char="." align="char"><bold>77.14</bold></td><td char="." align="char">55.44</td><td char="." align="char"><bold>98.65</bold></td><td char="." align="char">56.25</td><td char="." align="char">0.6389</td></tr><tr><td align="left">21</td><td char="." align="char">0.9213</td><td char="." align="char"><bold>95.01</bold></td><td char="." align="char">59.81</td><td char="." align="char">74.42</td><td char="." align="char">64.11</td><td char="." align="char">98.16</td><td char="." align="char">66.32</td><td char="." align="char">0.7189</td></tr><tr><td align="left">31</td><td char="." align="char">0.9361</td><td char="." align="char">93.55</td><td char="." align="char">64.80</td><td char="." align="char">66.94</td><td char="." align="char">62.31</td><td char="." align="char">96.61</td><td char="." align="char">65.85</td><td char="." align="char">0.7390</td></tr><tr><td align="left">41</td><td char="." align="char"><bold>0.9484</bold></td><td char="." align="char">93.48</td><td char="." align="char"><bold>74.36</bold></td><td char="." align="char">61.27</td><td char="." align="char">63.97</td><td char="." align="char">95.37</td><td char="." align="char">67.18</td><td char="." align="char"><bold>0.7469</bold></td></tr><tr><td align="left">51</td><td char="." align="char">0.9401</td><td char="." align="char">94.63</td><td char="." align="char">61.54</td><td char="." align="char">74.23</td><td char="." align="char">64.73</td><td char="." align="char">97.89</td><td char="." align="char">67.29</td><td char="." align="char">0.7401</td></tr><tr><td align="left">61</td><td char="." align="char">0.9430</td><td char="." align="char">94.56</td><td char="." align="char">67.27</td><td char="." align="char">67.89</td><td char="." align="char">64.61</td><td char="." align="char">97.07</td><td char="." align="char">67.58</td><td char="." align="char">0.7078</td></tr><tr><td align="left">71</td><td char="." align="char">0.9249</td><td char="." align="char">93.64</td><td char="." align="char">67.21</td><td char="." align="char">65.60</td><td char="." align="char">62.89</td><td char="." align="char">96.36</td><td char="." align="char">66.40</td><td char="." align="char">0.7272</td></tr><tr><td align="left">81</td><td char="." align="char">0.9440</td><td char="." align="char">94.94</td><td char="." align="char">70.00</td><td char="." align="char">66.04</td><td char="." align="char"><bold>65.25</bold></td><td char="." align="char">97.01</td><td char="." align="char"><bold>67.96</bold></td><td char="." align="char">0.7170</td></tr><tr><td align="left">91</td><td char="." align="char">0.9327</td><td char="." align="char">94.93</td><td char="." align="char">60.19</td><td char="." align="char">73.86</td><td char="." align="char">64.01</td><td char="." align="char">98.08</td><td char="." align="char">66.33</td><td char="." align="char">0.7119</td></tr><tr><td align="left">101</td><td char="." align="char">0.9230</td><td char="." align="char">93.33</td><td char="." align="char">70.94</td><td char="." align="char">61.03</td><td char="." align="char">62.16</td><td char="." align="char">95.53</td><td char="." align="char">65.61</td><td char="." align="char">0.7449</td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par49">The combination of input sequences with different scale order is an important parameter that affects the performance of the training model. The performance of the MSCAN model with the different combinations of input sequences on the training data is shown in Table <xref rid="Tab2" ref-type="table">2</xref>. MSCAN shows the best prediction performance when the combination is “21-nt + 41-nt + 31-nt”. According to the MSCAN model design, “21-nt + 41-nt + 31-nt” input sequences are entered into the model to implement three attention mechanisms, including the self-attention calculation mechanism for the 21-nt sequence, and the cross-attention calculation mechanisms for both “21-nt + 41-nt” and “21-nt + 31-nt” combinatorial sequences.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Evaluation results of MSCAN on five-fold cross-validation with different input sequences based on the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">combinations of sequences(nt)</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">21 + 31 + 41</td><td char="." align="char">0.9491</td><td char="." align="char"><bold>95.24</bold></td><td char="." align="char">58.59</td><td char="." align="char">73.42</td><td char="." align="char">63.11</td><td char="." align="char">98.26</td><td char="." align="char">65.17</td><td char="." align="char">0.7695</td></tr><tr><td align="left">21 + 41 + 31</td><td char="." align="char"><bold>0.9618</bold></td><td char="." align="char">94.86</td><td char="." align="char">59.69</td><td char="." align="char"><bold>83.70</bold></td><td char="." align="char"><bold>68.11</bold></td><td char="." align="char"><bold>98.72</bold></td><td char="." align="char">69.68</td><td char="." align="char"><bold>0.7949</bold></td></tr><tr><td align="left">31 + 21 + 41</td><td char="." align="char">0.9257</td><td char="." align="char">94.63</td><td char="." align="char">55.93</td><td char="." align="char">78.57</td><td char="." align="char">63.59</td><td char="." align="char">98.48</td><td char="." align="char">65.34</td><td char="." align="char">0.7419</td></tr><tr><td align="left">31 + 41 + 21</td><td char="." align="char">0.9463</td><td char="." align="char">95.09</td><td char="." align="char"><bold>68.47</bold></td><td char="." align="char">72.38</td><td char="." align="char">67.73</td><td char="." align="char">97.57</td><td char="." align="char"><bold>70.37</bold></td><td char="." align="char">0.7632</td></tr><tr><td align="left">41 + 21 + 31</td><td char="." align="char">0.9318</td><td char="." align="char">94.55</td><td char="." align="char">63.87</td><td char="." align="char">73.08</td><td char="." align="char">65.38</td><td char="." align="char">97.64</td><td char="." align="char">68.17</td><td char="." align="char">0.7617</td></tr><tr><td align="left">41 + 31 + 21</td><td char="." align="char">0.9427</td><td char="." align="char">93.86</td><td char="." align="char">65.41</td><td char="." align="char">71.90</td><td char="." align="char">65.20</td><td char="." align="char">97.10</td><td char="." align="char">68.50</td><td char="." align="char">0.7642</td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec6">
      <title>Comparison analysis of different feature encoding methods</title>
      <p id="Par50">In this section, we evaluate the performance of three distinct feature encoding methods—Word2vec, One-hot, and ENAC—utilizing the same MSCAN model for predicting m<sup>1</sup>A sites on the test data of Chen et al. The outcomes of this comparison are presented in Fig. <xref rid="Fig1" ref-type="fig">1</xref> and Table <xref rid="Tab3" ref-type="table">3</xref>, demonstrating that Word2vec consistently surpasses the other two encoding methods across all performance indices.<fig id="Fig1"><label>Fig. 1</label><caption><p>Performance of the MSCAN model based on the different feature encoding</p></caption><graphic xlink:href="12859_2024_5649_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>MSCAN model evaluation results with different feature encodings based on the test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Encoding</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">One-hot</td><td char="." align="char">0.9089</td><td char="." align="char">95.13</td><td char="." align="char">55.26</td><td char="." align="char">86.30</td><td char="." align="char">66.77</td><td char="." align="char">99.12</td><td char="." align="char">67.38</td><td char="." align="char">0.7294</td></tr><tr><td align="left">ENAC</td><td char="." align="char">0.9212</td><td char="." align="char">94.81</td><td char="." align="char">55.26</td><td char="." align="char">81.82</td><td char="." align="char">64.71</td><td char="." align="char">98.77</td><td char="." align="char">65.97</td><td char="." align="char">0.7322</td></tr><tr><td align="left">Word2vec</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char"><bold>58.77</bold></td><td char="." align="char"><bold>90.54</bold></td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char"><bold>99.39</bold></td><td char="." align="char"><bold>71.28</bold></td><td char="." align="char"><bold>0.7890</bold></td></tr></tbody></table><table-wrap-foot><p>Bold Indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par51">The superior performance of Word2vec can be attributed to the limitations of the One-hot and ENAC encoding methods. While One-hot encoding focuses on the local information of individual bases, and ENAC encoding considers both nucleic acid composition and position information, both methods neglect the semantic information inherent in the sequence context. In contrast, Word2vec prioritizes the contextual relationships between bases, resulting in a more effective representation of the sequence.</p>
      <p id="Par52">Our findings highlight the importance of selecting appropriate feature encoding methods for improved prediction accuracy, with Word2vec emerging as a particularly advantageous choice for the MSCAN model in the context of RNA methylation site prediction.</p>
    </sec>
    <sec id="Sec7">
      <title>Comparison with different variants of the MSCAN model</title>
      <p id="Par53">We conducted ablation experiments to assess the contribution of key components within our proposed MSCAN model based on the test data of Chen et al. Utilizing Word2vec for RNA sequence encoding, we constructed four sub-networks: self- and cross-attention network (SCAN), self-attention network (SAN), multi-scale cross-attention network (MCAN), and cross-attention network (CAN). SCAN represents MSCAN with one cross-attention module removed, SAN is SCAN devoid of cross-attention, MCAN is MSCAN without self-attention, and CAN is MCAN with one cross-attention module removed. The outcomes of these experiments are depicted in Fig. <xref rid="Fig2" ref-type="fig">2</xref> and summarized in Table <xref rid="Tab4" ref-type="table">4</xref>.<fig id="Fig2"><label>Fig. 2</label><caption><p>Performance of MSCAN and variant model on the test data</p></caption><graphic xlink:href="12859_2024_5649_Fig2_HTML" id="MO2"/></fig><table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparing MSCAN and variant model evaluation results based on test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">SAN</td><td char="." align="char">0.9321</td><td char="." align="char">95.05</td><td char="." align="char">55.26</td><td char="." align="char">85.14</td><td char="." align="char">66.24</td><td char="." align="char">99.04</td><td char="." align="char">67.02</td><td char="." align="char">0.7604</td></tr><tr><td align="left">SCAN</td><td char="." align="char">0.9277</td><td char="." align="char">95.29</td><td char="." align="char">53.51</td><td char="." align="char"><bold>91.04</bold></td><td char="." align="char">67.73</td><td char="." align="char"><bold>99.47</bold></td><td char="." align="char">67.40</td><td char="." align="char">0.7613</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char"><bold>58.77</bold></td><td char="." align="char">90.54</td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char">99.39</td><td char="." align="char"><bold>71.28</bold></td><td char="." align="char"><bold>0.7890</bold></td></tr><tr><td align="left">CAN</td><td char="." align="char">0.9299</td><td char="." align="char">94.89</td><td char="." align="char">52.63</td><td char="." align="char">85.71</td><td char="." align="char">64.81</td><td char="." align="char">99.12</td><td char="." align="char">65.21</td><td char="." align="char">0.7688</td></tr><tr><td align="left">MCAN</td><td char="." align="char">0.9270</td><td char="." align="char">94.81</td><td char="." align="char">55.26</td><td char="." align="char">81.82</td><td char="." align="char">64.71</td><td char="." align="char">98.77</td><td char="." align="char">65.97</td><td char="." align="char">0.7586</td></tr></tbody></table><table-wrap-foot><p>Bold Indicates the best performance</p><p>SAN contains only self-attention; SCAN, and MSCAN are combinations of self- and cross-attention; CAN and MCAN are combinations of only cross-attention</p></table-wrap-foot></table-wrap></p>
      <p id="Par54">SAN serves as the baseline model in this comparison. Upon the integration of cross-attention modules, the area under the precision-recall curve (AUPRC) for SCAN and MSCAN models increased by 0.09% and 2.86%, respectively. These results highlight the importance of incorporating cross-attention mechanisms within the MSCAN model for improved performance in predicting RNA methylation sites. Consequently, our findings emphasize the value of the multi-scale self- and cross-attention approach employed by MSCAN in advancing the understanding of RNA modifications and their functional implications.</p>
    </sec>
    <sec id="Sec8">
      <title>Comparison with state-of-the-art approaches</title>
      <p id="Par55">We compared MSCAN with several state-of-the-art models, including m6A-word2vec, DeepM6ASeq, and Plant6mA. To ensure robust evaluation, we employed a fivefold cross-validation on the training data of Chen et al. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref> and Table <xref rid="Tab5" ref-type="table">5</xref>, Our results demonstrate that MSCAN outperforms the other models, substantially improving prediction accuracy.<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance of the different models on the training data</p></caption><graphic xlink:href="12859_2024_5649_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab5"><label>Table 5</label><caption><p>Evaluation results of MSCAN and other state-of-the-art models based on five-fold cross-validation using the training data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9001</td><td char="." align="char">93.30</td><td char="." align="char">53.79</td><td char="." align="char">66.18</td><td char="." align="char">56.10</td><td char="." align="char">97.25</td><td char="." align="char">59.35</td><td char="." align="char">0.6505</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.8735</td><td char="." align="char">93.38</td><td char="." align="char">46.49</td><td char="." align="char">70.67</td><td char="." align="char">54.02</td><td char="." align="char">98.07</td><td char="." align="char">56.08</td><td char="." align="char">0.6279</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.9482</td><td char="." align="char">93.48</td><td char="." align="char"><bold>74.36</bold></td><td char="." align="char">61.27</td><td char="." align="char">63.97</td><td char="." align="char">95.37</td><td char="." align="char">67.18</td><td char="." align="char">0.7465</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9618</bold></td><td char="." align="char"><bold>94.86</bold></td><td char="." align="char">59.69</td><td char="." align="char"><bold>83.70</bold></td><td char="." align="char"><bold>68.11</bold></td><td char="." align="char"><bold>98.72</bold></td><td char="." align="char"><bold>69.68</bold></td><td char="." align="char"><bold>0.7949</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par56">In particular, MSCAN achieves a 4.84% enhancement in the AUPRC metric compared to the second-best performing model, Plant6mA. This superior performance can be attributed to utilizing the multi-scale self- and cross-attention mechanisms in MSCAN, as opposed to the self-attention mechanism employed by Plant6mA. The results underscore the effectiveness of MSCAN in identifying RNA methylation sites.</p>
      <p id="Par57">Next, we compare the performance of MSCAN with other state-of-the-art models using the test data of Chen et al. The results, as illustrated in Fig. <xref rid="Fig4" ref-type="fig">4</xref> and summarized in Table <xref rid="Tab6" ref-type="table">6</xref>, demonstrate the superior performance of MSCAN in predicting RNA methylation sites.<fig id="Fig4"><label>Fig. 4</label><caption><p>The ROC and PRC of MSCAN and other state-of-the-art models on the test data</p></caption><graphic xlink:href="12859_2024_5649_Fig4_HTML" id="MO4"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption><p>Evaluation results of MSCAN and other state-of-the-art models based on the test data of Chen et al.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">AUROC</th><th align="left">ACC</th><th align="left">Sen</th><th align="left">Precision</th><th align="left">MCC</th><th align="left">Spe</th><th align="left">F-1</th><th align="left">AUPRC</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9327</td><td char="." align="char">93.62</td><td char="." align="char"><bold>67.54</bold></td><td char="." align="char">64.17</td><td char="." align="char">62.32</td><td char="." align="char">90.43</td><td char="." align="char">65.81</td><td char="." align="char">0.7650</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.9257</td><td char="." align="char">95.37</td><td char="." align="char">65.79</td><td char="." align="char">79.79</td><td char="." align="char">70.00</td><td char="." align="char">98.33</td><td char="." align="char"><bold>72.12</bold></td><td char="." align="char">0.7743</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.9298</td><td char="." align="char">95.13</td><td char="." align="char">56.14</td><td char="." align="char">85.33</td><td char="." align="char">66.89</td><td char="." align="char">99.04</td><td char="." align="char">67.72</td><td char="." align="char">0.7676</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9374</bold></td><td char="." align="char"><bold>95.69</bold></td><td char="." align="char">58.77</td><td char="." align="char"><bold>90.54</bold></td><td char="." align="char"><bold>70.95</bold></td><td char="." align="char"><bold>99.39</bold></td><td char="." align="char">71.28</td><td char="." align="char"><bold>0.7890</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par58">MSCAN outperforms DeepM6ASeq and m6A-word2vec by 1.47% and 2.4% in terms of AUPRC, respectively. This enhanced performance can be attributed to the multi-scale self- and cross-attention network's ability to capture meaningful sequence encodings for more accurate classification. Furthermore, MSCAN surpasses Plant6mA by 2.14% in AUPRC, which may further verify the limitations of the single-scale self-attention mechanism in learning complex contextual relationships between sequence elements. The integration of the cross-attention mechanism enables the model to discern deeper sequence meanings, thus improving its performance.</p>
    </sec>
    <sec id="Sec9">
      <title>Assessing model reliability</title>
      <p id="Par59">To evaluate the reliability of our proposed model, we performed one hundred replications of experiments using the test data from Chen et al., evaluating the m6A-word2vec, DeepM6ASeq, Plant6mA, and MSCAN models. In each replication, we used the same test data and ran each model under identical conditions to ensure experimental consistency.</p>
      <p id="Par60">To evaluate the statistical significance of AUPRC values between different methods, we employed Student's t-test [<xref ref-type="bibr" rid="CR31">31</xref>]. This statistical method helps determine whether performance differences between different methods are significant. Table <xref rid="Tab7" ref-type="table">7</xref> below shows the <italic>p</italic> values for the difference in the performance of the four classifiers.
<table-wrap id="Tab7"><label>Table 7</label><caption><p>A statistically significant correlation matrix for the difference in the performance of the four classifiers</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Classifiers</th><th align="left" colspan="4">Classifiers</th></tr><tr><th align="left">m6A-word2vec</th><th align="left">DeepM6ASeq</th><th align="left">Plant6mA</th><th align="left">MSCAN</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">DeepM6ASeq</td><td align="left">0.001243</td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">Plant6mA</td><td align="left">2.905E−44</td><td align="left">8.01217E−35</td><td align="left"/><td align="left"/></tr><tr><td align="left">MSCAN</td><td align="left">4.71415E−64</td><td align="left">1.25245E−58</td><td align="left">0</td><td align="left"/></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec10">
      <title>Assessing model generalization ability</title>
      <p id="Par61">Based on the data set of Song et al., the generalization ability of MSCAN was evaluated by training the model individually for each methylation type. As presented in Table <xref rid="Tab8" ref-type="table">8</xref>, the MSCAN model consistently outperforms state-of-the-art models, including m6A-word2vec, DeepM6ASeq, and Plant6mA. This result provides empirical evidence of the model's generalizability across diverse methylation site prediction tasks.
<table-wrap id="Tab8"><label>Table 8</label><caption><p>Compare MSCAN to other methods under AUC</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifiers</th><th align="left">m<sup>6</sup>A</th><th align="left">Ψ</th><th align="left">m<sup>1</sup>A</th><th align="left">m<sup>6</sup>Am</th><th align="left">Am</th><th align="left">Cm</th><th align="left">Gm</th><th align="left">Um</th><th align="left">m<sup>5</sup>C</th><th align="left">m<sup>7</sup>G</th><th align="left">m<sup>5</sup>U</th><th align="left">I</th></tr></thead><tbody><tr><td align="left">m6A-word2vec</td><td char="." align="char">0.9773</td><td char="." align="char">0.7060</td><td char="." align="char">0.8385</td><td char="." align="char">0.9867</td><td char="." align="char">0.9174</td><td char="." align="char">0.9120</td><td char="." align="char">0.9554</td><td char="." align="char">0.8467</td><td char="." align="char">0.9611</td><td char="." align="char">0.7505</td><td char="." align="char">0.9499</td><td char="." align="char">0.6180</td></tr><tr><td align="left">DeepM6ASeq</td><td char="." align="char">0.9752</td><td char="." align="char">0.7510</td><td char="." align="char">0.8289</td><td char="." align="char">0.9837</td><td char="." align="char">0.9213</td><td char="." align="char">0.9173</td><td char="." align="char">0.9538</td><td char="." align="char">0.8716</td><td char="." align="char">0.9675</td><td char="." align="char">0.7527</td><td char="." align="char">0.9584</td><td char="." align="char">0.5872</td></tr><tr><td align="left">Plant6mA</td><td char="." align="char">0.5964</td><td char="." align="char">0.5478</td><td char="." align="char">0.7268</td><td char="." align="char">0.7826</td><td char="." align="char">0.8110</td><td char="." align="char">0.8016</td><td char="." align="char">0.8279</td><td char="." align="char">0.7847</td><td char="." align="char">0.6806</td><td char="." align="char">0.6690</td><td char="." align="char">0.9528</td><td char="." align="char">0.5137</td></tr><tr><td align="left">MSCAN</td><td char="." align="char"><bold>0.9834</bold></td><td char="." align="char"><bold>0.7622</bold></td><td char="." align="char"><bold>0.8541</bold></td><td char="." align="char"><bold>0.9904</bold></td><td char="." align="char"><bold>0.9292</bold></td><td char="." align="char"><bold>0.9203</bold></td><td char="." align="char"><bold>0.9577</bold></td><td char="." align="char"><bold>0.8966</bold></td><td char="." align="char"><bold>0.9729</bold></td><td char="." align="char"><bold>0.7994</bold></td><td char="." align="char"><bold>0.9674</bold></td><td char="." align="char"><bold>0.6569</bold></td></tr></tbody></table><table-wrap-foot><p>Bold indicates the best performance</p></table-wrap-foot></table-wrap></p>
      <p id="Par62">Theoretically, the self- and cross-attention mechanism employed by the MSCAN model enables it to capture long-range dependencies and complex interactions between input features more effectively than other models, such as Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). This characteristic is particularly advantageous in discerning biologically relevant patterns in methylation site prediction, which may contribute to the model's enhanced generalizability.</p>
    </sec>
    <sec id="Sec11">
      <title>Comparison with cross-modification validation approaches</title>
      <p id="Par63">Thus far, our results have demonstrated the model's robust classification performance. Notably, a significant advantage of the proposed MSCAN model is its ability to learn the underlying associations among different RNA modifications. Previous studies have revealed clear evolutionary and functional cross-talk among various post-translational modifications of proteins [<xref ref-type="bibr" rid="CR32">32</xref>] and histone and chromatin modifications [<xref ref-type="bibr" rid="CR33">33</xref>]. Such associations might also exist at the epi-transcriptome level among different RNA modifications.</p>
      <p id="Par64">To better understand the inherent shared structures among different RNA modifications, we performed cross-modification validation on the second dataset. The resulting AUROC values are displayed in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. As the figure shows, cross-modification validation yielded poorer prediction results than those obtained using modification-consistent data and models, indicating the specificity of our method for a particular modification.<fig id="Fig5"><label>Fig. 5</label><caption><p>Heat map of different AUROC values in cross-methylation validation. The horizontal axis is the model type, and the vertical axis is the test data type</p></caption><graphic xlink:href="12859_2024_5649_Fig5_HTML" id="MO5"/></fig></p>
      <p id="Par65">Interestingly, in experiments where the test dataset and model were inconsistent, some groups achieved high AUROC values greater than 0.85, suggesting strong and significant positive associations among certain RNA modifications, even those originating from different nucleotides. This observation implies the existence of regions intensively modified by multiple RNA modifications, which likely serve as key regulatory components for the epi-transcriptome layer of gene regulation. Notably, the sequence signatures of these key regulatory regions are largely shared among different RNA modifications (including those that modify different nucleotides) and were successfully captured by our model. As presented in Table <xref rid="Tab9" ref-type="table">9</xref>, the most strongly associated modifications originated from the same type of base, with A and G belonging to purine-like bases, and C and U belonging to pyrimidine bases.
<table-wrap id="Tab9"><label>Table 9</label><caption><p>Association of RNA modifications revealed by MSCAN</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Model</th><th align="left">AUROC</th><th align="left">AUPRC</th><th align="left">ACC</th><th align="left">Dataset</th><th align="left">Model</th><th align="left">AUROC</th><th align="left">AUPRC</th><th align="left">ACC</th></tr></thead><tbody><tr><td align="left">Am</td><td align="left">Am</td><td char="." align="char">0.9292</td><td char="." align="char">0.9231</td><td char="." align="char">86.36</td><td align="left">Gm</td><td align="left">Gm</td><td char="." align="char">0.9577</td><td char="." align="char">0.9637</td><td char="." align="char">88.33</td></tr><tr><td align="left">Gm</td><td align="left">Am</td><td char="." align="char">0.9082</td><td char="." align="char">0.9233</td><td char="." align="char">81.11</td><td align="left">Am</td><td align="left">Gm</td><td char="." align="char">0.8695</td><td char="." align="char">0.8809</td><td char="." align="char">80.16</td></tr><tr><td align="left">Cm</td><td align="left">Am</td><td char="." align="char">0.8724</td><td char="." align="char">0.8906</td><td char="." align="char">73.51</td><td align="left">Cm</td><td align="left">Gm</td><td char="." align="char">0.8083</td><td char="." align="char">0.8280</td><td char="." align="char">72.18</td></tr><tr><td align="left">Um</td><td align="left">Am</td><td char="." align="char">0.7884</td><td char="." align="char">0.7839</td><td char="." align="char">60.00</td><td align="left">Um</td><td align="left">Gm</td><td char="." align="char">0.7387</td><td char="." align="char">0.7659</td><td char="." align="char">66.34</td></tr><tr><td align="left">Cm</td><td align="left">Cm</td><td char="." align="char">0.9203</td><td char="." align="char">0.9273</td><td char="." align="char">83.44</td><td align="left">Um</td><td align="left">Um</td><td char="." align="char">0.8966</td><td char="." align="char">0.8756</td><td char="." align="char">82.92</td></tr><tr><td align="left">Um</td><td align="left">Cm</td><td char="." align="char">0.8647</td><td char="." align="char">0.8514</td><td char="." align="char">79.75</td><td align="left">Cm</td><td align="left">Um</td><td char="." align="char">0.8859</td><td char="." align="char">0.8739</td><td char="." align="char">81.78</td></tr><tr><td align="left">Am</td><td align="left">Cm</td><td char="." align="char">0.8830</td><td char="." align="char">0.8862</td><td char="." align="char">72.31</td><td align="left">Am</td><td align="left">Um</td><td char="." align="char">0.8458</td><td char="." align="char">0.8282</td><td char="." align="char">78.51</td></tr><tr><td align="left">Gm</td><td align="left">Cm</td><td char="." align="char">0.8865</td><td char="." align="char">0.9070</td><td char="." align="char">69.44</td><td align="left">Gm</td><td align="left">Um</td><td char="." align="char">0.8480</td><td char="." align="char">0.8589</td><td char="." align="char">76.66</td></tr></tbody></table></table-wrap></p>
      <p id="Par66">To further verify this finding, we compared Am, Gm, Cm, and Um correlations through local BLAST [<xref ref-type="bibr" rid="CR34">34</xref>] software. First, the Am, Gm, and Cm comparison libraries are established based on the Am data set, Gm data set, and Cm data set respectively. Secondly, the Am, Gm, Cm, and Um data sets are used to compare the comparison libraries with different methylation in pairs. Then, the BLAST output table is obtained. Finally, compare the average value of the comparison result "bit-score". As shown in Table <xref rid="Tab10" ref-type="table">10</xref>, the average bit-score value of the Gm sequence compared to the Am comparison library is high, indicating that the Am sequence and the Gm sequence are highly similar. Similarly, the average bit-score value of the Um sequence compared to the Cm comparison library is high, indicating that the Um sequence and Cm sequence similarity is high, which may validate the idea that the most closely related modifications originate from the same type of bases.
<table-wrap id="Tab10"><label>Table 10</label><caption><p>Compare the average bit-score of various methylated sequences</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Query subject</th><th align="left">Am</th><th align="left">Gm</th><th align="left">Cm</th><th align="left">Um</th></tr></thead><tbody><tr><td align="left">Am</td><td align="left"/><td char="." align="char">9.679614</td><td char="." align="char">5.866832</td><td char="." align="char">3.30773</td></tr><tr><td align="left">Gm</td><td align="left"/><td char="." align="char"/><td char="." align="char">3.357072</td><td char="." align="char">1.639136</td></tr><tr><td align="left">Cm</td><td align="left"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char">8.793488</td></tr><tr><td align="left">Um</td><td align="left"/><td char="." align="char"/><td char="." align="char"/><td char="." align="char"/></tr></tbody></table></table-wrap></p>
      <p id="Par67">Our model provides experimental verification of the existence of an inherent shared structure between different RNA modifications. These findings underscore the potential of the MSCAN model in advancing our understanding of the complex interplay between various RNA modifications and their functional implications.</p>
    </sec>
    <sec id="Sec12">
      <title>Web server</title>
      <p id="Par68">We have developed a user-friendly web server for predicting twelve widely occurring human RNA modification sites (m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um), accessible at <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>, to facilitate the use of the MSCAN model for RNA methylation site prediction. Take the step of predicting the m<sup>1</sup>A methylation site as an example. First, click the “Prediction” button and select the “m<sup>1</sup>A” successively. Next, type or paste the RNA sequence, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>a. Third, leave your email address in the input box and click the “submit” button. After a calculation period, the prediction results will be displayed in a table, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>b. This intuitive web server offers researchers an efficient and convenient platform for employing the MSCAN model in their investigations of RNA modifications and their functional implications.<fig id="Fig6"><label>Fig. 6</label><caption><p>Webserver interface. a. Input interface. b. Prediction result</p></caption><graphic xlink:href="12859_2024_5649_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Discussion</title>
    <p id="Par69">First, based on the test data of Chen et al., we compared the performance of various features based on the MSCAN model, including One-hot encoding, ENAC, and Word2vec. The results reveal that Word2vec outperforms One-hot and ENAC in predicting AUROC and AUPRC. Specifically, the AUPRC of MSCAN<sub>word2vec</sub> is 5.96% and 5.68% higher than that of MSCAN<sub>One-hot</sub> and MSCAN<sub>ENAC</sub>, respectively. These findings are in line with Zhang et al.'s study [<xref ref-type="bibr" rid="CR20">20</xref>], which highlights that One-hot focuses on local semantic information while ENAC only considers the sequence's nucleic acid composition and position, neglecting more profound semantic information. Conversely, Word2vec captures the contextual semantic information of the sequence, significantly enhancing the model's predictive capability.</p>
    <p id="Par70">Second, based on the test data of Chen et al., we assessed the impact of various MSCAN components by comparing the performance of different MSCAN variants, such as SCAN, SAN, MCAN, and CAN. Experimental results show that MSCAN reduces AUPRC by 3.04% and 2.77% respectively after deleting a self-attention module or a cross-attention module. This finding is consistent with Sun et al.'s study [<xref ref-type="bibr" rid="CR35">35</xref>], which posits that the removal of self- or cross-attention modules leads to diminished model performance. When both the Multi-Scale and cross-attention modules are removed, the AUPRC of MSCAN decreases by 2.86%. This result aligns with Chen et al.'s study [<xref ref-type="bibr" rid="CR36">36</xref>], which emphasizes that cross-attention effectively learns multi-scale transformer features for data recognition.</p>
    <p id="Par71">Third, we compared the performance of m6A-word2vec, DeepM6ASeq, Plant6mA, and MSCAN based on the test data of Chen et al. MSCAN's AUROC and AUPRC outperformed the other three state-of-the-art models. In particular, MSCAN surpassed Plant6mA by 2.14% in terms of AUPRC. This study substantiates that the utilization of multi-scale input and cross-attention allows the model to extract diverse features and provide deep semantics, which Plant6mA cannot achieve through information fusion from multiple scales. This conclusion is supported by Guo et al.'s study [<xref ref-type="bibr" rid="CR37">37</xref>], which demonstrated that multi-scale transformers could extract rich and robust features from different scale inputs.</p>
    <p id="Par72">Four, To make fair comparisons with m6A-word2vec, DeepM6ASeq, Plant6mA methods, we tested MSCAN on twelve RNA modification datasets(m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um). The results show that MSCAN outperforms all other competing methods. our predicted results may also be consistent with biological insights, which illustrates that MSCAN has good robustness.</p>
    <p id="Par73">Five, based on the dataset of Song et al., we designed a cross-modification validation experiment in which twelve different methylation models were tested using twelve sets of methylation test datasets, respectively. We discovered that the most strongly associated modifications originated from the same base class, such as A and G belonging to purine-like bases. The AUROC and AUPRC metrics of the Am test set on the Gm prediction model are second only to the Am test set on the similar Am prediction model. This finding is consistent with Song et al.'s study [<xref ref-type="bibr" rid="CR5">5</xref>], which proposed the existence of an inherent shared structure between different RNA modifications.</p>
    <p id="Par74">Lastly, we compared Am, Gm, Cm, and Um correlations through local BLAST software. We found the average bit-score value of the Gm sequence compared to the Am comparison library is high, indicating that the Am sequence and the Gm sequence are highly similar. Similarly, the average bit-score value of the Um sequence compared to the Cm comparison library is high, indicating that the Um sequence and Cm sequence similarity is high, which may validate the idea that the most closely related modifications originate from the same type of bases.These findings underscore the potential of the MSCAN model in advancing our understanding of the complex interplay between some RNA modifications and their functional implications.</p>
  </sec>
  <sec id="Sec14">
    <title>Conclusions</title>
    <p id="Par75">This study presents a novel multi-scale cross-attention network (MSCAN) for predicting RNA methylation sites. By combining multi-scale, self-, and cross-attention mechanisms, MSCAN effectively extracts in-depth features from 41 base pair sequences at various scales. The model outperforms state-of-the-art predictors for all twelve modification sites, demonstrating its strong generalization ability.</p>
    <p id="Par76">Crucially, through the cross-modification validation experiments, our model unveils significant associations among different types of RNA modifications in terms of their related sequence contexts. This finding offers valuable insights into the complex relationships between RNA modifications and their respective sequence environments.</p>
    <p id="Par77">It is worth noting that the data set samples of the MSCAN model have the following conditions: (1) The sample is a 41-nt fixed-length sequence, (2) The methylation site must be in the center of the sequence, (3) The sample sequence must have a label. It may seem that MSCAN may only be tested by this method.We hope that in the future, targeting the characteristics of RNA sequences of different lengths, the model structure is adjusted to better capture and utilize these characteristics, and focusing particularly on studies that investigate the biological functions and regulatory mechanisms of different RNA sequence lengths.</p>
  </sec>
  <sec id="Sec15">
    <title>Materials and methods</title>
    <sec id="Sec16">
      <title>Datasets</title>
      <p id="Par78">In the present study, the benchmark datasets employed to train and test the proposed methods were gathered from previous works [5, 25]. These datasets encompass twelve distinct types of RNA modifications, namely m<sup>6</sup>A, m<sup>1</sup>A, m<sup>5</sup>C, m<sup>5</sup>U, m<sup>6</sup>Am, m<sup>7</sup>G, Ψ, I, Am, Cm, Gm, and Um from H. sapiens. They can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>, and detailed information is provided in Table <xref rid="Tab11" ref-type="table">11</xref>. To maintain consistency, all sequence samples were adjusted to a length of 41-nt, with the modified or unmodified site positioned at the center. In cases where the original sequence length fell short of 41-nt, we employed a padding technique, appending “−” to the head or tail of the sequence, to ensure a uniform length of 41-nt across all samples. The raw RNA datasets are represented as <inline-formula id="IEq1"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_{0} = \left\{ {x^{n} } \right\}_{n = 1}^{N}$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mfenced close="}" open="{"><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mfenced><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>N</italic> is the sequence number, and each <inline-formula id="IEq2"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x^{n} \in {\mathbb{R}}^{L}$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq2.gif"/></alternatives></inline-formula> is an RNA sequence. Each entry <inline-formula id="IEq3"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i}^{n} \in \left\{ {A,C,G,U,` - ^{\prime}} \right\}\;or\;x_{i}^{n} \in \left\{ {A,C,G,U} \right\},i = 1,2,3, \ldots ,L$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mo>`</mml:mo><mml:msup><mml:mo>-</mml:mo><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfenced><mml:mspace width="0.277778em"/><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.277778em"/><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq3.gif"/></alternatives></inline-formula>, where <italic>L</italic> is the fixed sequence length. The model training and experimental parameter optimization of MSCAN are based on the dataset of Chen et al., and the evaluation of MSCAN generalization capability is based on the dataset of Song et al. The ratio of positive-to-negative samples of Chen's and Song's datasets was 1:10 and 1:1, respectively, as shown in Table <xref rid="Tab11" ref-type="table">11</xref>. The corresponding sequences were followed by aligning of the sequences according to sequence-logo representations rendered using the WebLogo program [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>], As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>.
<table-wrap id="Tab11"><label>Table 11</label><caption><p>A statistic of the training and test datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Full name</th><th align="left">Dataset</th><th align="left">Original base</th><th align="left">Number of positive</th><th align="left">Number of negative</th><th align="left">Source of data</th></tr></thead><tbody><tr><td align="left" rowspan="2">1-Methyladenosine</td><td align="left">m<sup>1</sup>A_train0</td><td align="left">A</td><td char="." align="char">593</td><td char="." align="char">5930</td><td align="left">Chen et al.[<xref ref-type="bibr" rid="CR25">25</xref>]</td></tr><tr><td align="left">m<sup>1</sup>A_test0</td><td align="left">A</td><td char="." align="char">114</td><td char="." align="char">1140</td><td align="left"/></tr><tr><td align="left" rowspan="2">N6-methyladenosine</td><td align="left">m<sup>6</sup>A_ train</td><td align="left">A</td><td char="." align="char">41,307</td><td char="." align="char">41,307</td><td align="left">Song et al.[<xref ref-type="bibr" rid="CR5">5</xref>]</td></tr><tr><td align="left">m<sup>6</sup>A_test</td><td align="left"> A</td><td char="." align="char">5901</td><td char="." align="char">5901</td><td align="left"/></tr><tr><td align="left" rowspan="2">1-Methyladenosine</td><td align="left">m<sup>1</sup>A_train</td><td align="left">A</td><td char="." align="char">7357</td><td char="." align="char">7357</td><td align="left"/></tr><tr><td align="left">m<sup>1</sup>A_test</td><td align="left">A</td><td char="." align="char">1051</td><td char="." align="char">1051</td><td align="left"/></tr><tr><td align="left" rowspan="2">5-Methylcytidine</td><td align="left">m<sup>5</sup>C_train</td><td align="left">C</td><td char="." align="char">5953</td><td char="." align="char">5953</td><td align="left"/></tr><tr><td align="left">m<sup>5</sup>C_test</td><td align="left">C</td><td char="." align="char">850</td><td char="." align="char">850</td><td align="left"/></tr><tr><td align="left" rowspan="2">5-Methyluridine</td><td align="left">m<sup>5</sup>U_train</td><td align="left">U</td><td char="." align="char">863</td><td char="." align="char">863</td><td align="left"/></tr><tr><td align="left">m<sup>5</sup>U_test</td><td align="left">U</td><td char="." align="char">123</td><td char="." align="char">123</td><td align="left"/></tr><tr><td align="left" rowspan="2">N6,2′-<italic>O</italic>-dimethyl adenosine</td><td align="left">m<sup>6</sup>Am_train</td><td align="left">A</td><td char="." align="char">1172</td><td char="." align="char">1172</td><td align="left"/></tr><tr><td align="left">m<sup>6</sup>Am_test</td><td align="left">A</td><td char="." align="char">167</td><td char="." align="char">167</td><td align="left"/></tr><tr><td align="left" rowspan="2">7-Methylguanosine</td><td align="left">m<sup>7</sup>G_train</td><td align="left">G</td><td char="." align="char">605</td><td char="." align="char">605</td><td align="left"/></tr><tr><td align="left">m<sup>7</sup>G_test</td><td align="left">G</td><td char="." align="char">86</td><td char="." align="char">86</td><td align="left"/></tr><tr><td align="left" rowspan="2">Pseudouridine</td><td align="left">Pse_train</td><td align="left">U</td><td char="." align="char">1989</td><td char="." align="char">1989</td><td align="left"/></tr><tr><td align="left">Pse_test</td><td align="left">U</td><td char="." align="char">284</td><td char="." align="char">284</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methyladenosine</td><td align="left">Am_train</td><td align="left">A</td><td char="." align="char">848</td><td char="." align="char">848</td><td align="left"/></tr><tr><td align="left">Am_test</td><td align="left">A</td><td char="." align="char">121</td><td char="." align="char">121</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methylcytidine</td><td align="left">Cm_train</td><td align="left">C</td><td char="." align="char">1058</td><td char="." align="char">1058</td><td align="left"/></tr><tr><td align="left">Cm_test</td><td align="left">C</td><td char="." align="char">151</td><td char="." align="char">151</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methylguanosine</td><td align="left">Gm_train</td><td align="left">G</td><td char="." align="char">636</td><td char="." align="char">636</td><td align="left"/></tr><tr><td align="left">Gm_test</td><td align="left">G</td><td char="." align="char">90</td><td char="." align="char">90</td><td align="left"/></tr><tr><td align="left" rowspan="2">2′-<italic>O</italic>-methyluridine</td><td align="left">Um_train</td><td align="left">U</td><td char="." align="char">1438</td><td char="." align="char">1438</td><td align="left"/></tr><tr><td align="left">Um_test</td><td align="left">U</td><td char="." align="char">205</td><td char="." align="char">205</td><td align="left"/></tr><tr><td align="left" rowspan="2">Inosine</td><td align="left">I_train</td><td align="left">A</td><td char="." align="char">5164</td><td char="." align="char">5164</td><td align="left"/></tr><tr><td align="left">I_test</td><td align="left">A</td><td char="." align="char">737</td><td char="." align="char">737</td><td align="left"/></tr></tbody></table></table-wrap><fig id="Fig7"><label>Fig. 7</label><caption><p>The motif of methylation sites. <bold>a</bold> m<sup>1</sup>A in the dataset of Chen et al. <bold>b</bold> m<sup>6</sup>A. <bold>c</bold> Ψ. <bold>d</bold> m<sup>1</sup>A. <bold>e</bold> m<sup>6</sup>Am. <bold>f</bold> Am. <bold>g</bold> Cm. <bold>h</bold> Gm. <bold>i</bold> Um. <bold>j</bold> m<sup>5</sup>C. <bold>k</bold> m<sup>5</sup>U. <bold>l</bold> m<sup>7</sup>G. <bold>m</bold> I in the dataset of Song et al.</p></caption><graphic xlink:href="12859_2024_5649_Fig7a_HTML" id="d32e3256"/><graphic xlink:href="12859_2024_5649_Fig7b_HTML" id="d32e3257"/></fig></p>
    </sec>
    <sec id="Sec17">
      <title>Feature encoding representation</title>
      <p id="Par79">Achieving an effective feature encoding representation of the sequence is crucial for improving the evaluation metrics of a model. This study uses Word2vec to transform the sequence into embedded vector representations. Since its introduction in 2013, Word2vec has significantly advanced the performance of a wide array of natural language processing (NLP) tasks.</p>
      <p id="Par80">The Word2vec methodology offers two different frameworks for encoding: Skip-gram and Continuous Bag of Words (CBOW). The Skip-gram approach predicts contextual information surrounding a given word, whereas the CBOW model generates an embedding for the target word based on its contextual associations. These embeddings are derived through a neural network application, adeptly capturing the inherent relationships within the data.</p>
      <p id="Par81">We developed an RNA embedding approach by treating RNA sequences as sentences and k consecutive RNA nucleotides (k-mers) as words within these sentences. Mathematically, we define the mapping from single nucleotides to the vector representation of k-mers <inline-formula id="IEq4"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f:\sum\nolimits_{{}}^{L} { \mapsto Y^{L - k + 1} }$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow/></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:mo>↦</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq4.gif"/></alternatives></inline-formula>, which is subsequently fed into the neural network for training. This process results in d-dimensional embedded vectors, denoted by <inline-formula id="IEq5"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{m}^{n} \in {\mathbb{R}}^{{m \times d_{m} }}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq5.gif"/></alternatives></inline-formula>, where <italic>m</italic> = <italic>L</italic> − <italic>k</italic> + 1, and <italic>d</italic><sub><italic>m</italic></sub> represents the embedding dimension. Gene2vec [<xref ref-type="bibr" rid="CR21">21</xref>] demonstrated that 3-mers provide the optimal prediction performance. Consequently, we adopted a 3-mers encoding strategy for the input data. Specifically, we employed a sliding window of size 3-nt to slide 41-nt sample sequences with one stride, generating a sequence of 39 words. Each word corresponds to an index in all possible 3-mer combinations(105 or 65 types). Given the relatively large dataset and limited word types in our corpus, we chose the Continuous Bag of Words (CBOW) model for encoding, as it offers faster training times than the Skip-gram model. We used the grid-search strategy for the optimization of the parameters for the experiments, word vector dimension in [100,3 00]. Feature encoding with a word vector dimension of 100 achieved the best performance. In summary, each 3-mer is converted into a word vector, transforming a 41-nt sequence into a 39 × 100 matrix, where 100 represents the word vector dimension.</p>
    </sec>
    <sec id="Sec18">
      <title>Model</title>
      <p id="Par82">As shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>, MSCAN represents an innovative DL architecture that employs a combination of multi-scale self- and cross-attention mechanisms and point-wise, fully connected layers in the encoder. This innovative approach enables the effective modeling of both intra- and inter-sequence interactions across a wide range of scales within RNA-seq data by transforming local RNA sequences into high-dimensional vectors via representations through its multi-scale self- and cross-attention networks. MSCAN efficiently extracts crucial RNA sequence features, thereby facilitating the accurate prediction of m<sup>1</sup>A modifications.<fig id="Fig8"><label>Fig. 8</label><caption><p>Structure of our computational framework based on multi-scale self- and cross-attention network to predict m<sup>1</sup>A methylation site</p></caption><graphic xlink:href="12859_2024_5649_Fig8_HTML" id="MO8"/></fig></p>
      <p id="Par83">The results of this study indicate that the nucleotide base neighboring the methylation site is instrumental in determining the specific type of methylation site and its potential functional consequences [<xref ref-type="bibr" rid="CR40">40</xref>–<xref ref-type="bibr" rid="CR42">42</xref>]. Therefore, the original sample sequence was extracted with two subsequences. These subsequences were centered on the sequence midpoint. One subsequence was 21-nt long, and the other was 31-nt long, as shown in Fig. <xref rid="Fig9" ref-type="fig">9</xref>.<fig id="Fig9"><label>Fig. 9</label><caption><p>Schematic diagram of the obtained subsequences</p></caption><graphic xlink:href="12859_2024_5649_Fig9_HTML" id="MO9"/></fig></p>
      <p id="Par84">In this paper, we represent the dataset as a collection of sample sequences, each consisting of a main sequence and two subsequences. The dataset can be expressed as  <inline-formula id="IEq6"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\{({\text{x}}}_{s0}^{1}, {\text{x}}_{s1}^{1} ,{\text{x}}_{s2}^{1} ,{\text{y}}^{1} )$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq6.gif"/></alternatives></inline-formula>, <inline-formula id="IEq7"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\text{x}}_{s0}^{2}, {\text{x}}_{s1}^{2}, {\text{x}}_{s2}^{2}, {\text{y}}^{2} )$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq7.gif"/></alternatives></inline-formula>, ⋯, <inline-formula id="IEq8"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{(x}}_{s0}^{n} , {\text{x}}_{s1}^{n}, {\text{x}}_{s2}^{n} ,{\text{y}}^{n} )\}$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:msubsup><mml:mtext>(x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>x</mml:mtext><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mtext>y</mml:mtext></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq8.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq9"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{n} \in \left\{ {0,1} \right\}$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq9.gif"/></alternatives></inline-formula>, <inline-formula id="IEq10"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s0}^{i} ,x_{s1}^{i} ,x_{s2}^{i}$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq10.gif"/></alternatives></inline-formula> are the three sequences of the i-th sample, <inline-formula id="IEq11"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s0}^{i}$$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq11.gif"/></alternatives></inline-formula> is the main sequence, with s0 = 41, <inline-formula id="IEq12"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{s1}^{i} ,x_{s2}^{i}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq12.gif"/></alternatives></inline-formula> is the subsequence, with s1 = 21, and s2 = 31. Experiments show that the performance of trained models exhibits variability when the order of input sample sequences is altered, as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. MSCAN employs the Word2vec encoder to encode word vectors for these sequences. For example, sequences with lengths 21-nt, 41-nt, and 31-nt are transformed into three distinct matrices of varying dimensions: 19 × 100, 39 × 100, and 29 × 100, respectively.</p>
      <p id="Par85">To account for the lack of recursion or convolution in the model, it is necessary to incorporate information about the relative positions of tokens within sequences so that the model can utilize sequence order effectively. To achieve this, "position encoding" is added to the Word2vec embedding output, forming the input for the encoder. The positional encoding method employed in this work was first introduced by Vaswani et al. [<xref ref-type="bibr" rid="CR43">43</xref>] in a machine translation task.</p>
      <p id="Par86">The encoder is composed of a stack of N = 3 identical layers. Each layer has two sub-layers. The first sub-layer is a multi-scale self- and cross-attention network, while the second is a position-wise, fully connected feed-forward network. To facilitate effective information flow, each of these sub-layers incorporates a residual connection in conjunction with layer normalization.</p>
      <p id="Par87">The output generated by each sub-layer can be expressed as LayerNorm(x + sublayer(x)), where sublayer(x) represents the function associated with the sub-layer in question. Both the embedding layer and all model sub-layers yield outputs with a dimension of <inline-formula id="IEq13"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{model} = 64$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq13.gif"/></alternatives></inline-formula>, allowing for seamless residual connections.</p>
      <p id="Par88">Upon completion of the classification process, a linear transformation followed by a sigmoid function is employed to convert the encoder output into predicted probabilities. We used grid-search to choose the hyperparameters on the training data of Chen et al., specifically, epoch in [50, 100], learning_rate in [5e−4, 5e−2], batch in [5, 10, 20, 60], and dropout in [0.2, 0.5]. Final epoch = 100, learning_rate = 5e−4, batch = 10, and dropout = 0.2 is the optimal hyperparameters.</p>
    </sec>
    <sec id="Sec19">
      <title>Multi-scale self- and cross-attention network</title>
      <p id="Par89">The multi-scale self and cross-attention network constitutes the initial layer of the encoder, designed to handle linguistic input at various scales. Utilizing word2vec embeddings, matrices at three distinct scales (take <inline-formula id="IEq14"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}} ,X_{s1}^{{}} ,X_{s2}^{{}}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq14.gif"/></alternatives></inline-formula> as an example) are introduced into the self-attention and cross-attention modules for simultaneous computation. Specifically, <inline-formula id="IEq15"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq15.gif"/></alternatives></inline-formula> is incorporated into the self-attention module, while the two combinations (<inline-formula id="IEq16"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq16.gif"/></alternatives></inline-formula> and <inline-formula id="IEq17"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq17.gif"/></alternatives></inline-formula>, <inline-formula id="IEq18"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq18.gif"/></alternatives></inline-formula> and <inline-formula id="IEq19"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s2}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq19.gif"/></alternatives></inline-formula>) are integrated into the cross-attention module. Subsequently, the outputs from these modules are directly added and relayed to the subsequent layer, as shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>.<fig id="Fig10"><label>Fig. 10</label><caption><p>The internal structure of the multi-scale self- and cross-attention network</p></caption><graphic xlink:href="12859_2024_5649_Fig10_HTML" id="MO10"/></fig></p>
    </sec>
    <sec id="Sec20">
      <title>Cross-attention network</title>
      <p id="Par90">The cross-attention network is designed to extract and learn relationships between words in sequences of varying scales, effectively capturing associations across different sequences. Using sequences <inline-formula id="IEq20"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M52"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq20.gif"/></alternatives></inline-formula> and <inline-formula id="IEq21"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M54"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq21.gif"/></alternatives></inline-formula> as examples, we first transform each sequence into three different terms, which are query, key, and value. This is achieved through the application of linear projections.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{s0} = X_{s0} W_{s0}^{Q} ,K_{s0} = X_{s0} W_{s0}^{K} ,V_{s0} = X_{s0} W_{s0}^{V}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{s1} = X_{s1} W_{s1}^{Q} ,K_{s1} = X_{s1} W_{s1}^{K} ,V_{s1} = X_{s1} W_{s1}^{V}$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq22"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{m} \in {\mathbb{R}}^{{m \times d_{model} }}$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq22.gif"/></alternatives></inline-formula> is the output of the sequence embedding module, <italic>m</italic> represents the length of the input sequence <inline-formula id="IEq23"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m \in \left\{ {s_{0} ,s_{1} ,s_{2} } \right\}$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq23.gif"/></alternatives></inline-formula>. <inline-formula id="IEq24"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{m}^{Q} ,W_{m}^{K} \in {\mathbb{R}}^{{d_{model} \times d_{k} }}$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq24.gif"/></alternatives></inline-formula>, <inline-formula id="IEq25"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{m}^{V} \in {\mathbb{R}}^{{d_{model} \times d_{v} }}$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq25.gif"/></alternatives></inline-formula>. <italic>X</italic><sub><italic>m</italic></sub> is transformed into the query matrix <inline-formula id="IEq26"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{m} \in {\mathbb{R}}^{{m \times d_{k} }}$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq26.gif"/></alternatives></inline-formula>, the key matrix <inline-formula id="IEq27"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K_{m} \in {\mathbb{R}}^{{m \times d_{k} }}$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq27.gif"/></alternatives></inline-formula>, and the value matrix <inline-formula id="IEq28"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{m} \in {\mathbb{R}}^{{m \times d_{v} }}$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq28.gif"/></alternatives></inline-formula>, in which <italic>d</italic><sub><italic>k</italic></sub> is the dimension of matrices <italic>Q</italic><sub><italic>m</italic></sub>, <italic>K</italic><sub><italic>m</italic></sub>, and <italic>d</italic><sub><italic>v</italic></sub> is the dimension of matrix <italic>V</italic><sub><italic>m</italic></sub>.</p>
      <p id="Par91">Second, we compute the cross-modal dot product between the query vector of <inline-formula id="IEq29"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M74"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq29.gif"/></alternatives></inline-formula> and the key vector of <inline-formula id="IEq30"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M76"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq30.gif"/></alternatives></inline-formula>, dividing the result value by <inline-formula id="IEq31"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sqrt {d_{k} }$$\end{document}</tex-math><mml:math id="M78"><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq31.gif"/></alternatives></inline-formula>, to estimate the association between the <inline-formula id="IEq32"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s0}^{{}}$$\end{document}</tex-math><mml:math id="M80"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq32.gif"/></alternatives></inline-formula> and <inline-formula id="IEq33"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{s1}^{{}}$$\end{document}</tex-math><mml:math id="M82"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow/></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq33.gif"/></alternatives></inline-formula>. These results are subsequently refined and normalized utilizing the softmax function, yielding attention weight coefficients. Lastly, we leverage these coefficients to aggregate the corresponding value vectors from each feature sequence, thereby facilitating that the associated information between the two sequences is obtained. The cross-attention function can be described as follows:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Cross - Attention(Q_{s0} ,K_{s1} ,V_{s1} ) = softmax\left( {\frac{{Q_{s0} K_{s1}^{T} }}{{\sqrt {d_{k} } }}} \right)V_{s1}$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec21">
      <title>Self-attention network</title>
      <p id="Par92">In contrast to the cross-attention module, which primarily focuses on inter-sequence interactions, the self-attention module identifies and elucidates intra-sequence associations. The self-attention function is described as<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Self - Attention(Q_{s0} ,K_{s0} ,V_{s0} ) = softmax\left( {\frac{{Q_{s0} K_{s0}^{T} }}{{\sqrt {d_{k} } }}} \right)V_{s0}$$\end{document}</tex-math><mml:math id="M86" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec22">
      <title>Multi-head multi-scale self- and cross-attention</title>
      <p id="Par93">The above elucidation pertains to single-headed attention, a fundamental mechanism in attention-based models. However, multi-headed attention is commonly employed in practice to augment model efficacy and expedite training. This technique entails conducting single-headed attention in parallel across multiple instances, known as "heads", and subsequently integrating the outcomes derived from each head. By incorporating multi-headed attention, the model can effectively capture diverse contextual information and intricate relationships inherent in the input data. The function of cross-attention is described as:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; MultiHead(Q,K,V) = Concat\left( {head_{1} ,...,head_{h} } \right)W^{O} \\ &amp; \quad where^{{}} head_{i} = Attention\left( {Q_{s0} W_{s0s0i}^{{Q_{s0} }} ,K_{s0} W_{s0s0i}^{{K_{s0} }} ,V_{s0} W_{s0s0i}^{{V_{s0} }} } \right) \\ &amp; \quad + Attention\left( {Q_{s0} W_{s0s1i}^{{Q_{s0} }} ,K_{s1} W_{s0s1i}^{{K_{s1} }} ,V_{s1} W_{s0s1i}^{{V_{s1} }} } \right) \\ &amp; \quad + Attention\left( {Q_{s0} W_{s0s2i}^{{Q_{s0} }} ,K_{s2} W_{s0s2i}^{{K_{s2} }} ,V_{s2} W_{s0s2i}^{{V_{s2} }} } \right) \\ \end{aligned}$$\end{document}</tex-math><mml:math id="M88" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>M</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:msup><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mi>w</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow/></mml:msup><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where the <inline-formula id="IEq34"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{s0s0i}^{{Q_{s0} }} ,W_{s0s0i}^{{K_{s0} }} ,W_{s0s1i}^{{Q_{s0} }} ,W_{s0s1i}^{{K_{s1} }} ,W_{s0s2i}^{{Q_{s0} }} ,W_{s0s2i}^{{K_{s2} }} , \in {\mathbb{R}}^{{d_{model} \times d_{k} }}$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq34.gif"/></alternatives></inline-formula>, <inline-formula id="IEq35"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{s0s0i}^{{V_{s0} }} ,W_{s0s1i}^{{V_{s1} }} ,W_{s0s2i}^{{V_{s2} }} \in {\mathbb{R}}^{{d_{model} \times d_{v} }}$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>0</mml:mn><mml:mi>s</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq35.gif"/></alternatives></inline-formula> and <inline-formula id="IEq36"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W^{O} \in {\mathbb{R}}^{{hd_{v} \times d_{model} }}$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>O</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">model</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2024_5649_Article_IEq36.gif"/></alternatives></inline-formula></p>
      <p id="Par94">In this task, we employ h = 8 parallel attention layers. For each layer,we use <italic>d</italic><sub><italic>k</italic></sub> = <italic>d</italic><sub><italic>v</italic></sub> = <italic>d</italic><sub><italic>model</italic></sub>/h = 8.</p>
    </sec>
    <sec id="Sec23">
      <title>Position-wise feed-forward networks</title>
      <p id="Par95">After the multi-headed, multi-scale self- and cross-attention layer, a second sub-layer is incorporated to augment the representative capacity of the model further. This additional component comprises a position-wise, fully connected feed-forward network, enhancing the overall model performance. The architecture of this network entails two successive linear transformations, with an intervening rectified linear unit (ReLU) activation function, ensuring a non-linear and expressive representation of the input data. It is defined as:<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$FFN(x) = \max (0,xW_{1} + b_{1} )W_{2} + b_{2}$$\end{document}</tex-math><mml:math id="M96" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true">max</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2024_5649_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par96">The input and output have dimensionality d<sub>model</sub> = 64, while the inner layer's dimensionality is d<sub>ff</sub> = 256.</p>
    </sec>
    <sec id="Sec24">
      <title>Classification module</title>
      <p id="Par97">To accomplish the classification task, the initial step involves computing the average of the encoder output. Subsequently, a linear transformation is applied, followed by implementing a sigmoid activation function. The optimization of the model is facilitated by employing cross-entropy loss as the primary objective. Finally, the methylation site probabilities are acquired, providing a robust and comprehensive representation of the underlying biological processes.</p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>RNA</term>
        <def>
          <p id="Par4">Ribonucleic acid</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>1</sup>A</term>
        <def>
          <p id="Par5">N1-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>6</sup>A</term>
        <def>
          <p id="Par6">N6-methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Ψ</term>
        <def>
          <p id="Par7">Pseudouridine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>6</sup>Am</term>
        <def>
          <p id="Par8">N6,2′-<italic>O</italic>-dimethyl adenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Am</term>
        <def>
          <p id="Par9">2′-<italic>O</italic>-Methyladenosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Cm</term>
        <def>
          <p id="Par10">2′-<italic>O</italic>-Methylcytidine</p>
        </def>
      </def-item>
      <def-item>
        <term>Gm</term>
        <def>
          <p id="Par11">2′-<italic>O</italic>-Methylguanosine</p>
        </def>
      </def-item>
      <def-item>
        <term>Um</term>
        <def>
          <p id="Par12">2′-<italic>O</italic>-Methyluridine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>5</sup>C</term>
        <def>
          <p id="Par13">5-Methylcytidine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>7</sup>G</term>
        <def>
          <p id="Par14">7-Methylguanosine</p>
        </def>
      </def-item>
      <def-item>
        <term>m<sup>5</sup>U</term>
        <def>
          <p id="Par15">5-Methyluridine</p>
        </def>
      </def-item>
      <def-item>
        <term>I</term>
        <def>
          <p id="Par16">Inosine</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par17">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>BiLSTM</term>
        <def>
          <p id="Par18">Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p id="Par19">Long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par20">Recurrent neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>NLP</term>
        <def>
          <p id="Par21">Natural language processing</p>
        </def>
      </def-item>
      <def-item>
        <term>DL</term>
        <def>
          <p id="Par22">Deep learning</p>
        </def>
      </def-item>
      <def-item>
        <term>MSCAN</term>
        <def>
          <p id="Par23">Multi-scale self- and cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>MCAN</term>
        <def>
          <p id="Par24">Multi-scale cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>SCAN</term>
        <def>
          <p id="Par25">Self- and cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>CAN</term>
        <def>
          <p id="Par26">Cross-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>SAN</term>
        <def>
          <p id="Par27">Self-attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>Sn</term>
        <def>
          <p id="Par28">Sensitivity</p>
        </def>
      </def-item>
      <def-item>
        <term>Sp</term>
        <def>
          <p id="Par29">Specificity</p>
        </def>
      </def-item>
      <def-item>
        <term>ACC</term>
        <def>
          <p id="Par30">Accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>Pre</term>
        <def>
          <p id="Par31">Precision</p>
        </def>
      </def-item>
      <def-item>
        <term>MCC</term>
        <def>
          <p id="Par32">Matthews correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>AUROC</term>
        <def>
          <p id="Par33">Area under the receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>AUPRC</term>
        <def>
          <p id="Par34">Area under the precision-recall curve</p>
        </def>
      </def-item>
      <def-item>
        <term>ENAC</term>
        <def>
          <p id="Par35">Enhanced nucleic acid composition</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>HW built the architecture for MSCAN, designed and implemented the experiments, analyzed the results, and wrote the paper. LZ and TH conducted the experiments and revised the paper. DW conducted the experiments, analyzed the results, and revised the paper. LZ and YS supervised the project, analyzed the result, and revised the paper. All authors read, critically revised, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work has been supported by the National Natural Science Foundation of China (31871337 and 61971422 to LZ), and the "333 Project" of Jiangsu(BRA2020328 to WHL). The funding body did not play any roles in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The data supporting the findings of the article is available at the web server <ext-link ext-link-type="uri" xlink:href="http://47.242.23.141/MSCAN/index.php">http://47.242.23.141/MSCAN/index.php</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par98">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par99">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par100">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>El Allali</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Elhamraoui</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Daoud</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Machine learning applications in RNA modification sites prediction</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>5510</fpage>
        <lpage>5524</lpage>
        <pub-id pub-id-type="pmid">34712397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>SY</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bi</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>XL</given-names>
          </name>
        </person-group>
        <article-title>A brief review of machine learning methods for RNA methylation sites prediction</article-title>
        <source>Methods</source>
        <year>2022</year>
        <volume>203</volume>
        <fpage>399</fpage>
        <lpage>421</lpage>
        <pub-id pub-id-type="pmid">35248693</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Bioinformatics approaches for deciphering the epitranscriptome: recent progress and emerging topics</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2020</year>
        <volume>18</volume>
        <fpage>1587</fpage>
        <lpage>1604</lpage>
        <pub-id pub-id-type="pmid">32670500</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>LF</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>XQ</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>FS</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>XH</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>TB</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>XM</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>KX</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>MY</given-names>
          </name>
        </person-group>
        <article-title>TransformerCPI: improving compound–protein interaction prediction by sequence-based deep learning with self-attention mechanism and label reversal experiments</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>16</issue>
        <fpage>4406</fpage>
        <lpage>4414</lpage>
        <pub-id pub-id-type="pmid">32428219</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>ZT</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>BW</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>KQ</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>de Magalhaes</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Rigden</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Attention-based multi-label neural networks for integrated prediction and interpretation of twelve widely occurring RNA modifications</article-title>
        <source>Nat Commun</source>
        <year>2021</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="pmid">33397941</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grozhik</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Olarerin-George</surname>
            <given-names>AO</given-names>
          </name>
          <name>
            <surname>Sindelar</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Jaffrey</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Antibody cross-reactivity accounts for widespread appearance of m1A in 5' UTRs</article-title>
        <source>Nat Commun</source>
        <year>2019</year>
        <volume>11</volume>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dominissini</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The dynamic N(1)-methyladenosine methylome in eukaryotic messenger RNA</article-title>
        <source>Nature</source>
        <year>2016</year>
        <volume>530</volume>
        <issue>7591</issue>
        <fpage>1</fpage>
        <lpage>39</lpage>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>ZK</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>GZ</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Dominissini</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High-resolution N-6-methyladenosine (m(6)A) map using photo-crosslinking-assisted m(6)A sequencing</article-title>
        <source>Angew Chem Int Ed</source>
        <year>2015</year>
        <volume>54</volume>
        <issue>5</issue>
        <fpage>1587</fpage>
        <lpage>1590</lpage>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Transcriptome-wide mapping reveals reversible and dynamic N(1)-methyladenosine methylome</article-title>
        <source>Nat Chem Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>5</issue>
        <fpage>311</fpage>
        <lpage>316</lpage>
        <pub-id pub-id-type="pmid">26863410</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Masiello</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Biggiogera</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Ultrastructural localization of 5-methylcytosine on DNA and RNA</article-title>
        <source>Cell Mol Life Sci</source>
        <year>2017</year>
        <volume>74</volume>
        <issue>16</issue>
        <fpage>3057</fpage>
        <lpage>3064</lpage>
        <pub-id pub-id-type="pmid">28391361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiaoyu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xushen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Meiling</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Kun</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ying</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Base-resolution mapping reveals distinct m1A methylome in nuclear- and mitochondrial-encoded transcripts</article-title>
        <source>Mol Cell</source>
        <year>2017</year>
        <volume>68</volume>
        <issue>5</issue>
        <fpage>993</fpage>
        <lpage>1005</lpage>
        <pub-id pub-id-type="pmid">29107537</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rauch</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Dickinson</surname>
            <given-names>BC</given-names>
          </name>
        </person-group>
        <article-title>Evolution of a reverse transcriptase to map N1-methyladenosine in human messenger RNA</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>12</issue>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">30573832</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y-H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>SRAMP: prediction of mammalian N6-methyladenosine (m6A) sites based on sequence-derived features</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>10</issue>
        <fpage>e91</fpage>
        <lpage>e91</lpage>
        <pub-id pub-id-type="pmid">26896799</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>RAMPred: identifying the N(1)-methyladenosine sites in eukaryotic transcriptomes</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="pmid">28442746</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>iRNA-3typeA: identifying three types of modification at RNA's adenosine sites</article-title>
        <source>Mol Ther Nucleic Acids</source>
        <year>2018</year>
        <volume>11</volume>
        <fpage>468</fpage>
        <lpage>474</lpage>
        <pub-id pub-id-type="pmid">29858081</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>iMRM: a platform for simultaneously identifying multiple kinds of RNA modifications</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>11</issue>
        <fpage>3336</fpage>
        <lpage>3342</lpage>
        <pub-id pub-id-type="pmid">32134472</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Iuchi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Matsutani</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yamada</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Iwano</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Sumi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hosoda</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Fukunaga</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hamada</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Representation learning applications in biological sequence analysis</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>3198</fpage>
        <lpage>3208</lpage>
        <pub-id pub-id-type="pmid">34141139</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Angermueller</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Pärnamaa</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Parts</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Stegle</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for computational biology</article-title>
        <source>Mol Syst Biol</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>7</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huss</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Abid</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mohammadi</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Torkamani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Telenti</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A primer on deep learning in genomics</article-title>
        <source>Nat Genet</source>
        <year>2019</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>12</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">30478442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>EDLm(6)APred: ensemble deep learning approach for mRNA m(6)A site prediction</article-title>
        <source>BMC Bioinform</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>PW</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>LY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Gene2vec: gene subsequence embedding for prediction of mammalian N-6-methyladenosine sites from mRNA</article-title>
        <source>RNA</source>
        <year>2019</year>
        <volume>25</volume>
        <issue>2</issue>
        <fpage>205</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="pmid">30425123</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>AthMethPre: a web server for the prediction and query of mRNA m(6)A sites in <italic>Arabidopsis</italic>
<italic>thaliana</italic></article-title>
        <source>Mol Biosyst</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>11</issue>
        <fpage>3333</fpage>
        <lpage>3337</lpage>
        <pub-id pub-id-type="pmid">27550167</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lv</surname>
            <given-names>ZB</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>A convolutional neural network using dinucleotide one-hot encoder for identifying DNA N6-methyladenine sites in the rice genome</article-title>
        <source>Neurocomputing</source>
        <year>2021</year>
        <volume>422</volume>
        <fpage>214</fpage>
        <lpage>221</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tahir</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hayat</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>KT</given-names>
          </name>
        </person-group>
        <article-title>Prediction of N6-methyladenosine sites using convolution neural network model based on distributed feature representations</article-title>
        <source>Neural Netw</source>
        <year>2020</year>
        <volume>129</volume>
        <fpage>385</fpage>
        <lpage>391</lpage>
        <pub-id pub-id-type="pmid">32593932</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AI</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Baggag</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bensmail</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive review and assessment of computational methods for predicting RNA post-transcriptional modification sites from RNA sequences</article-title>
        <source>Brief Bioinform</source>
        <year>2019</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>1676</fpage>
        <lpage>1696</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>NN</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>BERMP: a cross-species classifier for predicting m(6)A sites by integrating a deep learning algorithm and a random forest approach</article-title>
        <source>Int J Biol Sci</source>
        <year>2018</year>
        <volume>14</volume>
        <issue>12</issue>
        <fpage>1669</fpage>
        <lpage>1677</lpage>
        <pub-id pub-id-type="pmid">30416381</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hamada</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>DeepM6ASeq: prediction and characterization of m6A-containing sequences using deep learning</article-title>
        <source>BMC Bioinform</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Rp</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sw</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Gan</surname>
            <given-names>WA</given-names>
          </name>
        </person-group>
        <article-title>DeepFusion: a deep learning based multi-scale feature fusion method for predicting drug–target interactions</article-title>
        <source>Methods</source>
        <year>2022</year>
        <volume>204</volume>
        <fpage>269</fpage>
        <lpage>277</lpage>
        <pub-id pub-id-type="pmid">35219861</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Kim Y, Denton C, Hoang L, Rush AM. Structured attention networks. 2017, p. 1–21.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Plant6mA: a predictor for predicting N6-methyladenine sites with lightweight structure in plant genomes</article-title>
        <source>Methods (San Diego, Calif)</source>
        <year>2022</year>
        <volume>204</volume>
        <fpage>1</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="pmid">35483547</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>FY</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>DX</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>YZ</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Daly</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>QZ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>iLearnPlus: a comprehensive and automated machine-learning platform for nucleic acid and protein sequence analysis, prediction and visualization</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>10</issue>
        <fpage>e60</fpage>
        <pub-id pub-id-type="pmid">33660783</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>KY</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>TY</given-names>
          </name>
          <name>
            <surname>Kao</surname>
            <given-names>HJ</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>WC</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>HD</given-names>
          </name>
        </person-group>
        <article-title>dbPTM in 2019: exploring disease association and cross-talk of post-translational modifications</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>D298</fpage>
        <lpage>D308</lpage>
        <pub-id pub-id-type="pmid">30418626</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Shilatifard</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The language of histone crosstalk</article-title>
        <source>Cell</source>
        <year>2010</year>
        <volume>142</volume>
        <issue>5</issue>
        <fpage>682</fpage>
        <lpage>685</lpage>
        <pub-id pub-id-type="pmid">20813257</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boratyn</surname>
            <given-names>GM</given-names>
          </name>
          <name>
            <surname>Camacho</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>PS</given-names>
          </name>
          <name>
            <surname>Coulouris</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Fong</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Matten</surname>
            <given-names>WT</given-names>
          </name>
          <name>
            <surname>McGinnis</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Merezhuk</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BLAST: a more efficient report with usability improvements</article-title>
        <source>Nucleic Acids Res</source>
        <year>2013</year>
        <volume>41</volume>
        <issue>W1</issue>
        <fpage>W29</fpage>
        <lpage>W33</lpage>
        <pub-id pub-id-type="pmid">23609542</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Sun LC, Liu B, Tao JH, Lian Z. IEEE: multimodal cross- and self-attention network for speech emotion recognition. In: IEEE international conference on acoustics, speech and signal processing (ICASSP): Jun 06–11 2021; Electr Network. 2021, p. 4275–4279.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Chen CF, Fan Q, Panda R. CrossViT: cross-attention multi-scale vision transformer for image classification. In: ICCV. 2021, p. 1–12.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Guo Q, Qiu X, Liu P, Xue X, Zhang Z. Multi-scale self-attention for text classification. In: Proceedings of the AAAI conference on artificial intelligence, 2020, p. 7847–7854.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crooks</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Chandonia</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>SE</given-names>
          </name>
        </person-group>
        <article-title>WebLogo: a sequence logo generator</article-title>
        <source>Genome Res</source>
        <year>2004</year>
        <volume>14</volume>
        <issue>6</issue>
        <fpage>1188</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="pmid">15173120</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schneider</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Stephens</surname>
            <given-names>RM</given-names>
          </name>
        </person-group>
        <article-title>Sequence logos: a new way to display consensus sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>1990</year>
        <volume>18</volume>
        <issue>20</issue>
        <fpage>6097</fpage>
        <lpage>6100</lpage>
        <pub-id pub-id-type="pmid">2172928</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lister</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Mukamel</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Nery</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Urich</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Puddifoot</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Johnson</surname>
            <given-names>ND</given-names>
          </name>
          <name>
            <surname>Lucero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Dwork</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Schultz</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ecker</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>Global epigenomic reconfiguration during mammalian brain development</article-title>
        <source>Science</source>
        <year>2013</year>
        <volume>341</volume>
        <issue>6146</issue>
        <fpage>629</fpage>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>JU</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Distribution, recognition and regulation of non-CpG methylation in the adult mammalian brain</article-title>
        <source>Nat Neurosci</source>
        <year>2014</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>215</fpage>
        <lpage>222</lpage>
        <pub-id pub-id-type="pmid">24362762</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ziller</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bock</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Boyle</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Epstein</surname>
            <given-names>CB</given-names>
          </name>
          <name>
            <surname>Bernstein</surname>
            <given-names>BE</given-names>
          </name>
          <name>
            <surname>Lengauer</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Genomic distribution and inter-sample variation of non-CpG methylation across human cell types</article-title>
        <source>PLoS Genet</source>
        <year>2011</year>
        <volume>7</volume>
        <issue>12</issue>
        <fpage>e1002389</fpage>
        <pub-id pub-id-type="pmid">22174693</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. Attention is all you need. arXiv. 2017, p. 1–15.</mixed-citation>
    </ref>
  </ref-list>
</back>
