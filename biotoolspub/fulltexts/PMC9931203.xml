<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Digital Health</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2767-3170</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9931203</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000152</article-id>
    <article-id pub-id-type="publisher-id">PDIG-D-22-00258</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Medical Conditions</subject>
          <subj-group>
            <subject>Infectious Diseases</subject>
            <subj-group>
              <subject>Viral Diseases</subject>
              <subj-group>
                <subject>Covid 19</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Parsers</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Parsers</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Diagnostic Medicine</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Natural Language Processing</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Public and Occupational Health</subject>
          <subj-group>
            <subject>Behavioral and Social Aspects of Health</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Natural Language Processing</subject>
            <subj-group>
              <subject>Named Entity Recognition</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Medical Conditions</subject>
          <subj-group>
            <subject>Infectious Diseases</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Large-scale application of named entity recognition to biomedicine and epidemiology</article-title>
      <alt-title alt-title-type="running-head">Biomedical-epidemiology-named entity recognition</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1061-5845</contrib-id>
        <name>
          <surname>Raza</surname>
          <given-names>Shaina</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Reji</surname>
          <given-names>Deepak John</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shajan</surname>
          <given-names>Femi</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Bashir</surname>
          <given-names>Syed Raza</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Dalla Lana School of Public Health, University of Toronto, Toronto, Ontario, Canada</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Environmental Resources Management, Bangalore, India</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Toronto Metropolitan University, Toronto, Ontario, Canada</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Mattie</surname>
          <given-names>Heather</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Harvard University T H Chan School of Public Health, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>No competing interests.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>shaina.raza@utoronto.ca</email> (SR); <email>syedraza.bashir@ryerson.ca</email> (SRB)</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>7</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <volume>1</volume>
    <issue>12</issue>
    <elocation-id>e0000152</elocation-id>
    <history>
      <date date-type="received">
        <day>4</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>1</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Raza et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Raza et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pdig.0000152.pdf"/>
    <abstract>
      <sec id="sec001">
        <title>Background</title>
        <p>Despite significant advancements in biomedical named entity recognition methods, the clinical application of these systems continues to face many challenges: (1) most of the methods are trained on a limited set of clinical entities; (2) these methods are heavily reliant on a large amount of data for both pre-training and prediction, making their use in production impractical; (3) they do not consider non-clinical entities, which are also related to patient’s health, such as social, economic or demographic factors.</p>
      </sec>
      <sec id="sec002">
        <title>Methods</title>
        <p>In this paper, we develop Bio-Epidemiology-NER (<ext-link xlink:href="https://pypi.org/project/Bio-Epidemiology-NER/" ext-link-type="uri">https://pypi.org/project/Bio-Epidemiology-NER/</ext-link>) an open-source Python package for detecting biomedical named entities from the text. This approach is based on a Transformer-based system and trained on a dataset that is annotated with many named entities (medical, clinical, biomedical, and epidemiological). This approach improves on previous efforts in three ways: (1) it recognizes many clinical entity types, such as medical risk factors, vital signs, drugs, and biological functions; (2) it is easily configurable, reusable, and can scale up for training and inference; (3) it also considers non-clinical factors (age and gender, race and social history and so) that influence health outcomes. At a high level, it consists of the phases: pre-processing, data parsing, named entity recognition, and named entity enhancement.</p>
      </sec>
      <sec id="sec003">
        <title>Results</title>
        <p>Experimental results show that our pipeline outperforms other methods on three benchmark datasets with macro-and micro average F1 scores around 90 percent and above.</p>
      </sec>
      <sec id="sec004">
        <title>Conclusion</title>
        <p>This package is made publicly available for researchers, doctors, clinicians, and anyone to extract biomedical named entities from unstructured biomedical texts.</p>
      </sec>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>This paper introduces and presents a python package <ext-link xlink:href="https://pypi.org/project/Bio-Epidemiology-NER/" ext-link-type="uri">https://pypi.org/project/Bio-Epidemiology-NER/</ext-link> that can extract named entities from biomedical texts. Different from previous works, this package extracts not only clinical entities, such as disease, signs, and symptoms, but also demographics of the patients from the texts. This package can be used with minor code requirements and by epidemiologists, doctors, practitioners, or others in the field to see the named entities from texts. The knowledge gained from the named entities helps the end users see the statistics or spread of infectious disease in the least time and while parsing many free texts.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution>University of Toronto</institution>
        </funding-source>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1061-5845</contrib-id>
          <name>
            <surname>Raza</surname>
            <given-names>Shaina</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>The authors received no specific funding for this work.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="8"/>
      <table-count count="6"/>
      <page-count count="18"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>data is benchmark, cited and is available.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>data is benchmark, cited and is available.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec005">
    <title>1 Introduction</title>
    <p>Named entity recognition (NER) [<xref rid="pdig.0000152.ref001" ref-type="bibr">1</xref>], a subtask of Natural Language Processing (NLP), seeks to identify and classify named entities (such as person, place, and event) in the unstructured text into pre-defined categories. In the biomedical domain, a fundamental task of NLP is the recognition of named entities, such as genes, diseases, species, chemicals, medical codes, drug names, and so [<xref rid="pdig.0000152.ref002" ref-type="bibr">2</xref>]. NER can extract meaningful information from biomedical and clinical texts that can be used for many purposes, such as to study the statistical significance of certain entities (diseases, conditions), events, classification, or relation extraction tasks [<xref rid="pdig.0000152.ref003" ref-type="bibr">3</xref>]. The recognition of clinical information through NER on a typical medical record is shown in <xref rid="pdig.0000152.g001" ref-type="fig">Fig 1</xref>.</p>
    <fig position="float" id="pdig.0000152.g001">
      <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>Example of the medical records NER result.</title>
      </caption>
      <graphic xlink:href="pdig.0000152.g001" position="float"/>
    </fig>
    <p>As illustrated in <xref rid="pdig.0000152.g001" ref-type="fig">Fig 1</xref>, it is possible to extract medical information from a typical medical record, such as disease disorder or signs/symptoms, as well as personal demographics (age, sex, location). The state-of-the-art work [<xref rid="pdig.0000152.ref003" ref-type="bibr">3</xref>–<xref rid="pdig.0000152.ref005" ref-type="bibr">5</xref>] in biomedical NER mainly focuses on limited named entities (disease, chemicals, genes, etc.,). However, many biomedical entities must be considered, particularly those related to clinical diagnoses, such as disease, symptoms, medical concepts, risk factors, and vital signs; epidemiological entities, such as infectious diseases or patient demographics. This research is motivated by the need for an efficient and comprehensive biomedical NER that can automatically extract many entity types (clinical, epidemiological, demographics) from free texts (medical records, electronic health records, published literature) [<xref rid="pdig.0000152.ref006" ref-type="bibr">6</xref>] in multiple formats (text, PDFs, rich text). This research aims to facilitate medical practitioners, clinicians, nurses, and doctors in the fast retrieval of information with high accuracy and efficiency.</p>
    <p>In the state-of-the-art, the NER models are categorized into three main methods: early rule-based and dictionary-based methods [<xref rid="pdig.0000152.ref007" ref-type="bibr">7</xref>], statistical machine-learning-based methods [<xref rid="pdig.0000152.ref006" ref-type="bibr">6</xref>], and deep-learning-based methods [<xref rid="pdig.0000152.ref002" ref-type="bibr">2</xref>,<xref rid="pdig.0000152.ref008" ref-type="bibr">8</xref>,<xref rid="pdig.0000152.ref009" ref-type="bibr">9</xref>] in recent years. Although rule-based methods have demonstrated high accuracy, they require many rules written by subject-matter experts, which is a limitation. Statistical machine learning methods also require an annotated corpus, which is not always feasible for large training tasks and limited resources (time and annotators). Deep learning methods have demonstrated powerful generalization ability in recent years and have become the mainstream method for solving NER tasks [<xref rid="pdig.0000152.ref010" ref-type="bibr">10</xref>]. The development of hardware capabilities, the emergence of distributed word representations, and the availability of large training corpora have contributed significantly to the success of deep neural network-based methods [<xref rid="pdig.0000152.ref011" ref-type="bibr">11</xref>,<xref rid="pdig.0000152.ref012" ref-type="bibr">12</xref>].</p>
    <p>One of the most effective deep-neural network-based models is Bidirectional Encoder Representations from Transformers (BERT) [<xref rid="pdig.0000152.ref013" ref-type="bibr">13</xref>], which is a multi-layer Transformer [<xref rid="pdig.0000152.ref012" ref-type="bibr">12</xref>] model with self-attention [<xref rid="pdig.0000152.ref014" ref-type="bibr">14</xref>]. The original BERT model was trained on vast quantities of data for more than 104 languages, making its representations applicable to many smaller and similar downstream tasks, such as classification, NER, and relation extraction. Research shows that the distillation of a large language model can yield almost the same results as the original model, but we benefit from better efficiency and ease of use for production [<xref rid="pdig.0000152.ref015" ref-type="bibr">15</xref>]. In this research, we employ DistilBERT [<xref rid="pdig.0000152.ref016" ref-type="bibr">16</xref>], a simplified version of the BERT with fewer parameters, faster training, and better performance for the task of biomedical NER. Our contribution to this research is three-fold:</p>
    <list list-type="order">
      <list-item>
        <p>We developed a python package BioEN, short for <bold>Bio</bold>-<bold>E</bold>pidemiology-<bold>N</bold>er (<ext-link xlink:href="https://pypi.org/project/Bio-Epidemiology-NER/" ext-link-type="uri">https://pypi.org/project/Bio-Epidemiology-NER/</ext-link>), which can recognize accurate biomedical named entity annotations from the free text data (medical records, clinical notes, case reports, scientific publications). This package can parse text data in various input formats, including text files, tabular data, and PDF files. To facilitate analysis for end users, the model outputs named entities in both data frames and annotated PDF formats (if the input is a PDF file). The novelty of this work is in the subtle integration of many NLP models that are stacked into a package for ease-of-use for the medical community and the researchers.</p>
      </list-item>
      <list-item>
        <p>We make this package publicly available for distribution as software tools via PyPI and pip, making it easy for developers, researchers, and anyone with minimal programming knowledge to download and install it for simple experiments and large, professional systems.</p>
      </list-item>
      <list-item>
        <p>We provide many biomedical entity types, such as diseases, risk factors, adverse events, and patient demographics, which are both extensive and more informative in comparison to previous works in this line of research.</p>
      </list-item>
    </list>
    <p>Experimental results on several benchmark datasets showed the superiority of our approach compared to the state-of-the-art methods.</p>
    <p>The rest of the paper is organized as follows: section 2 is the related work, section 3 is the methodology, section 4 is the experimental setup, section 5 is the results and analysis, section 6 is the discussion, and section 7 is the conclusion.</p>
  </sec>
  <sec id="sec006">
    <title>2 Related work</title>
    <p>Named entity recognition (NER) is the task of identifying a named entity (a real-world object or concept) in unstructured text and then classifying the entity into a standard category [<xref rid="pdig.0000152.ref001" ref-type="bibr">1</xref>]. These methods involve two tasks: (1) identification of entities (e.g., persons, organizations, locations, etc.) in text, and (2) classification of these entities into a set of pre-defined categories, such as person names, organizations (companies, government organizations, committees, etc.), locations (cities, countries, towns), date and time [<xref rid="pdig.0000152.ref001" ref-type="bibr">1</xref>]. Traditional NER methods only consider specific entities. However, there can be more entities, depending on the domain used. For example, the field of biomedicine covers entities such as genes, diseases, chemicals, and proteins [<xref rid="pdig.0000152.ref002" ref-type="bibr">2</xref>].</p>
    <p>In recent years, there has been a dramatic increase in biomedical data [<xref rid="pdig.0000152.ref017" ref-type="bibr">17</xref>]. Due to the COVID-19 surge, there has been a massive increase in biomedical data in the last two years. Such enormous data is challenging to process, significantly when the urgency of time and the number of patients is increasing exponentially. [<xref rid="pdig.0000152.ref018" ref-type="bibr">18</xref>]. To perform biomedical mining, it is essential to accommodate a prior process of biomedical NER. Biomedical NER is the task of identifying entities in the biomedical domain, such as chemical compounds, genes, proteins, viruses, disorders, drugs, adverse effects, metabolites, diseases, tissues, DNAs and RNAs, organs, toxins, food, or so [<xref rid="pdig.0000152.ref003" ref-type="bibr">3</xref>,<xref rid="pdig.0000152.ref010" ref-type="bibr">10</xref>]. Most research [<xref rid="pdig.0000152.ref001" ref-type="bibr">1</xref>,<xref rid="pdig.0000152.ref003" ref-type="bibr">3</xref>,<xref rid="pdig.0000152.ref019" ref-type="bibr">19</xref>] in biomedical NER focus on general approaches to named entities that are not specific to the biomedical field. On the other hand, some works [<xref rid="pdig.0000152.ref020" ref-type="bibr">20</xref>–<xref rid="pdig.0000152.ref022" ref-type="bibr">22</xref>] focus solely on biomedical and chemical NER; however, they don’t cover many clinical entities. In this research, we plan to cover many named entities, that are both clinical, biomedical and epidemiological.</p>
    <p>Word embedding is a valuable technique that uses a large amount of unlabeled data to learn the latent syntactic and semantic information of words/tokens and map these words/tokens into dense low-dimensional vectors. In the past few years, many word embedding methods, such Word2Vec [<xref rid="pdig.0000152.ref023" ref-type="bibr">23</xref>] and GloVe [<xref rid="pdig.0000152.ref024" ref-type="bibr">24</xref>] are proposed. Unlike traditional word embeddings such as Word2Vec and GloVe, the embedding assigned to the word/token by the language mode, such as ELMo [<xref rid="pdig.0000152.ref025" ref-type="bibr">25</xref>] and BERT [<xref rid="pdig.0000152.ref013" ref-type="bibr">13</xref>] depends on the context, which means the same word/token could have different representations in different contexts. BERT employs Transformer [<xref rid="pdig.0000152.ref014" ref-type="bibr">14</xref>] to pre-train word representations by jointly conditioning on both the left and right context in all layers. Because of the great success of BERT, it has gradually become a mainstream method using a large corpus to pre-train BERT and fine-tunes it on the target dataset. The BERT is also a widely used model for many downstream tasks, such as NER and relation extractions.</p>
    <p>Some biomedical works consider BERT for the biomedical NER tasks [<xref rid="pdig.0000152.ref005" ref-type="bibr">5</xref>,<xref rid="pdig.0000152.ref026" ref-type="bibr">26</xref>] and have shown outstanding performance. In this work, we also use the BERT model for NER task but the distilled version of the BERT, DistilBERT [<xref rid="pdig.0000152.ref016" ref-type="bibr">16</xref>]. The DistilBERT retains only half of the actual BERT model’s layers and parameters. The distilled versions also balance the computational complexity and the accuracy of the model, which is the motivation for our model building.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec007">
    <title>3 Materials and methods</title>
    <sec id="sec008">
      <title>3.1 Problem definition</title>
      <p>Given an input sentence <italic toggle="yes">X</italic> = {<italic toggle="yes">x</italic><sub>1</sub>, <italic toggle="yes">x</italic><sub>2</sub>,….,<italic toggle="yes">x</italic><sub><italic toggle="yes">N</italic></sub>}, where <italic toggle="yes">x</italic><sub><italic toggle="yes">i</italic></sub> is the <italic toggle="yes">i</italic><sup>th</sup> word (token), and <italic toggle="yes">N</italic> represents the length of the sentence. The goal of this study is to classify each token in <italic toggle="yes">X</italic> and assign it to a corresponding label <italic toggle="yes">y</italic>∈<italic toggle="yes">Y</italic>, where <italic toggle="yes">Y</italic> is a pre-defined list of all possible label types (e.g., disease, symptoms, drugs etc.).</p>
      <p>Next, we present the workflow of BioEN development architecture in <xref rid="pdig.0000152.g002" ref-type="fig">Fig 2</xref>.</p>
      <fig position="float" id="pdig.0000152.g002">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>BioEN ((Bio-Epidemiology-NER) Development Architecture.</title>
        </caption>
        <graphic xlink:href="pdig.0000152.g002" position="float"/>
      </fig>
    </sec>
    <sec id="sec009">
      <title>3.2 Overall architecture</title>
      <p>We have proposed and developed the BioEN package with a 3-phased approach in this study, as shown in <xref rid="pdig.0000152.g002" ref-type="fig">Fig 2</xref>.</p>
      <p>The detail of each phase is given below:</p>
      <p>First, we get the data, which is free text, and we feed the biomedical data to BioEN. In the first phase, the solution phase (starting from the top) of the architecture, we build a fine-tuned Transformer model (we name it the biomedical-ner-all model) with a data parser and a NER enhancer. The second phase is the model registering and serving to prepare the models and related components for packaging. The third phase is the production phase, where we make our python package ready and deploy it for real-time use. We explain the phases of BioEN architecture below:</p>
      <sec id="sec010">
        <title>3.2.1 Solution phase</title>
        <p>The first phase is the solution phase, where we have the data parser component, model processing, and final output generation. We name this phase the ‘solution’ phase since we provide the leading solutions to biomedical NER tasks here.</p>
        <p><italic toggle="yes">Data ingestion</italic>. The solution phase starts it working with the data ingestion. We can feed free (unstructured) texts in any format (text files, rich texts, pdf files) to the data ingestion step. In this study, we feed the biomedical data (details in Section 4.1). However, we design this architecture with reusability in mind so that the same architecture can be used with any other domain-specific data (e.g., life sciences, news feeds, entertainment).</p>
        <p><italic toggle="yes">Data parser</italic>. The free texts after data ingestion go into the <italic toggle="yes">data parser</italic> module. Data parsing is converting data strings from one format to another that is readable by the following components in this phase. The data parser module can extract textual data from any format, including PDF documents. Such a multipurpose data parser assumes that most biomedicine articles are available in PDF file formats.</p>
        <p><italic toggle="yes">Transformer-based model</italic>, <italic toggle="yes">biomedical-ner-all</italic>. The pre-processed texts from the data parser go into the next module, a Transformer-based module. We name this module the <italic toggle="yes">biomedical-ner-all</italic> model, and we make this module available at <ext-link xlink:href="https://huggingface.co/d4data/biomedical-ner-all" ext-link-type="uri">https://huggingface.co/d4data/biomedical-ner-all</ext-link>. The biomedical-ner-all model can identify the biomedical-named entities from the texts. We have fine-tuned this model on biomedicine data that covers a large number of clinical, epidemiological, and non-clinical (demographics) named entities. More details about biomedical-ner-all in Section 3.3.</p>
        <p><italic toggle="yes">NER enhancer</italic>. The output of the last module (i.e., Transformer-based model) is in the IOB (Inside-Outside-Before) format, which has become a prototypical standard format for tagging tokens in the NER tasks [<xref rid="pdig.0000152.ref027" ref-type="bibr">27</xref>]. The NER enhancer module is built on top of the biomedical-ner-all model and converts the IOB representation to a user-friendly format by associating chunks (tokens of recognized named entities) with their respective labels and enhancing the NER predictions. We filter out the NER chunks with no associated entity (tagged ‘O’). The output of the ner enhancer module is the named entities that are easily readable and tagged. For example, we tag the exact token place for a disease mention, a symptom, or any other named entities as output representations.</p>
      </sec>
      <sec id="sec011">
        <title>3.2.2 Model registering and serving</title>
        <p>The second phase in the BioEN development architecture is the model registering and serving. In this phase, we bundle our ML models (in the first phase) into a package for local real-time inference and batch inference. The idea is to support the real-time data processing and model serving workflow. We register the model and its components in a standard format for packaging (as in PyPi and pip) that can be used in various downstream tools—for example, batch inference or real-time serving through a REST API. By the end of this phase, we will have a package and a hosted model that can be called using a generalized code snippet, and we can load and run the model for the biomedical NER task.</p>
      </sec>
      <sec id="sec012">
        <title>3.2.3 Biomedical-epidemiology-NER</title>
        <p>The third phase in BioEN development architecture is the production phase. In this phase, we handle the versioning of our package and upload the final version to PyPI for distribution. The idea is to make this package available open-source so that other developers, biostatisticians, epidemiologists, or researchers can easily download and install it for simple experiments or as part of large, professional systems. The package is available under MIT license with this link <ext-link xlink:href="https://pypi.org/project/Bio-Epidemiology-NER/" ext-link-type="uri">https://pypi.org/project/Bio-Epidemiology-NER/</ext-link> and can be installed in any python environment by the following simple python command<bold>: pip install Bio-Epidemiology-NER</bold></p>
        <p>Below, we show the use of this package, which is quite simple, in <xref rid="pdig.0000152.g003" ref-type="fig">Fig 3</xref>.</p>
        <fig position="float" id="pdig.0000152.g003">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Illustration of package use on a case report.</title>
          </caption>
          <graphic xlink:href="pdig.0000152.g003" position="float"/>
        </fig>
        <p>The results are saved either in dataframes as CSV files with each chunk and named entity as output, or in PDF files with entities marked and shown. The tutorial and further details for use are given in the package website.</p>
      </sec>
      <sec id="sec013">
        <title>3.2.4 Biomedical named entities</title>
        <p>The package output is biomedical named entities that are provided to the user in two formats: 1) data frames in CSV format with each word/ chunk and the identified named entity, and 2) pdf file with named entities highlighted and annotated in the texts.</p>
        <p>In the state-of-the-art biomedicine works, there are usually a few named entities, such as diseases, genes, proteins, chemicals or species. However, we provide many clinical, non-clinical (demographics), and epidemiological named entities related to infectious diseases and the events, which we claim to be our unique contribution. We list the named entities that we are using in this work in <xref rid="pdig.0000152.t001" ref-type="table">Table 1</xref>:</p>
        <table-wrap position="float" id="pdig.0000152.t001">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.t001</object-id>
          <label>Table 1</label>
          <caption>
            <title>Named entities used in this work.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000152.t001" id="pdig.0000152.t001g" position="float"/>
            <table frame="hsides" rules="groups">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="left" rowspan="1" colspan="1">Activity</th>
                  <th align="left" rowspan="1" colspan="1">Diagnostic_procedure</th>
                  <th align="left" rowspan="1" colspan="1">Shape</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Administration</td>
                  <td align="left" rowspan="1" colspan="1">Disease_disorder</td>
                  <td align="left" rowspan="1" colspan="1">Frequency</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Age</td>
                  <td align="left" rowspan="1" colspan="1">Distance</td>
                  <td align="left" rowspan="1" colspan="1">Subject</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Personal_background</td>
                  <td align="left" rowspan="1" colspan="1">Sign_symptom</td>
                  <td align="left" rowspan="1" colspan="1">Texture</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Family_history</td>
                  <td align="left" rowspan="1" colspan="1">Medication</td>
                  <td align="left" rowspan="1" colspan="1">Therapeutic_procedure</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Height</td>
                  <td align="left" rowspan="1" colspan="1">Outcome</td>
                  <td align="left" rowspan="1" colspan="1">Time</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Sex</td>
                  <td align="left" rowspan="1" colspan="1">Severity</td>
                  <td align="left" rowspan="1" colspan="1">Volume</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Color</td>
                  <td align="left" rowspan="1" colspan="1">Lab_value</td>
                  <td align="left" rowspan="1" colspan="1">Weight</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Date</td>
                  <td align="left" rowspan="1" colspan="1">Mass</td>
                  <td align="left" rowspan="1" colspan="1">Dosage</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Non-biological_location</td>
                  <td align="left" rowspan="1" colspan="1">History</td>
                  <td align="left" rowspan="1" colspan="1">Duration</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Detailed_description</td>
                  <td align="left" rowspan="1" colspan="1">Co-reference</td>
                  <td align="left" rowspan="1" colspan="1">Biological_attribute</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Occupation</td>
                  <td align="left" rowspan="1" colspan="1">Qualitative_concept</td>
                  <td align="left" rowspan="1" colspan="1">Biological_structure</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Personal- Biological_structure</td>
                  <td align="left" rowspan="1" colspan="1">Quantitative_concept</td>
                  <td align="left" rowspan="1" colspan="1">Clinical_event</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">Area</td>
                  <td align="left" rowspan="1" colspan="1">Other_entity</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="t001fn001">
              <p>Next, we explain our methodology and discuss our Transformer-based model <bold><italic toggle="yes">biomedical-ner-all</italic></bold> in detail.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
    </sec>
    <sec id="sec014">
      <title>3.3 Model details</title>
      <p>BERT and its refined version, DistilBERT [<xref rid="pdig.0000152.ref016" ref-type="bibr">16</xref>], are Transformer-based models with self-attention blocks. These models are pre-trained on unlabeled raw texts and can be used for various tasks, including question answering, sentence-pair classification, and sequence tagging tasks [<xref rid="pdig.0000152.ref028" ref-type="bibr">28</xref>]. The idea is to have a general architecture that applies to many problems and a pre-trained model that reduces the need for labeled data. This study fine-tunes the pre-trained DistilBERT model to learn a more accurate representation of target domain entities (biomedicine entities). We prefer the fine-tuning over the pre-training task that is more expensive than fine-tuning. In particular, we change the last layer of the DistilBERT model for our specific biomedical task and fine-tune it on our dataset. We show the model adaption from a teacher model (pre-trained DistilBERT) to our student model (fine-tuned DistilBERT) in <xref rid="pdig.0000152.g004" ref-type="fig">Fig 4</xref>.</p>
      <fig position="float" id="pdig.0000152.g004">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Model adaption from the teacher model to the student model.</title>
        </caption>
        <graphic xlink:href="pdig.0000152.g004" position="float"/>
      </fig>
      <p>As shown in <xref rid="pdig.0000152.g004" ref-type="fig">Fig 4</xref>, we fine-tine the pre-trained DistilBERT model’s weights for the initialization of the NER task, and we adjust the input and output to our biomedical task. We release the model weights of our fine-tuned model here [<xref rid="pdig.0000152.ref029" ref-type="bibr">29</xref>]. The model weights are also packaged in our python package [<xref rid="pdig.0000152.ref030" ref-type="bibr">30</xref>].</p>
      <p>In the fine-tuning stage, we replace the entity tagging head of DistilBERT with a randomly initialized new head that covers all the entity categories of the target domain. We fine-tune the model using the target domain (biomedicine) training data. The model is optimized with Adam [<xref rid="pdig.0000152.ref031" ref-type="bibr">31</xref>] with a batch size of 16 and a learning rate of 2e-5. We train the model for 40 epochs and evaluate the model on the development set using entity-level F1-score on sub-word tokens. In addition to early stopping, the model is regularized with dropout within each transformer block and weight decay. The dropout is set to 0.1, and the weight decay is set to be 0.01 in the experiments. The best-performing model weights is used as the final prediction model.</p>
      <p>As the input for the BERT model, we use the CoNLL-2003 [<xref rid="pdig.0000152.ref032" ref-type="bibr">32</xref>] formatted data, split into sentences and tokenized on the word level. Sentences more prolonged than the limit (512 sequences) are split into separate input sequences for the network. When converting the predictions back to the word-level CoNLL format, we assign the predicted entity label of the first sub-word unit for the entire token. Our fine-tuned model, which we name as ‘biomedical-ner-all’ released with our package also, is shown in <xref rid="pdig.0000152.g005" ref-type="fig">Fig 5</xref>.</p>
      <fig position="float" id="pdig.0000152.g005">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>biomedical-ner-all model.</title>
        </caption>
        <graphic xlink:href="pdig.0000152.g005" position="float"/>
      </fig>
      <p>As shown in <xref rid="pdig.0000152.g005" ref-type="fig">Fig 5</xref>, we give the input, sequences of texts to the model. The input is tokenized, and its input representation is constructed for each given token by summing the corresponding token, segment, and position embeddings. The embedding of words goes as input to the dense layer, where we perform the enhancements to convert the IOB format of CONLL-2003 to a user-friendly format. The output is the set of entities that are user-friendly and easily readable. Along with extracting each entity, our model also shows a confidence score. A confidence score is simply a decimal number between 0 and 1 and indicates how confident the system is with its prediction. We consider only the entities with a prediction confidence score of more than 0.4 in the final output.</p>
    </sec>
    <sec id="sec015">
      <title>3.4 Data</title>
      <p>In this work, we use the publicly available data MACROBBAT 2020 dataset [<xref rid="pdig.0000152.ref033" ref-type="bibr">33</xref>]. The dataset details are available in the original paper [<xref rid="pdig.0000152.ref034" ref-type="bibr">34</xref>], where the authors define the acronym ACROBBAT as ‘Annotation for Case Reports using Open Biomedical Annotation Terms’. The dataset consists of 200 source documents in plain text and 200 annotation documents, each annotation document with plain text. Each document is named using PubMed document identifier, for example, 18258107.txt and 18258107.ann. The authors extracted the document’s text from the PubMed article but only included the clinical case report information, which is also relevant to our application because it contains patients’ data.</p>
      <p>As mentioned in the dataset paper [<xref rid="pdig.0000152.ref034" ref-type="bibr">34</xref>], the documents were manually annotated by researchers with prior experience reading biomedical and clinical language. Following completion, the annotations were checked for format and type consistency. We fine-tune our Transformer-based model (shown in <xref rid="pdig.0000152.g005" ref-type="fig">Fig 5</xref>) with the MACROBBAT data, which covers a wide range of named entities (clinical, demographics, epidemiological and event-based). We also update the package with additional training on a portion of COVID-19 data to accurately detect the mentions of the latest Coronavirus and/or COVID-19 named entities. The details of the dataset used in this study to train our model are given in <xref rid="pdig.0000152.t002" ref-type="table">Table 2</xref>:</p>
      <table-wrap position="float" id="pdig.0000152.t002">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Dataset details.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000152.t002" id="pdig.0000152.t002g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">No. of documents</th>
                <th align="left" rowspan="1" colspan="1">200 PubMed documents</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>No. of sentences</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">3,652</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>No. of annotations</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">59,164</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Main Entity types</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Clinical events, Diagnostic, procedure, disease disorder, medication, sign symptoms, time expressions, demographics, patient history, temporal and causal relations, co-references.</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Distinct entity types</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">42 (given in <xref rid="pdig.0000152.t001" ref-type="table">Table 1</xref>)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>Besides MACROBBAT, we also evaluate our approach against the following benchmark datasets:</p>
      <list list-type="bullet">
        <list-item>
          <p><bold>NCBI-Disease</bold> [<xref rid="pdig.0000152.ref035" ref-type="bibr">35</xref>]: it is the dataset introduced for disease NER and normalization. It has been widely used for a lot of applications. It consists of 793 PubMed abstracts with disease mentions.</p>
        </list-item>
        <list-item>
          <p><bold>I2b2-2012</bold> [<xref rid="pdig.0000152.ref036" ref-type="bibr">36</xref>]: it consists of clinical (problems, tests, treatments, clinical departments), occurrences (admission, discharge and evidence) mentions using 310 discharge summaries.</p>
        </list-item>
      </list>
      <p>We also collected random case reports (around 500) from the LitCOVID [<xref rid="pdig.0000152.ref037" ref-type="bibr">37</xref>] data source from 2020–2021 to see the effectiveness of our approach on the biomedical and COVID-19 patients’ data.</p>
    </sec>
    <sec id="sec016">
      <title>3.5 Benchmarking methods and evaluation</title>
      <p><bold>Benchmarking</bold>: To assess the utility and challenges of our approach, we evaluate the performance of our NER approach against the following state-of-the-art models:</p>
      <list list-type="bullet">
        <list-item>
          <p><bold>BiLSTM-CNN-Char</bold> [<xref rid="pdig.0000152.ref038" ref-type="bibr">38</xref>], a hybrid Bidirectional Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) architecture that learns both character and word-level features for the NER task.</p>
        </list-item>
        <list-item>
          <p><bold>SciBERT</bold> (Base), a pre-trained language model based on BERT pre-trained on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks.</p>
        </list-item>
        <list-item>
          <p><bold>BlueBERT</bold> [<xref rid="pdig.0000152.ref039" ref-type="bibr">39</xref>], BERT-based uncased model pretrained on PubMed abstracts and MIMIC-III.</p>
        </list-item>
        <list-item>
          <p><bold>ClinicalBERT</bold> [<xref rid="pdig.0000152.ref040" ref-type="bibr">40</xref>], BERT-Base-cased model trained on MIMIC notes.</p>
        </list-item>
        <list-item>
          <p><bold>BioBERT</bold> [<xref rid="pdig.0000152.ref005" ref-type="bibr">5</xref>], a pre-trained biomedical language representation model for biomedical text mining. We use the BioBERT-Base v1.2 (+ PubMed 1M).</p>
        </list-item>
      </list>
      <p>These models have obtained state-of-the-art performance in their works, respectively.</p>
      <p><bold>Evaluation metrics</bold>: Following the standard practice [<xref rid="pdig.0000152.ref002" ref-type="bibr">2</xref>,<xref rid="pdig.0000152.ref032" ref-type="bibr">32</xref>,<xref rid="pdig.0000152.ref041" ref-type="bibr">41</xref>] to evaluate NER tasks, we use the typical evaluation method, i.e., precision, recall and F1-score at a token level.</p>
      <list list-type="bullet">
        <list-item>
          <p>Precision: percentage of named entities found by the learning system that are correct.</p>
        </list-item>
        <list-item>
          <p>Recall: percentage of named entities present in the data found by the system. A named entity is correct only if it is an exact match of the corresponding entity in the data file.</p>
        </list-item>
        <list-item>
          <p>F1-score: harmonic mean of precision and recall.</p>
        </list-item>
      </list>
      <p><bold>Configurations and Hyperparameters:</bold> We use PyTorch for the model implementation. We run our experiments on GPU: 1 x GeForce RTX 3060 with 16.0 GB RAM to integrate the components of our package. We use Grid search to get the optimal values for the hyperparameters and early stopping to overcome possible overfitting. We specify the following hyperparameters as shown in <xref rid="pdig.0000152.t003" ref-type="table">Table 3</xref>.</p>
      <table-wrap position="float" id="pdig.0000152.t003">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Hyperparameters used.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000152.t003" id="pdig.0000152.t003g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Hyperparameter</th>
                <th align="left" rowspan="1" colspan="1">Optimal value used</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Learning rate</td>
                <td align="left" rowspan="1" colspan="1">2E-5</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Batch size</td>
                <td align="left" rowspan="1" colspan="1">16</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Epochs</td>
                <td align="left" rowspan="1" colspan="1">40</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Optimizer</td>
                <td align="left" rowspan="1" colspan="1">Adam</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Dropout rate</td>
                <td align="left" rowspan="1" colspan="1">0.5</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Optimizer</td>
                <td align="left" rowspan="1" colspan="1">Adam</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Hidden Size</td>
                <td align="left" rowspan="1" colspan="1">768</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Embedding Size</td>
                <td align="left" rowspan="1" colspan="1">128</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Max Seq Length</td>
                <td align="left" rowspan="1" colspan="1">512</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Warmup Steps</td>
                <td align="left" rowspan="1" colspan="1">3000</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Weight decay</td>
                <td align="left" rowspan="1" colspan="1">0.01</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">dropout</td>
                <td align="left" rowspan="1" colspan="1">0.1</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>We have divided the dataset into training, validation, and test sets, with a 70:15:15 ratio for all experiments.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec017">
    <title>4 Results</title>
    <p>In this section, we present the results and analysis.</p>
    <sec id="sec018">
      <title>4.1 Overall performance evaluation</title>
      <p>We present the results of our model and the baseline models on all the datasets in <xref rid="pdig.0000152.t004" ref-type="table">Table 4</xref>.</p>
      <table-wrap position="float" id="pdig.0000152.t004">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.t004</object-id>
        <label>Table 4</label>
        <caption>
          <title>Overall performance.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000152.t004" id="pdig.0000152.t004g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="1" colspan="1">Method</th>
                <th align="center" rowspan="1" colspan="1">Metric</th>
                <th align="center" rowspan="1" colspan="1">MACCROBAT</th>
                <th align="center" rowspan="1" colspan="1">NCBI-Disease</th>
                <th align="center" rowspan="1" colspan="1">I2b2-2012</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">BiLSTM-CNN-Char</td>
                <td align="center" rowspan="1" colspan="1">Precision</td>
                <td align="center" rowspan="1" colspan="1">84.43</td>
                <td align="center" rowspan="1" colspan="1">85.24</td>
                <td align="center" rowspan="1" colspan="1">79.35</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">Recall</td>
                <td align="center" rowspan="1" colspan="1">83.97</td>
                <td align="center" rowspan="1" colspan="1">83.31</td>
                <td align="center" rowspan="1" colspan="1">78.11</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">F1-score</td>
                <td align="center" rowspan="1" colspan="1">84.20</td>
                <td align="center" rowspan="1" colspan="1">84.26</td>
                <td align="center" rowspan="1" colspan="1">78.73</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SciBERT</td>
                <td align="center" rowspan="1" colspan="1">Precision</td>
                <td align="center" rowspan="1" colspan="1">78.10</td>
                <td align="center" rowspan="1" colspan="1">76.88</td>
                <td align="center" rowspan="1" colspan="1">77.01</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">Recall</td>
                <td align="center" rowspan="1" colspan="1">72.18</td>
                <td align="center" rowspan="1" colspan="1">74.10</td>
                <td align="center" rowspan="1" colspan="1">75.18</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">F1-score</td>
                <td align="center" rowspan="1" colspan="1">75.02</td>
                <td align="center" rowspan="1" colspan="1">75.46</td>
                <td align="center" rowspan="1" colspan="1">76.08</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">BlueBERT</td>
                <td align="center" rowspan="1" colspan="1">Precision</td>
                <td align="center" rowspan="1" colspan="1">84.04</td>
                <td align="center" rowspan="1" colspan="1">83.37</td>
                <td align="center" rowspan="1" colspan="1">81.10</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">Recall</td>
                <td align="center" rowspan="1" colspan="1">81.48</td>
                <td align="center" rowspan="1" colspan="1">81.39</td>
                <td align="center" rowspan="1" colspan="1">80.88</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">F1-score</td>
                <td align="center" rowspan="1" colspan="1">82.74</td>
                <td align="center" rowspan="1" colspan="1">82.37</td>
                <td align="center" rowspan="1" colspan="1">80.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ClinicalBERT</td>
                <td align="center" rowspan="1" colspan="1">Precision</td>
                <td align="center" rowspan="1" colspan="1">81.01</td>
                <td align="center" rowspan="1" colspan="1">84.08</td>
                <td align="center" rowspan="1" colspan="1">80.35</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">Recall</td>
                <td align="center" rowspan="1" colspan="1">79.10</td>
                <td align="center" rowspan="1" colspan="1">80.11</td>
                <td align="center" rowspan="1" colspan="1">78.69</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">F1-score</td>
                <td align="center" rowspan="1" colspan="1">80.04</td>
                <td align="center" rowspan="1" colspan="1">82.05</td>
                <td align="center" rowspan="1" colspan="1">79.51</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">BioBERT v1.2</td>
                <td align="center" rowspan="1" colspan="1">Precision</td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">86</italic>.<italic toggle="yes">72</italic></td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">85</italic>.<italic toggle="yes">80</italic></td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">88</italic>.<italic toggle="yes">00</italic></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">Recall</td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">88</italic>.<italic toggle="yes">31</italic></td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">84</italic>.<italic toggle="yes">29</italic></td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">86</italic>.<italic toggle="yes">10</italic></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">F1-score</td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">87</italic>.<italic toggle="yes">51</italic></td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">85</italic>.<italic toggle="yes">04</italic></td>
                <td align="center" rowspan="1" colspan="1"><italic toggle="yes">87</italic>.<italic toggle="yes">04</italic></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>BioEN (our approach)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">Precision</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>92.10</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>91.68</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>90.10</bold>
                </td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">Recall</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>91.68</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>88.92</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>88.98</bold>
                </td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1"/>
                <td align="center" rowspan="1" colspan="1">F1-score</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>91.89</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>90.28</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>89.54</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p><xref rid="pdig.0000152.t004" ref-type="table">Table 4</xref> shows that our BioEN approach achieves state-of-the-art performance for detecting many biomedical-named entities. This is demonstrated by our model outperforming other methods by performing around 90% F1-score on all datasets. The superiority of our model is credited to its architecture and carefully fine-tuned biomedical-ner-all model. This result also demonstrates that a model that is trained on domain-specific data (e.g., biomedical data) can be applied to a wide variety of domain-specific terminologies. For example, we train this package BioEN (including its components) on biomedical named entities, and we can detect a large variety of clinical, event-based, and epidemiological named entities to study infectious diseases and population groups. Our model also considers the causal relations and co-references provided by the MACCROBAT dataset on which it is primarily trained. Thus, this package can incorporate a diverse vocabulary and phenomena described in clinical documents without requiring direct connections to curated concepts (e.g., MeSH, UMLS knowledge bases).</p>
      <p>We also see that BERT-based methods (BioBERT, BlueBERT, and ClinicalBERT) that have been pre-trained on PubMed and/or MIMIC-III clinical notes perform well. This is most likely because these methods have been well-trained for extracting richer features, resulting in better performance. BioBERT outperforms other BlueBERT, ClinicalBERT, and SciBERT, which is probably because BioBERT is pre-trained on more biomedical and clinical data and can better infer the patterns from the test data. We also find that BlueBERT performance is quite good, above 80%, which shows models pre-trained on domain-specific literature (e.g., biomedicine) perform well in the respective downstream tasks.</p>
      <p>As demonstrated in <xref rid="pdig.0000152.t004" ref-type="table">Table 4</xref>, BiLSTM-CNN-Char that automatically detects word- and character-level features using a hybrid BiLSTM and CNN architecture yields quite a good result, after BioEN (ours) and BioBERT methods. BiLSTM-CNN-Char model achieves an F1- score performance of approximately 84% on MACCROBAT and NCBI datasets, which are quite high compared to most models. BiLSTM-CNN-Char has also been used as a state-of-the-art and conventional model for many biomedical datasets. However, the latter works show that adding the language models on top of traditional models (e.g., BiLSTM) shows good performance [<xref rid="pdig.0000152.ref042" ref-type="bibr">42</xref>,<xref rid="pdig.0000152.ref043" ref-type="bibr">43</xref>], which may be attributed to large-scale pre-training tasks on the top.</p>
      <p>SciBERT is trained on papers from the <ext-link xlink:href="http://semanticscholar.org" ext-link-type="uri">semanticscholar.org</ext-link> corpus; while the knowledge gained is significant, the model’s performance in our work is somewhat compromised. We anticipate this comparatively lower performance may result from the limited biomedical literature used to train the model, and the named entity types of the actual model differ in some way from what is expected by our application.</p>
      <p>Although we fine-tune each baseline method to its optimal hyperparameter settings, we anticipate that the relatively low scores of these baselines on the MACCROBAT dataset, which is a primary dataset for our model training, can be because of a few factors, for example, lack of complete training, and unavailability of the training/test set splits utilized in previous studies.</p>
    </sec>
    <sec id="sec019">
      <title>4.2 Effectiveness of the BioEN on case reports</title>
      <p>We give a snippet from a COVID-19-related case report [<xref rid="pdig.0000152.ref044" ref-type="bibr">44</xref>] to BioEN (our method) and show the confidence score for the predicted entities. Due to brevity reasons, we show the results only on one sentence from the case report in <xref rid="pdig.0000152.t005" ref-type="table">Table 5</xref>.</p>
      <table-wrap position="float" id="pdig.0000152.t005">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.t005</object-id>
        <label>Table 5</label>
        <caption>
          <title>The confidence score of the model on different named entities by BioEN.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000152.t005" id="pdig.0000152.t005g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="1" colspan="1">Entity group</th>
                <th align="center" rowspan="1" colspan="1">Value</th>
                <th align="center" rowspan="1" colspan="1">Score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sex</td>
                <td align="left" rowspan="1" colspan="1">man</td>
                <td align="right" rowspan="1" colspan="1">0.999528</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">History</td>
                <td align="left" rowspan="1" colspan="1">40s</td>
                <td align="right" rowspan="1" colspan="1">0.867149</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Clinical_event</td>
                <td align="left" rowspan="1" colspan="1">admitted</td>
                <td align="right" rowspan="1" colspan="1">0.999799</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Location</td>
                <td align="left" rowspan="1" colspan="1">local hospital</td>
                <td align="right" rowspan="1" colspan="1">0.997007</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Date</td>
                <td align="left" rowspan="1" colspan="1">6 days after</td>
                <td align="right" rowspan="1" colspan="1">0.991963</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Disease_disorder</td>
                <td align="left" rowspan="1" colspan="1">COVID-19</td>
                <td align="right" rowspan="1" colspan="1">1.000000</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Diagnostic_procedure</td>
                <td align="left" rowspan="1" colspan="1">general condition</td>
                <td align="right" rowspan="1" colspan="1">0.999905</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Therapeutic_procedure</td>
                <td align="left" rowspan="1" colspan="1">treated</td>
                <td align="right" rowspan="1" colspan="1">0.999675</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Location</td>
                <td align="left" rowspan="1" colspan="1">intensive care unit</td>
                <td align="right" rowspan="1" colspan="1">0.999643</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sign_symptom</td>
                <td align="left" rowspan="1" colspan="1">cough</td>
                <td align="right" rowspan="1" colspan="1">0.999682</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sign_symptom</td>
                <td align="left" rowspan="1" colspan="1">experienced dyspnoea recurred and rapidly increased</td>
                <td align="right" rowspan="1" colspan="1">0.999941</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sign_symptom</td>
                <td align="left" rowspan="1" colspan="1">dyspnoea</td>
                <td align="right" rowspan="1" colspan="1">0.999938</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Sign_symptom</td>
                <td align="left" rowspan="1" colspan="1">recurred</td>
                <td align="right" rowspan="1" colspan="1">0.992294</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Diagnostic_procedure</td>
                <td align="left" rowspan="1" colspan="1">CT</td>
                <td align="right" rowspan="1" colspan="1">0.999842</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Biological_structure</td>
                <td align="left" rowspan="1" colspan="1">pulmonary</td>
                <td align="right" rowspan="1" colspan="1">0.999952</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Diagnostic_procedure</td>
                <td align="left" rowspan="1" colspan="1">angiogram</td>
                <td align="right" rowspan="1" colspan="1">0.999405</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Area</td>
                <td align="left" rowspan="1" colspan="1">10×18 cm</td>
                <td align="right" rowspan="1" colspan="1">0.997637</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Detailed_description</td>
                <td align="left" rowspan="1" colspan="1">cavitary</td>
                <td align="right" rowspan="1" colspan="1">0.999947</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Detailed_description</td>
                <td align="left" rowspan="1" colspan="1">pulmonary cavitary</td>
                <td align="right" rowspan="1" colspan="1">0.999942</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Detailed_description</td>
                <td align="left" rowspan="1" colspan="1">air-fluid level</td>
                <td align="right" rowspan="1" colspan="1">0.999005</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Disease_disorder</td>
                <td align="left" rowspan="1" colspan="1">atelectasis</td>
                <td align="right" rowspan="1" colspan="1">0.997569</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Detailed_description</td>
                <td align="left" rowspan="1" colspan="1">one-way valve mechanism</td>
                <td align="right" rowspan="1" colspan="1">0.847769</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Co-reference</td>
                <td align="left" rowspan="1" colspan="1">developed pneumatocele</td>
                <td align="right" rowspan="1" colspan="1">0.863188</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Co-reference</td>
                <td align="left" rowspan="1" colspan="1">one-way pneumatocele</td>
                <td align="right" rowspan="1" colspan="1">0.792779</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Biological_structure</td>
                <td align="left" rowspan="1" colspan="1">bronchial endobronchial segments</td>
                <td align="right" rowspan="1" colspan="1">0.915637</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Biological_structure</td>
                <td align="left" rowspan="1" colspan="1">right lower lobe</td>
                <td align="right" rowspan="1" colspan="1">0.999896</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Biological_structure</td>
                <td align="left" rowspan="1" colspan="1">endobronchial</td>
                <td align="right" rowspan="1" colspan="1">0.999509</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Date</td>
                <td align="left" rowspan="1" colspan="1">4 weeks after</td>
                <td align="right" rowspan="1" colspan="1">0.999853</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Date</td>
                <td align="left" rowspan="1" colspan="1">Six months after</td>
                <td align="right" rowspan="1" colspan="1">0.999874</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Biological_structure</td>
                <td align="left" rowspan="1" colspan="1">lung</td>
                <td align="right" rowspan="1" colspan="1">0.980932</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>As can be seen, our model is able to predict the named entities with quite accuracy, which two experts in the biomedicine field also validate.</p>
    </sec>
    <sec id="sec020">
      <title>4.3 Case study</title>
      <p>We show our model’s most frequent top-10 named entity types predicted by parsing 100 random case reports from PubMed in <xref rid="pdig.0000152.t006" ref-type="table">Table 6</xref>. These case reports are selected from the timeline 2020–2021 and are related to COVID-19. These results show the predictions from our model.</p>
      <table-wrap position="float" id="pdig.0000152.t006">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.t006</object-id>
        <label>Table 6</label>
        <caption>
          <title>Most frequent named entities from 100 covid-19 case reports.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000152.t006" id="pdig.0000152.t006g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Disease disorder</th>
                <th align="left" rowspan="1" colspan="1">Sign symptom</th>
                <th align="left" rowspan="1" colspan="1">Therapeutic procedure</th>
                <th align="left" rowspan="1" colspan="1">Medication</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">covid-19</td>
                <td align="left" rowspan="1" colspan="1">cough</td>
                <td align="left" rowspan="1" colspan="1">arterial</td>
                <td align="left" rowspan="1" colspan="1">aspirin</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">homocystinuria</td>
                <td align="left" rowspan="1" colspan="1">fever</td>
                <td align="left" rowspan="1" colspan="1">Endomyocardial</td>
                <td align="left" rowspan="1" colspan="1">homocysteine</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">influenza</td>
                <td align="left" rowspan="1" colspan="1">shortness of breath</td>
                <td align="left" rowspan="1" colspan="1">intubation</td>
                <td align="left" rowspan="1" colspan="1">alcohol-based</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">asthma</td>
                <td align="left" rowspan="1" colspan="1">sore throat</td>
                <td align="left" rowspan="1" colspan="1">oxygenation</td>
                <td align="left" rowspan="1" colspan="1">Paxlovid</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SARS</td>
                <td align="left" rowspan="1" colspan="1">headache</td>
                <td align="left" rowspan="1" colspan="1">splenectomy</td>
                <td align="left" rowspan="1" colspan="1">Tylenol</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">gastroenteritis</td>
                <td align="left" rowspan="1" colspan="1">aches and pains</td>
                <td align="left" rowspan="1" colspan="1">vaccination</td>
                <td align="left" rowspan="1" colspan="1">ibuprofen</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">long-COVID</td>
                <td align="left" rowspan="1" colspan="1">diarrhoea</td>
                <td align="left" rowspan="1" colspan="1">venoarterial</td>
                <td align="left" rowspan="1" colspan="1">clopidogrel</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">cardiac</td>
                <td align="left" rowspan="1" colspan="1">chest pain</td>
                <td align="left" rowspan="1" colspan="1">Myocardial</td>
                <td align="left" rowspan="1" colspan="1">prasugrel</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">repiratory</td>
                <td align="left" rowspan="1" colspan="1">rash</td>
                <td align="left" rowspan="1" colspan="1">Endovascular</td>
                <td align="left" rowspan="1" colspan="1">acetaminophen</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">pneumonia</td>
                <td align="left" rowspan="1" colspan="1">difficulty breathing</td>
                <td align="left" rowspan="1" colspan="1">transplantation</td>
                <td align="left" rowspan="1" colspan="1">antiviral pills</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>These results in <xref rid="pdig.0000152.t006" ref-type="table">Table 6</xref> can be used to get valuable information regarding the most frequent disorders or symptoms mentioned in the case report or to find the most common findings efficiently. According to these results, the most common symptom is cough and fever, while aspirin is the most common drug ingredient. The most common disease disorder here is COVID-19 since these are COVID-19 case reports.</p>
      <p>We also show the most common disease disorder in two sexes (male and female), based on 100 case reports data, and the results are shown in <xref rid="pdig.0000152.g006" ref-type="fig">Fig 6</xref>.</p>
      <fig position="float" id="pdig.0000152.g006">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>Distribution of disease disorders among male and female groups.</title>
        </caption>
        <graphic xlink:href="pdig.0000152.g006" position="float"/>
      </fig>
      <p>As shown in <xref rid="pdig.0000152.g006" ref-type="fig">Fig 6</xref>, COVID-19 patients around 54% as male, and the others are females. Ovarian failure, a female disease order, is found in female patients only. For the other diseases, we see asthma mostly in male patients and endometriosis only in male patients.</p>
      <p>We also show the percentage of most occurring diseases in the patients in <xref rid="pdig.0000152.g007" ref-type="fig">Fig 7</xref>, and the most frequent diseases are COVID-19 positive, pneumonia, and respiratory, which are primarily related to COVID-19 disease.</p>
      <fig position="float" id="pdig.0000152.g007">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g007</object-id>
        <label>Fig 7</label>
        <caption>
          <title>Percentage of most occurring disease disorders in patients.</title>
        </caption>
        <graphic xlink:href="pdig.0000152.g007" position="float"/>
      </fig>
      <p>We show a snippet of one case report in PDF format that is parsed by our BioEN model, and the results are saved and annotated in the same PDF file as shown in <xref rid="pdig.0000152.g008" ref-type="fig">Fig 8</xref>.</p>
      <fig position="float" id="pdig.0000152.g008">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000152.g008</object-id>
        <label>Fig 8</label>
        <caption>
          <title>Annotations produced by our model in PDF file.</title>
        </caption>
        <graphic xlink:href="pdig.0000152.g008" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec021">
    <title>5 Discussions</title>
    <p>This package’s results and findings can be used in healthcare applications, such as assisting doctors, nurses, and clinical experts in matching symptoms to diagnosis, treatment, and follow-up. This package is simple to install and configurable for real-time use by medical practitioners. The model’s results apply to various applications, for example, disease detection, demographic studies, social determinants of health, semantic relation extraction between concepts in medicine biology, and other related tasks. BioEN also impacts application performance in terms of precision and recall.</p>
    <p>Healthcare and health science data face numerous challenges in the “big data” era. With this approach, we attempt to provide automatic methods for text and data mining tools that must be deployed to deal with large, highly heterogeneous data sets. As the field of NLP advances, policymakers will have more opportunities to understand the value of electronic medical records and clinical records, as well as the cost-effectiveness and cost-savings implications of health system planning. This solution allows for the tracking of medical as well as social determinants of health, which can lead to the reduction of health disparities. However, more research is required to understand and assess the dataset better.</p>
    <p><italic toggle="yes">Limitations</italic>: So far, we rely on benchmark data to train the model. However, more data is required to train the model to study many infectious diseases. In the future, we plan to annotate our biomedical data, and we strongly encourage the inclusion of medical professionals in the annotation guideline. We also intend to curate more clinical data; in particular, getting real-time access to EHRs would be helpful. Due to the black-box nature of most deep neural networks, we also plan to handle bias or systematic error in research methods, which may influence disease associations and predictions. We also plan to consider the human evaluation to have predicted entities as being more accurate, informative, and biomedical. We plan to make the model multi-lingual to consider more text from other languages and avoid any bias towards a single language.</p>
  </sec>
  <sec sec-type="conclusions" id="sec022">
    <title>6 Conclusion</title>
    <p>In conclusion, this paper presents BioEN development architecture consisting of several components stacked together. We use an approach to train models for the biomedical named entities by fine-tuning the BERT-based Transformer model. We fine-tune a Transformer based architecture to the task of biomedical NER. We evaluate the performance of our approach in different benchmark datasets, and our method achieves state-of-the-art results compared to the baselines. We demonstrate through extensive experiments that using contextualized word embedding pre-trained on biomedical corpora significantly improves the outcomes in NER tasks.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to acknowledge the Canadian Institutes of Health Research’s Institute of Health Services and Policy Research (CIHR-IHSPR) as part of the Equitable AI and Public Health cohort for the research support.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pdig.0000152.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Nadeau</surname><given-names>D</given-names></name>, <name><surname>Sekine</surname><given-names>S</given-names></name>. <article-title>A survey of named entity recognition and classification.</article-title><source>Lingvisticae Investig</source>. <year>2007</year>;<volume>30</volume>: <fpage>3</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Cho</surname><given-names>H</given-names></name>, <name><surname>Lee</surname><given-names>H</given-names></name>. <article-title>Biomedical named entity recognition using deep neural networks with contextual information</article-title>. <source>BMC Bioinformatics</source>. <year>2019</year>;<volume>20</volume>: <fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12859-019-3321-4</pub-id><?supplied-pmid 31881938?><pub-id pub-id-type="pmid">30606105</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Perera</surname><given-names>N</given-names></name>, <name><surname>Dehmer</surname><given-names>M</given-names></name>, <name><surname>Emmert-Streib</surname><given-names>F</given-names></name>. <article-title>Named Entity Recognition and Relation Detection for Biomedical Information Extraction.</article-title><source>Front Cell Dev Biol</source>. <year>2020</year>;<volume>8</volume>: <fpage>673</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fcell.2020.00673</pub-id><?supplied-pmid 32984300?><pub-id pub-id-type="pmid">32984300</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Boudjellal</surname><given-names>N</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Khan</surname><given-names>A</given-names></name>, <name><surname>Ahmad</surname><given-names>A</given-names></name>, <name><surname>Naseem</surname><given-names>R</given-names></name>, <name><surname>Shang</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>ABioNER: A BERT-Based Model for Arabic Biomedical Named-Entity Recognition.</article-title><source>Complexity</source>. <year>2021</year>;<volume>2021</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1155/2021/6633213</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Yoon</surname><given-names>W</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Kim</surname><given-names>D</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>So</surname><given-names>CH</given-names></name>, <etal>et al</etal>. <article-title>BioBERT: A pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>: <fpage>1234</fpage>–<lpage>1240</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id><?supplied-pmid 31501885?><pub-id pub-id-type="pmid">31501885</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>K</given-names></name>, <name><surname>Li</surname><given-names>F</given-names></name>, <name><surname>Liu</surname><given-names>L</given-names></name>, <name><surname>Han</surname><given-names>Y</given-names></name>. <article-title>Implementation of a kernel-based Chinese relation extraction system.</article-title><source>Jisuanji Yanjiu yu Fazhan(Computer Res Dev.</source><year>2007</year>;<volume>44</volume>: <fpage>1406</fpage>–<lpage>1411</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Xue</surname><given-names>Y</given-names></name>, <name><surname>Liang</surname><given-names>H</given-names></name>, <name><surname>Wu</surname><given-names>X</given-names></name>, <name><surname>Gong</surname><given-names>H</given-names></name>, <name><surname>Li</surname><given-names>B</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>. <article-title>Effects of electronic medical record in a Chinese hospital: a time series study.</article-title><source>Int J Med Inform</source>. <year>2012</year>;<volume>81</volume>: <fpage>683</fpage>–<lpage>689</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ijmedinf.2012.05.017</pub-id><?supplied-pmid 22727614?><pub-id pub-id-type="pmid">22727614</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Yan</surname><given-names>H</given-names></name>, <name><surname>Deng</surname><given-names>B</given-names></name>, <name><surname>Li</surname><given-names>X</given-names></name>, <name><surname>Qiu</surname><given-names>X</given-names></name>. <article-title>TENER: Adapting Transformer Encoder for Named Entity Recognition.</article-title><year>2019</year>. Available: <ext-link xlink:href="http://arxiv.org/abs/1911.04474" ext-link-type="uri">http://arxiv.org/abs/1911.04474</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Raza</surname><given-names>S</given-names></name>, <name><surname>Schwartz</surname><given-names>B</given-names></name>. <article-title>Detecting Biomedical Named Entities in COVID-19 Texts.</article-title><source>Workshop on Healthcare AI and COVID-19, ICML 2022.</source><year>2022</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Kocaman</surname><given-names>V</given-names></name>, <name><surname>Talby</surname><given-names>D</given-names></name>. <article-title>Biomedical Named Entity Recognition at Scale.</article-title><source>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics).</source><year>2021</year>. pp. <fpage>635</fpage>–<lpage>646</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/978-3-030-68763-2_48</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Du</surname><given-names>X</given-names></name>, <name><surname>Cai</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>S</given-names></name>, <name><surname>Zhang</surname><given-names>L</given-names></name>. <article-title>Overview of deep learning.</article-title><source>2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC).</source><year>2016</year>. pp. <fpage>159</fpage>–<lpage>164</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Wu</surname><given-names>X</given-names></name>, <name><surname>Lode</surname><given-names>M</given-names></name>. <article-title>Language Models are Unsupervised Multitask Learners (Summarization).</article-title><source>OpenAI Blog.</source><year>2020</year>;<volume>1</volume>: <fpage>1</fpage>–<lpage>7</lpage>. Available: <ext-link xlink:href="https://github.com/codelucas/newspaper" ext-link-type="uri">https://github.com/codelucas/newspaper</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Devlin</surname><given-names>J</given-names></name>, <name><surname>Chang</surname><given-names>MW</given-names></name>, <name><surname>Lee</surname><given-names>K</given-names></name>, <name><surname>Toutanova</surname><given-names>K</given-names></name>. <article-title>BERT: Pre-training of deep bidirectional transformers for language understanding</article-title>. <source>NAACL HLT 2019–2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies—Proceedings of the Conference</source>. Association for Computational Linguistics (ACL); <year>2019</year>. pp. <fpage>4171</fpage>–<lpage>4186</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Vaswani</surname><given-names>A</given-names></name>, <name><surname>Shazeer</surname><given-names>N</given-names></name>, <name><surname>Parmar</surname><given-names>N</given-names></name>, <name><surname>Uszkoreit</surname><given-names>J</given-names></name>, <name><surname>Jones</surname><given-names>L</given-names></name>, <name><surname>Gomez</surname><given-names>AN</given-names></name>, <etal>et al</etal>. <article-title>Attention is all you need</article-title>. <source>Advances in neural information processing systems</source>. <year>2017</year>. pp. <fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>W</given-names></name>, <name><surname>Wei</surname><given-names>F</given-names></name>, <name><surname>Dong</surname><given-names>L</given-names></name>, <name><surname>Bao</surname><given-names>H</given-names></name>, <name><surname>Yang</surname><given-names>N</given-names></name>, <name><surname>Zhou</surname><given-names>M</given-names></name>. <article-title>Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers.</article-title><source>Adv Neural Inf Process Syst</source>. <year>2020</year>;<volume>33</volume>: <fpage>5776</fpage>–<lpage>5788</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Sanh</surname><given-names>V</given-names></name>, <name><surname>Debut</surname><given-names>L</given-names></name>, <name><surname>Chaumond</surname><given-names>J</given-names></name>, <name><surname>Wolf</surname><given-names>T</given-names></name>. <article-title>DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.</article-title><source>arXiv Prepr arXiv191001108.</source><year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Tsatsaronis</surname><given-names>G</given-names></name>, <name><surname>Schroeder</surname><given-names>M</given-names></name>, <name><surname>Paliouras</surname><given-names>G</given-names></name>, <name><surname>Almirantis</surname><given-names>Y</given-names></name>, <name><surname>Androutsopoulos</surname><given-names>I</given-names></name>, <name><surname>Gaussier</surname><given-names>E</given-names></name>, <etal>et al</etal>. <article-title>BioASQ: A Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering.</article-title><source>AAAI fall symposium: Information retrieval and knowledge discovery in biomedical text.</source><year>2012</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Raza</surname><given-names>S</given-names></name>, <name><surname>Schwartz</surname><given-names>B</given-names></name>, <name><surname>Rosella</surname><given-names>LC</given-names></name>. <article-title>CoQUAD: a COVID-19 question answering dataset system, facilitating research, benchmarking, and practice</article-title>. <source>BMC Bioinformatics</source>. <year>2022</year>;<volume>23</volume>: <fpage>210</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12859-022-04751-6</pub-id><?supplied-pmid 35655148?><pub-id pub-id-type="pmid">35655148</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Goyal</surname><given-names>A</given-names></name>, <name><surname>Gupta</surname><given-names>V</given-names></name>, <name><surname>Kumar</surname><given-names>M</given-names></name>. <article-title>Recent named entity recognition and classification techniques: a systematic review.</article-title><source>Comput Sci Rev</source>. <year>2018</year>;<volume>29</volume>: <fpage>21</fpage>–<lpage>43</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Leser</surname><given-names>U</given-names></name>, <name><surname>Hakenberg</surname><given-names>J</given-names></name>. <article-title>What makes a gene name? Named entity recognition in the biomedical literature</article-title>. <source>Brief Bioinform</source>. <year>2005</year>;<volume>6</volume>: <fpage>357</fpage>–<lpage>369</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/6.4.357</pub-id><?supplied-pmid 16420734?><pub-id pub-id-type="pmid">16420734</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Eltyeb</surname><given-names>S</given-names></name>, <name><surname>Salim</surname><given-names>N</given-names></name>. <article-title>Chemical named entities recognition: a review on approaches and applications.</article-title><source>J Cheminform</source>. <year>2014</year>;<volume>6</volume>: <fpage>1</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">24397863</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Griffin</surname><given-names>DO</given-names></name>, <name><surname>Jensen</surname><given-names>A</given-names></name>, <name><surname>Khan</surname><given-names>M</given-names></name>, <name><surname>Chin</surname><given-names>J</given-names></name>, <name><surname>Chin</surname><given-names>K</given-names></name>, <name><surname>Saad</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Pulmonary Embolism and Increased Levels of d-Dimer in Patients with Coronavirus Disease</article-title>. <source>Emerg Infect Dis</source>. <year>2020</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3201/eid2608.201477</pub-id><?supplied-pmid 32348233?><pub-id pub-id-type="pmid">32348233</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Goldberg</surname><given-names>Y</given-names></name>, <name><surname>Levy</surname><given-names>O</given-names></name>. <article-title>word2vec Explained: deriving Mikolov et al.’s negative-sampling word-embedding method.</article-title><source>arXiv Prepr arXiv14023722.</source><year>2014</year>. Available: <ext-link xlink:href="http://arxiv.org/abs/1402.3722" ext-link-type="uri">http://arxiv.org/abs/1402.3722</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Pennington J. GloVe: Global Vectors for Word Representation. 2021. Available: <ext-link xlink:href="https://nlp.stanford.edu/projects/glove" ext-link-type="uri">https://nlp.stanford.edu/projects/glove</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">AllenNLP. AllenNLP—ELMo—Allen Institute for AI. 2022. Available: <ext-link xlink:href="https://allenai.org/allennlp/software/elmo" ext-link-type="uri">https://allenai.org/allennlp/software/elmo</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Asgari-Chenaghlu</surname><given-names>M</given-names></name>, <name><surname>Feizi-Derakhshi</surname><given-names>M-R</given-names></name>, <name><surname>farzinvash</surname><given-names>L</given-names></name>, <name><surname>Balafar</surname><given-names>M-A</given-names></name>, <name><surname>Motamed</surname><given-names>C</given-names></name>. <article-title>TopicBERT: A Transformer transfer learning based memory-graph approach for multimodal streaming social media topic detection</article-title>. <year>2020</year>. Available: <ext-link xlink:href="http://arxiv.org/abs/2008.06877" ext-link-type="uri">http://arxiv.org/abs/2008.06877</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">Sexton T. IOB Format Intro—Nestor. 2022. Available: <ext-link xlink:href="https://pages.nist.gov/nestor/examples/named-entities/01-BIO-format" ext-link-type="uri">https://pages.nist.gov/nestor/examples/named-entities/01-BIO-format</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Pearce</surname><given-names>K</given-names></name>, <name><surname>Zhan</surname><given-names>T</given-names></name>, <name><surname>Komanduri</surname><given-names>A</given-names></name>, <name><surname>Zhan</surname><given-names>J</given-names></name>. <source>A Comparative Study of Transformer-Based Language Models on Extractive Question Answering</source>. <year>2021</year>. Available: <ext-link xlink:href="http://arxiv.org/abs/2110.03142" ext-link-type="uri">http://arxiv.org/abs/2110.03142</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref029">
      <label>29</label>
      <mixed-citation publication-type="other">dreji18. Bio-Epidemiology-NER. GitHub. 2022. Available: <ext-link xlink:href="https://github.com/dreji18/Bio-Epidemiology-NER" ext-link-type="uri">https://github.com/dreji18/Bio-Epidemiology-NER</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref030">
      <label>30</label>
      <mixed-citation publication-type="other">Bio-Epidemiology-NER. PyPI. 2022. Available: <ext-link xlink:href="https://pypi.org/project/Bio-Epidemiology-NER" ext-link-type="uri">https://pypi.org/project/Bio-Epidemiology-NER</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref031">
      <label>31</label>
      <mixed-citation publication-type="other">Kingma DP, Ba JL. Adam: A method for stochastic optimization. 3rd International Conference on Learning Representations, ICLR 2015—Conference Track Proceedings. International Conference on Learning Representations, ICLR; 2015.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Tjong Kim Sang</surname><given-names>EF</given-names></name>, <name><surname>de Meulder</surname><given-names>F</given-names></name>. <article-title>Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition</article-title>. <source>Proc 7th Conf Nat Lang Learn CoNLL 2003 HLT-NAACL 2003.</source><year>2003</year>; <fpage>142</fpage>–<lpage>147</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Caufield</surname><given-names>JH</given-names></name>. <source>MACCROBAT</source>. <year>2020</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.6084/m9.figshare.9764942.v2</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Caufield</surname><given-names>JH</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>, <name><surname>Bai</surname><given-names>Y</given-names></name>, <name><surname>Liem</surname><given-names>DA</given-names></name>, <name><surname>Garlid</surname><given-names>AO</given-names></name>, <name><surname>Chang</surname><given-names>K-W</given-names></name>, <etal>et al</etal>. <article-title>A Comprehensive Typing System for Information Extraction from Clinical Narratives.</article-title><source>medRxiv</source>. <year>2019</year>; 19009118. Available: <ext-link xlink:href="https://www.medrxiv.org/content/10.1101/19009118v1%0Ahttp://files/803/Caufieldetal.-2019-AComprehensiveTypingSystemforInformationExtr.pdf%0Ahttp://files/804/19009118v1.html%0Ahttps://www.medrxiv.org/content/medrxiv/early/2019/10/22/19009118.fu" ext-link-type="uri">https://www.medrxiv.org/content/10.1101/19009118v1%0Ahttp://files/803/Caufieldetal.-2019—AComprehensiveTypingSystemforInformationExtr.pdf%0Ahttp://files/804/19009118v1.html%0Ahttps://www.medrxiv.org/content/medrxiv/early/2019/10/22/19009118.fu</ext-link></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Doğan</surname><given-names>RI</given-names></name>, <name><surname>Leaman</surname><given-names>R</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>NCBI disease corpus: A resource for disease name recognition and concept normalization.</article-title><source>J Biomed Inform</source>. <year>2014</year>;<volume>47</volume>: <fpage>1</fpage>–<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2013.12.006</pub-id><?supplied-pmid 24393765?><pub-id pub-id-type="pmid">24393765</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Sun</surname><given-names>W</given-names></name>, <name><surname>Rumshisky</surname><given-names>A</given-names></name>, <name><surname>Uzuner</surname><given-names>O</given-names></name>. <article-title>Evaluating temporal relations in clinical text: 2012 i2b2 challenge.</article-title><source>J Am Med Informatics Assoc</source>. <year>2013</year>;<volume>20</volume>: <fpage>806</fpage>–<lpage>813</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/amiajnl-2013-001628</pub-id><?supplied-pmid 23564629?><pub-id pub-id-type="pmid">23564629</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Q</given-names></name>, <name><surname>Allot</surname><given-names>A</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>LitCovid: An open database of COVID-19 literature</article-title>. <source>Nucleic Acids Res</source>. <year>2021</year>;<volume>49</volume>: <fpage>D1534</fpage>–<lpage>D1540</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkaa952</pub-id><?supplied-pmid 33166392?><pub-id pub-id-type="pmid">33166392</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Chiu</surname><given-names>JPC</given-names></name>, <name><surname>Nichols</surname><given-names>E</given-names></name>. <article-title>Named Entity Recognition with Bidirectional LSTM-CNNs.</article-title><source>Trans Assoc Comput Linguist.</source><year>2016</year>;<volume>4</volume>: <fpage>357</fpage>–<lpage>370</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/tacl_a_00104</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>Y</given-names></name>, <name><surname>Yan</surname><given-names>S</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>Transfer learning in biomedical natural language processing: an evaluation of BERT and ELMo on ten benchmarking datasets.</article-title><source>arXiv Prepr arXiv190605474.</source><year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Alsentzer</surname><given-names>E</given-names></name>, <name><surname>Murphy</surname><given-names>JR</given-names></name>, <name><surname>Boag</surname><given-names>W</given-names></name>, <name><surname>Weng</surname><given-names>W-H</given-names></name>, <name><surname>Jin</surname><given-names>D</given-names></name>, <name><surname>Naumann</surname><given-names>T</given-names></name>, <etal>et al</etal>. <article-title>Publicly available clinical BERT embeddings.</article-title><source>arXiv Prepr arXiv190403323.</source><year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Tsai</surname><given-names>RT-H</given-names></name>, <name><surname>Wu</surname><given-names>S-H</given-names></name>, <name><surname>Chou</surname><given-names>W-C</given-names></name>, <name><surname>Lin</surname><given-names>Y-C</given-names></name>, <name><surname>He</surname><given-names>D</given-names></name>, <name><surname>Hsiang</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Various criteria in the evaluation of biomedical named entity recognition</article-title>. <source>BMC Bioinformatics</source>. <year>2006</year>;<volume>7</volume>: <fpage>1</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">16393334</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Agarwal</surname><given-names>K</given-names></name>, <name><surname>Choudhury</surname><given-names>S</given-names></name>, <name><surname>Tipirneni</surname><given-names>S</given-names></name>, <name><surname>Mukherjee</surname><given-names>P</given-names></name>, <name><surname>Ham</surname><given-names>C</given-names></name>, <name><surname>Tamang</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Preparing for the next pandemic via transfer learning from existing diseases with hierarchical multi-modal BERT: a study on COVID-19 outcome prediction.</article-title><source>Sci Rep.</source><year>2022</year>;<volume>12</volume>: <fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-022-13072-w</pub-id><?supplied-pmid 35750878?><pub-id pub-id-type="pmid">34992227</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Gao</surname><given-names>S</given-names></name>, <name><surname>Kotevska</surname><given-names>O</given-names></name>, <name><surname>Sorokine</surname><given-names>A</given-names></name>, <name><surname>Christian</surname><given-names>JB</given-names></name>. <article-title>A pre-training and self-training approach for biomedical named entity recognition.</article-title><source>PLoS One.</source><year>2021</year>;<volume>16</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0246310</pub-id><?supplied-pmid 33561139?><pub-id pub-id-type="pmid">33561139</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000152.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Bugge</surname><given-names>AS</given-names></name>, <name><surname>Sundset</surname><given-names>A</given-names></name>, <name><surname>Aaløkken</surname><given-names>TM</given-names></name>, <name><surname>Jørgensen</surname><given-names>LH</given-names></name>. <article-title>Treatment of a pneumatocele in a COVID-19 patient with endobronchial valves</article-title>. <source>BMJ Case Reports CP</source>. <year>2022</year>;<volume>15</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/bcr-2022-250409</pub-id><?supplied-pmid 35728911?><pub-id pub-id-type="pmid">35728911</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
