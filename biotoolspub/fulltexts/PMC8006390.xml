<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8006390</article-id>
    <article-id pub-id-type="publisher-id">4099</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-021-04099-3</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Factor graph-aggregated heterogeneous network embedding for disease-gene association prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>He</surname>
          <given-names>Ming</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Chen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Bo</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Yadong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Li</surname>
          <given-names>Junyi</given-names>
        </name>
        <address>
          <email>lijunyi@hit.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.19373.3f</institution-id><institution-id institution-id-type="ISNI">0000 0001 0193 3564</institution-id><institution>School of Computer Science and Technology, </institution><institution>Harbin Institute of Technology (Shenzhen), </institution></institution-wrap>Shenzhen, 518055 Guangdong China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.19373.3f</institution-id><institution-id institution-id-type="ISNI">0000 0001 0193 3564</institution-id><institution>Center for Bioinformatics, School of Computer Science and Technology, </institution><institution>Harbin Institute of Technology, </institution></institution-wrap>Harbin, 150001 Heilongjiang China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>29</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>22</volume>
    <elocation-id>165</elocation-id>
    <history>
      <date date-type="received">
        <day>9</day>
        <month>12</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>23</day>
        <month>3</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Exploring the relationship between disease and gene is of great significance for understanding the pathogenesis of disease and developing corresponding therapeutic measures. The prediction of disease-gene association by computational methods accelerates the process.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Many existing methods cannot fully utilize the multi-dimensional biological entity relationship to predict disease-gene association due to multi-source heterogeneous data. This paper proposes FactorHNE, a factor graph-aggregated heterogeneous network embedding method for disease-gene association prediction, which captures a variety of semantic relationships between the heterogeneous nodes by factorization. It produces different semantic factor graphs and effectively aggregates a variety of semantic relationships, by using end-to-end multi-perspectives loss function to optimize model. Then it produces good nodes embedding to prediction disease-gene association.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Experimental verification and analysis show FactorHNE has better performance and scalability than the existing models. It also has good interpretability and can be extended to large-scale biomedical network data analysis.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Disease-gene association prediction</kwd>
      <kwd>Heterogeneous network</kwd>
      <kwd>Graph neural network</kwd>
      <kwd>Factorization</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par9">In the field of biomedical research, the disease-gene association prediction is a fundamental and important problem [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. With the advancement of machine learning and artificial intelligence research, many machine learning methods have been applied to discover new genetic associations of diseases. However, there are still many challenges in this research area. For instance, the number of gene sets is much larger than that of confirmed disease-related genes. In other words, it is difficult to use less data to mine the pattern of disease-gene association. Meanwhile, the genetic heterogeneity of diseases makes the pattern diverse, which increases the difficulty of mining too. Then it is suggested that if a gene has similar characteristics to a known disease causal gene, it might also be associated with this same disease.</p>
    <p id="Par10">Disease-gene association prediction is a process of mining and discovering candidate genes that may be associated with disease through the data set of known actual disease-gene association. And computational methods can greatly accelerate the process of research in the field of biological information. In recent years, a lot of related work emerge. Some works [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>] are from data sources (such as gene expression data, KEGG, etc.) to manually extract features, then uses machine learning classifier to train and predict the task. However, the amount of data is very large, and not all genes have the same extent of exploration. Therefore, except for some common genes, most of the available data are very scarce, which makes feature engineering only use a small number of common features. Biological data is complex, and various biological data have become a simple and clear form through network representation, so network-based methods [<xref ref-type="bibr" rid="CR5">5</xref>] have become the mainstream direction of disease-gene association prediction. These methods [<xref ref-type="bibr" rid="CR6">6</xref>–<xref ref-type="bibr" rid="CR8">8</xref>] are used to mine new disease-gene association in biological entity network, and have achieved good performance. However, due to the limited number of data sources, each method can be further improved through an integrated process. In particular, Han et al. [<xref ref-type="bibr" rid="CR9">9</xref>] predicted the new disease-gene association through the graph convolution network with the features obtained by the integrated matrix decomposition method and the original features, which can capture the linear and nonlinear relationship between diseases and genes at the same time and obtain better performance. Yang et al. [<xref ref-type="bibr" rid="CR8">8</xref>] integrated from the data level, carefully selected the most favorable data sources to build a multi-mode network, and used Node2vec [<xref ref-type="bibr" rid="CR10">10</xref>] to learn node representation on complex network, so as to measure the proximity of disease-gene node pairs and make prediction, or reconstruct a two-layer heterogeneous network containing only disease and gene nodes, which can be used for the final network prediction methods. Benefit from the rapid development of graph neural network, the ability of learning node representation for downstream tasks (link prediction, etc.) directly from heterogeneous networks is greatly enhanced. At present, data level integration is adopted in many works to avoid excessive information loss in the process of model integration (a single model cannot capture all the feature information).</p>
    <p id="Par11">Many methods are only applicable to scenes of homogeneous networks. In fact, most of the scenes in real life are modeled as heterogeneous networks, that is, including multiple node types and multiple relationship types. For example, DeepWalk [<xref ref-type="bibr" rid="CR11">11</xref>], Node2vec [<xref ref-type="bibr" rid="CR10">10</xref>], LINE [<xref ref-type="bibr" rid="CR12">12</xref>] and other methods are designed for the purpose of passing through the network. If they are applied to heterogeneous network data, the heterogeneity of nodes and relationships will be ignored, thus rich semantic information will be lost. Therefore, it is urgent to develop heterogeneous network representation learning methods. Metapath2vec [<xref ref-type="bibr" rid="CR13">13</xref>] is one of the first methods of representation learning from heterogeneous networks, and also the first propose place of metapath, where rich semantic information between different nodes is contain, but it is similar to those in the case of Node2vec, where it is not extendable, and relies on the structural integrity of the network. Wang et al. [<xref ref-type="bibr" rid="CR14">14</xref>] proposed HAN, based on the GAT [<xref ref-type="bibr" rid="CR15">15</xref>] model of integrating a neighbor's graph neural network using a self-attention mechanism, as well as metapath, based on the multiple sampling of neighbors, using a self-attention mechanism to integrate neighbor information from metapath, and after the addition of a layer of semantic attention, which can fusion multiple node information from the different metapath pattern. Since it can alleviate the problem of network heterogeneity and generate node representation containing rich topological structure information and semantic information, this architecture has become a classic architecture of graph neural network model for heterogeneous network. Subsequently, various heterogeneous network embedding models basically retain the two-layer attention mechanism of HAN. However, most of the existing models consider only two end node and one edge from metapath, ignoring information from multiple nodes in the metapath intermedia, which lead to a problem known as early summarization [<xref ref-type="bibr" rid="CR16">16</xref>].</p>
    <p id="Par12">In this work, we present FactorHNE, which is a heterogeneous graph neural network model architecture for aggregating multiple factor graphs for prediction tasks. In addition to any information available, a heterogeneous network of four different nodes was constructed, and based on metapath, multiple patterns were mined. In the node information aggregation phase, in order to alleviate the problem of early summarization, we used factor diagram decomposition based on metapath reconstruction of neighborhood subgraphs to capture the multiple semantics included in the metapath relationship, and the effectiveness of this method was verified [<xref ref-type="bibr" rid="CR17">17</xref>], when multiple relationships between nodes in the graph were mined. After any of the node features are mine in metapath, we used an attention mechanism to integrate the semantic information in any of the metapath. By designing this model, we can make good use of the multi-source biological data to mine the pattern of disease-gene association and promote the understanding of disease pathogenesis and the development of therapeutic drugs. Our major contributions can be summarized as follows:<list list-type="bullet"><list-item><p id="Par13">Through factor decomposition of neighborhood subgraphs of nodes, we mined a variety of relationship information, and effectively alleviated the early summarization problem from metapath sampling.</p></list-item><list-item><p id="Par14">We designed a number of comparison experiments on a large-scale network, verified the performance advantage of our model over existing models, and analyzed the experimental results.</p></list-item><list-item><p id="Par15">We designed a deep learning model for heterogeneous network link prediction, which can effectively learn rich topological information and semantic information in heterogeneous networks, and can be extended to large-scale biomedical network data, and verified by design experiments.</p></list-item></list></p>
  </sec>
  <sec id="Sec2">
    <title>Results and discussions</title>
    <p id="Par16">In this section, we will introduce our experimental settings and result analysis in detail. At the same time, FactorHNE and other network embedding methods are compared under fair conditions. By observing and comparing the experimental results, the advantages of our model in the task of disease-gene association prediction in a large-scale heterogeneous network are analyzed.</p>
  </sec>
  <sec id="Sec3">
    <title>Baselines</title>
    <p id="Par17">To assess the performance of a link prediction model, we adopt the AP, AUC, Precision@K, and Recall@K which commonly used in model evaluation. AP represents the area under the P–R curve drawn according to the precision and recall of the model, AUC represents the area under ROC curve of the model, these two indicators are commonly used to evaluate prediction tasks, in addition, the Precision@K and Recall@K denote the precision and recall are producted based on the Kth largest threshold. We calculate these evaluation indexes for FactorHNE model and other baselines, and then analyze the experimental results. And the baseline we use are shown as follows:<list list-type="bullet"><list-item><p id="Par18">Metapath2vec [<xref ref-type="bibr" rid="CR13">13</xref>] is a traditional random walk based model, using metapath to mentor the next hop neighbor, producing a heterogeneous node sequence based on the specific metapath, and using the Skip-gram model to generate node embedding, we have tried a variety of metapath, report the best of the results.</p></list-item><list-item><p id="Par19">HIN2vec [<xref ref-type="bibr" rid="CR18">18</xref>] is a model for heterogeneous network embedding. By applying optimization constraints to multiple downstream tasks between node pairs, it is possible to train both heterogeneous nodes embedding and multiple metapath embedding, meaning that it will automatically try any combination of metapath to produce the most suitable node embedding.</p></list-item><list-item><p id="Par20">HERec [<xref ref-type="bibr" rid="CR19">19</xref>] is a recommended model for heterogeneous networks, based on multiple metapath pattern converts the original heterogeneous network to an homogeneous network, then use DeepWalk model to generate node embedding from all metapath, and after combined ones from each metapath, a final embedding of the node will be generated.</p></list-item><list-item><p id="Par21">GAT [<xref ref-type="bibr" rid="CR15">15</xref>] is a GNN model for homogeneous networks, where neighbor information is aggregated using a self-attention mechanism, and node embedding is obtained using semi-supervise training, it is an end-to-end model. where we show the best after attempted multiple metapath pattern.</p></list-item><list-item><p id="Par22">HAN [<xref ref-type="bibr" rid="CR14">14</xref>] is a GNN model for heterogeneous networks, using methods similar to those found in HERec to convert networks to homogeneous, then using GAT to generate node embedding in each metapath semantic environment, and finally using a semantic-level attention to aggregate node embedding in different metapath pattern.</p></list-item><list-item><p id="Par23">MAGNN [<xref ref-type="bibr" rid="CR20">20</xref>] is a heterogeneous network GNN model, which alleviates the early summarization problem to some extent by encoding metapath instances, and extends the model to larger heterogeneous networks through neighbor sampling mechanism.</p></list-item></list></p>
    <p id="Par24">All baselines can be further subdivided into unsupervised and semi supervised learning models. The first three models belong to unsupervised learning model, and the last three GNN models belong to semi supervised learning model. However, our dataset does not have node label information, so we add a loss function based on downstream link prediction task to GNN model, For the traditional model (the first three baselines), we set the parameters of random walk as follows: window set is equal to 5, walk length is equal to 100, each node performs 10 walks, and the number of negative samples is 5, We set the embedding dimension of the generation node to 64. We use the Adam optimizer with a learning rate of 0.005 and a L2 penalty weight of 0.001. We use the same training set and test set, and the same training method. For GNN models (MAGNN and FactorHNE) using neighbor sampling, the number of neighbors is fixed to 100. For fair comparison, our results take the average value of three runs.</p>
  </sec>
  <sec id="Sec4">
    <title>Experiment analysis</title>
    <p id="Par25">The experimental results of FactorHNE and other baselines are shown in Table <xref rid="Tab1" ref-type="table">1</xref>. Through the analysis of the experimental results, some conclusions can be drawn.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Experimental results (%) of link prediction task on dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model</th><th align="left">P@1000</th><th align="left">R@1000</th><th align="left">P@10,000</th><th align="left">R@10,000</th><th align="left">P@20,000</th><th align="left">R@20,000</th></tr></thead><tbody><tr><td align="left">Metapath2vec</td><td char="." align="char">99.60 ± 0.202</td><td char="." align="char">3.81 ± 0.301</td><td char="." align="char">95.40 ± 0.202</td><td char="." align="char">36.46 ± 0.023</td><td char="." align="char">82.65 ± 0.011</td><td char="." align="char">63.18 ± 0.022</td></tr><tr><td align="left">HIN2vec</td><td char="." align="char">99.60 ± 0.051</td><td char="." align="char">3.81 ± 0.241</td><td char="." align="char">74.22 ± 0.102</td><td char="." align="char">28.37 ± 0.043</td><td char="." align="char">58.99 ± 0.031</td><td char="." align="char">45.09 ± 0.021</td></tr><tr><td align="left">HERec</td><td char="." align="char">63.30 ± 0.063</td><td char="." align="char">2.42 ± 0.182</td><td char="." align="char">72.58 ± 0.035</td><td char="." align="char">27.74 ± 0.061</td><td char="." align="char">71.55 ± 0.102</td><td char="." align="char">54.69 ± 0.100</td></tr><tr><td align="left">GAT</td><td char="." align="char">94.90 ± 0.171</td><td char="." align="char">3.62 ± 0.304</td><td char="." align="char">93.67 ± 0.043</td><td char="." align="char">35.80 ± 0.102</td><td char="." align="char">90.45 ± 0.211</td><td char="." align="char">69.14 ± 0.117</td></tr><tr><td align="left">HAN</td><td char="." align="char">99.60 ± 0.093</td><td char="." align="char">3.81 ± 0.301</td><td char="." align="char"><bold>99.16</bold> ± 0.202</td><td char="." align="char"><bold>37.90</bold> ± 0.306</td><td char="." align="char">96.28 ± 0.130</td><td char="." align="char">73.59 ± 0.317</td></tr><tr><td align="left">MAGNN</td><td char="." align="char">99.30 ± 0.122</td><td char="." align="char">3.80 ± 0.103</td><td char="." align="char">98.11 ± 0.351</td><td char="." align="char">37.50 ± 0.203</td><td char="." align="char">94.99 ± 0.033</td><td char="." align="char">72.61 ± 0.091</td></tr><tr><td align="left">FactorHNE</td><td char="." align="char"><bold>99.70</bold> ± 0.062</td><td char="." align="char"><bold>3.81</bold> ± 0.202</td><td char="." align="char">99.07 ± 0.121</td><td char="." align="char">37.87 ± 0.082</td><td char="." align="char"><bold>96.91</bold> ± 0.072</td><td char="." align="char"><bold>74.08</bold> ± 0.145</td></tr></tbody></table><table-wrap-foot><p>Bold values are the highest value of all baselines</p></table-wrap-foot></table-wrap></p>
    <p id="Par26">ROC and PR curves are shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Our test set contains 52,328 positive and negative edge samples(generate negative samples by randomly selecting edges that do not exist in the dataset), so the value of K in Precision@K and Recall@K is {1000, 10,000, 20,000}. As can be seen from Table <xref rid="Tab1" ref-type="table">1</xref>, the performance of the traditional model based on unsupervised learning is much lower than that of the GNN model based on semi supervised learning. The main reason is that they cannot carry out end-to-end learning and cannot benefit from the gradient optimization of downstream tasks. Therefore, the embedding generated may be stable in most of the downstream tasks, but none of them will be particularly excellent. Another reason is that they can only use the topology information in the network, ignoring the content of the node itself. Therefore, compared with the GNN model, the performance gap will be more obvious. After all, the information contained is not in the same level.<fig id="Fig1"><label>Fig. 1</label><caption><p><bold>a</bold> ROC curves of all models; <bold>b</bold> P–R curve of all models</p></caption><graphic xlink:href="12859_2021_4099_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par27">In addition, by comparing the performance of several GNN models, it can be found that the GAT model designed for homogeneous network has great advantages over the traditional model, but compared with FactorHNE and HAN, it is still about 5–6% worse in performance. In addition, it seems that the improved metapath instance encode component of MAGNN based on HAN does not seem to be particularly obvious in our problem, because MAGNN uses the strategy of sampling neighbors to improve scalability like FactorHNE, and the actual number of neighbors may exceed several orders of magnitude. The reason for poor performance may be that the improvement brought by the improvement is not enough to make up for the loss of neighbor information Missing gap. In contrast, our FactorHNE model uses the strategy of aggregation factor graph to mine multiple semantic information implied in metapath. At the same time, it uses sampling neighbor strategy to improve the scalability of the model, and even outperforms HAN which uses more neighbor information. In a word, compared with the improved strategy of MAGNN, our strategy of aggregation factor graph shows a good effect in solving early summation issue, and its performance is also ahead of all baselines in most indicators.</p>
    <sec id="Sec5">
      <title>Experiment analysis</title>
      <p id="Par28">In this section, we will fine tune the values of the four parameters, compare the performance changes of the model under different parameters, and measure the change degree of the model through the AUC index. The comparative experimental results of all parameters are shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. The four parameters are as follows:<list list-type="bullet"><list-item><p id="Par29"><italic>Dimension of hidden embedding</italic> Figure <xref rid="Fig2" ref-type="fig">2</xref>a shows the influence of dimension of hidden embedding on the final performance of the model. We can see that the curve rises rapidly at the beginning, achieves the best result when reaching 128, and then begins to decline. We think that this is because the aggregation of multiple factor graphs requires a larger dimension to contain rich information, while the latter descending part may contain redundant dimensions, which produces noise.
</p></list-item><list-item><p id="Par30"><italic>Number of attention head</italic> In Fig. <xref rid="Fig2" ref-type="fig">2</xref>b, we verify the influence degree of the long attention mechanism. We can see that the curve is relatively gentle, and there is a slow upward trend at the beginning. Therefore, the long attention mechanism has a certain improvement effect on the model, and ensures that the model is more stable, which is conducive to the recurrence of the results.</p></list-item><list-item><p id="Par31"><italic>Number of factor graph</italic> This parameter represents the number of factor graphs we use when factoring neighborhood subgraphs. In Fig. <xref rid="Fig2" ref-type="fig">2</xref>c, the curve is basically smooth, and the best performance is achieved at 16. Considering the computational overhead caused by increasing the number of factor graphs, the best performance can be achieved by using fewer factor graphs, and it does not need to adjust parameters to get better performance.</p></list-item><list-item><p id="Par32"><italic>Weight of factorization loss</italic> This parameter is used to control the proportion of downstream task loss and factor graph decomposition loss. From Fig. <xref rid="Fig2" ref-type="fig">2</xref>d, we find that the AUC can be improved by 2–3% by increasing the decomposition loss of factor graph within a certain range, which indicates that the multiple semantic information mined by factor graph has a beneficial effect on the prediction performance of the model. However, excessive increase in the weight of γ will make a mockery of the impact of downstream task loss, resulting in performance degradation.<fig id="Fig2"><label>Fig. 2</label><caption><p>Parameter analysis of FactorHNE</p></caption><graphic xlink:href="12859_2021_4099_Fig2_HTML" id="MO3"/></fig></p></list-item></list></p>
    </sec>
    <sec id="Sec6">
      <title>Case study</title>
      <p id="Par33">In order to further analyze the biological significance of our model, we select two different diseases for mining analysis. The two different disease are Gait abnormality (CUI:C0575081) and Congenital Epicanthus (CUI:C0678230). We use our model with optimal performance to calculate the score of possible association between these two diseases and all genes in the dataset, and listed the top 20 candidate genes. The results are shown in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Case study results</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">CUI</th><th align="left">Disease name</th><th align="left">CUI</th><th align="left">Disease</th></tr></thead><tbody><tr><td align="left">C0575081</td><td align="left">Gait abnormality</td><td align="left">CUI:C0678230</td><td align="left">Congenital Epicanthus</td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left">Gene</th><th align="left">Original DB</th><th align="left">Gene</th><th align="left">Original DB</th></tr></thead><tbody><tr><td align="left">FGFR3</td><td align="left"/><td align="left">FBN1</td><td align="left"/></tr><tr><td align="left">POU1F1</td><td align="left"/><td align="left">IKBKG</td><td align="left"/></tr><tr><td align="left">ROR2</td><td align="left"/><td align="left">LBR</td><td align="left"/></tr><tr><td align="left">GRM1</td><td align="left"/><td align="left">KCNJ2</td><td align="left"/></tr><tr><td align="left">OFD1</td><td align="left">DisGeNet*</td><td align="left">ROR2</td><td align="left">DisGeNet</td></tr><tr><td align="left">BMPR1B</td><td align="left"/><td align="left">SOX9</td><td align="left"/></tr><tr><td align="left">FGFR2</td><td align="left"/><td align="left">FLNA</td><td align="left">DisGeNet*</td></tr><tr><td align="left">RPS29</td><td align="left"/><td align="left">GDF5</td><td align="left"/></tr><tr><td align="left">IL6</td><td align="left"/><td align="left">LMNA</td><td align="left"/></tr><tr><td align="left">SLC9A6</td><td align="left"/><td align="left">TBX3</td><td align="left"/></tr><tr><td align="left">MYH6</td><td align="left"/><td align="left">FOXG1</td><td align="left">DisGeNet</td></tr><tr><td align="left">RAF1</td><td align="left"/><td align="left">OFD1</td><td align="left">DisGeNet</td></tr><tr><td align="left">COL6A2</td><td align="left"/><td align="left">HDAC6</td><td align="left"/></tr><tr><td align="left">MKKS</td><td align="left"/><td align="left">GRM1</td><td align="left"/></tr><tr><td align="left">MAP3K7</td><td align="left"/><td align="left">TGDS</td><td align="left"/></tr><tr><td align="left">PTCH2</td><td align="left"/><td align="left">WDR60</td><td align="left">DisGeNet</td></tr><tr><td align="left">KCNJ2</td><td align="left"/><td align="left">GJA1</td><td align="left">DisGeNet</td></tr><tr><td align="left">RAG1</td><td align="left"/><td align="left">OAT</td><td align="left"/></tr><tr><td align="left">LMNA</td><td align="left">DisGeNet</td><td align="left">ZMPSTE24</td><td align="left"/></tr><tr><td align="left">FAS</td><td align="left">DisGeNet</td><td align="left">TREX1</td><td align="left"/></tr></tbody></table><table-wrap-foot><p>In the prediction results of the above table, the candidate genes with known association were labeled in the <bold>original DB</bold>, and candidate genes marked with "*" indicate newly discovered associated genes, that is, there are not exist in dataset but records in the latest online database. The results show that our model has the ability to mine new disease gene associations, such as <bold>OFD1-C057508</bold> and <bold>FLNA-C0678230</bold>. Our model does not remember the existing associations in the original dataset, but predicts new candidate genes by mining the hidden patterns. This is very important, because it is difficult to mine new genes only by making a high score for the known associations. Therefore, our model can help to decipher the relationship between diseases and genes, which has certain biomedical significance</p></table-wrap-foot></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec7">
    <title>Conclusions</title>
    <p id="Par34">In this paper, we use a new method to solve the early summation problem in heterogeneous network GNN model. By factoring the neighborhood subgraphs of homogeneous graphs transformed according to metapath, our proposed FactorHNE can mine a variety of semantic information in metapath complex patterns, and then generate excellent node embedding for link prediction through a double aggregation structure. The double aggregation structure first aggregates the semantic information in different factor graphs in a single metapath pattern, and then aggregates the semantic information in all metapath pattern by using the attention mechanism. In addition, we combine two loss functions in the optimization objective function of the model, and control the proportion of the two by weight coefficient to generate the most suitable node embedding for link prediction task. In the end, we compare the advantages and disadvantages of our model with a variety of baselines, and analyze some factors that affect the performance of the model by adjusting multiple parameters. Generally speaking, the FactorHNE model proposed by us shows good scalability and performance advantages.</p>
  </sec>
  <sec id="Sec8">
    <title>Materials and methods</title>
    <sec id="Sec9">
      <title>DataSet</title>
      <p id="Par35">We use the data set which is derived from [<xref ref-type="bibr" rid="CR8">8</xref>] and contains four different node types: gene, disease, gene ontology (GO) and disease symptoms. They are shown in Table <xref rid="Tab3" ref-type="table">3</xref> and are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/xasdzxc/FactorHNE/tree/master/data">https://github.com/xasdzxc/FactorHNE/tree/master/data</ext-link>.<table-wrap id="Tab3"><label>Table 3</label><caption><p>An overview of heterogeneous network dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Node</th><th align="left">Number</th><th align="left">Relation</th><th align="left">Metapath</th></tr></thead><tbody><tr><td align="left">Gene (G)</td><td align="left">21584</td><td align="left">G–G|G–D|G–O</td><td align="left">GG|GDG|GOG</td></tr><tr><td align="left">Disease (D)</td><td align="left">15030</td><td align="left">D–G|D–S</td><td align="left">DGD|DSD</td></tr><tr><td align="left">GO (O)</td><td align="left">14204</td><td align="left">O–G</td><td align="left">–</td></tr><tr><td align="left">Symptom (S)</td><td align="left">6540</td><td align="left">S–D</td><td align="left">–</td></tr></tbody></table></table-wrap></p>
      <p id="Par36">We collected 130,820 disease-gene association from DisGeNet, 213,888 protein–protein interactions from Menche, 99,087 disease-symptom association from HPO and Orphanet, and 218,337 annotation records from STRING 10.</p>
      <p id="Par37">All the initial values of edge weights in the heterogeneous network are set to 1. On this basis, the metagraph of the heterogeneous network we built is shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>:<fig id="Fig3"><label>Fig. 3</label><caption><p>Metagraph for heterogeneous networks</p></caption><graphic xlink:href="12859_2021_4099_Fig3_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec10">
      <title>Model architecture</title>
      <p id="Par38">In this section, we introduce the implementation principles and details of the individual components of the FactorHNE model. FactorHNE is composed of three main parts: neighborhood subgraph factorization, inter-metapath factor graph aggregation, and multi-metapath semantic aggregation. Figure <xref rid="Fig4" ref-type="fig">4</xref> illustrates the overall framework of the FactorHNE model.<fig id="Fig4"><label>Fig. 4</label><caption><p>The overall architecture of FactorHNE. <bold>a</bold> Model global architecture; <bold>b</bold> neighborhood subgraph factor decomposition; <bold>c</bold> inter-metapath factor graph aggregation</p></caption><graphic xlink:href="12859_2021_4099_Fig4_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec11">
      <title>Neighborhood subgraph factorization</title>
      <p id="Par39">For a heterogeneous graph <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G = \left( {V,E} \right)$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq1.gif"/></alternatives></inline-formula>, It owns the node type set <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A$$\end{document}</tex-math><mml:math id="M4"><mml:mi>A</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq2.gif"/></alternatives></inline-formula> relational type set <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R$$\end{document}</tex-math><mml:math id="M6"><mml:mi>R</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq3.gif"/></alternatives></inline-formula>, two mapping functions: <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varphi :{V} \to {A}$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi>φ</mml:mi><mml:mo>:</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq4.gif"/></alternatives></inline-formula> and <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi :E \to R$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo>:</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq5.gif"/></alternatives></inline-formula>, and it has the property of <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left| A \right| + \left| R \right| &gt; 2$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mfenced close="|" open="|"><mml:mi>A</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close="|" open="|"><mml:mi>R</mml:mi></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq6.gif"/></alternatives></inline-formula>. heterogeneous graph <italic>G</italic> contains a variety of types of nodes, different node contains its own features may not in the same space, such as, <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{1}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq7.gif"/></alternatives></inline-formula> dimension node features and <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{2}$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq8.gif"/></alternatives></inline-formula> dimension another type node feature interact directly, even the dimension of the same case, is not reasonable, because of the feature space is different, just meaningless calculation. In order to solve this problem, we need to all types of nodes are projected onto the same vector space here. Our solution is for each node <italic>v</italic> of type <italic>a</italic> to design a linear transformation matrix <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_{a} \in {\mathbb{R}}^{{d^{\prime} \times d_{a} }}$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq9.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d^{\prime}$$\end{document}</tex-math><mml:math id="M20"><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq10.gif"/></alternatives></inline-formula> denotes the dimension of all node type feature vector after the projection, and <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{a}$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mi>d</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq11.gif"/></alternatives></inline-formula> represents the original feature vector dimension of node type <italic>a</italic>, so we have the following procedure:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{v}^{{\prime}} = M_{a} \cdot x_{v}^{a}$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{v}^{a}$$\end{document}</tex-math><mml:math id="M26"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq12.gif"/></alternatives></inline-formula> represents the original feature of node <inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v \in V_{a}$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq13.gif"/></alternatives></inline-formula>,<inline-formula id="IEq14"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{a}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mi>V</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq14.gif"/></alternatives></inline-formula> represents the set of all nodes belonging to type <inline-formula id="IEq15"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a \in A$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq15.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq16"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{v}^{{\prime}}$$\end{document}</tex-math><mml:math id="M34"><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq16.gif"/></alternatives></inline-formula> represents the vector representation of node <italic>v</italic> after projected into the same space. In this way, it not only solves the problem caused by the heterogeneity of heterogeneous network, but also unifies the dimension of model input feature vector.</p>
      <p id="Par40">Next, we will define a collection of multiple metapath <italic>M</italic>, for one of the <inline-formula id="IEq17"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_{p} = a_{1} \to ^{{r_{1} }} a_{2} \to ^{{r_{2} }} \ldots a_{n - 1} \to ^{{r_{n - 1} }} a_{n}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msup><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msup><mml:mo>…</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msup><mml:msub><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq17.gif"/></alternatives></inline-formula> can be abbreviated to <inline-formula id="IEq18"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{1} \cdot a_{2} \ldots a_{n - 1} \cdot a_{n}$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq18.gif"/></alternatives></inline-formula>, where the source node connects to the target node through a range of different nodes and relationships using a defined pattern, which called “metapath”, and for each <inline-formula id="IEq19"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_{l} \in M$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq19.gif"/></alternatives></inline-formula>, the heterogenous graph <inline-formula id="IEq20"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G$$\end{document}</tex-math><mml:math id="M42"><mml:mi>G</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq20.gif"/></alternatives></inline-formula> is converted into a homogeneous graph <inline-formula id="IEq21"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g_{{m_{l} }}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>g</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq21.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq22"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l$$\end{document}</tex-math><mml:math id="M46"><mml:mi>l</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq22.gif"/></alternatives></inline-formula> is index of the different metapaths is included. For each homogeneous graph <italic>g</italic> from one metapath converts, before our neighbor information in aggregate phase to factorization so that can capture a variety of semantic information implied in metapath instance edge, the key idea is homogeneous graph based on the transformation of metapath only focus on two end node and a synthesis edge, which can cause early summarization issue. With the factorization step, the model can capture a variety of relations information implied in a single edge at a simple figure, so as to solve early summarization issue. For this issue, our solution is to reconstruct the edge weight of homogeneous graph <italic>g</italic> with the same operation for many times, based on the following formula:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{e} = \sigma \left( {S\left( {h_{v}^{{\prime}} ,h_{u}^{{\prime}} } \right)} \right)$$\end{document}</tex-math><mml:math id="M48" display="block"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>S</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par41">where <inline-formula id="IEq23"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{e}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>W</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq23.gif"/></alternatives></inline-formula> denotes new weight matrix after refactoring with <italic>g</italic> each edge, <italic>e</italic> is factor graph, <inline-formula id="IEq24"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma \left( \cdot \right)$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mo>·</mml:mo></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq24.gif"/></alternatives></inline-formula> is sigmod function that used for standardize weights, <inline-formula id="IEq25"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S\left( {h_{v}^{{\prime}} ,h_{u}^{{\prime}} } \right)$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mi>S</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq25.gif"/></alternatives></inline-formula> compute a score between node <italic>v</italic> and <italic>u</italic> (we use a single layer MLP as the implementation) because the focus is on the edge, so maintaining the features of nodes, we can get the factor graph <inline-formula id="IEq26"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G = \left( {W_{e} ,h^{{\prime }} } \right)$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq26.gif"/></alternatives></inline-formula>. If we just repeat this step to obtain multiple factor graphs, we will not be able to distinguish the information of each factor graph, which will only increase the stability of the model and not be able to mine the multiple semantic information contained in the single metapath edge. So we need to apply constraints that will include different information from each factor graph in order to obtain the rich semantic information in the metapath instance edge [<xref ref-type="bibr" rid="CR17">17</xref>]. A discriminant loss function for any factor graph is added here, after any label information is included<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_{e} = Softmax\left( {F\left( {EnCoder\left( {W_{e} ,h^{{\prime }} } \right)} \right)} \right)$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>F</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>
For each factor graph, we first coded it according to its new edge weight matrix <inline-formula id="IEq27"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{e}$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mi>W</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq27.gif"/></alternatives></inline-formula> and the original node feature set <italic>h</italic>′ to obtain a form that is convenient for classifier <inline-formula id="IEq28"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F\left( \cdot \right)$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mi>F</mml:mi><mml:mfenced close=")" open="("><mml:mo>·</mml:mo></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq28.gif"/></alternatives></inline-formula> processing. The classifier adopted is a single-layer full connection layer. Then, after standardization by the <inline-formula id="IEq29"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Softmax$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mi mathvariant="italic">Softmax</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq29.gif"/></alternatives></inline-formula> layer, cross entropy is used to calculate the discriminant loss of multiple factor graphs<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{L}}_{Factor} = \frac{1}{N}\mathop \sum \limits_{i}^{N} \left( {\mathop \sum \limits_{y = 1}^{{N_{e} }} - {\mathbb{I}}\left( {e = y} \right){\text{log}}\left( {P_{i}^{e} \left[ y \right]} \right)} \right)$$\end{document}</tex-math><mml:math id="M66" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Factor</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mfenced close=")" open="("><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:munderover><mml:mo>-</mml:mo><mml:mi mathvariant="double-struck">I</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mtext>log</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msubsup><mml:mfenced close="]" open="["><mml:mi>y</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq30"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N$$\end{document}</tex-math><mml:math id="M68"><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq30.gif"/></alternatives></inline-formula> represents the number of factor graphs, and <inline-formula id="IEq31"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_{e}$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mi>N</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq31.gif"/></alternatives></inline-formula> represents the number of different labels contained in all factor graphs, which we set to <inline-formula id="IEq32"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_{e} = N$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq32.gif"/></alternatives></inline-formula> in order to distinguish each factor graph. <inline-formula id="IEq33"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbb{I}}\left( \cdot \right)$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi><mml:mfenced close=")" open="("><mml:mo>·</mml:mo></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq33.gif"/></alternatives></inline-formula> represents the indicator function, and the probability that the <inline-formula id="IEq34"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M76"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq34.gif"/></alternatives></inline-formula>th factor graph with label <inline-formula id="IEq35"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y$$\end{document}</tex-math><mml:math id="M78"><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq35.gif"/></alternatives></inline-formula> represented by <inline-formula id="IEq36"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{i}^{e} \left[ y \right]$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msubsup><mml:mfenced close="]" open="["><mml:mi>y</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq36.gif"/></alternatives></inline-formula>. Through these operations above, several factor graphs containing different semantic information can be finally obtained, as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>b.</p>
    </sec>
    <sec id="Sec12">
      <title>Inter-metapath factor graph aggregation</title>
      <p id="Par42">In order to include multiple semantic information from any of the factor graphs, we used neighbor information aggregation from each factor graph, and after combining the feature information from each of the factor graph to produce any of the specific node information from metapath, this part have two steps, shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>c.</p>
      <p id="Par43">As for the single factor graph <italic>e</italic>, we use the self-attention mechanism proposed in the work of Veličković et al. [<xref ref-type="bibr" rid="CR15">15</xref>] to aggregate the neighbors of the target node on the factor graph <italic>e</italic>. Specifically, we first calculate the attention weight between the target node and neighbor <inline-formula id="IEq37"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j \in N$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq37.gif"/></alternatives></inline-formula>, <italic>N</italic> represents the set of all neighbors, as shown in the formula follow<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{ij}^{m} = Attention\left( {h_{i}^{{\prime}} ,h_{j}^{{\prime}} ,m} \right)$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq38"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{ij}^{m}$$\end{document}</tex-math><mml:math id="M86"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq38.gif"/></alternatives></inline-formula> represents the attention weights from nodes <inline-formula id="IEq39"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left( {i,j} \right)$$\end{document}</tex-math><mml:math id="M88"><mml:mfenced close=")" open="("><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq39.gif"/></alternatives></inline-formula> in factor graph <italic>e</italic> with the metapath <inline-formula id="IEq40"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M90"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq40.gif"/></alternatives></inline-formula> connection, and <inline-formula id="IEq41"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Attention\left( \cdot \right)$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mo>·</mml:mo></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq41.gif"/></alternatives></inline-formula> is used to integrate feature vectors from nodes <inline-formula id="IEq42"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M94"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq42.gif"/></alternatives></inline-formula> and <inline-formula id="IEq43"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M96"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq43.gif"/></alternatives></inline-formula> after projection with an attention vector, after the standardization of any neighbor attention weights from the target nodes from metapath <inline-formula id="IEq44"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M98"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq44.gif"/></alternatives></inline-formula>. the process is as follows<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha_{ij}^{m} = Softmax\left( {w_{ij}^{m} } \right) = \frac{{exp(w_{ij}^{m} )}}{{\mathop \sum \nolimits_{k = 1}^{\left| N \right|} {\text{exp}}(w_{ik}^{m} )}}$$\end{document}</tex-math><mml:math id="M100" display="block"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mfenced close="|" open="|"><mml:mi>N</mml:mi></mml:mfenced></mml:msubsup><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>
Once the attention weights of all the neighbors have been generated, the aggregation operation can be performed, as shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. The formula is as follows:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z_{i}^{m} = \mathop \sum \limits_{j}^{\left| N \right|} \alpha_{ij}^{m} \cdot h_{j}^{{\prime}}$$\end{document}</tex-math><mml:math id="M102" display="block"><mml:mrow><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mfenced close="|" open="|"><mml:mi>N</mml:mi></mml:mfenced></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><italic>N</italic> here includes the target node itself. In order to guarantee the aggregation process can maintain stability, we adopted multi-head attention mechanism. Meanwhile, it still can expand capacity of the model is based on repeat <inline-formula id="IEq45"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M104"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq45.gif"/></alternatives></inline-formula> times attention aggregation process, then <inline-formula id="IEq46"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K$$\end{document}</tex-math><mml:math id="M106"><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq46.gif"/></alternatives></inline-formula> results concatenate together in the end, all the factors graph generated feature vector concatenate together as a representation vector with metapath <inline-formula id="IEq47"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M108"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq47.gif"/></alternatives></inline-formula><fig id="Fig5"><label>Fig. 5</label><caption><p>An example of node aggregation based on self-attention mechanism</p></caption><graphic xlink:href="12859_2021_4099_Fig5_HTML" id="MO2"/></fig>.</p>
    </sec>
    <sec id="Sec13">
      <title>Multi-metapath semantic aggregation</title>
      <p id="Par44">Previous sections illustrate a full process based on single metapath <inline-formula id="IEq48"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M110"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq48.gif"/></alternatives></inline-formula>, therefore, we need to integrate the semantic information and structural information from different metapath <inline-formula id="IEq49"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{ {m_{1} ,m_{2} , \ldots ,m_{l} } \right\}$$\end{document}</tex-math><mml:math id="M112"><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq49.gif"/></alternatives></inline-formula>. Now we have all node embedding set <inline-formula id="IEq50"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{ {Z_{v}^{{m_{1} }} ,Z_{v}^{{m_{2} }} , \ldots ,Z_{v}^{{m_{l} }} } \right\}$$\end{document}</tex-math><mml:math id="M114"><mml:mfenced close="}" open="{"><mml:mrow><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:msubsup></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq50.gif"/></alternatives></inline-formula> generated by different metapath pattern. In particular, we averaged any of the target node embedding from any metapath as follows<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{{m_{i} }} = \frac{1}{{\left| {V_{a} } \right|}}\mathop \sum \limits_{{v \in V_{a} }} {\text{tanh}}\left( {W_{a} Z_{v}^{{m_{i} }} + \varepsilon_{a} } \right)$$\end{document}</tex-math><mml:math id="M116" display="block"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mfenced close="|" open="|"><mml:msub><mml:mi>V</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mfenced></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mtext>tanh</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq51"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{a}$$\end{document}</tex-math><mml:math id="M118"><mml:msub><mml:mi>W</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq51.gif"/></alternatives></inline-formula> is a linear transformation matrix that specific to a certain node type <italic>a</italic>, <inline-formula id="IEq52"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varepsilon_{a}$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mi>ε</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq52.gif"/></alternatives></inline-formula> is corresponding to the bias of the linear transformation, both are trainable parameter. <italic>V</italic><sub><italic>a</italic></sub> denote all node of type <italic>a</italic> in homogeneous graph based on metapath <inline-formula id="IEq53"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_{i}$$\end{document}</tex-math><mml:math id="M122"><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq53.gif"/></alternatives></inline-formula>. Similar to the process of calculate weight neighbor's attention weight in section above, for each of the metapath <inline-formula id="IEq54"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_{i}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq54.gif"/></alternatives></inline-formula> attention while computing information fusion weights, the formula is as follows.<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{{m_{i} }} = \left\langle {Q,P_{{m_{i} }} } \right\rangle$$\end{document}</tex-math><mml:math id="M126" display="block"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="〉" open="〈"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\omega_{{m_{i} }} = Softmax\left( {w_{{m_{i} }} } \right) = \frac{{{\text{exp}}\left( {w_{{m_{i} }} } \right)}}{{\mathop \sum \nolimits_{j = 1}^{l} {\text{exp}}\left( {w_{{m_{j} }} } \right)}}$$\end{document}</tex-math><mml:math id="M128" display="block"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>w</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>exp</mml:mtext><mml:mfenced close=")" open="("><mml:msub><mml:mi>w</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:mtext>exp</mml:mtext><mml:mfenced close=")" open="("><mml:msub><mml:mi>w</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H_{v} = \mathop \sum \limits_{{m_{i} \in M}} \omega_{{m_{i} }} \cdot Z_{v}^{{m_{i} }}$$\end{document}</tex-math><mml:math id="M130" display="block"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ω</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>·</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq55"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q$$\end{document}</tex-math><mml:math id="M132"><mml:mi>Q</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq55.gif"/></alternatives></inline-formula> is an attention vector at the single metapath level, <inline-formula id="IEq56"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\langle \cdot \right\rangle$$\end{document}</tex-math><mml:math id="M134"><mml:mfenced close="〉" open="〈"><mml:mo>·</mml:mo></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq56.gif"/></alternatives></inline-formula> is an inner product, <inline-formula id="IEq57"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\omega_{{m_{i} }}$$\end{document}</tex-math><mml:math id="M136"><mml:msub><mml:mi>ω</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq57.gif"/></alternatives></inline-formula> is an attention weight of metapath <inline-formula id="IEq58"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_{i}$$\end{document}</tex-math><mml:math id="M138"><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq58.gif"/></alternatives></inline-formula> and <italic>H</italic><sub><italic>v</italic></sub> is an embedding vector of the final heterogeneous network node <italic>v</italic> with multi-metapath semantic information.</p>
    </sec>
    <sec id="Sec14">
      <title>Optimization</title>
      <p id="Par45">We aim to obtain a heterogeneous network embedding model that dedicated to disease-gene association prediction. Some previous models based on random walk usually divide generated node embedding and link prediction into two parts, which leads to final node embedding lack of optimization information of link prediction task. Our FactorHNE model benefits from the underlying architecture of neural network and can combine link prediction task in an end-to-end model. We calculate a similarity score by designing the decoder for the node pairs that need to be predicted. Here we directly set the decoder as the inner product, and then we have<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Score_{gd} = \sigma \left( {\left\langle {H_{g} ,H_{d} } \right\rangle } \right)$$\end{document}</tex-math><mml:math id="M140" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi mathvariant="italic">gd</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mfenced close="〉" open="〈"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>
For the loss function of the model, we adopt the binary cross entropy function, the specific form is shown as follows<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{Pred} = - \mathop \sum \limits_{{\left( {g,d} \right) \in {\Phi }}} {\text{log}}\left( {Score_{gd} } \right)) - \mathop \sum \limits_{{\left( {g,d} \right) \in {\Phi }^{ - } }} {\text{log}}( - Score_{gd} )$$\end{document}</tex-math><mml:math id="M142" display="block"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Pred</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mfenced><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow></mml:munder><mml:mtext>log</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi mathvariant="italic">gd</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>-</mml:mo></mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mfenced><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:munder><mml:mtext>log</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi mathvariant="italic">gd</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>
where <inline-formula id="IEq59"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\Phi }$$\end{document}</tex-math><mml:math id="M144"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq59.gif"/></alternatives></inline-formula> is the edge set exist in original network dataset, <inline-formula id="IEq60"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\Phi }^{ - }$$\end{document}</tex-math><mml:math id="M146"><mml:msup><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq60.gif"/></alternatives></inline-formula> is a set of gene and disease node pairs from negative sampling [<xref ref-type="bibr" rid="CR21">21</xref>] in original dataset, so that our model can enjoy optimization based on downstream tasks. we mentioned before, set up a loss function <inline-formula id="IEq61"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{Factor}$$\end{document}</tex-math><mml:math id="M148"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Factor</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq61.gif"/></alternatives></inline-formula> for graph factorization and as a result, we disposed by setting the weight <inline-formula id="IEq62"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M150"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="12859_2021_4099_Article_IEq62.gif"/></alternatives></inline-formula> to control the balance of the loss function from two parts, we have the final optimization goal as follows<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Loss = L_{Pred} + \gamma \cdot L_{Factor}$$\end{document}</tex-math><mml:math id="M152" display="block"><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Pred</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">Factor</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2021_4099_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>ROC</term>
        <def>
          <p id="Par4">Receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>AUC</term>
        <def>
          <p id="Par5">Area under the curve</p>
        </def>
      </def-item>
      <def-item>
        <term>P–R</term>
        <def>
          <p id="Par6">Precision–recall</p>
        </def>
      </def-item>
      <def-item>
        <term>AP</term>
        <def>
          <p id="Par7">Average precision</p>
        </def>
      </def-item>
      <def-item>
        <term>GNN</term>
        <def>
          <p id="Par8">Graph neual network</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors' contributions</title>
    <p>JL and MH designed the study, performed bioinformatics analysis and drafted the manuscript. All of the authors performed the analysis and participated in the revision of the manuscript. JL and YW conceived of the study, participated in its design and coordination and drafted the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the grants from the National Key Research Program (2017YFC1201201, 2018YFC0910504 and 2017YFC0907503), Shenzhen Science and Technology Program the university stable support program (2021) from JL.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>All the datasets are available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/xasdzxc/FactorHNE/tree/master/data">https://github.com/xasdzxc/FactorHNE/tree/master/data</ext-link>. All additional files are available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/xasdzxc/FactorHNE">https://github.com/xasdzxc/FactorHNE</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par46">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par47">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par48">The authors declare that there is no conflict of interest regarding the publication of this paper.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Denny</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Ritchie</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Basford</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Pulley</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Bastarache</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Brown-Gentry</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Masys</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Roden</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Crawford</surname>
            <given-names>DC</given-names>
          </name>
        </person-group>
        <article-title>PheWAS: demonstrating the feasibility of a phenome-wide scan to discover gene–disease associations</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>9</issue>
        <fpage>1205</fpage>
        <lpage>1210</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq126</pub-id>
        <pub-id pub-id-type="pmid">20335276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Özgür</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Vu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Erkan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Radev</surname>
            <given-names>DR</given-names>
          </name>
        </person-group>
        <article-title>Identifying gene-disease associations using centrality on a literature mined gene-interaction network</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <issue>13</issue>
        <fpage>i277</fpage>
        <lpage>i285</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn182</pub-id>
        <pub-id pub-id-type="pmid">18586725</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nikdelfaz</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Jalili</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Disease genes prediction by HMM based PU-learning using gene expression profiles</article-title>
        <source>J Biomed Inform</source>
        <year>2018</year>
        <volume>81</volume>
        <fpage>102</fpage>
        <lpage>111</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2018.03.006</pub-id>
        <pub-id pub-id-type="pmid">29571901</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vasighizaker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jalili</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>C-PUGP: A cluster-based positive unlabeled learning method for disease gene prediction and prioritization</article-title>
        <source>Comput Biol Chem</source>
        <year>2018</year>
        <volume>76</volume>
        <fpage>23</fpage>
        <lpage>31</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2018.05.022</pub-id>
        <pub-id pub-id-type="pmid">29890338</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yue</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Parthasarathy</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Moosavinasab</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Graph embedding on biomedical networks: methods, applications and evaluations</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>36</volume>
        <issue>4</issue>
        <fpage>1241</fpage>
        <lpage>1251</lpage>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Patra</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Genome-wide inferring gene–phenotype relationship by walking on the heterogeneous network</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>9</issue>
        <fpage>1219</fpage>
        <lpage>1224</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq108</pub-id>
        <pub-id pub-id-type="pmid">20215462</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Gulbahce</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Network-based methods for human disease gene prediction</article-title>
        <source>Brief Funct Genom</source>
        <year>2011</year>
        <volume>10</volume>
        <issue>5</issue>
        <fpage>280</fpage>
        <lpage>293</lpage>
        <pub-id pub-id-type="doi">10.1093/bfgp/elr024</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>HerGePred: heterogeneous network embedding representation for disease gene prediction</article-title>
        <source>IEEE J Biomed Health Inform</source>
        <year>2018</year>
        <volume>23</volume>
        <issue>4</issue>
        <fpage>1805</fpage>
        <lpage>1815</lpage>
        <pub-id pub-id-type="doi">10.1109/JBHI.2018.2870728</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Han P, Yang P, Zhao P, Shang S, Liu Y, Zhou J, Gao X, Kalnis P. GCN-MF: disease-gene association identification by graph convolutional networks and matrix factorization. In: Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery and data mining, Anchorage, AK, USA. Association for Computing Machinery. 2019. p. 705–13.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Grover A, Leskovec J. node2vec: scalable feature learning for networks. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, San Francisco, California, USA. Association for Computing Machinery. 2016. p. 855–64.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Perozzi B, Al-Rfou R, Skiena S. DeepWalk: online learning of social representations. In: Proceedings of the 20th ACM SIGKDD international conference on knowledge discovery and data mining, New York, New York, USA. Association for Computing Machinery. 2014. p. 701–10.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Tang J, Qu M, Wang M, Zhang M, Yan J, Mei Q. LINE: large-scale Information Network Embedding. In: Proceedings of the 24th international conference on world wide web, Florence, Italy. International World Wide Web Conferences Steering Committee. 2015. p. 1067–1077.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Dong Y, Chawla NV, Swami A. metapath2vec: scalable representation learning for heterogeneous networks. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining, Halifax, NS, Canada. Association for Computing Machinery. 2017. p. 135–144.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Wang X, Ji H, Shi C, Wang B, Ye Y, Cui P, Yu PS. Heterogeneous graph attention network. In: The world wide web conference, San Francisco, CA, USA. Association for Computing Machinery. 2019. p. 2022–32.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Veličković P, Cucurull G, Casanova A, Romero A, Lio P, Bengio Y. Graph attention networks. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/171010903">arXiv:171010903</ext-link> (2017).</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Qu Y, Bai T, Zhang W, Nie J, Tang J. An end-to-end neighborhood-based interaction model for knowledge-enhanced recommendation. In: Proceedings of the 1st international workshop on deep learning practice for high-dimensional sparse data, Anchorage, Alaska. Association for Computing Machinery. 2019: Article 8.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Yang Y, Feng Z, Song M, Wang X. Factorizable graph convolutional networks. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/201005421">arXiv:201005421</ext-link> (2020).</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Fu T-Y, Lee W-C, Lei Z. HIN2Vec: explore meta-paths in heterogeneous information networks for representation learning. In: Proceedings of the 2017 ACM on conference on information and knowledge management, Singapore, Singapore. Association for Computing Machinery. 2017. p. 1797–806.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>WX</given-names>
          </name>
          <name>
            <surname>Philip</surname>
            <given-names>SY</given-names>
          </name>
        </person-group>
        <article-title>Heterogeneous information network embedding for recommendation</article-title>
        <source>IEEE Trans Knowl Data Eng</source>
        <year>2018</year>
        <volume>31</volume>
        <issue>2</issue>
        <fpage>357</fpage>
        <lpage>370</lpage>
        <pub-id pub-id-type="doi">10.1109/TKDE.2018.2833443</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Fu X, Zhang J, Meng Z, King I. MAGNN: metapath aggregated graph neural network for heterogeneous graph embedding. In: Proceedings of the web conference 2020, Taipei, Taiwan. Association for Computing Machinery. 2020. p. 2331–2341.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Mikolov T, Sutskever I, Chen K, Corrado G, Dean J. Distributed representations of words and phrases and their compositionality. In: Proceedings of the 26th international conference on neural information processing systems, vol 2, Lake Tahoe, Nevada. Curran Associates Inc. 2013. p. 3111–9.</mixed-citation>
    </ref>
  </ref-list>
</back>
