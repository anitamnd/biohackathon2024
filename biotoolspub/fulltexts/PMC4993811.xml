<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5196</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4993811</article-id>
    <article-id pub-id-type="doi">10.3389/fninf.2016.00036</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Technology Report</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A Multi-facetted Visual Analytics Tool for Exploratory Analysis of Human Brain and Function Datasets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Angulo</surname>
          <given-names>Diego A.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/339832/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schneider</surname>
          <given-names>Cyril</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Oliver</surname>
          <given-names>James H.</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/368542/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Charpak</surname>
          <given-names>Nathalie</given-names>
        </name>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hernandez</surname>
          <given-names>Jose T.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/343621/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1">
      <sup>1</sup>
      <institution>IMAGINE, Systems and Computing Engineering, Universidad de los Andes</institution>
      <country>Bogota, Colombia</country>
    </aff>
    <aff id="aff2">
      <sup>2</sup>
      <institution>LCNS, CHUL</institution>
      <country>Quebec, QC, Canada</country>
    </aff>
    <aff id="aff3">
      <sup>3</sup>
      <institution>VRAC, Iowa State University</institution>
      <country>Ames, IA, USA</country>
    </aff>
    <aff id="aff4">
      <sup>4</sup>
      <institution>Kangaroo Foundation</institution>
      <country>Bogota, Colombia</country>
    </aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Arjen Van Ooyen, Vrije Universiteit Amsterdam, Netherlands</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Hidetoshi Ikeno, University of Hyogo, Japan; Xi-Nian Zuo, Chinese Academy of Sciences, China</p>
      </fn>
      <corresp id="fn001">*Correspondence: Diego A. Angulo <email xlink:type="simple">da.angulo39@uniandes.edu.co</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>23</day>
      <month>8</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2016</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>36</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>4</month>
        <year>2016</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>8</month>
        <year>2016</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2016 Angulo, Schneider, Oliver, Charpak and Hernandez.</copyright-statement>
      <copyright-year>2016</copyright-year>
      <copyright-holder>Angulo, Schneider, Oliver, Charpak and Hernandez</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Brain research typically requires large amounts of data from different sources, and often of different nature. The use of different software tools adapted to the nature of each data source can make research work cumbersome and time consuming. It follows that data is not often used to its fullest potential thus limiting exploratory analysis. This paper presents an ancillary software tool called BRAVIZ that integrates interactive visualization with real-time statistical analyses, facilitating access to multi-facetted neuroscience data and automating many cumbersome and error-prone tasks required to explore such data. Rather than relying on abstract numerical indicators, BRAVIZ emphasizes brain images as the main object of the analysis process of individuals or groups. BRAVIZ facilitates exploration of trends or relationships to gain an integrated view of the phenomena studied, thus motivating discovery of new hypotheses. A case study is presented that incorporates brain structure and function outcomes together with different types of clinical data.</p>
    </abstract>
    <kwd-group>
      <kwd>exploratory analysis</kwd>
      <kwd>visual analytics</kwd>
      <kwd>fMRI</kwd>
      <kwd>MRI</kwd>
      <kwd>tractography</kwd>
      <kwd>cohort studies</kwd>
      <kwd>python</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">Departamento Administrativo de Ciencia, Tecnología e Innovación<named-content content-type="fundref-id">10.13039/100007637</named-content></funding-source>
        <award-id rid="cn001">528</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="12"/>
      <table-count count="0"/>
      <equation-count count="0"/>
      <ref-count count="43"/>
      <page-count count="17"/>
      <word-count count="10797"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1. Motivation</title>
    <p>An important challenge in brain research, in both normal and pathological conditions, is to better understand the extent to which the physical structure of the brain influences its functioning. The most common research procedure is characterized by experiments aimed at collecting data directed toward testing a former hypothesis. This confirmatory-like methodology imposes limitations on the way data is used, and it is typically used only once which is unfortunate since data acquisition is generally time and resource intensive.</p>
    <p>In the last two decades brain research data has increasingly been gathered in a more open fashion and many databases are now available to the public (Milham, <xref rid="B25" ref-type="bibr">2012</xref>). In parallel, data collection, storage, and sharing, have been improved at both technical and policy levels, have advanced (Eckersley et al., <xref rid="B11" ref-type="bibr">2003</xref>), together with technologies used to consolidate, search and access the data (Van Horn and Toga, <xref rid="B36" ref-type="bibr">2009</xref>; Wood et al., <xref rid="B40" ref-type="bibr">2014</xref>). This allows massive amounts of data to be consolidated into databases and searched in efficient ways. In this way questions can be explored and large data pools can be mined for interesting relationships.</p>
    <p>The resting state functional magnetic resonance imaging (rfMRI) community is exemplary with large efforts such as the Consortium for Reliability and Reproducibility (CoRR) (Zuo and Xing, <xref rid="B43" ref-type="bibr">2014</xref>) and the Human Connectome Project (Marcus et al., <xref rid="B24" ref-type="bibr">2013</xref>; Hodge et al., <xref rid="B20" ref-type="bibr">2016</xref>), which allow researchers to share data and enables the exploration of integrated datasets containing data from thousands of subjects.</p>
    <p>This has led to rapid changes in the way research can be conducted, i.e., a shift from hypothesis-driven research into data-driven research, where data is available first and research questions and hypotheses are formulated on the basis of exploration of data. The methodology used in data-driven research differs significantly from that for hypothesis-driven research. Data-driven research seeks to find and extract meaningful insights from data using exploratory methods (Tukey, <xref rid="B35" ref-type="bibr">1980</xref>) and has already proven effective in economics, terrorism prevention, and business intelligence domains which are characterized by large and heterogeneous data sets (Cook and Thomas, <xref rid="B8" ref-type="bibr">2005</xref>). Exploratory research involves iterating through data several times, looking at it from different points of view, transforming data, searching for interesting subjects and measurements, gathering details and performing group analyses. These analysis tasks are carried out multiple times, and often in different order, as researchers learn more about the data. It is therefore helpful to provide tools to make annotations and save findings, so that explorations can be continued later as an integral part of the ongoing process of discovery.</p>
    <p>During this process several data patterns may likely lead to unexpected insights. Unfortunately, it is also likely that these patterns are caused by the unique noise structure of the current data and therefore cannot be generalized to the global population. Automatic data-mining algorithms can find thousands of possible relations, but true findings need to be backed up by science and current knowledge. Therefore, domain experts must be involved in interpretation of insights. Moreover, insights that integrate data from different domains require experts from all these domains.</p>
    <p>Visual analytics (Keim et al., <xref rid="B23" ref-type="bibr">2008</xref>) has emerged as a discipline that seeks to integrate statistics, machine learning, data mining and interactive data visualization with the objective of optimizing the use of data available for exploratory research. The analyst is acknowledged as the most important actor, and all tools are designed to support exploration and provide timely access to the required data as well as to informatics and statistics functions. Another principle in visual analytics is that analysts should focus on data and not on operational details of the tools. Therefore, tools should provide the data and functionality to complete the task, while keeping non-relevant details and complex functionality hidden.</p>
    <p>Exploratory brain research is a domain that could certainly benefit from visual analytics techniques. Indeed, brain function-related datasets are a combination of spatial (brain imaging) and non-spatial (clinical) measurements that could be analyzed together to better understand the link between brain structure and function as they relate to human health and behavior. Examples of spatial measurements include brain anatomy acquired by means of magnetic resonance imaging (MRI), neural pathways trajectory acquired by diffusion weighted imaging (DWI), patterns of cerebral activation in specific tasks and acquired by functional MRI (fMRI), or brain networks functionality and corticomotor function tested by transcranial magnetic stimulation (TMS) of motor and non-motor areas of brain. Specialized tools can process these neuroimaging modalities to model brain structure, build pathways, produce statistical maps of activation patterns, and neural connections. Brain researchers need to correlate these neurophysiological measurements and models to data of a different nature, such as neuropsychological performance, behaviors, and other clinical data.</p>
    <p>However, the tools currently used in brain research are generally specific to the type or domain of data analyzed and they are optimized to support linear work flows. It follows that experts must often switch between tools to integrate and analyze data from different domains. In the worst cases, they may even have to move to a different computer. This process is time-consuming and repetitive. It requires the analyst to focus attention on the “how” rather than the “what,” and thus makes exploratory analysis challenging.</p>
  </sec>
  <sec id="s2">
    <title>2. Introduction</title>
    <p>This paper introduces BRAVIZ, a software tool based on visual analytics and aimed at supporting exploratory analysis in brain research. More specifically, it focuses on datasets that include MRI derived measurements and models as well as TMS and clinical outcomes. BRAVIZ is comprised of several applications that integrate interactive visualizations, links to detailed meta-data, creation of new variables as well as statistical models and analyses, all of which are designed to support and facilitate full exploratory analyses. It is implemented on python and available under an open source license.</p>
  </sec>
  <sec id="s3">
    <title>3. Related work on neuroimaging and exploratory analysis</title>
    <p>Several data processing and visualization tools are available to support research on neuroimaging. For example, Freesurfer (Fischl, <xref rid="B13" ref-type="bibr">2012</xref>), FSL (Jenkinson et al., <xref rid="B22" ref-type="bibr">2012</xref>), and SPM (Friston et al., <xref rid="B15" ref-type="bibr">2006</xref>) segment, register and perform statistical testing of brain image data. 3D Slicer (Fedorov et al., <xref rid="B12" ref-type="bibr">2012</xref>), Brain Visa (Cointepas et al., <xref rid="B6" ref-type="bibr">2001</xref>), and ITKSnap (Yushkevich et al., <xref rid="B42" ref-type="bibr">2006</xref>) are commonly used to integrate data from different image modalities (structural, diffusion-weighted, functional among others). They have all proven to be efficient at processing bulk images in a pipeline, and visualizing data from a single subject, but they fall short when several iterations through the data are required. The interfaces proposed for statistical testing require extensive configuration, which is appropriate for testing specific hypotheses, but becomes cumbersome when several possibilities are to be explored. Efficient mechanisms for restricting analysis to only a subset of subjects (e.g., with common clinical or lesion characteristics) or going back to a subject's details are missing. Complementary data loaded from tables can be used, but changing variables often means creating new tables and making them fit the required format.</p>
    <p>Non-spatial information visualization tools like GGobi (Cook and Swayne, <xref rid="B7" ref-type="bibr">2007</xref>) and Tableau (Hanrahan, <xref rid="B17" ref-type="bibr">2003</xref>) can be used for interactive exploratory analysis. They support data transformations, model fitting, and interactive visualization. They also enable detection of outliers (important in data-driven research whereas usually unnecessary in hypothesis-driven research), provide additional details, determine subsets of subjects, and visualize patterns and trends in different ways (e.g., parallel coordinates, scatter plots, histograms, etc.). However, these tools do not integrate well with spatial data. Scalar data derived from original images can be added but there is no easy way to link back to the original data or to explore spatial features that cannot be encoded into numerical variables.</p>
    <p>Recently, there has been an increased interest in resting state fMRI (rfMRI) and the connectivity networks that are inferred from it (Biswal et al., <xref rid="B1" ref-type="bibr">2010</xref>; Rubinov and Sporns, <xref rid="B29" ref-type="bibr">2010</xref>). Analyzing this data requires the mixed use of spatial tools performing voxel wise and cluster analyzes with graph oriented tools and statistical analysis tools. The Connectome Computation System (CCS) (Xu et al., <xref rid="B41" ref-type="bibr">2015</xref>) integrates data pre-processing tools, with connectome generation and finally mining and visualization of automatic data. This kind of integrated environment allows researchers to efficiently explore data and pursue multiple hypotheses. BRAVIZ focuses on the last layer of this process but is focused on other neuro-image modalities.</p>
    <p>INVIZIAN (Bowman et al., <xref rid="B3" ref-type="bibr">2011</xref>, <xref rid="B4" ref-type="bibr">2012a</xref>,<xref rid="B5" ref-type="bibr">b</xref>) uses Ggobi options to explore, in an abstract 3D space, the relations between scalar values and anatomical features of large brain datasets. It provides an environment for exploratory research involving data from several databases for hypotheses generation. However, it works only with automatic feature extraction from structural MRI. Like BRAVIZ, INVIZIAN focuses on easing the users' visual pattern search, however BRAVIZ targets a broader range of spatial data, and focuses on data generated by users rather than on machine learning.</p>
    <p>A visual analysis tool for high dimensional genetic and clinical data is presented in Hinterberg et al. (<xref rid="B18" ref-type="bibr">2014</xref>). The user explores the data by quickly iterating through several models that relate genetic data to clinical outcomes. Models are displayed as trees and linked with distributions of the selected parameters. Tools are provided to automatically find the most relevant parameters to reduce the size of the search space. This tool is optimized for a single type of data, a single type of model, and a specific workflow. In contrast, BRAVIZ proposes to support multiple tasks, data types and workflows by providing a set of applications to be used independently or combined for complex exploratory analyses, as for example to interactively probe the multifaceted relationships between spatial and non spatial outcomes at the level of individuals, subsets of subjects or group of subjects.</p>
    <p>Even though multiple tools exist for analysis and exploration of spatial and non-spatial data, the integration of multiple kinds/levels of analyses and data in a single environment remains challenging. BRAVIZ provides a unique unified environment for analyzing spatial and non-spatial data interactively, and in this way, it supports data-driven research.</p>
  </sec>
  <sec id="s4">
    <title>4. BRAVIZ architecture</title>
    <p>Figure <xref ref-type="fig" rid="F1">1</xref> shows the BRAVIZ architecture which is based on the Model-View-Controller pattern, where the bottom layer (Project reader) together with the data repository constitute the model, the BRAVIZ Library (shaded region) makes up the controller, and each application represents a different view.</p>
    <fig id="F1" position="float">
      <label>Figure 1</label>
      <caption>
        <p><bold>The BRAVIZ software architecture, the main library is shaded</bold>.</p>
      </caption>
      <graphic xlink:href="fninf-10-00036-g0001"/>
    </fig>
    <p>Instead of a large monolithic application, BRAVIZ takes a distributed approach and thus is comprised of a set of applications tailored toward specific analysis tasks and data types. New BRAVIZ applications are implemented based on the common library, freeing developers from thinking about technical details related to data manipulation. All applications use the same model, which also provides a channel for data sharing. Users can create custom samples, new variables and custom geometric structures and store them in the database, where they can be read by any other BRAVIZ application. An additional communication mechanism is provided that enables applications to exchange data in real-time. In this way individual applications can be combined to solve more complex tasks. Section 4.2 will describe current applications.</p>
    <p>The library provides tools for loading spatial data (and transforming it into an appropriate coordinate system), for manipulating tabular data, for creating spatial and non-spatial interactive data visualizations, and for interacting with other applications and between different users. The types of spatial-data supported by the current implementation are: structural MRI, diffusion MRI, functional MRI, label maps, tractography reconstructions, structure segmentation models, and Freesurfer cortex reconstructions. Non-spatial data can be any numeric or categorical variable, including TMS, clinical, and socio-economic data. More details on the Braviz library will be given in Section 4.4.</p>
    <sec>
      <title>4.1. Design and development methodology</title>
      <p>A “user centered” approach (Wassink et al., <xref rid="B38" ref-type="bibr">2009</xref>) was taken to design and implement BRAVIZ. The authors worked closely with brain researchers of several specialties, visited several labs and hospitals, and learned as much as possible about research workflows and the bottlenecks they contain. Prototypes were implemented in several iterations and shared with different domain experts, whose feedback motivated the design of the next generation. The initial stages of design focused on identifying the obstacles that affect exploratory analysis and communication between experts, and examined ways of mitigating them. The team of experts was composed of radiologists, psychiatrists, physicians, neurophysiologists, physical therapists, pediatricians, statisticians, engineers, and economists.</p>
      <p>From analyzing the visualization options in current neuroimaging tools, as well as how domain experts used them, the BRAVIZ team learned what was expected from image viewers, i.e., which features were important to implement and which were seldom used. SPM (Friston et al., <xref rid="B15" ref-type="bibr">2006</xref>), Osirix (Rosset et al., <xref rid="B28" ref-type="bibr">2004</xref>), and 3D-Slicer (Fedorov et al., <xref rid="B12" ref-type="bibr">2012</xref>) were the reference at this stage. For example, researchers needed to visualize several types of data in the same space and to be able to compare brain images between two subjects. Also obvious was the need to integrate spatial visualizations with non-spatial data for the same subject in order to be able to understand relationships. Another common issue discovered in this exchange with expert users was that navigation from one subject to another typically requires re-starting the visualization application which is cumbersome.</p>
      <p>In addition, there was the need for performing statistical analysis in real time, working with different groups of subjects in the same space, creating and importing new data on the fly, performing group analyzes, identifying outliers, and detecting data quality issues.</p>
    </sec>
    <sec>
      <title>4.2. Applications set</title>
      <p>The current set of BRAVIZ applications can be divided in three categories. One set of applications measures or creates new descriptors from geometric data, one displays geometric data using other variables as context, and the third explores numerical and categorical data. This supports different stages of the exploratory analysis process, respectively, data transformation, visualization, and subjects-to-group analyses. These applications are accessible from the main menu (Figure <xref ref-type="fig" rid="F2">2</xref>) by clicking on the corresponding buttons. The bottom row provides access to utilities to manage samples, variables and scenarios, as well as importing and exporting data.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p><bold>BRAVIZ main menu, each button provides access to an application</bold>.</p>
        </caption>
        <graphic xlink:href="fninf-10-00036-g0002"/>
      </fig>
      <sec>
        <title>4.2.1. Descriptors for geometric data</title>
        <p>The <italic>Region of Interest (ROI) Builder</italic> application (Figure <xref ref-type="fig" rid="F3">3C</xref>) provides an interface for helping experts position a spherical ROI within the brain of each subject. These spheres are placed and sized with respect to images (from any modality) or cortex reconstructions. It is also possible to preview the fibers that cross the ROI, and to evaluate mean value inside the sphere of any scalar image, for example mean FA (fractional anisotropy associated to the integrity of myelin covering axons) or mean <italic>t</italic>-value associated with an fMRI test (representing to what degree a region is involved in a given task). Linear and non-linear registration maps can be used to approximate the position and size of the sphere in other subjects. The expected workflow is positioning the ROI in one subject, extrapolating it to a sample and making fine adjustments in position and size. The interface is optimized to support this (buttons, hotkeys, and visualization). Several ROIs can be used to select specific or more complex bundles. All data generated in the application (ROIs, bundles, and scalars) can be used on any other BRAVIZ application.</p>
        <fig id="F3" position="float">
          <label>Figure 3</label>
          <caption>
            <p><bold>Examples of BRAVIZ applications. (A)</bold> Check Registration, <bold>(B)</bold> Correlations, <bold>(C)</bold> ROI Builder, <bold>(D)</bold> FMRI Explorer.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0003"/>
        </fig>
        <p>In addition, the current BRAVIZ implementation includes an application for making linear measurements (lengths) of brain structures, and an application (<italic>Logic Bundles</italic>) for defining fiber bundles by combining ROIs and segmented structures through logical operations. For example, a bundle may be defines as the fibers that go through structure <italic>A</italic> or ROI <italic>B</italic> but that don't cross structure <italic>C</italic>.</p>
      </sec>
      <sec>
        <title>4.2.2. Geometric data visualization</title>
        <p>The <italic>Subject Overview</italic> application is shown in Figure <xref ref-type="fig" rid="F4">4</xref>. This tool provides access to several kinds of spatial data in a unique 3D renderer and eases the rapid navigation of the data from one subject to another. Geometrical features such as MRI volumes or mean fractional anisotropy of DWI in relation to a chosen structure can be captured directly from this application and added to the database as a new variable. The application also shows the values per subject of selected variables as well as users' annotations. This ensures an integrated overview of each case and follow-up between different users depending on the data available to BRAVIZ.</p>
        <fig id="F4" position="float">
          <label>Figure 4</label>
          <caption>
            <p><bold>Main interface of the subject overview application: at the bottom of the render some variables about the subject provide context</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0004"/>
        </fig>
        <p>A small multiples display (Tufte and Graves-Morris, <xref rid="B34" ref-type="bibr">1983</xref>) with views of several subjects is useful for finding trends across a sample or for quality control to detect contaminated images. Subjects are ordered from left to right according to a chosen numerical variable and each row corresponds to a nominal variable. In the example presented in Figure <xref ref-type="fig" rid="F5">5</xref> the three rows are children born at term, preterm in incubators (preterm controls) and preterms with Kangaroo Mother Care intervention (see case studies in Section 5) and subjects are sorted from left to right according to the score on an IQ test. The bar-plot at the right shows the distribution of this test amongst the three groups. This plot is linked with the 3D views, thus clicking on a bar will bring the corresponding subject into view. If more details of any subject are required, the user may right click on that subjects image to load the corresponding subject on other BRAVIZ applications.</p>
        <fig id="F5" position="float">
          <label>Figure 5</label>
          <caption>
            <p><bold>Quality control on the corpus callosum fibers from the whole sample</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0005"/>
        </fig>
        <p>The <italic>fMRI Explorer</italic> application from Figure <xref ref-type="fig" rid="F3">3D</xref> displays raw BOLD signals and contrast designs associated with fMRI experiments. It can also be used to compare signals at different locations or from different subjects. The <italic>Check Registration</italic> application (Figure <xref ref-type="fig" rid="F3">3A</xref>) allows the user to visualize simultaneously two images, from different modalities or different subjects and in a given coordinates system to assess the quality of registration.</p>
      </sec>
      <sec>
        <title>4.2.3. Numerical and categorical data exploration</title>
        <p>The <italic>ANOVA</italic> application (see Figure <xref ref-type="fig" rid="F6">6</xref>) provides access to statistical models implemented in <italic>R</italic> (Team, <xref rid="B33" ref-type="bibr">2012</xref>). In order to fit a model the user has to use the left side panel to select the outcome variable, the regressors and interaction terms and the sample. Variables are selected from the database, which additionally stores the type of each variable, its description and in the case of nominal variables the labels for each level. The variable selection dialog shows this meta-data for each variable and allows users to modify it. It also displays an overview plot of the variable which allows the user to infer the distribution of values. This plot can be configured to show the relationship between two variables (outcome vs. regressor) so that the user may do a preliminary visual assessment of relations between variables. Finally, the dialog provides mechanisms to search the database. When all parameters are set the user clicks the <italic>Calculate ANOVA</italic> button, the system will fetch the variable values for the selected sample from the database and fit the model using the <italic>CAR</italic> package of R.</p>
        <fig id="F6" position="float">
          <label>Figure 6</label>
          <caption>
            <p><bold>An application for performing ANOVA analyses using the data in the BRAVIZ database</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0006"/>
        </fig>
        <p>After fitting the model, the main plot will show diagnostics (distribution of residuals and a scatter plot of residuals vs. fitted values) for the validation of the ANOVA hypotheses (noise normally distributed and with constant variance) and the table at the bottom right shows the resulting statistics. The application can also show box-plots and scatter-plots that provide additional insights on the relation between regressors (nominal and numeric variables and interaction terms) and outcomes. Individual points in these plots can be identified by positioning the mouse over them. Additionally, by right clicking the mouse, the associated individual subject data can be loaded into other BRAVIZ applications to get supplemental information. This can be especially useful for instance to interpret outliers.</p>
        <p>Figure <xref ref-type="fig" rid="F7">7</xref> shows an alternative analysis application (<italic>Linear Model</italic>) which fits standard linear models and shows the effect of each regressor (numerical variables, dummy variables representing levels of nominal variables, and interaction terms). The application provides a similar interface and functions in the same way as the ANOVA application. The example from the figure shows a linear regression between the average length of fibers going through the mid-anterior section of the corpus callosum and the latency in Transcraneal Magnetic Stimulation test (see case studies in Section 5).</p>
        <fig id="F7" position="float">
          <label>Figure 7</label>
          <caption>
            <p><bold>(A)</bold> Scatter plot and linear fit between the Ccma fibers and interhemispheric transfer timer, <bold>(B)</bold> same plot after removing four outliers, <bold>(C)</bold> corpus callosum of the circled outlier of plot <bold>(A)</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0007"/>
        </fig>
        <p>The <italic>Correlations</italic> application shown in Figure <xref ref-type="fig" rid="F3">3B</xref> displays a list of variables, a correlation matrix of selected variables, and scatter plots of selected correlations. Points in the plot can be queried and right clicked. Additionally, they can be temporarily eliminated from the analysis to see the impact they have on the correlation that is currently tested.</p>
        <p>The <italic>Parallel Coordinates</italic> display from Figure <xref ref-type="fig" rid="F8">8</xref> provides another way of analyzing relations involving several variables. This functionality is exemplified in the second case study presented thereafter (see Section 5). Each vertical axis represents a variable, and each line is a subject. Users can interactively apply filters to each axis, in order to see how changes in one variable affect other values, and to understand relations involving several variables. In the figure, gray lines represent subjects excluded by the filters while color lines are those subjects that match the filters.</p>
        <fig id="F8" position="float">
          <label>Figure 8</label>
          <caption>
            <p><bold>Parallel coordinates display configured for searching possible PVL cases, lines that don't match the filters on each axis are shown in gray</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0008"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>4.3. Global features</title>
      <p>In addition to the unique features of each BRAVIZ application, the integrated platform provides features and combinations of tools (designed to be used together) in order to specifically favor the complex process of exploratory analyzes.</p>
      <sec>
        <title>4.3.1. Linking clinical outcomes and brain data</title>
        <p>Subjects in BRAVIZ are an integral part of the process, and therefore all types of data per subject is always accessible. For example, the <italic>Subject Overview</italic> application displays a set of clinical variables and annotations together with spatial data. It follows that users of BRAVIZ can make a context-dependent reading of images and of other spatial data. Such information would only be displayed elsewhere by other tools.</p>
        <p>Several scalar measurements can be derived from spatial data within the tool itself. For example a group of segmented structures can be selected and their combined volume added as a new variable. These values can afterwards be used together with clinical variables for statistical analysis, but a link is kept between the initial data and the environment in which it was generated. Continuing with this example, if the researcher finds an outlier, she/he can right click on it and from the context menu open the application in which the odd value was generated. The application will load with the configuration it had at that time, but focused on the subject of interest. In this way the extreme value can be analyzed to determine if it is caused by a particular artifact of the subject, such as a segmentation error, a problem with the image, or a sign of an actual pathology.</p>
      </sec>
      <sec>
        <title>4.3.2. Comparing subjects</title>
        <p>A common task in exploratory research is analyzing similarities and differences amongst a group of subjects. In most existing visualization tools for spatial data, users have to select the subject of interest at the onset of analysis, and then configure all the visualization options and load the necessary files. BRAVIZ takes a different approach, and always allows the subjects of interest to change in the middle of the analysis while maintaining the configuration of the application. In this way it is easy to look at different subjects from the same point of view, which makes comparing data very efficient.</p>
      </sec>
      <sec>
        <title>4.3.3. Working with samples</title>
        <p>Often some properties of the data apply only to a specific group/sample of subjects. In BRAVIZ samples are a central component of every analysis. Samples can indeed be defined by using filters on variable values, manually adding and removing specific subjects, taking random subsets, or combining samples through set operations (union, intersection, and difference). These samples can then be used for iterative analyses between different groups or can be modified (e.g., withdrawal of outiers), and the results of the modification visualized in real time. This contrasts with hypothesis-driven research where the sample must be set at the onset of analyses.</p>
      </sec>
      <sec>
        <title>4.3.4. Working with incomplete data</title>
        <p>It is not uncommon for some values or geometric data to be missing in some subjects. Applications that show geometric data detect missing data, hide the corresponding object from the scene, and display warning in the status bar. Group analysis tools display the number of missing points, and ignore them when performing calculations. Also, when building samples, the using filters the interface provides a checkbox that allows the user to include or exclude subjects with a missing value for the specific variable studied.</p>
      </sec>
      <sec>
        <title>4.3.5. Supporting long workflows</title>
        <p>Analyzing a complex dataset requires a significant amount of time, and will likely be split in multiple sessions. BRAVIZ applications allow saving analyzes and restoring them using custom names and descriptions, and attaching textual annotations to subjects, variables, and geometric objects (for example ROIs), and thus favors re-use of previous explorations. A log of each analysis session is kept, which can be reviewed and annotated using a web interface. These features allow other users to understand the meaning of variables, geometric structures and scenarios created by colleagues thereby favoring collaboration.</p>
      </sec>
      <sec>
        <title>4.3.6. Integrating tools</title>
        <p>In addition to the common database where all tools read and store variables and geometric objects, BRAVIZ includes a real-time communication mechanism. All applications can be coordinated to focus on the same subject (see Figure <xref ref-type="fig" rid="F9">9</xref>), to work with the same sample, or use the same set of variables. Applications may be running on different screens or even different devices; allowing users to get different perspectives of the data at the same time. Of note, BRAVIZ applications have the option to block specific parameters to keep the application from changing if the user prefers it. Also, for some actions that are likely to produce important changes, BRAVIZ asks the user for confirmation, and provide the option to always accept or always ignore the specific change.</p>
        <fig id="F9" position="float">
          <label>Figure 9</label>
          <caption>
            <p><bold>An example of BRAVIZ running on a large display in a collaborative setting</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0009"/>
        </fig>
        <p>Multiple users can work with the same data base thus can share data and thoughts. In this way one user may create a new measurement and make it available to other users. Real-time communication is implemented through TCP, therefore it would be possible to link together multiple workstations, but the research team has yet to explore whether this would provide a convenient user experience.</p>
      </sec>
    </sec>
    <sec>
      <title>4.4. The BRAVIZ library</title>
      <p>The Braviz library (shaded region of Figure <xref ref-type="fig" rid="F1">1</xref>) is divided in three modules that provide several common features to ease the development of applications. In addition, it abstracts access to data so that applications can be ported to different datasets. Of note, BRAVIZ library can also be used in python applications and scripts, including interactive work in a terminal or an iPython notebook.</p>
      <sec>
        <title>4.4.1. Read and filter</title>
        <p>The <italic>Read and Filter</italic> module is in charge of reading the configuration file and instantiating the appropriate project reader class. In addition, it holds several utility functions for converting image data between formats, applying affine transformations, filtering tractography, and deriving scalar measures from scalar data. This module also abstracts reading and writing data from the BRAVIZ database. Currently this database is implemented in <italic>SQLite</italic> (Hipp et al., <xref rid="B19" ref-type="bibr">2015</xref>) and it holds all non-spatial data, samples, scenarios, and other objects created by users.</p>
      </sec>
      <sec>
        <title>4.4.2. Visualization</title>
        <p>The Visualization module contains functions and widgets that can be used to create spatial and non-spatial visualizations. Spatial visualizations are implemented with VTK (Schroeder et al., <xref rid="B32" ref-type="bibr">1996</xref>), but several classes are available to streamline development. For example, <italic>managers</italic> are available for tractography, fMRI, and segmentation data. These are high-level classes that connect to the <italic>Read and Filter</italic> module, load the appropriate data, and manage the VTK visualization pipeline ending in a specified renderer. The user only needs to provide the current subject, current coordinate system, and visualization parameters. Of note, these classes expose methods as <italic>change_subject</italic> and <italic>change_coordinates</italic> which conveniently allows switching to a different subject or a different coordinate system.</p>
        <p>Non-spatial visualizations use Matplotlib (Hunter, <xref rid="B21" ref-type="bibr">2007</xref>) and Seaborn (Waskom et al., <xref rid="B37" ref-type="bibr">2014</xref>), or D3 (Bostock et al., <xref rid="B2" ref-type="bibr">2011</xref>) in case of web based applications. This module provides functions to create common visualizations by providing an input data-frame and other configuration parameters. All BRAVIZ visualizations exhibit consistent behavior, i.e., they allow the user to query the subject id of a data point by hovering over it, create a context menu by right clicking on a point, and allow for highlighting points on the display.</p>
      </sec>
      <sec>
        <title>4.4.3. Interaction</title>
        <p>The <italic>interaction</italic> module includes common QT widgets as well as utilities to create web based applications and to handle communications between applications. It also handles connection to external tools. For example, it contains functions that use the <italic>R</italic> system to perform statistical analysis.</p>
      </sec>
    </sec>
    <sec>
      <title>4.5. Importing data into BRAVIZ</title>
      <p>As mentioned above, making BRAVIZ generalizable to support different data-sets and data-formats was a primary design goal. In order to use BRAVIZ on an existing data-set, spatial data should be pre-processed using standard neuroimage tools. Instead of copying spatial data, BRAVIZ access it using specific <italic>ProjectReader</italic> classes. Finally several options are available to import non-spatial data.</p>
      <sec>
        <title>4.5.1. Pre-processing</title>
        <p>While BRAVIZ integrates some basic image processing algorithms, the focus remains on interactive visualization. In this end, data should be pre-processed using third party tools before starting a BRAVIZ project. As a minimum, BRAVIZ expects registration matrices linking the different coordinate systems present in images. Running the FreeSurfer <italic>recon_all</italic> pipeline will provide BRAVIZ segmentation, cortical parcellation and Talairach registration, which are basic for most visualizations.</p>
        <p>In addition, BRAVIZ can read SPM statistical maps and warp fields as well as tractography output (currently in VTK format), Tracula bundles and any type of scalar map, for example those derived from the tensor model.</p>
        <p>Pipeline systems such as LONI pipeline (Dinov et al., <xref rid="B10" ref-type="bibr">2009</xref>), NiPype (Gorgolewski et al., <xref rid="B16" ref-type="bibr">2011</xref>), or the CCS (Xu et al., <xref rid="B41" ref-type="bibr">2015</xref>) are ideally suited to automate these necessary pre-processing steps.</p>
      </sec>
      <sec>
        <title>4.5.2. Reading spatial data</title>
        <p>BRAVIZ accesses geometric data through the project reader interface (see Figure <xref ref-type="fig" rid="F1">1</xref>), which can have different implementations for different projects. All the upper layers, including applications, will access data through <italic>ProjectReader</italic> objects by specifying the type of data, the subject id, the coordinate space, and additional parameters appropriate for each data type (e.g., scalars for tractography or contrast for fMRI maps). This object is also responsible of returning indices of available data. Internally the class must be able to load the appropriate data, apply the correct transformations, and finally return the requested data as a python object.</p>
        <p>For example, in the case study presented below, all project's data was stored on hard disk, using NIFTI format for images, and VTK format for tractography and segmented structures. Files were stored in a layout such that the full path for each file can be determined based on subject id. Pre-calculated transformation matrices and warp fields were located and internally applied on load.</p>
        <p>New reader classes can be implemented to read data from different sources and different formats (e.g., reading DICOM objects from a PACS). The nibabel and vtk python libraries provide functions to load data stored in several formats, making the implementation of these classes feasible in a short amount of time.</p>
        <p>It is noteworthy that setting up BRAVIZ to work with a new dataset requires expertise from engineers. Recall that BRAVIZ is targeted at interdisciplinary teams and one of the goals is allowing the members of these teams to work together efficiently. Additional details of how BRAVIZ handles spatial and non-spatial data are described in the project's documentation.</p>
      </sec>
      <sec>
        <title>4.5.3. Importing non-spatial data</title>
        <p>By means of integrated tools clinical data can be imported into the system from excel tables or SPSS files using integrated tools. This data is copied into a database, and can be accessed from all applications. The python terminal or iPython notebooks (Prez and Granger, <xref rid="B26" ref-type="bibr">2007</xref>) can also be used to interactively read data from other sources (for example scraping web sites or by parsing DICOM headers), transform it into a pandas dataframe, and save it into the BRAVIZ database using a high level API.</p>
        <p>Of note, additional data can be added at any time and non-spatial data can also be exported to an spreadsheet using a graphical interfaces. It follows that the user is able to take some variables of interest out of BRAVIZ, perform calculation on an external tool, and import the results back into BRAVIZ.</p>
      </sec>
    </sec>
  </sec>
  <sec id="s5">
    <title>5. Case studies</title>
    <p>The functionality provided by BRAVIZ can be used both for untargeted, intuitive and adaptive discovery of relationships in order to improve understanding of data; as well as for structured dissection of data. In Section 5.1 an example of adaptive data exploration is presented. Section 5.2 illustrates pre-structured, targeted exploratory analysis to identify potential candidates for a sub-analysis of leukomalacia in a cohort of adolescents followed since birth.</p>
    <p>In these case studies, MRI, fMRI and diffusion data were acquired, anonymized, and stored in DICOM format, then pre-processed using dcm2nii (Rorden and Brett, <xref rid="B27" ref-type="bibr">2000</xref>), fsl (Jenkinson et al., <xref rid="B22" ref-type="bibr">2012</xref>), freesurfer (Fischl, <xref rid="B13" ref-type="bibr">2012</xref>), camino (Cook et al., <xref rid="B9" ref-type="bibr">2006</xref>), and spm (Friston et al., <xref rid="B15" ref-type="bibr">2006</xref>). A custom BRAVIZ project reader was implemented to read the output of this process. Clinical data was primarily consolidated in an SPSS database then imported in BRAVIZ. These tasks were performed by the engineering members of the group. Afterwards, researchers were free to explore and analyze data with BRAVIZ on their own computers. The first case study was carried out by a neurophysiologist, while the second one was completed by a pediatrician and a neuro-radiologist.</p>
    <sec>
      <title>5.1. Adaptive exploration of anatomical and functional data in prematurity</title>
      <p>The collection of the data used in the case studies was approved by the ethical committee from the school of medicine of Universidad Javeriana (Bogotá, Colombia) as well as the ethical committee of Fundación Santafé de Bogotá (Bogotá, Colombia), all participants and their parents provided written informed consent. This section describes an adaptive inference process in which insights inspire subsequent exploratory steps, and, more specifically, highlights the flexibility that BRAVIZ affords.</p>
      <sec>
        <title>5.1.1. Rationale and initial hypotheses</title>
        <p>Data comes from the seminal demonstration (Schneider et al., <xref rid="B30" ref-type="bibr">2012</xref>) of the influence of a very premature birth (&lt;33 weeks of gestational age) on brain function in a sample of 15-year old adolescents who were compared to their term peers. This study also showed the positive impact of an early care protocol (Kangaroo Mother Care) on brain functions, but this is beyond the present topic. The authors used the noninvasive and painless TMS of the primary motor cortex (referred to as the motor brain) and showed that the control of hand by brain was suboptimal in the preterm group. Especially, the excitability of the motor brain was lower and the time required for the transfer of nervous signal from one cerebral hemisphere to the other (interhemispheric transfer) was longer. These abnormalities were related to the deleterious after-effects of a premature birth that could still be detected 15 years later in brain (Schneider et al., <xref rid="B30" ref-type="bibr">2012</xref>). Indeed, the interruption of the <italic>in utero</italic> maturation of the corpus callosum, a structure comprised of large-diametered fast-conducting myelinated fibers and connecting the two cerebral hemispheres, interfered with the normal installation of circuits in each hemisphere and of the functional lateralization between hemispheres, thus altering the sensorimotor and cognitive brain function (Schneider et al., <xref rid="B31" ref-type="bibr">2008</xref>; Flamand et al., <xref rid="B14" ref-type="bibr">2012</xref>; Schneider et al., <xref rid="B30" ref-type="bibr">2012</xref>).</p>
        <p>However, the study had not yet established any link between MRI-DTI measurements of the corpus callosum thinning and the lower clinical performances in the preterm group as compared to the peers term. Two reasons can explain this limitation: the difficulty to statistically analyze, visualize, explore, and understand the link between outcomes of different nature (severely time-consuming with the use of different softwares and data transformations likely providing biases or mistakes); the required involvement of experts dedicated to the interpretation of each outcome.</p>
        <p>The working hypothesis was that BRAVIZs user-centered approach and applications/modules with real-time statistical analyses (color coding for instantaneous detection of a correlation for example), and access to multifacetted neuroscience and clinical data (spatial and non-spatial interactive data visualizations with common operations available between applications) should favor multi-tasking along with adaptation to user's expertise leading to easy detection of outliers and emergence of unsuspected relationships between target variables.</p>
      </sec>
      <sec>
        <title>5.1.2. Contribution of BRAVIZ to scientific discovery (ancillary hypotheses)</title>
        <p>All data had been already imported in BRAVIZ by the engineer before onset of work and this substantially fastened the access to spatial and non-spatial data. BRAVIZ was used to explore the potential links between clinical outcomes and lower excitability of the motor brain, interhemispheric dysfunction, and volume/numbers of fibers of the corpus callosum. The applications were used following the non-linear procedure that BRAVIZ uniquely supports. ANOVA results with scatter plots, standard deviations and superimposition of individual values helped immediately detect four outliers in the 15-year preterm adolescents sample. This should have taken far more time with other applications not processed by BRAVIZ in real time and in parallel. The <italic>Correlation Viewer</italic> allowed to remove these outliers with a simple click and to see instantaneously that they affected ANOVA results, which would not have been possible to detect if all applications had not be launched in the same workspace. Thus, the combination of <italic>ANOVA, Correlation Viewer</italic>, and <italic>Parallel Coordinates</italic> (MRI for structure volume, DTI for fibers) showed that, without the outliers (studied below), the medial-anterior part of the corpus callosum (maCC connecting the motor areas between hemispheres) was smaller in volume in the preterm group (17, 228 ± 5100 mm<sup>3</sup>) than in the term (22, 352 ± 3900 mm<sup>3</sup>; <italic>p</italic> = 0.02) and exhibited fewer callosal fibers (1806 ± 573) than in the term (2600 ± 570; <italic>p</italic> = 0.008). Despite this thinning of corpus callosum, no link was detected with the interhemispheric time of transfer between motor areas that was shown to be significantly longer in the preterm group (Schneider et al., <xref rid="B30" ref-type="bibr">2012</xref>). However, the correlation matrix and scatter plots brought to attention that, by excluding the four outliers, a strongly red-colored (significant) link appeared between the increasing interhemispheric transfer time and the longer length of the maCC fibers: Figure <xref ref-type="fig" rid="F7">7B</xref> shows this strong correlation for the preterm group (orange circles) when the outliers are removed (as a contrast to Figure <xref ref-type="fig" rid="F7">7A</xref>), the longer the maCC fibers and the longer the interhemispheric transfer time. This correlation was absent in the term group (green circles).</p>
        <p>The real time access to clinical characteristics by right clicking the dots in BRAVIZs scatter plots eased to understand that outliers in Figure <xref ref-type="fig" rid="F7">7B</xref> were participants with either cerebral palsy or Xfragile pathology. The parallel access DTI data and scatter plots in the same workspace favored the immediate detection that the circled outlier in Figure <xref ref-type="fig" rid="F7">7A</xref> was a participant with a dramatic thinning of the maCC (Figure <xref ref-type="fig" rid="F7">7C</xref>). This explains that, as compared to other participants with shorter length of maCC fibers, the interhemispheric transfer time was longer (holes in corpus callosum likely leading to temporal dispersion of current between hemispheres). We already knew that the preterm group had longer interhemispheric transfer time (Schneider et al., <xref rid="B30" ref-type="bibr">2012</xref>) but BRAVIZ guided the analysis to rapidly visualize and test that this was related to the length of fibers in the preterm group, even if length was not different than in the term group. This contributes to raise the very new hypothesis that the underlying problem in our preterm sample may not not be the structural defect (excluding the outliers) but more likely the synaptic arrangement of connections between hemispheres, those with longer interhemispheric transfer time presenting with less efficient transcallosal networks.</p>
        <p>Precisely, not all participants in the preterm group presented with lengthened interhemipsheric transfer time but five of them were over 20 ms when 8 and 14 ms are usually expected for men and women, respectively (Schneider et al., <xref rid="B30" ref-type="bibr">2012</xref>). BRAVIZs parallel coordinates of the different variables was useful once again to efficiently identify that four out of these five participants over 20 ms had a transient score at the infant neurological international battery (Infanib) at 6 months of age. This intuitively led to launch BRAVIZs <italic>Correlation Viewer</italic> and to highlight a strong link between Infanib at 6 months of age and our neurophysiological measures known as different in the preterm group (Schneider et al., <xref rid="B30" ref-type="bibr">2012</xref>) such as the lower excitability of the motor brain and higher occurrence of ipsilateral muscle responses to TMS of the motor brain (which is abnormal given the typical crossed organization of motor systems for hand function). In that vein, BRAVIZs applications contributed to highlight that the four participants above 20 ms thus who significantly drove the correlation in Figure <xref ref-type="fig" rid="F7">7A</xref> had a dysfunctional organization of the motor brain. One another ancillary hypothesis could be that Infanib testing at 6 months of age may be predictive of long-term impairment of the motor brain function, including a poor efficiency of the interhemispheric connections (time over 20 ms at 15 years of age, see Figure <xref ref-type="fig" rid="F7">7A</xref>).</p>
        <p>Merging the neurophysiological expertise with the potential of BRAVIZ for data-driven analysis led to one last interesting new finding in this case study. This concerns the visuomotor control of movement which involved the corpus callosum function (Schneider et al., <xref rid="B31" ref-type="bibr">2008</xref>) and which is assessed by the standardized score of the visuomotor integration test (VMI StS). This score was found to be significantly lower in the preterm group (95.5 ± 7) than in the term (108.5 ± 3.5; <italic>p</italic> = 0.0001) at 15 years of age. The <italic>Correlation Viewer</italic> (color codes highlighting the significant links and excluding the outliers determined above) used together with the parallel coordinates application (see all studied variables in real time in the same workspace) detected that the lower (lesser) VMI StS scores of the preterm group could be explained by a lower excitability of the motor brain (higher motor threshold, i.e., higher intensity of TMS to generate a response in the muscle, RMTd in Figure <xref ref-type="fig" rid="F10">10</xref>, the excluded outliers are represented by empty circles) and higher occurence of abnormal ipsilateral responses (Ipsifreqnd in Figure <xref ref-type="fig" rid="F11">11</xref>). By extension, BRAVIZ afforded applications and context to detect that the impairement of visuomotor control of movement in our sample of 15-year adolescents born prematurely was related to dysfunction of the motor brain and pathways, in terms of maladaptive synaptic organization (rather than anatomical issues), and that could have been predicted by the transient Infanib at 6 months of age. Overall, these new hypotheses driven by BRAVIZ in our sample of preterm adolescent may impact early rehabilitation when synaptic issues are more sensitive than anatomical to training-induced mechanisms of adaptation and motor learning.</p>
        <fig id="F10" position="float">
          <label>Figure 10</label>
          <caption>
            <p><bold>VMI vs. M1 excitability excluding outliers (empty circles)</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0010"/>
        </fig>
        <fig id="F11" position="float">
          <label>Figure 11</label>
          <caption>
            <p><bold>VMI vs. ipsilateral corticospinal responses excluding outliers (empty circles)</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-10-00036-g0011"/>
        </fig>
      </sec>
      <sec>
        <title>5.1.3. Conclusions</title>
        <p>BRAVIZ adapted and intuitively guided the exploratory analysis of these multi-kind and multifacetted outcomes. With different experts gathered (i.e., neonatologist, neurophysiologist, psychologist, physical therapist) this new tool helped unmask important relationships between variables of brain function and uncover new hypotheses in prematurity that go beyond previous works in preterm children (Schneider et al., <xref rid="B31" ref-type="bibr">2008</xref>, <xref rid="B30" ref-type="bibr">2012</xref>; Flamand et al., <xref rid="B14" ref-type="bibr">2012</xref>). BRAVIZ-related analysis of experimental data in prematurity pointed out for the first time that the long-term impairments (clinical data) in prematurity may not be the smaller volume of some structures but the lesser efficacy of synapses between neurons and of networks between structures (such as the corpus callosum between hemispheres). On that vein, a specific focus, in terms of quality and intensity of intervention for synaptic efficiency, should be made on those individuals presenting characteristics that BRAVIZ unique exploratory analysis has identified at risk for the integrity of brain function.</p>
      </sec>
    </sec>
    <sec>
      <title>5.2. Pre-structured, targeted search, and characterization of leukomalacia patients</title>
      <p>Periventricular Leukomalacia (PVL) is characterized by a lesion in the periventricular germinal matrix which results in a loss of white matter ventricular dilation. Preterm babies, especially those born prior to 33 weeks of gestation (due to non-invagination yet of highly vascularized germinal matrix) present with a significant risk of suffering from this condition and from its long-term physiological consequences, including motor and vision impairments, cerebral palsy and epilepsy.</p>
      <p>Of note, the imaging protocol of the study did not include FLAIR images which are most appropriate for PVL detection. BRAVIZ and its applications thus offered the alternative to identify in the database for subjects who might possibly suffer this PVL condition. Such exploration targeted a better understanding of the samples health issues rather than directly testing a scientific hypothesis. However, incidental results may result from BRAVIZs data-driven analysis.</p>
      <p>A parallel coordinates display was used to visualize the ventricles volume and the total white matter (myelinated fibers comprising brain networks). Figure <xref ref-type="fig" rid="F8">8</xref> shows for example that the dataset included motor and visual testing, intelligence assessment, a classical neurological evaluation to discriminate between normal and abnormal neurological status and some risk factors, such as weight and gestational age (Ballard) at birth. Data could be filtered by axis dragging in order to keep only subjects with high ventricular volume and low white matter volume (shown in color at the figure, while excluded are shown in gray), i.e., with characteristics related to PVL condition. Lines (one line per participant) with decreasing slope from first segment (ventricules volume) to second segment (white matter) may reflect ventricular dilation (first segment) as a result of the loss of white matter, in relation to neurological status (abnormal in red and normal in blue).</p>
      <p>The line highlighted in Figure <xref ref-type="fig" rid="F8">8</xref> showed ventricules dilatation, low white matter volume, low scores for motor and visual components of visuomotor integration testing (VMI) and low birthweight (pesnacer). The context menu that appeared by right clicking on the line enabled to switch to the individual's brain facts, images and statistics in other BRAVIZ applications and to get additional details for better understanding the whole clinical profile of such an abnormal condition at 15 years of age. For example, the Subject Overview application denoted that the participant was born by C-Section in emergency after a twin pregnancy; the mother had HELPP syndrome (malignant hypertension) and died after giving birth; the abnormal status during the first year of life transformed in a diagnosis of cerebral palsy at the end of the first year (spastic diplegia and right arm hemiparesis). Altogether, the clinical profile and the symptoms together with the T1 image of ventricles dilatation (Figure <xref ref-type="fig" rid="F12">12</xref>) could be associated with PVL.</p>
      <fig id="F12" position="float">
        <label>Figure 12</label>
        <caption>
          <p><bold>Details of a subject with possible PVL, the left panel shows values for several variables as well as the full clinical history</bold>.</p>
        </caption>
        <graphic xlink:href="fninf-10-00036-g0012"/>
      </fig>
      <p>The 15-year subject data associated with the top line in Figure <xref ref-type="fig" rid="F8">8</xref> (highest ventricles volume) showed in Subject Overview a very premature birth at 31 weeks of gestational age and given by C-section in emergency because of profuse bleeding (placenta previae), signs of leucoencephalopathy and an increased volume of the left lateral ventricle in CT scan, epilepsy not yet controlled, severe bilateral hearing loss, and abnormal bilateral vision, but a normal psychomotor development. BRAVIZs coordinated applications looking at indicator variables then at candidates' detailed profiles detected two cases with possible existence of PVL out of our sample of participants, although the original data had not been collected with the view of evaluating such white matter disorders. This witnessed the usefulness of the <italic>Subject Overview</italic> application to provide sufficient information to better understand each case and its life trajectory (variables, annotations) with no need to gather additional files.</p>
    </sec>
  </sec>
  <sec id="s6">
    <title>6. Discussion</title>
    <p>The cases studies illustrate how BRAVIZ can be used to improve understanding of a real data-set. A direct access to data makes researchers more efficient in the exploratory analysis and the recovery of data relevant to their questions. By combining several tools, users can perform group level analyses without loosing track of individual subjects, while getting additional details on a participant via a simple click. Sharing samples, variables, visualizations, and subjects of interest also provides an efficient channel for experts to communicate and share ideas, thoughts, advice, and opinions with each other.</p>
    <p>Direct access to data helps save time and more interestingly, enables researchers to efficiently pursue and address in real time all questions coming to mind. If testing an idea, hypothesis of relationships or finding an answer requires a cumbersome procedure and gathering data from several sources, it will likely not be explored. This exploration would take non intuitive manipulation of different softwares and far more time with elevated risks of biases and mistakes in data transformation, etc. With BRAVIZ, the number of questions that can be addressed are increasing and so are the chances of finding incidental but interesting results.</p>
    <p>Combining clinical and spatial data with the unstructured clinical history allows researchers to reconstruct a full picture of each subject. This is valuable for making accurate interpretations of results, for understanding deeper and more accurately the dataset and its outliers. Participants in BRAVIZ are always linked to all their associated data, therefore they are always analyzed with respect to their whole portrait. Subjects with specific conditions can be analyzed in isolation, or attempts can be made to generalize the properties of a peculiar subject. Back and forth analysis of the data are supported by BRAVIZ with iterations to isolate a case or to generalize to the group. In fact, samples of participants or data in BRAVIZ are recognized as an essential component of the analysis. They can be created in several ways, saved into the database for future use or used instantaneously in statistical models or group data visualizations. Researchers can thus iterate through several samples, several models, several measurements, and several views, thus gaining understanding of the data-set and raising questions and hypotheses for future projects.</p>
    <p>A log of each analysis session is automatically kept and made available through a web interface with all actions performed with the different applications used. Researchers can enhance this log by labeling the most important steps they made during a session and providing annotations. The status of an application can be reloaded at any point with a simple click of a button so that researchers are able to revisit visualization and explore different analysis paths, thus making possible to build on top of what was found with previous sessions.</p>
    <p>In contrast to current tools, BRAVIZ enables the visualization of data from different participants and the between-participant comparisons with most associated technical issues hidden to the user. The traditional separation of workspace, with one window for medical image viewer, and a second for a spreadsheet of clinical data, the researchers manually (and repeatedly) search for correlations between both kinds of data. BRAVIZ fixed this issue of storage of individual files to manage in different softwares (access, format, and transform data are automated and hidden actions) and harnesses and proceeds data in the same workspace. It follows that users focus on the task at hand, and not on technical details.</p>
  </sec>
  <sec id="s7">
    <title>7. Conclusions and future work</title>
    <p>BRAVIZ is a tool that facilitates interactive data visualization and exploratory analysis of datasets that combine clinical and neuro-image data. It is implemented as a set of applications that can be used at different points of exploratory analysis, possibly by different members of an interdisciplinary research team. Some applications are designed to extract scalar measurements from image data, others provide detailed views of particular subjects or data types and others perform group analyses. Custom samples of subjects can be defined and used across all applications to focus on the analysis. When several applications are running together, all of them can keep focus on the same subject (Figure <xref ref-type="fig" rid="F9">9</xref>) which supports and guide the users in their understanding of how the multi-dimensional views of the same individual's data interact together.</p>
    <p>The architecture also streamlines implementation of additional applications by encapsulating all low level data manipulation in a library. For example, BRAVIZ could easily be extended to support group based analysis like second level fMRI or VBM (Voxel Based Morphometry). In addition, several researchers have expressed interest in integrating other kinds of data, for example EEG signals or connectome graphs derived from DWI or fMRI. BRAVIZ is distributed under a LGPL license and the source code is available through the project web page <ext-link ext-link-type="uri" xlink:href="http://diego0020.github.io/braviz">http://diego0020.github.io/braviz</ext-link>. Additional testing with various datasets and by researchers of multiple backgrounds is required. Any assistance will be provided to anyone interested in setting up the environment and using it.</p>
    <p>Braviz has been tested on a larger project from the Kangaroo Foundation which includes about 450 participants, complex event related fMRI paradigms, larger numbers of clinical variables, and more anatomical imaging modalities. A common concern is whether this approach will work with larger datasets, with thousands or even millions of participants. Data visualization can surprise us, but generally does not scale well; while data modeling typically does scale but cannot surprise us (Wickham and Grolemund, <xref rid="B39" ref-type="bibr">2016</xref>). Therefore, one must iterate between visualization and modeling. One approach is to start exploring with a smaller subsample, and when an interesting trend is found, to try to see if generalization works for the full sample. Likewise, visualizations on a smaller subsample can be used to further understand and explore results obtained elsewhere. To this end, BRAVIZ provides the subsample mechanism.</p>
    <p>Currently there is a trend toward moving data storage and processing to dedicated servers and providing access to users via web browsers. This allows researchers to work from any place, or even start a session in one place and finish somewhere else. Logs, variables, samples, and other analysis artifacts could be kept in a centralized location to ease data downloading from a single place. In addition, if multiple experts used the same back-end, sharing would become trivial. The back-end could be implemented via a set of dedicated servers, or it could run in a scalable cloud. Powerful data processing algorithms could also be provided to leverage high performance computing infrastructure. BRAVIZ ought to be accessible through a web interface in the future, given the potential generalization of its applicability.</p>
    <p>The evergrowing interest in collecting data openly and making it available to the general community makes visual exploratory analysis tools like BRAVIZ become increasingly important. BRAVIZ has the ability to rapidly iterate and improve thus its future versions could contribute to increase the scientific productivity, optimally use the collected data, integrate the analysis between different variables and different users, and eventually speed-up knowledge transfer. The case studies suggested that BRAVIZ could represent a clinically relevant tool to understand brain function but also in the future to assess and help in decision making for care and therapy over lifespan.</p>
  </sec>
  <sec id="s8">
    <title>Author contributions</title>
    <p>DA designed and implemented the BRAVIZ software, under the supervision of JH and JO. All three drafted the technical portions of the manuscript. CS and NC contribute with final user point of view (pediatrician and neurophysiological) along the design and prototyping process, they conduct and wrote cases studies. All authors revised and contributed to the final version of this manuscript.</p>
  </sec>
  <sec id="s9">
    <title>Funding</title>
    <p>This work was developed as part of a PhD funded by the Departamento Administrativo de Ciencia, Tecnología e Innovación, Colombia (Colciencias), Grant number 528, national PhDs.</p>
    <sec>
      <title>Conflict of interest statement</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <p>This work was made possible by the Kangaroo Foundation, that generously provided a rich dataset, and whose experts were always willing to test prototypes and provide valuable feedback. The project also received important support from Colciencias, Universidad de los Andes, Iowa State University and Universit Laval-CHU of Qubec.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biswal</surname><given-names>B. B.</given-names></name><name><surname>Mennes</surname><given-names>M.</given-names></name><name><surname>Zuo</surname><given-names>X.-N.</given-names></name><name><surname>Gohel</surname><given-names>S.</given-names></name><name><surname>Kelly</surname><given-names>C.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Toward discovery science of human brain function</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>107</volume>, <fpage>4734</fpage>–<lpage>4739</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0911855107</pub-id><?supplied-pmid 20176931?><pub-id pub-id-type="pmid">20176931</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bostock</surname><given-names>M.</given-names></name><name><surname>Ogievetsky</surname><given-names>V.</given-names></name><name><surname>Heer</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>D3 data-driven documents</article-title>. <source>IEEE Trans. Vis. Comput. Graph.</source>
<volume>17</volume>, <fpage>2301</fpage>–<lpage>2309</lpage>. <pub-id pub-id-type="doi">10.1109/TVCG.2011.185</pub-id><?supplied-pmid 22034350?><pub-id pub-id-type="pmid">22034350</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>I.</given-names></name><name><surname>Joshi</surname><given-names>S.</given-names></name><name><surname>Van Horn</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>Query-based coordinated multiple views with feature similarity space for visual analysis of MRI repositories</article-title>, in <source>2011 IEEE Conference on Visual Analytics Science and Technology (VAST)</source> (<publisher-loc>Providence, RI</publisher-loc>), <fpage>267</fpage>–<lpage>268</lpage>.</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>I.</given-names></name><name><surname>Joshi</surname><given-names>S. H.</given-names></name><name><surname>Greer</surname><given-names>V.</given-names></name><name><surname>Darrell Van Horn</surname><given-names>J.</given-names></name></person-group> (<year>2012a</year>). <article-title>Feature-similarity visualization of MRI cortical surface data</article-title>, in <source>IEEE Conference on Visual Analytics Science and Technology (VAST)</source> (<publisher-loc>Seattle, WA</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>211</fpage>–<lpage>212</lpage>.</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>I.</given-names></name><name><surname>Joshi</surname><given-names>S. H.</given-names></name><name><surname>Van Horn</surname><given-names>J. D.</given-names></name></person-group> (<year>2012b</year>). <article-title>Visual systems for interactive exploration and mining of large-scale neuroimaging data archives</article-title>. <source>Front. Neuroinform.</source>
<volume>6</volume>:<issue>11</issue>. <pub-id pub-id-type="doi">10.3389/fninf.2012.00011</pub-id><?supplied-pmid 22536181?><pub-id pub-id-type="pmid">22536181</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cointepas</surname><given-names>Y.</given-names></name><name><surname>Mangin</surname><given-names>J.-F.</given-names></name><name><surname>Garnero</surname><given-names>L.</given-names></name><name><surname>Poline</surname><given-names>J.-B.</given-names></name><name><surname>Benali</surname><given-names>H.</given-names></name></person-group> (<year>2001</year>). <article-title>BrainVISA: software platform for visualization and analysis of multi-modality brain data</article-title>. <source>Neuroimage</source>
<volume>13</volume>:<fpage>98</fpage>
<pub-id pub-id-type="doi">10.1016/S1053-8119(01)91441-7</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>D.</given-names></name><name><surname>Swayne</surname><given-names>D. F.</given-names></name></person-group> (<year>2007</year>). <source>Interactive and Dynamic Graphics for Data Analysis: with R and GGobi</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>K. A.</given-names></name><name><surname>Thomas</surname><given-names>J. J.</given-names></name></person-group> (<year>2005</year>). <source>Illuminating the Path: The Research and Development Agenda for Visual Analytics</source>. <publisher-name>Technical Report, Pacific Northwest National Laboratory (PNNL)</publisher-name>, <publisher-loc>Richland, WA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>P. A.</given-names></name><name><surname>Bai</surname><given-names>Y.</given-names></name><name><surname>Nedjati-Gilani</surname><given-names>S.</given-names></name><name><surname>Seunarine</surname><given-names>K. K.</given-names></name><name><surname>Hall</surname><given-names>M. G.</given-names></name><name><surname>Parker</surname><given-names>G. J.</given-names></name><etal/></person-group> (<year>2006</year>). <article-title>Camino: open-source diffusion-MRI reconstruction and processing</article-title>, in <source>14th Scientific Meeting of the International Society for Magnetic Resonance in Medicine</source>, <volume>Vol. 2759</volume> (<publisher-loc>Seattle, WA</publisher-loc>).</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dinov</surname><given-names>I. D.</given-names></name><name><surname>Van Horn</surname><given-names>J. D.</given-names></name><name><surname>Lozev</surname><given-names>K. M.</given-names></name><name><surname>Magsipoc</surname><given-names>R.</given-names></name><name><surname>Petrosyan</surname><given-names>P.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><etal/></person-group>. (<year>2009</year>). <article-title>Efficient, distributed and interactive neuroimaging data analysis using the LONI pipeline</article-title>. <source>Front. Neuroinform.</source><volume>3</volume>:<fpage>22</fpage>. <pub-id pub-id-type="doi">10.3389/neuro.11.022.2009</pub-id><?supplied-pmid 19649168?><pub-id pub-id-type="pmid">19649168</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckersley</surname><given-names>P.</given-names></name><name><surname>Egan</surname><given-names>G. F.</given-names></name><name><surname>De Schutter</surname><given-names>E.</given-names></name><name><surname>Yiyuan</surname><given-names>T.</given-names></name><name><surname>Novak</surname><given-names>M.</given-names></name><name><surname>Sebesta</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2003</year>). <article-title>Neuroscience data and tool sharing</article-title>. <source>Neuroinformatics</source><volume>1</volume>, <fpage>149</fpage>–<lpage>165</lpage>. <pub-id pub-id-type="doi">10.1007/s12021-003-0002-1</pub-id><?supplied-pmid 15046238?><pub-id pub-id-type="pmid">15046238</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorov</surname><given-names>A.</given-names></name><name><surname>Beichel</surname><given-names>R.</given-names></name><name><surname>Kalpathy-Cramer</surname><given-names>J.</given-names></name><name><surname>Finet</surname><given-names>J.</given-names></name><name><surname>Fillion-Robin</surname><given-names>J.-C.</given-names></name><name><surname>Pujol</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>3d Slicer as an image computing platform for the quantitative imaging network</article-title>. <source>Magnet. Reson. Imaging</source><volume>30</volume>, <fpage>1323</fpage>–<lpage>1341</lpage>. <pub-id pub-id-type="doi">10.1016/j.mri.2012.05.001</pub-id><?supplied-pmid 22770690?><pub-id pub-id-type="pmid">22770690</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group> (<year>2012</year>). <article-title>FreeSurfer</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>774</fpage>–<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id><?supplied-pmid 22248573?><pub-id pub-id-type="pmid">22248573</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flamand</surname><given-names>V. H.</given-names></name><name><surname>Nadeau</surname><given-names>L.</given-names></name><name><surname>Schneider</surname><given-names>C.</given-names></name></person-group> (<year>2012</year>). <article-title>Brain motor excitability and visuomotor coordination in 8-year-old children born very preterm</article-title>. <source>Clin. Neurophysiol.</source>
<volume>123</volume>, <fpage>1191</fpage>–<lpage>1199</lpage>. <pub-id pub-id-type="doi">10.1016/j.clinph.2011.09.017</pub-id><?supplied-pmid 22018705?><pub-id pub-id-type="pmid">22018705</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Ashburner</surname><given-names>J. T.</given-names></name><name><surname>Kiebel</surname><given-names>S.</given-names></name><name><surname>Nichols</surname><given-names>T.</given-names></name><name><surname>Penny</surname><given-names>W. D.</given-names></name></person-group> (eds.) (<year>2006</year>). <source>Statistical Parametric Mapping: The Analysis of Functional Brain Images, 1st Edn.</source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Academic Press Inc</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K.</given-names></name><name><surname>Burns</surname><given-names>C. D.</given-names></name><name><surname>Madison</surname><given-names>C.</given-names></name><name><surname>Clark</surname><given-names>D.</given-names></name><name><surname>Halchenko</surname><given-names>Y. O.</given-names></name><name><surname>Waskom</surname><given-names>M. L.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python</article-title>. <source>Front. Neuroinform.</source><volume>5</volume>:<issue>13</issue>. <pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id><?supplied-pmid 21897815?><pub-id pub-id-type="pmid">21897815</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hanrahan</surname><given-names>P.</given-names></name></person-group> (<year>2003</year>). <source>Tableau Software White Paper-Visual Thinking for Business Intelligence.</source>
<publisher-loc>Seattle, WA</publisher-loc>: <publisher-name>Tableau Software</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hinterberg</surname><given-names>M. A.</given-names></name><name><surname>Kao</surname><given-names>D. P.</given-names></name><name><surname>Bristow</surname><given-names>M. R.</given-names></name><name><surname>Hunter</surname><given-names>L. E.</given-names></name><name><surname>Port</surname><given-names>J. D.</given-names></name><name><surname>Görg</surname><given-names>C.</given-names></name></person-group> (<year>2014</year>). <article-title>PEAX: interactive visual analysis and exploration of complex clinical phenotype and gene expression association</article-title>, in <source>Pacific Symposium on Biocomputing</source>, <volume>Vol. 20</volume> (<publisher-loc>Kohala, HI</publisher-loc>: <publisher-name>World Scientific</publisher-name>), <fpage>419</fpage>–<lpage>430</lpage>.</mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hipp</surname><given-names>D. R.</given-names></name><name><surname>Kennedy</surname><given-names>D.</given-names></name><name><surname>Mistachkin</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <source>SQLite (Version 3.8.10.2) [Computer software]</source>. <publisher-loc>North Carolina</publisher-loc>: <publisher-name>SQLite Development Team</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hodge</surname><given-names>M. R.</given-names></name><name><surname>Horton</surname><given-names>W.</given-names></name><name><surname>Brown</surname><given-names>T.</given-names></name><name><surname>Herrick</surname><given-names>R.</given-names></name><name><surname>Olsen</surname><given-names>T.</given-names></name><name><surname>Hileman</surname><given-names>M. E.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>ConnectomeDB—sharing human brain connectivity data</article-title>. <source>Neuroimage</source><volume>124</volume>, <fpage>1102</fpage>–<lpage>1107</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.04.046</pub-id><?supplied-pmid 25934470?><pub-id pub-id-type="pmid">25934470</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>J. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Matplotlib: a 2d graphics environment</article-title>. <source>Comput. Sci. Eng.</source>
<volume>9</volume>, <fpage>90</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Behrens</surname><given-names>T. E. J.</given-names></name><name><surname>Woolrich</surname><given-names>M. W.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2012</year>). <article-title>FSL</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>782</fpage>–<lpage>790</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id><?supplied-pmid 21979382?><pub-id pub-id-type="pmid">21979382</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Keim</surname><given-names>D.</given-names></name><name><surname>Andrienko</surname><given-names>G.</given-names></name><name><surname>Fekete</surname><given-names>J.-D.</given-names></name><name><surname>Grg</surname><given-names>C.</given-names></name><name><surname>Kohlhammer</surname><given-names>J.</given-names></name><name><surname>Melanon</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Visual analytics: definition, process, and challenges</article-title>, in <source>Information Visualization</source>, number 4950 in Lecture Notes in Computer Science, eds <person-group person-group-type="editor"><name><surname>Kerren</surname><given-names>A.</given-names></name><name><surname>Stasko</surname><given-names>J. T.</given-names></name><name><surname>Fekete</surname><given-names>J.-D.</given-names></name><name><surname>North</surname><given-names>C.</given-names></name></person-group> (<publisher-loc>Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>154</fpage>–<lpage>175</lpage>.</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>D. S.</given-names></name><name><surname>Harms</surname><given-names>M. P.</given-names></name><name><surname>Snyder</surname><given-names>A. Z.</given-names></name><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Wilson</surname><given-names>J. A.</given-names></name><name><surname>Glasser</surname><given-names>M. F.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Human connectome project informatics: quality control, database services, and data visualization</article-title>. <source>Neuroimage</source><volume>80</volume>, <fpage>202</fpage>–<lpage>219</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.077</pub-id><?supplied-pmid 23707591?><pub-id pub-id-type="pmid">23707591</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milham</surname><given-names>M. P.</given-names></name></person-group> (<year>2012</year>). <article-title>Open neuroscience solutions for the connectome-wide association era</article-title>. <source>Neuron</source>
<volume>73</volume>, <fpage>214</fpage>–<lpage>218</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2011.11.004</pub-id><?supplied-pmid 22284177?><pub-id pub-id-type="pmid">22284177</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prez</surname><given-names>F.</given-names></name><name><surname>Granger</surname><given-names>B. E.</given-names></name></person-group> (<year>2007</year>). <article-title>IPython: a system for interactive scientific computing</article-title>. <source>Comput. Sci. Eng.</source>
<volume>9</volume>, <fpage>21</fpage>–<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2007.53</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rorden</surname><given-names>C.</given-names></name><name><surname>Brett</surname><given-names>M.</given-names></name></person-group> (<year>2000</year>). <article-title>Stereotaxic display of brain lesions</article-title>. <source>Behav. Neurol.</source>
<volume>12</volume>, <fpage>191</fpage>–<lpage>200</lpage>. <pub-id pub-id-type="doi">10.1155/2000/421719</pub-id><?supplied-pmid 11568431?><pub-id pub-id-type="pmid">11568431</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosset</surname><given-names>A.</given-names></name><name><surname>Spadola</surname><given-names>L.</given-names></name><name><surname>Ratib</surname><given-names>O.</given-names></name></person-group> (<year>2004</year>). <article-title>OsiriX: an open-source software for navigating in multidimensional DICOM images</article-title>. <source>J. Digit. Imaging</source>
<volume>17</volume>, <fpage>205</fpage>–<lpage>216</lpage>. <pub-id pub-id-type="doi">10.1007/s10278-004-1014-6</pub-id><?supplied-pmid 15534753?><pub-id pub-id-type="pmid">15534753</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinov</surname><given-names>M.</given-names></name><name><surname>Sporns</surname><given-names>O.</given-names></name></person-group> (<year>2010</year>). <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>Neuroimage</source>
<volume>52</volume>, <fpage>1059</fpage>–<lpage>1069</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.003</pub-id><?supplied-pmid 19819337?><pub-id pub-id-type="pmid">19819337</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>C.</given-names></name><name><surname>Charpak</surname><given-names>N.</given-names></name><name><surname>Ruiz-Peláez</surname><given-names>J. G.</given-names></name><name><surname>Tessier</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>Cerebral motor function in very premature-at-birth adolescents: a brain stimulation exploration of kangaroo mother care effects</article-title>. <source>Acta Paediatr.</source>
<volume>101</volume>, <fpage>1045</fpage>–<lpage>1053</lpage>. <pub-id pub-id-type="doi">10.1111/j.1651-2227.2012.02770.x</pub-id><?supplied-pmid 22734793?><pub-id pub-id-type="pmid">22734793</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>C.</given-names></name><name><surname>Nadeau</surname><given-names>L.</given-names></name><name><surname>Bard</surname><given-names>C.</given-names></name><name><surname>Lambert</surname><given-names>J.</given-names></name><name><surname>Majnemer</surname><given-names>A.</given-names></name><name><surname>Malouin</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Visuo-motor coordination in 8-year-old children born pre-term before and after 28 weeks of gestation</article-title>. <source>Dev. Neurorehabil.</source><volume>11</volume>, <fpage>215</fpage>–<lpage>224</lpage>. <pub-id pub-id-type="doi">10.1080/17518420801887547</pub-id><?supplied-pmid 18608357?><pub-id pub-id-type="pmid">18608357</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schroeder</surname><given-names>W. J.</given-names></name><name><surname>Martin</surname><given-names>K. M.</given-names></name><name><surname>Lorensen</surname><given-names>W. E.</given-names></name></person-group> (<year>1996</year>). <article-title>The design and implementation of an object-oriented toolkit for 3d graphics and visualization</article-title>, in <source>Proceedings of the 7th Conference on Visualization′96</source> (<publisher-loc>Los Alamitos, CA</publisher-loc>: <publisher-name>IEEE Computer Society Press</publisher-name>), <fpage>93</fpage>.</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Team</surname><given-names>R. C.</given-names></name></person-group> (<year>2012</year>). <source>R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</source>. <publisher-loc>Vienna</publisher-loc>: <publisher-name>R Foundation for Statistical Computing</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tufte</surname><given-names>E. R.</given-names></name><name><surname>Graves-Morris</surname><given-names>P. R.</given-names></name></person-group> (<year>1983</year>). <source>The Visual Display of Quantitative Information</source>, <volume>Vol. 31</volume>
<publisher-loc>Cheshire, CT</publisher-loc>: <publisher-name>Graphics Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tukey</surname><given-names>J. W.</given-names></name></person-group> (<year>1980</year>). <article-title>We need both exploratory and confirmatory</article-title>. <source>Am. Stat.</source>
<volume>34</volume>, <fpage>23</fpage>–<lpage>25</lpage>.</mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Horn</surname><given-names>J. D.</given-names></name><name><surname>Toga</surname><given-names>A. W.</given-names></name></person-group> (<year>2009</year>). <article-title>Is it time to re-prioritize neuroimaging databases and digital repositories?</article-title>
<source>Neuroimage</source>
<volume>47</volume>, <fpage>1720</fpage>–<lpage>1734</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.086</pub-id><?supplied-pmid 19371790?><pub-id pub-id-type="pmid">19371790</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waskom</surname><given-names>M.</given-names></name><name><surname>Botvinnik</surname><given-names>O.</given-names></name><name><surname>Hobson</surname><given-names>P.</given-names></name><name><surname>Cole</surname><given-names>J. B.</given-names></name><name><surname>Halchenko</surname><given-names>Y.</given-names></name><name><surname>Hoyer</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2014</year>). <source>seaborn: v0.5.0 (November 2014)</source>. <pub-id pub-id-type="doi">10.5281/zenodo.12710</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wassink</surname><given-names>I.</given-names></name><name><surname>Kulyk</surname><given-names>O.</given-names></name><name><surname>van Dijk</surname><given-names>B.</given-names></name><name><surname>van der Veer</surname><given-names>G.</given-names></name><name><surname>van der Vet</surname><given-names>P.</given-names></name></person-group> (<year>2009</year>). <article-title>Applying a user-centered approach to interactive visualisation design</article-title>, in <source>Trends in Interactive Visualization</source>, eds <person-group person-group-type="editor"><name><surname>Liere</surname><given-names>R.</given-names></name><name><surname>Adriaansen</surname><given-names>T.</given-names></name><name><surname>Zudilova-Seinstra</surname><given-names>E.</given-names></name></person-group> (<publisher-loc>London, UK</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>175</fpage>–<lpage>199</lpage>.</mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wickham</surname><given-names>H.</given-names></name><name><surname>Grolemund</surname><given-names>G.</given-names></name></person-group> (<year>2016</year>). <source>R for Data Science.</source>
<publisher-loc>Sebastopol, CA</publisher-loc>: <publisher-name>O'Reilly Media</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>D.</given-names></name><name><surname>King</surname><given-names>M.</given-names></name><name><surname>Landis</surname><given-names>D.</given-names></name><name><surname>Courtney</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>R.</given-names></name><name><surname>Kelly</surname><given-names>R.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Harnessing modern web application technology to create intuitive and efficient data visualization and sharing tools</article-title>. <source>Front. Neuroinform.</source><volume>8</volume>:<issue>71</issue>. <pub-id pub-id-type="doi">10.3389/fninf.2014.00071</pub-id><?supplied-pmid 25206330?><pub-id pub-id-type="pmid">25206330</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>T.</given-names></name><name><surname>Yang</surname><given-names>Z.</given-names></name><name><surname>Jiang</surname><given-names>L.</given-names></name><name><surname>Xing</surname><given-names>X.-X.</given-names></name><name><surname>Zuo</surname><given-names>X.-N.</given-names></name></person-group> (<year>2015</year>). <article-title>A connectome computation system for discovery science of brain</article-title>. <source>Sci. Bull.</source>
<volume>60</volume>, <fpage>86</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1007/s11434-014-0698-3</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yushkevich</surname><given-names>P. A.</given-names></name><name><surname>Piven</surname><given-names>J.</given-names></name><name><surname>Hazlett</surname><given-names>H. C.</given-names></name><name><surname>Smith</surname><given-names>R. G.</given-names></name><name><surname>Ho</surname><given-names>S.</given-names></name><name><surname>Gee</surname><given-names>J. C.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>User-guided 3d active contour segmentation of anatomical structures: significantly improved efficiency and reliability</article-title>. <source>Neuroimage</source><volume>31</volume>, <fpage>1116</fpage>–<lpage>1128</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.015</pub-id><?supplied-pmid 16545965?><pub-id pub-id-type="pmid">16545965</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuo</surname><given-names>X.-N.</given-names></name><name><surname>Xing</surname><given-names>X.-X.</given-names></name></person-group> (<year>2014</year>). <article-title>Test-retest reliabilities of resting-state FMRI measurements in human brain functional connectomics: a systems neuroscience perspective</article-title>. <source>Neurosci. Biobehav. Rev.</source>
<volume>45</volume>, <fpage>100</fpage>–<lpage>118</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2014.05.009</pub-id><?supplied-pmid 24875392?><pub-id pub-id-type="pmid">24875392</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
