<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355295</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa436</article-id>
    <article-id pub-id-type="publisher-id">btaa436</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Macromolecular Sequence, Structure, and Function</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep multiple instance learning classifies subtissue locations in mass spectrometry images from tissue-level annotations</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Guo</surname>
          <given-names>Dan</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Föll</surname>
          <given-names>Melanie Christine</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Volkmann</surname>
          <given-names>Veronika</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Enderle-Ammour</surname>
          <given-names>Kathrin</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bronsert</surname>
          <given-names>Peter</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
        <xref ref-type="aff" rid="btaa436-aff4">b4</xref>
        <xref ref-type="aff" rid="btaa436-aff5">b5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schilling</surname>
          <given-names>Oliver</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vitek</surname>
          <given-names>Olga</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff1">b1</xref>
        <xref ref-type="corresp" rid="btaa436-cor1"/>
        <!--<email>o.vitek@neu.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa436-aff1"><label>b1</label><institution>Khoury College of Computer Sciences, Northeastern University</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
    <aff id="btaa436-aff2"><label>b2</label><institution>Institute for Surgical Pathology, Medical Center – University of Freiburg</institution>, 79106 Freiburg, <country country="DE">Germany</country></aff>
    <aff id="btaa436-aff3"><label>b3</label><institution>Faculty of Medicine, University of Freiburg</institution>, 79110 Freiburg, <country country="DE">Germany</country></aff>
    <aff id="btaa436-aff4">
      <label>b4</label>
      <institution>Tumorbank Comprehensive Cancer Center Freiburg, Medical Center – University of Freiburg</institution>
    </aff>
    <aff id="btaa436-aff5"><label>b5</label><institution>German Cancer Consortium (DKTK) and Cancer Research Center (DKFZ)</institution>, 79106 Freiburg, <country country="DE">Germany</country></aff>
    <author-notes>
      <corresp id="btaa436-cor1">To whom correspondence should be addressed. E-mail: <email>o.vitek@neu.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i300</fpage>
    <lpage>i308</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa436.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Mass spectrometry imaging (MSI) characterizes the molecular composition of tissues at spatial resolution, and has a strong potential for distinguishing tissue types, or disease states. This can be achieved by supervised classification, which takes as input MSI spectra, and assigns class labels to subtissue locations. Unfortunately, developing such classifiers is hindered by the limited availability of training sets with subtissue labels as the ground truth. Subtissue labeling is prohibitively expensive, and only rough annotations of the entire tissues are typically available. Classifiers trained on data with approximate labels have sub-optimal performance.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To alleviate this challenge, we contribute a semi-supervised approach <italic>mi-CNN</italic>. mi-CNN implements multiple instance learning with a convolutional neural network (CNN). The multiple instance aspect enables weak supervision from tissue-level annotations when classifying subtissue locations. The convolutional architecture of the CNN captures contextual dependencies between the spectral features. Evaluations on simulated and experimental datasets demonstrated that mi-CNN improved the subtissue classification as compared to traditional classifiers. We propose mi-CNN as an important step toward accurate subtissue classification in MSI, enabling rapid distinction between tissue types and disease states.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The data and code are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Vitek-Lab/mi-CNN_MSI">https://github.com/Vitek-Lab/mi-CNN_MSI</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSF</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>DBI-1759736</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>German Research Council</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>DFG</institution>
            <institution-id institution-id-type="DOI">10.13039/100004807</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>SCHI 871/11-1</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Biochemical constitution of tissues varies with tissue types (such as epithelial and connective tissues), or disease states (such as tumor and healthy tissues). Mass spectrometry imaging (MSI) provides an untargeted characterization of the molecular composition of such tissues at spatial resolution, simultaneously quantifying hundreds of analytes without the need for chemical labels or antibodies (<xref rid="btaa436-B27" ref-type="bibr">Spengler, 2015</xref>; <xref rid="btaa436-B17" ref-type="bibr">Jones <italic>et al.</italic>, 2012</xref>). Therefore, MSI has a strong potential to become a rapid diagnostic technology in the clinic (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>).</p>
    <p>Although the name of the technology contains the word ‘image’, the structure of MSI data is very different from other bioimaging technologies (<xref ref-type="fig" rid="btaa436-F1">Fig. 1</xref>). In MSI, mass spectra are acquired at thousands of different spatial <italic>locations</italic> in a raster pattern throughout the tissue. MSI techniques fall into two major categories: matrix-assisted laser desorption/ionization (MALDI) MSI (<xref rid="btaa436-B1" ref-type="bibr">Aichler and Walch, 2015</xref>) and desorption electrospray ionization (DESI) MSI (<xref rid="btaa436-B30" ref-type="bibr">Wu <italic>et al.</italic>, 2013</xref>). With each technique, the mass spectrum obtained at each location is a collection of <italic>features</italic>, corresponding to the ions of biochemical analytes such as metabolites, lipids, peptides and proteins. The features do not contain direct information regarding the identity of the underlying analyte, except for their ratios of mass over charge <italic>m</italic>/<italic>z</italic>. For one tissue location, a typical MSI experiment reports hundreds to thousands of <italic>m</italic>/<italic>z</italic> in ascending order. The intensities of the <italic>m</italic>/<italic>z</italic> correlate with the abundance of the analyte. A plot of the abundance of one <italic>m</italic>/<italic>z</italic> across all locations is referred to as an <italic>ion image</italic>.
</p>
    <fig id="btaa436-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>MSI data. (<bold>a</bold>) H&amp;E-stained optical images of a pair of tumor and healthy tissues from the human renal cell carcinoma (RCC) experiment. (<bold>b</bold>) Mass spectrum from one location in the tumor tissue. The inset zooms into <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mi>m</mml:mi><mml:mo>/</mml:mo><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Two features with <italic>m</italic>/<italic>z</italic> shift <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>22</mml:mn></mml:mrow></mml:math></inline-formula> can correspond to molecular ions and sodium adducts. Two features with <italic>m</italic>/<italic>z</italic> shift <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>38</mml:mn></mml:mrow></mml:math></inline-formula> can correspond to molecular ions and potassium adducts. (<bold>c</bold>) Ion images of <italic>m</italic>/<italic>z</italic> 215 of the tissues in (a)</p>
      </caption>
      <graphic xlink:href="btaa436f1"/>
    </fig>
    <p>A reliable diagnostics can be achieved by supervised classification models that take as input the observed mass spectra, and predict labels such as tumor, healthy or tumor subtypes. Beyond <italic>tissue-level classification</italic> (classifying the entire tissues), <italic>subtissue-level classification</italic> (classifying the disease status of individual locations within the tissues) is of most interest. Ranking <italic>m</italic>/<italic>z</italic> features by their predictive ability is also important. Currently, training subtissue-level classifiers providing this information requires training sets of tissues with reliable <italic>subtissue labels</italic>.</p>
    <p>Unfortunately, accessing a training set with reliable subtissue labels is challenging in practice. In a typical workflow, pathologists examine the hematoxylin and eosin (H&amp;E)-stained optical images such as in <xref ref-type="fig" rid="btaa436-F1">Figure 1a</xref>. To obtain subtissue labels, the pathologist must manually examine and annotate the distinct regions of each tissue (<xref rid="btaa436-B20" ref-type="bibr">Lou <italic>et al.</italic>, 2017</xref>). The cost of manual work is one of the reasons to the relatively small number of biological replicates in MSI. The procedure is particularly costly for heterogeneous tissues that require labeling of multiple small sub-regions, or for tissues with challenging histology. To be transferrable to MSI, the subtissue labeling must use specialized software that takes time to learn. As the result, pathologists often avoid labeling the individual locations, and only roughly annotate the entire tissues. <xref ref-type="fig" rid="btaa436-F1">Figure 1c</xref> shows that, although the tissue on the left is annotated as tumor, the ion image indicates tissue heterogeneity, and the tissue likely contains both cancerous tissue and healthy kidney parenchyma. Such imprecise labeling of tissue locations compromises the accuracy of the resulting classifiers.</p>
    <p>In addition to the labeling, high correlations between many <italic>m</italic>/<italic>z</italic> limit our ability to train accurate classifiers on MSI data. For example, in peptide MSI proteins are digested to give rise to multiple peptide ions of a same protein, and therefore have similar spatial distributions of abundance. An analyte can also produce multiple <italic>m</italic>/<italic>z</italic> ions for other reasons, that include sodium adducts, neutral loss ions, fragment ions or multiply charged ions. For example, <xref ref-type="fig" rid="btaa436-F1">Figure 1b</xref> illustrates the potential sodium and potassium adducts that give rise to correlated features. The high correlation in the high-dimensional vector of <italic>m</italic>/<italic>z</italic> features undermines the stability of the classifiers, and leads to overfitting (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>).</p>
    <p>To improve our ability to accurately classify subtissue locations in MSI from approximate tissue-level annotations, we propose a semi-supervised approach <italic>mi-convolutional neural network (CNN)</italic>. mi-CNN implements multiple instance learning (MIL) with a CNN. The multiple instance aspect of the approach enables weak supervision from tissue-level annotations when classifying subtissue labels. The convolutional architecture of the CNN captures potential contextual dependencies between <italic>m</italic>/<italic>z</italic>, such as sodium adducts and dehydrated ions. Evaluations on simulated and experimental datasets demonstrate that mi-CNN improved the subtissue classification as compared with traditional classifiers such as support vector machine (SVM) and CNN, and successfully reflected the truly predictive spectral features. We propose mi-CNN as an important step toward accurate subtissue classification in basic biology and clinical applications of MSI.</p>
  </sec>
  <sec>
    <title>2 Background</title>
    <sec>
      <title>2.1 Subtissue-level classification in MSI</title>
      <p>Classifying tissue locations using MSI spectra has already received a lot of attention (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>). Various classifiers have been proposed for these task, including linear discriminant analysis (<xref rid="btaa436-B10" ref-type="bibr">Dill <italic>et al.</italic>, 2010</xref>, <xref rid="btaa436-B11" ref-type="bibr">2011</xref>), regularized logistic regression (<xref rid="btaa436-B12" ref-type="bibr">Eberlin <italic>et al.</italic>, 2014</xref>; <xref rid="btaa436-B26" ref-type="bibr">Sans <italic>et al.</italic>, 2017</xref>), SVM (<xref rid="btaa436-B8" ref-type="bibr">Calligaris <italic>et al.</italic>, 2015</xref>), and many others. Variations of these approaches such as nearest shrunken centroids (<xref rid="btaa436-B6" ref-type="bibr">Bemis <italic>et al.</italic>, 2016</xref>) incorporate spatial smoothing to enhance the spatial stability of the results. The classifiers take as input <italic>m</italic>/<italic>z</italic> features at each location, classify the label of each location, and classify the tissues according to the majority of its location labels.</p>
      <p>Recently, neural networks became of a great interest for MSI. <xref rid="btaa436-B23" ref-type="bibr">Rauser <italic>et al.</italic> (2010)</xref> used fully connected neural networks for tumor classification, and <xref rid="btaa436-B16" ref-type="bibr">Inglese <italic>et al.</italic> (2017)</xref> used unsupervised neural networks to cluster tumor tissues. CNNs, a class of deep neural networks originally designed for image classification, were also introduced. CNN convolutes the image using a small-sized kernel to capture the local connectivity within an image (<xref rid="btaa436-B24" ref-type="bibr">Rawat and Wang, 2017</xref>). A novel application of CNN to MSI proposed to view mass spectra as 1D images. <xref rid="btaa436-B4" ref-type="bibr">Behrmann <italic>et al.</italic> (2018)</xref> used a modified Residual Net with 13 935 parameters and kernel size of 3 to capture isotopic patterns in mass spectra. <xref rid="btaa436-B28" ref-type="bibr">van Kersbergen <italic>et al.</italic> (2019)</xref> replaced convolutional layers in Behrmann’s network with dilated convolutional layers to increase receptive size, and capture globally distributed patterns in the spectra.</p>
      <p>Although the approaches above are quite diverse, they all rely on quality subtissue labels for training. As the result, they are undermined by training sets with approximate annotations, such as in <xref ref-type="fig" rid="btaa436-F1">Figure 1</xref>.</p>
    </sec>
    <sec>
      <title>2.2 Multiple instance learning (MIL)</title>
      <p>Multiple instance learning is a semi-supervised framework commonly used in a variety of applications such as image and video analysis (<xref rid="btaa436-B9" ref-type="bibr">Cheplygina <italic>et al.</italic>, 2019</xref>) and computer-aided diagnosis (<xref rid="btaa436-B14" ref-type="bibr">Fu <italic>et al.</italic>, 2010</xref>; <xref rid="btaa436-B18" ref-type="bibr">Kandemir and Hamprecht, 2015</xref>), but so far not utilized for MSI. In contrast to the classifiers above, MIL allows weak supervision of the training data. The approach considers groups of observations, called <italic>bags</italic>, where ground-truth labels are only available at the bag level. The labels of the observations in a bag, called <italic>instances</italic>, are unknown. In a binary classification problem MIL assumes that a positive bag contains at least one positive instance, but the negative bags contain only negative instances. The homogeneity of the data in the negative bags is the key feature of the approach that enables efficient learning.</p>
      <p>Existing MIL algorithms can be classified into two groups: bag space algorithms and instance space algorithm. Bag space algorithms, such as mi-Graph (<xref rid="btaa436-B32" ref-type="bibr">Zhou <italic>et al.</italic>, 2009</xref>) and MIL with instance (<xref rid="btaa436-B14" ref-type="bibr">Fu <italic>et al.</italic>, 2010</xref>), do not predict labels of individual instances. They classify the bags directly by considering similarities of input features between the bags. Instance space algorithms, such as mi-SVM (<xref rid="btaa436-B3" ref-type="bibr">Andrews <italic>et al.</italic>, 2003</xref>) and MILboost (<xref rid="btaa436-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2006</xref>), take features of the instances as input and predict labels of both instances and bags. For instance-level prediction, mi-SVM is one of the most accurate methods (<xref rid="btaa436-B18" ref-type="bibr">Kandemir and Hamprecht, 2015</xref>). The method treats labels of instances in positive bags as latent variables, and estimates them from the data. Parameters of SVM are optimized by iteratively training SVM on the current instance-level labels, and updating the instance-level labels from their predictions by the current SVM.</p>
    </sec>
    <sec>
      <title>2.3 Interpretation of black-box machine learning models</title>
      <p>Many of the classification approaches above function like a ‘black box’ and lack interpretability. Post-processing of these models (<xref rid="btaa436-B21" ref-type="bibr">Molnar, 2019</xref>) helps characterize the relative importance of each predictive feature after the model is fit. One such approach is Local Interpretable Model-agnostic Explanation (LIME; <xref rid="btaa436-B25" ref-type="bibr">Ribeiro <italic>et al.</italic>, 2016</xref>), which ranks features by their importance in predicting the label of a particular observation of interest. LIME generates new observations by permuting the values of the predictive features in the dataset, and obtains the black box predictions for these new observations. Next, LIME weights the new observations by their proximity to the observation of interest, and trains a weighted interpretable model (such as linear regression with subset selection or regularization) on the new observations and their predictions. Finally, LIME repeats this procedure multiple times, and ranks the features by their frequency of being selected as predictive.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Multiple instance learning with convolutional neural network (mi-CNN) </title>
    <sec>
      <title>3.1 Overview</title>
      <p>For the purposes of subtissue classification in MSI, we propose to view a <italic>tissue</italic> as a bag, and a tissue <italic>location</italic> as an instance. We assume that tissues annotated as non-tumor do not have tumor locations, but tissues annotated as tumor can have both tumor and non-tumor locations. MIL allows us to train classifiers of subtissue locations on training sets with such rough tissue-level annotations. Instance space algorithms are of a particular interest for this task. Our proposed approach takes as the baseline mi-SVM, which reported high classification accuracy on similar tasks in the past, but substitutes the SVM classifier with a CNN (<xref ref-type="fig" rid="btaa436-F2">Fig. 2</xref>). Although CNN are frequently used for image analyses in computer vision domains, the proposed approach uses CNN is a different way. We do not apply spatial convolution on a tissue, as we expect high heterogeneity of the microenvironment within a tumor, and an insufficient spatial smoothness of the location labels. Instead, the CNN incorporates convolutional filters to <italic>m</italic>/<italic>z</italic> in individual locations to capture potential correlations between <italic>m</italic>/<italic>z</italic> of a same location. The CNN has a lightweight structure to avoid overfitting. Finally, post-processing with LIME identifies highly predictive <italic>m</italic>/<italic>z</italic> for downstream biological and clinical interpretation.
</p>
      <fig id="btaa436-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Architecture of mi-CNN. <italic>π<sub>j</sub></italic> the probability that tissue <italic>j</italic> belongs to Class 1, and <italic>π<sub>ij</sub></italic> is the corresponding probability for the location <italic>i</italic> in that tissue. (<bold>a</bold>) Training set and (<bold>b</bold>) validation set</p>
        </caption>
        <graphic xlink:href="btaa436f2"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Notation</title>
      <p>Consider tissue <italic>j</italic> and its locations <italic>i</italic>. The tissue is characterized by a collection of mass spectra <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, and each mass spectrum <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a vector of <italic>M</italic> intensities of <italic>m</italic>/<italic>z</italic> features <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Let <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> denote the annotation of the tissue <italic>j</italic>, and <italic>y<sub>ij</sub></italic> the subtissue label at the <italic>i</italic>th location. Note that <italic>Y<sub>j</sub></italic> is known, and <italic>y<sub>ij</sub></italic> is unknown. Denote <italic>π<sub>j</sub></italic> the probability that tissue <italic>j</italic> belongs to Class 1, and <italic>π<sub>ij</sub></italic> is the corresponding probability for the location <italic>i</italic> in that tissue. Given a mass spectrum <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, our goal is to predict the label <italic>y<sub>ij</sub></italic> of this location, and the label <italic>Y<sub>j</sub></italic> of the entire tissue.</p>
    </sec>
    <sec>
      <title>3.3 Subtissue-level classification</title>
      <p>Using cross-entropy as the loss function, the objective of MIL is defined as
<disp-formula id="E1"><mml:math id="M1"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo>Θ</mml:mo></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="E2"><label>(1)</label><mml:math id="M2"><mml:mrow><mml:mtext mathvariant="bold">such</mml:mtext><mml:mo> </mml:mo><mml:mtext mathvariant="bold">that</mml:mtext><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the prediction of a classifier (a CNN) with parameters Θ.</p>
      <p>Since the subtissue labels <italic>y<sub>ij</sub></italic> are not observed, they are estimated by an expectation–maximization-like algorithm (Algorithm 1, similar to mi-SVM in Andrews <italic>et al.</italic>, 2003) minimizing the entropy loss [<xref ref-type="disp-formula" rid="E2">Equation (1)]</xref>. First, the labels of all subtissue locations are initialized with the annotations of the corresponding tissues. Next, the algorithm iterates between training CNN on the current location labels, estimating the probability <italic>π<sub>ij</sub></italic> that location <italic>i</italic> in tissue <italic>j</italic> belong to Class 1, and imputing the location labels <italic>y<sub>ij</sub></italic> from these probabilities until convergence. The constraint in <xref ref-type="disp-formula" rid="E2">Equation (1)</xref> ensures that the labels of non-tumor locations in non-tumor tissues are always classified as non-tumor. On the other hand, if no locations on a tumor tissue are classified as tumor, the location with the highest <italic>π<sub>ij</sub></italic> in this tissue will be labeled as tumor (Lines 7–10, Algorithm 1). The algorithm stops when the number of updated labels is below a threshold, or when the maximum number of iterations is reached.<boxed-text id="btaa436-BOX1" position="float" orientation="portrait"><sec><title><bold>Algorithm 1</bold> <italic>mi-CNN</italic></title><p>1: <bold>procedure</bold> mi-CNN(<inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, threshold)</p><p>2:  Initialize: <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:math></inline-formula></p><p>3:  <bold>while</bold> the number of updated labels &lt; threshold <bold>do</bold></p><p>4:   Compute CNN parameters Θ for current labels <italic>y<sub>ij</sub></italic></p><p>5:   Compute <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p><p>6:   For each <italic>j</italic> where <italic>Y<sub>j</sub></italic> = 1, set <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>ifelse</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p><p>7:   <bold>for</bold> each <italic>j</italic> where <italic>Y <sub>j</sub></italic> = 1 <bold>do</bold></p><p>8:    <bold>if</bold><inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula><bold>then</bold></p><p>9:     Compute <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="italic">arg</mml:mi><mml:munder><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p><p>10:     Set <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></p><p>11:    <bold>end if</bold></p><p>12:   <bold>end for</bold></p><p>13:  <bold>end while</bold></p><p>14:  OUTPUT (<inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>)</p><p>15: <bold>end procedure</bold></p></sec></boxed-text>The architecture of CNN must be adapted to the specifics of the MSI. In these experiments the number of <italic>m</italic>/<italic>z</italic> features can be very large (up to one hundred thousand), while the number of biological replicates is relatively small (typically &lt; 50). Therefore, the CNN should be relatively lightweight, and minimize the number of parameters to avoid overfitting. The convolution filter should be large enough to incorporate neighboring <italic>m</italic>/<italic>z</italic>, but small enough to benefit from weight sharing and computation reduction.</p>
      <p>We propose a 1D CNN, consisting of three basic components, namely convolutional layers, pooling layers and fully connected layers. Three convolutional layers hierarchically learn the potential patterns in a mass spectrum. For each layer, the filter size is set according to the contextual dependencies between <italic>m</italic>/<italic>z</italic> of interest, such as mass shifts corresponding to sodium adducts and molecular ions. After each convolutional layer, maxpooling reduces the resolution of the previous layer by focusing on large intensities of <italic>m</italic>/<italic>z</italic> features and reducing the impact of spectral noise. The CNN includes only one fully connected layer that captures globally distributed patterns (<xref ref-type="fig" rid="btaa436-F2">Fig. 2</xref>). <italic>Softmax</italic> activation function is used in the output layer to generate probability of each class.</p>
      <p>The CNN is trained using stochastic gradient descent. It calculates the partial derivative of the loss function in <xref ref-type="disp-formula" rid="E2">Equation (1)</xref> with respect to the learnable parameters in Θ by backpropagation, and iteratively updates Θ and values in each layer until convergence.</p>
      <p><bold>Tissue-level classification.</bold> The proposed tissue-level classification does not count the proportion of predicted location labels in a tissue. Instead, it treats each tissue as one observation, and uses the collection of mass spectra <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from all the locations in the tissue as its predictive features. The CNN architecture for this task is the same as the architecture for subtissue-level classification, with the exception of combining the probabilities of the individual locations into a pooling layer that estimates the probability of a tissue-level label. The pooling can be a simple max or mean pooling, or a generalized mean pooling
<disp-formula id="E3"><label>(2)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>r</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>I<sub>j</sub></italic> is the number of locations on tissue <italic>j</italic>, and <italic>r</italic> is an integer tuning parameter. The loss function is the cross-entropy of tissue-level predictions and tissue-level labels
<disp-formula id="E4"><label>(3)</label><mml:math id="M4"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo>Θ</mml:mo></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mi>J</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>π<sub>j</sub></italic> is pooled probability of <italic>π<sub>ij</sub></italic>, and <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are the predicted probabilities by CNN.</p>
    </sec>
    <sec>
      <title>3.4 Evaluation and interpretation</title>
      <p>We evaluate the accuracy of subtissue classification by calculating the accuracy and the balanced accuracy of label predictions at individual locations. We evaluate the accuracy of tissue-level classification by calculating the accuracy and the balanced accuracy of label predictions at the entire tissues. The metrics are defined as
<disp-formula id="E5"><label>(4)</label><mml:math id="M5"><mml:mrow><mml:mtext>Accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(5)</label><mml:math id="M6"><mml:mrow><mml:mtext>Balanced</mml:mtext><mml:mo> </mml:mo><mml:mtext>accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mtext>TN</mml:mtext></mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where for subtissue-level classification, <italic>TP</italic> is the number of correctly classified positive (i.e. tumor) locations across all the tissues, <italic>TN</italic> is the number of correctly classified negative (i.e. non-tumor) locations across all the tissues. <italic>P</italic> and <italic>N</italic> are the total numbers of locations across the tissues classified as tumor or non-tumor respectively. For tissue-level classification, <italic>TP</italic>, <italic>TN</italic>, <italic>P</italic> and <italic>N</italic> have the same interpretation, but for the entire tissues. Accuracy quantifies the overall proportion of correct predictions by model. When the number of observations in each class is not balanced, and the prediction of a minority class is under-represented, overall accuracy may inaccurately characterize the performance. In this case, balanced accuracy, quantifying the average of individual proportions of correct predictions in each class may provide more insights.</p>
      <p>Even when we can report the accuracy of classification, the classifier remains a black box. Therefore, we use LIME to assist with the interpretation, and identify <italic>m</italic>/<italic>z</italic> features that play a particularly important role in classifying the labels of individual locations. We randomly select a subset of locations in the validation sets in our experiments, use LIME to select top five influential features for each location, and rank the selected features by frequency of being selected in multiple locations.</p>
    </sec>
    <sec>
      <title>3.5 Implementation</title>
      <p>We implemented <italic>mi-CNN</italic> using Tensorflow (<xref rid="btaa436-B2" ref-type="bibr">Allaire and Tang, 2019</xref>) in the RStudio environment. We constructed a CNN architecture of three convolutional layers with Rectified Linear Unit (ReLU) activation, and a fully connected layer. The filter sizes of each convolutional layer were set as 38, 18 and 16. The network had 1774 trainable parameters in total for an input length of 850. CNN were trained using batch stochastic gradient descent optimization. Training one epoch of the renal cell carcinoma (RCC) dataset with 5350 spectra took ∼10 s, and training the entire model took ∼1.5 h on a computer with 64 RAM and 3.6 GHz CPU. Baseline model mi-SVM was implemented in R following (Andrews <italic>et al.</italic>, 2003). The maximum number of iterations of mi-SVM was set as 200. The kernel function used was radial basis function with gamma as 0.0012 in simulation datasets and human RCC data, and sigmoid function with gamma as 0.00125 in human bladder cancer data. LIME was implemented using R package <italic>lime</italic> (<xref rid="btaa436-B22" ref-type="bibr">Pedersen and Benesty, 2019</xref>). The number of bins for continuous variable was set as 4 and the kernel width was set as 0.1 in <italic>lime</italic>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Data</title>
    <p>We evaluated the performance of mi-CNN on five datasets. Two experimental datasets represent two human cancers, and two different MSI acquisition strategies (DESI, characterizing metabolites and lipids and MALDI, characterizing peptides). We further simulated three datasets with known ground truth, inspired from one of the experimental datasets.</p>
    <sec>
      <title>4.1 Human RCC experiment</title>
      <p>The experiment aimed to classify locations in human renal tissues as tumor versus healthy. Pairs of tumor and healthy tissue sections were collected from eight human donors with RCC. The tissues were subjected to serial H&amp;E staining. Pathology examination of the H&amp;E-stained tissues was unable to classify the tissues at the sub-tissue resolution, and only annotated each entire tissue section as tumor or healthy (<xref ref-type="fig" rid="btaa436-F3">Fig. 3</xref>).
</p>
      <fig id="btaa436-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Human RCC experiment. Pairs of tumor and healthy tissues from eight donors were H&amp;E stained, and examined by a pathologist. For each pair, the tissue on the left has the pathology annotation of tumor, and the tissue on the right has the pathology annotation of healthy. The subtissue-level annotations were not available for this experiment. (<bold>a</bold>) Training set and (b) Validation set</p>
        </caption>
        <graphic xlink:href="btaa436f3"/>
      </fig>
      <p>Data from the tissues were acquired using DESI ionization source on a Thermo Finnigan LTQ ion trap mass spectrometer in negative mode. The mass range covered 150–1000 Da. In total, 7567 mass spectra were collected from on average 472 locations per tissue. Prior to classification, the spectra were normalized by total ion current (TIC) and resampled to unit mass resolution, which produced 850 <italic>m</italic>/<italic>z</italic> features per mass spectrum. The data are available in R package <italic>CardinalWorkflow</italic> (<xref rid="btaa436-B7" ref-type="bibr">Bemis, 2019</xref>). The pairs of tissues were randomly split into a training set (six pairs) and validation set (two pairs).</p>
    </sec>
    <sec>
      <title>4.2 Human bladder cancer experiment</title>
      <p>The experiment aimed to classify human bladder cancer tissues as tumor versus stroma. Two tissue microarrays (TMAs) containing core needle biopsies from resected formalin-fixed and paraffin-embedded bladder tissues of 49 patients were built, and each TMA was mounted onto a separate glass slide (<xref ref-type="fig" rid="btaa436-F4">Fig. 4</xref>). A pathologist annotated 42 tissue cores by carefully examining sub-areas of each tissue and color-coded subregions presenting tumor and subregions presenting stroma (<xref ref-type="fig" rid="btaa436-F4">Fig. 4</xref>). The annotations are viewed as ground truth in this article. The label tumor was assigned to tissue cores containing tumor subregions, and the label stroma to cores containing only stroma.
</p>
      <fig id="btaa436-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Human bladder cancer experiment. H&amp;E-stained optical images of human bladder cancer tissues after data acquisition. Letters above each tissue are tissue-level annotations (T, tumor; S, stroma). The colors inside each core indicate subtissue-level pathology (red, tumor; blue, stroma), viewed as the ground truth. (<bold>a</bold>) Training set: 3 purely stroma tissues and 18 tissues with both tumor and stroma locations. (<bold>b</bold>) Validation set: 7 purely stroma tissues and 14 tissues with both tumor and stroma</p>
        </caption>
        <graphic xlink:href="btaa436f4"/>
      </fig>
      <p>The proteins in the tissues were digested with trypsin and the peptides were covered with alpha-cyano-4-hydroxycinnamic acid matrix and analyzed with an AB SCIEX 4800 MALDI Time-of-Flight (TOF)/TOF mass spectrometer in positive mode. The mass range was 800–2300 Da. Subregion annotations containing 3152 mass spectra in total and 77 spectra per tissue were extracted via an affine transformation strategy (<xref rid="btaa436-B13" ref-type="bibr">Föll <italic>et al.</italic>, 2019</xref>). The two datasets were resampled, combined and pre-processed using Cardinal and MALDIquant algorithms on <ext-link ext-link-type="uri" xlink:href="https://usegalaxy.eu">https://usegalaxy.eu</ext-link> (<xref rid="btaa436-B5" ref-type="bibr">Bemis <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B13" ref-type="bibr">Föll <italic>et al.</italic>, 2019</xref>; <xref rid="btaa436-B15" ref-type="bibr">Gibb and Strimmer, 2012</xref>). The major pre-processing steps comprised peak picking, re-calibration, removal of contaminants and TIC normalization. The pre-processed file contained 593 <italic>m</italic>/<italic>z</italic> features. Annotated tissues from one slide were used as training set (21 tissues), and on the second slide as the validation set (21 tissues). The split aims to test the robustness of the classifier to experimental batch effects.</p>
      <p><bold>Simulated Dataset 1: one differentially abundant analyte with four features, and a complex background</bold>. The simulation is based on the mass spectra from eight healthy tissues in RCC dataset. It mimicked real-life variation in feature intensities, while providing the ground truth regarding both the labels of the tissue locations and the predictive features.</p>
      <p>First, the eight healthy tissues in the RCC dataset were split into two halves, as shown in <xref ref-type="fig" rid="btaa436-F5">Figure 5</xref>. Since the mass spectra from these tissues have real-life biological and technological variation, but no systematic variation between the tissue types, they are viewed as a complex background.
</p>
      <fig id="btaa436-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Simulated Dataset 1. Healthy tissues from the RCC experiment were split into halves. Locations on the left half of the upper newly created tissues were labeled as tumor, and the remaining locations as healthy. The labels were viewed as the ground truth. To mimic pathology annotations, the entire upper tissues were annotated as tumor, and the lower tissues as healthy. A synthetic analyte with four features, differentially abundant between tumor and healthy, was added to the experimental spectra. Its intensity was confounded by a morphology structure spanning both tissue types</p>
        </caption>
        <graphic xlink:href="btaa436f5"/>
      </fig>
      <p>Second, the newly created tissues were assigned tissue- and subtissue-level labels. The left half of the upper newly created tissues was labeled as tumor, and the remaining locations as healthy. These labels were viewed as the ground truth. To mimic pathology annotations at the tissue level, the entire upper tissues were annotated as tumor, and the lower tissues as healthy.</p>
      <p>Next, one synthetic differentially abundant analyte between the tumor and the healthy locations was added to the experimental spectra. The simulation incorporated a morphology (grey area in <xref ref-type="fig" rid="btaa436-F5">Fig. 5</xref>) that confounded the intensity of the differentially abundant analyte and spanned both tumor and the healthy tissue locations. The intensity <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> of this analyte at location <italic>i</italic> in tissue <italic>j</italic> was simulated as follows
<disp-formula id="E7"><label>(6)</label><mml:math id="M7"><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo>μ</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ϵ</mml:mo><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>δ</mml:mo><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>μ</italic> is the mean intensity of the analyte for tumor or stroma, <italic>S<sub>j</sub></italic> is the biological between-tissue variation, <italic>δ<sub>ij</sub></italic> is the variation between the morphological region and background, and <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the biological and technological variation between locations of a same tissue. All the random variables are independent. <italic>I</italic><sub>in</sub> and <italic>I</italic><sub>out</sub> are indicators of whether a tissue location is inside or outside a morphology region, and <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> is the mean intensity shift of locations inside or outside the morphological region. Here <italic>μ </italic>= 50 for tumor and <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>150</mml:mn></mml:mrow></mml:math></inline-formula> for healthy, <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.15</mml:mn><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>δ</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ε</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <p>Finally, we simulated four individual <italic>m</italic>/<italic>z</italic> features generated by this analyte. The features correspond to dehydrated ions <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mi>O</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 407), molecular molecules <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (m/z 425), sodium adducts <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 447) and potassium adducts <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 463). Each feature was simulated as <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>/</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mi mathvariant="italic">Dirchlet</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
      <p>Similarly to the RCC dataset, the tissues were split into a training set of six tissue pairs, and a validation set of two tissue pairs.</p>
      <p><bold>Simulated Dataset 2: one analyte with differential relative intensity of two of the four features, and a complex background.</bold> We mimicked a situation where tumor locations affect the relative intensities of features of a same analyte. We assumed that the synthetic analyte produced more potassium adducts in tumor locations, but more sodium adducts in healthy tissues. The simulation repeated the procedure above, while setting the mean intensity of the analyte to <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:mo>μ</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:math></inline-formula> 50 for both tumor and healthy locations, and setting the total intensity of molecular ions and dehydrated ions to <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>407</mml:mn><mml:mo>,</mml:mo><mml:mn>425</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The total intensity of adducts <inline-formula id="IE34"><mml:math id="IM34"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> was simulated from <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:mi mathvariant="italic">Dirichlet</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. Next, in the tumor locations we set the intensity of sodium adducts <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, the intensity of potassium adducts <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. In the healthy locations we set the intensity of sodium adducts <inline-formula id="IE38"><mml:math id="IM38"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, and the intensity of potassium adducts <inline-formula id="IE39"><mml:math id="IM39"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> in healthy.</p>
      <p><bold>Simulated Dataset 3: impact of biological variation, technological variation and sample size.</bold> The simulation evaluated the effect of biological and technological variation, and of the number of tissues in the training set, on the performance of mi-CNN. We simulated training sets with between 13 and 130 tissues, half of which annotated at the tissue level as tumor, and the other half as healthy. Each simulated tissue was characterized by 25 locations, with spectra randomly selected from the healthy tissues in the RCC experiment to represent complex background. As in Datasets 1 and 2, only half of the locations in the tumor-annotated tissues had tumor locations as the ground truth. The synthetic analyte was simulated as in <xref ref-type="disp-formula" rid="E7">Equation (6)</xref>, with <italic>μ</italic>  =  50 for the tumor locations and <italic>μ</italic>  =  150 for the healthy locations. <italic>σ<sub>S</sub></italic> varied from <inline-formula id="IE40"><mml:math id="IM40"><mml:mrow><mml:mn>0.1</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE41"><mml:math id="IM41"><mml:mrow><mml:mn>0.3</mml:mn><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ε</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> varied between <inline-formula id="IE42"><mml:math id="IM42"><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE43"><mml:math id="IM43"><mml:mrow><mml:mn>0.15</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
  </sec>
  <sec>
    <title>5 Results</title>
    <sec>
      <title>5.1 Results for the simulated datasets</title>
      <p><bold>Taking as input tissue-level annotations, mi-CNN accurately classified subtissue labels.</bold> We compared the ability of mi-CNN and mi-SVM, and that of the classical CNN and SVM, to classify subtissue labels on Simulated Dataset 1. <xref rid="btaa436-T1" ref-type="table">Table 1</xref> shows that SVM and CNN had high accuracy when comparing the classified locations to tissue-level annotations in the training set. This is expected, as the methods were trained to minimize the classification loss with respect to tissue-level annotations. However, these predictive patterns were undermined by the mislabeled healthy locations in the tumor-annotated tissues of the training set. When comparing the classifications to the ground truth at the location level, the methods had worse accuracy (and worse balanced accuracy, that accounts for differences in the number of tumor and healthy locations) in both the training and the validation dataset. <xref ref-type="fig" rid="btaa436-F6">Figure 6</xref> details the predictions on the validation set. It illustrates that SVM had poor predictions for both tumor and healthy locations, while CNN had poor predictions for healthy locations.
</p>
      <fig id="btaa436-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>Simulation Dataset 1: subtissue-level classification on the validation set </p>
        </caption>
        <graphic xlink:href="btaa436f6"/>
      </fig>
      <table-wrap id="btaa436-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Simulated Dataset 1: classification accuracy</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Compare with</th>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.895 (0.895)</td>
              <td rowspan="1" colspan="1">0.948 (0.948)</td>
              <td rowspan="1" colspan="1">0.885 (0.882)</td>
              <td rowspan="1" colspan="1">0.751 (0.742)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.747 (0.833)</td>
              <td rowspan="1" colspan="1">0.747 (0.833)</td>
              <td rowspan="1" colspan="1">0.809 (0.862)</td>
              <td rowspan="1" colspan="1">0.979 (0.981)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.778 (0.671)</td>
              <td rowspan="1" colspan="1">0.752 (0.831)</td>
              <td rowspan="1" colspan="1">0.833 (0.693)</td>
              <td rowspan="1" colspan="1">0.975 (0.964)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note</italic>: Accuracy [<xref ref-type="disp-formula" rid="E5">Equation (4)]</xref> and balanced accuracy [in parentheses, <xref ref-type="disp-formula" rid="E6">Equation (5)]</xref>. The first two rows evaluate the accuracy with respect to tissue-level annotations. The last four rows evaluate the accuracy with respect to labels of within-tissue locations.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Although the accuracy of mi-SVM and mi-CNN classification compared with tissue-level annotations was lower than that of SVM and CNN (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Row 1 and 2), their results were closer to the ground truth location labels, both on the training (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Rows 3 and 4) and the validation sets (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Rows 5 and 6). <xref ref-type="fig" rid="btaa436-F6">Figure 6</xref> illustrates that mi-SVM, and in particular mi-CNN, classified the labels of the individual locations more correctly.</p>
      <p><xref rid="btaa436-T2" ref-type="table">Table 2</xref> shows that the results are not limited to situations when the predictive analyte is differentially abundant. Qualitatively similar results are obtained with the predictive pattern in Simulated Dataset 2.</p>
      <p><bold>mi-CNN improved subtissue classification by leveraging changes in relative abundances of features from a same analyte.</bold><xref rid="btaa436-T1" ref-type="table">Tables 1</xref> and <xref rid="btaa436-T2" ref-type="table">2</xref> show that mi-CNN and CNN had higher classification accuracy with respect to the location labels as compared to mi-SVM and SVM. To evaluate whether the improved accuracy was due to the CNN’s ability to capture the contextual relationships between related <italic>m</italic>/<italic>z</italic>, we ranked the predictive features by their importance in these methods using LIME. <xref ref-type="fig" rid="btaa436-F7">Figure 7</xref> compares the relative importance of the top five features, when classifying a tumor location in one tissue with mi-SVM and mi-CNN. Both methods classified this location correctly. However, while in mi-SVM the most predictive feature is part of the background, mi-CNN ranked the <italic>m</italic>/<italic>z</italic> features (407, 425, 447 and 463) of the synthetic differentially abundant analyte among the top five most predictive.
</p>
      <fig id="btaa436-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Simulated Dataset 1: LIME-based importance of <italic>m</italic>/<italic>z</italic> features when classifying a tumor location in the validation set. A location in the simulated tissue UH9912_01 was classified correctly by both mi-SVM and mi-CNN. However, only mi-CNN captured the four <italic>m</italic>/<italic>z</italic> features (407, 425, 447 and 463) from the synthetic differentially abundant analyte. (<bold>a</bold>) mi-SVM and (<bold>b</bold>) mi-CNN</p>
        </caption>
        <graphic xlink:href="btaa436f7"/>
      </fig>
      <table-wrap id="btaa436-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Simulated Dataset 2: classification accuracy</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Compare with</th>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.532 (0.530)</td>
              <td rowspan="1" colspan="1">0.778 (0.777)</td>
              <td rowspan="1" colspan="1">0.860 (0.856)</td>
              <td rowspan="1" colspan="1">0.700 (0.690)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.565 (0.538)</td>
              <td rowspan="1" colspan="1">0.734 (0.810)</td>
              <td rowspan="1" colspan="1">0.758 (0.776)</td>
              <td rowspan="1" colspan="1">0.877 (0.800)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.530 (0.449)</td>
              <td rowspan="1" colspan="1">0.869 (0.896)</td>
              <td rowspan="1" colspan="1">0.771 (0.500)</td>
              <td rowspan="1" colspan="1">0.912 (0.701)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic>Note</italic>: As <xref rid="btaa436-T1" ref-type="table">Table 1</xref>, for Simulated Dataset 2.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Out of 200 randomly selected locations, mi-CNN consistently ranked all these features among the top five most predictive in 32.3% of the locations, and at least one of these features among the top five most predictive in 99.3% of the locations. The respective numbers for mi-SVM were very low, 0% and 6%. This illustrates the utility of incorporating the domain-specific information in the size of the convolution filter in the neural network.</p>
      <p><bold>In presence of larger variation, accurate subtissue-level classification with mi-CNN required a larger sample size.</bold> We evaluated the accuracy of mi-CNN with respect to subtissue labels on Simulated Dataset 3. <xref ref-type="fig" rid="btaa436-F8">Figure 8a</xref> shows that, in situations where both between-tissue and within-tissue variation is relatively small, mi-CNN can have a high classification accuracy on the validation set, even when trained on a relatively small number of 12 biological replicates. <xref ref-type="fig" rid="btaa436-F8">Figure 8c and d</xref> illustrates that the between-tissue variation dominates the classification accuracy, and the within-tissue variation has a relatively small impact. Including more biological replicates is beneficial when variation is large.
</p>
      <fig id="btaa436-F8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>Simulated Dataset 3: impact of biological (a,b) and technological variation (c,d) of the synthetic analyte, and of the number of training set tissues, on the accuracy of mi-CNN with respect to subtissue labels. When biological variation is relatively small, mi-CNN correctly classified subtissue locations, even with a small number of biological replicates in the training set. Including more biological replicates is beneficial when variation is large</p>
        </caption>
        <graphic xlink:href="btaa436f8"/>
      </fig>
    </sec>
    <sec>
      <title>5.2 Results for the experimental datasets</title>
      <p><bold>RCC experiment.</bold> Although subtissue-level ground truth was not available for the RCC experiment, we used the fact that the tissue sections annotated as healthy were expected to be free from tumor. Therefore, we evaluated the classifications with respect to the homogeneity of subtissue classification of the healthy sections. <xref ref-type="fig" rid="btaa436-F9">Figure 9</xref> illustrates that, on the training set, mi-SVM and mi-CNN both had homogeneous predictions of healthy on healthy tissue. On the validation set, mi-CNN had slightly more homogeneous predictions of healthy on healthy tissues than mi-SVM. The predictions of SVM and mi-SVM had no substantial difference in this dataset. CNN has less homogeneous predictions of healthy on healthy tissues than mi-CNN in both training and validation set. This indicates that mi-CNN can improve prediction on healthy locations by considering healthy locations in the tumor tissues.
</p>
      <fig id="btaa436-F9" orientation="portrait" position="float">
        <label>Fig. 9.</label>
        <caption>
          <p>Classification accuracy: the RCC experiment. (<bold>a</bold>) Tissue-level pathology annotations. (<bold>b</bold>) Optical images of H&amp;E stained tissues. (<bold>c-f</bold>) Subtissue-level classifications</p>
        </caption>
        <graphic xlink:href="btaa436f9"/>
      </fig>
      <p>LIME-based interpretation of mi-SVM and mi-CNN highlighted different features as highly predictive. For mi-SVM, <italic>m</italic>/<italic>z</italic> 181, 215, 760, 865 and 898 were ranked as the top 5 most important. For mi-CNN, these were <italic>m</italic>/<italic>z</italic> 217, 751, 773, 885 and 886. These results indicate that the choice of the classifier plays an important role in both predictive accuracy and the choice of predictive features in this dataset.</p>
      <p><bold>Human bladder cancer experiment.</bold><xref ref-type="fig" rid="btaa436-F10">Figure 10</xref> compares the classification of SVM, CNN, mi-SVM and mi-CNN with the ground truth subtissue-level labels on selected heterogeneous tumor tissue and pure stroma tissue. Similar to results on Simulated Datasets 1 and 2, SVM and CNN classified many stroma locations in the tumor tissue as tumor in the training dataset (see <xref ref-type="fig" rid="btaa436-F10">Fig. 10</xref>). Not surprisingly, both SVM and CNN had poor predictions in the validation set, presenting mixture predictions of tumor and stroma in the stroma tissue.
</p>
      <fig id="btaa436-F10" orientation="portrait" position="float">
        <label>Fig. 10.</label>
        <caption>
          <p>Classification accuracy: the human bladder cancer experiment. (<bold>a</bold>) Tissue-level pathology annotations. (<bold>b</bold>) Subtissue-level pathology labels on optical images. (<bold>c</bold>) Subtissue-level labels on MSI (viewed as ground truth). (<bold>d–g</bold>) Subtissue-level classifications</p>
        </caption>
        <graphic xlink:href="btaa436f10"/>
      </fig>
      <p>mi-SVM and mi-CNN improved the classification of SVM and CNN in terms of both accuracy and balanced accuracy (<xref rid="btaa436-T3" ref-type="table">Table 3</xref>). From <xref ref-type="fig" rid="btaa436-F10">Figure 10</xref>, mi-CNN correctly classified more stroma locations in the tumor tissues than mi-SVM for both training and validation tissues. In addition, mi-CNN had the smallest number of false positives on the stroma tissues, showing most clean classifications in stroma tissues in <xref ref-type="fig" rid="btaa436-F10">Figure 10</xref>.
</p>
      <table-wrap id="btaa436-T3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>Classification accuracy: the human bladder cancer experiment</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="2" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.959 (0.946)</td>
              <td rowspan="1" colspan="1">0.827 (0.946)</td>
              <td rowspan="1" colspan="1">0.939 (0.946)</td>
              <td rowspan="1" colspan="1">0.800 (0.855)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.801 (0.793)</td>
              <td rowspan="1" colspan="1">0.767 (0.759)</td>
              <td rowspan="1" colspan="1">0.847 (0.842)</td>
              <td rowspan="1" colspan="1">0.941 (0.941)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.755 (0.750)</td>
              <td rowspan="1" colspan="1">0.779 (0.774)</td>
              <td rowspan="1" colspan="1">0.827 (0.823)</td>
              <td rowspan="1" colspan="1">0.928 (0.928)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic>Note</italic>: Values without the parentheses are accuracy calculated by <xref ref-type="disp-formula" rid="E5">Equation (4)</xref>. Values in parenthesis are balanced accuracy calculated by <xref ref-type="disp-formula" rid="E6">Equation (5)</xref>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>LIME analysis of mi-CNN classifications of a subset of 200 locations in validation set selected <italic>m</italic>/<italic>z</italic> 925.44, 944.44, 946.44, 1105.54 and 1198.69 as most predictive. Among those, <italic>m</italic>/<italic>z</italic> 944.44 is likely to be Histone 2 A, which is known to be upregulated in tumors, and <italic>m</italic>/<italic>z</italic> 1105.54 is likely to correspond to Collagen I which is known to be upregulated in stroma. LIME analysis of mi-SVM selected five different predictive features, <italic>m</italic>/<italic>z</italic> 1669.73, 1475.72, 1529.7, 963.44 and 1054.49.</p>
    </sec>
  </sec>
  <sec>
    <title>6 Discussion</title>
    <p>We introduced mi-CNN, a deep MIL approach for classifying subtissue locations in MSI experiments. The multiple instance aspect of the approach enabled training the classifier with weak supervision, using rough tissue-level annotations in the training set. The convolutional architecture of the CNN captured contextual dependencies between the spectral features. Evaluations on simulated and experimental datasets demonstrated that mi-CNN improved the subtissue classification as compared with traditional SVM and CNN.</p>
    <p>The approach assumed that, in a binary classification problem, a tissue labeled as tumor had at least one tumor location, but the tissues labeled as non-tumor were tumor-free. This assumption is reasonable for MSI, as homogeneous healthy tissue biopsies are relatively easy to obtain, however tumor biopsies are more likely to contain a mix of tumor and non-tumor regions. In a case where both non-tumor and tumor tissues are heterogeneous, the proposed approach is no longer suitable since the reliable label of non-tumor is crucial to the method. Although we only discussed binary classification, mi-CNN can also be adapted to multi-class classification, such as different grades of tumor tissues or multiple tissue types.</p>
    <p>In contrast to the typical applications of CNN in computer vision, the CNN architecture in this work did not include spatial convolution of tissues. This is a consequence of typically high heterogeneity of the microenvironment within a tumor, and of lack of spatial smoothness of location labels.</p>
    <p>At the same time, the CNN architecture took advantage of the mass spectral patterns to alleviate the high dimensionality and the high correlations in the predictive feature space. In this work, the size of convolutional filters captured one of the most common sources of correlations between <italic>m</italic>/<italic>z</italic>, i.e. the presence of molecular ions and their adducts. The <italic>m</italic>/<italic>z</italic> dependencies can become more complicated and ambiguous in other cases, e.g. with larger mass ranges. The convolutional aspects can be easily adapted to such situations types by changing the size of filter and the network depth.</p>
    <p>Although neural networks have a large parameter space and need large training datasets, we found that mi-CNN worked well on the relatively small numbers of biological tissues. This may be due to a combination of the CNN architecture, which uses locally connected neurons and weight sharing filters to reduce the parameter space and the computational cost, and a relatively large number of heterogeneous subtissue locations available for training.</p>
    <p>Overall, we found that mi-CNN is well-suited for training subtissue-level classifiers on datasets with tissue-level annotations. This is particularly important in situations where tumor and non-tumor tissues are tightly connected, making manual labeling of the training sets difficult or even impossible at all. The approach is an important step toward taking a full advantage of MSI’s capability of providing molecular information, and minimizing manual labor for tissue imaging and classification.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgement</title>
    <p>We thank K. A. Bemis for helpful discussions.</p>
    <sec>
      <title>Funding</title>
      <p>The work was supported in part by the NSF [award DBI-1759736 to O.V.]; and by the German Research Council [DFG, SCHI 871/11-1 to O.S.].</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa436-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aichler</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Walch</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>) 
<article-title>MALDI imaging mass spectrometry: current frontiers and perspectives in pathology research and practice</article-title>. <source>Lab. Invest</source>., <volume>95</volume>, <fpage>422</fpage>–<lpage>431</lpage>.<pub-id pub-id-type="pmid">25621874</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Allaire</surname><given-names>J.J.</given-names></name>, <name name-style="western"><surname>Tang</surname><given-names>Y.</given-names></name></person-group> (<year>2019</year>) <italic>Tensorflow: R Interface to ‘TensorFlow’.</italic> R package version 2.0.0.</mixed-citation>
    </ref>
    <ref id="btaa436-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Andrews</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>Support vector machines for multiple-instance learning</article-title>. In: <italic>Advances in Neural Information Processing Systems</italic>, p. <fpage>577</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Behrmann</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Deep learning for tumor classification in imaging mass spectrometry</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1215</fpage>–<lpage>1223</lpage>.<pub-id pub-id-type="pmid">29126286</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Cardinal: an R package for statistical analysis of mass spectrometry-based imaging experiments</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>2418</fpage>–<lpage>2420</lpage>.<pub-id pub-id-type="pmid">25777525</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Probabilistic segmentation of mass spectrometry images helps select important ions and characterize confidence in the resulting segments</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>15</volume>, <fpage>1761</fpage>–<lpage>1772</lpage>.<pub-id pub-id-type="pmid">26796117</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.A.</given-names></name></person-group> (<year>2019</year>) <italic>CardinalWorkflows: Datasets and Workflows for the Cardinal Mass Spectrometry Imaging Package</italic>. R package version 1.17.0.</mixed-citation>
    </ref>
    <ref id="btaa436-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Calligaris</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MALDI mass spectrometry imaging analysis of pituitary adenomas for near-real-time tumor delineation</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>112</volume>, <fpage>9978</fpage>–<lpage>9983</lpage>.<pub-id pub-id-type="pmid">26216958</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cheplygina</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Not-so-supervised: a survey of semi-supervised, multi-instance, and transfer learning in medical image analysis</article-title>. <source>Med. Image Anal</source>., <volume>54</volume>, <fpage>280</fpage>–<lpage>296</lpage>.<pub-id pub-id-type="pmid">30959445</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dill</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Multivariate statistical differentiation of renal cell carcinomas based on lipidomic analysis by ambient ionization imaging mass spectrometry</article-title>. <source>Anal. Bioanal. Chem</source>., <volume>398</volume>, <fpage>2969</fpage>–<lpage>2978</lpage>.<pub-id pub-id-type="pmid">20953777</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dill</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Multivariate statistical identification of human bladder carcinomas using ambient ionization imaging mass spectrometry</article-title>. <source>Chemistry</source>, <volume>17</volume>, <fpage>2897</fpage>–<lpage>2902</lpage>.<pub-id pub-id-type="pmid">21284043</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Eberlin</surname><given-names>L.S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Molecular assessment of surgical-resection margins of gastric cancer by mass-spectrometric imaging</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>111</volume>, <fpage>2436</fpage>–<lpage>2441</lpage>.<pub-id pub-id-type="pmid">24550265</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Föll</surname><given-names>M.C.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Reproducible mass spectrometry imaging data analysis in Galaxy</article-title>. <source>GigaScience</source>, <volume>8</volume>, <fpage>628719</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fu</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>MILIS: multiple instance learning with instance selection</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>33</volume>, <fpage>958</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gibb</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>) 
<article-title>MALDIQUANT: a versatile R package for the analysis of mass spectrometry data</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>2270</fpage>–<lpage>2271</lpage>.<pub-id pub-id-type="pmid">22796955</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Inglese</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Deep learning and 3D-DESI imaging reveal the hidden metabolic heterogeneity of cancer</article-title>. <source>Chem. Sci</source>., <volume>8</volume>, <fpage>3500</fpage>–<lpage>3511</lpage>.<pub-id pub-id-type="pmid">28507724</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>E.A.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Imaging mass spectrometry statistical analysis</article-title>. <source>J. Proteomics</source>, <volume>75</volume>, <fpage>4962</fpage>–<lpage>4989</lpage>.<pub-id pub-id-type="pmid">22743164</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kandemir</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Hamprecht</surname><given-names>F.A.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Computer-aided diagnosis from weak supervision: a benchmarking study</article-title>. <source>Comput. Med. Imaging Graph</source>., <volume>42</volume>, <fpage>44</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">25475486</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kriegsmann</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MALDI TOF imaging mass spectrometry in clinical pathology: a valuable tool for cancer diagnostics (review)</article-title>. <source>Int. J. Oncol</source>., <volume>46</volume>, <fpage>893</fpage>–<lpage>906</lpage>.<pub-id pub-id-type="pmid">25482502</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lou</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>An experimental guideline for the analysis of histologically heterogeneous tumors by MALDI-TOF mass spectrometry imaging</article-title>. <source>Biochim. Biophys. Acta Proteins Proteom</source>., <volume>1865</volume>, <fpage>957</fpage>–<lpage>966</lpage>.<pub-id pub-id-type="pmid">27725306</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B21">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Molnar</surname><given-names>C.</given-names></name></person-group> (<year>2019</year>) <italic>Interpretable Machine Learning</italic>. Lulu. com.</mixed-citation>
    </ref>
    <ref id="btaa436-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Pedersen</surname><given-names>T.L.</given-names></name>, <name name-style="western"><surname>Benesty</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>) <italic>LIME: Local Interpretable Model-Agnostic Explanations</italic>. R package version 0.5.1.</mixed-citation>
    </ref>
    <ref id="btaa436-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rauser</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Classification of HER2 receptor status in breast cancer tissues by MALDI imaging mass spectrometry</article-title>. <source>J. Proteome Res</source>., <volume>9</volume>, <fpage>1854</fpage>–<lpage>1863</lpage>.<pub-id pub-id-type="pmid">20170166</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rawat</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Deep convolutional neural networks for image classification: a comprehensive review</article-title>. <source>Neural Comput</source>., <volume>29</volume>, <fpage>2352</fpage>–<lpage>2449</lpage>.<pub-id pub-id-type="pmid">28599112</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ribeiro</surname><given-names>M.T.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>“Why should I trust you?” Explaining the predictions of any classifier</article-title>. In: <italic>22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>, p. <fpage>1135</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sans</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Metabolic markers and statistical prediction of serous ovarian cancer aggressiveness by ambient ionization mass spectrometry imaging</article-title>. <source>Cancer Res</source>., <volume>77</volume>, <fpage>2903</fpage>–<lpage>2913</lpage>.<pub-id pub-id-type="pmid">28416487</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Spengler</surname><given-names>B.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Mass spectrometry imaging of biomolecular information</article-title>. <source>Anal. Chem</source>., <volume>87</volume>, <fpage>64</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">25490190</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>van Kersbergen</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Cancer detection in mass spectrometry imaging data by dilated convolutional neural networks</article-title>. In: <italic>Medical Imaging 2019: Digital Pathology</italic>, Vol. <volume>10956</volume>, p. 109560I, International Society for Optics and Photonics.</mixed-citation>
    </ref>
    <ref id="btaa436-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vaysse</surname><given-names>P.M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Mass spectrometry imaging for clinical research-latest developments, applications, and current limitations</article-title>. <source>Analyst</source>, <volume>142</volume>, <fpage>2690</fpage>–<lpage>2712</lpage>.<pub-id pub-id-type="pmid">28642940</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wu</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Mass spectrometry imaging under ambient conditions</article-title>. <source>Mass Spectrom. Rev</source>., <volume>32</volume>, <fpage>218</fpage>–<lpage>243</lpage>.<pub-id pub-id-type="pmid">22996621</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Multiple instance boosting for object detection</article-title>. In: <italic>Advances in Neural Information Processing Systems</italic>, p. <fpage>1417</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>Z.-H.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Multi-instance learning by treating instances as non-IID samples</article-title>. In: <italic>Proceedings of the 26th Annual International Conference on Machine Learning</italic>, p. <fpage>1249</fpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355295</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa436</article-id>
    <article-id pub-id-type="publisher-id">btaa436</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Macromolecular Sequence, Structure, and Function</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep multiple instance learning classifies subtissue locations in mass spectrometry images from tissue-level annotations</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Guo</surname>
          <given-names>Dan</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Föll</surname>
          <given-names>Melanie Christine</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Volkmann</surname>
          <given-names>Veronika</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Enderle-Ammour</surname>
          <given-names>Kathrin</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bronsert</surname>
          <given-names>Peter</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
        <xref ref-type="aff" rid="btaa436-aff4">b4</xref>
        <xref ref-type="aff" rid="btaa436-aff5">b5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schilling</surname>
          <given-names>Oliver</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vitek</surname>
          <given-names>Olga</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff1">b1</xref>
        <xref ref-type="corresp" rid="btaa436-cor1"/>
        <!--<email>o.vitek@neu.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa436-aff1"><label>b1</label><institution>Khoury College of Computer Sciences, Northeastern University</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
    <aff id="btaa436-aff2"><label>b2</label><institution>Institute for Surgical Pathology, Medical Center – University of Freiburg</institution>, 79106 Freiburg, <country country="DE">Germany</country></aff>
    <aff id="btaa436-aff3"><label>b3</label><institution>Faculty of Medicine, University of Freiburg</institution>, 79110 Freiburg, <country country="DE">Germany</country></aff>
    <aff id="btaa436-aff4">
      <label>b4</label>
      <institution>Tumorbank Comprehensive Cancer Center Freiburg, Medical Center – University of Freiburg</institution>
    </aff>
    <aff id="btaa436-aff5"><label>b5</label><institution>German Cancer Consortium (DKTK) and Cancer Research Center (DKFZ)</institution>, 79106 Freiburg, <country country="DE">Germany</country></aff>
    <author-notes>
      <corresp id="btaa436-cor1">To whom correspondence should be addressed. E-mail: <email>o.vitek@neu.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i300</fpage>
    <lpage>i308</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa436.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Mass spectrometry imaging (MSI) characterizes the molecular composition of tissues at spatial resolution, and has a strong potential for distinguishing tissue types, or disease states. This can be achieved by supervised classification, which takes as input MSI spectra, and assigns class labels to subtissue locations. Unfortunately, developing such classifiers is hindered by the limited availability of training sets with subtissue labels as the ground truth. Subtissue labeling is prohibitively expensive, and only rough annotations of the entire tissues are typically available. Classifiers trained on data with approximate labels have sub-optimal performance.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To alleviate this challenge, we contribute a semi-supervised approach <italic>mi-CNN</italic>. mi-CNN implements multiple instance learning with a convolutional neural network (CNN). The multiple instance aspect enables weak supervision from tissue-level annotations when classifying subtissue locations. The convolutional architecture of the CNN captures contextual dependencies between the spectral features. Evaluations on simulated and experimental datasets demonstrated that mi-CNN improved the subtissue classification as compared to traditional classifiers. We propose mi-CNN as an important step toward accurate subtissue classification in MSI, enabling rapid distinction between tissue types and disease states.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The data and code are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Vitek-Lab/mi-CNN_MSI">https://github.com/Vitek-Lab/mi-CNN_MSI</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSF</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>DBI-1759736</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>German Research Council</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>DFG</institution>
            <institution-id institution-id-type="DOI">10.13039/100004807</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>SCHI 871/11-1</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Biochemical constitution of tissues varies with tissue types (such as epithelial and connective tissues), or disease states (such as tumor and healthy tissues). Mass spectrometry imaging (MSI) provides an untargeted characterization of the molecular composition of such tissues at spatial resolution, simultaneously quantifying hundreds of analytes without the need for chemical labels or antibodies (<xref rid="btaa436-B27" ref-type="bibr">Spengler, 2015</xref>; <xref rid="btaa436-B17" ref-type="bibr">Jones <italic>et al.</italic>, 2012</xref>). Therefore, MSI has a strong potential to become a rapid diagnostic technology in the clinic (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>).</p>
    <p>Although the name of the technology contains the word ‘image’, the structure of MSI data is very different from other bioimaging technologies (<xref ref-type="fig" rid="btaa436-F1">Fig. 1</xref>). In MSI, mass spectra are acquired at thousands of different spatial <italic>locations</italic> in a raster pattern throughout the tissue. MSI techniques fall into two major categories: matrix-assisted laser desorption/ionization (MALDI) MSI (<xref rid="btaa436-B1" ref-type="bibr">Aichler and Walch, 2015</xref>) and desorption electrospray ionization (DESI) MSI (<xref rid="btaa436-B30" ref-type="bibr">Wu <italic>et al.</italic>, 2013</xref>). With each technique, the mass spectrum obtained at each location is a collection of <italic>features</italic>, corresponding to the ions of biochemical analytes such as metabolites, lipids, peptides and proteins. The features do not contain direct information regarding the identity of the underlying analyte, except for their ratios of mass over charge <italic>m</italic>/<italic>z</italic>. For one tissue location, a typical MSI experiment reports hundreds to thousands of <italic>m</italic>/<italic>z</italic> in ascending order. The intensities of the <italic>m</italic>/<italic>z</italic> correlate with the abundance of the analyte. A plot of the abundance of one <italic>m</italic>/<italic>z</italic> across all locations is referred to as an <italic>ion image</italic>.
</p>
    <fig id="btaa436-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>MSI data. (<bold>a</bold>) H&amp;E-stained optical images of a pair of tumor and healthy tissues from the human renal cell carcinoma (RCC) experiment. (<bold>b</bold>) Mass spectrum from one location in the tumor tissue. The inset zooms into <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mi>m</mml:mi><mml:mo>/</mml:mo><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Two features with <italic>m</italic>/<italic>z</italic> shift <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>22</mml:mn></mml:mrow></mml:math></inline-formula> can correspond to molecular ions and sodium adducts. Two features with <italic>m</italic>/<italic>z</italic> shift <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>38</mml:mn></mml:mrow></mml:math></inline-formula> can correspond to molecular ions and potassium adducts. (<bold>c</bold>) Ion images of <italic>m</italic>/<italic>z</italic> 215 of the tissues in (a)</p>
      </caption>
      <graphic xlink:href="btaa436f1"/>
    </fig>
    <p>A reliable diagnostics can be achieved by supervised classification models that take as input the observed mass spectra, and predict labels such as tumor, healthy or tumor subtypes. Beyond <italic>tissue-level classification</italic> (classifying the entire tissues), <italic>subtissue-level classification</italic> (classifying the disease status of individual locations within the tissues) is of most interest. Ranking <italic>m</italic>/<italic>z</italic> features by their predictive ability is also important. Currently, training subtissue-level classifiers providing this information requires training sets of tissues with reliable <italic>subtissue labels</italic>.</p>
    <p>Unfortunately, accessing a training set with reliable subtissue labels is challenging in practice. In a typical workflow, pathologists examine the hematoxylin and eosin (H&amp;E)-stained optical images such as in <xref ref-type="fig" rid="btaa436-F1">Figure 1a</xref>. To obtain subtissue labels, the pathologist must manually examine and annotate the distinct regions of each tissue (<xref rid="btaa436-B20" ref-type="bibr">Lou <italic>et al.</italic>, 2017</xref>). The cost of manual work is one of the reasons to the relatively small number of biological replicates in MSI. The procedure is particularly costly for heterogeneous tissues that require labeling of multiple small sub-regions, or for tissues with challenging histology. To be transferrable to MSI, the subtissue labeling must use specialized software that takes time to learn. As the result, pathologists often avoid labeling the individual locations, and only roughly annotate the entire tissues. <xref ref-type="fig" rid="btaa436-F1">Figure 1c</xref> shows that, although the tissue on the left is annotated as tumor, the ion image indicates tissue heterogeneity, and the tissue likely contains both cancerous tissue and healthy kidney parenchyma. Such imprecise labeling of tissue locations compromises the accuracy of the resulting classifiers.</p>
    <p>In addition to the labeling, high correlations between many <italic>m</italic>/<italic>z</italic> limit our ability to train accurate classifiers on MSI data. For example, in peptide MSI proteins are digested to give rise to multiple peptide ions of a same protein, and therefore have similar spatial distributions of abundance. An analyte can also produce multiple <italic>m</italic>/<italic>z</italic> ions for other reasons, that include sodium adducts, neutral loss ions, fragment ions or multiply charged ions. For example, <xref ref-type="fig" rid="btaa436-F1">Figure 1b</xref> illustrates the potential sodium and potassium adducts that give rise to correlated features. The high correlation in the high-dimensional vector of <italic>m</italic>/<italic>z</italic> features undermines the stability of the classifiers, and leads to overfitting (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>).</p>
    <p>To improve our ability to accurately classify subtissue locations in MSI from approximate tissue-level annotations, we propose a semi-supervised approach <italic>mi-convolutional neural network (CNN)</italic>. mi-CNN implements multiple instance learning (MIL) with a CNN. The multiple instance aspect of the approach enables weak supervision from tissue-level annotations when classifying subtissue labels. The convolutional architecture of the CNN captures potential contextual dependencies between <italic>m</italic>/<italic>z</italic>, such as sodium adducts and dehydrated ions. Evaluations on simulated and experimental datasets demonstrate that mi-CNN improved the subtissue classification as compared with traditional classifiers such as support vector machine (SVM) and CNN, and successfully reflected the truly predictive spectral features. We propose mi-CNN as an important step toward accurate subtissue classification in basic biology and clinical applications of MSI.</p>
  </sec>
  <sec>
    <title>2 Background</title>
    <sec>
      <title>2.1 Subtissue-level classification in MSI</title>
      <p>Classifying tissue locations using MSI spectra has already received a lot of attention (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>). Various classifiers have been proposed for these task, including linear discriminant analysis (<xref rid="btaa436-B10" ref-type="bibr">Dill <italic>et al.</italic>, 2010</xref>, <xref rid="btaa436-B11" ref-type="bibr">2011</xref>), regularized logistic regression (<xref rid="btaa436-B12" ref-type="bibr">Eberlin <italic>et al.</italic>, 2014</xref>; <xref rid="btaa436-B26" ref-type="bibr">Sans <italic>et al.</italic>, 2017</xref>), SVM (<xref rid="btaa436-B8" ref-type="bibr">Calligaris <italic>et al.</italic>, 2015</xref>), and many others. Variations of these approaches such as nearest shrunken centroids (<xref rid="btaa436-B6" ref-type="bibr">Bemis <italic>et al.</italic>, 2016</xref>) incorporate spatial smoothing to enhance the spatial stability of the results. The classifiers take as input <italic>m</italic>/<italic>z</italic> features at each location, classify the label of each location, and classify the tissues according to the majority of its location labels.</p>
      <p>Recently, neural networks became of a great interest for MSI. <xref rid="btaa436-B23" ref-type="bibr">Rauser <italic>et al.</italic> (2010)</xref> used fully connected neural networks for tumor classification, and <xref rid="btaa436-B16" ref-type="bibr">Inglese <italic>et al.</italic> (2017)</xref> used unsupervised neural networks to cluster tumor tissues. CNNs, a class of deep neural networks originally designed for image classification, were also introduced. CNN convolutes the image using a small-sized kernel to capture the local connectivity within an image (<xref rid="btaa436-B24" ref-type="bibr">Rawat and Wang, 2017</xref>). A novel application of CNN to MSI proposed to view mass spectra as 1D images. <xref rid="btaa436-B4" ref-type="bibr">Behrmann <italic>et al.</italic> (2018)</xref> used a modified Residual Net with 13 935 parameters and kernel size of 3 to capture isotopic patterns in mass spectra. <xref rid="btaa436-B28" ref-type="bibr">van Kersbergen <italic>et al.</italic> (2019)</xref> replaced convolutional layers in Behrmann’s network with dilated convolutional layers to increase receptive size, and capture globally distributed patterns in the spectra.</p>
      <p>Although the approaches above are quite diverse, they all rely on quality subtissue labels for training. As the result, they are undermined by training sets with approximate annotations, such as in <xref ref-type="fig" rid="btaa436-F1">Figure 1</xref>.</p>
    </sec>
    <sec>
      <title>2.2 Multiple instance learning (MIL)</title>
      <p>Multiple instance learning is a semi-supervised framework commonly used in a variety of applications such as image and video analysis (<xref rid="btaa436-B9" ref-type="bibr">Cheplygina <italic>et al.</italic>, 2019</xref>) and computer-aided diagnosis (<xref rid="btaa436-B14" ref-type="bibr">Fu <italic>et al.</italic>, 2010</xref>; <xref rid="btaa436-B18" ref-type="bibr">Kandemir and Hamprecht, 2015</xref>), but so far not utilized for MSI. In contrast to the classifiers above, MIL allows weak supervision of the training data. The approach considers groups of observations, called <italic>bags</italic>, where ground-truth labels are only available at the bag level. The labels of the observations in a bag, called <italic>instances</italic>, are unknown. In a binary classification problem MIL assumes that a positive bag contains at least one positive instance, but the negative bags contain only negative instances. The homogeneity of the data in the negative bags is the key feature of the approach that enables efficient learning.</p>
      <p>Existing MIL algorithms can be classified into two groups: bag space algorithms and instance space algorithm. Bag space algorithms, such as mi-Graph (<xref rid="btaa436-B32" ref-type="bibr">Zhou <italic>et al.</italic>, 2009</xref>) and MIL with instance (<xref rid="btaa436-B14" ref-type="bibr">Fu <italic>et al.</italic>, 2010</xref>), do not predict labels of individual instances. They classify the bags directly by considering similarities of input features between the bags. Instance space algorithms, such as mi-SVM (<xref rid="btaa436-B3" ref-type="bibr">Andrews <italic>et al.</italic>, 2003</xref>) and MILboost (<xref rid="btaa436-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2006</xref>), take features of the instances as input and predict labels of both instances and bags. For instance-level prediction, mi-SVM is one of the most accurate methods (<xref rid="btaa436-B18" ref-type="bibr">Kandemir and Hamprecht, 2015</xref>). The method treats labels of instances in positive bags as latent variables, and estimates them from the data. Parameters of SVM are optimized by iteratively training SVM on the current instance-level labels, and updating the instance-level labels from their predictions by the current SVM.</p>
    </sec>
    <sec>
      <title>2.3 Interpretation of black-box machine learning models</title>
      <p>Many of the classification approaches above function like a ‘black box’ and lack interpretability. Post-processing of these models (<xref rid="btaa436-B21" ref-type="bibr">Molnar, 2019</xref>) helps characterize the relative importance of each predictive feature after the model is fit. One such approach is Local Interpretable Model-agnostic Explanation (LIME; <xref rid="btaa436-B25" ref-type="bibr">Ribeiro <italic>et al.</italic>, 2016</xref>), which ranks features by their importance in predicting the label of a particular observation of interest. LIME generates new observations by permuting the values of the predictive features in the dataset, and obtains the black box predictions for these new observations. Next, LIME weights the new observations by their proximity to the observation of interest, and trains a weighted interpretable model (such as linear regression with subset selection or regularization) on the new observations and their predictions. Finally, LIME repeats this procedure multiple times, and ranks the features by their frequency of being selected as predictive.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Multiple instance learning with convolutional neural network (mi-CNN) </title>
    <sec>
      <title>3.1 Overview</title>
      <p>For the purposes of subtissue classification in MSI, we propose to view a <italic>tissue</italic> as a bag, and a tissue <italic>location</italic> as an instance. We assume that tissues annotated as non-tumor do not have tumor locations, but tissues annotated as tumor can have both tumor and non-tumor locations. MIL allows us to train classifiers of subtissue locations on training sets with such rough tissue-level annotations. Instance space algorithms are of a particular interest for this task. Our proposed approach takes as the baseline mi-SVM, which reported high classification accuracy on similar tasks in the past, but substitutes the SVM classifier with a CNN (<xref ref-type="fig" rid="btaa436-F2">Fig. 2</xref>). Although CNN are frequently used for image analyses in computer vision domains, the proposed approach uses CNN is a different way. We do not apply spatial convolution on a tissue, as we expect high heterogeneity of the microenvironment within a tumor, and an insufficient spatial smoothness of the location labels. Instead, the CNN incorporates convolutional filters to <italic>m</italic>/<italic>z</italic> in individual locations to capture potential correlations between <italic>m</italic>/<italic>z</italic> of a same location. The CNN has a lightweight structure to avoid overfitting. Finally, post-processing with LIME identifies highly predictive <italic>m</italic>/<italic>z</italic> for downstream biological and clinical interpretation.
</p>
      <fig id="btaa436-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Architecture of mi-CNN. <italic>π<sub>j</sub></italic> the probability that tissue <italic>j</italic> belongs to Class 1, and <italic>π<sub>ij</sub></italic> is the corresponding probability for the location <italic>i</italic> in that tissue. (<bold>a</bold>) Training set and (<bold>b</bold>) validation set</p>
        </caption>
        <graphic xlink:href="btaa436f2"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Notation</title>
      <p>Consider tissue <italic>j</italic> and its locations <italic>i</italic>. The tissue is characterized by a collection of mass spectra <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, and each mass spectrum <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a vector of <italic>M</italic> intensities of <italic>m</italic>/<italic>z</italic> features <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Let <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> denote the annotation of the tissue <italic>j</italic>, and <italic>y<sub>ij</sub></italic> the subtissue label at the <italic>i</italic>th location. Note that <italic>Y<sub>j</sub></italic> is known, and <italic>y<sub>ij</sub></italic> is unknown. Denote <italic>π<sub>j</sub></italic> the probability that tissue <italic>j</italic> belongs to Class 1, and <italic>π<sub>ij</sub></italic> is the corresponding probability for the location <italic>i</italic> in that tissue. Given a mass spectrum <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, our goal is to predict the label <italic>y<sub>ij</sub></italic> of this location, and the label <italic>Y<sub>j</sub></italic> of the entire tissue.</p>
    </sec>
    <sec>
      <title>3.3 Subtissue-level classification</title>
      <p>Using cross-entropy as the loss function, the objective of MIL is defined as
<disp-formula id="E1"><mml:math id="M1"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo>Θ</mml:mo></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="E2"><label>(1)</label><mml:math id="M2"><mml:mrow><mml:mtext mathvariant="bold">such</mml:mtext><mml:mo> </mml:mo><mml:mtext mathvariant="bold">that</mml:mtext><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the prediction of a classifier (a CNN) with parameters Θ.</p>
      <p>Since the subtissue labels <italic>y<sub>ij</sub></italic> are not observed, they are estimated by an expectation–maximization-like algorithm (Algorithm 1, similar to mi-SVM in Andrews <italic>et al.</italic>, 2003) minimizing the entropy loss [<xref ref-type="disp-formula" rid="E2">Equation (1)]</xref>. First, the labels of all subtissue locations are initialized with the annotations of the corresponding tissues. Next, the algorithm iterates between training CNN on the current location labels, estimating the probability <italic>π<sub>ij</sub></italic> that location <italic>i</italic> in tissue <italic>j</italic> belong to Class 1, and imputing the location labels <italic>y<sub>ij</sub></italic> from these probabilities until convergence. The constraint in <xref ref-type="disp-formula" rid="E2">Equation (1)</xref> ensures that the labels of non-tumor locations in non-tumor tissues are always classified as non-tumor. On the other hand, if no locations on a tumor tissue are classified as tumor, the location with the highest <italic>π<sub>ij</sub></italic> in this tissue will be labeled as tumor (Lines 7–10, Algorithm 1). The algorithm stops when the number of updated labels is below a threshold, or when the maximum number of iterations is reached.<boxed-text id="btaa436-BOX1" position="float" orientation="portrait"><sec><title><bold>Algorithm 1</bold> <italic>mi-CNN</italic></title><p>1: <bold>procedure</bold> mi-CNN(<inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, threshold)</p><p>2:  Initialize: <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:math></inline-formula></p><p>3:  <bold>while</bold> the number of updated labels &lt; threshold <bold>do</bold></p><p>4:   Compute CNN parameters Θ for current labels <italic>y<sub>ij</sub></italic></p><p>5:   Compute <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p><p>6:   For each <italic>j</italic> where <italic>Y<sub>j</sub></italic> = 1, set <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>ifelse</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p><p>7:   <bold>for</bold> each <italic>j</italic> where <italic>Y <sub>j</sub></italic> = 1 <bold>do</bold></p><p>8:    <bold>if</bold><inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula><bold>then</bold></p><p>9:     Compute <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="italic">arg</mml:mi><mml:munder><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p><p>10:     Set <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></p><p>11:    <bold>end if</bold></p><p>12:   <bold>end for</bold></p><p>13:  <bold>end while</bold></p><p>14:  OUTPUT (<inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>)</p><p>15: <bold>end procedure</bold></p></sec></boxed-text>The architecture of CNN must be adapted to the specifics of the MSI. In these experiments the number of <italic>m</italic>/<italic>z</italic> features can be very large (up to one hundred thousand), while the number of biological replicates is relatively small (typically &lt; 50). Therefore, the CNN should be relatively lightweight, and minimize the number of parameters to avoid overfitting. The convolution filter should be large enough to incorporate neighboring <italic>m</italic>/<italic>z</italic>, but small enough to benefit from weight sharing and computation reduction.</p>
      <p>We propose a 1D CNN, consisting of three basic components, namely convolutional layers, pooling layers and fully connected layers. Three convolutional layers hierarchically learn the potential patterns in a mass spectrum. For each layer, the filter size is set according to the contextual dependencies between <italic>m</italic>/<italic>z</italic> of interest, such as mass shifts corresponding to sodium adducts and molecular ions. After each convolutional layer, maxpooling reduces the resolution of the previous layer by focusing on large intensities of <italic>m</italic>/<italic>z</italic> features and reducing the impact of spectral noise. The CNN includes only one fully connected layer that captures globally distributed patterns (<xref ref-type="fig" rid="btaa436-F2">Fig. 2</xref>). <italic>Softmax</italic> activation function is used in the output layer to generate probability of each class.</p>
      <p>The CNN is trained using stochastic gradient descent. It calculates the partial derivative of the loss function in <xref ref-type="disp-formula" rid="E2">Equation (1)</xref> with respect to the learnable parameters in Θ by backpropagation, and iteratively updates Θ and values in each layer until convergence.</p>
      <p><bold>Tissue-level classification.</bold> The proposed tissue-level classification does not count the proportion of predicted location labels in a tissue. Instead, it treats each tissue as one observation, and uses the collection of mass spectra <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from all the locations in the tissue as its predictive features. The CNN architecture for this task is the same as the architecture for subtissue-level classification, with the exception of combining the probabilities of the individual locations into a pooling layer that estimates the probability of a tissue-level label. The pooling can be a simple max or mean pooling, or a generalized mean pooling
<disp-formula id="E3"><label>(2)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>r</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>I<sub>j</sub></italic> is the number of locations on tissue <italic>j</italic>, and <italic>r</italic> is an integer tuning parameter. The loss function is the cross-entropy of tissue-level predictions and tissue-level labels
<disp-formula id="E4"><label>(3)</label><mml:math id="M4"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo>Θ</mml:mo></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mi>J</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>π<sub>j</sub></italic> is pooled probability of <italic>π<sub>ij</sub></italic>, and <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are the predicted probabilities by CNN.</p>
    </sec>
    <sec>
      <title>3.4 Evaluation and interpretation</title>
      <p>We evaluate the accuracy of subtissue classification by calculating the accuracy and the balanced accuracy of label predictions at individual locations. We evaluate the accuracy of tissue-level classification by calculating the accuracy and the balanced accuracy of label predictions at the entire tissues. The metrics are defined as
<disp-formula id="E5"><label>(4)</label><mml:math id="M5"><mml:mrow><mml:mtext>Accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(5)</label><mml:math id="M6"><mml:mrow><mml:mtext>Balanced</mml:mtext><mml:mo> </mml:mo><mml:mtext>accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mtext>TN</mml:mtext></mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where for subtissue-level classification, <italic>TP</italic> is the number of correctly classified positive (i.e. tumor) locations across all the tissues, <italic>TN</italic> is the number of correctly classified negative (i.e. non-tumor) locations across all the tissues. <italic>P</italic> and <italic>N</italic> are the total numbers of locations across the tissues classified as tumor or non-tumor respectively. For tissue-level classification, <italic>TP</italic>, <italic>TN</italic>, <italic>P</italic> and <italic>N</italic> have the same interpretation, but for the entire tissues. Accuracy quantifies the overall proportion of correct predictions by model. When the number of observations in each class is not balanced, and the prediction of a minority class is under-represented, overall accuracy may inaccurately characterize the performance. In this case, balanced accuracy, quantifying the average of individual proportions of correct predictions in each class may provide more insights.</p>
      <p>Even when we can report the accuracy of classification, the classifier remains a black box. Therefore, we use LIME to assist with the interpretation, and identify <italic>m</italic>/<italic>z</italic> features that play a particularly important role in classifying the labels of individual locations. We randomly select a subset of locations in the validation sets in our experiments, use LIME to select top five influential features for each location, and rank the selected features by frequency of being selected in multiple locations.</p>
    </sec>
    <sec>
      <title>3.5 Implementation</title>
      <p>We implemented <italic>mi-CNN</italic> using Tensorflow (<xref rid="btaa436-B2" ref-type="bibr">Allaire and Tang, 2019</xref>) in the RStudio environment. We constructed a CNN architecture of three convolutional layers with Rectified Linear Unit (ReLU) activation, and a fully connected layer. The filter sizes of each convolutional layer were set as 38, 18 and 16. The network had 1774 trainable parameters in total for an input length of 850. CNN were trained using batch stochastic gradient descent optimization. Training one epoch of the renal cell carcinoma (RCC) dataset with 5350 spectra took ∼10 s, and training the entire model took ∼1.5 h on a computer with 64 RAM and 3.6 GHz CPU. Baseline model mi-SVM was implemented in R following (Andrews <italic>et al.</italic>, 2003). The maximum number of iterations of mi-SVM was set as 200. The kernel function used was radial basis function with gamma as 0.0012 in simulation datasets and human RCC data, and sigmoid function with gamma as 0.00125 in human bladder cancer data. LIME was implemented using R package <italic>lime</italic> (<xref rid="btaa436-B22" ref-type="bibr">Pedersen and Benesty, 2019</xref>). The number of bins for continuous variable was set as 4 and the kernel width was set as 0.1 in <italic>lime</italic>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Data</title>
    <p>We evaluated the performance of mi-CNN on five datasets. Two experimental datasets represent two human cancers, and two different MSI acquisition strategies (DESI, characterizing metabolites and lipids and MALDI, characterizing peptides). We further simulated three datasets with known ground truth, inspired from one of the experimental datasets.</p>
    <sec>
      <title>4.1 Human RCC experiment</title>
      <p>The experiment aimed to classify locations in human renal tissues as tumor versus healthy. Pairs of tumor and healthy tissue sections were collected from eight human donors with RCC. The tissues were subjected to serial H&amp;E staining. Pathology examination of the H&amp;E-stained tissues was unable to classify the tissues at the sub-tissue resolution, and only annotated each entire tissue section as tumor or healthy (<xref ref-type="fig" rid="btaa436-F3">Fig. 3</xref>).
</p>
      <fig id="btaa436-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Human RCC experiment. Pairs of tumor and healthy tissues from eight donors were H&amp;E stained, and examined by a pathologist. For each pair, the tissue on the left has the pathology annotation of tumor, and the tissue on the right has the pathology annotation of healthy. The subtissue-level annotations were not available for this experiment. (<bold>a</bold>) Training set and (b) Validation set</p>
        </caption>
        <graphic xlink:href="btaa436f3"/>
      </fig>
      <p>Data from the tissues were acquired using DESI ionization source on a Thermo Finnigan LTQ ion trap mass spectrometer in negative mode. The mass range covered 150–1000 Da. In total, 7567 mass spectra were collected from on average 472 locations per tissue. Prior to classification, the spectra were normalized by total ion current (TIC) and resampled to unit mass resolution, which produced 850 <italic>m</italic>/<italic>z</italic> features per mass spectrum. The data are available in R package <italic>CardinalWorkflow</italic> (<xref rid="btaa436-B7" ref-type="bibr">Bemis, 2019</xref>). The pairs of tissues were randomly split into a training set (six pairs) and validation set (two pairs).</p>
    </sec>
    <sec>
      <title>4.2 Human bladder cancer experiment</title>
      <p>The experiment aimed to classify human bladder cancer tissues as tumor versus stroma. Two tissue microarrays (TMAs) containing core needle biopsies from resected formalin-fixed and paraffin-embedded bladder tissues of 49 patients were built, and each TMA was mounted onto a separate glass slide (<xref ref-type="fig" rid="btaa436-F4">Fig. 4</xref>). A pathologist annotated 42 tissue cores by carefully examining sub-areas of each tissue and color-coded subregions presenting tumor and subregions presenting stroma (<xref ref-type="fig" rid="btaa436-F4">Fig. 4</xref>). The annotations are viewed as ground truth in this article. The label tumor was assigned to tissue cores containing tumor subregions, and the label stroma to cores containing only stroma.
</p>
      <fig id="btaa436-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Human bladder cancer experiment. H&amp;E-stained optical images of human bladder cancer tissues after data acquisition. Letters above each tissue are tissue-level annotations (T, tumor; S, stroma). The colors inside each core indicate subtissue-level pathology (red, tumor; blue, stroma), viewed as the ground truth. (<bold>a</bold>) Training set: 3 purely stroma tissues and 18 tissues with both tumor and stroma locations. (<bold>b</bold>) Validation set: 7 purely stroma tissues and 14 tissues with both tumor and stroma</p>
        </caption>
        <graphic xlink:href="btaa436f4"/>
      </fig>
      <p>The proteins in the tissues were digested with trypsin and the peptides were covered with alpha-cyano-4-hydroxycinnamic acid matrix and analyzed with an AB SCIEX 4800 MALDI Time-of-Flight (TOF)/TOF mass spectrometer in positive mode. The mass range was 800–2300 Da. Subregion annotations containing 3152 mass spectra in total and 77 spectra per tissue were extracted via an affine transformation strategy (<xref rid="btaa436-B13" ref-type="bibr">Föll <italic>et al.</italic>, 2019</xref>). The two datasets were resampled, combined and pre-processed using Cardinal and MALDIquant algorithms on <ext-link ext-link-type="uri" xlink:href="https://usegalaxy.eu">https://usegalaxy.eu</ext-link> (<xref rid="btaa436-B5" ref-type="bibr">Bemis <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B13" ref-type="bibr">Föll <italic>et al.</italic>, 2019</xref>; <xref rid="btaa436-B15" ref-type="bibr">Gibb and Strimmer, 2012</xref>). The major pre-processing steps comprised peak picking, re-calibration, removal of contaminants and TIC normalization. The pre-processed file contained 593 <italic>m</italic>/<italic>z</italic> features. Annotated tissues from one slide were used as training set (21 tissues), and on the second slide as the validation set (21 tissues). The split aims to test the robustness of the classifier to experimental batch effects.</p>
      <p><bold>Simulated Dataset 1: one differentially abundant analyte with four features, and a complex background</bold>. The simulation is based on the mass spectra from eight healthy tissues in RCC dataset. It mimicked real-life variation in feature intensities, while providing the ground truth regarding both the labels of the tissue locations and the predictive features.</p>
      <p>First, the eight healthy tissues in the RCC dataset were split into two halves, as shown in <xref ref-type="fig" rid="btaa436-F5">Figure 5</xref>. Since the mass spectra from these tissues have real-life biological and technological variation, but no systematic variation between the tissue types, they are viewed as a complex background.
</p>
      <fig id="btaa436-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Simulated Dataset 1. Healthy tissues from the RCC experiment were split into halves. Locations on the left half of the upper newly created tissues were labeled as tumor, and the remaining locations as healthy. The labels were viewed as the ground truth. To mimic pathology annotations, the entire upper tissues were annotated as tumor, and the lower tissues as healthy. A synthetic analyte with four features, differentially abundant between tumor and healthy, was added to the experimental spectra. Its intensity was confounded by a morphology structure spanning both tissue types</p>
        </caption>
        <graphic xlink:href="btaa436f5"/>
      </fig>
      <p>Second, the newly created tissues were assigned tissue- and subtissue-level labels. The left half of the upper newly created tissues was labeled as tumor, and the remaining locations as healthy. These labels were viewed as the ground truth. To mimic pathology annotations at the tissue level, the entire upper tissues were annotated as tumor, and the lower tissues as healthy.</p>
      <p>Next, one synthetic differentially abundant analyte between the tumor and the healthy locations was added to the experimental spectra. The simulation incorporated a morphology (grey area in <xref ref-type="fig" rid="btaa436-F5">Fig. 5</xref>) that confounded the intensity of the differentially abundant analyte and spanned both tumor and the healthy tissue locations. The intensity <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> of this analyte at location <italic>i</italic> in tissue <italic>j</italic> was simulated as follows
<disp-formula id="E7"><label>(6)</label><mml:math id="M7"><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo>μ</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ϵ</mml:mo><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>δ</mml:mo><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>μ</italic> is the mean intensity of the analyte for tumor or stroma, <italic>S<sub>j</sub></italic> is the biological between-tissue variation, <italic>δ<sub>ij</sub></italic> is the variation between the morphological region and background, and <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the biological and technological variation between locations of a same tissue. All the random variables are independent. <italic>I</italic><sub>in</sub> and <italic>I</italic><sub>out</sub> are indicators of whether a tissue location is inside or outside a morphology region, and <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> is the mean intensity shift of locations inside or outside the morphological region. Here <italic>μ </italic>= 50 for tumor and <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>150</mml:mn></mml:mrow></mml:math></inline-formula> for healthy, <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.15</mml:mn><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>δ</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ε</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <p>Finally, we simulated four individual <italic>m</italic>/<italic>z</italic> features generated by this analyte. The features correspond to dehydrated ions <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mi>O</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 407), molecular molecules <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (m/z 425), sodium adducts <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 447) and potassium adducts <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 463). Each feature was simulated as <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>/</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mi mathvariant="italic">Dirchlet</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
      <p>Similarly to the RCC dataset, the tissues were split into a training set of six tissue pairs, and a validation set of two tissue pairs.</p>
      <p><bold>Simulated Dataset 2: one analyte with differential relative intensity of two of the four features, and a complex background.</bold> We mimicked a situation where tumor locations affect the relative intensities of features of a same analyte. We assumed that the synthetic analyte produced more potassium adducts in tumor locations, but more sodium adducts in healthy tissues. The simulation repeated the procedure above, while setting the mean intensity of the analyte to <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:mo>μ</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:math></inline-formula> 50 for both tumor and healthy locations, and setting the total intensity of molecular ions and dehydrated ions to <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>407</mml:mn><mml:mo>,</mml:mo><mml:mn>425</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The total intensity of adducts <inline-formula id="IE34"><mml:math id="IM34"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> was simulated from <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:mi mathvariant="italic">Dirichlet</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. Next, in the tumor locations we set the intensity of sodium adducts <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, the intensity of potassium adducts <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. In the healthy locations we set the intensity of sodium adducts <inline-formula id="IE38"><mml:math id="IM38"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, and the intensity of potassium adducts <inline-formula id="IE39"><mml:math id="IM39"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> in healthy.</p>
      <p><bold>Simulated Dataset 3: impact of biological variation, technological variation and sample size.</bold> The simulation evaluated the effect of biological and technological variation, and of the number of tissues in the training set, on the performance of mi-CNN. We simulated training sets with between 13 and 130 tissues, half of which annotated at the tissue level as tumor, and the other half as healthy. Each simulated tissue was characterized by 25 locations, with spectra randomly selected from the healthy tissues in the RCC experiment to represent complex background. As in Datasets 1 and 2, only half of the locations in the tumor-annotated tissues had tumor locations as the ground truth. The synthetic analyte was simulated as in <xref ref-type="disp-formula" rid="E7">Equation (6)</xref>, with <italic>μ</italic>  =  50 for the tumor locations and <italic>μ</italic>  =  150 for the healthy locations. <italic>σ<sub>S</sub></italic> varied from <inline-formula id="IE40"><mml:math id="IM40"><mml:mrow><mml:mn>0.1</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE41"><mml:math id="IM41"><mml:mrow><mml:mn>0.3</mml:mn><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ε</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> varied between <inline-formula id="IE42"><mml:math id="IM42"><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE43"><mml:math id="IM43"><mml:mrow><mml:mn>0.15</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
  </sec>
  <sec>
    <title>5 Results</title>
    <sec>
      <title>5.1 Results for the simulated datasets</title>
      <p><bold>Taking as input tissue-level annotations, mi-CNN accurately classified subtissue labels.</bold> We compared the ability of mi-CNN and mi-SVM, and that of the classical CNN and SVM, to classify subtissue labels on Simulated Dataset 1. <xref rid="btaa436-T1" ref-type="table">Table 1</xref> shows that SVM and CNN had high accuracy when comparing the classified locations to tissue-level annotations in the training set. This is expected, as the methods were trained to minimize the classification loss with respect to tissue-level annotations. However, these predictive patterns were undermined by the mislabeled healthy locations in the tumor-annotated tissues of the training set. When comparing the classifications to the ground truth at the location level, the methods had worse accuracy (and worse balanced accuracy, that accounts for differences in the number of tumor and healthy locations) in both the training and the validation dataset. <xref ref-type="fig" rid="btaa436-F6">Figure 6</xref> details the predictions on the validation set. It illustrates that SVM had poor predictions for both tumor and healthy locations, while CNN had poor predictions for healthy locations.
</p>
      <fig id="btaa436-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>Simulation Dataset 1: subtissue-level classification on the validation set </p>
        </caption>
        <graphic xlink:href="btaa436f6"/>
      </fig>
      <table-wrap id="btaa436-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Simulated Dataset 1: classification accuracy</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Compare with</th>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.895 (0.895)</td>
              <td rowspan="1" colspan="1">0.948 (0.948)</td>
              <td rowspan="1" colspan="1">0.885 (0.882)</td>
              <td rowspan="1" colspan="1">0.751 (0.742)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.747 (0.833)</td>
              <td rowspan="1" colspan="1">0.747 (0.833)</td>
              <td rowspan="1" colspan="1">0.809 (0.862)</td>
              <td rowspan="1" colspan="1">0.979 (0.981)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.778 (0.671)</td>
              <td rowspan="1" colspan="1">0.752 (0.831)</td>
              <td rowspan="1" colspan="1">0.833 (0.693)</td>
              <td rowspan="1" colspan="1">0.975 (0.964)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note</italic>: Accuracy [<xref ref-type="disp-formula" rid="E5">Equation (4)]</xref> and balanced accuracy [in parentheses, <xref ref-type="disp-formula" rid="E6">Equation (5)]</xref>. The first two rows evaluate the accuracy with respect to tissue-level annotations. The last four rows evaluate the accuracy with respect to labels of within-tissue locations.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Although the accuracy of mi-SVM and mi-CNN classification compared with tissue-level annotations was lower than that of SVM and CNN (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Row 1 and 2), their results were closer to the ground truth location labels, both on the training (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Rows 3 and 4) and the validation sets (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Rows 5 and 6). <xref ref-type="fig" rid="btaa436-F6">Figure 6</xref> illustrates that mi-SVM, and in particular mi-CNN, classified the labels of the individual locations more correctly.</p>
      <p><xref rid="btaa436-T2" ref-type="table">Table 2</xref> shows that the results are not limited to situations when the predictive analyte is differentially abundant. Qualitatively similar results are obtained with the predictive pattern in Simulated Dataset 2.</p>
      <p><bold>mi-CNN improved subtissue classification by leveraging changes in relative abundances of features from a same analyte.</bold><xref rid="btaa436-T1" ref-type="table">Tables 1</xref> and <xref rid="btaa436-T2" ref-type="table">2</xref> show that mi-CNN and CNN had higher classification accuracy with respect to the location labels as compared to mi-SVM and SVM. To evaluate whether the improved accuracy was due to the CNN’s ability to capture the contextual relationships between related <italic>m</italic>/<italic>z</italic>, we ranked the predictive features by their importance in these methods using LIME. <xref ref-type="fig" rid="btaa436-F7">Figure 7</xref> compares the relative importance of the top five features, when classifying a tumor location in one tissue with mi-SVM and mi-CNN. Both methods classified this location correctly. However, while in mi-SVM the most predictive feature is part of the background, mi-CNN ranked the <italic>m</italic>/<italic>z</italic> features (407, 425, 447 and 463) of the synthetic differentially abundant analyte among the top five most predictive.
</p>
      <fig id="btaa436-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Simulated Dataset 1: LIME-based importance of <italic>m</italic>/<italic>z</italic> features when classifying a tumor location in the validation set. A location in the simulated tissue UH9912_01 was classified correctly by both mi-SVM and mi-CNN. However, only mi-CNN captured the four <italic>m</italic>/<italic>z</italic> features (407, 425, 447 and 463) from the synthetic differentially abundant analyte. (<bold>a</bold>) mi-SVM and (<bold>b</bold>) mi-CNN</p>
        </caption>
        <graphic xlink:href="btaa436f7"/>
      </fig>
      <table-wrap id="btaa436-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Simulated Dataset 2: classification accuracy</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Compare with</th>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.532 (0.530)</td>
              <td rowspan="1" colspan="1">0.778 (0.777)</td>
              <td rowspan="1" colspan="1">0.860 (0.856)</td>
              <td rowspan="1" colspan="1">0.700 (0.690)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.565 (0.538)</td>
              <td rowspan="1" colspan="1">0.734 (0.810)</td>
              <td rowspan="1" colspan="1">0.758 (0.776)</td>
              <td rowspan="1" colspan="1">0.877 (0.800)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.530 (0.449)</td>
              <td rowspan="1" colspan="1">0.869 (0.896)</td>
              <td rowspan="1" colspan="1">0.771 (0.500)</td>
              <td rowspan="1" colspan="1">0.912 (0.701)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic>Note</italic>: As <xref rid="btaa436-T1" ref-type="table">Table 1</xref>, for Simulated Dataset 2.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Out of 200 randomly selected locations, mi-CNN consistently ranked all these features among the top five most predictive in 32.3% of the locations, and at least one of these features among the top five most predictive in 99.3% of the locations. The respective numbers for mi-SVM were very low, 0% and 6%. This illustrates the utility of incorporating the domain-specific information in the size of the convolution filter in the neural network.</p>
      <p><bold>In presence of larger variation, accurate subtissue-level classification with mi-CNN required a larger sample size.</bold> We evaluated the accuracy of mi-CNN with respect to subtissue labels on Simulated Dataset 3. <xref ref-type="fig" rid="btaa436-F8">Figure 8a</xref> shows that, in situations where both between-tissue and within-tissue variation is relatively small, mi-CNN can have a high classification accuracy on the validation set, even when trained on a relatively small number of 12 biological replicates. <xref ref-type="fig" rid="btaa436-F8">Figure 8c and d</xref> illustrates that the between-tissue variation dominates the classification accuracy, and the within-tissue variation has a relatively small impact. Including more biological replicates is beneficial when variation is large.
</p>
      <fig id="btaa436-F8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>Simulated Dataset 3: impact of biological (a,b) and technological variation (c,d) of the synthetic analyte, and of the number of training set tissues, on the accuracy of mi-CNN with respect to subtissue labels. When biological variation is relatively small, mi-CNN correctly classified subtissue locations, even with a small number of biological replicates in the training set. Including more biological replicates is beneficial when variation is large</p>
        </caption>
        <graphic xlink:href="btaa436f8"/>
      </fig>
    </sec>
    <sec>
      <title>5.2 Results for the experimental datasets</title>
      <p><bold>RCC experiment.</bold> Although subtissue-level ground truth was not available for the RCC experiment, we used the fact that the tissue sections annotated as healthy were expected to be free from tumor. Therefore, we evaluated the classifications with respect to the homogeneity of subtissue classification of the healthy sections. <xref ref-type="fig" rid="btaa436-F9">Figure 9</xref> illustrates that, on the training set, mi-SVM and mi-CNN both had homogeneous predictions of healthy on healthy tissue. On the validation set, mi-CNN had slightly more homogeneous predictions of healthy on healthy tissues than mi-SVM. The predictions of SVM and mi-SVM had no substantial difference in this dataset. CNN has less homogeneous predictions of healthy on healthy tissues than mi-CNN in both training and validation set. This indicates that mi-CNN can improve prediction on healthy locations by considering healthy locations in the tumor tissues.
</p>
      <fig id="btaa436-F9" orientation="portrait" position="float">
        <label>Fig. 9.</label>
        <caption>
          <p>Classification accuracy: the RCC experiment. (<bold>a</bold>) Tissue-level pathology annotations. (<bold>b</bold>) Optical images of H&amp;E stained tissues. (<bold>c-f</bold>) Subtissue-level classifications</p>
        </caption>
        <graphic xlink:href="btaa436f9"/>
      </fig>
      <p>LIME-based interpretation of mi-SVM and mi-CNN highlighted different features as highly predictive. For mi-SVM, <italic>m</italic>/<italic>z</italic> 181, 215, 760, 865 and 898 were ranked as the top 5 most important. For mi-CNN, these were <italic>m</italic>/<italic>z</italic> 217, 751, 773, 885 and 886. These results indicate that the choice of the classifier plays an important role in both predictive accuracy and the choice of predictive features in this dataset.</p>
      <p><bold>Human bladder cancer experiment.</bold><xref ref-type="fig" rid="btaa436-F10">Figure 10</xref> compares the classification of SVM, CNN, mi-SVM and mi-CNN with the ground truth subtissue-level labels on selected heterogeneous tumor tissue and pure stroma tissue. Similar to results on Simulated Datasets 1 and 2, SVM and CNN classified many stroma locations in the tumor tissue as tumor in the training dataset (see <xref ref-type="fig" rid="btaa436-F10">Fig. 10</xref>). Not surprisingly, both SVM and CNN had poor predictions in the validation set, presenting mixture predictions of tumor and stroma in the stroma tissue.
</p>
      <fig id="btaa436-F10" orientation="portrait" position="float">
        <label>Fig. 10.</label>
        <caption>
          <p>Classification accuracy: the human bladder cancer experiment. (<bold>a</bold>) Tissue-level pathology annotations. (<bold>b</bold>) Subtissue-level pathology labels on optical images. (<bold>c</bold>) Subtissue-level labels on MSI (viewed as ground truth). (<bold>d–g</bold>) Subtissue-level classifications</p>
        </caption>
        <graphic xlink:href="btaa436f10"/>
      </fig>
      <p>mi-SVM and mi-CNN improved the classification of SVM and CNN in terms of both accuracy and balanced accuracy (<xref rid="btaa436-T3" ref-type="table">Table 3</xref>). From <xref ref-type="fig" rid="btaa436-F10">Figure 10</xref>, mi-CNN correctly classified more stroma locations in the tumor tissues than mi-SVM for both training and validation tissues. In addition, mi-CNN had the smallest number of false positives on the stroma tissues, showing most clean classifications in stroma tissues in <xref ref-type="fig" rid="btaa436-F10">Figure 10</xref>.
</p>
      <table-wrap id="btaa436-T3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>Classification accuracy: the human bladder cancer experiment</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="2" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.959 (0.946)</td>
              <td rowspan="1" colspan="1">0.827 (0.946)</td>
              <td rowspan="1" colspan="1">0.939 (0.946)</td>
              <td rowspan="1" colspan="1">0.800 (0.855)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.801 (0.793)</td>
              <td rowspan="1" colspan="1">0.767 (0.759)</td>
              <td rowspan="1" colspan="1">0.847 (0.842)</td>
              <td rowspan="1" colspan="1">0.941 (0.941)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.755 (0.750)</td>
              <td rowspan="1" colspan="1">0.779 (0.774)</td>
              <td rowspan="1" colspan="1">0.827 (0.823)</td>
              <td rowspan="1" colspan="1">0.928 (0.928)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic>Note</italic>: Values without the parentheses are accuracy calculated by <xref ref-type="disp-formula" rid="E5">Equation (4)</xref>. Values in parenthesis are balanced accuracy calculated by <xref ref-type="disp-formula" rid="E6">Equation (5)</xref>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>LIME analysis of mi-CNN classifications of a subset of 200 locations in validation set selected <italic>m</italic>/<italic>z</italic> 925.44, 944.44, 946.44, 1105.54 and 1198.69 as most predictive. Among those, <italic>m</italic>/<italic>z</italic> 944.44 is likely to be Histone 2 A, which is known to be upregulated in tumors, and <italic>m</italic>/<italic>z</italic> 1105.54 is likely to correspond to Collagen I which is known to be upregulated in stroma. LIME analysis of mi-SVM selected five different predictive features, <italic>m</italic>/<italic>z</italic> 1669.73, 1475.72, 1529.7, 963.44 and 1054.49.</p>
    </sec>
  </sec>
  <sec>
    <title>6 Discussion</title>
    <p>We introduced mi-CNN, a deep MIL approach for classifying subtissue locations in MSI experiments. The multiple instance aspect of the approach enabled training the classifier with weak supervision, using rough tissue-level annotations in the training set. The convolutional architecture of the CNN captured contextual dependencies between the spectral features. Evaluations on simulated and experimental datasets demonstrated that mi-CNN improved the subtissue classification as compared with traditional SVM and CNN.</p>
    <p>The approach assumed that, in a binary classification problem, a tissue labeled as tumor had at least one tumor location, but the tissues labeled as non-tumor were tumor-free. This assumption is reasonable for MSI, as homogeneous healthy tissue biopsies are relatively easy to obtain, however tumor biopsies are more likely to contain a mix of tumor and non-tumor regions. In a case where both non-tumor and tumor tissues are heterogeneous, the proposed approach is no longer suitable since the reliable label of non-tumor is crucial to the method. Although we only discussed binary classification, mi-CNN can also be adapted to multi-class classification, such as different grades of tumor tissues or multiple tissue types.</p>
    <p>In contrast to the typical applications of CNN in computer vision, the CNN architecture in this work did not include spatial convolution of tissues. This is a consequence of typically high heterogeneity of the microenvironment within a tumor, and of lack of spatial smoothness of location labels.</p>
    <p>At the same time, the CNN architecture took advantage of the mass spectral patterns to alleviate the high dimensionality and the high correlations in the predictive feature space. In this work, the size of convolutional filters captured one of the most common sources of correlations between <italic>m</italic>/<italic>z</italic>, i.e. the presence of molecular ions and their adducts. The <italic>m</italic>/<italic>z</italic> dependencies can become more complicated and ambiguous in other cases, e.g. with larger mass ranges. The convolutional aspects can be easily adapted to such situations types by changing the size of filter and the network depth.</p>
    <p>Although neural networks have a large parameter space and need large training datasets, we found that mi-CNN worked well on the relatively small numbers of biological tissues. This may be due to a combination of the CNN architecture, which uses locally connected neurons and weight sharing filters to reduce the parameter space and the computational cost, and a relatively large number of heterogeneous subtissue locations available for training.</p>
    <p>Overall, we found that mi-CNN is well-suited for training subtissue-level classifiers on datasets with tissue-level annotations. This is particularly important in situations where tumor and non-tumor tissues are tightly connected, making manual labeling of the training sets difficult or even impossible at all. The approach is an important step toward taking a full advantage of MSI’s capability of providing molecular information, and minimizing manual labor for tissue imaging and classification.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgement</title>
    <p>We thank K. A. Bemis for helpful discussions.</p>
    <sec>
      <title>Funding</title>
      <p>The work was supported in part by the NSF [award DBI-1759736 to O.V.]; and by the German Research Council [DFG, SCHI 871/11-1 to O.S.].</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa436-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aichler</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Walch</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>) 
<article-title>MALDI imaging mass spectrometry: current frontiers and perspectives in pathology research and practice</article-title>. <source>Lab. Invest</source>., <volume>95</volume>, <fpage>422</fpage>–<lpage>431</lpage>.<pub-id pub-id-type="pmid">25621874</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Allaire</surname><given-names>J.J.</given-names></name>, <name name-style="western"><surname>Tang</surname><given-names>Y.</given-names></name></person-group> (<year>2019</year>) <italic>Tensorflow: R Interface to ‘TensorFlow’.</italic> R package version 2.0.0.</mixed-citation>
    </ref>
    <ref id="btaa436-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Andrews</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>Support vector machines for multiple-instance learning</article-title>. In: <italic>Advances in Neural Information Processing Systems</italic>, p. <fpage>577</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Behrmann</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Deep learning for tumor classification in imaging mass spectrometry</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1215</fpage>–<lpage>1223</lpage>.<pub-id pub-id-type="pmid">29126286</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Cardinal: an R package for statistical analysis of mass spectrometry-based imaging experiments</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>2418</fpage>–<lpage>2420</lpage>.<pub-id pub-id-type="pmid">25777525</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Probabilistic segmentation of mass spectrometry images helps select important ions and characterize confidence in the resulting segments</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>15</volume>, <fpage>1761</fpage>–<lpage>1772</lpage>.<pub-id pub-id-type="pmid">26796117</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.A.</given-names></name></person-group> (<year>2019</year>) <italic>CardinalWorkflows: Datasets and Workflows for the Cardinal Mass Spectrometry Imaging Package</italic>. R package version 1.17.0.</mixed-citation>
    </ref>
    <ref id="btaa436-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Calligaris</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MALDI mass spectrometry imaging analysis of pituitary adenomas for near-real-time tumor delineation</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>112</volume>, <fpage>9978</fpage>–<lpage>9983</lpage>.<pub-id pub-id-type="pmid">26216958</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cheplygina</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Not-so-supervised: a survey of semi-supervised, multi-instance, and transfer learning in medical image analysis</article-title>. <source>Med. Image Anal</source>., <volume>54</volume>, <fpage>280</fpage>–<lpage>296</lpage>.<pub-id pub-id-type="pmid">30959445</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dill</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Multivariate statistical differentiation of renal cell carcinomas based on lipidomic analysis by ambient ionization imaging mass spectrometry</article-title>. <source>Anal. Bioanal. Chem</source>., <volume>398</volume>, <fpage>2969</fpage>–<lpage>2978</lpage>.<pub-id pub-id-type="pmid">20953777</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dill</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Multivariate statistical identification of human bladder carcinomas using ambient ionization imaging mass spectrometry</article-title>. <source>Chemistry</source>, <volume>17</volume>, <fpage>2897</fpage>–<lpage>2902</lpage>.<pub-id pub-id-type="pmid">21284043</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Eberlin</surname><given-names>L.S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Molecular assessment of surgical-resection margins of gastric cancer by mass-spectrometric imaging</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>111</volume>, <fpage>2436</fpage>–<lpage>2441</lpage>.<pub-id pub-id-type="pmid">24550265</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Föll</surname><given-names>M.C.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Reproducible mass spectrometry imaging data analysis in Galaxy</article-title>. <source>GigaScience</source>, <volume>8</volume>, <fpage>628719</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fu</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>MILIS: multiple instance learning with instance selection</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>33</volume>, <fpage>958</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gibb</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>) 
<article-title>MALDIQUANT: a versatile R package for the analysis of mass spectrometry data</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>2270</fpage>–<lpage>2271</lpage>.<pub-id pub-id-type="pmid">22796955</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Inglese</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Deep learning and 3D-DESI imaging reveal the hidden metabolic heterogeneity of cancer</article-title>. <source>Chem. Sci</source>., <volume>8</volume>, <fpage>3500</fpage>–<lpage>3511</lpage>.<pub-id pub-id-type="pmid">28507724</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>E.A.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Imaging mass spectrometry statistical analysis</article-title>. <source>J. Proteomics</source>, <volume>75</volume>, <fpage>4962</fpage>–<lpage>4989</lpage>.<pub-id pub-id-type="pmid">22743164</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kandemir</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Hamprecht</surname><given-names>F.A.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Computer-aided diagnosis from weak supervision: a benchmarking study</article-title>. <source>Comput. Med. Imaging Graph</source>., <volume>42</volume>, <fpage>44</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">25475486</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kriegsmann</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MALDI TOF imaging mass spectrometry in clinical pathology: a valuable tool for cancer diagnostics (review)</article-title>. <source>Int. J. Oncol</source>., <volume>46</volume>, <fpage>893</fpage>–<lpage>906</lpage>.<pub-id pub-id-type="pmid">25482502</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lou</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>An experimental guideline for the analysis of histologically heterogeneous tumors by MALDI-TOF mass spectrometry imaging</article-title>. <source>Biochim. Biophys. Acta Proteins Proteom</source>., <volume>1865</volume>, <fpage>957</fpage>–<lpage>966</lpage>.<pub-id pub-id-type="pmid">27725306</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B21">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Molnar</surname><given-names>C.</given-names></name></person-group> (<year>2019</year>) <italic>Interpretable Machine Learning</italic>. Lulu. com.</mixed-citation>
    </ref>
    <ref id="btaa436-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Pedersen</surname><given-names>T.L.</given-names></name>, <name name-style="western"><surname>Benesty</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>) <italic>LIME: Local Interpretable Model-Agnostic Explanations</italic>. R package version 0.5.1.</mixed-citation>
    </ref>
    <ref id="btaa436-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rauser</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Classification of HER2 receptor status in breast cancer tissues by MALDI imaging mass spectrometry</article-title>. <source>J. Proteome Res</source>., <volume>9</volume>, <fpage>1854</fpage>–<lpage>1863</lpage>.<pub-id pub-id-type="pmid">20170166</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rawat</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Deep convolutional neural networks for image classification: a comprehensive review</article-title>. <source>Neural Comput</source>., <volume>29</volume>, <fpage>2352</fpage>–<lpage>2449</lpage>.<pub-id pub-id-type="pmid">28599112</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ribeiro</surname><given-names>M.T.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>“Why should I trust you?” Explaining the predictions of any classifier</article-title>. In: <italic>22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>, p. <fpage>1135</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sans</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Metabolic markers and statistical prediction of serous ovarian cancer aggressiveness by ambient ionization mass spectrometry imaging</article-title>. <source>Cancer Res</source>., <volume>77</volume>, <fpage>2903</fpage>–<lpage>2913</lpage>.<pub-id pub-id-type="pmid">28416487</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Spengler</surname><given-names>B.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Mass spectrometry imaging of biomolecular information</article-title>. <source>Anal. Chem</source>., <volume>87</volume>, <fpage>64</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">25490190</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>van Kersbergen</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Cancer detection in mass spectrometry imaging data by dilated convolutional neural networks</article-title>. In: <italic>Medical Imaging 2019: Digital Pathology</italic>, Vol. <volume>10956</volume>, p. 109560I, International Society for Optics and Photonics.</mixed-citation>
    </ref>
    <ref id="btaa436-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vaysse</surname><given-names>P.M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Mass spectrometry imaging for clinical research-latest developments, applications, and current limitations</article-title>. <source>Analyst</source>, <volume>142</volume>, <fpage>2690</fpage>–<lpage>2712</lpage>.<pub-id pub-id-type="pmid">28642940</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wu</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Mass spectrometry imaging under ambient conditions</article-title>. <source>Mass Spectrom. Rev</source>., <volume>32</volume>, <fpage>218</fpage>–<lpage>243</lpage>.<pub-id pub-id-type="pmid">22996621</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Multiple instance boosting for object detection</article-title>. In: <italic>Advances in Neural Information Processing Systems</italic>, p. <fpage>1417</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>Z.-H.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Multi-instance learning by treating instances as non-IID samples</article-title>. In: <italic>Proceedings of the 26th Annual International Conference on Machine Learning</italic>, p. <fpage>1249</fpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355295</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa436</article-id>
    <article-id pub-id-type="publisher-id">btaa436</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Macromolecular Sequence, Structure, and Function</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep multiple instance learning classifies subtissue locations in mass spectrometry images from tissue-level annotations</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Guo</surname>
          <given-names>Dan</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff1">b1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Föll</surname>
          <given-names>Melanie Christine</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Volkmann</surname>
          <given-names>Veronika</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Enderle-Ammour</surname>
          <given-names>Kathrin</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bronsert</surname>
          <given-names>Peter</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
        <xref ref-type="aff" rid="btaa436-aff4">b4</xref>
        <xref ref-type="aff" rid="btaa436-aff5">b5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schilling</surname>
          <given-names>Oliver</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa436-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vitek</surname>
          <given-names>Olga</given-names>
        </name>
        <xref ref-type="aff" rid="btaa436-aff1">b1</xref>
        <xref ref-type="corresp" rid="btaa436-cor1"/>
        <!--<email>o.vitek@neu.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa436-aff1"><label>b1</label><institution>Khoury College of Computer Sciences, Northeastern University</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
    <aff id="btaa436-aff2"><label>b2</label><institution>Institute for Surgical Pathology, Medical Center – University of Freiburg</institution>, 79106 Freiburg, <country country="DE">Germany</country></aff>
    <aff id="btaa436-aff3"><label>b3</label><institution>Faculty of Medicine, University of Freiburg</institution>, 79110 Freiburg, <country country="DE">Germany</country></aff>
    <aff id="btaa436-aff4">
      <label>b4</label>
      <institution>Tumorbank Comprehensive Cancer Center Freiburg, Medical Center – University of Freiburg</institution>
    </aff>
    <aff id="btaa436-aff5"><label>b5</label><institution>German Cancer Consortium (DKTK) and Cancer Research Center (DKFZ)</institution>, 79106 Freiburg, <country country="DE">Germany</country></aff>
    <author-notes>
      <corresp id="btaa436-cor1">To whom correspondence should be addressed. E-mail: <email>o.vitek@neu.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i300</fpage>
    <lpage>i308</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa436.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Mass spectrometry imaging (MSI) characterizes the molecular composition of tissues at spatial resolution, and has a strong potential for distinguishing tissue types, or disease states. This can be achieved by supervised classification, which takes as input MSI spectra, and assigns class labels to subtissue locations. Unfortunately, developing such classifiers is hindered by the limited availability of training sets with subtissue labels as the ground truth. Subtissue labeling is prohibitively expensive, and only rough annotations of the entire tissues are typically available. Classifiers trained on data with approximate labels have sub-optimal performance.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To alleviate this challenge, we contribute a semi-supervised approach <italic>mi-CNN</italic>. mi-CNN implements multiple instance learning with a convolutional neural network (CNN). The multiple instance aspect enables weak supervision from tissue-level annotations when classifying subtissue locations. The convolutional architecture of the CNN captures contextual dependencies between the spectral features. Evaluations on simulated and experimental datasets demonstrated that mi-CNN improved the subtissue classification as compared to traditional classifiers. We propose mi-CNN as an important step toward accurate subtissue classification in MSI, enabling rapid distinction between tissue types and disease states.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The data and code are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Vitek-Lab/mi-CNN_MSI">https://github.com/Vitek-Lab/mi-CNN_MSI</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSF</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>DBI-1759736</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>German Research Council</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>DFG</institution>
            <institution-id institution-id-type="DOI">10.13039/100004807</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>SCHI 871/11-1</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Biochemical constitution of tissues varies with tissue types (such as epithelial and connective tissues), or disease states (such as tumor and healthy tissues). Mass spectrometry imaging (MSI) provides an untargeted characterization of the molecular composition of such tissues at spatial resolution, simultaneously quantifying hundreds of analytes without the need for chemical labels or antibodies (<xref rid="btaa436-B27" ref-type="bibr">Spengler, 2015</xref>; <xref rid="btaa436-B17" ref-type="bibr">Jones <italic>et al.</italic>, 2012</xref>). Therefore, MSI has a strong potential to become a rapid diagnostic technology in the clinic (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>).</p>
    <p>Although the name of the technology contains the word ‘image’, the structure of MSI data is very different from other bioimaging technologies (<xref ref-type="fig" rid="btaa436-F1">Fig. 1</xref>). In MSI, mass spectra are acquired at thousands of different spatial <italic>locations</italic> in a raster pattern throughout the tissue. MSI techniques fall into two major categories: matrix-assisted laser desorption/ionization (MALDI) MSI (<xref rid="btaa436-B1" ref-type="bibr">Aichler and Walch, 2015</xref>) and desorption electrospray ionization (DESI) MSI (<xref rid="btaa436-B30" ref-type="bibr">Wu <italic>et al.</italic>, 2013</xref>). With each technique, the mass spectrum obtained at each location is a collection of <italic>features</italic>, corresponding to the ions of biochemical analytes such as metabolites, lipids, peptides and proteins. The features do not contain direct information regarding the identity of the underlying analyte, except for their ratios of mass over charge <italic>m</italic>/<italic>z</italic>. For one tissue location, a typical MSI experiment reports hundreds to thousands of <italic>m</italic>/<italic>z</italic> in ascending order. The intensities of the <italic>m</italic>/<italic>z</italic> correlate with the abundance of the analyte. A plot of the abundance of one <italic>m</italic>/<italic>z</italic> across all locations is referred to as an <italic>ion image</italic>.
</p>
    <fig id="btaa436-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>MSI data. (<bold>a</bold>) H&amp;E-stained optical images of a pair of tumor and healthy tissues from the human renal cell carcinoma (RCC) experiment. (<bold>b</bold>) Mass spectrum from one location in the tumor tissue. The inset zooms into <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mi>m</mml:mi><mml:mo>/</mml:mo><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>300</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Two features with <italic>m</italic>/<italic>z</italic> shift <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>22</mml:mn></mml:mrow></mml:math></inline-formula> can correspond to molecular ions and sodium adducts. Two features with <italic>m</italic>/<italic>z</italic> shift <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>38</mml:mn></mml:mrow></mml:math></inline-formula> can correspond to molecular ions and potassium adducts. (<bold>c</bold>) Ion images of <italic>m</italic>/<italic>z</italic> 215 of the tissues in (a)</p>
      </caption>
      <graphic xlink:href="btaa436f1"/>
    </fig>
    <p>A reliable diagnostics can be achieved by supervised classification models that take as input the observed mass spectra, and predict labels such as tumor, healthy or tumor subtypes. Beyond <italic>tissue-level classification</italic> (classifying the entire tissues), <italic>subtissue-level classification</italic> (classifying the disease status of individual locations within the tissues) is of most interest. Ranking <italic>m</italic>/<italic>z</italic> features by their predictive ability is also important. Currently, training subtissue-level classifiers providing this information requires training sets of tissues with reliable <italic>subtissue labels</italic>.</p>
    <p>Unfortunately, accessing a training set with reliable subtissue labels is challenging in practice. In a typical workflow, pathologists examine the hematoxylin and eosin (H&amp;E)-stained optical images such as in <xref ref-type="fig" rid="btaa436-F1">Figure 1a</xref>. To obtain subtissue labels, the pathologist must manually examine and annotate the distinct regions of each tissue (<xref rid="btaa436-B20" ref-type="bibr">Lou <italic>et al.</italic>, 2017</xref>). The cost of manual work is one of the reasons to the relatively small number of biological replicates in MSI. The procedure is particularly costly for heterogeneous tissues that require labeling of multiple small sub-regions, or for tissues with challenging histology. To be transferrable to MSI, the subtissue labeling must use specialized software that takes time to learn. As the result, pathologists often avoid labeling the individual locations, and only roughly annotate the entire tissues. <xref ref-type="fig" rid="btaa436-F1">Figure 1c</xref> shows that, although the tissue on the left is annotated as tumor, the ion image indicates tissue heterogeneity, and the tissue likely contains both cancerous tissue and healthy kidney parenchyma. Such imprecise labeling of tissue locations compromises the accuracy of the resulting classifiers.</p>
    <p>In addition to the labeling, high correlations between many <italic>m</italic>/<italic>z</italic> limit our ability to train accurate classifiers on MSI data. For example, in peptide MSI proteins are digested to give rise to multiple peptide ions of a same protein, and therefore have similar spatial distributions of abundance. An analyte can also produce multiple <italic>m</italic>/<italic>z</italic> ions for other reasons, that include sodium adducts, neutral loss ions, fragment ions or multiply charged ions. For example, <xref ref-type="fig" rid="btaa436-F1">Figure 1b</xref> illustrates the potential sodium and potassium adducts that give rise to correlated features. The high correlation in the high-dimensional vector of <italic>m</italic>/<italic>z</italic> features undermines the stability of the classifiers, and leads to overfitting (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>).</p>
    <p>To improve our ability to accurately classify subtissue locations in MSI from approximate tissue-level annotations, we propose a semi-supervised approach <italic>mi-convolutional neural network (CNN)</italic>. mi-CNN implements multiple instance learning (MIL) with a CNN. The multiple instance aspect of the approach enables weak supervision from tissue-level annotations when classifying subtissue labels. The convolutional architecture of the CNN captures potential contextual dependencies between <italic>m</italic>/<italic>z</italic>, such as sodium adducts and dehydrated ions. Evaluations on simulated and experimental datasets demonstrate that mi-CNN improved the subtissue classification as compared with traditional classifiers such as support vector machine (SVM) and CNN, and successfully reflected the truly predictive spectral features. We propose mi-CNN as an important step toward accurate subtissue classification in basic biology and clinical applications of MSI.</p>
  </sec>
  <sec>
    <title>2 Background</title>
    <sec>
      <title>2.1 Subtissue-level classification in MSI</title>
      <p>Classifying tissue locations using MSI spectra has already received a lot of attention (<xref rid="btaa436-B19" ref-type="bibr">Kriegsmann <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B29" ref-type="bibr">Vaysse <italic>et al.</italic>, 2017</xref>). Various classifiers have been proposed for these task, including linear discriminant analysis (<xref rid="btaa436-B10" ref-type="bibr">Dill <italic>et al.</italic>, 2010</xref>, <xref rid="btaa436-B11" ref-type="bibr">2011</xref>), regularized logistic regression (<xref rid="btaa436-B12" ref-type="bibr">Eberlin <italic>et al.</italic>, 2014</xref>; <xref rid="btaa436-B26" ref-type="bibr">Sans <italic>et al.</italic>, 2017</xref>), SVM (<xref rid="btaa436-B8" ref-type="bibr">Calligaris <italic>et al.</italic>, 2015</xref>), and many others. Variations of these approaches such as nearest shrunken centroids (<xref rid="btaa436-B6" ref-type="bibr">Bemis <italic>et al.</italic>, 2016</xref>) incorporate spatial smoothing to enhance the spatial stability of the results. The classifiers take as input <italic>m</italic>/<italic>z</italic> features at each location, classify the label of each location, and classify the tissues according to the majority of its location labels.</p>
      <p>Recently, neural networks became of a great interest for MSI. <xref rid="btaa436-B23" ref-type="bibr">Rauser <italic>et al.</italic> (2010)</xref> used fully connected neural networks for tumor classification, and <xref rid="btaa436-B16" ref-type="bibr">Inglese <italic>et al.</italic> (2017)</xref> used unsupervised neural networks to cluster tumor tissues. CNNs, a class of deep neural networks originally designed for image classification, were also introduced. CNN convolutes the image using a small-sized kernel to capture the local connectivity within an image (<xref rid="btaa436-B24" ref-type="bibr">Rawat and Wang, 2017</xref>). A novel application of CNN to MSI proposed to view mass spectra as 1D images. <xref rid="btaa436-B4" ref-type="bibr">Behrmann <italic>et al.</italic> (2018)</xref> used a modified Residual Net with 13 935 parameters and kernel size of 3 to capture isotopic patterns in mass spectra. <xref rid="btaa436-B28" ref-type="bibr">van Kersbergen <italic>et al.</italic> (2019)</xref> replaced convolutional layers in Behrmann’s network with dilated convolutional layers to increase receptive size, and capture globally distributed patterns in the spectra.</p>
      <p>Although the approaches above are quite diverse, they all rely on quality subtissue labels for training. As the result, they are undermined by training sets with approximate annotations, such as in <xref ref-type="fig" rid="btaa436-F1">Figure 1</xref>.</p>
    </sec>
    <sec>
      <title>2.2 Multiple instance learning (MIL)</title>
      <p>Multiple instance learning is a semi-supervised framework commonly used in a variety of applications such as image and video analysis (<xref rid="btaa436-B9" ref-type="bibr">Cheplygina <italic>et al.</italic>, 2019</xref>) and computer-aided diagnosis (<xref rid="btaa436-B14" ref-type="bibr">Fu <italic>et al.</italic>, 2010</xref>; <xref rid="btaa436-B18" ref-type="bibr">Kandemir and Hamprecht, 2015</xref>), but so far not utilized for MSI. In contrast to the classifiers above, MIL allows weak supervision of the training data. The approach considers groups of observations, called <italic>bags</italic>, where ground-truth labels are only available at the bag level. The labels of the observations in a bag, called <italic>instances</italic>, are unknown. In a binary classification problem MIL assumes that a positive bag contains at least one positive instance, but the negative bags contain only negative instances. The homogeneity of the data in the negative bags is the key feature of the approach that enables efficient learning.</p>
      <p>Existing MIL algorithms can be classified into two groups: bag space algorithms and instance space algorithm. Bag space algorithms, such as mi-Graph (<xref rid="btaa436-B32" ref-type="bibr">Zhou <italic>et al.</italic>, 2009</xref>) and MIL with instance (<xref rid="btaa436-B14" ref-type="bibr">Fu <italic>et al.</italic>, 2010</xref>), do not predict labels of individual instances. They classify the bags directly by considering similarities of input features between the bags. Instance space algorithms, such as mi-SVM (<xref rid="btaa436-B3" ref-type="bibr">Andrews <italic>et al.</italic>, 2003</xref>) and MILboost (<xref rid="btaa436-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2006</xref>), take features of the instances as input and predict labels of both instances and bags. For instance-level prediction, mi-SVM is one of the most accurate methods (<xref rid="btaa436-B18" ref-type="bibr">Kandemir and Hamprecht, 2015</xref>). The method treats labels of instances in positive bags as latent variables, and estimates them from the data. Parameters of SVM are optimized by iteratively training SVM on the current instance-level labels, and updating the instance-level labels from their predictions by the current SVM.</p>
    </sec>
    <sec>
      <title>2.3 Interpretation of black-box machine learning models</title>
      <p>Many of the classification approaches above function like a ‘black box’ and lack interpretability. Post-processing of these models (<xref rid="btaa436-B21" ref-type="bibr">Molnar, 2019</xref>) helps characterize the relative importance of each predictive feature after the model is fit. One such approach is Local Interpretable Model-agnostic Explanation (LIME; <xref rid="btaa436-B25" ref-type="bibr">Ribeiro <italic>et al.</italic>, 2016</xref>), which ranks features by their importance in predicting the label of a particular observation of interest. LIME generates new observations by permuting the values of the predictive features in the dataset, and obtains the black box predictions for these new observations. Next, LIME weights the new observations by their proximity to the observation of interest, and trains a weighted interpretable model (such as linear regression with subset selection or regularization) on the new observations and their predictions. Finally, LIME repeats this procedure multiple times, and ranks the features by their frequency of being selected as predictive.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Multiple instance learning with convolutional neural network (mi-CNN) </title>
    <sec>
      <title>3.1 Overview</title>
      <p>For the purposes of subtissue classification in MSI, we propose to view a <italic>tissue</italic> as a bag, and a tissue <italic>location</italic> as an instance. We assume that tissues annotated as non-tumor do not have tumor locations, but tissues annotated as tumor can have both tumor and non-tumor locations. MIL allows us to train classifiers of subtissue locations on training sets with such rough tissue-level annotations. Instance space algorithms are of a particular interest for this task. Our proposed approach takes as the baseline mi-SVM, which reported high classification accuracy on similar tasks in the past, but substitutes the SVM classifier with a CNN (<xref ref-type="fig" rid="btaa436-F2">Fig. 2</xref>). Although CNN are frequently used for image analyses in computer vision domains, the proposed approach uses CNN is a different way. We do not apply spatial convolution on a tissue, as we expect high heterogeneity of the microenvironment within a tumor, and an insufficient spatial smoothness of the location labels. Instead, the CNN incorporates convolutional filters to <italic>m</italic>/<italic>z</italic> in individual locations to capture potential correlations between <italic>m</italic>/<italic>z</italic> of a same location. The CNN has a lightweight structure to avoid overfitting. Finally, post-processing with LIME identifies highly predictive <italic>m</italic>/<italic>z</italic> for downstream biological and clinical interpretation.
</p>
      <fig id="btaa436-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Architecture of mi-CNN. <italic>π<sub>j</sub></italic> the probability that tissue <italic>j</italic> belongs to Class 1, and <italic>π<sub>ij</sub></italic> is the corresponding probability for the location <italic>i</italic> in that tissue. (<bold>a</bold>) Training set and (<bold>b</bold>) validation set</p>
        </caption>
        <graphic xlink:href="btaa436f2"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Notation</title>
      <p>Consider tissue <italic>j</italic> and its locations <italic>i</italic>. The tissue is characterized by a collection of mass spectra <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, and each mass spectrum <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a vector of <italic>M</italic> intensities of <italic>m</italic>/<italic>z</italic> features <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Let <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> denote the annotation of the tissue <italic>j</italic>, and <italic>y<sub>ij</sub></italic> the subtissue label at the <italic>i</italic>th location. Note that <italic>Y<sub>j</sub></italic> is known, and <italic>y<sub>ij</sub></italic> is unknown. Denote <italic>π<sub>j</sub></italic> the probability that tissue <italic>j</italic> belongs to Class 1, and <italic>π<sub>ij</sub></italic> is the corresponding probability for the location <italic>i</italic> in that tissue. Given a mass spectrum <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, our goal is to predict the label <italic>y<sub>ij</sub></italic> of this location, and the label <italic>Y<sub>j</sub></italic> of the entire tissue.</p>
    </sec>
    <sec>
      <title>3.3 Subtissue-level classification</title>
      <p>Using cross-entropy as the loss function, the objective of MIL is defined as
<disp-formula id="E1"><mml:math id="M1"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo>Θ</mml:mo></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="E2"><label>(1)</label><mml:math id="M2"><mml:mrow><mml:mtext mathvariant="bold">such</mml:mtext><mml:mo> </mml:mo><mml:mtext mathvariant="bold">that</mml:mtext><mml:mo> </mml:mo><mml:munder><mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the prediction of a classifier (a CNN) with parameters Θ.</p>
      <p>Since the subtissue labels <italic>y<sub>ij</sub></italic> are not observed, they are estimated by an expectation–maximization-like algorithm (Algorithm 1, similar to mi-SVM in Andrews <italic>et al.</italic>, 2003) minimizing the entropy loss [<xref ref-type="disp-formula" rid="E2">Equation (1)]</xref>. First, the labels of all subtissue locations are initialized with the annotations of the corresponding tissues. Next, the algorithm iterates between training CNN on the current location labels, estimating the probability <italic>π<sub>ij</sub></italic> that location <italic>i</italic> in tissue <italic>j</italic> belong to Class 1, and imputing the location labels <italic>y<sub>ij</sub></italic> from these probabilities until convergence. The constraint in <xref ref-type="disp-formula" rid="E2">Equation (1)</xref> ensures that the labels of non-tumor locations in non-tumor tissues are always classified as non-tumor. On the other hand, if no locations on a tumor tissue are classified as tumor, the location with the highest <italic>π<sub>ij</sub></italic> in this tissue will be labeled as tumor (Lines 7–10, Algorithm 1). The algorithm stops when the number of updated labels is below a threshold, or when the maximum number of iterations is reached.<boxed-text id="btaa436-BOX1" position="float" orientation="portrait"><sec><title><bold>Algorithm 1</bold> <italic>mi-CNN</italic></title><p>1: <bold>procedure</bold> mi-CNN(<inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>J</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, threshold)</p><p>2:  Initialize: <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:math></inline-formula></p><p>3:  <bold>while</bold> the number of updated labels &lt; threshold <bold>do</bold></p><p>4:   Compute CNN parameters Θ for current labels <italic>y<sub>ij</sub></italic></p><p>5:   Compute <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p><p>6:   For each <italic>j</italic> where <italic>Y<sub>j</sub></italic> = 1, set <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>ifelse</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></p><p>7:   <bold>for</bold> each <italic>j</italic> where <italic>Y <sub>j</sub></italic> = 1 <bold>do</bold></p><p>8:    <bold>if</bold><inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula><bold>then</bold></p><p>9:     Compute <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="italic">arg</mml:mi><mml:munder><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p><p>10:     Set <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></p><p>11:    <bold>end if</bold></p><p>12:   <bold>end for</bold></p><p>13:  <bold>end while</bold></p><p>14:  OUTPUT (<inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>)</p><p>15: <bold>end procedure</bold></p></sec></boxed-text>The architecture of CNN must be adapted to the specifics of the MSI. In these experiments the number of <italic>m</italic>/<italic>z</italic> features can be very large (up to one hundred thousand), while the number of biological replicates is relatively small (typically &lt; 50). Therefore, the CNN should be relatively lightweight, and minimize the number of parameters to avoid overfitting. The convolution filter should be large enough to incorporate neighboring <italic>m</italic>/<italic>z</italic>, but small enough to benefit from weight sharing and computation reduction.</p>
      <p>We propose a 1D CNN, consisting of three basic components, namely convolutional layers, pooling layers and fully connected layers. Three convolutional layers hierarchically learn the potential patterns in a mass spectrum. For each layer, the filter size is set according to the contextual dependencies between <italic>m</italic>/<italic>z</italic> of interest, such as mass shifts corresponding to sodium adducts and molecular ions. After each convolutional layer, maxpooling reduces the resolution of the previous layer by focusing on large intensities of <italic>m</italic>/<italic>z</italic> features and reducing the impact of spectral noise. The CNN includes only one fully connected layer that captures globally distributed patterns (<xref ref-type="fig" rid="btaa436-F2">Fig. 2</xref>). <italic>Softmax</italic> activation function is used in the output layer to generate probability of each class.</p>
      <p>The CNN is trained using stochastic gradient descent. It calculates the partial derivative of the loss function in <xref ref-type="disp-formula" rid="E2">Equation (1)</xref> with respect to the learnable parameters in Θ by backpropagation, and iteratively updates Θ and values in each layer until convergence.</p>
      <p><bold>Tissue-level classification.</bold> The proposed tissue-level classification does not count the proportion of predicted location labels in a tissue. Instead, it treats each tissue as one observation, and uses the collection of mass spectra <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from all the locations in the tissue as its predictive features. The CNN architecture for this task is the same as the architecture for subtissue-level classification, with the exception of combining the probabilities of the individual locations into a pooling layer that estimates the probability of a tissue-level label. The pooling can be a simple max or mean pooling, or a generalized mean pooling
<disp-formula id="E3"><label>(2)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>r</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>I<sub>j</sub></italic> is the number of locations on tissue <italic>j</italic>, and <italic>r</italic> is an integer tuning parameter. The loss function is the cross-entropy of tissue-level predictions and tissue-level labels
<disp-formula id="E4"><label>(3)</label><mml:math id="M4"><mml:mrow><mml:munder><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mo>Θ</mml:mo></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mi>J</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>π<sub>j</sub></italic> is pooled probability of <italic>π<sub>ij</sub></italic>, and <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>Θ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are the predicted probabilities by CNN.</p>
    </sec>
    <sec>
      <title>3.4 Evaluation and interpretation</title>
      <p>We evaluate the accuracy of subtissue classification by calculating the accuracy and the balanced accuracy of label predictions at individual locations. We evaluate the accuracy of tissue-level classification by calculating the accuracy and the balanced accuracy of label predictions at the entire tissues. The metrics are defined as
<disp-formula id="E5"><label>(4)</label><mml:math id="M5"><mml:mrow><mml:mtext>Accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(5)</label><mml:math id="M6"><mml:mrow><mml:mtext>Balanced</mml:mtext><mml:mo> </mml:mo><mml:mtext>accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mtext>TN</mml:mtext></mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where for subtissue-level classification, <italic>TP</italic> is the number of correctly classified positive (i.e. tumor) locations across all the tissues, <italic>TN</italic> is the number of correctly classified negative (i.e. non-tumor) locations across all the tissues. <italic>P</italic> and <italic>N</italic> are the total numbers of locations across the tissues classified as tumor or non-tumor respectively. For tissue-level classification, <italic>TP</italic>, <italic>TN</italic>, <italic>P</italic> and <italic>N</italic> have the same interpretation, but for the entire tissues. Accuracy quantifies the overall proportion of correct predictions by model. When the number of observations in each class is not balanced, and the prediction of a minority class is under-represented, overall accuracy may inaccurately characterize the performance. In this case, balanced accuracy, quantifying the average of individual proportions of correct predictions in each class may provide more insights.</p>
      <p>Even when we can report the accuracy of classification, the classifier remains a black box. Therefore, we use LIME to assist with the interpretation, and identify <italic>m</italic>/<italic>z</italic> features that play a particularly important role in classifying the labels of individual locations. We randomly select a subset of locations in the validation sets in our experiments, use LIME to select top five influential features for each location, and rank the selected features by frequency of being selected in multiple locations.</p>
    </sec>
    <sec>
      <title>3.5 Implementation</title>
      <p>We implemented <italic>mi-CNN</italic> using Tensorflow (<xref rid="btaa436-B2" ref-type="bibr">Allaire and Tang, 2019</xref>) in the RStudio environment. We constructed a CNN architecture of three convolutional layers with Rectified Linear Unit (ReLU) activation, and a fully connected layer. The filter sizes of each convolutional layer were set as 38, 18 and 16. The network had 1774 trainable parameters in total for an input length of 850. CNN were trained using batch stochastic gradient descent optimization. Training one epoch of the renal cell carcinoma (RCC) dataset with 5350 spectra took ∼10 s, and training the entire model took ∼1.5 h on a computer with 64 RAM and 3.6 GHz CPU. Baseline model mi-SVM was implemented in R following (Andrews <italic>et al.</italic>, 2003). The maximum number of iterations of mi-SVM was set as 200. The kernel function used was radial basis function with gamma as 0.0012 in simulation datasets and human RCC data, and sigmoid function with gamma as 0.00125 in human bladder cancer data. LIME was implemented using R package <italic>lime</italic> (<xref rid="btaa436-B22" ref-type="bibr">Pedersen and Benesty, 2019</xref>). The number of bins for continuous variable was set as 4 and the kernel width was set as 0.1 in <italic>lime</italic>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Data</title>
    <p>We evaluated the performance of mi-CNN on five datasets. Two experimental datasets represent two human cancers, and two different MSI acquisition strategies (DESI, characterizing metabolites and lipids and MALDI, characterizing peptides). We further simulated three datasets with known ground truth, inspired from one of the experimental datasets.</p>
    <sec>
      <title>4.1 Human RCC experiment</title>
      <p>The experiment aimed to classify locations in human renal tissues as tumor versus healthy. Pairs of tumor and healthy tissue sections were collected from eight human donors with RCC. The tissues were subjected to serial H&amp;E staining. Pathology examination of the H&amp;E-stained tissues was unable to classify the tissues at the sub-tissue resolution, and only annotated each entire tissue section as tumor or healthy (<xref ref-type="fig" rid="btaa436-F3">Fig. 3</xref>).
</p>
      <fig id="btaa436-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Human RCC experiment. Pairs of tumor and healthy tissues from eight donors were H&amp;E stained, and examined by a pathologist. For each pair, the tissue on the left has the pathology annotation of tumor, and the tissue on the right has the pathology annotation of healthy. The subtissue-level annotations were not available for this experiment. (<bold>a</bold>) Training set and (b) Validation set</p>
        </caption>
        <graphic xlink:href="btaa436f3"/>
      </fig>
      <p>Data from the tissues were acquired using DESI ionization source on a Thermo Finnigan LTQ ion trap mass spectrometer in negative mode. The mass range covered 150–1000 Da. In total, 7567 mass spectra were collected from on average 472 locations per tissue. Prior to classification, the spectra were normalized by total ion current (TIC) and resampled to unit mass resolution, which produced 850 <italic>m</italic>/<italic>z</italic> features per mass spectrum. The data are available in R package <italic>CardinalWorkflow</italic> (<xref rid="btaa436-B7" ref-type="bibr">Bemis, 2019</xref>). The pairs of tissues were randomly split into a training set (six pairs) and validation set (two pairs).</p>
    </sec>
    <sec>
      <title>4.2 Human bladder cancer experiment</title>
      <p>The experiment aimed to classify human bladder cancer tissues as tumor versus stroma. Two tissue microarrays (TMAs) containing core needle biopsies from resected formalin-fixed and paraffin-embedded bladder tissues of 49 patients were built, and each TMA was mounted onto a separate glass slide (<xref ref-type="fig" rid="btaa436-F4">Fig. 4</xref>). A pathologist annotated 42 tissue cores by carefully examining sub-areas of each tissue and color-coded subregions presenting tumor and subregions presenting stroma (<xref ref-type="fig" rid="btaa436-F4">Fig. 4</xref>). The annotations are viewed as ground truth in this article. The label tumor was assigned to tissue cores containing tumor subregions, and the label stroma to cores containing only stroma.
</p>
      <fig id="btaa436-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Human bladder cancer experiment. H&amp;E-stained optical images of human bladder cancer tissues after data acquisition. Letters above each tissue are tissue-level annotations (T, tumor; S, stroma). The colors inside each core indicate subtissue-level pathology (red, tumor; blue, stroma), viewed as the ground truth. (<bold>a</bold>) Training set: 3 purely stroma tissues and 18 tissues with both tumor and stroma locations. (<bold>b</bold>) Validation set: 7 purely stroma tissues and 14 tissues with both tumor and stroma</p>
        </caption>
        <graphic xlink:href="btaa436f4"/>
      </fig>
      <p>The proteins in the tissues were digested with trypsin and the peptides were covered with alpha-cyano-4-hydroxycinnamic acid matrix and analyzed with an AB SCIEX 4800 MALDI Time-of-Flight (TOF)/TOF mass spectrometer in positive mode. The mass range was 800–2300 Da. Subregion annotations containing 3152 mass spectra in total and 77 spectra per tissue were extracted via an affine transformation strategy (<xref rid="btaa436-B13" ref-type="bibr">Föll <italic>et al.</italic>, 2019</xref>). The two datasets were resampled, combined and pre-processed using Cardinal and MALDIquant algorithms on <ext-link ext-link-type="uri" xlink:href="https://usegalaxy.eu">https://usegalaxy.eu</ext-link> (<xref rid="btaa436-B5" ref-type="bibr">Bemis <italic>et al.</italic>, 2015</xref>; <xref rid="btaa436-B13" ref-type="bibr">Föll <italic>et al.</italic>, 2019</xref>; <xref rid="btaa436-B15" ref-type="bibr">Gibb and Strimmer, 2012</xref>). The major pre-processing steps comprised peak picking, re-calibration, removal of contaminants and TIC normalization. The pre-processed file contained 593 <italic>m</italic>/<italic>z</italic> features. Annotated tissues from one slide were used as training set (21 tissues), and on the second slide as the validation set (21 tissues). The split aims to test the robustness of the classifier to experimental batch effects.</p>
      <p><bold>Simulated Dataset 1: one differentially abundant analyte with four features, and a complex background</bold>. The simulation is based on the mass spectra from eight healthy tissues in RCC dataset. It mimicked real-life variation in feature intensities, while providing the ground truth regarding both the labels of the tissue locations and the predictive features.</p>
      <p>First, the eight healthy tissues in the RCC dataset were split into two halves, as shown in <xref ref-type="fig" rid="btaa436-F5">Figure 5</xref>. Since the mass spectra from these tissues have real-life biological and technological variation, but no systematic variation between the tissue types, they are viewed as a complex background.
</p>
      <fig id="btaa436-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Simulated Dataset 1. Healthy tissues from the RCC experiment were split into halves. Locations on the left half of the upper newly created tissues were labeled as tumor, and the remaining locations as healthy. The labels were viewed as the ground truth. To mimic pathology annotations, the entire upper tissues were annotated as tumor, and the lower tissues as healthy. A synthetic analyte with four features, differentially abundant between tumor and healthy, was added to the experimental spectra. Its intensity was confounded by a morphology structure spanning both tissue types</p>
        </caption>
        <graphic xlink:href="btaa436f5"/>
      </fig>
      <p>Second, the newly created tissues were assigned tissue- and subtissue-level labels. The left half of the upper newly created tissues was labeled as tumor, and the remaining locations as healthy. These labels were viewed as the ground truth. To mimic pathology annotations at the tissue level, the entire upper tissues were annotated as tumor, and the lower tissues as healthy.</p>
      <p>Next, one synthetic differentially abundant analyte between the tumor and the healthy locations was added to the experimental spectra. The simulation incorporated a morphology (grey area in <xref ref-type="fig" rid="btaa436-F5">Fig. 5</xref>) that confounded the intensity of the differentially abundant analyte and spanned both tumor and the healthy tissue locations. The intensity <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> of this analyte at location <italic>i</italic> in tissue <italic>j</italic> was simulated as follows
<disp-formula id="E7"><label>(6)</label><mml:math id="M7"><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo>μ</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ϵ</mml:mo><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mover><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="italic">iid</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>δ</mml:mo><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>μ</italic> is the mean intensity of the analyte for tumor or stroma, <italic>S<sub>j</sub></italic> is the biological between-tissue variation, <italic>δ<sub>ij</sub></italic> is the variation between the morphological region and background, and <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:msub><mml:mrow><mml:mo>ε</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the biological and technological variation between locations of a same tissue. All the random variables are independent. <italic>I</italic><sub>in</sub> and <italic>I</italic><sub>out</sub> are indicators of whether a tissue location is inside or outside a morphology region, and <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> is the mean intensity shift of locations inside or outside the morphological region. Here <italic>μ </italic>= 50 for tumor and <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mrow><mml:mo>μ</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>150</mml:mn></mml:mrow></mml:math></inline-formula> for healthy, <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.15</mml:mn><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>δ</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>Δ</mml:mo><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ε</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <p>Finally, we simulated four individual <italic>m</italic>/<italic>z</italic> features generated by this analyte. The features correspond to dehydrated ions <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mi>O</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 407), molecular molecules <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (m/z 425), sodium adducts <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 447) and potassium adducts <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<italic>m</italic>/<italic>z</italic> 463). Each feature was simulated as <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>/</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mi mathvariant="italic">Dirchlet</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
      <p>Similarly to the RCC dataset, the tissues were split into a training set of six tissue pairs, and a validation set of two tissue pairs.</p>
      <p><bold>Simulated Dataset 2: one analyte with differential relative intensity of two of the four features, and a complex background.</bold> We mimicked a situation where tumor locations affect the relative intensities of features of a same analyte. We assumed that the synthetic analyte produced more potassium adducts in tumor locations, but more sodium adducts in healthy tissues. The simulation repeated the procedure above, while setting the mean intensity of the analyte to <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:mo>μ</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:math></inline-formula> 50 for both tumor and healthy locations, and setting the total intensity of molecular ions and dehydrated ions to <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>407</mml:mn><mml:mo>,</mml:mo><mml:mn>425</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The total intensity of adducts <inline-formula id="IE34"><mml:math id="IM34"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> was simulated from <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:mi mathvariant="italic">Dirichlet</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>. Next, in the tumor locations we set the intensity of sodium adducts <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, the intensity of potassium adducts <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. In the healthy locations we set the intensity of sodium adducts <inline-formula id="IE38"><mml:math id="IM38"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, and the intensity of potassium adducts <inline-formula id="IE39"><mml:math id="IM39"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>447</mml:mn><mml:mo>,</mml:mo><mml:mn>463</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> in healthy.</p>
      <p><bold>Simulated Dataset 3: impact of biological variation, technological variation and sample size.</bold> The simulation evaluated the effect of biological and technological variation, and of the number of tissues in the training set, on the performance of mi-CNN. We simulated training sets with between 13 and 130 tissues, half of which annotated at the tissue level as tumor, and the other half as healthy. Each simulated tissue was characterized by 25 locations, with spectra randomly selected from the healthy tissues in the RCC experiment to represent complex background. As in Datasets 1 and 2, only half of the locations in the tumor-annotated tissues had tumor locations as the ground truth. The synthetic analyte was simulated as in <xref ref-type="disp-formula" rid="E7">Equation (6)</xref>, with <italic>μ</italic>  =  50 for the tumor locations and <italic>μ</italic>  =  150 for the healthy locations. <italic>σ<sub>S</sub></italic> varied from <inline-formula id="IE40"><mml:math id="IM40"><mml:mrow><mml:mn>0.1</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE41"><mml:math id="IM41"><mml:mrow><mml:mn>0.3</mml:mn><mml:mo>μ</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mo>ε</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> varied between <inline-formula id="IE42"><mml:math id="IM42"><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE43"><mml:math id="IM43"><mml:mrow><mml:mn>0.15</mml:mn><mml:mo>μ</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
  </sec>
  <sec>
    <title>5 Results</title>
    <sec>
      <title>5.1 Results for the simulated datasets</title>
      <p><bold>Taking as input tissue-level annotations, mi-CNN accurately classified subtissue labels.</bold> We compared the ability of mi-CNN and mi-SVM, and that of the classical CNN and SVM, to classify subtissue labels on Simulated Dataset 1. <xref rid="btaa436-T1" ref-type="table">Table 1</xref> shows that SVM and CNN had high accuracy when comparing the classified locations to tissue-level annotations in the training set. This is expected, as the methods were trained to minimize the classification loss with respect to tissue-level annotations. However, these predictive patterns were undermined by the mislabeled healthy locations in the tumor-annotated tissues of the training set. When comparing the classifications to the ground truth at the location level, the methods had worse accuracy (and worse balanced accuracy, that accounts for differences in the number of tumor and healthy locations) in both the training and the validation dataset. <xref ref-type="fig" rid="btaa436-F6">Figure 6</xref> details the predictions on the validation set. It illustrates that SVM had poor predictions for both tumor and healthy locations, while CNN had poor predictions for healthy locations.
</p>
      <fig id="btaa436-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>Simulation Dataset 1: subtissue-level classification on the validation set </p>
        </caption>
        <graphic xlink:href="btaa436f6"/>
      </fig>
      <table-wrap id="btaa436-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Simulated Dataset 1: classification accuracy</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Compare with</th>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.895 (0.895)</td>
              <td rowspan="1" colspan="1">0.948 (0.948)</td>
              <td rowspan="1" colspan="1">0.885 (0.882)</td>
              <td rowspan="1" colspan="1">0.751 (0.742)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.747 (0.833)</td>
              <td rowspan="1" colspan="1">0.747 (0.833)</td>
              <td rowspan="1" colspan="1">0.809 (0.862)</td>
              <td rowspan="1" colspan="1">0.979 (0.981)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.778 (0.671)</td>
              <td rowspan="1" colspan="1">0.752 (0.831)</td>
              <td rowspan="1" colspan="1">0.833 (0.693)</td>
              <td rowspan="1" colspan="1">0.975 (0.964)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note</italic>: Accuracy [<xref ref-type="disp-formula" rid="E5">Equation (4)]</xref> and balanced accuracy [in parentheses, <xref ref-type="disp-formula" rid="E6">Equation (5)]</xref>. The first two rows evaluate the accuracy with respect to tissue-level annotations. The last four rows evaluate the accuracy with respect to labels of within-tissue locations.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Although the accuracy of mi-SVM and mi-CNN classification compared with tissue-level annotations was lower than that of SVM and CNN (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Row 1 and 2), their results were closer to the ground truth location labels, both on the training (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Rows 3 and 4) and the validation sets (<xref rid="btaa436-T1" ref-type="table">Table 1</xref>, Rows 5 and 6). <xref ref-type="fig" rid="btaa436-F6">Figure 6</xref> illustrates that mi-SVM, and in particular mi-CNN, classified the labels of the individual locations more correctly.</p>
      <p><xref rid="btaa436-T2" ref-type="table">Table 2</xref> shows that the results are not limited to situations when the predictive analyte is differentially abundant. Qualitatively similar results are obtained with the predictive pattern in Simulated Dataset 2.</p>
      <p><bold>mi-CNN improved subtissue classification by leveraging changes in relative abundances of features from a same analyte.</bold><xref rid="btaa436-T1" ref-type="table">Tables 1</xref> and <xref rid="btaa436-T2" ref-type="table">2</xref> show that mi-CNN and CNN had higher classification accuracy with respect to the location labels as compared to mi-SVM and SVM. To evaluate whether the improved accuracy was due to the CNN’s ability to capture the contextual relationships between related <italic>m</italic>/<italic>z</italic>, we ranked the predictive features by their importance in these methods using LIME. <xref ref-type="fig" rid="btaa436-F7">Figure 7</xref> compares the relative importance of the top five features, when classifying a tumor location in one tissue with mi-SVM and mi-CNN. Both methods classified this location correctly. However, while in mi-SVM the most predictive feature is part of the background, mi-CNN ranked the <italic>m</italic>/<italic>z</italic> features (407, 425, 447 and 463) of the synthetic differentially abundant analyte among the top five most predictive.
</p>
      <fig id="btaa436-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Simulated Dataset 1: LIME-based importance of <italic>m</italic>/<italic>z</italic> features when classifying a tumor location in the validation set. A location in the simulated tissue UH9912_01 was classified correctly by both mi-SVM and mi-CNN. However, only mi-CNN captured the four <italic>m</italic>/<italic>z</italic> features (407, 425, 447 and 463) from the synthetic differentially abundant analyte. (<bold>a</bold>) mi-SVM and (<bold>b</bold>) mi-CNN</p>
        </caption>
        <graphic xlink:href="btaa436f7"/>
      </fig>
      <table-wrap id="btaa436-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Simulated Dataset 2: classification accuracy</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Compare with</th>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.532 (0.530)</td>
              <td rowspan="1" colspan="1">0.778 (0.777)</td>
              <td rowspan="1" colspan="1">0.860 (0.856)</td>
              <td rowspan="1" colspan="1">0.700 (0.690)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.565 (0.538)</td>
              <td rowspan="1" colspan="1">0.734 (0.810)</td>
              <td rowspan="1" colspan="1">0.758 (0.776)</td>
              <td rowspan="1" colspan="1">0.877 (0.800)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.530 (0.449)</td>
              <td rowspan="1" colspan="1">0.869 (0.896)</td>
              <td rowspan="1" colspan="1">0.771 (0.500)</td>
              <td rowspan="1" colspan="1">0.912 (0.701)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic>Note</italic>: As <xref rid="btaa436-T1" ref-type="table">Table 1</xref>, for Simulated Dataset 2.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Out of 200 randomly selected locations, mi-CNN consistently ranked all these features among the top five most predictive in 32.3% of the locations, and at least one of these features among the top five most predictive in 99.3% of the locations. The respective numbers for mi-SVM were very low, 0% and 6%. This illustrates the utility of incorporating the domain-specific information in the size of the convolution filter in the neural network.</p>
      <p><bold>In presence of larger variation, accurate subtissue-level classification with mi-CNN required a larger sample size.</bold> We evaluated the accuracy of mi-CNN with respect to subtissue labels on Simulated Dataset 3. <xref ref-type="fig" rid="btaa436-F8">Figure 8a</xref> shows that, in situations where both between-tissue and within-tissue variation is relatively small, mi-CNN can have a high classification accuracy on the validation set, even when trained on a relatively small number of 12 biological replicates. <xref ref-type="fig" rid="btaa436-F8">Figure 8c and d</xref> illustrates that the between-tissue variation dominates the classification accuracy, and the within-tissue variation has a relatively small impact. Including more biological replicates is beneficial when variation is large.
</p>
      <fig id="btaa436-F8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>Simulated Dataset 3: impact of biological (a,b) and technological variation (c,d) of the synthetic analyte, and of the number of training set tissues, on the accuracy of mi-CNN with respect to subtissue labels. When biological variation is relatively small, mi-CNN correctly classified subtissue locations, even with a small number of biological replicates in the training set. Including more biological replicates is beneficial when variation is large</p>
        </caption>
        <graphic xlink:href="btaa436f8"/>
      </fig>
    </sec>
    <sec>
      <title>5.2 Results for the experimental datasets</title>
      <p><bold>RCC experiment.</bold> Although subtissue-level ground truth was not available for the RCC experiment, we used the fact that the tissue sections annotated as healthy were expected to be free from tumor. Therefore, we evaluated the classifications with respect to the homogeneity of subtissue classification of the healthy sections. <xref ref-type="fig" rid="btaa436-F9">Figure 9</xref> illustrates that, on the training set, mi-SVM and mi-CNN both had homogeneous predictions of healthy on healthy tissue. On the validation set, mi-CNN had slightly more homogeneous predictions of healthy on healthy tissues than mi-SVM. The predictions of SVM and mi-SVM had no substantial difference in this dataset. CNN has less homogeneous predictions of healthy on healthy tissues than mi-CNN in both training and validation set. This indicates that mi-CNN can improve prediction on healthy locations by considering healthy locations in the tumor tissues.
</p>
      <fig id="btaa436-F9" orientation="portrait" position="float">
        <label>Fig. 9.</label>
        <caption>
          <p>Classification accuracy: the RCC experiment. (<bold>a</bold>) Tissue-level pathology annotations. (<bold>b</bold>) Optical images of H&amp;E stained tissues. (<bold>c-f</bold>) Subtissue-level classifications</p>
        </caption>
        <graphic xlink:href="btaa436f9"/>
      </fig>
      <p>LIME-based interpretation of mi-SVM and mi-CNN highlighted different features as highly predictive. For mi-SVM, <italic>m</italic>/<italic>z</italic> 181, 215, 760, 865 and 898 were ranked as the top 5 most important. For mi-CNN, these were <italic>m</italic>/<italic>z</italic> 217, 751, 773, 885 and 886. These results indicate that the choice of the classifier plays an important role in both predictive accuracy and the choice of predictive features in this dataset.</p>
      <p><bold>Human bladder cancer experiment.</bold><xref ref-type="fig" rid="btaa436-F10">Figure 10</xref> compares the classification of SVM, CNN, mi-SVM and mi-CNN with the ground truth subtissue-level labels on selected heterogeneous tumor tissue and pure stroma tissue. Similar to results on Simulated Datasets 1 and 2, SVM and CNN classified many stroma locations in the tumor tissue as tumor in the training dataset (see <xref ref-type="fig" rid="btaa436-F10">Fig. 10</xref>). Not surprisingly, both SVM and CNN had poor predictions in the validation set, presenting mixture predictions of tumor and stroma in the stroma tissue.
</p>
      <fig id="btaa436-F10" orientation="portrait" position="float">
        <label>Fig. 10.</label>
        <caption>
          <p>Classification accuracy: the human bladder cancer experiment. (<bold>a</bold>) Tissue-level pathology annotations. (<bold>b</bold>) Subtissue-level pathology labels on optical images. (<bold>c</bold>) Subtissue-level labels on MSI (viewed as ground truth). (<bold>d–g</bold>) Subtissue-level classifications</p>
        </caption>
        <graphic xlink:href="btaa436f10"/>
      </fig>
      <p>mi-SVM and mi-CNN improved the classification of SVM and CNN in terms of both accuracy and balanced accuracy (<xref rid="btaa436-T3" ref-type="table">Table 3</xref>). From <xref ref-type="fig" rid="btaa436-F10">Figure 10</xref>, mi-CNN correctly classified more stroma locations in the tumor tissues than mi-SVM for both training and validation tissues. In addition, mi-CNN had the smallest number of false positives on the stroma tissues, showing most clean classifications in stroma tissues in <xref ref-type="fig" rid="btaa436-F10">Figure 10</xref>.
</p>
      <table-wrap id="btaa436-T3" orientation="portrait" position="float">
        <label>Table 3.</label>
        <caption>
          <p>Classification accuracy: the human bladder cancer experiment</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">SVM</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">mi-SVM</th>
              <th rowspan="1" colspan="1">mi-CNN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="2" colspan="1">Training</td>
              <td rowspan="1" colspan="1">Tissue annotations</td>
              <td rowspan="1" colspan="1">0.959 (0.946)</td>
              <td rowspan="1" colspan="1">0.827 (0.946)</td>
              <td rowspan="1" colspan="1">0.939 (0.946)</td>
              <td rowspan="1" colspan="1">0.800 (0.855)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.801 (0.793)</td>
              <td rowspan="1" colspan="1">0.767 (0.759)</td>
              <td rowspan="1" colspan="1">0.847 (0.842)</td>
              <td rowspan="1" colspan="1">0.941 (0.941)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Validation</td>
              <td rowspan="1" colspan="1">Subtissue labels</td>
              <td rowspan="1" colspan="1">0.755 (0.750)</td>
              <td rowspan="1" colspan="1">0.779 (0.774)</td>
              <td rowspan="1" colspan="1">0.827 (0.823)</td>
              <td rowspan="1" colspan="1">0.928 (0.928)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic>Note</italic>: Values without the parentheses are accuracy calculated by <xref ref-type="disp-formula" rid="E5">Equation (4)</xref>. Values in parenthesis are balanced accuracy calculated by <xref ref-type="disp-formula" rid="E6">Equation (5)</xref>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>LIME analysis of mi-CNN classifications of a subset of 200 locations in validation set selected <italic>m</italic>/<italic>z</italic> 925.44, 944.44, 946.44, 1105.54 and 1198.69 as most predictive. Among those, <italic>m</italic>/<italic>z</italic> 944.44 is likely to be Histone 2 A, which is known to be upregulated in tumors, and <italic>m</italic>/<italic>z</italic> 1105.54 is likely to correspond to Collagen I which is known to be upregulated in stroma. LIME analysis of mi-SVM selected five different predictive features, <italic>m</italic>/<italic>z</italic> 1669.73, 1475.72, 1529.7, 963.44 and 1054.49.</p>
    </sec>
  </sec>
  <sec>
    <title>6 Discussion</title>
    <p>We introduced mi-CNN, a deep MIL approach for classifying subtissue locations in MSI experiments. The multiple instance aspect of the approach enabled training the classifier with weak supervision, using rough tissue-level annotations in the training set. The convolutional architecture of the CNN captured contextual dependencies between the spectral features. Evaluations on simulated and experimental datasets demonstrated that mi-CNN improved the subtissue classification as compared with traditional SVM and CNN.</p>
    <p>The approach assumed that, in a binary classification problem, a tissue labeled as tumor had at least one tumor location, but the tissues labeled as non-tumor were tumor-free. This assumption is reasonable for MSI, as homogeneous healthy tissue biopsies are relatively easy to obtain, however tumor biopsies are more likely to contain a mix of tumor and non-tumor regions. In a case where both non-tumor and tumor tissues are heterogeneous, the proposed approach is no longer suitable since the reliable label of non-tumor is crucial to the method. Although we only discussed binary classification, mi-CNN can also be adapted to multi-class classification, such as different grades of tumor tissues or multiple tissue types.</p>
    <p>In contrast to the typical applications of CNN in computer vision, the CNN architecture in this work did not include spatial convolution of tissues. This is a consequence of typically high heterogeneity of the microenvironment within a tumor, and of lack of spatial smoothness of location labels.</p>
    <p>At the same time, the CNN architecture took advantage of the mass spectral patterns to alleviate the high dimensionality and the high correlations in the predictive feature space. In this work, the size of convolutional filters captured one of the most common sources of correlations between <italic>m</italic>/<italic>z</italic>, i.e. the presence of molecular ions and their adducts. The <italic>m</italic>/<italic>z</italic> dependencies can become more complicated and ambiguous in other cases, e.g. with larger mass ranges. The convolutional aspects can be easily adapted to such situations types by changing the size of filter and the network depth.</p>
    <p>Although neural networks have a large parameter space and need large training datasets, we found that mi-CNN worked well on the relatively small numbers of biological tissues. This may be due to a combination of the CNN architecture, which uses locally connected neurons and weight sharing filters to reduce the parameter space and the computational cost, and a relatively large number of heterogeneous subtissue locations available for training.</p>
    <p>Overall, we found that mi-CNN is well-suited for training subtissue-level classifiers on datasets with tissue-level annotations. This is particularly important in situations where tumor and non-tumor tissues are tightly connected, making manual labeling of the training sets difficult or even impossible at all. The approach is an important step toward taking a full advantage of MSI’s capability of providing molecular information, and minimizing manual labor for tissue imaging and classification.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgement</title>
    <p>We thank K. A. Bemis for helpful discussions.</p>
    <sec>
      <title>Funding</title>
      <p>The work was supported in part by the NSF [award DBI-1759736 to O.V.]; and by the German Research Council [DFG, SCHI 871/11-1 to O.S.].</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa436-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aichler</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Walch</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>) 
<article-title>MALDI imaging mass spectrometry: current frontiers and perspectives in pathology research and practice</article-title>. <source>Lab. Invest</source>., <volume>95</volume>, <fpage>422</fpage>–<lpage>431</lpage>.<pub-id pub-id-type="pmid">25621874</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Allaire</surname><given-names>J.J.</given-names></name>, <name name-style="western"><surname>Tang</surname><given-names>Y.</given-names></name></person-group> (<year>2019</year>) <italic>Tensorflow: R Interface to ‘TensorFlow’.</italic> R package version 2.0.0.</mixed-citation>
    </ref>
    <ref id="btaa436-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Andrews</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>Support vector machines for multiple-instance learning</article-title>. In: <italic>Advances in Neural Information Processing Systems</italic>, p. <fpage>577</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Behrmann</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Deep learning for tumor classification in imaging mass spectrometry</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1215</fpage>–<lpage>1223</lpage>.<pub-id pub-id-type="pmid">29126286</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Cardinal: an R package for statistical analysis of mass spectrometry-based imaging experiments</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>2418</fpage>–<lpage>2420</lpage>.<pub-id pub-id-type="pmid">25777525</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Probabilistic segmentation of mass spectrometry images helps select important ions and characterize confidence in the resulting segments</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>15</volume>, <fpage>1761</fpage>–<lpage>1772</lpage>.<pub-id pub-id-type="pmid">26796117</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Bemis</surname><given-names>K.A.</given-names></name></person-group> (<year>2019</year>) <italic>CardinalWorkflows: Datasets and Workflows for the Cardinal Mass Spectrometry Imaging Package</italic>. R package version 1.17.0.</mixed-citation>
    </ref>
    <ref id="btaa436-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Calligaris</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MALDI mass spectrometry imaging analysis of pituitary adenomas for near-real-time tumor delineation</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>112</volume>, <fpage>9978</fpage>–<lpage>9983</lpage>.<pub-id pub-id-type="pmid">26216958</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cheplygina</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Not-so-supervised: a survey of semi-supervised, multi-instance, and transfer learning in medical image analysis</article-title>. <source>Med. Image Anal</source>., <volume>54</volume>, <fpage>280</fpage>–<lpage>296</lpage>.<pub-id pub-id-type="pmid">30959445</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dill</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Multivariate statistical differentiation of renal cell carcinomas based on lipidomic analysis by ambient ionization imaging mass spectrometry</article-title>. <source>Anal. Bioanal. Chem</source>., <volume>398</volume>, <fpage>2969</fpage>–<lpage>2978</lpage>.<pub-id pub-id-type="pmid">20953777</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dill</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Multivariate statistical identification of human bladder carcinomas using ambient ionization imaging mass spectrometry</article-title>. <source>Chemistry</source>, <volume>17</volume>, <fpage>2897</fpage>–<lpage>2902</lpage>.<pub-id pub-id-type="pmid">21284043</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Eberlin</surname><given-names>L.S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Molecular assessment of surgical-resection margins of gastric cancer by mass-spectrometric imaging</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>111</volume>, <fpage>2436</fpage>–<lpage>2441</lpage>.<pub-id pub-id-type="pmid">24550265</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Föll</surname><given-names>M.C.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Reproducible mass spectrometry imaging data analysis in Galaxy</article-title>. <source>GigaScience</source>, <volume>8</volume>, <fpage>628719</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fu</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>MILIS: multiple instance learning with instance selection</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>33</volume>, <fpage>958</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gibb</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Strimmer</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>) 
<article-title>MALDIQUANT: a versatile R package for the analysis of mass spectrometry data</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>2270</fpage>–<lpage>2271</lpage>.<pub-id pub-id-type="pmid">22796955</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Inglese</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Deep learning and 3D-DESI imaging reveal the hidden metabolic heterogeneity of cancer</article-title>. <source>Chem. Sci</source>., <volume>8</volume>, <fpage>3500</fpage>–<lpage>3511</lpage>.<pub-id pub-id-type="pmid">28507724</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>E.A.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Imaging mass spectrometry statistical analysis</article-title>. <source>J. Proteomics</source>, <volume>75</volume>, <fpage>4962</fpage>–<lpage>4989</lpage>.<pub-id pub-id-type="pmid">22743164</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kandemir</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Hamprecht</surname><given-names>F.A.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Computer-aided diagnosis from weak supervision: a benchmarking study</article-title>. <source>Comput. Med. Imaging Graph</source>., <volume>42</volume>, <fpage>44</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">25475486</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kriegsmann</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>MALDI TOF imaging mass spectrometry in clinical pathology: a valuable tool for cancer diagnostics (review)</article-title>. <source>Int. J. Oncol</source>., <volume>46</volume>, <fpage>893</fpage>–<lpage>906</lpage>.<pub-id pub-id-type="pmid">25482502</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lou</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>An experimental guideline for the analysis of histologically heterogeneous tumors by MALDI-TOF mass spectrometry imaging</article-title>. <source>Biochim. Biophys. Acta Proteins Proteom</source>., <volume>1865</volume>, <fpage>957</fpage>–<lpage>966</lpage>.<pub-id pub-id-type="pmid">27725306</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B21">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Molnar</surname><given-names>C.</given-names></name></person-group> (<year>2019</year>) <italic>Interpretable Machine Learning</italic>. Lulu. com.</mixed-citation>
    </ref>
    <ref id="btaa436-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Pedersen</surname><given-names>T.L.</given-names></name>, <name name-style="western"><surname>Benesty</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>) <italic>LIME: Local Interpretable Model-Agnostic Explanations</italic>. R package version 0.5.1.</mixed-citation>
    </ref>
    <ref id="btaa436-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rauser</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Classification of HER2 receptor status in breast cancer tissues by MALDI imaging mass spectrometry</article-title>. <source>J. Proteome Res</source>., <volume>9</volume>, <fpage>1854</fpage>–<lpage>1863</lpage>.<pub-id pub-id-type="pmid">20170166</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rawat</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Deep convolutional neural networks for image classification: a comprehensive review</article-title>. <source>Neural Comput</source>., <volume>29</volume>, <fpage>2352</fpage>–<lpage>2449</lpage>.<pub-id pub-id-type="pmid">28599112</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ribeiro</surname><given-names>M.T.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>“Why should I trust you?” Explaining the predictions of any classifier</article-title>. In: <italic>22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>, p. <fpage>1135</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sans</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Metabolic markers and statistical prediction of serous ovarian cancer aggressiveness by ambient ionization mass spectrometry imaging</article-title>. <source>Cancer Res</source>., <volume>77</volume>, <fpage>2903</fpage>–<lpage>2913</lpage>.<pub-id pub-id-type="pmid">28416487</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Spengler</surname><given-names>B.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Mass spectrometry imaging of biomolecular information</article-title>. <source>Anal. Chem</source>., <volume>87</volume>, <fpage>64</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">25490190</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>van Kersbergen</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Cancer detection in mass spectrometry imaging data by dilated convolutional neural networks</article-title>. In: <italic>Medical Imaging 2019: Digital Pathology</italic>, Vol. <volume>10956</volume>, p. 109560I, International Society for Optics and Photonics.</mixed-citation>
    </ref>
    <ref id="btaa436-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vaysse</surname><given-names>P.M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Mass spectrometry imaging for clinical research-latest developments, applications, and current limitations</article-title>. <source>Analyst</source>, <volume>142</volume>, <fpage>2690</fpage>–<lpage>2712</lpage>.<pub-id pub-id-type="pmid">28642940</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wu</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Mass spectrometry imaging under ambient conditions</article-title>. <source>Mass Spectrom. Rev</source>., <volume>32</volume>, <fpage>218</fpage>–<lpage>243</lpage>.<pub-id pub-id-type="pmid">22996621</pub-id></mixed-citation>
    </ref>
    <ref id="btaa436-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Multiple instance boosting for object detection</article-title>. In: <italic>Advances in Neural Information Processing Systems</italic>, p. <fpage>1417</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa436-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>Z.-H.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Multi-instance learning by treating instances as non-IID samples</article-title>. In: <italic>Proceedings of the 26th Annual International Conference on Machine Learning</italic>, p. <fpage>1249</fpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
