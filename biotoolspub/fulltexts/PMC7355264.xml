<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355264</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa447</article-id>
    <article-id pub-id-type="publisher-id">btaa447</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Population Genomics and Molecular Evolution</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EvoLSTM: context-dependent models of sequence evolution using a sequence-to-sequence LSTM</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Lim</surname>
          <given-names>Dongjoon</given-names>
        </name>
        <xref ref-type="aff" rid="btaa447-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-9555-860X</contrib-id>
        <name>
          <surname>Blanchette</surname>
          <given-names>Mathieu</given-names>
        </name>
        <xref ref-type="corresp" rid="btaa447-cor1"/>
        <xref ref-type="aff" rid="btaa447-aff1"/>
        <!--<email>blanchem@cs.mcgill.ca</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa447-aff1"><institution>School of Computer Science, McGill University</institution>, Montreal, Quebec H3A 0G4, <country country="CA">Canada</country></aff>
    <author-notes>
      <corresp id="btaa447-cor1">To whom correspondence should be addressed. E-mail: <email>blanchem@cs.mcgill.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i353</fpage>
    <lpage>i361</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa447.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Accurate probabilistic models of sequence evolution are essential for a wide variety of bioinformatics tasks, including sequence alignment and phylogenetic inference. The ability to realistically simulate sequence evolution is also at the core of many benchmarking strategies. Yet, mutational processes have complex context dependencies that remain poorly modeled and understood.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We introduce EvoLSTM, a recurrent neural network-based evolution simulator that captures mutational context dependencies. EvoLSTM uses a sequence-to-sequence long short-term memory model trained to predict mutation probabilities at each position of a given sequence, taking into consideration the 14 flanking nucleotides. EvoLSTM can realistically simulate mammalian and plant DNA sequence evolution and reveals unexpectedly strong long-range context dependencies in mutation probabilities. EvoLSTM brings modern machine-learning approaches to bear on sequence evolution. It will serve as a useful tool to study and simulate complex mutational processes.</p>
      </sec>
      <sec id="s4">
        <title>Availability and implementation</title>
        <p>Code and dataset are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/DongjoonLim/EvoLSTM">https://github.com/DongjoonLim/EvoLSTM</ext-link>.</p>
      </sec>
      <sec id="s6">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Genome Canada Large-Scale Applied Research Project</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science and Engineering Research Council of Canada</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Probabilistic models of sequence evolution are among the earliest areas of research in bioinformatics. These models aim to quantify the probability of specific types of mutations such as substitutions (<xref rid="btaa447-B37" ref-type="bibr">Jukes <italic>et al.</italic>, 1969</xref>; <xref rid="btaa447-B38" ref-type="bibr">Kimura, 1980</xref>) and small indels (<xref rid="btaa447-B62" ref-type="bibr">Thorne <italic>et al.</italic>, 1991</xref>) in an evolving sequence. They provide the necessary probabilistic framework that allows formulating meaningful biological questions such as sequence alignment and phylogenetic inference. They also enable the realistic simulation of sequence evolution, and increasingly accurate tools have been introduced for this purpose over the years, including Rose (<xref rid="btaa447-B59" ref-type="bibr">Stoye <italic>et al.</italic>, 1998</xref>), INDELible (<xref rid="btaa447-B26" ref-type="bibr">Fletcher and Yang, 2009</xref>) and Evolver (<xref rid="btaa447-B23" ref-type="bibr">Edgar <italic>et al.</italic>, 2019</xref>). By enabling the simulation of fake but evolutionarily related sequences, these approaches enable benchmarking and validating bioinformatics tools for problems such as multiple sequence alignment (<xref rid="btaa447-B21" ref-type="bibr">Earl <italic>et al.</italic>, 2014</xref>; <xref rid="btaa447-B22" ref-type="bibr">Edgar, 2004</xref>; <xref rid="btaa447-B40" ref-type="bibr">Lassmann and Sonnhammer, 2005</xref>; <xref rid="btaa447-B51" ref-type="bibr">Papadopoulos and Agarwala, 2007</xref>; <xref rid="btaa447-B53" ref-type="bibr">Ramakrishnan <italic>et al.</italic>, 2018</xref>), ancestral genome reconstruction (<xref rid="btaa447-B13" ref-type="bibr">Blanchette <italic>et al.</italic>, 2004b</xref>) and phylogenetic inference (<xref rid="btaa447-B52" ref-type="bibr">Price <italic>et al.</italic>, 2010</xref>).</p>
    <p>Mutation probabilities have long been known to be dependent on sequence context: the probability of a mutation happening at a certain site does not only depend on the type of mutation (e.g. transition versus transversion), but also on the nucleotides around it (<xref rid="btaa447-B5" ref-type="bibr">Arenas, 2015</xref>). In some cases, this dependency is intrinsic to the mutational process itself. For example, perhaps the strongest type of context dependencies is the elevated C-to-T substitution rate in the context of a CpG dinucleotide, caused by the deamination of a methylated cytosine, transforming it to a thymine (<xref rid="btaa447-B11" ref-type="bibr">Bird, 1980</xref>; <xref rid="btaa447-B24" ref-type="bibr">Ehrlich and Wang, 1981</xref>). In other cases, it is the result of context-dependent DNA repair. <xref rid="btaa447-B61" ref-type="bibr">Surrallés <italic>et al.</italic> (2002)</xref> found that the transcription-coupled repair machinery shows high localization on gene rich regions of the human genome, and <xref rid="btaa447-B25" ref-type="bibr">Feng <italic>et al.</italic> (2002)</xref> found that transcription-coupled repair of cyclobutane pyrimidine dimers in Chinese hamster genome is context-dependent. Finally, it may be the result of context-dependent selective pressure. For example, coding sequence evolution is best captured by a 3-nucleotide codon model that accounts for the consequences of a nucleotide change on the amino acid encoded (<xref rid="btaa447-B28" ref-type="bibr">Goldman and Yang, 1994</xref>). There is also a rich literature on co-evolution models in DNA (<xref rid="btaa447-B42" ref-type="bibr">Makova and Hardison, 2015</xref>), RNA (<xref rid="btaa447-B33" ref-type="bibr">Holmes, 2004</xref>) and proteins (<xref rid="btaa447-B55" ref-type="bibr">Rodrigue <italic>et al.</italic>, 2005</xref>). Insertions and deletion rates also exhibit strong context dependencies, often linked to DNA polymerase slippage in locally repetitive sequences (<xref rid="btaa447-B43" ref-type="bibr">Messer and Arndt, 2007</xref>).</p>
    <p>Several types of models have been introduced to capture mutational context dependencies. <xref rid="btaa447-B36" ref-type="bibr">Jensen and Pedersen (2000)</xref> proposed a Markov chain Monte Carlo method to calculate the substitution rate dependent on its two flanking bases inside a protein-coding DNA region. Later, a maximum likelihood analysis to infer nucleotide or dinucleotide mutation frequencies in non-coding regions of the genome was proposed (<xref rid="btaa447-B7" ref-type="bibr">Arndt <italic>et al.</italic>, 2003</xref>). <xref rid="btaa447-B57" ref-type="bibr">Siepel and Haussler (2003)</xref> introduced a context-dependent substitution model that has been developed to reflect context dependencies in both coding and non-coding regions of the genome, and a parameter-rich Bayesian network substitution model with parameters defined from flanking base contexts for genome-wide ancestral reconstruction were developed (<xref rid="btaa447-B14" ref-type="bibr">Chachick and Tanay, 2012</xref>). However, these methods often limit the context effect to one flanking nucleotide/amino acid on each side due to the computational cost and sample size requirements growing exponentially with context size. The extent of longer-range dependencies in mutation rates is thus poorly understood, although sparse Bayesian models (<xref rid="btaa447-B41" ref-type="bibr">Ling <italic>et al.</italic>, 2019</xref>) have recently been introduced for that purpose and applied to viral evolution to determine the significance of certain configurations of nucleotide around mutation sites by inferring the mutation rate of 5-mers. <xref rid="btaa447-B2" ref-type="bibr">Aggarwala and Voight (2016)</xref> proposed a statistical model that takes parameters from observed frequency of mutations within 5-mer or 7-mer, while <xref rid="btaa447-B66" ref-type="bibr">Zhu <italic>et al.</italic> (2017)</xref> introduced a log-linear model for mutation frequency analysis that also considers up to 5-mers. It has also been found that variability of mutation in human genome between different populations of human genome are dependent on context beyond the immediate flanking bases (<xref rid="btaa447-B3" ref-type="bibr">Aikens <italic>et al.</italic>, 2019</xref>).</p>
    <p>To overcome the limitations of these probabilistic context-dependent substitution models, we propose an evolutionary model that harnesses recent developments in machine learning. In recent years, recurrent neural networks (RNNs) have enabled models to learn in the context of time series data much more efficiently than previously possible. In particular, the long short-term memory (LSTM) model architecture (<xref rid="btaa447-B27" ref-type="bibr">Gers <italic>et al.</italic>, 2000</xref>) made it possible for the deep neural network in the area of natural language modeling to overcome the vanishing gradient problem of standard RNN (<xref rid="btaa447-B60" ref-type="bibr">Sundermeyer <italic>et al.</italic>, 2012</xref>). More recently, RNN-encoder–decoder (<xref rid="btaa447-B15" ref-type="bibr">Cho <italic>et al.</italic>, 2014</xref>) architectures, which separate the network into an RNN-encoder and RNN-decoder to better capture the context of the input sequence, were introduced, with applications to automated language translation. With a similar idea, sequence-to-sequence models (Sutskever <italic>et al.</italic>, 2014) have shown that using LSTM networks in the encoder–decoder architecture can further improve the capacity to capture the context of the input in neural machine translation.</p>
    <p>In this paper, we introduce EvoLSTM, a sequence-to-sequence LSTM model of sequence evolution inspired by the aforementioned recent work in language modeling. We trained EvoLSTM from entire whole-genome primate alignments and show that it is able to capture context dependencies that are longer in range than what had been previous reported, for both substitutions and short indels. EvoLSTM’s RNN evolutionary model paves the way for a variety of applications that rely on realistic modeling of sequence evolution.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>EvoLSTM is a machine-learning based probabilistic model of context-dependent sequence evolution. In its simplest form, it takes as input a sequence <italic>S</italic> of length <italic>K</italic> and outputs a randomly generated descendant sequence <italic>T</italic> that may either be identical to <italic>S</italic> or may differ from it through one or more substitutions or indels. In this section, we explain EvoLSTM’s architecture, its training and evaluation.</p>
    <sec>
      <title>2.1 Training data</title>
      <p>EvoLSTM is trained from a set of pairs of aligned ancestral/descendant sequences. We used a 100-way alignment of whole vertebrate genomes (<xref rid="btaa447-B12" ref-type="bibr">Blanchette <italic>et al.</italic>, 2004a</xref>; <xref rid="btaa447-B45" ref-type="bibr">Miller <italic>et al.</italic>, 2007</xref>) and applied the Ancestors1.0 program (<xref rid="btaa447-B13" ref-type="bibr">Blanchette <italic>et al.</italic>, 2004b</xref>; <xref rid="btaa447-B20" ref-type="bibr">Diallo <italic>et al.</italic>, 2010</xref>) to infer maximum likelihood ancestral sequences genome-wide based on a simple context-independent substitution model. The approach has previously been shown to be highly accurate for most ancestors and, in particular, for primates (<xref rid="btaa447-B13" ref-type="bibr">Blanchette <italic>et al.</italic>, 2004b</xref>). We then extracted induced pairwise alignments between the human genome and various primate ancestors: the old-world monkey ancestor (catarrhini; 0.03 expected substitution per site), and the simian ancestor (simiiformes; 0.05 exp. subst./site). Since our analyses did not reveal significant differences between using one or the other as training data, which proceeded to use the old-world monkey ancestor, which has the benefit of being the close enough to human to limit the risks of double mutations at the same site, while providing us with sufficiently many mutations to learn from.</p>
      <p>Each pairwise alignment was then processed as follows (<xref ref-type="fig" rid="btaa447-F1">Fig. 1</xref>). First, gaps present in both sequences were removed. Second, each portion of 1 or 2 nucleotides in the descendant sequence that is aligned to consecutive gaps in the ancestors (hence the results of a 1 or 2 bp insertion) were combined with the previous descendant nucleotide and represented as a single character from an extended alphabet of size 86 (4 normal nucleotides + 16 dinucleotides for 1 bp insertions + 64 trinucleotides for 2 bp insertions + gap + dummy character). This allows treating insertions of size 1 or 2 as a substitution, which means that we do not need to assume we know ahead of time the position and size of an insertion. Since our focus is on short indels, we did not consider regions with larger indels, due to the exponential blow up in extended alphabet size that would be required.
</p>
      <fig id="btaa447-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Data preprocessing pipeline. An ancestor/descendant alignment is converted to a set of overlapping <italic>K</italic>-mer pairs from an extended alphabet of meta-nucleotides and gaps. Those <italic>K</italic>-mer pairs are used to train EvoLSTM</p>
        </caption>
        <graphic xlink:href="btaa447f1"/>
      </fig>
      <p>These modified ancestor-descendant alignments are sliced into <italic>K</italic>-mer pairs (for <italic>K</italic> ranging from 1 to 39). Those aligned <italic>K</italic>-mer pairs constitute the data from which EvoLSTM is trained. We selected the first 10 000 000 <italic>K</italic>-mer pairs from human chromosome 2 as the training set and the next 2 000 000 as validation set. Our test set consists of 149 860 432 <italic>K</italic>-mer pairs selected from all chromosomes except human chromosome 2, hence ensuring that the test set is entirely disjoint from the training and validation sets. This very large test set enables us to accurately estimate the accuracy of the trained models.</p>
    </sec>
    <sec>
      <title>2.2 EvoLSTM’s LSTM architecture</title>
      <p>EvoLSTM is an RNN that takes as input a <italic>K</italic>-mer and outputs the probability of each of the nucleotides (and meta-nucleotides) in a hypothetical descendant sequence (<xref ref-type="fig" rid="btaa447-F2">Fig. 2</xref>). It is based on the LSTM architecture for RNNs, which was introduced to address the vanishing gradient problem of classical RNNs (<xref rid="btaa447-B60" ref-type="bibr">Sundermeyer <italic>et al.</italic>, 2012</xref>). The LSTM cell corresponding to position <italic>t</italic> in the <italic>K</italic>-mer takes in an input value <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (the one-hot encoded version of meta-nucleotide at position <italic>t</italic>), as well as two types of recurrent states: the hidden state <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and the cell state <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which are vectors of predetermined dimensions. Following <xref rid="btaa447-B27" ref-type="bibr">Gers <italic>et al.</italic> (2000)</xref>, these states are combined with the input and are regulated by trainable input (<italic>W<sub>Inuc</sub></italic> and <italic>W<sub>Ih</sub></italic>), output (<italic>W<sub>Onuc</sub></italic> and <italic>W<sub>Oh</sub></italic>) and forget gates (<italic>W<sub>Fnuc</sub></italic> and <italic>W<sub>Fh</sub></italic>) weight vectors. Each LSTM cell remembers values of the hidden state and cell state over time intervals and the three gates modify the information received from the previous time step (<xref rid="btaa447-B60" ref-type="bibr">Sundermeyer <italic>et al.</italic>, 2012</xref>).
</p>
      <fig id="btaa447-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>EvoLSTM is a sequence-to-sequence bidirectional LSTM model made of an encoder (left portion, shown in red) and a decoder (right portion, shown in blue box). An ancestral sequences (here, ACT) are given as input to the encoder. Each cell recurrently receives information from the previously cell, in the form of a hidden state vector (blue arrows) and cell state vector (red arrows), and combines it with the one-hot encoded ancestral nucleotide to update those two vectors. The output of the encoder is the concatenation of the hidden and cell state vectors produced by the forward and reverse directions. Those vectors are an encoding of the sequence context, optimized so as to be maximally informative for the decoder. In the decoder, each cell receives as input (i) the one-hot encoded ancestral nucleotide and the previous descendant nucleotide generated by the model, as well as the state and cell vectors from the previous cell. It updates those two vectors and passes them to the next cell, but also feeds the hidden state vector to an MLP, which output a probability distribution over descendant characters (nucleotides or gap) at that position. A character is randomly drawn from that distribution, emitted and passed onto the next LSTM decoder cell</p>
        </caption>
        <graphic xlink:href="btaa447f2"/>
      </fig>
      <p>Specifically, we have
<disp-formula id="E1"><mml:math id="M1"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Fnuc</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Inuc</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>I</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Onuc</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>O</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>Finally, the outputs of each gate are combined to update the hidden state and the cell state of the current cell:
<disp-formula id="E2"><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:mi>tanh</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Cnuc</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:mi>tanh</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula id="IE4"><mml:math id="IM4"><mml:mo>⊙</mml:mo></mml:math></inline-formula> denotes the element-wise product.</p>
    </sec>
    <sec>
      <title>2.3 Sequence-to-sequence model</title>
      <p>Borrowing the idea from sequence-to-sequence learning (Sutskever <italic>et al.</italic>, 2014), EvoLSTM is composed of connected LSTM-based encoder and decoder networks (<xref ref-type="fig" rid="btaa447-F2">Fig. 2</xref>). The encoder is made of two LSTM looking at the same input <italic>K</italic>-mer but in opposite directions. Their last output hidden states <italic>h<sub>K</sub></italic> and cell states <italic>c<sub>K</sub></italic> are concatenated and passed to the decoder network, which uses it, along with the ancestral <italic>K</italic>-mer itself, to generate a descendant sequence. <italic>h<sub>K</sub></italic> and <italic>c<sub>K</sub></italic> capture the context information that will be used to inform the decoder.</p>
      <p>The decoder consists of an LSTM similar to the encoder, coupled with a fully connected neural network. Each cell receives the cell and hidden states from the previous cell, except for the first cell, which obtains those from the encoder (<italic>h<sub>K</sub></italic> and <italic>c<sub>K</sub></italic>). Cell <italic>t</italic> from the decoder is used to predict a probability distribution over meta-nucleotides at position <italic>t</italic> of the descendant sequence. The hidden state is fed to a fully connected multi-layer perceptron (MLP) with 86 outputs, to which a softmax function is applied to obtain a normalized probability distribution. Also, in addition to receiving meta-nucleotide <italic>x<sub>t</sub></italic> as input, cell <italic>t</italic> (for <italic>t</italic> &gt; 1) receives the observed (during training) or sampled (when using the network as a generative model) descendant nucleotide from position <italic>t</italic> − 1, providing it with information about the evolutionary event that took place at the previous position. This is particularly critical to enable indels spanning more than one nucleotide.</p>
    </sec>
    <sec>
      <title>2.4 Training EvoLSTM</title>
      <p>We trained our model using the cross-entropy (CE) (negative log-likelihood) as the loss function to minimize. In short, we aim to minimize
<disp-formula id="E3"><mml:math id="M3"><mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mtext>Training</mml:mtext><mml:mo> </mml:mo><mml:mtext>set</mml:mtext></mml:mrow></mml:munder><mml:mrow><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>A</italic> is an input ancestral <italic>K</italic>-mer and <italic>D</italic> is its descendant <italic>K</italic>-mer. Trainable weights include the input, output, forget, cell state and hidden state weight matrices and bias terms for both the encoder and decoder, as well as the weights of the MLP in the decoder. Training is carried out using the Adam optimizer (<xref rid="btaa447-B39" ref-type="bibr">Kingma and Ba, 2014</xref>) with a learning rate of 0.0001. We used batch learning with batch size 1024. To reduce overfitting, we used early stopping, ending training when the validation loss did not decrease for five consecutive epochs. To investigate the effect of context size, models were trained with six different values of <italic>K</italic>: 1, 5, 11, 15, 21 and 39.</p>
      <p>Hyper-parameters of the model were set based on a compromise between training time and accuracy on the validation set. The size of the hidden and cell state vectors was set to 512. The MLP consists of 1 hidden layer of 86 neurons with ReLU (rectified linear activation unit) (<xref rid="btaa447-B48" ref-type="bibr">Nair and Hinton, 2010</xref>) activation function and the output layer of 86 neurons.</p>
    </sec>
    <sec>
      <title>2.5 Using EvoLSTM as an evolution simulator</title>
      <p>To use a trained EvoLSTM model to simulate the evolution of a given ancestral <italic>K</italic>-mer sequence <italic>A</italic>, the model is used as described previously, with a few small modifications. At each position <italic>t</italic>, a meta-nucleotide is sampled from the distribution generated by the model at that position. It is that nucleotide (rather than the true descendant nucleotide, as was done during training phase) that is passed as input to the next cell. In contrast, in the context machine translation (Sutskever <italic>et al.</italic>, 2014), the goal is generally not to sample from a distribution over translations, but instead to identify the maximum-likelihood translation, which is achieved via a greedy or beam search algorithm (<xref rid="btaa447-B50" ref-type="bibr">Neubig, 2017</xref>).</p>
      <p>In order to use EvoLSTM to simulate the evolution of ancestral sequences longer than <italic>K</italic>, we proceed as follows. EvoLSTM breaks down the ancestral genome sequence of interest into <italic>K</italic>-mers similarly to the data preprocessing step described in <xref ref-type="fig" rid="btaa447-F1">Figure 1</xref> but without overlap between each <italic>K</italic>-mer. Denote those ancestral <italic>K</italic>-mers as <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. Each <italic>K</italic>-mer is given as input to EvoLSTM, in the order in which they appear in the sequence. To sample descendant <italic>K</italic>-mer <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, EvoLSTM uses the cell and hidden state vectors obtained from passing <italic>K</italic>-mer <italic>k<sub>i</sub></italic> to the encoder network together with the last simulated nucleotide obtained from <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to be passed down to the decoder network. Once all descendant <italic>K</italic>-mers are obtained, they are concatenated to yield the complete descendant sequence.</p>
      <p>The simulation processed described until now only allows mimicking sequence evolution over a branch of the same length as that corresponding to the pair of ancestor/descendant genomes used for training. Let us call that branch length the <italic>unit</italic> branch length. To simulate the evolution of branches of non-unit length, we proceed as follows. Suppose the target branch length is <italic>λ</italic> units long. Decompose <italic>λ</italic> into its integer and factional portions: <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:mo>λ</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="italic">Int</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>λ</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="italic">Frac</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>λ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We apply EvoLSTM <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:mi mathvariant="italic">Int</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>λ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> times, each time using it to re-evolve the sequence produced from the previous iteration. The resulting <italic>K</italic>-mer (which would be the ancestral <italic>K</italic>-mer if <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:mo>λ</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) is then fed one last time through EvoLSTM, but this time rejecting a proposed mutation with probability <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:mi mathvariant="italic">Frac</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>λ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S1</xref> shows that this iterative process captures well context dependencies of evolutionary events over longer branches.</p>
    </sec>
    <sec>
      <title>2.6 Evaluation</title>
      <sec>
        <title>2.6.1 Baseline approaches</title>
        <p>Past studies on evolution models have mainly focused on immediate neighbor context-dependent substitutions and are thus not directly comparable to the EvoLSTM. Instead, we implemented two baseline models. Our <italic>table-based</italic> approach is perhaps the most natural context-dependent evolutionary model: It simply approximates and saves <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:mi>Pr</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> as <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic>N</italic>(<italic>A</italic>, <italic>D</italic>) and <italic>N</italic>(<italic>A</italic>) are the observed frequencies of (<italic>D</italic>, <italic>A</italic>) and <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mo>*</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> alignments in the training set. As <italic>K</italic> increases, <italic>N</italic>(<italic>A</italic>) can become too small to provide a meaningful probability estimate. If <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, we symmetrically trim the context sequences (by one nucleotide at each end), until we get <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This approach enables this algorithm to use large context sizes when sufficient data exist, but to returns to smaller context sizes when it does not.</p>
        <p>We also implemented a second machine-learning approach using a standard bidirectional LSTM network (<xref ref-type="fig" rid="btaa447-F3">Fig. 3</xref>) coupled to a 1-hidden layer MLP (ReLU activation), with an output layer of 86 neurons. Unlike our EvoLSTM model, this model does not consider the prediction made in the previous time step and can make predictions based only on the bidirectional input context. The learning rate, hidden and cell state weight size, optimizer, initial learning rate, batch size and all other training details are identical to the sequence-to-sequence EvoLSTM.
</p>
        <fig id="btaa447-F3" orientation="portrait" position="float">
          <label>Fig. 3.</label>
          <caption>
            <p>Baseline bidirectional LSTM model structure. The two hidden states emitted from both directions are concatenated and passed down to an MLP</p>
          </caption>
          <graphic xlink:href="btaa447f3"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>2.7 Implementation</title>
      <p>EvoLSTM was implemented using tf.keras (<xref rid="btaa447-B16" ref-type="bibr">Chollet <italic>et al.</italic>, 2015</xref>) LSTM layers in Tensorflow 2.0 (<xref rid="btaa447-B1" ref-type="bibr">Abadi <italic>et al.</italic>, 2015</xref>). Biopython (<xref rid="btaa447-B17" ref-type="bibr">Cock <italic>et al.</italic>, 2009</xref>) was used for reading the MAF file and preprocessing genome sequences. All relevant code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/DongjoonLim/EvoLSTM">https://github.com/DongjoonLim/EvoLSTM</ext-link>.</p>
      <p>EvoLSTM is easy to train from whole-genome alignments and inferred ancestral sequences. It comes with code for interpretation and visualization of the models learned. It is also able to use a trained model to randomly evolve a given input sequence using substitutions and short indels. As such, it will easily integrate into more general genome evolution simulators such as Evolver (<xref rid="btaa447-B23" ref-type="bibr">Edgar <italic>et al.</italic>, 2019</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>This section begins with the assessment of the accuracy of EvoLSTM and baseline models, followed by an empirical analysis of context-dependent mutation probabilities learned by EvoLSTM.</p>
    <sec>
      <title>3.1 Model performance</title>
      <p>We first evaluated the ability of different approaches to properly estimate mutation probability in a context-dependent manner (<xref ref-type="fig" rid="btaa447-F4">Fig. 4</xref>). The models investigated (see Section 2) included our biLSTM and EvoLSTM seq2seq models, as well as a simpler adaptive frequency-based approach, each with context sizes <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>11</mml:mn><mml:mo>,</mml:mo><mml:mn>15</mml:mn><mml:mo>,</mml:mo><mml:mn>21</mml:mn><mml:mo>,</mml:mo><mml:mn>39</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Each model was trained on 10 000 000 aligned <italic>K</italic>-mer pairs extracted from the whole-genome alignment of the computationally reconstructed old-world monkey genome to the human genome (from human chromosomes 2), and evaluated on a similar but much larger test set obtained from chromosomes 1 and 3–22, containing &gt;149 million <italic>K</italic>-mer pairs. This atypical imbalance between the size of the training and test sets is intentional; having a very large test set allows us to accurately estimate context-dependent mutation probabilities using the simple frequency-based approach, to then be able to assess how the different approaches proposed can learn context dependencies from a relatively smaller training set.
</p>
      <fig id="btaa447-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>CE loss (lower is better) of the test set (&gt;149 million <italic>K</italic>-mers, corresponding to alignments of portions of the old-world monkeys’ ancestral genome against the human genome), with different context sizes <italic>K</italic>. The models compared are two baseline models (adaptive frequency table and biLSTM) as well as two versions of EvoLSTM, with one or two biLSTM layers</p>
        </caption>
        <graphic xlink:href="btaa447f4"/>
      </fig>
      <p>We assessed the ability of a model to accurately capture context-dependent mutation probabilities using the CE of the test data, which are equivalent to the negative log-likelihood of the data given the model. CE values that are reached using no context at all (<italic>K</italic> = 1) are much worse than those obtained with larger values of <italic>K</italic>, confirming that context dependencies are strong. The adaptive frequency table-based approach is limited in capturing long-range dependencies because of the exponential amount of data it would require in order to do so. In contrast, EvoLSTM (1 layer) is able to fully take advantage of large context sizes, reaching a minimal CE at <italic>K</italic> = 15. Larger values of <italic>K</italic> result in worse CE values, possibly because as the LSTM network becomes larger, gradients become unstable (<xref rid="btaa447-B29" ref-type="bibr">Greff <italic>et al.</italic>, 2017</xref>). However, this does not mean that context sizes larger than <italic>K</italic> = 15 do not have an incidence on mutation probabilities. Overall, the difference in CE values obtained [0.18 for EvoLSTM (<italic>K</italic> = 15) versus 0.195 for table-based (<italic>K</italic> = 21)] is notable and reliably reproduced over different restarts. Note that the reason the performance of the adaptive table-based approach remains stable for large values of <italic>K</italic> is that this approach adaptively trims each <italic>K</italic>-mer until its count in the training set is sufficiently large to make accurate probability estimations; in practice, for <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mi>K</mml:mi><mml:mo>≥</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula>, most <italic>K</italic>-mers get trimmed to 15-mers or shorter.</p>
      <p>We also tested whether it may be beneficial to add a second LSTM layer to EvoLSTM, which is an approach that has been shown to be beneficial in language modeling (Sutskever <italic>et al.</italic>, 2014). However, this did not improve the performance, and was much longer to train. We also observe that the effect of capturing contexts by separating the encoder from the decoder in the sequence-to-sequence model used in EvoLSTM is important since the CE of EvoLSTM is much lower than that of the baseline biLSTM, across all context sizes. This suggests that relatively long-range context dependencies exist, and that EvoLSTM is able to capture many.</p>
    </sec>
    <sec>
      <title>3.2 Flanking context strongly impacts mutation probability</title>
      <p>We next aimed to characterize the impact of long-range context on mutation probability, and better understand the ability of EvoLSTM to take this context into consideration. We used a trained EvoLSTM (<italic>K</italic> = 15) to simulate the evolution of a set of 149 860 432 <italic>K</italic>-mers from an ancestral old-world monkey sequence. We then tabulated the frequency of simulated mutations in each of the 256 different contexts of the form wxNyz, i.e. including two flanking bases on each side of the mutating base, and contrasted those frequencies to those observed in actual alignments of the same regions.</p>
      <p><xref ref-type="fig" rid="btaa447-F5">Figure 5</xref> shows the results for a subset of the 16 possible substitutions, 4 possible deletions and 4 possible insertions. See also <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S1–S4</xref> for full results. Several observations emerge. First, EvoLSTM efficiently captures and simulates context dependencies of that size, with correlation coefficients ranging from 0.83 to 0.99 for substitutions. In particular, it clearly and accurately captures the well-known CpG to TpG mutation of methylated C’s (<xref rid="btaa447-B34" ref-type="bibr">Jabbari and Bernardi, 2004</xref>), or the equivalent CpG to CpA from the reverse strand, assigning significantly higher mutation probability (0.1–0.25) to these mutations when in the right dinucleotide context versus in other contexts (&lt;0.05). Notably, even within the CpG dinucleotide context, the probability of C-to-T mutation is strongly dependent on the broader context. For example, CGCGz contexts are two times less mutagenic than AT-rich contexts. This may be explained by the presence of CpG islands in the genome, which is generally unmethylated and hence both CpG rich and substitution poor. Non-CpG contexts also exhibit strong context dependencies. For example, A-to-G transitions show a greater than 10-fold increase in the probability in the contexts of CAATw versus xAAAw.
</p>
      <fig id="btaa447-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Comparison of the observed and EvoLSTM-predicted mutation probabilities for context size <italic>K</italic> = 5. Each graph shows the results for a given mutation occurring at the center of the <italic>K</italic>-mer. Each plot has 256 points, corresponding to the 256 possible contexts for that mutation. Some of the contexts are labeled. The Pearson correlation coefficient <italic>r</italic> is given for each case</p>
        </caption>
        <graphic xlink:href="btaa447f5"/>
      </fig>
      <p><xref ref-type="fig" rid="btaa447-F6">Figure 6</xref> illustrates this phenomenon in more details in the case of CpG dinucleotide (left) and nucleotide deletion (right). The massive difference in CpG versus non-CpG C-to-T substitution probabilities is only the beginning of a dive into further and further refinements of context dependencies. The ACG context is 70% more mutagenic than the TCG context. There is then a 35% difference in C-to-T mutagenicity between different xACGy contexts, and a 2-fold difference between high and low mutagenic xGACGGy contexts. Throughout, the correspondence between the predicted and observed mutation probabilities remains quite high, until the context size considered becomes less relevant to mutation probability (e.g. for xACCTTy). Deletions (right panel) exhibit these long-range dependencies even more strikingly, with a 20-fold difference in A-deletion probabilities between highly mutagenic AAAAAAA context and conservative context TCCAGCG.
</p>
      <fig id="btaa447-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>EvoLSTM-predicted mutation probability and observed mutation probability in increasingly large contexts. Each dot represents one of the 16 possible context extensions. Out of those flanking base configurations, the top row shows the effect of adding the most mutagenic flanking bases, the second row shows the effect of adding the median mutagenic flanking bases and the bottom row shows the effect of the least mutagenic flanking bases</p>
        </caption>
        <graphic xlink:href="btaa447f6"/>
      </fig>
      <p>Transversions generally show a slightly weaker context-dependency (5-fold variation between most and least mutagenic contexts). Because they are also rarer in general, prediction accuracy is slightly worse due to the relatively small number of training examples.</p>
      <p><xref ref-type="fig" rid="btaa447-F5">Figure 5</xref> (bottom row) also shows the context-dependency of 1-nucleotide insertions and deletions. Those also display a very strong context-dependency. For example deletions of a T are roughly 8–12 times more likely in T-rich contexts than in GC-rich contexts such as zCTGz or zGTCz contexts. Insertions show a similar pattern of elevated probabilities for insertions of nucleotides in a context that resembles them, which is consistent with the well-known DNA polymerase slippage model (<xref rid="btaa447-B43" ref-type="bibr">Messer and Arndt, 2007</xref>).</p>
      <p>To study the impact of the broader context, we investigated how the probabilities of specific substitutions and indels vary as we look at increasingly large context sizes (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S7</xref>). Consider mutation <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mi>M</mml:mi><mml:mo>→</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, where <italic>M</italic> and <italic>N</italic> are nucleotides or gaps, which is taking place in the context <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:mi mathvariant="italic">xMy</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="italic">xNy</mml:mi></mml:mrow></mml:math></inline-formula>, where <italic>x</italic> and <italic>y</italic> are context nucleotides sequences of length greater or equal to zero (hence context size <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). A meaningful assessment of the degree to which considering an extra context nucleotide at each end (i.e. <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:mi mathvariant="italic">axMyb</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="italic">axNyb</mml:mi></mml:mrow></mml:math></inline-formula>) affects the predicted mutation probability is the log-odds ratio of the long context model to the short context model:
<disp-formula id="E4"><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>→</mml:mo><mml:mi>N</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">axMyb</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">xMy</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>Pr</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">axNyb</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="italic">axMyb</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>/</mml:mo><mml:mi>Pr</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="italic">xNy</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="italic">xMy</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <fig id="btaa447-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Increasing context size allows capturing strong dependencies not captured at lower context sizes. For each type of mutations (substitutions, deletions, insertions) and each context size <italic>K</italic> = 3, 5, 7, we show the log-odds ratio of a mutation/context pair in a model with context <italic>K</italic> versus one with context size <italic>K</italic> − 2. Each dot corresponds to a mutation/context pair, with <italic>x</italic>-coordinate being the log-odds ratio of the mutation in those two context sizes (<italic>K</italic> versus <italic>K</italic> − 2) and the <italic>y</italic>-axis being the same measure, but for the reverse complement of that mutation/context pair. Since most context-dependencies would be expected to be strand-independent, one would expect a strong correlation between those two values</p>
        </caption>
        <graphic xlink:href="btaa447f7"/>
      </fig>
      <p>If the mutation <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:mi>M</mml:mi><mml:mo>→</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> does not depend on distant context nucleotides <italic>a</italic> and <italic>b</italic>, we get <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:mi mathvariant="italic">LOR</mml:mi><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. However, if the presence of <italic>a</italic> and <italic>b</italic> significantly increases (resp. decreases) the odds of mutation, <italic>LOR</italic> takes on a positive (resp. negative) values.</p>
      <p>When <italic>K</italic> is relatively large (<italic>K</italic> &gt; 5), verifying EvoLSTM’s predictions about the frequencies of mutations in specific contexts become difficult, because our test data does not have sufficiently many examples of each mutation/context pairs for accurate estimation. Here, we take advantage of the fact that most mutational processes are agnostic of strandedness, which should result in context-dependencies to be invariant to reverse complementation:
<disp-formula id="E5"><mml:math id="M5"><mml:mrow><mml:mi mathvariant="italic">LOR</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>→</mml:mo><mml:mi>N</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">axMyb</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">xMy</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mi mathvariant="italic">LOR</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>′</mml:mo><mml:mo>→</mml:mo><mml:mi>N</mml:mi><mml:mo>′</mml:mo><mml:mo>;</mml:mo><mml:mi>b</mml:mi><mml:mo>′</mml:mo><mml:mi>y</mml:mi><mml:mo>′</mml:mo><mml:mi>M</mml:mi><mml:mi>x</mml:mi><mml:mo>′</mml:mo><mml:mi>a</mml:mi><mml:mo>′</mml:mo><mml:mo>;</mml:mo><mml:mi>y</mml:mi><mml:mo>′</mml:mo><mml:mi>M</mml:mi><mml:mo>′</mml:mo><mml:mi>x</mml:mi><mml:mo>′</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where prime indicates reverse complement. This provides us with a way to verify the internal consistency of the model, without the need for a test set. This serves as a proxy for evaluating the tool’s accuracy, because high correlations would be unlikely to arise by chance.</p>
      <p><xref ref-type="fig" rid="btaa447-F7">Figure 7</xref> shows how LOR values for mutation/context pairs relate to the LOR values for their reverse complement. For <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:mi>K</mml:mi><mml:mo>≤</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, LOR values are highly consistent between a mutation/context pair and its reverse complement. For example, <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:mi mathvariant="italic">LOR</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">TTTAA</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">TTA</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:math></inline-formula>, suggesting that a T-to-A substitution is approximately <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mn>0.55</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:mrow></mml:math></inline-formula> times more likely in the context TTTAA than in the shorter context TTA. The reverse-complement mutation/context pair displays a similarly strong bias, with <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:mi mathvariant="italic">LOR</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>T</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">TTAAA</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="italic">TAA</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.44</mml:mn></mml:mrow></mml:math></inline-formula>. With context size <italic>K</italic> = 7, the correspondence between reverse complements becomes less strong, suggesting that EvoLSTM’s estimations may be less accurate. Nonetheless, several results are striking and reproducible across reverse complements. Surprisingly, a C-to-A substitution in the context CCCCCCC is 3 times more likely than in the shorter CCCCC context. A-to-T substitutions are 5 times less likely in the context of ATTAAAG than in the context of TTAAA. These results show that long-range context dependencies are strong for certain mutations, and that EvoLSTM is able to capture many of them, although the task becomes increasingly difficult as <italic>K</italic> increases. Similar results are observed for deletions, but long-range context-dependencies for insertions appear to be less reliably captured, probably because of their rarity in our training set.</p>
    </sec>
    <sec>
      <title>3.3 Context-dependencies in other mammals and in plants</title>
      <p>To demonstrate the applicability of EvoLSTM outside of primates, we used it to learn mutation context-dependencies in other species. First, we trained a model on bats sequences (training set: 10 million <italic>K</italic>-mers; test set: 158 million <italic>K</italic>-mers), using the branch from the most recent common ancestor David’s Myotis bat (<italic>Myotis davidii</italic>) and Microbat (<italic>Myotis lucifugus</italic>) to descendant Microbat. <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S9</xref> shows that EvoLSTM is able to capture the same type of dependencies as in primates, although the correlations observed are weaker. We attribute those differences to the fact that the number of mutated sites available for training is substantially lower in bats, despite the branch lengths being similar to those used primates. This is likely an artifact of the way the multiple genome alignment used for ancestral genome reconstruction was built, using human as a reference, which results in highly diverged bat sequences to sometimes be missing from the alignment. Nevertheless, the predicted context dependencies learned in primates and bats are quite similar (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S3</xref>).</p>
      <p>We then repeated the analysis on plants (<italic>Brassicaceae</italic>), using a whole-genome alignment produced by <xref rid="btaa447-B30" ref-type="bibr">Haudry <italic>et al.</italic> (2013)</xref>. Here, we used as ancestral sequence the most recent ancestor of <italic>Arabidopsis thaliana</italic> and <italic>Arabidopsis lyrata</italic>, reconstructed using <italic>Capsella rubella</italic> as an outgroup, and studied its evolution toward the <italic>A.lyrata</italic> genome. We excluded coding regions, resulting in 10 million examples being used for training, but only 6 million for testing. Again, EvoLSTM is able to detect strong context dependencies, especially for insertions and deletions. The correlation coefficients of predicted and observed (in the test set) mutation frequencies are lower than in human, which we attribute in part to the fact that the test set used to estimate observed mutation frequencies is &gt;20 times smaller than in mammals. Notably, we observe an absence of CpG to TpG elevated substitution rate, due to the fact that DNA methylation is rare in plants, outside of transposable elements (<xref rid="btaa447-B65" ref-type="bibr">Zhang <italic>et al.</italic>, 2018</xref>).</p>
    </sec>
    <sec>
      <title>3.4 Running time</title>
      <p>EvoLSTM was trained on an Intel(R) Xeon(R) Silver 4210 CPU @ 2.20 GHz CPU and NVIDIA GeForce RTX 2080Ti GPU. Training on a set of 10 000 000 15-mer examples took on average 1374 s per epoch with the batch size of 1024 and the hidden state size of 512. The training was stopped after 132 epochs.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion and conclusion</title>
    <p>Context-dependent mutation rates have been known and documented for a long time, starting with the elevated CpG to TpG substitution rate (<xref rid="btaa447-B11" ref-type="bibr">Bird, 1980</xref>; <xref rid="btaa447-B24" ref-type="bibr">Ehrlich and Wang, 1981</xref>), and more recently in many other cases (<xref rid="btaa447-B6" ref-type="bibr">Arndt and Hwa, 2005</xref>; <xref rid="btaa447-B8" ref-type="bibr">Averof <italic>et al.</italic>, 2000</xref>; <xref rid="btaa447-B43" ref-type="bibr">Messer and Arndt, 2007</xref>; <xref rid="btaa447-B47" ref-type="bibr">Morton, 2003</xref>; <xref rid="btaa447-B57" ref-type="bibr">Siepel and Haussler, 2003</xref>). While several computational models have been proposed to characterize these dependencies [e.g. hidden Markov models (<xref rid="btaa447-B57" ref-type="bibr">Siepel and Haussler, 2003</xref>) or Bayesian networks (<xref rid="btaa447-B14" ref-type="bibr">Chachick and Tanay, 2012</xref>; <xref rid="btaa447-B18" ref-type="bibr">Cohn <italic>et al.</italic>, 2010</xref>)], those are generally unable to capture complex long-range dependencies. The EvoLSTM model introduced here builds on prior work in deep learning and natural language processing to learn and reveal such dependencies.</p>
    <p>The ability to efficiently learn and model context-dependent mutation rates is of high importance for several tasks. First, substitution models are at the core of sequence alignment tasks. Most commonly used alignment algorithms use context-independent models [e.g. Needleman-Wunsch algorithm (<xref rid="btaa447-B49" ref-type="bibr">Needleman and Wunsch, 1970</xref>), Blast (<xref rid="btaa447-B4" ref-type="bibr">Altschul <italic>et al.</italic>, 1990</xref>) and their variations (<xref rid="btaa447-B56" ref-type="bibr">Schwartz <italic>et al.</italic>, 2000</xref>; <xref rid="btaa447-B58" ref-type="bibr">Smith and Waterman, 1981</xref>)] or consider limited context for codon-based alignment (<xref rid="btaa447-B54" ref-type="bibr">Ranwez <italic>et al.</italic>, 2011</xref>). This is partly due to the algorithmic challenge linked to computing maximum likelihood alignments under context-dependent substitution or indel models (<xref rid="btaa447-B32" ref-type="bibr">Hickey and Blanchette, 2011</xref>). Yet many scoring-scheme agnostic pairwise and multiple alignment heuristics have been proposed recently, e.g. using reinforcement learning (<xref rid="btaa447-B35" ref-type="bibr">Jafari <italic>et al.</italic>, 2019</xref>; <xref rid="btaa447-B46" ref-type="bibr">Mircea <italic>et al.</italic>, 2018</xref>; <xref rid="btaa447-B53" ref-type="bibr">Ramakrishnan <italic>et al.</italic>, 2018</xref>). This paves the way for the possible adoption of complex mutation models such as EvoLSTM. Using accurate substitution and indel models is particularly important when aligning highly diverged sequences, where using the right model enables both more accurate alignment computation and higher remote homology detection, both of which are of high importance for whole-genome alignment (<xref rid="btaa447-B12" ref-type="bibr">Blanchette <italic>et al.</italic>, 2004a</xref>) and ancient transposable element detection (RepeatMasker; Smit <italic>et al.</italic><ext-link ext-link-type="uri" xlink:href="http://www.repeatmasker.org">http://www.repeatmasker.org</ext-link>). Accurate modeling of context dependencies is also important to obtain improved sequence evolution simulators [such as Evolver (<xref rid="btaa447-B23" ref-type="bibr">Edgar <italic>et al.</italic>, 2019</xref>)], which are instrumental in benchmarking a variety of bioinformatics tools such as whole-genome aligners (<xref rid="btaa447-B21" ref-type="bibr">Earl <italic>et al.</italic>, 2014</xref>). These models are also relevant to phylogenetic inference, where the choice of mutation models has been shown to have a high impact on the accuracy of the trees inferred, especially for highly divergent species (<xref rid="btaa447-B19" ref-type="bibr">Delsuc <italic>et al.</italic>, 2005</xref>). Finally, a more detailed study of the models learned by EvoLSTM is likely to reveal valuable information about mutagenesis and DNA repair. In particular, different types of cancer have been shown to be associated with different mutational signatures (<xref rid="btaa447-B31" ref-type="bibr">Helleday <italic>et al.</italic>, 2014</xref>); a detailed analysis of EvoLSTM models trained on such cancer mutations may help reveal the mechanisms at play.</p>
    <p>Many potentially fruitful directions may be explored to improve EvoLSTM’s accuracy and scalability. Attention mechanisms have shown promising results in neural machine translation (<xref rid="btaa447-B9" ref-type="bibr">Bahdanau <italic>et al.</italic>, 2014</xref>) for capturing larger sentence contexts and could be beneficial in our context. Other directions may include using transformers (<xref rid="btaa447-B63" ref-type="bibr">Vaswani <italic>et al.</italic>, 2017</xref>), which have recently revolutionized the field of natural language processing, as well as word embedding (<xref rid="btaa447-B44" ref-type="bibr">Mikolov <italic>et al.</italic>, 2013</xref>). Code optimization should also enable EvoLSTM to be trained on larger datasets; memory requirements currently limit us to using at most 10 million training examples.</p>
    <p>Several new biological applications would also be of interest. First, one may consider training an ensemble of models, to capture different types of genomic contexts (methylated versus non-methylated, or transcribed versus non-transcribed, protein-coding versus non-coding regions, etc.), which are believed to have different mutational signatures either due to different mutational or DNA repair processes, or to natural selection. Extending EvoLSTM to other types of mutational events such as transposable element insertions [which have been shown to be highly context-dependent (<xref rid="btaa447-B10" ref-type="bibr">Beggs <italic>et al.</italic>, 2000</xref>; <xref rid="btaa447-B64" ref-type="bibr">Wall <italic>et al.</italic>, 1999</xref>)] and tandem or segmental duplication would also be worthwhile.</p>
    <p>Applying EvoLSTM to the study of the mutational processes at play outside of primates would also be valuable. One challenge in that direction is data availability. To train EvoLSTM, one needs the possibility of accurately reconstructing an ancestral sequence, which is only feasible if at least two relatively closely related species and a close outgroup are available. These genomes need to be sufficiently closely related that they can be accurately aligned to each other, but diverged enough that the number of mutational events available for training is sufficient. As such, it works best for large genomes with a densely populated phylogenetic tree.</p>
    <p>In conclusion, machine-learning advances have only begun to impact evolutionary biology and genomics, but this represents an application area of potentially high impact, due to the complexity of the mechanisms at play and a large amount of genomic data available to train sophisticated models. EvoLSTM represents the first step in that direction, enabling a detailed study of context-dependent mutational mechanisms and their integration in sequence evolution simulations, with applications in genomics, evolution, phylogenetics and potentially human health.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa447_Supplementary_Data</label>
      <media xlink:href="btaa447_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgement</title>
    <p>We thank Sean McRae, Zichao Yan and Elliot Layne for useful suggestions on the manuscript.</p>
    <sec>
      <title>Funding</title>
      <p>This work was funded in part by a Genome Canada Large-Scale Applied Research Project (LSARP) grant and by a Discovery grant from the National Science and Engineering Research Council of Canada. We thank Calcul Quebec and Compute Canada for computing resources.</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa447-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Abadi</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</article-title>. <ext-link ext-link-type="uri" xlink:href="http://tensorflow.org">http://tensorflow.org (21 January 2020, date last accessed).</ext-link></mixed-citation>
    </ref>
    <ref id="btaa447-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aggarwala</surname><given-names>V.</given-names></name>, <name name-style="western"><surname>Voight</surname><given-names>B.F.</given-names></name></person-group> (<year>2016</year>) 
<article-title>An expanded sequence context model broadly explains variability in polymorphism levels across the human genome</article-title>. <source>Nat. Genet</source>., <volume>48</volume>, <fpage>349</fpage>–<lpage>355</lpage>.<pub-id pub-id-type="pmid">26878723</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aikens</surname><given-names>R.C.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Signals of variation in human mutation rate at multiple levels of sequence context</article-title>. <source>Mol. Biol. Evol</source>., <volume>36</volume>, <fpage>955</fpage>–<lpage>965</lpage>.<pub-id pub-id-type="pmid">30753705</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Altschul</surname><given-names>S.F.</given-names></name></person-group><etal>et al</etal> (<year>1990</year>) 
<article-title>Basic local alignment search tool</article-title>. <source>J. Mol. Biol</source>., <volume>215</volume>, <fpage>403</fpage>–<lpage>410</lpage>.<pub-id pub-id-type="pmid">2231712</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Arenas</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Trends in substitution models of molecular evolution</article-title>. <source>Front. Genet</source>., <volume>6</volume>, <fpage>319</fpage>.<pub-id pub-id-type="pmid">26579193</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Arndt</surname><given-names>P.F.</given-names></name>, <name name-style="western"><surname>Hwa</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Identification and measurement of neighbor-dependent nucleotide substitution processes</article-title>. <source>Bioinformatics</source>, <volume>21</volume>, <fpage>2322</fpage>–<lpage>2328</lpage>.<pub-id pub-id-type="pmid">15769841</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Arndt</surname><given-names>P.F.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>DNA sequence evolution with neighbor-dependent mutation</article-title>. <source>J. Comput. Biol</source>., <volume>10</volume>, <fpage>313</fpage>–<lpage>322</lpage>.<pub-id pub-id-type="pmid">12935330</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Averof</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Evidence for a high frequency of simultaneous double-nucleotide substitutions</article-title>. <source>Science</source>, <volume>287</volume>, <fpage>1283</fpage>–<lpage>1286</lpage>.<pub-id pub-id-type="pmid">10678838</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Bahdanau</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Neural machine translation by jointly learning to align and translate</article-title>. <italic>arXiv preprint arXiv</italic>:1409.0473</mixed-citation>
    </ref>
    <ref id="btaa447-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Beggs</surname><given-names>M.L.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Mapping of IS6110 insertion sites in two epidemic strains of <italic>Mycobacterium tuberculosis</italic></article-title>. <source>J. Clin. Microbiol</source>., <volume>38</volume>, <fpage>2923</fpage>–<lpage>2928</lpage>.<pub-id pub-id-type="pmid">10921952</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bird</surname><given-names>A.P.</given-names></name></person-group> (<year>1980</year>) 
<article-title>DNA methylation and the frequency of CpG in animal DNA</article-title>. <source>Nucleic Acids Res</source>., <volume>8</volume>, <fpage>1499</fpage>–<lpage>1504</lpage>.<pub-id pub-id-type="pmid">6253938</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blanchette</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>a) 
<article-title>Aligning multiple genomic sequences with the threaded blockset aligner</article-title>. <source>Genome Res</source>., <volume>14</volume>, <fpage>708</fpage>–<lpage>715</lpage>.<pub-id pub-id-type="pmid">15060014</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blanchette</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>b) 
<article-title>Reconstructing large regions of an ancestral mammalian genome in silico</article-title>. <source>Genome Res</source>., <volume>14</volume>, <fpage>2412</fpage>–<lpage>2423</lpage>.<pub-id pub-id-type="pmid">15574820</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chachick</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Tanay</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Inferring divergence of context-dependent substitution rates in drosophila genomes with applications to comparative genomics</article-title>. <source>Mol. Biol. Evol</source>., <volume>29</volume>, <fpage>1769</fpage>–<lpage>1780</lpage>.<pub-id pub-id-type="pmid">22319143</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Cho</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Learning phrase representations using RNN encoder-decoder for statistical machine translation</article-title>. In: <italic>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</italic>, pp. 1724–1734. Association for Computational Linguistics, Doha, Qatar.</mixed-citation>
    </ref>
    <ref id="btaa447-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Chollet</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Keras</article-title>. <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras (21 January 2020, date last accessed).</ext-link></mixed-citation>
    </ref>
    <ref id="btaa447-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cock</surname><given-names>P.J.A.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Biopython: freely available Python tools for computational molecular biology and bioinformatics</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>1422</fpage>–<lpage>1423</lpage>.<pub-id pub-id-type="pmid">19304878</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cohn</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Mean field variational approximation for continuous-time Bayesian networks</article-title>. <source>J. Mach. Learn. Res</source>., <volume>11</volume>, <fpage>2745</fpage>–<lpage>2783</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Delsuc</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>Phylogenomics and the reconstruction of the tree of life</article-title>. <source>Nat. Rev. Genet</source>., <volume>6</volume>, <fpage>361</fpage>–<lpage>375</lpage>.<pub-id pub-id-type="pmid">15861208</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Diallo</surname><given-names>A.B.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Ancestors 1.0: a web server for ancestral sequence reconstruction</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>130</fpage>–<lpage>131</lpage>.<pub-id pub-id-type="pmid">19850756</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Earl</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Alignathon: a competitive assessment of whole-genome alignment methods</article-title>. <source>Genome Res</source>., <volume>24</volume>, <fpage>2077</fpage>–<lpage>2089</lpage>.<pub-id pub-id-type="pmid">25273068</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Edgar</surname><given-names>R.C.</given-names></name></person-group> (<year>2004</year>) 
<article-title>MUSCLE: multiple sequence alignment with high accuracy and high throughput</article-title>. <source>Nucleic Acids Res</source>., <volume>32</volume>, <fpage>1792</fpage>–<lpage>1797</lpage>.<pub-id pub-id-type="pmid">15034147</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B23">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Edgar</surname><given-names>R.C.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Evolver</article-title>. <ext-link ext-link-type="uri" xlink:href="http://www.drive5.com/evolver">http://www.drive5.com/evolver (21 January 2020, date last accessed).</ext-link></mixed-citation>
    </ref>
    <ref id="btaa447-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ehrlich</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>R.</given-names></name></person-group> (<year>1981</year>) 
<article-title>5-methylcytosine in eukaryotic DNA</article-title>. <source>Science</source>, <volume>212</volume>, <fpage>1350</fpage>–<lpage>1357</lpage>.<pub-id pub-id-type="pmid">6262918</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Feng</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Transcription-coupled DNA repair is genomic context-dependent</article-title>. <source>J. Biol. Chem</source>., <volume>277</volume>, <fpage>12777</fpage>–<lpage>12783</lpage>.<pub-id pub-id-type="pmid">11821423</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fletcher</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>Z.</given-names></name></person-group> (<year>2009</year>) 
<article-title>INDELible: a flexible simulator of biological sequence evolution</article-title>. <source>Mol. Biol. Evol</source>., <volume>26</volume>, <fpage>1879</fpage>–<lpage>1888</lpage>.<pub-id pub-id-type="pmid">19423664</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gers</surname><given-names>F.A.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Learning to forget: continual prediction with LSTM</article-title>. Continual prediction with lstm. <italic>Neural computation</italic>, <volume>12</volume>, <fpage>2451</fpage>–<lpage>2471</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goldman</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>Z.</given-names></name></person-group> (<year>1994</year>) 
<article-title>A codon-based model of nucleotide substitution for protein-coding DNA sequences</article-title>. <source>Mol. Biol. Evol</source>., <volume>11</volume>, <fpage>725</fpage>–<lpage>736</lpage>.<pub-id pub-id-type="pmid">7968486</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Greff</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>LSTM: a search space odyssey</article-title>. <source>IEEE Trans. Neural Networks Learn. Syst</source>., <volume>28</volume>, <fpage>2222</fpage>–<lpage>2232</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Haudry</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>An atlas of over 90,000 conserved noncoding sequences provides insight into crucifer regulatory regions</article-title>. <source>Nat. Genet</source>., <volume>45</volume>, <fpage>891</fpage>–<lpage>898</lpage>.<pub-id pub-id-type="pmid">23817568</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Helleday</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Mechanisms underlying mutational signatures in human cancers</article-title>. <source>Nat. Rev. Genet</source>., <volume>15</volume>, <fpage>585</fpage>–<lpage>598</lpage>.<pub-id pub-id-type="pmid">24981601</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hickey</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Blanchette</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>) 
<article-title>A probabilistic model for sequence alignment with context-sensitive indels</article-title>. <italic>J. Comput. Biol.</italic>,18 <volume>11</volume>, <fpage>1449</fpage>–<lpage>1464</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Holmes</surname><given-names>I.</given-names></name></person-group> (<year>2004</year>) 
<article-title>A probabilistic model for the evolution of RNA structure</article-title>. <source>BMC Bioinform</source>., <volume>5</volume>, <fpage>166</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jabbari</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Bernardi</surname><given-names>G.</given-names></name></person-group> (<year>2004</year>) 
<article-title>Cytosine methylation and cpg, tpg (cpa) and tpa frequencies</article-title>. <source>Gene</source>, <volume>333</volume>, <fpage>143</fpage>–<lpage>149</lpage>.<pub-id pub-id-type="pmid">15177689</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jafari</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Using deep reinforcement learning approach for solving the multiple sequence alignment problem</article-title>. <source>SN Appl. Sci</source>., <volume>1</volume>, <fpage>592</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jensen</surname><given-names>J.L.</given-names></name>, <name name-style="western"><surname>Pedersen</surname><given-names>A.-M.K.</given-names></name></person-group> (<year>2000</year>) 
<article-title>Probabilistic models of DNA sequence evolution with context dependent rates of substitution</article-title>. <source>Adv. Appl. Prob</source>., <volume>32</volume>, <fpage>499</fpage>–<lpage>517</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jukes</surname><given-names>T.H.</given-names></name></person-group><etal>et al</etal> (<year>1969</year>) 
<article-title>Evolution of protein molecules</article-title>. <source>Mammalian Protein Metab</source>., <volume>3</volume>, <fpage>132</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kimura</surname><given-names>M.</given-names></name></person-group> (<year>1980</year>) 
<article-title>A simple method for estimating evolutionary rates of base substitutions through comparative studies of nucleotide sequences</article-title>. <source>J. Mol. Evol</source>., <volume>16</volume>, <fpage>111</fpage>–<lpage>120</lpage>.<pub-id pub-id-type="pmid">7463489</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B39">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kingma</surname><given-names>D.P.</given-names></name>, <name name-style="western"><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>) 
<article-title>Adam: a method for stochastic optimization</article-title>. In: <italic>3rd International Conference on Learning Representations, ICLR 2015</italic>, San Diego, CA, USA, May 7-9, 2015, ConferenceTrack Proceedings.</mixed-citation>
    </ref>
    <ref id="btaa447-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lassmann</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Sonnhammer</surname><given-names>E.L.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Kalign—an accurate and fast multiple sequence alignment algorithm</article-title>. <source>BMC Bioinform</source>., <volume>6</volume>, <fpage>298</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ling</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>A Bayesian framework for inferring the influence of sequence context on point mutations</article-title>. <source>Mol. Biol. Evol</source>., <volume>37</volume>, <fpage>893</fpage>–<lpage>903</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Makova</surname><given-names>K.D.</given-names></name>, <name name-style="western"><surname>Hardison</surname><given-names>R.C.</given-names></name></person-group> (<year>2015</year>) 
<article-title>The effects of chromatin organization on variation in mutation rates in the genome</article-title>. <source>Nat. Rev. Genet</source>., <volume>16</volume>, <fpage>213</fpage>–<lpage>223</lpage>.<pub-id pub-id-type="pmid">25732611</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Messer</surname><given-names>P.W.</given-names></name>, <name name-style="western"><surname>Arndt</surname><given-names>P.F.</given-names></name></person-group> (<year>2007</year>) 
<article-title>The majority of recent short DNA insertions in the human genome are tandem duplications</article-title>. <source>Mol. Biol. Evol</source>., <volume>24</volume>, <fpage>1190</fpage>–<lpage>1197</lpage>.<pub-id pub-id-type="pmid">17322553</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B44">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Mikolov</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Efficient estimation of word representations in vector space</article-title>. <italic>arXiv preprint arXiv</italic>:1301.3781</mixed-citation>
    </ref>
    <ref id="btaa447-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Miller</surname><given-names>W.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>28-way vertebrate alignment and conservation track in the UCSC genome browser</article-title>. <source>Genome Res</source>., <volume>17</volume>, <fpage>1797</fpage>–<lpage>1808</lpage>.<pub-id pub-id-type="pmid">17984227</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B46">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Mircea</surname><given-names>I.-G.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>A reinforcement learning based approach to multiple sequence alignment</article-title>. In: <italic>Proceedings of the 7th International Workshop Soft Computing Applications (SOFA2016),</italic> vol. 2<italic>,</italic> pp. 54–70. Cham, Switzerland, Springer.</mixed-citation>
    </ref>
    <ref id="btaa447-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Morton</surname><given-names>B.R.</given-names></name></person-group> (<year>2003</year>) 
<article-title>The role of context-dependent mutations in generating compositional and codon usage bias in grass chloroplast DNA</article-title>. <source>J. Mol. Evol</source>., <volume>56</volume>, <fpage>616</fpage>–<lpage>629</lpage>.<pub-id pub-id-type="pmid">12698298</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B48">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Nair</surname><given-names>V.</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>G.E.</given-names></name></person-group> (<year>2010</year>) 
<article-title>Rectified linear units improve restricted Boltzmann machines</article-title>. In: <italic>Proceedings of the 27th International Conference on Machine Learning</italic>, pp. <fpage>807</fpage>–<lpage>814</lpage>. Omnipress, Madison, WI, USA.</mixed-citation>
    </ref>
    <ref id="btaa447-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Needleman</surname><given-names>S.B.</given-names></name>, <name name-style="western"><surname>Wunsch</surname><given-names>C.D.</given-names></name></person-group> (<year>1970</year>) 
<article-title>A general method applicable to the search for similarities in the amino acid sequence of two proteins</article-title>. <source>J. Mol. Biol</source>., <volume>48</volume>, <fpage>443</fpage>–<lpage>453</lpage>.<pub-id pub-id-type="pmid">5420325</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B50">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Neubig</surname><given-names>G.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Neural machine translation and sequence-to-sequence models: a tutorial</article-title>. <italic>arXiv preprint arXiv:1703.01619</italic></mixed-citation>
    </ref>
    <ref id="btaa447-B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Papadopoulos</surname><given-names>J.S.</given-names></name>, <name name-style="western"><surname>Agarwala</surname><given-names>R.</given-names></name></person-group> (<year>2007</year>) 
<article-title>Cobalt: constraint-based alignment tool for multiple protein sequences</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>1073</fpage>–<lpage>1079</lpage>.<pub-id pub-id-type="pmid">17332019</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Price</surname><given-names>M.N.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Fasttree 2—approximately maximum-likelihood trees for large alignments</article-title>. <source>PLoS One</source>, <volume>5</volume>, <fpage>e9490</fpage>.<pub-id pub-id-type="pmid">20224823</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B53">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ramakrishnan</surname><given-names>R.K.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Rlalign: a reinforcement learning approach for multiple sequence alignment</article-title>. In: <italic>2018 IEEE 18th International Conference on Bioinformatics and Bioengineering (BIBE)</italic>, pp. <fpage>61</fpage>–<lpage>66</lpage>. IEEE Computer Society, Conference Publishing Services, Los Alamitos, CA, USA.</mixed-citation>
    </ref>
    <ref id="btaa447-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ranwez</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>MACSE: multiple alignment of coding sequences accounting for frameshifts and stop codons</article-title>. <source>PLoS One</source>, <volume>6</volume>, <fpage>e22594</fpage>.<pub-id pub-id-type="pmid">21949676</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rodrigue</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>Site interdependence attributed to tertiary structure in amino acid sequence evolution</article-title>. <source>Gene</source>, <volume>347</volume>, <fpage>207</fpage>–<lpage>217</lpage>.<pub-id pub-id-type="pmid">15733531</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schwartz</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>Pipmaker—a web server for aligning two genomic DNA sequences</article-title>. <source>Genome Res</source>., <volume>10</volume>, <fpage>577</fpage>–<lpage>586</lpage>.<pub-id pub-id-type="pmid">10779500</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Siepel</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Haussler</surname><given-names>D.</given-names></name></person-group> (<year>2003</year>) 
<article-title>Phylogenetic estimation of context-dependent substitution rates by maximum likelihood</article-title>. <source>Mol. Biol. Evol</source>., <volume>21</volume>, <fpage>468</fpage>–<lpage>488</lpage>.<pub-id pub-id-type="pmid">14660683</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>T.F.</given-names></name>, <name name-style="western"><surname>Waterman</surname><given-names>M.S.</given-names></name></person-group> (<year>1981</year>) 
<article-title>Identification of common molecular subsequences</article-title>. <source>J. Mol. Biol</source>., <volume>147</volume>, <fpage>195</fpage>–<lpage>197</lpage>.<pub-id pub-id-type="pmid">7265238</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stoye</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>1998</year>) 
<article-title>Rose: generating sequence families</article-title>. <source>Bioinformatics</source>, <volume>14</volume>, <fpage>157</fpage>–<lpage>163</lpage>.<pub-id pub-id-type="pmid">9545448</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B60">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Sundermeyer</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>LSTM neural networks for language modeling</article-title>. In: <italic>13th Annual Conf of the</italic> <italic><italic>Int</italic>ernational Speech Communication Association</italic>, pp. 194-197. Portland, OR, USA. ISCA</mixed-citation>
    </ref>
    <ref id="btaa447-B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Surrallés</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Clusters of transcription-coupled repair in the human genome</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>99</volume>, <fpage>10571</fpage>–<lpage>10574</lpage>.<pub-id pub-id-type="pmid">12142466</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sutskever</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Sequence to sequence learning with neural networks</article-title>. In: <italic>Proceedings of the 27th International Conference on Neural Information Processing Systems</italic> - vol. 2, NIPS’14, page 3104–3112, Cambridge, MA, USA. MIT Press.</mixed-citation>
    </ref>
    <ref id="btaa447-B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Thorne</surname><given-names>J.L.</given-names></name></person-group><etal>et al</etal> (<year>1991</year>) 
<article-title>An evolutionary model for maximum likelihood alignment of DNA sequences</article-title>. <source>J. Mol. Evol</source>., <volume>33</volume>, <fpage>114</fpage>–<lpage>124</lpage>.<pub-id pub-id-type="pmid">1920447</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B64">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Vaswani</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Attention is all you need</article-title>. In: <source>Advances in Neural Information Processing Systems</source>, pp. <fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa447-B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wall</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>1999</year>) 
<article-title>Context-sensitive transposition of IS6110 in mycobacteria</article-title>. <source>Microbiology</source>, <volume>145</volume>, <fpage>3169</fpage>–<lpage>3176</lpage>.<pub-id pub-id-type="pmid">10589725</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B66">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Dynamics and function of DNA methylation in plants</article-title>. <source>Nat. Rev. Mol. Cell Biol</source>., <volume>19</volume>, <fpage>489</fpage>–<lpage>506</lpage>.<pub-id pub-id-type="pmid">29784956</pub-id></mixed-citation>
    </ref>
    <ref id="btaa447-B67">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhu</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Statistical methods for identifying sequence motifs affecting point mutations</article-title>. <source>Genetics</source>, <volume>205</volume>, <fpage>843</fpage>–<lpage>856</lpage>.<pub-id pub-id-type="pmid">27974498</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
