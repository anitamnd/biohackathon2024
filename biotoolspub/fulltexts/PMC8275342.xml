<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8275342</article-id>
    <article-id pub-id-type="pmid">34252931</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab268</article-id>
    <article-id pub-id-type="publisher-id">btab268</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Regulatory and Functional Genomics</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CROTON: an automated and variant-aware deep learning framework for predicting CRISPR/Cas9 editing outcomes</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Victoria R</given-names>
        </name>
        <aff><institution>Hunter College High School</institution>, New York, NY 10128, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Zhang</surname>
          <given-names>Zijun</given-names>
        </name>
        <aff><institution>Center for Computational Biology, Flatiron Institute, Simons Foundation</institution>, New York, NY 10010, <country country="US">USA</country></aff>
        <xref rid="btab268-cor1" ref-type="corresp"/>
        <!--zzhang@flatironinstitute.org-->
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Troyanskaya</surname>
          <given-names>Olga G</given-names>
        </name>
        <aff><institution>Center for Computational Biology, Flatiron Institute, Simons Foundation</institution>, New York, NY 10010, <country country="US">USA</country></aff>
        <aff><institution>Lewis-Sigler Institute for Integrative Genomics, Princeton University</institution>, Princeton, NJ 08540, <country country="US">USA</country></aff>
        <aff><institution>Department of Computer Science, Princeton University</institution>, Princeton, NJ 08544, <country country="US">USA</country></aff>
        <xref rid="btab268-cor1" ref-type="corresp"/>
        <!--ogt@genomics.princeton.edu-->
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab268-cor1">To whom correspondence should be addressed. <email>zzhang@flatironinstitute.org</email> or <email>ogt@genomics.princeton.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-07-12">
      <day>12</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB/ECCB 2021 Proceedings</issue-title>
    <fpage>i342</fpage>
    <lpage>i348</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab268.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>CRISPR/Cas9 is a revolutionary gene-editing technology that has been widely utilized in biology, biotechnology and medicine. CRISPR/Cas9 editing outcomes depend on local DNA sequences at the target site and are thus predictable. However, existing prediction methods are dependent on both feature and model engineering, which restricts their performance to existing knowledge about CRISPR/Cas9 editing.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Herein, deep multi-task convolutional neural networks (CNNs) and neural architecture search (NAS) were used to automate both feature and model engineering and create an end-to-end deep-learning framework, CROTON (CRISPR Outcomes Through cONvolutional neural networks). The CROTON model architecture was tuned automatically with NAS on a synthetic large-scale construct-based dataset and then tested on an independent primary T cell genomic editing dataset. CROTON outperformed existing expert-designed models and non-NAS CNNs in predicting 1 base pair insertion and deletion probability as well as deletion and frameshift frequency. Interpretation of CROTON revealed local sequence determinants for diverse editing outcomes. Finally, CROTON was utilized to assess how single nucleotide variants (SNVs) affect the genome editing outcomes of four clinically relevant target genes: the viral receptors <italic toggle="yes">ACE2</italic> and <italic toggle="yes">CCR5</italic> and the immune checkpoint inhibitors <italic toggle="yes">CTLA4</italic> and <italic toggle="yes">PDCD1</italic>. Large SNV-induced differences in CROTON predictions in these target genes suggest that SNVs should be taken into consideration when designing widely applicable gRNAs.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link xlink:href="https://github.com/vli31/CROTON" ext-link-type="uri">https://github.com/vli31/CROTON</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Flatiron Institute</institution>
          </institution-wrap>
          <!-- oupReleaseDelayRemoved from OA Article (00|0) -->
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Simons Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000893</institution-id>
          </institution-wrap>
          <!-- oupReleaseDelayRemoved from OA Article (00|0) -->
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Flatiron Research Fellow</institution>
          </institution-wrap>
          <!-- oupReleaseDelayRemoved from OA Article (00|0) -->
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated protein 9 (Cas9) is a revolutionary gene-editing technology that has broad applications in basic biology, biotechnology and medicine (<xref rid="btab268-B7" ref-type="bibr">Hsu <italic toggle="yes">et al</italic>., 2014</xref>). CRISPR/Cas9-mediated genome editing follows two major steps: (1) the induction of a double-stranded break (DSB) in a target DNA sequence and (2) the activation of cellular DNA-repair pathways. CRISPR/Cas9 is a ribonucleoprotein that consists of a guide RNA (gRNA) that defines a target DNA sequence and the dual DNA endonuclease Cas9 which induces a DSB around 3 base pairs (bps) upstream of an ‘NGG’ protospacer adjacent motif (PAM). Following DNA cleavage, a DSB can be repaired by three DNA repair pathways: template-free non-homologous end-joining (NHEJ) and microhomology-mediated end joining (MMEJ), as well as template-directed homology-directed repair (HDR). HDR can be used to introduce precise DNA modifications, but it is inefficient, especially in non-mitotic cells, and often generates unwanted byproducts. In contrast, NHEJ and MMEJ were believed to trigger random repair outcomes. However, recent research has shown that NHEJ and MMEJ repair outcomes are dependent on features on target DNA sequences (<xref rid="btab268-B12" ref-type="bibr">Molla and Yang, 2020</xref>).</p>
    <p>Since a range of DNA sequence factors, such as GC content and microhomology length and position, may contribute to repair outcomes, accurate prediction of template-free CRISPR/Cas9 editing outcomes is a challenging bioinformatics question. Three machine learning (ML) models, inDelphi, FORECasT and SPROUT, which utilize neural networks and k-nearest neighbors, multinomial logistic regression, as well as gradient-boosting decision trees, respectively, have been designed to tackle this question. However, these ML methods require both feature and model engineering and are thus limited by existing knowledge about CRISPR/Cas9-induced DSB repair (<xref rid="btab268-B1" ref-type="bibr">Allen <italic toggle="yes">et al</italic>., 2019</xref>; <xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al</italic>., 2019</xref>; <xref rid="btab268-B13" ref-type="bibr">Shen <italic toggle="yes">et al</italic>., 2018</xref>).</p>
    <p>A potential alternative ML framework is deep convolutional neural networks (CNNs), which have attracted attention in computational biology because they excel at pattern recognition. Indeed, many state-of-the-art ML models capable of predicting specific molecular phenotypes from raw DNA sequences utilize deep CNNs (<xref rid="btab268-B6" ref-type="bibr">Eraslan <italic toggle="yes">et al</italic>., 2019</xref>; <xref rid="btab268-B22" ref-type="bibr">Zhang <italic toggle="yes">et al</italic>., 2021</xref>). Since deep CNNs process raw sequences, manual feature engineering is not required for CNN-generation, which can expedite model creation. Furthermore, CNNs can detect and process important, but not well-understood, parts of an input, rendering it potentially more effective and versatile relative to other ML methods. Effective model architectures are essential for CNN performance, but CNN architecture design requires a substantial amount of ML knowledge and time. Recently, neural architecture search (NAS), a state-of-the-art method for finding good neural network architectures has been developed to automate model-engineering. NAS is a form of automated machine learning (AutoML) that has been shown to generate CNNs with comparable efficacy to manually engineered models (<xref rid="btab268-B22" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btab268-B24" ref-type="bibr">Zoph and Le, 2017</xref>).</p>
    <p>Herein, CROTON (CRISPR Outcomes Through cONvolutional neural networks), a novel deep learning framework based on deep CNNs and NAS, has been created to predict CRISPR/Cas9 editing outcomes. By leveraging CNNs and NAS, CROTON fully automates the tasks of predicting 1 bp insertion and deletion probability as well as deletion and frameshift frequency from raw sequences alone and without any prior knowledge (<xref rid="btab268-F1" ref-type="fig">Fig. 1</xref>). We demonstrate that CROTON, which was trained on a synthetic construct-based dataset, outperforms existing approaches on a held-out, independent endogenous T-cell dataset. CROTON was then utilized to evaluate the effect of single nucleotide variants (SNVs) on the CRISPR/Cas9-mediated genome editing outcomes of four clinically relevant target genes: <italic toggle="yes">ACE2</italic>, <italic toggle="yes">CCR5</italic>, <italic toggle="yes">CTLA4</italic> and <italic toggle="yes">PDCD1</italic>. The differences in predicted SNV-induced editing outcomes suggest that SNVs should be considered when designing widely applicable gRNAs.</p>
    <fig position="float" id="btab268-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>The CROTON ML pipeline is highly automated. Unlike the three existing models for CRISPR/Cas9 editing outcome prediction, CNN and NAS-based CROTON is based on automated feature and model design, which creates an end-to-end ML pipeline from data acquisition to model deployment</p>
      </caption>
      <graphic xlink:href="btab268f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Acquisition and pre-processing of CRISPR/Cas9 editing outcome datasets</title>
      <p>The datasets used to train CROTON were acquired from two previous works that produced the models FORECasT and SPROUT (<xref rid="btab268-B1" ref-type="bibr">Allen <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al.</italic>, 2019</xref>). To reconcile the two datasets, we compiled 60 bp genomic sequences as the model inputs. Specifically, for each gRNA in the FORECasT dataset, we aligned the PAM sites at 33 nt so the cut site was at the center (30 nt) of all input sequences. The pseudo-letter ‘N’ was padded to the FORECasT sequences if they were shorter than 60 bp after PAM realignment. To obtain DNA sequences for SPROUT, retrieved genomic coordinates were mapped to the human genome build 38 (hg38). Subsequently, sequences from FORECasT and SPROUT were one hot encoded to <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mn>4</mml:mn><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> matrices for each DNA sequence, where <italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>60 was the sequence length, the nucleotide ‘A’ was represented by the array [1, 0, 0, 0], ‘C’ was represented by [0, 1, 0, 0], ‘G’ was represented by [0, 0, 1, 0], ‘T’ was represented by [0, 0, 0, 1] and ‘N’ was represented by [0.25, 0.25, 0.25, 0.25].</p>
      <p>To compile the editing outcomes, CIGAR (Compact Idiosyncratic Gapped Alignment Report) strings were processed for the FORECasT and SPROUT datasets. For each gRNA, we computed the following editing outcome statistics: (1) 1 bp insertion frequency, (2) 1 bp deletion frequency, (3) deletion frequency, (4) 1 bp frameshift frequency, (5) 2 bp frameshift frequency and (6) total frameshift frequency. (Given <italic toggle="yes">I</italic> is the total number of insertions, <italic toggle="yes">D</italic> is the total number of deletions and <italic toggle="yes">I </italic>+<italic toggle="yes"> D</italic> is the total number of insertions or deletions (indels), the first three metrics were defined as follows: (i) <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>b</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> (ii) <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>b</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> and (iii) <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mi>D</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. The next three frameshift frequency statistics were defined as the proportion of indel outcomes that induced a frameshift of 1 bp, 2 bp or the union of both).</p>
      <p>We leveraged the large-scale FORECasT data to train the model and held out the SPROUT dataset as an independent dataset for performance evaluation. Within the FORECasT data, samples were randomly split into training, validation and testing datasets in an 8:1:1 ratio. The FORECasT training dataset had 28 105 datapoints, and both the FORECasT test and validation datasets had 3512 datapoints. In addition, the SPROUT dataset, which we utilized for cross-cellular testing, had 1603 datapoints. The validation dataset was used to monitor model training convergence and early-stopping, while the testing datasets were held-out as independent, unseen datasets to evaluate the trained model performance.</p>
    </sec>
    <sec>
      <title>2.2 Automated deep learning interface for CRISPR/Cas9 editing outcome prediction</title>
      <p>CROTON is a deep CNN that predicts CRISPR/Cas9 editing outcomes from raw one hot encoded DNA sequences. Given a one-hot encoded input sequence of shape <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>×</mml:mo><mml:mn>60</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, the task for CROTON was to learn a function <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>ω</mml:mo><mml:mo>;</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with trainable parameters <italic toggle="yes">ω</italic> under a fixed architecture <italic toggle="yes">a</italic> that mapped a sequence <italic toggle="yes">x<sub>i</sub></italic> to a vector of six indel and frameshift-related probabilities <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>|</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, such that <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>ω</mml:mo><mml:mo>;</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. To search for expressive architectures <italic toggle="yes">a</italic> and learn <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>ω</mml:mo><mml:mo>;</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, AMBER (v0.1.0), a framework for CNN architecture design for genomic sequence processing, was utilized to automatically design the CROTON model architecture. In AMBER, CROTON’s input and output stems were fixed to fit the input sequences and output labels, while its middle eight convolution layers were searched (<xref rid="btab268-B22" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
      <p>We first describe the fixed input and output stems for CROTON. The input layer contained a 4 × 60 matrix <italic toggle="yes">x<sub>i</sub></italic>, followed by a linear stem convolution layer with kernel size 8 that expanded the 4-channel DNA sequence into 32 channels. The top of the model employed global average pooling that flattened convolution layers to a fully connected layer with 32 hidden units, and the final outputs of the model were multi-tasking predictions for each of the six editing outcome statistics. We used binary cross-entropy as the loss function to update <italic toggle="yes">ω</italic> for predictions of the six indel and frameshift-related probabilities on a set of <italic toggle="yes">N</italic> training datapoints:
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>ω</mml:mo><mml:mo>;</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mo>·</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>ω</mml:mo><mml:mo>;</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>·</mml:mo><mml:mo> </mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>ω</mml:mo><mml:mo>;</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Next, we describe the model search space for the variable layers of CROTON. Specifically, the middle eight convolution layers were variable, and their computational operations and residual connections were searched by AMBER (<xref rid="btab268-B22" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>) to build an optimal CNN architecture. For each layer, AMBER searched for six candidate computational operations: four convolution layers with Rectified Linear Unit (ReLU) activation, kernel size <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and dilation rate <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, as well as the maximum and average pooling layers with pooling size = 4 and stride size = 1. Convolution operations across all layers had 32 filters, consistent with the input stem linear convolution. A special operation, identity mapping, was also added at each layer to potentially reduce model complexity. For any layer <italic toggle="yes">t</italic>, the computation operation was sparsely encoded by <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. Residual connections for the <italic toggle="yes">t</italic>th layer were encoded as binary tokens <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> from each of the preceding layers <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>..</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. For brevity, we let <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:msubsup><mml:mo>|</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> be CROTON’s model architecture tokens for both computation operations and residual connections in the <italic toggle="yes">T </italic>=<italic toggle="yes"> </italic>8 model space, such that a set of architecture tokens <italic toggle="yes">a</italic> fully specifies a model architecture for CROTON. In total, this eight-layer model space hosted <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mn>1.54</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mn>15</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> viable model architectures.</p>
      <p>Therefore, the architecture search problem was formulated as a sparse classification for the selection of computation operations, and binary classifications for residual connections, respectively. AMBER leverages a recurrent neural network (RNN) with parameters <italic toggle="yes">θ</italic> as a controller model to generate CROTON’s model architectures <italic toggle="yes">a</italic> with log-likelihood <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mo>π</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>;</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. A detailed explanation of the AMBER workflow can be found in our published work (<xref rid="btab268-B22" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
      <p>Formally, let <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> denote the computation operation, and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> denote residual connections for the <italic toggle="yes">t</italic>th layer; let <italic toggle="yes">h<sub>t</sub></italic> denote the hidden states of the controller model at the <italic toggle="yes">t</italic>th layer. At each layer <italic toggle="yes">t</italic>, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> were sampled probabilistically from multinomial and binomial distributions, respectively; subsequently, the sampled tokens were fed as inputs to the next layer <italic toggle="yes">t </italic>+<italic toggle="yes"> </italic>1. In particular, the controller model predicted the <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> by first updating the hidden state through a long short-term memory (LSTM) cell <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>o</mml:mi></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, then sampling from the multinomial distribution of softmax function <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> transformed <italic toggle="yes">h<sub>t</sub></italic> by weight <italic toggle="yes">W<sub>o</sub></italic>:
<disp-formula id="E2"><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>o</mml:mi></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>The residual connection for the <italic toggle="yes">t</italic>th layer from the <italic toggle="yes">r</italic>th layer, <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>r</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, was sampled from the binomial distribution whose probability was determined by an attention mechanism between the query layer’s hidden state <italic toggle="yes">h<sub>t</sub></italic> and the previous layer’s hidden state <italic toggle="yes">h<sub>r</sub></italic>, with trainable weights <italic toggle="yes">v</italic>, <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:
<disp-formula id="E3"><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>·</mml:mo><mml:mi>tanh</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Thus, the total trainable parameters for the controller model were <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mo>θ</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, and the log-likelihood for selecting a set of architecture tokens <italic toggle="yes">a</italic> under the parameters <italic toggle="yes">θ</italic> was <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:mo>π</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>;</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We employed reinforcement learning to optimize <italic toggle="yes">θ</italic>. Following the previously established REINFORCE rule (<xref rid="btab268-B18" ref-type="bibr">Williams, 1992</xref>), the policy gradient for <italic toggle="yes">θ</italic> was obtained to maximize the average multi-tasking Spearman’s correlation coefficient R on the validation dataset over a batch of <italic toggle="yes">m</italic> sampled architectures, with an exponential moving average of rewards <italic toggle="yes">b</italic> to stabilize the reward signals:
<disp-formula id="E4"><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mo>θ</mml:mo></mml:msub></mml:mrow><mml:mo>π</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Finally, the optimal AMBER-searched CNN architecture, which was defined as the best reward architecture in the last controller step, was scaled in width by a scaling factor. Dropouts were then added after each searched layer before the architecture was re-trained from scratch. We performed a simple grid search for these two additional hyperparameters and reported the best performing model with width scaling factor = 6 and dropout rate = 0.4. Training convergence was defined as validation loss not decreasing for at least 50 epochs.</p>
    </sec>
    <sec>
      <title>2.3 Performance comparisons</title>
      <p>We sampled CNN architectures from the same model space without training the AMBER controller model to benchmark the quality of the automatically designed model architecture. In particular, computational operations were sampled uniformly from the model space; residual connections were sampled at the same density as CROTON. A total of <italic toggle="yes">n </italic>=<italic toggle="yes"> </italic>50 models with sampled architectures were trained with identical width-scale factor and optimization configurations to robustly evaluate an uninformed, null distribution of performance in the model space. Subsequently, the testing performance for every CROTON prediction task was compared to that of the sampled model cohort.</p>
      <p>We also evaluated CROTON’s predictions by classifying each individual task’s predicted probability as high (larger than the observed median value) versus low (lower than the observed median value), and calculated area under the curve receiver operating characteristics (AUC-ROC) for this binary classification problem.</p>
      <p>Furthermore, we applied the trained CROTON model on the held-out SPROUT T-cell dataset as an independent, cross-cellular benchmark. Existing methods were benchmarked against CROTON, including inDelphi (<xref rid="btab268-B13" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2018</xref>), FORECasT (<xref rid="btab268-B1" ref-type="bibr">Allen <italic toggle="yes">et al.</italic>, 2019</xref>) and SPROUT (<xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al.</italic>, 2019</xref>). For inDelphi and FORECasT, we used the publicly available trained models (<ext-link xlink:href="https://github.com/maxwshen/inDelphi-model" ext-link-type="uri">https://github.com/maxwshen/inDelphi-model</ext-link> and <ext-link xlink:href="https://github.com/felicityallen/SelfTarget" ext-link-type="uri">https://github.com/felicityallen/SelfTarget</ext-link>) to generate predictions for all sequences in the SPROUT dataset. The Pearson’s correlation between predicted and observed values was then utilized to compare the performance of inDelphi and FORECasT to that of CROTON. Since inDelphi had different models for different cell lines, we reported values from the best performing inDelphi cell-line/model. For the SPROUT model trained on the SPROUT dataset, we compared CROTON’s performance to the published metrics (<xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al.</italic>, 2019</xref>) under the criteria defined by SPROUT (i.e. Kendall’s tau for 1 bp insertion and deletion probabilities, and Pearson’s correlation for deletion frequency).</p>
    </sec>
    <sec>
      <title>2.4 <italic toggle="yes">In silico</italic> saturated mutagenesis analysis for model interpretation</title>
      <p>To interpret how the CNNs made their predictions, <italic toggle="yes">in silico</italic> saturated mutagenesis was performed using the Selene framework (<xref rid="btab268-B4" ref-type="bibr">Chen <italic toggle="yes">et al</italic>., 2019</xref>). <italic toggle="yes">In silico</italic> saturated mutagenesis is a perturbation-based base importance analysis method in which CNNs evaluate DNA sequences with single nucleotide polymorphisms (SNPs). In an SNP, a nucleotide at a specific position along a DNA sequence is changed to another, for instance, ‘ACC’ is a perturbed sequence of ‘GCC’. In <italic toggle="yes">in silico</italic> saturated mutagenesis, the model runs on every possible one hot encoded sequence that can be perturbed from the original sequence. The final interpretation output is a matrix with the same shape as the input (4 × 60) in which every matrix entry represents a base importance score calculated as the difference between the predictions of the reference sequence and the altered sequence. In summary, <italic toggle="yes">in silico</italic> saturated mutagenesis evaluates how important every base pair position is to a CNN by computing the deviation of its predictions for sequences with SNPs at that position from the original unperturbed sequence. Herein, sequences with model predictions within 0.05 of true values were utilized for <italic toggle="yes">in silico</italic> saturated mutagenesis analysis.</p>
    </sec>
    <sec>
      <title>2.5 Variant effect analysis for frameshift gRNA design</title>
      <p>The human genome-wide variants dbSNP build 151 VCF file was downloaded from NCBI (<ext-link xlink:href="http://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh38p7/VCF/" ext-link-type="uri">ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh38p7/VCF/</ext-link>). For all annotated coding exons in Gencode V35, we scanned potential PAM sites (‘NGG’) in the hg38 genome before aligning them to the CROTON 60 bp window. Then, bedtools (v2.29) was used to intersect the PAM sequences to the variants. For each PAM site with variants in the four representative genes (<italic toggle="yes">ACE2</italic>, <italic toggle="yes">CCR5</italic>, <italic toggle="yes">CTLA4</italic> and <italic toggle="yes">PDCD1</italic>), CROTON predicted editing outcome probabilities for sequences with reference and alternative alleles. The differences between reference and alternative alleles were subsequently calculated for each of the individual tasks. In addition, to find the least variant gene-editing targets, the absolute differences between the reference and alternative CROTON predictions were computed across all statistics for all SNVs at a particular potential target location. Then these targets were ranked by the mean of their absolute differences to elucidate the gene targets with the least impactful SNVs.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Automated model architecture design for CROTON</title>
      <p>CROTON was built on data from FORECasT because it produced the largest CRISPR/Cas9 editing outcome dataset relative to those of inDelphi and SPROUT (<xref rid="btab268-B1" ref-type="bibr">Allen <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B13" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2018</xref>). FORECasT data was split into training, validation and testing datasets and all metrics presented are from model performance on the testing dataset, which CROTON was unexposed to during training. CROTON was designed to predict 1 bp insertion and 1 bp deletion probability, as well as deletion, 1 bp frameshift, 2 bp frameshift and overall frameshift frequency. Since these features were interrelated, we chose to utilize a multi-task learning framework.</p>
      <p>Multi-task learning can outperform single-task learning by leveraging features derived for multiple prediction tasks (<xref rid="btab268-B21" ref-type="bibr">Zhang and Yang, 2018</xref>). In addition, manually tuning a CNN would be time-consuming and limited in scope. Thus, we utilized NAS to automatically create a multi-task deep CNN framework for CRISPR/Cas9 editing outcome prediction. The NAS model search space contained dilated and non-dilated one-dimensional convolutional layers with kernel sizes four and eight (dconv4, dconv8, conv4 and conv8) as well as the maximum pooling (maxpool), average pooling (avgpool) and identity layers (Methods). To assess the efficacy of automated model engineering, the final NAS architecture was compared to 50 randomly sampled model architectures from the search space. The final NAS-designed CROTON model outperformed all randomly selected model architectures, indicating that NAS is an effective strategy for deep-CNN design. The final CROTON architecture achieved Pearson’s Correlations (<italic toggle="yes">R<sub>P</sub></italic>) greater than 60 for all prediction tasks and <italic toggle="yes">R<sub>P</sub></italic> greater than 70 for deletion frequency, 1 bp insertion probability and 1 bp deletion probability prediction (<xref rid="btab268-F2" ref-type="fig">Fig. 2A</xref>).</p>
      <fig position="float" id="btab268-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>NAS designs effective multi-task deep CNN architectures. (<bold>A</bold>) CROTON outperforms models with sampled architectures from the model search space. CROTON achieves <italic toggle="yes">R<sub>P</sub></italic> of &gt; 60 for all prediction tasks and <italic toggle="yes">R<sub>P</sub></italic> of 87.96 and 90.79 for deletion frequency and 1 bp insertion probability prediction, respectively. (<bold>B</bold>) The layer selection probabilities for the best CROTON architecture</p>
        </caption>
        <graphic xlink:href="btab268f2" position="float"/>
      </fig>
      <p>We also analyzed the average layer selection probabilities for the NAS run. Interestingly, across all model layers, convolutional layers were consistently favored over pooling layers, indicating that precise feature locations were conserved in our model. In addition, a dilated convolutional layer of size 8 was favored for all layers after Layer 1. Dilated layers allow the receptive field to be enlarged without losing resolution or coverage, further suggesting that spatial relationships between features were important for CRISPR/Cas9 outcome prediction (<xref rid="btab268-F2" ref-type="fig">Fig. 2B;</xref>  <xref rid="btab268-B20" ref-type="bibr">Yu and Koltun, 2016</xref>).</p>
    </sec>
    <sec>
      <title>3.2 Croton accurately predicts CRISPR/Cas9 editing outcomes across cell lines and outperforms other predictors</title>
      <p>The efficacy of CROTON was also assessed by computing whether it made accurate predictions above or below the median value in each task dataset. Using this evaluation strategy, the area under the curve (AUC) was calculated to measure CROTON’s performance. On the FORECasT data, CROTON achieved AUCs of greater than 80 for all prediction tasks and greater than 90 for the deletion frequency and 1 bp insertion tasks (<xref rid="btab268-F3" ref-type="fig">Fig. 3A</xref>). Since FORECasT data was based on synthetic gRNA-CRISPR target constructs, it was important to test CROTON on an endogenously generated gene-editing dataset (<xref rid="btab268-B1" ref-type="bibr">Allen <italic toggle="yes">et al.</italic>, 2019</xref>). To this end, CROTON was tested with the held-out, independent SPROUT CRISPR/Cas9 editing outcome dataset. This dataset was derived from primary human T cells, which are widely utilized in therapeutic cell engineering (<xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B17" ref-type="bibr">Wang <italic toggle="yes">et al</italic>., 2020</xref>). On the SPROUT dataset, CROTON’s performance was conserved with AUCs similar to those measured with the FORECasT dataset, indicating that large-scale synthetic construct based datasets are effective for endogenous CRISPR/Cas9 predictions (<xref rid="btab268-F3" ref-type="fig">Fig. 3B</xref>).</p>
      <fig position="float" id="btab268-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>CROTON makes accurate CRISPR/Cas9 editing outcome predictions across cell lines. (<bold>A</bold>) AUC-ROC curves for CROTON’s predictions on the testing FORECasT dataset. (<bold>B</bold>) AUC-ROC curves for CROTON’s performance on the held-out, primary T cell-derived SPROUT dataset. Across cell lines, CROTON achieved AUCs &gt; 0.75 for all prediction tasks and AUCs &gt; 0.90 for deletion frequency and 1 bp insertion prediction</p>
        </caption>
        <graphic xlink:href="btab268f3" position="float"/>
      </fig>
      <p>CROTON’s predictive accuracy on the SPROUT dataset was then compared to that of existing ML-based CRISPR/Cas9 editing outcome predictors: SPROUT, FORECasT and inDelphi. For inDelphi, metrics for the best performing model on the HEK293 cell line were reported. Overall, CROTON substantially outperformed all models on all but one task. CROTON was only less effective than FORECasT at frameshift frequency prediction but outperformed FORECasT with wide margins on other prediction tasks such as deletion and 1 bp insertion frequency (<xref rid="btab268-T1" ref-type="table">Tables 1</xref> and <xref rid="btab268-T2" ref-type="table">2</xref>). Notably, CROTON performed on par or even outperformed SPROUT, which was trained on the SPROUT dataset.</p>
      <table-wrap position="float" id="btab268-T1">
        <label>Table 1.</label>
        <caption>
          <p>Performance comparison of CROTON, inDelphi and FORECasT by Pearson’s correlation (<italic toggle="yes">R<sub>P</sub></italic>)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">CROTON</th>
              <th rowspan="1" colspan="1">inDelphi</th>
              <th rowspan="1" colspan="1">FORECasT</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Deletion frequency</td>
              <td rowspan="1" colspan="1">
                <bold>81.12</bold>
              </td>
              <td rowspan="1" colspan="1">51.00</td>
              <td rowspan="1" colspan="1">73.17</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1 bp insertion</td>
              <td rowspan="1" colspan="1">
                <bold>82.42</bold>
              </td>
              <td rowspan="1" colspan="1">52.40</td>
              <td rowspan="1" colspan="1">75.10</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1 bp deletion</td>
              <td rowspan="1" colspan="1">
                <bold>57.51</bold>
              </td>
              <td rowspan="1" colspan="1">21.45</td>
              <td rowspan="1" colspan="1">30.36</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1 bp frameshift frequency</td>
              <td rowspan="1" colspan="1">
                <bold>73.84</bold>
              </td>
              <td rowspan="1" colspan="1">54.69</td>
              <td rowspan="1" colspan="1">66.71</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2 bp frameshift frequency</td>
              <td rowspan="1" colspan="1">
                <bold>64.30</bold>
              </td>
              <td rowspan="1" colspan="1">42.40</td>
              <td rowspan="1" colspan="1">50.04</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Frameshift frequency</td>
              <td rowspan="1" colspan="1">55.56</td>
              <td rowspan="1" colspan="1">51.54</td>
              <td rowspan="1" colspan="1">
                <bold>57.94</bold>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap position="float" id="btab268-T2">
        <label>Table 2.</label>
        <caption>
          <p>Performance comparison of CROTON and SPROUT</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">CROTON</th>
              <th rowspan="1" colspan="1">SPROUT</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Deletion frequency (<italic toggle="yes">R<sub>P</sub></italic>)</td>
              <td rowspan="1" colspan="1">
                <bold>81.12</bold>
              </td>
              <td rowspan="1" colspan="1">77</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1 bp insertion (K Tau)</td>
              <td rowspan="1" colspan="1">
                <bold>65.22</bold>
              </td>
              <td rowspan="1" colspan="1">62</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1 bp deletion (K Tau)</td>
              <td rowspan="1" colspan="1">
                <bold>43.81</bold>
              </td>
              <td rowspan="1" colspan="1">40</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.3 <italic toggle="yes">In silico</italic> mutagenesis revealed local sequence determinants for diverse editing outcomes</title>
      <p>Since CROTON is an effective CRISPR/Cas9 editing outcome predictor and does not utilize any manual feature engineering, it was important to elucidate how CROTON made predictions from a raw input sequence. Thus, we conducted <italic toggle="yes">in silico</italic> saturated mutagenesis for CROTON on all prediction tasks for both the FORECasT and SPROUT datasets. These plots display the average importance values computed over multiple sequences in these test datasets (Methods). Across FORECasT and SPROUT data, saturated mutagenesis plots for the same prediction task were very similar. Representative <italic toggle="yes">in silico</italic> saturated mutagenesis plots based on FORECasT data are shown in which larger text is indicative of nucleotides with greater importance to CROTON prediction (<xref rid="btab268-F4" ref-type="fig">Fig. 4</xref>).</p>
      <fig position="float" id="btab268-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>The importance assigned by CROTON to every nucleotide on the input sequence <italic toggle="yes">In silico</italic> saturated mutagenesis plots for 1 bp insertion probability (<bold>A</bold>), 1 bp deletion probability (<bold>B</bold>), deletion frequency (<bold>C</bold>) and frameshift frequency (<bold>D</bold>)</p>
        </caption>
        <graphic xlink:href="btab268f4" position="float"/>
      </fig>
      <p>Consistent with prior reports, the base pairs upstream of the PAM sequence were the most important for CROTON’s template-free CRISPR/Cas9 editing outcome predictions (<xref rid="btab268-F4" ref-type="fig">Fig. 4</xref>; <xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B13" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2018</xref>). In particular, our analyses support cross-cell line and cross-organism studies that have shown that the nucleotide 4 base pairs upstream of the PAM has the greatest effect on CRISPR/Cas9 DSB repair (<xref rid="btab268-F4" ref-type="fig">Fig. 4A and C</xref>; <xref rid="btab268-B12" ref-type="bibr">Molla and Yang, 2020</xref>). Thus, our study confirms that the positions of nucleotides relative to the PAM site are important to CRISPR/Cas9 editing outcomes. Notably, 1 bp deletion and frameshift frequency had determinants across the entire input sequence (<xref rid="btab268-F4" ref-type="fig">Fig. 4B and D</xref>), suggesting that they are more complex prediction tasks.</p>
    </sec>
    <sec>
      <title>3.4 Croton reveals the effects of SNVs on CRISPR/Cas9-mediated genome editing</title>
      <p>There are approximately 10–15 million common human SNVs, which can impact the efficacy of CRISPR/Cas9 editing (<xref rid="btab268-B3" ref-type="bibr">Chen <italic toggle="yes">et al</italic>., 2020</xref>; <xref rid="btab268-B5" ref-type="bibr">Eichler <italic toggle="yes">et al</italic>., 2007</xref>). Since CROTON accurately predicts 1 bp insertion probability with the best performance (<xref rid="btab268-T1" ref-type="table">Tables 1</xref> and <xref rid="btab268-T2" ref-type="table">2</xref>), we utilized 1 bp insertion probability to analyze the effect of SNVs on CRISPR/Cas9 editing outcomes. CROTON was applied across the coding regions of the gene bodies of 4 clinically relevant gene editing targets: <italic toggle="yes">ACE2</italic>, <italic toggle="yes">CCR5</italic>, <italic toggle="yes">CTLA4</italic> and <italic toggle="yes">PDCD1</italic>. <italic toggle="yes">ACE2</italic> and <italic toggle="yes">CCR5</italic> are receptors for the SARS-CoV-2 virus and the human immunodeficiency virus (HIV), respectively, and have been considered as therapeutic targets for viral infection (<xref rid="btab268-B11" ref-type="bibr">Michauld <italic toggle="yes">et al</italic>., 2020</xref>; <xref rid="btab268-B16" ref-type="bibr">Vangelista and Vento, 2018</xref>). <italic toggle="yes">CTLA4</italic> and <italic toggle="yes">PDCD1</italic> are immune checkpoint inhibitors that can be targeted for cancer immunotherapy (<xref rid="btab268-B14" ref-type="bibr">Shi <italic toggle="yes">et al</italic>., 2017</xref>; <xref rid="btab268-B15" ref-type="bibr">Stadtmaue <italic toggle="yes">et al</italic>., 2020</xref>; <xref rid="btab268-B17" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>). Indeed, several ongoing clinical trials utilize CRISPR/Cas9 to delete <italic toggle="yes">PDCD1</italic>, including one that has been deemed safe and feasible for late-stage non-small cell lung cancer (NSCLC) patients (ClinicalTrials.gov NCT02793856; <xref rid="btab268-B10" ref-type="bibr">Lu <italic toggle="yes">et al</italic>., 2020</xref>; <xref rid="btab268-B17" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
      <p>Notably, CROTON’s analysis revealed that there were SNVs that altered the 1 bp insertion probability by <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mo>≥</mml:mo></mml:math></inline-formula> 30% in all four clinically relevant genes (<xref rid="btab268-T3" ref-type="table">Table 3</xref>). We have also tabulated the top ten least variant gene target locations for each of these genes (Supplementary Tables S1–S4). Since 1 bp insertions result in frameshift mutations that will likely inactivate the target gene, these findings indicate that personalized genomic variants should be properly considered for these PAM sites for genome-editing applications in patients. We further analyzed <italic toggle="yes">PDCD1</italic> because it is involved in the greatest number of ongoing interventional CRISPR/Cas9 clinical trials (<xref rid="btab268-B17" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>). 1 bp insertion probability in <italic toggle="yes">PDCD1</italic> varies considerably across the coding regions of the gene body. Notably, the two gRNAs which were used in the NSCLC trial, hereafter referred to as gRNA1 and gRNA2, had a high and low 1 bp insertion probability, respectively (<xref rid="btab268-F5" ref-type="fig">Fig. 5</xref>; boxed in orange). These differences indicate that gRNA1 by itself is more likely to create a loss of function mediated by a 1 bp insertion than gRNA2. CROTON’s predictions indicate that SNVs may be important factors to consider in CRISPR/Cas9 genome editing, especially in clinical trials with patients that harbor these variants.</p>
      <fig position="float" id="btab268-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>SNVs affect CRISPR/Cas9 editing outcomes. The distribution of CROTON’s 1 bp insertion probability predictions on all 211 PAM sites across the five <italic toggle="yes">PDCD1</italic> coding regions. The orange boxes indicate gRNA1 (left) and gRNA2 (right), which were utilized in an NSCLC clinical trial that used CRISPR/Cas9 to inactivate <italic toggle="yes">PDCD1</italic>. The black horizontal line indicates the 1 bp insertion probability prediction for the reference sequence, while circles (color-coded by exon) indicate the 1 bp insertion probability predictions for sequences with alternative alleles</p>
        </caption>
        <graphic xlink:href="btab268f5" position="float"/>
      </fig>
      <table-wrap position="float" id="btab268-T3">
        <label>Table 3.</label>
        <caption>
          <p>SNVs with a High Impact on 1 bp Insertion Probability</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Gene</th>
              <th rowspan="1" colspan="1">Variant</th>
              <th rowspan="1" colspan="1">Reference Pred.</th>
              <th rowspan="1" colspan="1">Alternate Pred.</th>
              <th rowspan="1" colspan="1">Absolute difference</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs1284638279</td>
              <td rowspan="1" colspan="1">0.576</td>
              <td rowspan="1" colspan="1">0.110</td>
              <td rowspan="1" colspan="1">0.466</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ACE2</italic>
              </td>
              <td rowspan="1" colspan="1">rs1482922566</td>
              <td rowspan="1" colspan="1">0.656</td>
              <td rowspan="1" colspan="1">0.222</td>
              <td rowspan="1" colspan="1">0.434</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ACE2</italic>
              </td>
              <td rowspan="1" colspan="1">rs370610075</td>
              <td rowspan="1" colspan="1">0.056</td>
              <td rowspan="1" colspan="1">0.489</td>
              <td rowspan="1" colspan="1">0.432</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs535799968</td>
              <td rowspan="1" colspan="1">0.029</td>
              <td rowspan="1" colspan="1">0.429</td>
              <td rowspan="1" colspan="1">0.399</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs141119263</td>
              <td rowspan="1" colspan="1">0.202</td>
              <td rowspan="1" colspan="1">0.601</td>
              <td rowspan="1" colspan="1">0.398</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs769685838</td>
              <td rowspan="1" colspan="1">0.130</td>
              <td rowspan="1" colspan="1">0.524</td>
              <td rowspan="1" colspan="1">0.394</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs371902970</td>
              <td rowspan="1" colspan="1">0.132</td>
              <td rowspan="1" colspan="1">0.515</td>
              <td rowspan="1" colspan="1">0.382</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs370660750</td>
              <td rowspan="1" colspan="1">0.116</td>
              <td rowspan="1" colspan="1">0.497</td>
              <td rowspan="1" colspan="1">0.381</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs1021665035</td>
              <td rowspan="1" colspan="1">0.110</td>
              <td rowspan="1" colspan="1">0.475</td>
              <td rowspan="1" colspan="1">0.365</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs1185044781</td>
              <td rowspan="1" colspan="1">0.399</td>
              <td rowspan="1" colspan="1">0.036</td>
              <td rowspan="1" colspan="1">0.363</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">CCR5</italic>
              </td>
              <td rowspan="1" colspan="1">rs1032906612</td>
              <td rowspan="1" colspan="1">0.060</td>
              <td rowspan="1" colspan="1">0.422</td>
              <td rowspan="1" colspan="1">0.362</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">CCR5</italic>
              </td>
              <td rowspan="1" colspan="1">rs139737901</td>
              <td rowspan="1" colspan="1">0.190</td>
              <td rowspan="1" colspan="1">0.552</td>
              <td rowspan="1" colspan="1">0.362</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">CCR5</italic>
              </td>
              <td rowspan="1" colspan="1">rs767205045</td>
              <td rowspan="1" colspan="1">0.546</td>
              <td rowspan="1" colspan="1">0.186</td>
              <td rowspan="1" colspan="1">0.360</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs368550965</td>
              <td rowspan="1" colspan="1">0.184</td>
              <td rowspan="1" colspan="1">0.537</td>
              <td rowspan="1" colspan="1">0.353</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs749023157</td>
              <td rowspan="1" colspan="1">0.039</td>
              <td rowspan="1" colspan="1">0.388</td>
              <td rowspan="1" colspan="1">0.350</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">CCR5</italic>
              </td>
              <td rowspan="1" colspan="1">rs768195565</td>
              <td rowspan="1" colspan="1">0.583</td>
              <td rowspan="1" colspan="1">0.248</td>
              <td rowspan="1" colspan="1">0.336</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">CTLA4</italic>
              </td>
              <td rowspan="1" colspan="1">rs1461208141</td>
              <td rowspan="1" colspan="1">0.420</td>
              <td rowspan="1" colspan="1">0.098</td>
              <td rowspan="1" colspan="1">0.322</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ACE2</italic>
              </td>
              <td rowspan="1" colspan="1">rs148036434</td>
              <td rowspan="1" colspan="1">0.472</td>
              <td rowspan="1" colspan="1">0.149</td>
              <td rowspan="1" colspan="1">0.322</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs1422265917</td>
              <td rowspan="1" colspan="1">0.015</td>
              <td rowspan="1" colspan="1">0.336</td>
              <td rowspan="1" colspan="1">0.321</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ACE2</italic>
              </td>
              <td rowspan="1" colspan="1">rs748076875</td>
              <td rowspan="1" colspan="1">0.077</td>
              <td rowspan="1" colspan="1">0.393</td>
              <td rowspan="1" colspan="1">0.317</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">CTLA4</italic>
              </td>
              <td rowspan="1" colspan="1">rs1444367175</td>
              <td rowspan="1" colspan="1">0.221</td>
              <td rowspan="1" colspan="1">0.537</td>
              <td rowspan="1" colspan="1">0.316</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">ACE2</italic>
              </td>
              <td rowspan="1" colspan="1">rs1395782023</td>
              <td rowspan="1" colspan="1">0.083</td>
              <td rowspan="1" colspan="1">0.398</td>
              <td rowspan="1" colspan="1">0.314</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs146642159</td>
              <td rowspan="1" colspan="1">0.033</td>
              <td rowspan="1" colspan="1">0.346</td>
              <td rowspan="1" colspan="1">0.313</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs1485118790</td>
              <td rowspan="1" colspan="1">0.389</td>
              <td rowspan="1" colspan="1">0.080</td>
              <td rowspan="1" colspan="1">0.309</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs1329281649</td>
              <td rowspan="1" colspan="1">0.398</td>
              <td rowspan="1" colspan="1">0.095</td>
              <td rowspan="1" colspan="1">0.303</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs774374376</td>
              <td rowspan="1" colspan="1">0.019</td>
              <td rowspan="1" colspan="1">0.321</td>
              <td rowspan="1" colspan="1">0.302</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">PDCD1</italic>
              </td>
              <td rowspan="1" colspan="1">rs1371267560</td>
              <td rowspan="1" colspan="1">0.512</td>
              <td rowspan="1" colspan="1">0.212</td>
              <td rowspan="1" colspan="1">0.300</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>CRISPR/Cas9 is a transformative gene-editing technology that has been widely applied in basic and translational biological research (<xref rid="btab268-B7" ref-type="bibr">Hsu <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btab268-B17" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>). Recently, the creation of ML models capable of predicting the repair outcomes of CRISPR/Cas9 editing has highlighted the potential of predictable and precise template-free genome editing paradigms (<xref rid="btab268-B12" ref-type="bibr">Molla and Yang, 2020</xref>). However, existing ML prediction methods are all dependent on feature and model engineering, which may restrict their performance to current knowledge about CRISPR/Cas9 editing (<xref rid="btab268-B1" ref-type="bibr">Allen <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B9" ref-type="bibr">Leenay <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B13" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2018</xref>). Notably, deep CNNs and state-of-the-art NAS have been used to generate computational models based on genomic sequences (<xref rid="btab268-B6" ref-type="bibr">Eraslan <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab268-B22" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btab268-B24" ref-type="bibr">Zoph and Le, 2017</xref>). In this study, we created CROTON, a novel framework that leverages both multi-tasking deep CNNs and NAS to predict CRISPR/Cas9 editing outcomes. CROTON predicts 1 bp insertion and 1 bp deletion probability, as well as deletion, 1 bp frameshift, 2 bp frameshift, and overall frameshift frequency directly from raw DNA target sequences. CROTON is highly automated relative to existing ML prediction methods and it outperforms them on a primary T cell-based genomic editing dataset. These results highlight the potential for CNNs and NAS for the precise prediction of genomic editing outcomes. A CROTON web interface has been made publicly available at the following link: <ext-link xlink:href="https://github.com/vli31/CROTON" ext-link-type="uri">https://github.com/vli31/CROTON</ext-link>.</p>
    <p>The efficacy of NAS-designed models implies that NAS has significant potential in genomics and can design models that accurately predict molecular phenotypes from raw sequence alone. Furthermore, <italic toggle="yes">in silico</italic> saturated mutagenesis of CROTON showed that nucleotides upstream of the PAM were important to CNN prediction, which aligns with previous reports (<xref rid="btab268-B12" ref-type="bibr">Molla and Yang, 2020</xref>). Currently, although CROTON was built on the synthetic construct-based FORECasT dataset, when tested on the endogenous genomic SPROUT dataset, CROTON’s accuracy was largely conserved and it outperformed existing models. CROTON’s effectiveness between these two datasets indicates that utilizing synthetic constructs is an effective strategy to generate the large-scale data necessary for ML.</p>
    <p>CROTON is highly effective in predicting 1 bp insertion probability, which can result in a frameshift mutation that inactivates a target gene. However, similar to other CRISPR/Cas9 editing outcomes predictors, CROTON is less effective in predicting overall frameshift frequency, which may limit its usage for loss-of-function gRNA design. CROTON’s accurate 1 bp insertion probability predictions were applied to 4 clinically relevant target genes to assess how SNVs affect genome editing outcomes. On all four genes, <italic toggle="yes">ACE2</italic>, <italic toggle="yes">CCR5</italic>, <italic toggle="yes">CTLA4</italic> and <italic toggle="yes">PDCD1</italic>, CROTON found variants that caused a significant difference in 1 bp insertion probability. To our knowledge, this is the first study that considers how naturally occuring variants affect CRISPR/Cas9 gene editing outcomes. We found that genomic loci with SNVs that have large effects on CRISPR/Cas9 editing outcomes should be avoided in widely applicable gRNA design. Further analysis of two gRNAs that were utilized in an NSCLC clinical trial revealed differential 1 bp insertion probability. Future studies may reveal whether this difference has a significant impact on genome editing outcomes in patients and whether there are better gRNA pairs for effective <italic toggle="yes">PDCD1</italic> genome editing. A CRISPR editing outcome predictor sensitive to genetic alterations at base-pair resolution like CROTON could be critical for designing effective gene therapies tailored to individual patients.</p>
    <p>In addition, CROTON may be further developed to predict a more complete spectrum of DNA repair sequences. Notably, template-free CRISPR/Cas9-based correction of genetic diseases has been performed in Hermansky-Pudlak syndrome and Menkes disease with 88% and 94% efficiency, respectively (<xref rid="btab268-B13" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2018</xref>). If CROTON can predict specific DNA sequences resulting from template-free repair of a CRISPR/Cas9-induced DSB, it may also be utilized to design gRNAs capable of restoring normal gene function.</p>
    <p>Furthermore, CROTON may be adapted to elucidate the fundamental cellular and molecular alterations induced by CRISPR/Cas9 editing. CROTON can be used to form a deep learning pipeline with existing algorithms that can predict transcription, splicing and polyadenylation from raw DNA sequences (<xref rid="btab268-B2" ref-type="bibr">Bogard <italic toggle="yes">et al</italic>., 2019</xref>; <xref rid="btab268-B8" ref-type="bibr">Jaganathan <italic toggle="yes">et al</italic>., 2019</xref>; <xref rid="btab268-B23" ref-type="bibr">Zhou <italic toggle="yes">et al</italic>., 2018</xref>). This CROTON-based platform would allow CRISPR/Cas9 to be used for precise manipulation of the transcriptome, thus creating a novel paradigm for functional genomics and biomedicine.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>Supplementary Data</label>
      <media xlink:href="btab268_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors thank Dr. Natalie Sauerwald as well as all members of the Troyanskaya lab for their helpful discussions. The authors are also pleased to acknowledge that this work was performed using the high-performance computing resources at the Simons Foundation.</p>
    <sec>
      <title>Funding</title>
      <p>ZZ is supported by the Flatiron Institute, a division of the Simons Foundation, as a Flatiron Research Fellow.</p>
    </sec>
    <sec sec-type="COI-statement">
      <title>Conflict of Interest</title>
      <p>none declared.</p>
    </sec>
    <sec sec-type="data-availability">
      <title>Data availability</title>
      <p>FORECasT data can be downloaded from https://figshare.com/articles/dataset/processed_mutational_profiles/7312067, and SPROUT data can be downloaded from https://figshare.com/projects/Systematic_characterization_of_genome_editing_in_primary_T_cells_reveals_proximal_genomic_insertions_and_enables_machine_learning_prediction_of_CRISPR-Cas9_DNA_repair_outcomes/37166.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab268-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allen</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Predicting the mutations generated by repair of Cas9-induced double-strand breaks</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>64</fpage>–<lpage>72</lpage>.</mixed-citation>
    </ref>
    <ref id="btab268-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bogard</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>A deep neural network for predicting and engineering alternative polyadenylation</article-title>. <source>Cell</source>, <volume>178</volume>, <fpage>91</fpage>–<lpage>106</lpage>.<pub-id pub-id-type="pmid">31178116</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>SNP-CRISPR: a web tool for SNP-specific genome editing</article-title>. <source>Genes Genomes Genet</source>., <volume>10</volume>, <fpage>489</fpage>–<lpage>494</lpage>.</mixed-citation>
    </ref>
    <ref id="btab268-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Selene: a PyTorch-based deep learning library for sequence</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>315</fpage>–<lpage>318</lpage>.<pub-id pub-id-type="pmid">30923381</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eichler</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>) <article-title>Completing the map of human genetic variation</article-title>. <source>Nature</source>, <volume>447</volume>, <fpage>161</fpage>–<lpage>165</lpage>.<pub-id pub-id-type="pmid">17495918</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eraslan</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat. Rev. Genet</source>., <volume>20</volume>, <fpage>389</fpage>–<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hsu</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Development and applications of CRISPR-Cas9 for genome engineering</article-title>. <source>Cell</source>, <volume>157</volume>, <fpage>1262</fpage>–<lpage>1278</lpage>.<pub-id pub-id-type="pmid">24906146</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jaganathan</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Predicting splicing from primary sequence with deep learning</article-title>. <source>Cell</source>, <volume>176</volume>, <fpage>535</fpage>–<lpage>548</lpage>.<pub-id pub-id-type="pmid">30661751</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leenay</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Large dataset enables prediction of repair after CRISPR-Cas9 editing in primary T cells</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>1034</fpage>–<lpage>1037</lpage>.<pub-id pub-id-type="pmid">31359007</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Safety and feasibility of CRISPR-edited T cells in patients with refractory non-small-cell lung cancer</article-title>. <source>Nat. Med</source>., <volume>26</volume>, <fpage>732</fpage>–<lpage>740</lpage>.<pub-id pub-id-type="pmid">32341578</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Michauld</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>ACE2 as a therapeutic target for COVID-19; its role in infectious processes and regulation by modulators of the RAAS system</article-title>. <source>J. Clin. Med</source>., <volume>9</volume>, <fpage>2096</fpage>.<pub-id pub-id-type="pmid">32635289</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Molla</surname><given-names>K.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Predicting CRISPR/Cas9-induced mutations for precise genome editing</article-title>. <source>Trends Biotechnol</source>., <volume>38</volume>, <fpage>136</fpage>–<lpage>141</lpage>.<pub-id pub-id-type="pmid">31526571</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Predictable and precise template-free CRISPR editing of pathogenic variants</article-title>. <source>Nature</source>, <volume>563</volume>, <fpage>646</fpage>–<lpage>651</lpage>.<pub-id pub-id-type="pmid">30405244</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shi</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>CRISPR knock out CTLA-4 enhances the anti-tumor activity of cytotoxic T lymphocytes</article-title>. <source>Gene</source>, <volume>636</volume>, <fpage>36</fpage>–<lpage>41</lpage>.<pub-id pub-id-type="pmid">28888577</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stadtmaue</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>CRISPR-engineered T cells in patients with refractory cancer</article-title>. <source>Science</source>, <volume>367</volume>, <fpage>eaba7365</fpage>.<pub-id pub-id-type="pmid">32029687</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vangelista</surname><given-names>L.</given-names></string-name>, <string-name><surname>Vento</surname><given-names>S.</given-names></string-name></person-group> (<year>2018</year>) <article-title>The expanding therapeutic perspective of CCR5 blockade</article-title>. <source>Front. Immunol</source>., <volume>8</volume>, <fpage>1981</fpage>.<pub-id pub-id-type="pmid">29375583</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>CRISPR-based therapeutic genome editing: strategies and in vivo delivery by AAV vectors</article-title>. <source>Cell</source>, <volume>181</volume>, <fpage>136</fpage>–<lpage>150</lpage>.<pub-id pub-id-type="pmid">32243786</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname><given-names>R.J.</given-names></string-name></person-group> (<year>1992</year>) <article-title>Simple statistical gradient-following algorithms for connectionist reinforcement learning</article-title>. <source>Mach. Learn</source>., <volume>8</volume>, <fpage>229</fpage>–<lpage>256</lpage>.</mixed-citation>
    </ref>
    <ref id="btab268-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yu</surname><given-names>F.</given-names></string-name>, <string-name><surname>Koltun</surname><given-names>V.</given-names></string-name></person-group> (<year>2016</year>) Multi-scale context aggregation by dilated convolutions. In: <italic toggle="yes">4th Int. 620 Conf. Learn. Represent. ICLR 2016 - Conf. Track Proc</italic>.</mixed-citation>
    </ref>
    <ref id="btab268-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Q.</given-names></string-name></person-group> (<year>2018</year>) <article-title>An overview of multi-task learning</article-title>. <source>Natl. Sci. Rev</source>., <volume>5</volume>, <fpage>30</fpage>–<lpage>43</lpage>.</mixed-citation>
    </ref>
    <ref id="btab268-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>An automated framework for efficiently designing deep convolutional neural networks in genomics</article-title>. <source>Nat. Mach. Intell</source>., <volume>15</volume>, <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btab268-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk</article-title>. <source>Nat. Genet</source>., <volume>50</volume>, <fpage>1171</fpage>–<lpage>1179</lpage>.<pub-id pub-id-type="pmid">30013180</pub-id></mixed-citation>
    </ref>
    <ref id="btab268-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zoph</surname><given-names>B.</given-names></string-name>, <string-name><surname>Le</surname><given-names>Q.V.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Neural architecture search with reinforcement learning</article-title>. <source>In 5th International Conference on Learning Representations (ICLR, 2017)</source>.</mixed-citation>
    </ref>
  </ref-list>
</back>
