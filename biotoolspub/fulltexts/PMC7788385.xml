<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?covid-19-tdm?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Vis Media (Beijing)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Vis Media (Beijing)</journal-id>
    <journal-title-group>
      <journal-title>Computational Visual Media</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">2096-0433</issn>
    <issn pub-type="epub">2096-0662</issn>
    <publisher>
      <publisher-name>Tsinghua University Press</publisher-name>
      <publisher-loc>Beijing</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7788385</article-id>
    <article-id pub-id-type="pmid">33432275</article-id>
    <article-id pub-id-type="publisher-id">199</article-id>
    <article-id pub-id-type="doi">10.1007/s41095-020-0199-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Review Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>RGB-D salient object detection: A survey</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhou</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Fan</surname>
          <given-names>Deng-Ping</given-names>
        </name>
        <address>
          <email>dengpfan@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cheng</surname>
          <given-names>Ming-Ming</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shen</surname>
          <given-names>Jianbing</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shao</surname>
          <given-names>Ling</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label>Inception Institute of Artificial Intelligence (IIAI), Abu Dhabi, United Arab Emirates </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.216938.7</institution-id><institution-id institution-id-type="ISNI">0000 0000 9878 7032</institution-id><institution>CS, Nankai University, </institution></institution-wrap>Tianjin, 300350 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>7</day>
      <month>1</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>7</day>
      <month>1</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2021</year>
    </pub-date>
    <volume>7</volume>
    <issue>1</issue>
    <fpage>37</fpage>
    <lpage>69</lpage>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>7</day>
        <month>10</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made.</license-p>
        <license-p>The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</license-p>
        <license-p>To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. Other papers from this open access journal are available free of charge from <ext-link ext-link-type="uri" xlink:href="http://www.springer.com/journal/41095">http://www.springer.com/journal/41095</ext-link>. To submit a manuscript, please go to <ext-link ext-link-type="uri" xlink:href="https://www.editorialmanager.com/cvmj">https://www.editorialmanager.com/cvmj</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p>Salient object detection, which simulates human visual perception in locating the most significant object(s) in a scene, has been widely applied to various computer vision tasks. Now, the advent of depth sensors means that depth maps can easily be captured; this additional spatial information can boost the performance of salient object detection. Although various RGB-D based salient object detection models with promising performance have been proposed over the past several years, an in-depth understanding of these models and the challenges in this field remains lacking. In this paper, we provide a comprehensive survey of RGB-D based salient object detection models from various perspectives, and review related benchmark datasets in detail. Further, as light fields can also provide depth maps, we review salient object detection models and popular benchmark datasets from this domain too. Moreover, to investigate the ability of existing models to detect salient objects, we have carried out a comprehensive attribute-based evaluation of several representative RGB-D based salient object detection models. Finally, we discuss several challenges and open directions of RGB-D based salient object detection for future research. All collected models, benchmark datasets, datasets constructed for attribute-based evaluation, and related code are publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/taozh2017/RGBD-SODsurvey">https://github.com/taozh2017/RGBD-SODsurvey</ext-link>.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>RGB-D</kwd>
      <kwd>saliency</kwd>
      <kwd>light fields</kwd>
      <kwd>benchmarks</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<back>
  <fn-group>
    <fn>
      <p><bold>Tao Zhou</bold> received his Ph.D. degree in pattern recognition and intelligent systems from the Institute of Image Processing and Pattern Recognition, Shanghai JiaoTong University in 2016. He is currently a research scientist at the Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates. His research interests include machine learning, computer vision, and medical image analysis.</p>
    </fn>
    <fn>
      <p><bold>Deng-Ping Fan</bold> received his Ph.D. degree from Nankai University in 2019. He joined the Inception Institute of Artificial Intelligence in 2019. He has published about 20 papers in leading journals and conferences such as CVPR and ICCV. His research interests include computer vision, deep learning, and saliency detection.</p>
    </fn>
    <fn>
      <p><bold>Ming-Ming Cheng</bold> received his Ph.D. degree from Tsinghua University in 2012. He then was a research fellow for 2 years with Prof. Philip Torr in Oxford. He is now a professor at Nankai University, leading the Media Computing Lab. His research interests include computer graphics, machine learning, computer vision, and image processing. He is an Associate Editor of IEEE TIP. He has received several research awards, including an ACM China Rising Star Award, and an IBM Global SUR Award.</p>
    </fn>
    <fn>
      <p><bold>Jianbing Shen</bold> is currently the Lead Scientist of the Inception Institute of Artificial Intelligence. He is also a full professor at the School of Computer Science, Beijing Institute of Technology. He has published about 100 journal and conference papers in places such as IEEE TPAMI, CVPR, and ICCV. His research interests include computer vision and deep learning. He is an Associate Editor of IEEE TNNLS, IEEE TIP, etc.</p>
    </fn>
    <fn>
      <p><bold>Ling Shao</bold> is the CEO and Chief Scientist of the Inception Institute of Artificial Intelligence. His research interests include computer vision, machine learning, and medical imaging. He is an Associate Editor of IEEE TIP, IEEE TNNLS, and several other journals. He is a Fellow of the International Association of Pattern Recognition, the Institution of Engineering and Technology, and the British Computer Society.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>This research was supported by a Major Project for a New Generation of AI under Grant No. 2018AAA0100400, National Natural Science Foundation of China (61922046), and Tianjin Natural Science Foundation (17JCJQJC43700).</p>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>[1]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Fan</surname>
            <given-names>D P</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>M M</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>S H</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>Q B</given-names>
          </name>
          <name>
            <surname>Borji</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Ferrari</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Hebert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sminchisescu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Salient objects in clutter: Bringing salient object detection to the foreground</article-title>
        <source>Computer Vision — ECCV 2018</source>
        <year>2018</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>196</fpage>
        <lpage>212</lpage>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>[2]</label>
      <mixed-citation publication-type="other">Nie, G.-Y.; Cheng, M.-M.; Liu, Y.; Liang, Z.; Fan, D.-P.; Liu, Y.; Wang, Y. Multi-level context ultra-aggregation for stereo matching. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 3278–3286, 2019.</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>[3]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>J Y</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Tu</surname>
            <given-names>Z W</given-names>
          </name>
        </person-group>
        <article-title>Unsupervised object class discovery via saliency-guided multiple class learning</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2015</year>
        <volume>37</volume>
        <issue>4</issue>
        <fpage>862</fpage>
        <lpage>875</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2014.2353617</pub-id>
        <pub-id pub-id-type="pmid">26353299</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>[4]</label>
      <mixed-citation publication-type="other">Fan, D. P.; Li, T. P.; Lin, Z.; Ji, G. P.; Zhang, D. W.; Cheng, M. M.; Fu, H.; Shen, J. Re-thinking co-salient object detection. <italic>arXiv preprint</italic> arXiv:2007.03380, 2020.</mixed-citation>
    </ref>
    <ref id="CR5">
      <label>[5]</label>
      <mixed-citation publication-type="other">Rapantzikos, K.; Avrithis, Y.; Kollias, S. Dense saliency-based spatiotemporal feature points for action recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1454–1461, 2009.</mixed-citation>
    </ref>
    <ref id="CR6">
      <label>[6]</label>
      <mixed-citation publication-type="other">Fan, D.-P.; Wang, W.; Cheng, M.-M.; Shen, J. Shifting more attention to video salient object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 8554–8564, 2019.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>[7]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>W G</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>J B</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>R G</given-names>
          </name>
          <name>
            <surname>Porikli</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Saliency-aware video object segmentation</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2018</year>
        <volume>40</volume>
        <issue>1</issue>
        <fpage>20</fpage>
        <lpage>33</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2017.2662005</pub-id>
        <pub-id pub-id-type="pmid">28166489</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>[8]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>H M</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W G</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>S Y</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>J B</given-names>
          </name>
          <name>
            <surname>Lam</surname>
            <given-names>K M</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Ferrari</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Hebert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sminchisescu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Pyramid dilated deeper ConvLSTM for video salient object detection</article-title>
        <source>Computer Vision — ECCV 2018. Lecture Notes in Computer Science, Vol. 11215</source>
        <year>2018</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>744</fpage>
        <lpage>760</lpage>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>[9]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>W G</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>J B</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Video salient object detection via fully convolutional networks</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2018</year>
        <volume>27</volume>
        <issue>1</issue>
        <fpage>38</fpage>
        <lpage>49</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2017.2754941</pub-id>
        <pub-id pub-id-type="pmid">28945593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>[10]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Shimoda</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Yanai</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Leibe</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Matas</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sebe</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Welling</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Distinct class-specific saliency maps for weakly supervised semantic segmentation</article-title>
        <source>Computer Vision — ECCV 2016. Lecture Notes in Computer Science, Vol. 9908</source>
        <year>2016</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>218</fpage>
        <lpage>234</lpage>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>[11]</label>
      <mixed-citation publication-type="other">Zeng, Y.; Zhuge, Y.; Lu, H.; Zhang, L. Joint learning of saliency detection and weakly supervised semantic segmentation. In: Proceedings of the IEEE International Conference on Computer Vision, 7223–7233, 2019.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>[12]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Fan</surname>
            <given-names>D P</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>G P</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>J B</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Martel</surname>
            <given-names>A L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>PraNet: Parallel reverse attention network for polyp segmentation</article-title>
        <source>Medical Image Computing and Computer Assisted Intervention — MICCAI 2020. Lecture Notes in Computer Science, Vol. 12266</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>263</fpage>
        <lpage>273</lpage>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>[13]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fan</surname>
            <given-names>D P</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>G P</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Inf-Net: Automatic COVID-19 lung infection segmentation from CT images</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2020</year>
        <volume>39</volume>
        <issue>8</issue>
        <fpage>2626</fpage>
        <lpage>2637</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2020.2996645</pub-id>
        <pub-id pub-id-type="pmid">32730213</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>[14]</label>
      <mixed-citation publication-type="other">Wu, Y.-H.; Gao, S.-H.; Mei, J.; Xu, J.; Fan, D.-P.; Zhao, C.- W.; Cheng, M.-M. JCS: An explainable COVID-19 diagnosis system by joint classification and segmentation. <italic>arXiv preprint</italic> arXiv:2004.07054, 2020.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>[15]</label>
      <mixed-citation publication-type="other">Mahadevan, V.; Vasconcelos, N. Saliency-based discriminant tracking. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1007–1013, 2009.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>[16]</label>
      <mixed-citation publication-type="other">Hong, S.; You, T.; Kwak, S.; Han, B. Online tracking by learning discriminative saliency map with convolutional neural network. In: Proceedings of the International Conference on Machine Learning, 597–606, 2015.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>[17]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Oyang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X G</given-names>
          </name>
        </person-group>
        <article-title>Person re-identification by saliency learning</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2017</year>
        <volume>39</volume>
        <issue>2</issue>
        <fpage>356</fpage>
        <lpage>370</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2016.2544310</pub-id>
        <pub-id pub-id-type="pmid">27019470</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>[18]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Martinel</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Micheloni</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Foresti</surname>
            <given-names>G L</given-names>
          </name>
        </person-group>
        <article-title>Kernelized saliency-based person Re-identification through multiple metric learning</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2015</year>
        <volume>24</volume>
        <issue>12</issue>
        <fpage>5645</fpage>
        <lpage>5658</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2015.2487048</pub-id>
        <pub-id pub-id-type="pmid">26452280</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>[19]</label>
      <mixed-citation publication-type="other">Fan, D.-P.; Ji, G.-P.; Sun, G.; Cheng, M.-M.; Shen, J.; Shao, L. Camouaged object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2777–2787, 2020.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>[20]</label>
      <mixed-citation publication-type="other">Liu, G.; Fan, D. A model of visual attention for natural image retrieval. In: Proceedings of the IEEE Conference on Information Science and Cloud Computing Companion, 728–733, 2013.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>[21]</label>
      <mixed-citation publication-type="other">Zhao, J.-X.; Liu, J.-J.; Fan, D.-P.; Cao, Y.; Yang, J.; Cheng, M.-M. EGNet: Edge guidance network for salient object detection. In: Proceedings of the IEEE International Conference on Computer Vision, 8779–8788, 2019.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>[22]</label>
      <mixed-citation publication-type="other">Tu, W.-C.; He, S.; Yang, Q.; Chien, S.-Y. Real-time salient object detection with a minimum spanning tree. In: Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2334–2342, 2016.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>[23]</label>
      <mixed-citation publication-type="other">Xia, C.; Li, J.; Chen, X.; Zheng, A.; Zhang, Y. What is and what is not a salient object? Learning salient object detector by ensembling linear exemplar regressors. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 4142–4150, 2017.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>[24]</label>
      <mixed-citation publication-type="other">Hou, X.; Zhang, L. Saliency detection: A spectral residual approach. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1–8, 2007.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>[25]</label>
      <mixed-citation publication-type="other">Yan, Q.; Xu, L.; Shi, J.; Jia, J. Hierarchical saliency detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1155–1162, 2013.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>[26]</label>
      <mixed-citation publication-type="other">Yang, C.; Zhang, L.; Lu, H.; Ruan, X.; Yang, M.-H. Saliency detection via graph-based manifold ranking. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3166–3173, 2013.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>[27]</label>
      <mixed-citation publication-type="other">Li, G.; Yu, Y. Deep contrast learning for salient object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 478–487, 2016.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>[28]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>D W</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>D Y</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>J W</given-names>
          </name>
        </person-group>
        <article-title>Co-saliency detection via a self-paced multiple-instance learning framework</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2017</year>
        <volume>39</volume>
        <issue>5</issue>
        <fpage>865</fpage>
        <lpage>878</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2016.2567393</pub-id>
        <pub-id pub-id-type="pmid">27187947</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>[29]</label>
      <mixed-citation publication-type="other">Zhang, P.; Wang, D.; Lu, H.; Wang, H.; Ruan, X. Amulet: Aggregating multi-level convolutional features for salient object detection. In: Proceedings of the IEEE International Conference on Computer Vision, 202–211, 2017.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>[30]</label>
      <mixed-citation publication-type="other">Zhang, P.; Wang, D.; Lu, H.; Wang, H.; Yin, B. Learning uncertain convolutional features for accurate saliency detection. In: Proceedings of the IEEE International Conference on Computer Vision, 212–221, 2017.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>[31]</label>
      <mixed-citation publication-type="other">Wang, T.; Borji, A.; Zhang, L.; Zhang, P.; Lu, H. A stagewise refinement model for detecting salient objects in images. In: Proceedings of the IEEE International Conference on Computer Vision, 4019–4028, 2017.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>[32]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>D G</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Ferrari</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Hebert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sminchisescu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Contour knowledge transfer for salient object detection</article-title>
        <source>Computer Vision — ECCV 2018. Lecture Notes in Computer Science, Vol. 11219</source>
        <year>2018</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>370</fpage>
        <lpage>385</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>[33]</label>
      <mixed-citation publication-type="other">Wang, W.; Zhao, S.; Shen, J.; Hoi, S. C.; Borji, A. Salient object detection with pyramid attention and salient edges. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1448–1457, 2019.</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>[34]</label>
      <mixed-citation publication-type="other">Su, J.; Li, J.; Zhang, Y.; Xia, C.; Tian, Y. Selectivity or invariance: Boundary-aware salient object detection. In: Proceedings of the IEEE International Conference on Computer Vision, 3799–3808, 2019.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>[35]</label>
      <mixed-citation publication-type="other">Zhao, T.; Wu, X. Pyramid feature attention network for saliency detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3085–3094, 2019.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>[36]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cong</surname>
            <given-names>R M</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C Q</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Q M</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>X C</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>C P</given-names>
          </name>
        </person-group>
        <article-title>Saliency detection for stereoscopic images based on depth confidence analysis and multiple cues fusion</article-title>
        <source>IEEE Signal Processing Letters</source>
        <year>2016</year>
        <volume>23</volume>
        <issue>6</issue>
        <fpage>819</fpage>
        <lpage>823</lpage>
        <pub-id pub-id-type="doi">10.1109/LSP.2016.2557347</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>[37]</label>
      <mixed-citation publication-type="other">Guo, J.; Ren, T.; Bei, J. Salient object detection for RGB-D image via saliency evolution. In: Proceedings of the IEEE International Conference on Multimedia and Expo, 1–6, 2016.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>[38]</label>
      <mixed-citation publication-type="other">Fan, D. P.; Lin, Z.; Zhang, Z.; Zhu, M. L.; Cheng, M. M. Rethinking RGB-D salient object detection: Models, data sets, and large-scale benchmarks. <italic>IEEE Transactions on Neural Networks and Learning Systems</italic> doi: 10.1109/TNNLS.2020.2996406, 2020.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>[39]</label>
      <mixed-citation publication-type="other">Zhang, M.; Ren, W.; Piao, Y.; Rong, Z.; Lu, H. Select, supplement and focus for RGB-D saliency detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 3469–3478, 2020.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>[40]</label>
      <mixed-citation publication-type="other">Piao, Y.; Rong, Z.; Zhang, M.; Ren, W.; Lu, H. A2dele: Adaptive and attentive depth distiller for efficient RGB-D salient object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 9057–9066, 2020.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>[41]</label>
      <mixed-citation publication-type="other">Liu, N.; Zhang, N.; Han, J. Learning selective self-mutual attention for RGB-D saliency detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2020.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>[42]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>G Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Ling</surname>
            <given-names>H B</given-names>
          </name>
        </person-group>
        <article-title>ICNet: Information conversion network for RGB-D based salient object detection</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2020</year>
        <volume>29</volume>
        <fpage>4873</fpage>
        <lpage>4884</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2020.2976689</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>[43]</label>
      <mixed-citation publication-type="other">Fu, K.; Fan, D.-P.; Ji, G.-P.; Zhao, Q. JL-DCF: Joint learning and densely-cooperative fusion framework for RGB-D salient object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3049–3059, 2020.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>[44]</label>
      <mixed-citation publication-type="other">Zhang, J.; Fan, D.-P.; Dai, Y.; Anwar, S.; Saleh, F. S.; Zhang, T.; Barnes, N. UC-Net: Uncertainty inspired RGB-D saliency detection via conditional variational autoencoders. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2020.</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>[45]</label>
      <mixed-citation publication-type="other">Chen, H.; Li, Y. F. CNN-based RGB-D salient object detection: Learn, select and fuse. <italic>arXiv preprint</italic> arXiv:1909.09309, 2019.</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>[46]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lang</surname>
            <given-names>C Y</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>T V</given-names>
          </name>
          <name>
            <surname>Katti</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yadati</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kankanhalli</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>S C</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Fitzgibbon</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lazebnik</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Perona</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Schmid</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Depth matters: influence of depth cues on visual saliency</article-title>
        <source>Computer Vision — ECCV 2012. Lecture Notes in Computer Science, Vol. 7573</source>
        <year>2012</year>
        <publisher-loc>Berlin Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>101</fpage>
        <lpage>115</lpage>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>[47]</label>
      <mixed-citation publication-type="other">Ciptadi, A.; Hermans, T.; Rehg, J. M. An in depth view of saliency. In: Proceedings of the 24th British Machine Vision Conference, 2013.</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>[48]</label>
      <mixed-citation publication-type="other">Desingh, K.; Madhava Krishna, K.; Rajan, D.; Jawahar, C. V. Depth really matters: Improving visual salient region detection with depth. In: Proceedings of the British Machine Vision Conference, 98.1–98.11, 2013.</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>[49]</label>
      <mixed-citation publication-type="other">Cheng, Y. P.; Fu, H. Z.; Wei, X. X.; Xiao, J. J.; Cao, X. C. Depth enhanced saliency detection method. In: Proceedings of the International Conference on Internet Multimedia Computing and Service, 23–27, 2014.</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>[50]</label>
      <mixed-citation publication-type="other">Ren, J.; Gong, X.; Yu, L.; Zhou, W.; Yang, M. Y. Exploiting global priors for RGB-D saliency detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 25–32, 2015.</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>[51]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>H W</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>W H</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>W M</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>R R</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Fleet</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Pajdla</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Schiele</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Tuytelaars</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>RGBD salient object detection: A benchmark and algorithms</article-title>
        <source>Computer Vision — ECCV 2014. Lecture Notes in Computer Science, Vol. 8691</source>
        <year>2014</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>92</fpage>
        <lpage>109</lpage>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>[52]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qu</surname>
            <given-names>L Q</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>S F</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J W</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>J D</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>Y D</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Q X</given-names>
          </name>
        </person-group>
        <article-title>RGBD salient object detection via deep fusion</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2017</year>
        <volume>26</volume>
        <issue>5</issue>
        <fpage>2274</fpage>
        <lpage>2285</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2017.2682981</pub-id>
        <pub-id pub-id-type="pmid">28320666</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>[53]</label>
      <mixed-citation publication-type="other">Zhao, J.-X.; Cao, Y.; Fan, D.-P.; Cheng, M.-M.; Li, X.-Y.; Zhang, L. Contrast prior and fluid pyramid integration for RGBD salient object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3927–3936, 2019.</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>[54]</label>
      <mixed-citation publication-type="other">Piao, Y.; Ji, W.; Li, J.; Zhang, M.; Lu, H. Depth-induced multi-scale recurrent attention network for saliency detection. In: Proceedings of the IEEE International Conference on Computer Vision, 7254–7263, 2019.</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>[55]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y F</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Multi-modal fusion network with multi-scale multi-path and cross-modal interactions for RGB-D salient object detection</article-title>
        <source>Pattern Recognition</source>
        <year>2019</year>
        <volume>86</volume>
        <fpage>376</fpage>
        <lpage>385</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2018.08.007</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>[56]</label>
      <mixed-citation publication-type="other">Ju, R.; Ge, L.; Geng, W.; Ren, T.; Wu, G. Depth saliency based on anisotropic center-surround difierence. In: Proceedings of the IEEE International Conference on Image Processing, 1115–1119, 2014.</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>[57]</label>
      <mixed-citation publication-type="other">Feng, D.; Barnes, N.; You, S.; McCarthy, C. Local background enclosure for RGB-D salient object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2343–2350, 2016.</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>[58]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Han</surname>
            <given-names>J W</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>C G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X L</given-names>
          </name>
        </person-group>
        <article-title>CNNs-based RGB-D saliency detection via cross-view transfer and multiview fusion</article-title>
        <source>IEEE Transactions on Cybernetics</source>
        <year>2018</year>
        <volume>48</volume>
        <issue>11</issue>
        <fpage>3171</fpage>
        <lpage>3183</lpage>
        <pub-id pub-id-type="doi">10.1109/TCYB.2017.2761775</pub-id>
        <pub-id pub-id-type="pmid">29990092</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <label>[59]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Borji</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>M M</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Salient object detection: A benchmark</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2015</year>
        <volume>24</volume>
        <issue>12</issue>
        <fpage>5706</fpage>
        <lpage>5722</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2015.2487833</pub-id>
        <pub-id pub-id-type="pmid">26452281</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <label>[60]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cong</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>M-M</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Review of visual saliency detection with comprehensive information</article-title>
        <source>IEEE Transactions on Circuits and Systems for Video Technology</source>
        <year>2018</year>
        <volume>29</volume>
        <issue>10</issue>
        <fpage>2941</fpage>
        <lpage>2959</lpage>
        <pub-id pub-id-type="doi">10.1109/TCSVT.2018.2870832</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <label>[61]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Borji</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>A review of co-saliency detection algorithms: Fundamentals, applications, and challenges</article-title>
        <source>ACM Transactions on Intelligent Systems and Technology</source>
        <year>2018</year>
        <volume>9</volume>
        <issue>4</issue>
        <fpage>1</fpage>
        <lpage>31</lpage>
        <pub-id pub-id-type="doi">10.1145/3158674</pub-id>
      </element-citation>
    </ref>
    <ref id="CR62">
      <label>[62]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Han</surname>
            <given-names>J W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D W</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Advanced deep-learning techniques for salient and category-specific object detection: A survey</article-title>
        <source>IEEE Signal Processing Magazine</source>
        <year>2018</year>
        <volume>35</volume>
        <issue>1</issue>
        <fpage>84</fpage>
        <lpage>100</lpage>
        <pub-id pub-id-type="doi">10.1109/MSP.2017.2749125</pub-id>
      </element-citation>
    </ref>
    <ref id="CR63">
      <label>[63]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>T V</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>S C</given-names>
          </name>
        </person-group>
        <article-title>Attentive systems: A survey</article-title>
        <source>International Journal of Computer Vision</source>
        <year>2018</year>
        <volume>126</volume>
        <issue>1</issue>
        <fpage>86</fpage>
        <lpage>110</lpage>
        <pub-id pub-id-type="doi">10.1007/s11263-017-1042-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR64">
      <label>[64]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Borji</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>M M</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>Q B</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Salient object detection: A survey</article-title>
        <source>Computational Visual Media</source>
        <year>2019</year>
        <volume>5</volume>
        <issue>2</issue>
        <fpage>117</fpage>
        <lpage>150</lpage>
        <pub-id pub-id-type="doi">10.1007/s41095-019-0149-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR65">
      <label>[65]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>Z Q</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S T</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>X D</given-names>
          </name>
        </person-group>
        <article-title>Object detection with deep learning: A review</article-title>
        <source>IEEE Transactions on Neural Networks and Learning Systems</source>
        <year>2019</year>
        <volume>30</volume>
        <issue>11</issue>
        <fpage>3212</fpage>
        <lpage>3232</lpage>
        <pub-id pub-id-type="doi">10.1109/TNNLS.2018.2876865</pub-id>
        <pub-id pub-id-type="pmid">30703038</pub-id>
      </element-citation>
    </ref>
    <ref id="CR66">
      <label>[66]</label>
      <mixed-citation publication-type="other">Wang, W. G.; Lai, Q. X.; Fu, H. Z.; Shen, J. B.; Ling, H. B.; Yang, R. G. Salient object detection in the deep learning era: An in-depth survey. <italic>arXiv preprint</italic> arXiv:1904.09146, 2019.</mixed-citation>
    </ref>
    <ref id="CR67">
      <label>[67]</label>
      <mixed-citation publication-type="other">Zhang, H.; Lei, J.; Fan, X.; Wu, M.; Zhang, P.; Bu, S. Depth combined saliency detection based on region contrast model. In: Proceedings of International Conference on Computer Science &amp; Education, 763–766, 2012.</mixed-citation>
    </ref>
    <ref id="CR68">
      <label>[68]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lei</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>H L</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>C P</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L H</given-names>
          </name>
        </person-group>
        <article-title>Evaluation and modeling of depth feature incorporated visual attention for salient object segmentation</article-title>
        <source>Neurocomputing</source>
        <year>2013</year>
        <volume>120</volume>
        <fpage>24</fpage>
        <lpage>33</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2012.08.057</pub-id>
      </element-citation>
    </ref>
    <ref id="CR69">
      <label>[69]</label>
      <mixed-citation publication-type="other">Fan, X.; Liu, Z.; Sun, G. Salient region detection for stereoscopic images. In: Proceedings of the International Conference on Digital Signal Processing, 454–458, 2014.</mixed-citation>
    </ref>
    <ref id="CR70">
      <label>[70]</label>
      <mixed-citation publication-type="other">Guo, J. F.; Ren, T. W.; Bei, J.; Zhu, Y. J. Salient object detection in RGB-D image based on saliency fusion and propagation. In: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, Article No. 59, 2015.</mixed-citation>
    </ref>
    <ref id="CR71">
      <label>[71]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>Y L</given-names>
          </name>
          <name>
            <surname>Tong</surname>
            <given-names>R F</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Depth incorporating with color improves salient object detection</article-title>
        <source>The Visual Computer</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>1</issue>
        <fpage>111</fpage>
        <lpage>121</lpage>
        <pub-id pub-id-type="doi">10.1007/s00371-014-1059-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR72">
      <label>[72]</label>
      <mixed-citation publication-type="other">Jiang, L.; Koch, A.; Zell, A. Salient regions detection for indoor robots using RGB-D data. In: Proceedings of the IEEE International Conference on Robotics and Automation, 1323–1328, 2015.</mixed-citation>
    </ref>
    <ref id="CR73">
      <label>[73]</label>
      <mixed-citation publication-type="other">Xue, H.; Gu, Y.; Li, Y.; Yang, J. RGB-D saliency detection via mutual guided manifold ranking. In: Proceedings of IEEE International Conference on Image Processing, 666–670, 2015.</mixed-citation>
    </ref>
    <ref id="CR74">
      <label>[74]</label>
      <mixed-citation publication-type="other">Zhu, L.; Cao, Z.; Fang, Z.; Xiao, Y.; Wu, J.; Deng, H.; Liu, J. Selective features for RGB-D saliency. In: Proceedings of Chinese Automation Congress, 512–517, 2015.</mixed-citation>
    </ref>
    <ref id="CR75">
      <label>[75]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Du</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>H K</given-names>
          </name>
          <name>
            <surname>Mei</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Improving RGBD saliency detection using progressive region classification and saliency fusion</article-title>
        <source>IEEE Access</source>
        <year>2016</year>
        <volume>4</volume>
        <fpage>8987</fpage>
        <lpage>8994</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2016.2632724</pub-id>
      </element-citation>
    </ref>
    <ref id="CR76">
      <label>[76]</label>
      <mixed-citation publication-type="other">Wang, S.-T.; Zhou, Z.; Qu, H.-B.; Li, B. RGBD saliency detection under bayesian framework. In: Proceedings of the 23rd International Conference on Pattern Recognition, 1881–1886, 2016.</mixed-citation>
    </ref>
    <ref id="CR77">
      <label>[77]</label>
      <mixed-citation publication-type="other">Sheng, H.; Liu, X.; Zhang, S. Saliency analysis based on depth contrast increased. In: Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, 1347–1351, 2016.</mixed-citation>
    </ref>
    <ref id="CR78">
      <label>[78]</label>
      <mixed-citation publication-type="other">Song, H.; Liu, Z.; Du, H.; Sun, G. Depth-aware saliency detection using discriminative saliency fusion. In: Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, 1626–1630, 2016.</mixed-citation>
    </ref>
    <ref id="CR79">
      <label>[79]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S T</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Qu</surname>
            <given-names>H B</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Lai</surname>
            <given-names>S H</given-names>
          </name>
          <name>
            <surname>Lepetit</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Nishino</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Visual saliency detection for RGB-D images with generative model</article-title>
        <source>Computer Vision — ACCV 2016. Lecture Notes in Computer Science, Vol. 10115</source>
        <year>2017</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>20</fpage>
        <lpage>35</lpage>
      </element-citation>
    </ref>
    <ref id="CR80">
      <label>[80]</label>
      <mixed-citation publication-type="other">Feng, D.; Barnes, N.; You, S. HOSO: Histogram of surface orientation for RGB-D salient object detection. In Proceedings of the International Conference on Digital Image Computing: Techniques and Applications, 1–8, 2017.</mixed-citation>
    </ref>
    <ref id="CR81">
      <label>[81]</label>
      <mixed-citation publication-type="other">Chen, H.; Li, Y.-F.; Su, D. M<sup>3</sup>Net: Multi-scale multi-path multi-modal fusion network and example application to RGB-D salient object detection. In: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, 4911–4916, 2017.</mixed-citation>
    </ref>
    <ref id="CR82">
      <label>[82]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y F</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Liu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Vincze</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>RGB-D saliency detection by multi-stream late fusion network</article-title>
        <source>Computer Vision Systems. Lecture Notes in Computer Science, Vol. 10528</source>
        <year>2017</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>459</fpage>
        <lpage>468</lpage>
      </element-citation>
    </ref>
    <ref id="CR83">
      <label>[83]</label>
      <mixed-citation publication-type="other">Shigematsu, R.; Feng, D.; You, S.; Barnes, N. Learning RGB-D salient object detection using background enclosure, depth contrast, and top-down features. In: Proceedings of the IEEE International Conference on Computer Vision Workshops, 2749–2757, 2017.</mixed-citation>
    </ref>
    <ref id="CR84">
      <label>[84]</label>
      <mixed-citation publication-type="other">Zhu, C.; Li, G.; Wang, W.; Wang, R. An innovative salient object detection using center-dark channel prior. In: Proceedings of the IEEE International Conference on Computer Vision Workshops, 1509–1515, 2017.</mixed-citation>
    </ref>
    <ref id="CR85">
      <label>[85]</label>
      <mixed-citation publication-type="other">Zhu, C.; Li, G. A three-pathway psychobiological framework of salient object detection using stereoscopic technology. In: Proceedings of the IEEE International Conference on Computer Vision Workshops, 3008–3014, 2017.</mixed-citation>
    </ref>
    <ref id="CR86">
      <label>[86]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>A Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M H</given-names>
          </name>
        </person-group>
        <article-title>RGB-D salient object detection via minimum barrier distance transform and saliency fusion</article-title>
        <source>IEEE Signal Processing Letters</source>
        <year>2017</year>
        <volume>24</volume>
        <issue>5</issue>
        <fpage>663</fpage>
        <lpage>667</lpage>
        <pub-id pub-id-type="doi">10.1109/LSP.2017.2688136</pub-id>
      </element-citation>
    </ref>
    <ref id="CR87">
      <label>[87]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>H K</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>G L</given-names>
          </name>
          <name>
            <surname>Le Meur</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>T W</given-names>
          </name>
        </person-group>
        <article-title>Depth-aware salient object detection and segmentation via multiscale discriminative saliency fusion and bootstrap learning</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2017</year>
        <volume>26</volume>
        <issue>9</issue>
        <fpage>4204</fpage>
        <lpage>4216</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2017.2711277</pub-id>
        <pub-id pub-id-type="pmid">28650800</pub-id>
      </element-citation>
    </ref>
    <ref id="CR88">
      <label>[88]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cong</surname>
            <given-names>R M</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>W S</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Q M</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>X C</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>C P</given-names>
          </name>
        </person-group>
        <article-title>An iterative co-saliency framework for RGBD images</article-title>
        <source>IEEE Transactions on Cybernetics</source>
        <year>2019</year>
        <volume>49</volume>
        <issue>1</issue>
        <fpage>233</fpage>
        <lpage>246</lpage>
        <pub-id pub-id-type="doi">10.1109/TCYB.2017.2771488</pub-id>
        <pub-id pub-id-type="pmid">29990261</pub-id>
      </element-citation>
    </ref>
    <ref id="CR89">
      <label>[89]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Imamoglu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Shimoda</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>Y M</given-names>
          </name>
          <name>
            <surname>Kanezaki</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yanai</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Nishida</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>An integration of bottom-up and top-down salient cues on RGB-D data: Saliency from objectness versus non-objectness</article-title>
        <source>Signal, Image and Video Processing</source>
        <year>2018</year>
        <volume>12</volume>
        <issue>2</issue>
        <fpage>307</fpage>
        <lpage>314</lpage>
        <pub-id pub-id-type="doi">10.1007/s11760-017-1159-7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR90">
      <label>[90]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cong</surname>
            <given-names>R M</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Q M</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>X C</given-names>
          </name>
          <name>
            <surname>Ling</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>HSCS: Hierarchical sparsity based Co-saliency detection for RGBD images</article-title>
        <source>IEEE Transactions on Multimedia</source>
        <year>2019</year>
        <volume>21</volume>
        <issue>7</issue>
        <fpage>1660</fpage>
        <lpage>1671</lpage>
        <pub-id pub-id-type="doi">10.1109/TMM.2018.2884481</pub-id>
      </element-citation>
    </ref>
    <ref id="CR91">
      <label>[91]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cong</surname>
            <given-names>R M</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Q M</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>X C</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>C P</given-names>
          </name>
        </person-group>
        <article-title>Co-saliency detection for RGBD images based on multi-constraint feature matching and cross label propagation</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2018</year>
        <volume>27</volume>
        <issue>2</issue>
        <fpage>568</fpage>
        <lpage>579</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2017.2763819</pub-id>
        <pub-id pub-id-type="pmid">29053455</pub-id>
      </element-citation>
    </ref>
    <ref id="CR92">
      <label>[92]</label>
      <mixed-citation publication-type="other">Chen, H.; Li, Y. Progressively complementarity-aware fusion network for RGB-D salient object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3051–3060, 2018.</mixed-citation>
    </ref>
    <ref id="CR93">
      <label>[93]</label>
      <mixed-citation publication-type="other">Huang, P.; Shen, C.-H.; Hsiao, H.-F. RGBD salient object detection using spatially coherent deep learning framework. In: Proceedings of the IEEE International Conference on Digital Signal Processing, 1–5, 2018.</mixed-citation>
    </ref>
    <ref id="CR94">
      <label>[94]</label>
      <mixed-citation publication-type="other">Chen, H.; Li, Y.-F.; Su, D. Attention-aware crossmodal cross-level fusion network for RGB-D salient object detection. In: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, 6821–6826, 2018.</mixed-citation>
    </ref>
    <ref id="CR95">
      <label>[95]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>F F</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>L J</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Qiao</surname>
            <given-names>Y H</given-names>
          </name>
          <name>
            <surname>Cai</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Qing</surname>
            <given-names>L Y</given-names>
          </name>
        </person-group>
        <article-title>Stereoscopic saliency model using contrast and depth-guided-background prior</article-title>
        <source>Neurocomputing</source>
        <year>2018</year>
        <volume>275</volume>
        <fpage>2227</fpage>
        <lpage>2238</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2017.10.052</pub-id>
      </element-citation>
    </ref>
    <ref id="CR96">
      <label>[96]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Z Y</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Q T</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Salient object detection for RGB-D image by single stream recurrent convolution neural network</article-title>
        <source>Neurocomputing</source>
        <year>2019</year>
        <volume>363</volume>
        <fpage>46</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2019.07.012</pub-id>
      </element-citation>
    </ref>
    <ref id="CR97">
      <label>[97]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z Z</given-names>
          </name>
        </person-group>
        <article-title>RGB-D salient object detection by a CNN with multiple layers fusion</article-title>
        <source>IEEE Signal Processing Letters</source>
        <year>2019</year>
        <volume>26</volume>
        <issue>4</issue>
        <fpage>552</fpage>
        <lpage>556</lpage>
        <pub-id pub-id-type="doi">10.1109/LSP.2019.2898508</pub-id>
      </element-citation>
    </ref>
    <ref id="CR98">
      <label>[98]</label>
      <mixed-citation publication-type="other">Liu, D.; Hu, Y.; Zhang, K.; Chen, Z. Two-stream refinement network for RGB-D saliency detection. In: Proceedings of IEEE International Conference on Image Processing, 3925–3929, 2019.</mixed-citation>
    </ref>
    <ref id="CR99">
      <label>[99]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Du</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Salient object segmentation based on depth-aware image layering</article-title>
        <source>Multimedia Tools and Applications</source>
        <year>2019</year>
        <volume>78</volume>
        <issue>9</issue>
        <fpage>12125</fpage>
        <lpage>12138</lpage>
        <pub-id pub-id-type="doi">10.1007/s11042-018-6736-4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR100">
      <label>[100]</label>
      <mixed-citation publication-type="other">Zhou, W. J.; Lv, Y., Lei, J. S.; Yu, L. Global and local-contrast guides content-aware fusion for RGB-D saliency prediction. <italic>IEEE Transactions on Systems, Man, and Cybernetics: Systems</italic> doi: 10.1109/TSMC.2019.2957386, 2019.</mixed-citation>
    </ref>
    <ref id="CR101">
      <label>[101]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>C Y</given-names>
          </name>
          <name>
            <surname>Hang</surname>
            <given-names>H M</given-names>
          </name>
        </person-group>
        <article-title>Learning-based saliency model with depth information</article-title>
        <source>Journal of Vision</source>
        <year>2015</year>
        <volume>15</volume>
        <issue>6</issue>
        <fpage>19</fpage>
        <pub-id pub-id-type="doi">10.1167/15.6.19</pub-id>
      </element-citation>
    </ref>
    <ref id="CR102">
      <label>[102]</label>
      <mixed-citation publication-type="other">Zhu, C.; Cai, X.; Huang, K.; Li, T. H.; Li, G. PDNet: Prior-model guided depth-enhanced network for salient object detection. In: Proceedings of the IEEE International Conference on Multimedia and Expo, 199–204, 2019.</mixed-citation>
    </ref>
    <ref id="CR103">
      <label>[103]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y F</given-names>
          </name>
        </person-group>
        <article-title>Three-stream attention-aware network for RGB-D salient object detection</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2019</year>
        <volume>28</volume>
        <issue>6</issue>
        <fpage>2825</fpage>
        <lpage>2835</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2019.2891104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR104">
      <label>[104]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y F</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Discriminative cross-modal transfer learning and densely cross-level feedback fusion for RGB-D salient object detection</article-title>
        <source>IEEE Transactions on Cybernetics</source>
        <year>2020</year>
        <volume>50</volume>
        <issue>11</issue>
        <fpage>4808</fpage>
        <lpage>4820</lpage>
        <pub-id pub-id-type="doi">10.1109/TCYB.2019.2934986</pub-id>
        <pub-id pub-id-type="pmid">31484153</pub-id>
      </element-citation>
    </ref>
    <ref id="CR105">
      <label>[105]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cong</surname>
            <given-names>R M</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J H</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Q M</given-names>
          </name>
          <name>
            <surname>Kwong</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Going from RGB to RGBD saliency: A depth-guided transformation model</article-title>
        <source>IEEE Transactions on Cybernetics</source>
        <year>2020</year>
        <volume>50</volume>
        <issue>8</issue>
        <fpage>3627</fpage>
        <lpage>3639</lpage>
        <pub-id pub-id-type="doi">10.1109/TCYB.2019.2932005</pub-id>
        <pub-id pub-id-type="pmid">31443060</pub-id>
      </element-citation>
    </ref>
    <ref id="CR106">
      <label>[106]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>N N</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>X J</given-names>
          </name>
        </person-group>
        <article-title>Adaptive fusion for RGB-D salient object detection</article-title>
        <source>IEEE Access</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>55277</fpage>
        <lpage>55284</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2019.2913107</pub-id>
      </element-citation>
    </ref>
    <ref id="CR107">
      <label>[107]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jin</surname>
            <given-names>Z G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J K</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Co-saliency detection for RGBD images based on effective propagation mechanism</article-title>
        <source>IEEE Access</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>141311</fpage>
        <lpage>141318</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2019.2943899</pub-id>
      </element-citation>
    </ref>
    <ref id="CR108">
      <label>[108]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>M K</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X Y</given-names>
          </name>
        </person-group>
        <article-title>Depth-aware saliency detection using convolutional neural networks</article-title>
        <source>Journal of Visual Communication and Image Representation</source>
        <year>2019</year>
        <volume>61</volume>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jvcir.2019.03.019</pub-id>
      </element-citation>
    </ref>
    <ref id="CR109">
      <label>[109]</label>
      <mixed-citation publication-type="other">Chen, Z.; Huang, Q. Depth potentiality-aware gated attention network for RGB-D salient object detection. <italic>arXiv preprint</italic> arXiv:2003.08608, 2020.</mixed-citation>
    </ref>
    <ref id="CR110">
      <label>[110]</label>
      <mixed-citation publication-type="other">Wang, Y.; Li, Y. K.; Elder, J. H.; Lu, H. C.; Wu, R. M.; Zhang, L. Synergistic saliency and depth prediction for RGB-D saliency detection. <italic>arXiv preprint</italic> arXiv:2007.01711, 2020.</mixed-citation>
    </ref>
    <ref id="CR111">
      <label>[111]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>X F</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>G Y</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J Y</given-names>
          </name>
        </person-group>
        <article-title>Attention-guided RGBD saliency detection using appearance information</article-title>
        <source>Image and Vision Computing</source>
        <year>2020</year>
        <volume>95</volume>
        <fpage>103888</fpage>
        <pub-id pub-id-type="doi">10.1016/j.imavis.2020.103888</pub-id>
      </element-citation>
    </ref>
    <ref id="CR112">
      <label>[112]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Z Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>A cross-modal adaptive gated fusion generative adversarial network for RGB-D salient object detection</article-title>
        <source>Neurocomputing</source>
        <year>2020</year>
        <volume>387</volume>
        <fpage>210</fpage>
        <lpage>220</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2020.01.045</pub-id>
      </element-citation>
    </ref>
    <ref id="CR113">
      <label>[113]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>F F</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>L J</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Qiao</surname>
            <given-names>Y H</given-names>
          </name>
          <name>
            <surname>Cai</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Miao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>CoCNN: RGB-D deep fusion for stereoscopic salient object detection</article-title>
        <source>Pattern Recognition</source>
        <year>2020</year>
        <volume>104</volume>
        <fpage>107329</fpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2020.107329</pub-id>
      </element-citation>
    </ref>
    <ref id="CR114">
      <label>[114]</label>
      <mixed-citation publication-type="other">Jiang, B.; Zhou, Z. T.; Wang, X.; Tang, J.; Luo, B. cmSalGAN: RGB-D salient object detection with cross-view generative adversarial networks. <italic>IEEE Transactions on Multimedia</italic> doi: 10.1109/TMM.2020.2997184, 2020.</mixed-citation>
    </ref>
    <ref id="CR115">
      <label>[115]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Y M</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>C H</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>X P</given-names>
          </name>
        </person-group>
        <article-title>Multi-modal weights sharing and hierarchical feature fusion for RGBD salient object detection</article-title>
        <source>IEEE Access</source>
        <year>2020</year>
        <volume>8</volume>
        <fpage>26602</fpage>
        <lpage>26611</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2020.2971509</pub-id>
      </element-citation>
    </ref>
    <ref id="CR116">
      <label>[116]</label>
      <mixed-citation publication-type="other">Zhang, Z.; Lin, Z.; Xu, J.; Jin, W. D.; Lu, S. P.; Fan, D. P. Bilateral attention network for RGB-D salient object detection. <italic>arXiv preprint</italic> arXiv:2004.14582, 2020.</mixed-citation>
    </ref>
    <ref id="CR117">
      <label>[117]</label>
      <mixed-citation publication-type="other">Li, C. Y.; Cong, R. M.; Kwong, S.; Hou, J. H.; Fu, H. Z.; Zhu, G. P.; Zhang, D.; Huang, Q. ASIF-Net: Attention steered interweave fusion network for RGB-D salient object detection. <italic>IEEE Transactions on Cybernetics</italic> doi: 10.1109/TCYB.2020.2969255, 2020.</mixed-citation>
    </ref>
    <ref id="CR118">
      <label>[118]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>Y B</given-names>
          </name>
        </person-group>
        <article-title>Triple-complementary network for RGB-D salient object detection</article-title>
        <source>IEEE Signal Processing Letters</source>
        <year>2020</year>
        <volume>27</volume>
        <fpage>775</fpage>
        <lpage>779</lpage>
        <pub-id pub-id-type="doi">10.1109/LSP.2020.2989674</pub-id>
      </element-citation>
    </ref>
    <ref id="CR119">
      <label>[119]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>J P</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W Z</given-names>
          </name>
          <name>
            <surname>Qin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Improved saliency detection in RGB-D images using two-phase depth estimation and selective deep fusion</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2020</year>
        <volume>29</volume>
        <fpage>4296</fpage>
        <lpage>4307</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2020.2968250</pub-id>
      </element-citation>
    </ref>
    <ref id="CR120">
      <label>[120]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>W J</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y Z</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>GFNet: Gate fusion network with Res2Net for detecting salient objects in RGB-D images</article-title>
        <source>IEEE Signal Processing Letters</source>
        <year>2020</year>
        <volume>27</volume>
        <fpage>800</fpage>
        <lpage>804</lpage>
        <pub-id pub-id-type="doi">10.1109/LSP.2020.2993471</pub-id>
      </element-citation>
    </ref>
    <ref id="CR121">
      <label>[121]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Z Y</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J T</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Salient object detection for RGB-D images by generative adversarial network</article-title>
        <source>Multimedia Tools and Applications</source>
        <year>2020</year>
        <volume>79</volume>
        <issue>35–36</issue>
        <fpage>25403</fpage>
        <lpage>25425</lpage>
        <pub-id pub-id-type="doi">10.1007/s11042-020-09188-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR122">
      <label>[122]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>G Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>L W</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ling</surname>
            <given-names>H B</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>Cross-modal weighting network for RGB-D salient object detection</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12362</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>665</fpage>
        <lpage>681</lpage>
      </element-citation>
    </ref>
    <ref id="CR123">
      <label>[123]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pang</surname>
            <given-names>Y W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L H</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>X Q</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>Hierarchical dynamic filtering network for RGB-D salient object detection</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12370</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>235</fpage>
        <lpage>252</lpage>
      </element-citation>
    </ref>
    <ref id="CR124">
      <label>[124]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jiao</surname>
            <given-names>Z C</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lyu</surname>
            <given-names>S W</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>Cascade graph neural networks for RGB-D salient object detection</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12357</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>346</fpage>
        <lpage>364</lpage>
      </element-citation>
    </ref>
    <ref id="CR125">
      <label>[125]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>C Y</given-names>
          </name>
          <name>
            <surname>Cong</surname>
            <given-names>R M</given-names>
          </name>
          <name>
            <surname>Piao</surname>
            <given-names>Y R</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Q Q</given-names>
          </name>
          <name>
            <surname>Loy</surname>
            <given-names>C C</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>RGB-D salient object detection with cross-modality modulation and selection</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12353</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>225</fpage>
        <lpage>241</lpage>
      </element-citation>
    </ref>
    <ref id="CR126">
      <label>[126]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>X Q</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L H</given-names>
          </name>
          <name>
            <surname>Pang</surname>
            <given-names>Y W</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>A single stream network for robust and realtime RGB-D salient object detection</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12367</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>646</fpage>
        <lpage>662</lpage>
      </element-citation>
    </ref>
    <ref id="CR127">
      <label>[127]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ji</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Piao</surname>
            <given-names>Y R</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>Accurate RGB-D salient object detection via collaborative learning</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12363</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>52</fpage>
        <lpage>69</lpage>
      </element-citation>
    </ref>
    <ref id="CR128">
      <label>[128]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Fan</surname>
            <given-names>D P</given-names>
          </name>
          <name>
            <surname>Zhai</surname>
            <given-names>Y J</given-names>
          </name>
          <name>
            <surname>Borji</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>J F</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>BBS-Net: RGB-D salient object detection with a bifurcated backbone strategy network</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12357</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>275</fpage>
        <lpage>292</lpage>
      </element-citation>
    </ref>
    <ref id="CR129">
      <label>[129]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fei</surname>
            <given-names>S X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Piao</surname>
            <given-names>Y R</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>Asymmetric two-stream architecture for accurate RGB-D saliency detection</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12373</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>374</fpage>
        <lpage>390</lpage>
      </element-citation>
    </ref>
    <ref id="CR130">
      <label>[130]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>S H</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Vedaldi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Brox</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Frahm</surname>
            <given-names>J M</given-names>
          </name>
        </person-group>
        <article-title>Progressively guided alternate refinement network for RGB-D salient object detection</article-title>
        <source>Computer Vision — ECCV 2020. Lecture Notes in Computer Science, Vol. 12353</source>
        <year>2020</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>520</fpage>
        <lpage>538</lpage>
      </element-citation>
    </ref>
    <ref id="CR131">
      <label>[131]</label>
      <mixed-citation publication-type="other">Huang, Z.; Chen, H. X.; Zhou, T.; Yang, Y. Z.; Wang, C. Y. Multi-level cross-modal interaction network for RGB-D salient object detection. <italic>arXiv preprint</italic> arXiv:2007.14352, 2020.</mixed-citation>
    </ref>
    <ref id="CR132">
      <label>[132]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>Y M</given-names>
          </name>
          <name>
            <surname>Hao</surname>
            <given-names>A M</given-names>
          </name>
          <name>
            <surname>Qin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Data-level recombination and lightweight fusion scheme for RGB-D salient object detection</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2021</year>
        <volume>30</volume>
        <fpage>458</fpage>
        <lpage>471</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2020.3037470</pub-id>
        <pub-id pub-id-type="pmid">33201813</pub-id>
      </element-citation>
    </ref>
    <ref id="CR133">
      <label>[133]</label>
      <mixed-citation publication-type="other">Wang, X.; Li, S.; Chen, C.; Hao, A.; Qin, H. Knowing depth quality in advance: A depth quality assessment method for RGB-D salient object detection. <italic>arXiv preprint</italic> arXiv:2008.04157, 2020.</mixed-citation>
    </ref>
    <ref id="CR134">
      <label>[134]</label>
      <mixed-citation publication-type="other">Chen, C.; Wei, J.; Peng, C.; Qin, H. Depth quality aware salient object detection. <italic>arXiv preprint</italic> arXiv:2008.04159, 2020.</mixed-citation>
    </ref>
    <ref id="CR135">
      <label>[135]</label>
      <mixed-citation publication-type="other">Zhao, J. W.; Zhao, Y. F.; Li, J.; Chen, X. W. Is depth really necessary for salient object detection. <italic>arXiv preprint</italic> arXiv:2006.00269, 2020.</mixed-citation>
    </ref>
    <ref id="CR136">
      <label>[136]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>Y J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y F</given-names>
          </name>
          <name>
            <surname>Hung</surname>
            <given-names>T Y</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>G S</given-names>
          </name>
        </person-group>
        <article-title>RGBD salient object detection via disentangled cross-modal fusion</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2020</year>
        <volume>29</volume>
        <fpage>8407</fpage>
        <lpage>8416</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2020.3014734</pub-id>
      </element-citation>
    </ref>
    <ref id="CR137">
      <label>[137]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Piao</surname>
            <given-names>Y R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>J Y</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
        </person-group>
        <article-title>Saliency detection via depth-induced cellular automata on light field</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2020</year>
        <volume>29</volume>
        <fpage>1879</fpage>
        <lpage>1889</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2019.2942434</pub-id>
      </element-citation>
    </ref>
    <ref id="CR138">
      <label>[138]</label>
      <mixed-citation publication-type="other">Zhang, M.; Zhang, Y.; Piao, Y. R.; Hu, B. Q.; Lu, H. C. Feature reintegration over differential treatment: A top-down and adaptive fusion network for RGB-D salient object detection. In: Proceedings of the 28th ACM International Conference on Multimedia, 4107–4115, 2020.</mixed-citation>
    </ref>
    <ref id="CR139">
      <label>[139]</label>
      <mixed-citation publication-type="other">Niu, Y.; Geng, Y.; Li, X.; Liu, F. Leveraging stereopsis for saliency analysis. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 454–461, 2012.</mixed-citation>
    </ref>
    <ref id="CR140">
      <label>[140]</label>
      <mixed-citation publication-type="other">Li, N.; Ye, J.; Ji, Y.; Ling, H.; Yu, J. Saliency detection on light field. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2806–2813, 2014.</mixed-citation>
    </ref>
    <ref id="CR141">
      <label>[141]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Piao</surname>
            <given-names>Y R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>LFNet: Light field fusion network for salient object detection</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2020</year>
        <volume>29</volume>
        <fpage>6276</fpage>
        <lpage>6287</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2020.2990341</pub-id>
      </element-citation>
    </ref>
    <ref id="CR142">
      <label>[142]</label>
      <mixed-citation publication-type="other">Li, N.; Sun, B.; Yu, J. A weighted sparse coding framework for saliency detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 5216–5223, 2015.</mixed-citation>
    </ref>
    <ref id="CR143">
      <label>[143]</label>
      <mixed-citation publication-type="other">Zhang, J.; Wang, M.; Gao, J.; Wang, Y.; Zhang, X.; Wu, X. Saliency detection with a deeper investigation of light field. In: Proceedings of the International Joint Conference on Artificial Intelligence, 2212–2218, 2015.</mixed-citation>
    </ref>
    <ref id="CR144">
      <label>[144]</label>
      <mixed-citation publication-type="other">Sheng, H.; Zhang, S.; Liu, X.; Xiong, Z. Relative location for light field saliency detection. In: Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing, 1631–1635, 2016.</mixed-citation>
    </ref>
    <ref id="CR145">
      <label>[145]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rui</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Saliency detection on light field</article-title>
        <source>ACM Transactions on Multimedia Computing, Communications, and Applications</source>
        <year>2017</year>
        <volume>13</volume>
        <issue>3</issue>
        <fpage>1</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="doi">10.1145/3107956</pub-id>
      </element-citation>
    </ref>
    <ref id="CR146">
      <label>[146]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>A Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X Y</given-names>
          </name>
          <name>
            <surname>Mi</surname>
            <given-names>Z T</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>A two-stage Bayesian integration framework for salient object detection on light field</article-title>
        <source>Neural Processing Letters</source>
        <year>2017</year>
        <volume>46</volume>
        <issue>3</issue>
        <fpage>1083</fpage>
        <lpage>1094</lpage>
        <pub-id pub-id-type="doi">10.1007/s11063-017-9610-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR147">
      <label>[147]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>N Y</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>J W</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ling</surname>
            <given-names>H B</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>J Y</given-names>
          </name>
        </person-group>
        <article-title>Saliency detection on light field</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2017</year>
        <volume>39</volume>
        <issue>8</issue>
        <fpage>1605</fpage>
        <lpage>1616</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2016.2610425</pub-id>
        <pub-id pub-id-type="pmid">27654139</pub-id>
      </element-citation>
    </ref>
    <ref id="CR148">
      <label>[148]</label>
      <mixed-citation publication-type="other">Li, C.; Zhan, B.; Zhang, S.; Sheng, H. Saliency detection with relative location measure in light field image. In: Proceedings of the International Conference on Image, Vision and Computing, 8–12, 2017.</mixed-citation>
    </ref>
    <ref id="CR149">
      <label>[149]</label>
      <mixed-citation publication-type="other">Wang, S.; Liao, W.; Surman, P.; Tu, Z.; Zheng, Y.; Yuan, J. Salience guided depth calibration for perceptually optimized compressive light field 3D display. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2031–2040, 2018.</mixed-citation>
    </ref>
    <ref id="CR150">
      <label>[150]</label>
      <mixed-citation publication-type="other">Piao, Y. R.; Li, X.; Zhang, M. Depth-induced cellular automata for light field saliency. In: Proceedings of the Frontiers in Optics/Laser Science, OSA Technical Digest, FTh3E.3, 2018.</mixed-citation>
    </ref>
    <ref id="CR151">
      <label>[151]</label>
      <mixed-citation publication-type="other">Wang, T.; Piao, Y.; Li, X.; Zhang, L.; Lu, H. Deep learning for light field saliency detection. In: Proceedings of the IEEE International Conference on Computer Vision, 8838–8848, 2019.</mixed-citation>
    </ref>
    <ref id="CR152">
      <label>[152]</label>
      <mixed-citation publication-type="other">Piao, Y. R.; Rong, Z. K.; Zhang, M.; Li, X.; Lu, H. C. Deep light-field-driven saliency detection from a single view. In: Proceedings of the 28th International Joint Conference on Artificial Intelligence, 904–911, 2019.</mixed-citation>
    </ref>
    <ref id="CR153">
      <label>[153]</label>
      <mixed-citation publication-type="other">Zhang, M.; Li, J.; WEI, J.; Piao, Y.; Lu, H. Memory-oriented decoder for light field salient object detection. In: Proceedings of the International Conference on Neural Information Processing Systems, 896–906, 2019.</mixed-citation>
    </ref>
    <ref id="CR154">
      <label>[154]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Piao</surname>
            <given-names>Y R</given-names>
          </name>
          <name>
            <surname>Rong</surname>
            <given-names>Z K</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
        </person-group>
        <article-title>Exploit and replace: An asymmetrical two-stream architecture for versatile light field saliency detection</article-title>
        <source>Proceedings of the AAAI Conference on Artificial Intelligence</source>
        <year>2020</year>
        <volume>34</volume>
        <issue>7</issue>
        <fpage>11865</fpage>
        <lpage>11873</lpage>
        <pub-id pub-id-type="doi">10.1609/aaai.v34i07.6860</pub-id>
      </element-citation>
    </ref>
    <ref id="CR155">
      <label>[155]</label>
      <mixed-citation publication-type="other">Wang, X.; Dong, Y. Y.; Zhang, Q.; Wang, Q. Regionbased depth feature descriptor for saliency detection on light field. <italic>Multimedia Tools and Applications</italic>10.1007/s11042-020-08890-x, 2020.</mixed-citation>
    </ref>
    <ref id="CR156">
      <label>[156]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S P</given-names>
          </name>
          <name>
            <surname>Poppe</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Light field saliency detection with deep convolutional networks</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2020</year>
        <volume>29</volume>
        <fpage>4421</fpage>
        <lpage>4434</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2020.2970529</pub-id>
      </element-citation>
    </ref>
    <ref id="CR157">
      <label>[157]</label>
      <mixed-citation publication-type="other">Achanta, R.; Hemami, S.; Estrada, F.; Susstrunk, S. Frequency-tuned salient region detection. In: Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 1597–1604, 2009.</mixed-citation>
    </ref>
    <ref id="CR158">
      <label>[158]</label>
      <mixed-citation publication-type="other">Krahenbuhl, P. Saliency filters: Contrast based filtering for salient region detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 733–740, 2012.</mixed-citation>
    </ref>
    <ref id="CR159">
      <label>[159]</label>
      <mixed-citation publication-type="other">Fan, D.-P.; Cheng, M.-M.; Liu, Y.; Li, T.; Borji. A. Structure-measure: A new way to evaluate foreground maps. In: Proceedings of the IEEE International Conference on Computer Vision, 4548–4557, 2017.</mixed-citation>
    </ref>
    <ref id="CR160">
      <label>[160]</label>
      <mixed-citation publication-type="other">Fan, D. P.; Gong, C.; Cao, Y.; Ren, B.; Cheng, M. M.; Borji, A. Enhanced-alignment measure for binary foreground map evaluation. In: Proceedings of the 27th International Joint Conference on Artificial Intelligence, 698–704, 2018.</mixed-citation>
    </ref>
    <ref id="CR161">
      <label>[161]</label>
      <mixed-citation publication-type="other">Qin, Y.; Lu, H.; Xu, Y.; Wang, H. Saliency detection via cellular automata. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 110–119, 2015.</mixed-citation>
    </ref>
    <ref id="CR162">
      <label>[162]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Z H</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Z T</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>D W</given-names>
          </name>
        </person-group>
        <article-title>Salient region detection via integrating diffusion-based compactness and local contrast</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2015</year>
        <volume>24</volume>
        <issue>11</issue>
        <fpage>3308</fpage>
        <lpage>3320</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2015.2438546</pub-id>
        <pub-id pub-id-type="pmid">26080382</pub-id>
      </element-citation>
    </ref>
    <ref id="CR163">
      <label>[163]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>X M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y J</given-names>
          </name>
        </person-group>
        <article-title>300-FPS salient object detection via minimum directional contrast</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2017</year>
        <volume>26</volume>
        <issue>9</issue>
        <fpage>4243</fpage>
        <lpage>4254</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2017.2710636</pub-id>
        <pub-id pub-id-type="pmid">28650801</pub-id>
      </element-citation>
    </ref>
    <ref id="CR164">
      <label>[164]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Qi</surname>
            <given-names>J Q</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L H</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Salient object detection via multiple instance learning</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2017</year>
        <volume>26</volume>
        <issue>4</issue>
        <fpage>1911</fpage>
        <lpage>1922</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2017.2669878</pub-id>
        <pub-id pub-id-type="pmid">28212086</pub-id>
      </element-citation>
    </ref>
    <ref id="CR165">
      <label>[165]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>X M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y J</given-names>
          </name>
        </person-group>
        <article-title>Water flow driven salient object detection at 180 fps</article-title>
        <source>Pattern Recognition</source>
        <year>2018</year>
        <volume>76</volume>
        <fpage>95</fpage>
        <lpage>107</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2017.10.027</pub-id>
      </element-citation>
    </ref>
    <ref id="CR166">
      <label>[166]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tao</surname>
            <given-names>D C</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Multi-view learning with incomplete views</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2015</year>
        <volume>24</volume>
        <issue>12</issue>
        <fpage>5812</fpage>
        <lpage>5825</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2015.2490539</pub-id>
        <pub-id pub-id-type="pmid">26469202</pub-id>
      </element-citation>
    </ref>
    <ref id="CR167">
      <label>[167]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Thung</surname>
            <given-names>K H</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>X F</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>D G</given-names>
          </name>
        </person-group>
        <article-title>Effective feature learning and fusion of multimodality data using stage-wise deep neural network for dementia diagnosis</article-title>
        <source>Human Brain Mapping</source>
        <year>2019</year>
        <volume>40</volume>
        <issue>3</issue>
        <fpage>1001</fpage>
        <lpage>1016</lpage>
        <pub-id pub-id-type="doi">10.1002/hbm.24428</pub-id>
        <pub-id pub-id-type="pmid">30381863</pub-id>
      </element-citation>
    </ref>
    <ref id="CR168">
      <label>[168]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>M X</given-names>
          </name>
          <name>
            <surname>Thung</surname>
            <given-names>K H</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>D G</given-names>
          </name>
        </person-group>
        <article-title>Latent representation learning for Alzheimer’s disease diagnosis with incomplete multi-modality neuroimaging and genetic data</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2019</year>
        <volume>38</volume>
        <issue>10</issue>
        <fpage>2411</fpage>
        <lpage>2422</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2019.2913158</pub-id>
        <pub-id pub-id-type="pmid">31021792</pub-id>
      </element-citation>
    </ref>
    <ref id="CR169">
      <label>[169]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Thung</surname>
            <given-names>K H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>M X</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C Q</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>D G</given-names>
          </name>
        </person-group>
        <article-title>Multi-modal latent space inducing ensemble SVM classifier for early dementia diagnosis with neuroimaging data</article-title>
        <source>Medical Image Analysis</source>
        <year>2020</year>
        <volume>60</volume>
        <fpage>101630</fpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2019.101630</pub-id>
        <pub-id pub-id-type="pmid">31927474</pub-id>
      </element-citation>
    </ref>
    <ref id="CR170">
      <label>[170]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H Z</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>J B</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Hi-net: Hybrid-fusion network for multi-modal MR image synthesis</article-title>
        <source>IEEE Transactions on Medical Imaging</source>
        <year>2020</year>
        <volume>39</volume>
        <issue>9</issue>
        <fpage>2772</fpage>
        <lpage>2781</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2020.2975344</pub-id>
        <pub-id pub-id-type="pmid">32086202</pub-id>
      </element-citation>
    </ref>
    <ref id="CR171">
      <label>[171]</label>
      <mixed-citation publication-type="other">Godard, C.; Aodha, O. M.; Brostow, G. J. Unsupervised monocular depth estimation with left-right consistency. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 6602–6611, 2017.</mixed-citation>
    </ref>
    <ref id="CR172">
      <label>[172]</label>
      <mixed-citation publication-type="other">Liu, F.; Shen, C.; Lin, G. Deep convolutional neural fields for depth estimation from a single image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 5162–5170, 2015.</mixed-citation>
    </ref>
    <ref id="CR173">
      <label>[173]</label>
      <mixed-citation publication-type="other">Wang, L.; Zhang, J.; Wang, O.; Lin, Z.; Lu, H. SDC-depth: Semantic divide-and-conquer network for monocular depth estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 541–550, 2020.</mixed-citation>
    </ref>
    <ref id="CR174">
      <label>[174]</label>
      <mixed-citation publication-type="other">Jin, L.; Xu, Y.; Zheng, J.; Zhang, J.; Tang, R.; Xu, S.; Yu, J.; Gao, S. Geometric structure based and regularized depth estimation from 360 indoor imagery. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 889–898, 2020.</mixed-citation>
    </ref>
    <ref id="CR175">
      <label>[175]</label>
      <mixed-citation publication-type="other">Mirza, M.; Osindero, S. Conditional generative adversarial nets. <italic>arXiv preprint</italic> arXiv:1411.1784, 2014.</mixed-citation>
    </ref>
    <ref id="CR176">
      <label>[176]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>D D</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>G K</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>J W</given-names>
          </name>
        </person-group>
        <article-title>Multi-scale adversarial feature learning for saliency detection</article-title>
        <source>Symmetry</source>
        <year>2018</year>
        <volume>10</volume>
        <issue>10</issue>
        <fpage>457</fpage>
        <pub-id pub-id-type="doi">10.3390/sym10100457</pub-id>
      </element-citation>
    </ref>
    <ref id="CR177">
      <label>[177]</label>
      <mixed-citation publication-type="other">Pan, J. T.; Ferrer, C. C.; McGuinness, K.; O’Connor, N. E.; Torres, J.; Sayrol, E.; Giro-i-Nieto, X. SalGAN: Visual saliency prediction with generative adversarial networks. <italic>arXiv preprint</italic> arXiv:1701.01081, 2017.</mixed-citation>
    </ref>
    <ref id="CR178">
      <label>[178]</label>
      <mixed-citation publication-type="other">Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; Polosukhin, I. Attention is all you need. In: Proceedings of the Conference on Neural Information Processing Systems, 5998–6008, 2017.</mixed-citation>
    </ref>
    <ref id="CR179">
      <label>[179]</label>
      <mixed-citation publication-type="other">Wang, F.; Jiang, M.; Qian, C.; Yang, S.; Li, C.; Zhang, H.; Wang, X.; Tang, X. Residual attention network for image classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3156–3164, 2017.</mixed-citation>
    </ref>
    <ref id="CR180">
      <label>[180]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Fang</surname>
            <given-names>H S</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>J K</given-names>
          </name>
          <name>
            <surname>Tai</surname>
            <given-names>Y W</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>C W</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Ferrari</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Hebert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sminchisescu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Pairwise body-part attention for recognizing human-object interactions</article-title>
        <source>Computer Vision — ECCV 2018. Lecture Notes in Computer Science, Vol. 11214</source>
        <year>2018</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>52</fpage>
        <lpage>68</lpage>
      </element-citation>
    </ref>
    <ref id="CR181">
      <label>[181]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>W G</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>J B</given-names>
          </name>
        </person-group>
        <article-title>Deep visual attention prediction</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2018</year>
        <volume>27</volume>
        <issue>5</issue>
        <fpage>2368</fpage>
        <lpage>2378</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2017.2787612</pub-id>
        <pub-id pub-id-type="pmid">29990140</pub-id>
      </element-citation>
    </ref>
    <ref id="CR182">
      <label>[182]</label>
      <mixed-citation publication-type="other">Lu, J.; Yang, J.; Batra, D.; Parikh, D. Hierarchical question-image co-attention for visual question answering. In: Proceedings of the International Conference on Neural Information Processing Systems, 289–297, 2016.</mixed-citation>
    </ref>
    <ref id="CR183">
      <label>[183]</label>
      <mixed-citation publication-type="other">Yu, Z.; Yu, J.; Cui, Y.; Tao, D.; Tian, Q. Deep modular co-attention networks for visual question answering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 6281–6290, 2019.</mixed-citation>
    </ref>
    <ref id="CR184">
      <label>[184]</label>
      <mixed-citation publication-type="other">Lu, X.; Wang, W.; Ma, C.; Shen, J.; Shao, L.; Porikli, F. See more, know more: Unsupervised video object segmentation with co-attention siamese networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 3623–3632, 2019.</mixed-citation>
    </ref>
    <ref id="CR185">
      <label>[185]</label>
      <mixed-citation publication-type="other">Zeng, Y.; Zhuge, Y.; Lu, H.; Zhang, L.; Qian, M.; Yu, Y. Multi-source weak supervision for saliency detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 6074–6083, 2019.</mixed-citation>
    </ref>
    <ref id="CR186">
      <label>[186]</label>
      <mixed-citation publication-type="other">Zhang, D. W.; Meng, D. Y.; Zhao, L.; Han, J. W. Bridging saliency detection to weakly supervised object detection based on self-paced curriculum learning. <italic>arXiv preprint</italic> arXiv:1703.01290, 2017.</mixed-citation>
    </ref>
    <ref id="CR187">
      <label>[187]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qian</surname>
            <given-names>M Y</given-names>
          </name>
          <name>
            <surname>Qi</surname>
            <given-names>J Q</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L H</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>M Y</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H C</given-names>
          </name>
        </person-group>
        <article-title>Language-aware weak supervision for salient object detection</article-title>
        <source>Pattern Recognition</source>
        <year>2019</year>
        <volume>96</volume>
        <fpage>106955</fpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2019.06.021</pub-id>
      </element-citation>
    </ref>
    <ref id="CR188">
      <label>[188]</label>
      <mixed-citation publication-type="other">Yan, P.; Li, G.; Xie, Y.; Li, Z.; Wang, C.; Chen, T.; Lin, L. Semi-supervised video salient object detection using pseudo-labels. In: Proceedings of the IEEE International Conference on Computer Vision, 7284–7293, 2019.</mixed-citation>
    </ref>
    <ref id="CR189">
      <label>[189]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Huo</surname>
            <given-names>S W</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>C P</given-names>
          </name>
          <name>
            <surname>Kung</surname>
            <given-names>S Y</given-names>
          </name>
        </person-group>
        <article-title>Semi-supervised salient object detection using a linear feedback control system model</article-title>
        <source>IEEE Transactions on Cybernetics</source>
        <year>2019</year>
        <volume>49</volume>
        <issue>4</issue>
        <fpage>1173</fpage>
        <lpage>1185</lpage>
        <pub-id pub-id-type="doi">10.1109/TCYB.2018.2793278</pub-id>
        <pub-id pub-id-type="pmid">29993850</pub-id>
      </element-citation>
    </ref>
    <ref id="CR190">
      <label>[190]</label>
      <mixed-citation publication-type="other">Zhang, D.; Han, J.; Zhang, Y. Supervision by fusion: Towards unsupervised learning of deep salient object detector. In: Proceedings of the IEEE International Conference on Computer Vision, 4048–4056, 2017.</mixed-citation>
    </ref>
    <ref id="CR191">
      <label>[191]</label>
      <mixed-citation publication-type="other">Chen, T.; Liu, S.; Chang, S.; Cheng, Y.; Amini, L.; Wang, Z. Adversarial robustness: From self-supervised pre-training to fine-tuning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 699–708, 2020.</mixed-citation>
    </ref>
    <ref id="CR192">
      <label>[192]</label>
      <mixed-citation publication-type="other">Dai, A.; Diller, C.; Niefiner, M. SG-NN: Sparse generative neural networks for self-supervised scene completion of RGB-D scans. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 849–858, 2020.</mixed-citation>
    </ref>
    <ref id="CR193">
      <label>[193]</label>
      <mixed-citation publication-type="other">Lai, K.; Bo, L.; Ren, X.; Fox, D. A largescale hierarchical multi-view RGB-D object dataset. In: Proceedings of the IEEE International Conference on Robotics and Automation, 1817–1824, 2011.</mixed-citation>
    </ref>
    <ref id="CR194">
      <label>[194]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>P C</given-names>
          </name>
          <name>
            <surname>Ogunbona</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Wannous</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Pala</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Daoudi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Flórez-Revuelta</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A large scale RGB-D dataset for action recognition</article-title>
        <source>Understanding Human Activities Through 3D Sensors. Lecture Notes in Computer Science, Vol. 10188.</source>
        <year>2018</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>101</fpage>
        <lpage>114</lpage>
      </element-citation>
    </ref>
    <ref id="CR195">
      <label>[195]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>Y H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L J</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Ferrari</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Hebert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sminchisescu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>AMC: AutoML for model compression and acceleration on mobile devices</article-title>
        <source>Computer Vision — ECCV 2018. Lecture Notes in Computer Science, Vol. 11211.</source>
        <year>2018</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>815</fpage>
        <lpage>832</lpage>
      </element-citation>
    </ref>
    <ref id="CR196">
      <label>[196]</label>
      <mixed-citation publication-type="other">Cheng, Y.; Wang, D.; Zhou, P.; Zhang, T. A survey of model compression and acceleration for deep neural networks. <italic>arXiv preprint</italic> arXiv:1710.09282, 2017.</mixed-citation>
    </ref>
    <ref id="CR197">
      <label>[197]</label>
      <mixed-citation publication-type="other">Ma, Y.; Sun, D.; Meng, Q.; Ding, Z.; Li, C. Learning multiscale deep features and SVM regressors for adaptive RGB-T saliency detection. In: Proceedings of the 10th International Symposium on Computational Intelligence and Design, 389–392, 2017.</mixed-citation>
    </ref>
    <ref id="CR198">
      <label>[198]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>G Z</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C L</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>Y P</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>A H</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>RGB-T saliency detection benchmark: Dataset, baselines, analysis and a novel approach</article-title>
        <source>Image and Graphics Technologies and Applications. Communications in Computer and Information Science, Vol. 875.</source>
        <year>2018</year>
        <publisher-loc>Singapore</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>359</fpage>
        <lpage>369</lpage>
      </element-citation>
    </ref>
    <ref id="CR199">
      <label>[199]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>G Z</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C L</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>Y P</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>A H</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>RGB-T saliency detection benchmark: Dataset, baselines, analysis and a novel approach</article-title>
        <source>Image and Graphics Technologies and Applications. Communications in Computer and Information Science, Vol. 875</source>
        <year>2018</year>
        <publisher-loc>Singapore</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>359</fpage>
        <lpage>369</lpage>
      </element-citation>
    </ref>
    <ref id="CR200">
      <label>[200]</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>D D</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>Z L</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Pan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Qu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>RGB-T saliency detection via robust graph learning and collaborative manifold ranking</article-title>
        <source>Bio-inspired Computing: Theories and Applications. Communications in Computer and Information Science, Vol. 1160</source>
        <year>2020</year>
        <publisher-loc>Singapore</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>670</fpage>
        <lpage>684</lpage>
      </element-citation>
    </ref>
    <ref id="CR201">
      <label>[201]</label>
      <mixed-citation publication-type="other">Tu, Z.; Xia, T.; Li, C.; Lu, Y.; Tang, J. M3S-NIR: Multi-modal multi-scale noise-insensitive ranking for RGB-T saliency detection. In: Proceedings of the IEEE Conference on Multimedia Information Processing and Retrieval, 141–146, 2019.</mixed-citation>
    </ref>
    <ref id="CR202">
      <label>[202]</label>
      <mixed-citation publication-type="other">Tu, Z. Z.; Li, Z.; Li, C. L.; Lang, Y.; Tang, J. Multi-interactive encoder-decoder network for RGBT salient object detection. <italic>arXiv preprint</italic> arXiv:2005.02315, 2020.</mixed-citation>
    </ref>
    <ref id="CR203">
      <label>[203]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tu</surname>
            <given-names>Z Z</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X X</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>RGB-T image saliency detection via collaborative graph learning</article-title>
        <source>IEEE Transactions on Multimedia</source>
        <year>2020</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>160</fpage>
        <lpage>173</lpage>
        <pub-id pub-id-type="doi">10.1109/TMM.2019.2924578</pub-id>
      </element-citation>
    </ref>
    <ref id="CR204">
      <label>[204]</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>N C</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D W</given-names>
          </name>
          <name>
            <surname>Shan</surname>
            <given-names>C F</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>J G</given-names>
          </name>
        </person-group>
        <article-title>RGB-T salient object detection via fusing multi-level CNN features</article-title>
        <source>IEEE Transactions on Image Processing</source>
        <year>2020</year>
        <volume>29</volume>
        <fpage>3321</fpage>
        <lpage>3335</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2019.2959253</pub-id>
      </element-citation>
    </ref>
    <ref id="CR205">
      <label>[205]</label>
      <mixed-citation publication-type="other">Tu, Z. Z.; Ma, Y.; Li, Z.; Li, C. L.; Xu, J. M.; Liu, Y. T. RGBT salient object detection: A large-scale dataset and benchmark. <italic>arXiv preprint</italic> arXiv:2007.03262, 2020.</mixed-citation>
    </ref>
  </ref-list>
</back>
