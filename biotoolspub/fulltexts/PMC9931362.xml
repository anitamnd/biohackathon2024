<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pdig.0000086.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Digital Health</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2767-3170</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9931362</article-id>
    <article-id pub-id-type="publisher-id">PDIG-D-21-00039</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000086</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cognitive Science</subject>
            <subj-group>
              <subject>Cognitive Psychology</subject>
              <subj-group>
                <subject>Language</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Language</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Language</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
        <subj-group>
          <subject>Sociology</subject>
          <subj-group>
            <subject>Communications</subject>
            <subj-group>
              <subject>Mass Media</subject>
              <subj-group>
                <subject>Encyclopedias</subject>
                <subj-group>
                  <subject>Online Encyclopedias</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Natural Language Processing</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Applications</subject>
          <subj-group>
            <subject>Web-Based Applications</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Science Policy</subject>
        <subj-group>
          <subject>Open Science</subject>
          <subj-group>
            <subject>Open Data</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
        <subj-group>
          <subject>Linguistics</subject>
          <subj-group>
            <subject>Grammar</subject>
            <subj-group>
              <subject>Syntax</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DrNote: An open medical annotation service</article-title>
      <alt-title alt-title-type="running-head">DrNote: An open medical annotation service</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0323-0904</contrib-id>
        <name>
          <surname>Frei</surname>
          <given-names>Johann</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3061-5818</contrib-id>
        <name>
          <surname>Soto-Rey</surname>
          <given-names>Iñaki</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="econtrib001" ref-type="author-notes">
          <sup>‡</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2857-7122</contrib-id>
        <name>
          <surname>Kramer</surname>
          <given-names>Frank</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>IT-Infrastructure for Translational Medical Research, Faculty of Applied Computer Science, University of Augsburg, Augsburg, Germany</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Medical Data Integration Center, Institute for Digital Medicine, University Hospital Augsburg, Augsburg, Germany</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Banerjee</surname>
          <given-names>Imon</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Emory University, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <fn fn-type="other" id="econtrib001">
        <p>‡ Clinical Partner</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>johann.frei@informatik.uni-augsburg.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>1</volume>
    <issue>8</issue>
    <elocation-id>e0000086</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>7</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>7</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Frei et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Frei et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pdig.0000086.pdf"/>
    <abstract>
      <p>In the context of clinical trials and medical research medical text mining can provide broader insights for various research scenarios by tapping additional text data sources and extracting relevant information that is often exclusively present in unstructured fashion. Although various works for data like electronic health reports are available for English texts, only limited work on tools for non-English text resources has been published that offers immediate practicality in terms of flexibility and initial setup. We introduce DrNote, an open source text annotation service for medical text processing. Our work provides an entire annotation pipeline with its focus on a fast yet effective and easy to use software implementation. Further, the software allows its users to define a custom annotation scope by filtering only for relevant entities that should be included in its knowledge base. The approach is based on OpenTapioca and combines the publicly available datasets from WikiData and Wikipedia, and thus, performs entity linking tasks. In contrast to other related work our service can easily be built upon any language-specific Wikipedia dataset in order to be trained on a specific target language. We provide a public demo instance of our DrNote annotation service at <ext-link xlink:href="https://drnote.misit-augsburg.de/" ext-link-type="uri">https://drnote.misit-augsburg.de/</ext-link>.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Since much highly relevant information in healthcare and clinical research is exclusively stored as unstructured text, retrieving and processing such data poses a major challenge. Novel data-driven text processing methods require large amounts of annotated data in order to exceed non data-driven methods’ performance. In the medical domain, such data is not publicly available and restricted access is limited due to federal privacy regulations. We circumvent this issue by developing an annotation pipeline that works on sparse data and retrieves the training data from publicly available data sources. The fully automated pipeline can be easily adapted by third parties for custom use cases or directly applied within minutes for medical use cases. It significantly lowers the barrier for fast analysis of unstructured clinical text data in certain scenarios.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100002347</institution-id>
            <institution>bundesministerium für bildung und forschung</institution>
          </institution-wrap>
        </funding-source>
        <award-id>FKZ01ZZ1804E</award-id>
      </award-group>
      <funding-statement>This work is a part of the DIFUTURE project funded by the German Ministry of Education and Research (Bundesministerium für Bildung und Forschung, BMBF) grant FKZ01ZZ1804E. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="2"/>
      <page-count count="18"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The Wikipedia and WikiData datasets are publicly available at: <ext-link xlink:href="https://dumps.wikimedia.org/enwiki/" ext-link-type="uri">https://dumps.wikimedia.org/enwiki/</ext-link>
<ext-link xlink:href="https://dumps.wikimedia.org/dewiki/" ext-link-type="uri">https://dumps.wikimedia.org/dewiki/</ext-link>
<ext-link xlink:href="https://dumps.wikimedia.org/wikidatawiki/entities/" ext-link-type="uri">https://dumps.wikimedia.org/wikidatawiki/entities/</ext-link> Our project repository is publicly available at: GitHub: <ext-link xlink:href="https://github.com/frankkramer-lab/DrNote" ext-link-type="uri">https://github.com/frankkramer-lab/DrNote</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The Wikipedia and WikiData datasets are publicly available at: <ext-link xlink:href="https://dumps.wikimedia.org/enwiki/" ext-link-type="uri">https://dumps.wikimedia.org/enwiki/</ext-link>
<ext-link xlink:href="https://dumps.wikimedia.org/dewiki/" ext-link-type="uri">https://dumps.wikimedia.org/dewiki/</ext-link>
<ext-link xlink:href="https://dumps.wikimedia.org/wikidatawiki/entities/" ext-link-type="uri">https://dumps.wikimedia.org/wikidatawiki/entities/</ext-link> Our project repository is publicly available at: GitHub: <ext-link xlink:href="https://github.com/frankkramer-lab/DrNote" ext-link-type="uri">https://github.com/frankkramer-lab/DrNote</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Effective processing of natural clinical language data has increasingly become a key element for clinical and medical data analysis. Recent trends in the field of natural language processing (NLP) have established novel data-driven neural approaches to largely improve a broad variety of language and text analysis tasks like neural machine translation, text summarization, question answering, text classification and information extraction in general. Most notably, emerging from semantic word embeddings like Word2Vec [<xref rid="pdig.0000086.ref001" ref-type="bibr">1</xref>] and GloVe [<xref rid="pdig.0000086.ref002" ref-type="bibr">2</xref>], contextualized word embedding techniques like ELMo [<xref rid="pdig.0000086.ref003" ref-type="bibr">3</xref>] or BERT [<xref rid="pdig.0000086.ref004" ref-type="bibr">4</xref>] based on the Transformer network architecture [<xref rid="pdig.0000086.ref005" ref-type="bibr">5</xref>] are applied in order to solve most of context-specific downstream tasks. Attention-based language models therefore gained popularity among the NLP research community since they are able to outperform simpler rule-based models, statistical methods like conditional random fields and other, neural methods like LSTM-based models on core NLP tasks such as named entity recognition (NER).</p>
    <p>On the matter of domain-specific neural approaches for NLP numerous derivatives [<xref rid="pdig.0000086.ref006" ref-type="bibr">6</xref>–<xref rid="pdig.0000086.ref011" ref-type="bibr">11</xref>] are applied for various NLP downstream tasks. The trend of these neural approaches appear to steer towards end-to-end models [<xref rid="pdig.0000086.ref012" ref-type="bibr">12</xref>] which are often optimized for specific purposes [<xref rid="pdig.0000086.ref013" ref-type="bibr">13</xref>]. While most works focus on English data, creating cross-lingual approaches [<xref rid="pdig.0000086.ref004" ref-type="bibr">4</xref>, <xref rid="pdig.0000086.ref014" ref-type="bibr">14</xref>, <xref rid="pdig.0000086.ref015" ref-type="bibr">15</xref>] for medical applications is difficult due to the lack of sufficient data.</p>
    <p>Traditional non-deep learning NLP systems often adopt pipeline-based approaches [<xref rid="pdig.0000086.ref016" ref-type="bibr">16</xref>, <xref rid="pdig.0000086.ref017" ref-type="bibr">17</xref>] for text processing in which each pipeline stage performs a modular text processing task, enabling the reuse of single components on different applications and contexts in a simplified fashion. The core components often rely on feature-based machine learning or linguistic rule-based methods, although certain frameworks [<xref rid="pdig.0000086.ref016" ref-type="bibr">16</xref>, <xref rid="pdig.0000086.ref018" ref-type="bibr">18</xref>] integrate also neural approaches for certain NLP tasks in more recent versions. For the framework of [<xref rid="pdig.0000086.ref018" ref-type="bibr">18</xref>], a domain-specific model [<xref rid="pdig.0000086.ref019" ref-type="bibr">19</xref>] has been published for biomedical applications for English text data. For German texts, mEx [<xref rid="pdig.0000086.ref020" ref-type="bibr">20</xref>] implements a similar pipeline for clinical texts based on SpaCy [<xref rid="pdig.0000086.ref016" ref-type="bibr">16</xref>], albeit its trained models have not been published.</p>
    <p>Historically, NLP software for medical applications has been an ongoing research subject. The software system <italic toggle="yes">medSynDiKATe</italic> [<xref rid="pdig.0000086.ref021" ref-type="bibr">21</xref>] is an early approach to extract relevant information from pathology finding reports in German language. <italic toggle="yes">Apache cTAKES</italic> [<xref rid="pdig.0000086.ref022" ref-type="bibr">22</xref>] is another modular software for medical text processing, following the UIMA architecture, that uses OpenNLP [<xref rid="pdig.0000086.ref023" ref-type="bibr">23</xref>] for text analysis. While [<xref rid="pdig.0000086.ref022" ref-type="bibr">22</xref>] is mainly designed for English texts, [<xref rid="pdig.0000086.ref024" ref-type="bibr">24</xref>] shows only moderate results for German data when using input text translation into English. <italic toggle="yes">HITEx</italic> [<xref rid="pdig.0000086.ref025" ref-type="bibr">25</xref>] based on the <italic toggle="yes">GATE</italic> [<xref rid="pdig.0000086.ref026" ref-type="bibr">26</xref>] framework, and <italic toggle="yes">MetaMaps</italic> [<xref rid="pdig.0000086.ref027" ref-type="bibr">27</xref>] present comparable notable implementations for medical text processing for English text data. Provided as a public web API, <italic toggle="yes">PubTator</italic> [<xref rid="pdig.0000086.ref028" ref-type="bibr">28</xref>] is a similar text mining tool for English biomedical text annotations with support for a fixed set of entry types.</p>
    <p>From the perspective of commercial software for medical text analysis in German language, <italic toggle="yes">Averbis Health Discovery</italic> [<xref rid="pdig.0000086.ref029" ref-type="bibr">29</xref>] provides an industry solution to NLP tasks for clinical applications. For a deeper insight in remaining challenges of non-English medical text processing we point to the review paper [<xref rid="pdig.0000086.ref030" ref-type="bibr">30</xref>]. More information on the situation of clinical text analysis methods such as for medical concept extraction and normalization or for clinical challenges in general are presented in review papers [<xref rid="pdig.0000086.ref031" ref-type="bibr">31</xref>–<xref rid="pdig.0000086.ref033" ref-type="bibr">33</xref>]. In similar contexts, <italic toggle="yes">Trove</italic> [<xref rid="pdig.0000086.ref033" ref-type="bibr">33</xref>] is proposed as a framework for weak supervised clinical NER tasks. While the latter work yields a broad overview on key aspects of different methodological concepts and covers weak supervised settings with ontology-based knowledge bases in English, it acknowledges the need for further work on non-English contexts.</p>
    <p>For text annotation and entity linking in general, earlier works focus on Wikipedia and WikiData as knowledge base. Entity linking on unstructured texts to Wikipedia was shown in [<xref rid="pdig.0000086.ref034" ref-type="bibr">34</xref>–<xref rid="pdig.0000086.ref037" ref-type="bibr">37</xref>], even before the WikiData [<xref rid="pdig.0000086.ref038" ref-type="bibr">38</xref>] knowledge graph was introduced. Different entity linking approaches were evaluated and compared in [<xref rid="pdig.0000086.ref039" ref-type="bibr">39</xref>]. In addition to WikiData, other knowledge bases [<xref rid="pdig.0000086.ref040" ref-type="bibr">40</xref>–<xref rid="pdig.0000086.ref043" ref-type="bibr">43</xref>] have been released as well. For tagging engines like <italic toggle="yes">TagMe</italic> [<xref rid="pdig.0000086.ref037" ref-type="bibr">37</xref>], refined entity linking systems [<xref rid="pdig.0000086.ref044" ref-type="bibr">44</xref>, <xref rid="pdig.0000086.ref045" ref-type="bibr">45</xref>] were released. More recently, neural-based entity linking methods have been proposed [<xref rid="pdig.0000086.ref046" ref-type="bibr">46</xref>–<xref rid="pdig.0000086.ref048" ref-type="bibr">48</xref>].</p>
    <sec id="sec002">
      <title>Motivation</title>
      <p>By considering common natural language processing tasks as a learning problem, this inherently implies the need for training data. Since novel Transformer-based architectures have been proven effective on large amount of domain-specific training data [<xref rid="pdig.0000086.ref006" ref-type="bibr">6</xref>–<xref rid="pdig.0000086.ref011" ref-type="bibr">11</xref>], training such domain-specific models for certain languages from scratch without any pretraining [<xref rid="pdig.0000086.ref007" ref-type="bibr">7</xref>, <xref rid="pdig.0000086.ref009" ref-type="bibr">9</xref>, <xref rid="pdig.0000086.ref010" ref-type="bibr">10</xref>] remains a major challenge due to the lack of appropriate datasets in general. Hence, transfer learning approaches are commonly used for use case-specific downstream tasks and integrated in practical application [<xref rid="pdig.0000086.ref013" ref-type="bibr">13</xref>], in order to mitigate the required amount of training data and boost the performance of the model.</p>
      <p>Open datasets of biomedical texts and clinical letters for English languages have been published [<xref rid="pdig.0000086.ref049" ref-type="bibr">49</xref>, <xref rid="pdig.0000086.ref050" ref-type="bibr">50</xref>]. In the particular case of German data resources for clinical letters, the situation is more dire [<xref rid="pdig.0000086.ref030" ref-type="bibr">30</xref>, <xref rid="pdig.0000086.ref051" ref-type="bibr">51</xref>, <xref rid="pdig.0000086.ref052" ref-type="bibr">52</xref>] as no large dataset is publicly available.</p>
      <p>In addition, one property of natural language processing methods concerns the possible dependency on one specific language: Although works on cross- and multilingual language models like XLM, XLM-R [<xref rid="pdig.0000086.ref014" ref-type="bibr">14</xref>, <xref rid="pdig.0000086.ref015" ref-type="bibr">15</xref>] or mBERT [<xref rid="pdig.0000086.ref004" ref-type="bibr">4</xref>] present notable results, they indicate higher downstream task performance scores for monolingual models on non low-resource languages.</p>
      <p>Since text processing pipelines need to be manually fine tuned for their corresponding downstream task on aggregated training data in order to reach significant level of performance, these pipelines require a high level of technical skill sets in order to apply existing methods based on contextualized word embeddings in dedicated domain contexts.</p>
    </sec>
    <sec id="sec003">
      <title>Contributions</title>
      <p>Consequently, in this work we primarily focus on methods that do not rely on techniques like contextualized word embeddings and can be built using a public dataset. From our perspective, this enables a simplified process for build, deployment and application.</p>
      <p>This work presents an open annotation tool for unstructured medical texts which implements an entity linking solution.</p>
      <p>Our key contributions can be considered as an ensemble of the following items:
<list list-type="bullet"><list-item><p><italic toggle="yes">Automated build process:</italic> Our annotation tool requires precomputed annotation data in order to perform the entity linking tasks. To preprocess and obtain the annotation data, we provide a fully automated, end-to-end build pipeline that enables the user to adapt our pipeline for custom use cases.</p></list-item><list-item><p><italic toggle="yes">Use of public data:</italic> The annotation tool relies on the publicly available, open WikiData and Wikipedia datasets. The datasets are used for initial training of the annotation candidate classifier at build time, and as a knowledge base for entity linking later during the text annotation.</p></list-item><list-item><p><italic toggle="yes">Language support:</italic> Our implementation is capable of adopting other languages in its build pipeline. The user can choose a specific language from the set of supported languages in Wikipedia.</p></list-item><list-item><p><italic toggle="yes">Usability:</italic> The annotation service offers a simplified RESTful API for entity linking. The user can input plain text into a basic web interface. In addition, PDF documents can be uploaded and processed. In the case of using pretrained annotation data, the annotation service can be easily deployed on premise instantly.</p></list-item></list></p>
    </sec>
  </sec>
  <sec sec-type="materials|methods" id="sec004">
    <title>Materials and methods</title>
    <sec id="sec005">
      <title>Open datasets</title>
      <p>The need for training data is one of the major issues in the area of data-driven methods. In this work, we combine two open public data sets in order to retrieve appropriate training data.</p>
      <sec id="sec006">
        <title>WikiData</title>
        <p>WikiData [<xref rid="pdig.0000086.ref038" ref-type="bibr">38</xref>] is a free open knowledge base with multilingual, structured data. Its entities (<italic toggle="yes">items</italic>) are represented in a graph structure, in which each entity consists of an item identifier and main item label. These items can store short <italic toggle="yes">description</italic> texts, <italic toggle="yes">labels</italic> and potential <italic toggle="yes">alias</italic> labels for certain languages. In addition, an item may comprise a list of <italic toggle="yes">statements</italic> to further encode knowledge. Hereby, a statement is defined by a property and a list of corresponding values. These values can either encode explicit structured values or references to other entities in the knowledge base. Furthermore, each item can store references to other wiki entries through its <italic toggle="yes">sitelink</italic> attribute. Given by the nature of its graphical representation, the WikiData repository can be queried through a public SPARQL-API. The entire WikiData knowledge base is also accessible through a file download for local use.</p>
      </sec>
      <sec id="sec007">
        <title>Wikipedia</title>
        <p>For the sake of simplicity, the Wikipedia platform is considered in this work as a set of independent open public language-specific wiki sites. Each wiki site is composed by a set of wiki pages. A wiki page consists of a page title and the page content. The page content is written in the <italic toggle="yes">Wikitext</italic> syntax which constitutes a simplified hypertext markup language. Plain texts from a wiki page contain words that can reference other wiki pages, and thereby form a graph-like structure consisting of one node per wiki page. Every wiki page references a corresponding item from the WikiData knowledge base. These references often expose the limitation of linking wiki pages to WikiData items due to the diverging concept scope granularity: For instance, the German wiki page for <italic toggle="yes">Diabetes mellitus</italic> links to the WikiData item <italic toggle="yes">Q12206</italic> which in reverse links back to the German <italic toggle="yes">Diabetes mellitus</italic> wiki page through the entity sitelinks. However, the WikiData item <italic toggle="yes">Q3025883</italic> represents the concept of <italic toggle="yes">Type-2-Diabetes</italic> and its sitelink back to the German wiki page resolves to the wiki page <italic toggle="yes">Diabetes mellitus</italic> with focus on the page section <italic toggle="yes">Diabetes Typ 2</italic>. This implies a potential loss of information due to the granularity mismatch since the mapping between wiki pages and WikiData items does not exhibit the bijective property.</p>
        <p>In general, the language-specific wiki dataset can be downloaded in order to obtain the content of all wiki pages.</p>
      </sec>
    </sec>
    <sec id="sec008">
      <title>Text annotation</title>
      <p>One of the decisive components that are vital to such an annotation pipeline is the tagging and linking component. The high-level task for this component is to identify all semantically corresponding entities of a given knowledge base for a given text and link the affected text positions by their related entity references. This task is regarded as an entity linking (EL) task.
<disp-formula id="pdig.0000086.e001"><alternatives><graphic xlink:href="pdig.0000086.e001.jpg" id="pdig.0000086.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>δ</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>s</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>Ω</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
where:</p>
      <p><italic toggle="yes">ω</italic> = mention</p>
      <p><italic toggle="yes">δ</italic> = text document</p>
      <p><italic toggle="yes">s</italic> = identified text span</p>
      <p><italic toggle="yes">ϵ</italic> = (concept) entity</p>
      <p>Ω = knowledge base (KB)</p>
      <p><italic toggle="yes">link</italic>(<italic toggle="yes">m</italic>) = entity linking function</p>
      <p>The objective to approximate the entity linking function <italic toggle="yes">link</italic>(<italic toggle="yes">m</italic>) can be decomposed into two independent subtasks. The first step covers the mention detection and candidate generation. At this step, all possible entities <italic toggle="yes">ϵ</italic> from the knowledge base Ω that match to the detected mention <italic toggle="yes">ω</italic> are considered. The second step regards the selection of the best entity candidate for the mention <italic toggle="yes">ω</italic> (Entity Disambiguation). The proper design of this step heavily depends on the <italic toggle="yes">ω</italic> ↔ <italic toggle="yes">ϵ</italic> match scoring function which may incorporate context-dependent scores in addition to context-independent similarity metrics.</p>
      <p>In this work, we heavily rely on OpenTapioca [<xref rid="pdig.0000086.ref053" ref-type="bibr">53</xref>] for solving the entity linking objective. OpenTapioca leverages the tagging functionality of the Apache Solr software in order to implement the candidate generation step. OpenTapioca creates and prepares a Solr collection in advance to index all relevant terms of the WikiData knowledge base for accelerated mention lookup and tagging.</p>
      <p>For the estimation of the matching score of a mention to a corresponding entity candidate, the following local feature vector is defined and sampled for each pair of entity candidate <italic toggle="yes">ϵ</italic> and mention <italic toggle="yes">ω</italic>:
<disp-formula id="pdig.0000086.e002"><alternatives><graphic xlink:href="pdig.0000086.e002.jpg" id="pdig.0000086.e002g" position="anchor"/><mml:math id="M2" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mo>(</mml:mo><mml:mi>ω</mml:mi><mml:mo>,</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mtext>p</mml:mtext><mml:mo>(</mml:mo><mml:mi>ω</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mtext>log</mml:mtext><mml:mspace width="4pt"/><mml:mtext>PR</mml:mtext><mml:mo>(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mtext>stmd</mml:mtext><mml:mo>(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mtext>sl</mml:mtext><mml:mo>(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
where:</p>
      <p><italic toggle="yes">p</italic>(<italic toggle="yes">ω</italic>) = probability of mention <italic toggle="yes">ω</italic> in the language model</p>
      <p><italic toggle="yes">PR</italic>(<italic toggle="yes">ϵ</italic>) = PageRank score of entity <italic toggle="yes">ϵ</italic> in KB Ω</p>
      <p><italic toggle="yes">stmd</italic>(<italic toggle="yes">ϵ</italic>) = number of statements of entity <italic toggle="yes">ϵ</italic></p>
      <p><italic toggle="yes">sl</italic>(<italic toggle="yes">ϵ</italic>) = number of sitelinks of entity <italic toggle="yes">ϵ</italic></p>
      <p>Hereby, a feature matrix <italic toggle="yes">FM</italic><sub>0</sub> is constructed from the stacked local feature vectors. The sequence of detected mentions forms a weighted graph <italic toggle="yes">G</italic>, where each (<italic toggle="yes">ω</italic>-<italic toggle="yes">ϵ</italic>) pair yields a node, connected to all nodes with neighboring <italic toggle="yes">ω</italic><sub><italic toggle="yes">neighbor</italic></sub> mentions. To represent semantic clusters, the connection weights between two nodes a, b with their entities <italic toggle="yes">ϵ</italic><sub><italic toggle="yes">b</italic></sub> and <italic toggle="yes">ϵ</italic><sub><italic toggle="yes">a</italic></sub> are modulated by the probability to reach each other or a common entity <italic toggle="yes">ϵ</italic><sub>3<italic toggle="yes">rd</italic></sub> in the knowledge base graph Ω. The reachability is limited to first order connectivity. The feature matrix <italic toggle="yes">F</italic><sub>0</sub> is propagated along the stochastic adjacency matrix <inline-formula id="pdig.0000086.e003"><alternatives><graphic xlink:href="pdig.0000086.e003.jpg" id="pdig.0000086.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>M</mml:mi><mml:mo>~</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> for <italic toggle="yes">n</italic> iterations, where <italic toggle="yes">M</italic> represents the unnormalized (non-stochastic) adjacency matrix of the graph <italic toggle="yes">G</italic>, resulting in the contextualized feature tensor (<italic toggle="yes">FM</italic><sub>0</sub>, <italic toggle="yes">FM</italic><sub>1</sub>, ⋯, <italic toggle="yes">FM</italic><sub><italic toggle="yes">n</italic></sub>). A support vector machine (SVM) is applied to estimate the score for each entity candidate of each mention. For a deeper explanation, we point to the original paper [<xref rid="pdig.0000086.ref053" ref-type="bibr">53</xref>].</p>
      <p>Whereas the uni-gram language model is computed on the WikiData entity labels as an approximation, and the Page Rank scores for the entities can be computed on the WikiData knowledge base graph structure, it is important to note that the SVM classifier cannot be trained without annotated training data. Thus, the user is required to extract documents and annotate the documents’ mentions with their related entity links manually.</p>
      <p>OpenTapioca requires a tool-specific <italic toggle="yes">profile</italic> for term indexing that defines all entities which should be part of the knowledge base Ω. The text annotation only covers terms that were previously included in the OpenTapioca <italic toggle="yes">profile</italic>.</p>
    </sec>
    <sec id="sec009">
      <title>Text postprocessing and filtering</title>
      <p>In order to allow encoding of prior knowledge about the target annotation structure, it is necessary to analyse the input text data by an NLP toolchain. We rely on the library SpaCy [<xref rid="pdig.0000086.ref016" ref-type="bibr">16</xref>] in conjunction with its published pretrained pipeline components. The components mainly consist of a simple universal part-of-speech tagger, a more detailed part-of-speech tagger, a morpholgizer and a dependency parser.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec010">
    <title>Results</title>
    <sec id="sec011">
      <title>Build pipeline</title>
      <p>An automated pipeline has been developed that performs the following steps:</p>
      <sec id="sec012">
        <title>Installation of required components</title>
        <p>All required dependencies are installed to the local machine. This mainly includes a container runtime and basic shell tools.</p>
      </sec>
      <sec id="sec013">
        <title>Automated NIF extraction</title>
        <p>We acquire the required training data through a pipeline of parsing, extraction and transformation steps of the formerly mentioned datasets. First, the Wikipedia pages for a given language code are parsed. During that step, all referencing terms in the page texts are extracted and their referenced pages are resolved. Given the OpenTapioca <italic toggle="yes">profile</italic>, we then query the SPARQL API to obtain all affected WikiData items. The entire WikiData dataset is parsed and for each WikiData item sitelink that points to its Wikipedia page, we add its item identifier to the processed Wikipedia page in the database to establish a bijective mapping while ignoring more fine-granular WikiData items.</p>
        <p>Given the parsed and linked data for WikiData and Wikipedia, we can select all pages that contain referencing terms in the text to other pages if the related WikiData items were included by the OpenTapioca <italic toggle="yes">profile</italic>. By doing so, we treat relevant referencing terms as word annotations and, therefore, can synthesize the required dataset with annotated mentions. To avoid irrelevant text sections, only the sentences with relevant terms are further extracted. For sentence splitting, SpaCy [<xref rid="pdig.0000086.ref016" ref-type="bibr">16</xref>] is used. The transformed data is stored in the common NIF format.</p>
      </sec>
      <sec id="sec014">
        <title>OpenTapioca annotation setup</title>
        <p>The initialization steps for OpenTapioca are performed as follows: Based on the given OpenTapioca <italic toggle="yes">profile</italic>, all labels and alias terms of the selected WikiData items are loaded and indexed by the Solr instance. In addition, the buildup of the entity graph for the PageRank computation as well as the buildup of the uni-gram language model is run, followed by the training of the SVM classifier on the extracted NIF dataset. The logical data flow process is visualized in the box <italic toggle="yes">Build Stage</italic> of <xref rid="pdig.0000086.g001" ref-type="fig">Fig 1</xref>.</p>
        <fig position="float" id="pdig.0000086.g001">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.g001</object-id>
          <label>Fig 1</label>
          <caption>
            <title>Visualization of logical data flow: The box “Build Stage” describes the components for data generation and preparation.</title>
            <p>The box “Runtime Stage” illustrates the processing of an annotation request. The components of OpenTapioca and Apache Solr are shared during build and runtime stage.</p>
          </caption>
          <graphic xlink:href="pdig.0000086.g001" position="float"/>
        </fig>
        <p>The build pipeline eventually outputs a single package file that is needed for the instant deployment of the annotation service.</p>
      </sec>
    </sec>
    <sec id="sec015">
      <title>Service</title>
      <p>The annotation service provides a platform for text input processing through an HTTP-based RESTful API as well as through a basic web interface. The implementation integrates the annotation strategy of OpenTapioca and the entity tagging process through an Apache Solr instance. For a successful deployment, the prebuilt file package is required which stores the classifier and language model information as well as the index database of the Solr collection for accelerated entity lookup.</p>
      <p>In addition to the plain text annotation, the service features the processing of PDF documents with options for data input and output. Concerning the data input, the text from a PDF document is extracted in order to apply the entity linking task. Therefore, PDF documents with digital text information can be directly processed. In case of scanned documents that encode their information in an image format, an additional OCR step is applied. The OCR step is based on the Tesseract [<xref rid="pdig.0000086.ref054" ref-type="bibr">54</xref>] software.</p>
      <p>Concerning the data output, the annotation information can be either provided as a machine-readable JSON response or as a PDF document with embedded hyperlinks to the corresponding WikiData item page for all identified mentions. The service provides the option to postprocess the input text and its annotations in order to filter out annotations which are implausible based on their linguistic or structural properties. For instance, one may require the annotations to have at least one word token tagged as a noun in certain scenarios.</p>
      <p>The logical data flow for the annotation service is depicted in the box <italic toggle="yes">Runtime Stage</italic> of <xref rid="pdig.0000086.g001" ref-type="fig">Fig 1</xref>.</p>
    </sec>
    <sec id="sec016">
      <title>Build for medical use case</title>
      <p>We apply the developed build pipeline and annotation service for our central use case for medical text analysis. The computed initialization data for the annotation service was retrieved by our build pipeline for our specified use case.</p>
      <p>One of the most relevant information in medical letters includes data which is associated to symptoms, diagnoses, drugs and medications. Therefore, the entity selection process is managed in the way to cover all WikiData items that represent direct or indirect instances of these concepts in the knowledge base.</p>
      <p>Our strategy to select all relevant entries leverages the graphical structure of the WikiData knowledge base. An item is a part of the knowledge base index if at least one of the following conditions is satisfied:
<list list-type="bullet"><list-item><p>The item has a <italic toggle="yes">Disease Ontology</italic> (P699) statement entry.</p></list-item><list-item><p>The item has an <italic toggle="yes">UMLS CUI</italic> (P2892) statement entry.</p></list-item><list-item><p>The item has a <italic toggle="yes">MeSH descriptor ID</italic> (P486) statement entry.</p></list-item><list-item><p>The item has a <italic toggle="yes">MeSH tree code</italic> (P672) statement entry.</p></list-item><list-item><p>The item is a subclass of <italic toggle="yes">Medication</italic> (P12140).</p></list-item></list></p>
      <p>Since the entity linking task can only detect references to entities that have been indexed through the build pipeline, an effective feature selection contributes crucially to the capabilities of our annotation service. In our medical use case scenario, the need for multiple selection features can be demonstrated by the fact that the WikiData knowledge base can be considered incomplete. For instance, 27786 unique entities with an associated UMLS CUI statement can be found in WikiData at the time of writing. In contrast, the UMLS metathesaurus (2020AB) consists of 15938386 total entries and 4413090 unique CUIs. Adding the <italic toggle="yes">MeSH descriptor ID</italic> (P486) to the UMLS CUI selection feature increases the number of entries by 26932 and therefore can add highly relevant items to the knowledge base despite the problem of missing WikiData UMLS references.</p>
      <p>Using multiple direct features of an item for entity selection, however, only mitigates the described issue. In addition to such direct features, we demonstrate that utilizing the hierarchical internal WikiData structure can be beneficial in order to further reduce the item miss rate due to the lack of data or incomplete data in WikiData items: The item <italic toggle="yes">Medication</italic> (Q12140) is referenced by several other items through the property <italic toggle="yes">Subclass of</italic> (P279), and thus, all items that are a subclass of <italic toggle="yes">Medication</italic> can be directly selected as relevant entries. In this context, not only first order subclass items are included but also all n-degree subclass items from the WikiData hierarchy. For instance the item <italic toggle="yes">Opioid</italic> (Q427523) is selected through the hierarchy path <italic toggle="yes">Medication</italic> ⊆ <italic toggle="yes">Analgesic</italic> ⊆ <italic toggle="yes">Opioid</italic> where ⊆ is a <italic toggle="yes">Subclass of</italic> reference.</p>
      <p>The build pipeline was executed for an German OpenTapioca profile with the formerly mentioned item selection features. The processing and training was performed on an 8-core Intel Xeon Silver 4210 virtual machine with 128GB memory. The computation times for various pipeline substages are depicted in <xref rid="pdig.0000086.t001" ref-type="table">Table 1</xref>. While later substages depend on the defined OpenTapioca profile and require recomputation on profile changes, earlier substages are independent of profile changes. Regarding multicore scaling, parts of the pipeline support the multiprocess architecture model. The computation times vary based on the number of WikiData entities and Wikipedia pages. For the presented computation times, the NIF generation stage processed 95.1M WikiData entities and 5.6M German Wikipedia pages.</p>
      <table-wrap position="float" id="pdig.0000086.t001">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Build Processing Times.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000086.t001" id="pdig.0000086.t001g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Stage</th>
                <th align="left" rowspan="1" colspan="1">Substage</th>
                <th align="left" rowspan="1" colspan="1">Time</th>
                <th align="left" rowspan="1" colspan="1">Multicore</th>
                <th align="left" rowspan="1" colspan="1">Profile</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">NIF &amp; OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Data download</td>
                <td align="left" rowspan="1" colspan="1">5h</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">NIF</td>
                <td align="left" rowspan="1" colspan="1">Page &amp; redirect extraction</td>
                <td align="left" rowspan="1" colspan="1">2h</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">NIF</td>
                <td align="left" rowspan="1" colspan="1">Entity extraction</td>
                <td align="left" rowspan="1" colspan="1">16h</td>
                <td align="left" rowspan="1" colspan="1">yes</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">NIF</td>
                <td align="left" rowspan="1" colspan="1">Entity filtering</td>
                <td align="left" rowspan="1" colspan="1">24m</td>
                <td align="left" rowspan="1" colspan="1">yes</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">NIF</td>
                <td align="left" rowspan="1" colspan="1">Pagelinks extraction</td>
                <td align="left" rowspan="1" colspan="1">106h</td>
                <td align="left" rowspan="1" colspan="1">yes</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">NIF</td>
                <td align="left" rowspan="1" colspan="1">NIF file generation</td>
                <td align="left" rowspan="1" colspan="1">1h</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">dependent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Language model creation</td>
                <td align="left" rowspan="1" colspan="1">16h</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Link extraction</td>
                <td align="left" rowspan="1" colspan="1">15h</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Link sorting</td>
                <td align="left" rowspan="1" colspan="1">45s</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Link sparse matrix conversion</td>
                <td align="left" rowspan="1" colspan="1">24m</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Page rank computation</td>
                <td align="left" rowspan="1" colspan="1">26m</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">independent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Entity indexing</td>
                <td align="left" rowspan="1" colspan="1">11h</td>
                <td align="left" rowspan="1" colspan="1">no</td>
                <td align="left" rowspan="1" colspan="1">dependent</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OpenTapioca</td>
                <td align="left" rowspan="1" colspan="1">Classifier training</td>
                <td align="left" rowspan="1" colspan="1">2m</td>
                <td align="left" rowspan="1" colspan="1">partly</td>
                <td align="left" rowspan="1" colspan="1">dependent</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p>Build times for German medical use case: NIF-based substages interact with a MongoDB database. MongoDB supports read operations on multiple cores. Profile-dependent stages require recomputation on profile changes.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>As described in the previous chapter, our annotation service exposes a simple HTTP REST interface as well as a graphical web interface. The web interface is depicted in <xref rid="pdig.0000086.g002" ref-type="fig">Fig 2</xref> for an in-browser text annotation of an anonymized text snippet from the MIMIC-III [<xref rid="pdig.0000086.ref049" ref-type="bibr">49</xref>] dataset. For demonstration purposes, we created a PDF document with the same text content and submitted the document to the PDF upload interface to retrieve an annotated PDF document with its embedded annotation links as output. The result is shown in <xref rid="pdig.0000086.g003" ref-type="fig">Fig 3</xref>.</p>
      <fig position="float" id="pdig.0000086.g002">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Demo for web interface.</title>
          <p>Browser-based annotation on example data from the MIMIC-III [<xref rid="pdig.0000086.ref049" ref-type="bibr">49</xref>] dataset.</p>
        </caption>
        <graphic xlink:href="pdig.0000086.g002" position="float"/>
      </fig>
      <fig position="float" id="pdig.0000086.g003">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Demo for PDF annotation.</title>
          <p>A PDF page demo with embedded annotations on example data from MIMIC-III [<xref rid="pdig.0000086.ref049" ref-type="bibr">49</xref>] dataset.</p>
        </caption>
        <graphic xlink:href="pdig.0000086.g003" position="float"/>
      </fig>
      <p>Our pretrained data for an instant service deployment as well as the source code is available at our project repository page at <ext-link xlink:href="https://github.com/frankkramer-lab/DrNote" ext-link-type="uri">https://github.com/frankkramer-lab/DrNote</ext-link>.</p>
    </sec>
    <sec id="sec017">
      <title>Performance evaluation</title>
      <p>To evaluate the annotation performance we compare our method with Apache cTAKES (version 4.0.0.1) and PubTator (<ext-link xlink:href="https://www.ncbi.nlm.nih.gov/research/pubtator/api.html" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/research/pubtator/api.html</ext-link>) as baseline. Since our method is designed for multilingual use cases and for non-English data in specific, we focus on German text data for performance comparisons. To avoid inadequate evaluation issues such as missing UMLS references or ambiguous mappings between non-isomorphic knowledge bases, we consider the annotation task as a binary text segmentation task at which the annotation spans define the binary segmentation mask. For clinical contexts, we randomly drew 50 samples from the GERNERMED [<xref rid="pdig.0000086.ref055" ref-type="bibr">55</xref>] test set and manually corrected incorrect annotation spans, since the dataset is based on an automated translation of the <italic toggle="yes">n2c2 2018 ADE and Medication Extraction Challenge</italic> [<xref rid="pdig.0000086.ref050" ref-type="bibr">50</xref>] dataset with automated annotation alignments. All labels except for <italic toggle="yes">Drug</italic> were omitted for comparison reasons.</p>
      <p>In order to quantify the domain-shift bias in non-clinical contexts on the biomedical <italic toggle="yes">Mantra GSC</italic> [<xref rid="pdig.0000086.ref056" ref-type="bibr">56</xref>] datasets. In these datasets, the annotations are linked to their corresponding UMLS entries. Since WikiData lacks large parts of the UMLS references mentioned (Medline: 90 out of 309 UMLS concepts known, EMEA: 121 out of 425 UMLS concepts known), the DrNote scores are also evaluated on a filtered set of UMLS annotations that are reference in WikiData, yet in all setups, DrNote annotations were limited to entities that are subclasses (P279) or instances of (P31) of medications (Q12140) for comparison reasons. Apache cTAKES uses the UMLS metathesaurus directly and therefore does not suffer from incomplete UMLS data. Given its focus on biomedical texts, PubTator supports the entity concepts <italic toggle="yes">gene</italic>, <italic toggle="yes">disease</italic>, <italic toggle="yes">chemical</italic>, <italic toggle="yes">species</italic>, <italic toggle="yes">mutation</italic> and <italic toggle="yes">cellline</italic>. The entity concept chemicals is identified by PubTator through a search-based dictionary lookup in the MeSH thesaurus.</p>
      <p>The evaluation results are given as f1 scores based on the character-level text segmentation masks from the ground truth (GT) and the predicted segmentation in <xref rid="pdig.0000086.t002" ref-type="table">Table 2</xref>.</p>
      <table-wrap position="float" id="pdig.0000086.t002">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Annotation Performance Evaluation.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000086.t002" id="pdig.0000086.t002g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Dataset</th>
                <th align="left" rowspan="1" colspan="1">Method</th>
                <th align="center" rowspan="1" colspan="1">F1 score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">GERNERMED</td>
                <td align="left" rowspan="1" colspan="1">cTAKES</td>
                <td align="char" char="." rowspan="1" colspan="1">0.632</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GERNERMED</td>
                <td align="left" rowspan="1" colspan="1">DrNote</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.722</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GERENRMED</td>
                <td align="left" rowspan="1" colspan="1">PubTator</td>
                <td align="char" char="." rowspan="1" colspan="1">0.523</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Medline GSC</td>
                <td align="left" rowspan="1" colspan="1">cTAKES</td>
                <td align="char" char="." rowspan="1" colspan="1">0.148</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Medline GSC</td>
                <td align="left" rowspan="1" colspan="1">DrNote</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.226</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Medline GSC</td>
                <td align="left" rowspan="1" colspan="1">PubTator</td>
                <td align="char" char="." rowspan="1" colspan="1">0.123</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EMEA GSC</td>
                <td align="left" rowspan="1" colspan="1">cTAKES</td>
                <td align="char" char="." rowspan="1" colspan="1">0.162</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EMEA GSC</td>
                <td align="left" rowspan="1" colspan="1">DrNote</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.261</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EMEA GSC</td>
                <td align="left" rowspan="1" colspan="1">PubTator</td>
                <td align="char" char="." rowspan="1" colspan="1">0.0728</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Medline GSC</td>
                <td align="left" rowspan="1" colspan="1">DrNote (filtered)</td>
                <td align="char" char="." rowspan="1" colspan="1">0.414</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EMEA GSC</td>
                <td align="left" rowspan="1" colspan="1">DrNote (filtered)</td>
                <td align="char" char="." rowspan="1" colspan="1">0.503</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>Evaluation results of cTAKES, PubTator and DrNote (ours) on various datasets. Filtered results exclude annotations from the ground truth if their corresponding UMLS CUI is not referenced in WikiData.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>While our method exhibits substantially better text segmentation f1 score performance in comparison to cTAKES and PubTator, and demonstrates considerable results on the clinical dataset, all methods show subpar results on biomedical datasets. We mainly attribute this circumstance to the fact that both biomedical datasets include annotation phrases in part-of-speech (PoS) forms other than nouns, in which case both methods tend to fail. While cTAKES and PubTator are incapable of German word stemming due to the focus on English, our method relies on the nominalized WikiData labels and fails for similar reasons. However, our method seems to perform better on all datasets which we attribute to the broader set of common alias labels in WikiData compared to the related UMLS or MeSH entry labels as illustrated in <xref rid="pdig.0000086.g004" ref-type="fig">Fig 4</xref>. In contrast to cTAKES, our method can also use linguistic information to avoid obvious PoS-related annotation errors as shown in <xref rid="pdig.0000086.g005" ref-type="fig">Fig 5</xref>. cTAKES is still able to detect certain German UMLS entities due to the fact that the German language represents the largest non-English language in the UMLS metathesaurus, however PubTator uses the English MeSH database and does not include the German MeSH terms. Conversely, PubTator is able to detect specialized codes from MeSH whereas cTAKES does not detect certain codes (<xref rid="pdig.0000086.g006" ref-type="fig">Fig 6</xref>) although the displayed code <italic toggle="yes">RAD001</italic> is present in the UMLS database. With respect to our method, we also identified scenarios in which correct annotations were skipped due to our filter mechanism meant to exclude non-medication items as shown in <xref rid="pdig.0000086.g007" ref-type="fig">Fig 7</xref>. For this particular instance, the item <italic toggle="yes">Steroid</italic> had been annotated correctly, yet due to the structure in the WikiData graph, the item (Q177911) is not classified as being a subclass or instance of medication and skipped for that reason.</p>
      <fig position="float" id="pdig.0000086.g004">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Comparative Sample 1 and 2.</title>
          <p>Specialized German term missing in UMLS or MeSH, (<italic toggle="yes">Laktulose</italic>,<italic toggle="yes">Protonenpumpenhemmer</italic>, cTAKES &amp; PubTator).</p>
        </caption>
        <graphic xlink:href="pdig.0000086.g004" position="float"/>
      </fig>
      <fig position="float" id="pdig.0000086.g005">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Comparative Sample 3.</title>
          <p>Artifacts from lack of German linguistics (<italic toggle="yes">Das</italic>, cTAKES).</p>
        </caption>
        <graphic xlink:href="pdig.0000086.g005" position="float"/>
      </fig>
      <fig position="float" id="pdig.0000086.g006">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>Comparative Sample 4.</title>
          <p>Weakness of cTAKES to detect certain codes (<italic toggle="yes">RAD001</italic>, cTAKES).</p>
        </caption>
        <graphic xlink:href="pdig.0000086.g006" position="float"/>
      </fig>
      <fig position="float" id="pdig.0000086.g007">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000086.g007</object-id>
        <label>Fig 7</label>
        <caption>
          <title>Comparative Sample 5.</title>
          <p>Ignored annotations due to WikiData graph structure (<italic toggle="yes">Steroid</italic> as no subclass/instance of medication), DrNote).</p>
        </caption>
        <graphic xlink:href="pdig.0000086.g007" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec018">
    <title>Discussion</title>
    <p>Considering the dire state of natural language processing tools with support for multi-language data input in the medical context, the presented annotation service can offer useful services for research applications and related text analysis tasks. Inherently to the chosen dictionary-based entity detection and linking approach, the capabilities of the service as well as its limitations exclude the tool for certain tasks: The entity detection method is limited to only recognize entities that are part of the WikiData knowledge base label and alias term sets, excluding semantically related terms or slightly altered, corrupted terms that are closely related to their correct term when evaluated on the Levenshtein distance metric. A potential remedy for this issue can be the use of a spellchecker component. The entity disambiguation step cannot reject false positive mentions in situations where the entity candidate presents imprecise label or alias values. For instance, the item <italic toggle="yes">Universe</italic> (Q1) contains the word <italic toggle="yes">all</italic> as an alias value. Subsequently, <italic toggle="yes">all</italic> will be linked to Q1 in the case that Q1 was previously included by the entity selection step. To effectively counter such artifacts, a deeper semantic understanding is required. However, the buildup of semantic understanding is mostly handled by utilizing large training data from certain target domains and poses a major disadvantage of data-driven methods since large datasets can be challenging to obtain and may jeopardize robust multi-language support. By offering advanced annotation filter rules based on linguistic features through SpaCy, this may alleviate the problem in situations where a pretrained SpaCy pipeline is available for the corresponding text language.</p>
    <p>Currently, our approach is strictly tied to the label and alias terms from WikiData that are typically nominalized. Therefore, relevant terms in different part-of-speech configurations such as adjectives cannot be detected due to the lack of language-dependent stemming or lemmatization. Further work on such improvements is considered future work.</p>
    <p>The synthesis of the annotated dataset of relevant mentions from the Wikipedia and WikiData datasets and its transformation into the NIF file format only considers links of mentions at a page to another referenced page whenever the link was inserted manually by a Wikipedia author. In frequent cases, only the first mention of a referenced concept is linked by the authors on the page, despite the fact that the mention text may appear multiple times on the same Wikipedia page. This may induce lower recall scores in contrast to a complete and manual annotation. Our mitigation approach reduces the probability of including false negative terms by only extracting single sentences from the Wikipedia page texts.</p>
  </sec>
  <sec sec-type="conclusions" id="sec019">
    <title>Conclusion</title>
    <p>In this work we introduced our annotation service DrNote as an open platform for entity linking in the context of medical text processing with multi-language support. The annotation service can operate directly on precomputed initialization data which are provided for instant deployment. An fully automated build pipeline was presented to enable users to customize the annotation service for specific needs while the generated dataset solely relies on open public data. We presented the feature support for PDF document processing and annotation as well as the integration of SpaCy for advanced linguistic-based annotation filtering.</p>
    <p>Common limitations of the chosen entity linking approach were further discussed as well as its conceptual drawback compared to competing data-driven approaches. While purely data-driven approaches may enable huge advancements over traditional approaches, their individual applicability for certain languages in the medical context remains to be challenging due to the lack of sufficiently large training data. Privacy concerns and legal restrictions for data use and access may hinder further improvements on the availability of such datasets in the future.</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pdig.0000086.ref001">
      <label>1</label>
      <mixed-citation publication-type="other">Mikolov T, Chen K, Corrado G, Dean J. Efficient Estimation of Word Representations in Vector Space. In: 1st International Conference on Learning Representations, ICLR 2013, Scottsdale, Arizona, USA, May 2-4, 2013, Workshop Track Proceedings; 2013.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref002">
      <label>2</label>
      <mixed-citation publication-type="other">Pennington J, Socher R, Manning CD. Glove: Global Vectors for Word Representation. In: Moschitti A, Pang B, Daelemans W, editors. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL. ACL; 2014. p. 1532–1543.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref003">
      <label>3</label>
      <mixed-citation publication-type="other">Peters ME, Neumann M, Iyyer M, Gardner M, Clark C, Lee K, et al. Deep Contextualized Word Representations. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). New Orleans, Louisiana: Association for Computational Linguistics; 2018. p. 2227–2237.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref004">
      <label>4</label>
      <mixed-citation publication-type="other">Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:181004805 [cs]. 2019;.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Vaswani</surname><given-names>A</given-names></name>, <name><surname>Shazeer</surname><given-names>N</given-names></name>, <name><surname>Parmar</surname><given-names>N</given-names></name>, <name><surname>Uszkoreit</surname><given-names>J</given-names></name>, <name><surname>Jones</surname><given-names>L</given-names></name>, <name><surname>Gomez</surname><given-names>AN</given-names></name>, <etal>et al</etal>. <article-title>Attention is all you need</article-title>. <source>Advances in neural information processing systems</source>. <year>2017</year>;<volume>30</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref006">
      <label>6</label>
      <mixed-citation publication-type="book"><name><surname>Peng</surname><given-names>Y</given-names></name>, <name><surname>Yan</surname><given-names>S</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <part-title>Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets</part-title>. In: <source>Proceedings of the 18th BioNLP Workshop and Shared Task</source>. <publisher-loc>Florence, Italy</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>; <year>2019</year>. p. <fpage>58</fpage>–<lpage>65</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Rasmy</surname><given-names>L</given-names></name>, <name><surname>Xiang</surname><given-names>Y</given-names></name>, <name><surname>Xie</surname><given-names>Z</given-names></name>, <name><surname>Tao</surname><given-names>C</given-names></name>, <name><surname>Zhi</surname><given-names>D</given-names></name>. <article-title>Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction</article-title>. <source>npj Digital Medicine</source>. <year>2021</year>;<volume>4</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41746-021-00455-y</pub-id><?supplied-pmid 34017034?><pub-id pub-id-type="pmid">33398041</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref008">
      <label>8</label>
      <mixed-citation publication-type="other">Beltagy I, Lo K, Cohan A. SciBERT: A Pretrained Language Model for Scientific Text. In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Hong Kong, China: Association for Computational Linguistics; 2019. p. 3615–3620.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref009">
      <label>9</label>
      <mixed-citation publication-type="book"><name><surname>Alsentzer</surname><given-names>E</given-names></name>, <name><surname>Murphy</surname><given-names>J</given-names></name>, <name><surname>Boag</surname><given-names>W</given-names></name>, <name><surname>Weng</surname><given-names>WH</given-names></name>, <name><surname>Jindi</surname><given-names>D</given-names></name>, <name><surname>Naumann</surname><given-names>T</given-names></name>, <etal>et al</etal>. <part-title>Publicly Available Clinical BERT Embeddings</part-title>. In: <source>Proceedings of the 2nd Clinical Natural Language Processing Workshop</source>. <publisher-loc>Minneapolis, Minnesota, USA</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>; <year>2019</year>. p. <fpage>72</fpage>–<lpage>78</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Yoon</surname><given-names>W</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Kim</surname><given-names>D</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>So</surname><given-names>CH</given-names></name>, <etal>et al</etal>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1234</fpage>–<lpage>1240</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id><?supplied-pmid 31501885?><pub-id pub-id-type="pmid">31501885</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>F</given-names></name>, <name><surname>Jin</surname><given-names>Y</given-names></name>, <name><surname>Liu</surname><given-names>W</given-names></name>, <name><surname>Rawat</surname><given-names>BPS</given-names></name>, <name><surname>Cai</surname><given-names>P</given-names></name>, <name><surname>Yu</surname><given-names>H</given-names></name>. <article-title>Fine-Tuning Bidirectional Encoder Representations From Transformers (BERT)–Based Models on Large-Scale Electronic Health Record Notes: An Empirical Study</article-title>. <source>JMIR Medical Informatics</source>. <year>2019</year>;<volume>7</volume>(<issue>3</issue>):<fpage>e14830</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/14830</pub-id><?supplied-pmid 31516126?><pub-id pub-id-type="pmid">31516126</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref012">
      <label>12</label>
      <mixed-citation publication-type="book"><name><surname>Kamath</surname><given-names>U</given-names></name>, <name><surname>Liu</surname><given-names>J</given-names></name>, <name><surname>Whitaker</surname><given-names>J</given-names></name>. <source>Deep learning for NLP and speech recognition</source>. <volume>vol. 84</volume>. <publisher-name>Springer</publisher-name>; <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Liang</surname><given-names>H</given-names></name>, <name><surname>Tsui</surname><given-names>BY</given-names></name>, <name><surname>Ni</surname><given-names>H</given-names></name>, <name><surname>Valentim</surname><given-names>CCS</given-names></name>, <name><surname>Baxter</surname><given-names>SL</given-names></name>, <name><surname>Liu</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence</article-title>. <source>Nature Medicine</source>. <year>2019</year>;<volume>25</volume>(<issue>3</issue>):<fpage>433</fpage>–<lpage>438</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-018-0335-9</pub-id><?supplied-pmid 30742121?><pub-id pub-id-type="pmid">30742121</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Conneau</surname><given-names>A</given-names></name>, <name><surname>Lample</surname><given-names>G</given-names></name>. <article-title>Cross-lingual language model pretraining</article-title>. <source>Advances in neural information processing systems</source>. <year>2019</year>;<volume>32</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref015">
      <label>15</label>
      <mixed-citation publication-type="book"><name><surname>Conneau</surname><given-names>A</given-names></name>, <name><surname>Khandelwal</surname><given-names>K</given-names></name>, <name><surname>Goyal</surname><given-names>N</given-names></name>, <name><surname>Chaudhary</surname><given-names>V</given-names></name>, <name><surname>Wenzek</surname><given-names>G</given-names></name>, <name><surname>Guzmán</surname><given-names>F</given-names></name>, <etal>et al</etal>. <part-title>Unsupervised Cross-lingual Representation Learning at Scale</part-title>. In: <source>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</source>. <publisher-name>Online: Association for Computational Linguistics</publisher-name>; <year>2020</year>. p. <fpage>8440</fpage>–<lpage>8451</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref016">
      <label>16</label>
      <mixed-citation publication-type="other">Explosion AI Gmbh. SpaCy: Industrial-Strength Natural Language Processing; 2022. <ext-link xlink:href="https://spacy.io/" ext-link-type="uri">https://spacy.io/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref017">
      <label>17</label>
      <mixed-citation publication-type="book"><name><surname>Manning</surname><given-names>C</given-names></name>, <name><surname>Surdeanu</surname><given-names>M</given-names></name>, <name><surname>Bauer</surname><given-names>J</given-names></name>, <name><surname>Finkel</surname><given-names>J</given-names></name>, <name><surname>Bethard</surname><given-names>S</given-names></name>, <name><surname>McClosky</surname><given-names>D</given-names></name>. <part-title>The Stanford CoreNLP Natural Language Processing Toolkit</part-title>. In: <source>Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</source>. <publisher-loc>Baltimore, Maryland</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>; <year>2014</year>. p. <fpage>55</fpage>–<lpage>60</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref018">
      <label>18</label>
      <mixed-citation publication-type="other">Qi P, Zhang Y, Zhang Y, Bolton J, Manning CD. Stanza: A Python Natural Language Processing Toolkit for Many Human Languages. In: ACL; 2020.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Qi</surname><given-names>P</given-names></name>, <name><surname>Manning</surname><given-names>CD</given-names></name>, <name><surname>Langlotz</surname><given-names>CP</given-names></name>. <article-title>Biomedical and clinical English model packages for the Stanza Python NLP library</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2021</year>;<volume>28</volume>(<issue>9</issue>):<fpage>1892</fpage>–<lpage>1899</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/jamia/ocab090</pub-id><?supplied-pmid 34157094?><pub-id pub-id-type="pmid">34157094</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref020">
      <label>20</label>
      <mixed-citation publication-type="other">Roller R, Alt C, Seiffe L, Wang H. mEx—An Information Extraction Platform for German Medical Text. In: Proceedings of the 11th International Conference on Semantic Web Applications and Tools for Healthcare and Life Sciences (SWAT4HCLS’2018). Semantic Web Applications and Tools for Healthcare and Life Sciences (SWAT4HCLS-2018), December 3-5, Antwerp, Belgium; 2018.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Hahn</surname><given-names>U</given-names></name>, <name><surname>Romacker</surname><given-names>M</given-names></name>, <name><surname>Schulz</surname><given-names>S</given-names></name>. <article-title>medSynDiKATe—a natural language system for the extraction of medical information from findings reports</article-title>. <source>International Journal of Medical Informatics</source>. <year>2002</year>;<volume>67</volume>(<issue>1</issue>):<fpage>63</fpage>–<lpage>74</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S1386-5056(02)00053-9</pub-id><?supplied-pmid 12460632?><pub-id pub-id-type="pmid">12460632</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Savova</surname><given-names>GK</given-names></name>, <name><surname>Masanz</surname><given-names>JJ</given-names></name>, <name><surname>Ogren</surname><given-names>PV</given-names></name>, <name><surname>Zheng</surname><given-names>J</given-names></name>, <name><surname>Sohn</surname><given-names>S</given-names></name>, <name><surname>Kipper-Schuler</surname><given-names>KC</given-names></name>, <etal>et al</etal>. <article-title>Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications</article-title>. <source>Journal of the American Medical Informatics Association: JAMIA</source>. <year>2010</year>;<volume>17</volume>(<issue>5</issue>):<fpage>507</fpage>–<lpage>513</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/jamia.2009.001560</pub-id><?supplied-pmid 20819853?><pub-id pub-id-type="pmid">20819853</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref023">
      <label>23</label>
      <mixed-citation publication-type="other">Apache Foundation. Apache OpenNLP; 2022. <ext-link xlink:href="https://opennlp.apache.org/" ext-link-type="uri">https://opennlp.apache.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref024">
      <label>24</label>
      <mixed-citation publication-type="book"><name><surname>Becker</surname><given-names>M</given-names></name>, <name><surname>Böckmann</surname><given-names>B</given-names></name>. <part-title>Extraction of UMLS concepts using Apache cTAKES for German language</part-title>. In: <name><surname>Schreier</surname><given-names>G</given-names></name>, <name><surname>Ammenwerth</surname><given-names>E</given-names></name>, <name><surname>Hörbst</surname><given-names>A</given-names></name>, editors. <source>Health Informatics Meets eHealth. vol. 223 of Studies in Health Technology and Informatics</source>. <publisher-name>IOS Press</publisher-name>; <year>2016</year>. p. <fpage>71</fpage>–<lpage>76</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Zeng</surname><given-names>QT</given-names></name>, <name><surname>Goryachev</surname><given-names>S</given-names></name>, <name><surname>Weiss</surname><given-names>S</given-names></name>, <name><surname>Sordo</surname><given-names>M</given-names></name>, <name><surname>Murphy</surname><given-names>SN</given-names></name>, <name><surname>Lazarus</surname><given-names>R</given-names></name>. <article-title>Extracting principal diagnosis, co-morbidity and smoking status for asthma research: evaluation of a natural language processing system</article-title>. <source>BMC Medical Informatics and Decision Making</source>. <year>2006</year>;<volume>6</volume>(<issue>1</issue>):<fpage>30</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/1472-6947-6-30</pub-id><?supplied-pmid 16872495?><pub-id pub-id-type="pmid">16872495</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Cunningham</surname><given-names>H</given-names></name>, <name><surname>Tablan</surname><given-names>V</given-names></name>, <name><surname>Roberts</surname><given-names>A</given-names></name>, <name><surname>Bontcheva</surname><given-names>K</given-names></name>. <article-title>Getting More Out of Biomedical Documents with GATE’s Full Lifecycle Open Source Text Analytics</article-title>. <source>PLOS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>2</issue>):<fpage>e1002854</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002854</pub-id><?supplied-pmid 23408875?><pub-id pub-id-type="pmid">23408875</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Aronson</surname><given-names>AR</given-names></name>, <name><surname>Lang</surname><given-names>FM</given-names></name>. <article-title>An overview of MetaMap: historical perspective and recent advances</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2010</year>;<volume>17</volume>(<issue>3</issue>):<fpage>229</fpage>–<lpage>236</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/jamia.2009.002733</pub-id><?supplied-pmid 20442139?><pub-id pub-id-type="pmid">20442139</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>CH</given-names></name>, <name><surname>Kao</surname><given-names>HY</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>PubTator: a web-based text mining tool for assisting biocuration</article-title>. <source>Nucleic Acids Research</source>. <year>2013</year>;<volume>41</volume>(<issue>W1</issue>):<fpage>W518</fpage>–<lpage>W522</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkt441</pub-id><?supplied-pmid 23703206?><pub-id pub-id-type="pmid">23703206</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref029">
      <label>29</label>
      <mixed-citation publication-type="other">Averbis Gmbh. Averbis Health Discovery; 2022. <ext-link xlink:href="https://averbis.com/de/health-discovery/" ext-link-type="uri">https://averbis.com/de/health-discovery/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Névéol</surname><given-names>A</given-names></name>, <name><surname>Dalianis</surname><given-names>H</given-names></name>, <name><surname>Velupillai</surname><given-names>S</given-names></name>, <name><surname>Savova</surname><given-names>G</given-names></name>, <name><surname>Zweigenbaum</surname><given-names>P</given-names></name>. <article-title>Clinical Natural Language Processing in languages other than English: opportunities and challenges</article-title>. <source>Journal of Biomedical Semantics</source>. <year>2018</year>;<volume>9</volume>(<issue>1</issue>):<fpage>12</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13326-018-0179-8</pub-id><?supplied-pmid 29602312?><pub-id pub-id-type="pmid">29602312</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Percha</surname><given-names>B</given-names></name>. <article-title>Modern Clinical Text Mining: A Guide and Review</article-title>. <source>Annual Review of Biomedical Data Science</source>. <year>2021</year>;<volume>4</volume>:<fpage>165</fpage>–<lpage>187</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1146/annurev-biodatasci-030421-030931</pub-id><?supplied-pmid 34465177?><pub-id pub-id-type="pmid">34465177</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Fu</surname><given-names>S</given-names></name>, <name><surname>Chen</surname><given-names>D</given-names></name>, <name><surname>He</surname><given-names>H</given-names></name>, <name><surname>Liu</surname><given-names>S</given-names></name>, <name><surname>Moon</surname><given-names>S</given-names></name>, <name><surname>Peterson</surname><given-names>KJ</given-names></name>, <etal>et al</etal>. <article-title>Clinical concept extraction: A methodology review</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2020</year>;<volume>109</volume>:<fpage>103526</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jbi.2020.103526</pub-id><?supplied-pmid 32768446?><pub-id pub-id-type="pmid">32768446</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Fries</surname><given-names>JA</given-names></name>, <name><surname>Steinberg</surname><given-names>E</given-names></name>, <name><surname>Khattar</surname><given-names>S</given-names></name>, <name><surname>Fleming</surname><given-names>SL</given-names></name>, <name><surname>Posada</surname><given-names>J</given-names></name>, <name><surname>Callahan</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Ontology-driven weak supervision for clinical entity classification in electronic health records</article-title>. <source>Nature Communications</source>. <year>2021</year>;<volume>12</volume>(<issue>1</issue>):<fpage>2017</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41467-021-22328-4</pub-id><?supplied-pmid 33795682?><pub-id pub-id-type="pmid">33795682</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref034">
      <label>34</label>
      <mixed-citation publication-type="other">Kulkarni S, Singh A, Ramakrishnan G, Chakrabarti S. Collective annotation of Wikipedia entities in web text. In: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. KDD’09. New York, NY, USA: Association for Computing Machinery; 2009. p. 457–466.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref035">
      <label>35</label>
      <mixed-citation publication-type="other">Mihalcea R, Csomai A. Wikify! linking documents to encyclopedic knowledge. In: Proceedings of the sixteenth ACM conference on Conference on information and knowledge management. CIKM’07. New York, NY, USA: Association for Computing Machinery; 2007. p. 233–242.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref036">
      <label>36</label>
      <mixed-citation publication-type="other">Milne D, Witten IH. Learning to link with wikipedia. In: Proceedings of the 17th ACM conference on Information and knowledge management. CIKM’08. New York, NY, USA: Association for Computing Machinery; 2008. p. 509–518.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref037">
      <label>37</label>
      <mixed-citation publication-type="other">Ferragina P, Scaiella U. TAGME: on-the-fly annotation of short text fragments (by wikipedia entities). In: Proceedings of the 19th ACM international conference on Information and knowledge management. CIKM’10. New York, NY, USA: Association for Computing Machinery; 2010. p. 1625–1628.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Vrandečić</surname><given-names>D</given-names></name>, <name><surname>Krötzsch</surname><given-names>M</given-names></name>. <article-title>Wikidata: a free collaborative knowledgebase</article-title>. <source>Communications of the ACM</source>. <year>2014</year>;<volume>57</volume>(<issue>10</issue>):<fpage>78</fpage>–<lpage>85</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1145/2629489</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Hachey</surname><given-names>B</given-names></name>, <name><surname>Radford</surname><given-names>W</given-names></name>, <name><surname>Nothman</surname><given-names>J</given-names></name>, <name><surname>Honnibal</surname><given-names>M</given-names></name>, <name><surname>Curran</surname><given-names>JR</given-names></name>. <article-title>Evaluating Entity Linking with Wikipedia</article-title>. <source>Artificial Intelligence</source>. <year>2013</year>;<volume>194</volume>:<fpage>130</fpage>–<lpage>150</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.artint.2012.04.005</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref040">
      <label>40</label>
      <mixed-citation publication-type="other">Bollacker K, Evans C, Paritosh P, Sturge T, Taylor J. Freebase: a collaboratively created graph database for structuring human knowledge. In: Proceedings of the 2008 ACM SIGMOD international conference on Management of data. SIGMOD’08. New York, NY, USA: Association for Computing Machinery; 2008. p. 1247–1250.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Auer</surname><given-names>S</given-names></name>, <name><surname>Bizer</surname><given-names>C</given-names></name>, <name><surname>Kobilarov</surname><given-names>G</given-names></name>, <name><surname>Lehmann</surname><given-names>J</given-names></name>, <name><surname>Cyganiak</surname><given-names>R</given-names></name>, <name><surname>Ives</surname><given-names>Z</given-names></name>. <article-title>DBpedia: A Nucleus for a Web of Open Data</article-title>. <source>The Semantic Web</source>. <year>2007</year>; p. <fpage>722</fpage>–<lpage>735</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/978-3-540-76298-0_52</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref042">
      <label>42</label>
      <mixed-citation publication-type="other">Suchanek FM, Kasneci G, Weikum G. Yago: a core of semantic knowledge. In: Proceedings of the 16th international conference on World Wide Web. WWW’07. New York, NY, USA: Association for Computing Machinery; 2007. p. 697–706.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Hoffart</surname><given-names>J</given-names></name>, <name><surname>Suchanek</surname><given-names>FM</given-names></name>, <name><surname>Berberich</surname><given-names>K</given-names></name>, <name><surname>Weikum</surname><given-names>G</given-names></name>. <article-title>YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia</article-title>. <source>Artificial Intelligence</source>. <year>2013</year>;<volume>194</volume>:<fpage>28</fpage>–<lpage>61</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.artint.2012.06.001</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref044">
      <label>44</label>
      <mixed-citation publication-type="book"><name><surname>Piccinno</surname><given-names>F</given-names></name>, <name><surname>Ferragina</surname><given-names>P</given-names></name>. <part-title>From TagME to WAT: a new entity annotator</part-title>. In: <source>Proceedings of the first international workshop on Entity recognition &amp; disambiguation. ERD’14</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>; <year>2014</year>. p. <fpage>55</fpage>–<lpage>62</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Ponza</surname><given-names>M</given-names></name>, <name><surname>Ferragina</surname><given-names>P</given-names></name>, <name><surname>Piccinno</surname><given-names>F</given-names></name>. <article-title>Swat: A system for detecting salient Wikipedia entities in texts</article-title>. <source>Computational Intelligence</source>. <year>2019</year>;<volume>35</volume>(<issue>4</issue>):<fpage>858</fpage>–<lpage>890</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/coin.12216</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Kolitsas</surname><given-names>N</given-names></name>, <name><surname>Ganea</surname><given-names>OE</given-names></name>, <name><surname>Hofmann</surname><given-names>T</given-names></name>. <article-title>End-to-End Neural Entity Linking</article-title>. <source>CoRR</source>. <year>2018</year>;abs/1808.07699.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref047">
      <label>47</label>
      <mixed-citation publication-type="other">Kannan Ravi MP, Singh K, Mulang’ IO, Shekarpour S, Hoffart J, Lehmann J. CHOLAN: A Modular Approach for Neural Entity Linking on Wikipedia and Wikidata. In: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. Online: Association for Computational Linguistics; 2021. p. 504–514.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref048">
      <label>48</label>
      <mixed-citation publication-type="other">van Hulst JM, Hasibi F, Dercksen K, Balog K, de Vries AP. REL: An Entity Linker Standing on the Shoulders of Giants. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. New York, NY, USA: Association for Computing Machinery; 2020. p. 2197–2200.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref049">
      <label>49</label>
      <mixed-citation publication-type="journal"><name><surname>Johnson</surname><given-names>AEW</given-names></name>, <name><surname>Pollard</surname><given-names>TJ</given-names></name>, <name><surname>Shen</surname><given-names>L</given-names></name>, <name><surname>Lehman</surname><given-names>LwH</given-names></name>, <name><surname>Feng</surname><given-names>M</given-names></name>, <name><surname>Ghassemi</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>MIMIC-III, a freely accessible critical care database</article-title>. <source>Scientific Data</source>. <year>2016</year>;<volume>3</volume>(<issue>1</issue>):<fpage>160035</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/sdata.2016.35</pub-id><?supplied-pmid 27219127?><pub-id pub-id-type="pmid">27219127</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Henry</surname><given-names>S</given-names></name>, <name><surname>Buchan</surname><given-names>K</given-names></name>, <name><surname>Filannino</surname><given-names>M</given-names></name>, <name><surname>Stubbs</surname><given-names>A</given-names></name>, <name><surname>Uzuner</surname><given-names>O</given-names></name>. <article-title>2018 n2c2 shared task on adverse drug events and medication extraction in electronic health records</article-title>. <source>Journal of the American Medical Informatics Association: JAMIA</source>. <year>2020</year>;<volume>27</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>12</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/jamia/ocz166</pub-id><?supplied-pmid 31584655?><pub-id pub-id-type="pmid">31584655</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref051">
      <label>51</label>
      <mixed-citation publication-type="journal"><name><surname>Starlinger</surname><given-names>J</given-names></name>, <name><surname>Kittner</surname><given-names>M</given-names></name>, <name><surname>Blankenstein</surname><given-names>O</given-names></name>, <name><surname>Leser</surname><given-names>U</given-names></name>. <article-title>How to improve information extraction from German medical records</article-title>. <source>it—Information Technology</source>. <year>2017</year>;<volume>59</volume>(<issue>4</issue>):<fpage>171</fpage>–<lpage>179</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Hellrich</surname><given-names>J</given-names></name>, <name><surname>Matthies</surname><given-names>F</given-names></name>, <name><surname>Faessler</surname><given-names>E</given-names></name>, <name><surname>Hahn</surname><given-names>U</given-names></name>. <article-title>Sharing models and tools for processing German clinical texts</article-title>. <source>Studies in Health Technology and Informatics</source>. <year>2015</year>;<volume>210</volume>:<fpage>734</fpage>–<lpage>738</lpage>. <?supplied-pmid 25991250?><pub-id pub-id-type="pmid">25991250</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref053">
      <label>53</label>
      <mixed-citation publication-type="other">Delpeuch A. OpenTapioca: Lightweight Entity Linking for Wikidata. In: Kaffee LA, Tifrea-Marciuska O, Simperl E, Vrandecic D, editors. Proceedings of the 1st Wikidata Workshop (Wikidata 2020) co-located with 19th International Semantic Web Conference(OPub 2020), Virtual Conference, November 2-6, 2020. vol. 2773 of CEUR Workshop Proceedings. CEUR-WS.org; 2020.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>Kay</surname><given-names>A</given-names></name>. <article-title>Tesseract: an open-source optical character recognition engine</article-title>. <source>Linux Journal</source>. <year>2007</year>;<volume>2007</volume>(<issue>159</issue>):<fpage>2</fpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref055">
      <label>55</label>
      <mixed-citation publication-type="journal"><name><surname>Frei</surname><given-names>J</given-names></name>, <name><surname>Kramer</surname><given-names>F</given-names></name>. <article-title>GERNERMED: An open German medical NER model</article-title>. <source>Software Impacts</source>. <year>2022</year>;<volume>11</volume>:<fpage>100212</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.simpa.2021.100212</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000086.ref056">
      <label>56</label>
      <mixed-citation publication-type="journal"><name><surname>Kors</surname><given-names>JA</given-names></name>, <name><surname>Clematide</surname><given-names>S</given-names></name>, <name><surname>Akhondi</surname><given-names>SA</given-names></name>, <name><surname>van Mulligen</surname><given-names>EM</given-names></name>, <name><surname>Rebholz-Schuhmann</surname><given-names>D</given-names></name>. <article-title>A multilingual gold-standard corpus for biomedical concept recognition: the Mantra GSC</article-title>. <source>Journal of the American Medical Informatics Association: JAMIA</source>. <year>2015</year>;<volume>22</volume>(<issue>5</issue>):<fpage>948</fpage>–<lpage>956</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/jamia/ocv037</pub-id><?supplied-pmid 25948699?><pub-id pub-id-type="pmid">25948699</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pdig.0000086.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000086.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Banerjee</surname>
          <given-names>Imon</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Imon Banerjee</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Imon Banerjee</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pdig.0000086" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">13 Sep 2021</named-content>
    </p>
    <p><!-- <div> -->PDIG-D-21-00039<!-- </div> --><!-- <div> -->DrNote: An open medical annotation service<!-- </div> --><!-- <div> -->PLOS Digital Health</p>
    <p>Dear Dr. Frei,</p>
    <p>Thank you for submitting your manuscript to PLOS Digital Health. After careful consideration, we feel that it has merit but does not fully meet PLOS Digital Health’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>==============================<!-- </div> --><!-- <div> -->EDITOR: Please insert comments here and delete this placeholder text when finished. Be sure to:<!-- </div> --><list list-type="bullet"><list-item><p>Indicate which changes you require for acceptance versus which changes you recommend</p></list-item><list-item><p>Address any conflicts between the reviews so that it's clear which advice the authors should follow</p></list-item><list-item><p>Provide specific feedback from your evaluation of the manuscript</p></list-item></list></p>
    <p>Please ensure that your decision is justified on PLOS Digital Health’s <ext-link xlink:href="https://journals.plos.org/digitalhealth/s/journal-information#loc-criteria-for-publication" ext-link-type="uri">publication criteria </ext-link>and not, for example, on novelty or perceived impact.</p>
    <p>==============================</p>
    <p>Please submit your revised manuscript by Nov 12 2021 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>digitalhealth@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pdig/" ext-link-type="uri">https://www.editorialmanager.com/pdig/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>A rebuttal letter that responds to each point raised by the editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p>
        </list-item>
        <list-item>
          <p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p>
        </list-item>
        <list-item>
          <p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p>
        </list-item>
      </list>
    </p>
    <p>Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Imon Banerjee</p>
    <p>Section Editor</p>
    <p>PLOS Digital Health</p>
    <p>Journal Requirements:</p>
    <p>1. We ask that a manuscript source file is provided at Revision. Please upload your manuscript file as a .doc, .docx, .rtf or .tex. If you are providing a .tex file, please upload it under the item type ‘LaTeX Source File’ and leave your .pdf version as the item type ‘Manuscript’.</p>
    <p>2. We do not publish any copyright or trademark symbols that usually accompany proprietary names, eg (R), (C), or TM  (e.g. next to drug or reagent names). Therefore please remove all instances of trademark/copyright symbols throughout the text, including "UMLS®" on page 12.</p>
    <p>3. Please update the completed 'Competing Interests' statement, including any COIs declared by your co-authors. If you have no competing interests to declare, please state "The authors have declared that no competing interests exist". Otherwise please declare all competing interests beginning with the statement "I have read the journal's policy and the authors of this manuscript have the following competing interests:"</p>
    <p>Additional Editor Comments (if provided):</p>
    <p>Authors are requested to response to the reviewers comments - particularly related to the baseline.</p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. Does this manuscript meet PLOS Digital Health’s <ext-link xlink:href="https://journals.plos.org/digitalhealth/s/criteria-for-publication" ext-link-type="uri">publication criteria</ext-link>? Is the manuscript technically sound, and do the data support the conclusions? The manuscript must describe methodologically and ethically rigorous research with conclusions that are appropriately drawn based on the data presented.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Partly</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously?<!-- </font> --></p>
    <p>Reviewer #1: I don't know</p>
    <p>Reviewer #2: N/A</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available (please refer to the Data Availability Statement at the start of the manuscript PDF file)?</p>
    <p>The <ext-link xlink:href="https://journals.plos.org/digitalhealth/s/data-availability" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception. The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS Digital Health does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: Innovation= Useful + Novel. The authors argue that the tool is very useful esp. for non English text. The question I have is whether the approach used is novel compared to what already exists. It would be good to clarify this in the narrative.</p>
    <p>Also in the concluding section, it would be great to get an assessment of performance of the tool vs purely data-driven approaches in English text as well as other non English text.</p>
    <p>Reviewer #2: Summary</p>
    <p>====================================</p>
    <p>+ This manuscript describes an open annotation framework, DrNote, which leverages public Wikipedia data to create a medical entity linker. This annotator builds on the OpenTapioca, an entity linking framework. OpenTapioca requires annotating documents to tag entity mentions. DrNote proposes a distantly supervised approach for creating the labeled training data (for symptoms, diagnoses, drugs and medications) by creating an annotated dataset using string matching with WikiData &amp; Wikipedia. A key benefit of this approach is taking advantage of multiple languages in wikipedia, a key challenge area in clinical/EHR NLP. The resulting software and dataset are provided.</p>
    <p>Strengths</p>
    <p>====================================</p>
    <p>+ Multilinguality is a critical application area and Wikidata has some considerable advantages for covering multiple languages</p>
    <p>+ Building a WikiData KG subset of key medical concepts is a useful dataset contribution</p>
    <p>+ Software is open source</p>
    <p>Weaknesses</p>
    <p>====================================</p>
    <p>+ The primary weakness of this manuscript is that there are no empirical results which with to evaluate the performance of the proposed annotation framework. The manuscript focuses on describing the process by which the wiki dataset is created and various aspects of the general software platform (and how it uses/interfaces with OpenTapioca and Apache Solr) but there are no empirical evaluations or experiments to measure quality of the annotator. This is a significant weakness and makes it difficult to evaluate the merits of the proposed contributions.</p>
    <p>+ The domain shift from wiki text to EHR/clinical text is likely quite significant. A spot check with some MIMIC-III data (see below) reveals some of the limitations, but this needs to be characterized systematically using expert-labeled datasets. Restricting to medical entities in the WikiData KB is a valid use case, (for example, for tagging medical concepts in web data or consumer facing health literature this might be fine) but the cost of the domain shift needs to be measured</p>
    <p>+ The multilinguality capability, while appealing, isn't motivated by results on multilingual datasets.</p>
    <p>+ There are commercial solutions that handle Multilinguality (e.g., Amazon Comprehend Medical). It would be nice to include a baseline compared to such a service.</p>
    <p>Recommendations</p>
    <p>====================================</p>
    <p>+ The authors need to provide empirical measures of their systems performance by evaluating on some expert annotated (bio)medical datasets. Even an NER evaluation (vs. entity linking / NED, which is challenging here given the WikiData KG) would provide some sense of the annotator's term coverage and bound entity linking performance. There are a few parallel biomedical corpora that could be used:</p>
    <p>- (biomedical) <ext-link xlink:href="https://academic.oup.com/jamia/article/22/5/948/930067#210287674" ext-link-type="uri">https://academic.oup.com/jamia/article/22/5/948/930067#210287674</ext-link></p>
    <p>- (biomedical) <ext-link xlink:href="https://huggingface.co/datasets/scielo" ext-link-type="uri">https://huggingface.co/datasets/scielo</ext-link></p>
    <p>For clinical text, the situation is quite sparse (as noted by the authors) but there are clinical corpora in English that could be used to assess NER/term coverage and at least provide some empirical measurements of transitioning from wiki data to clinical/EHR text. Something like the 2018 n2c2 Adverse Drug Event (ADE) and Medication Extraction Challenge would work fine as an evaluation here.</p>
    <p>+ There is considerable prior work on distant/weakly supervised, pseudo/silver-labeling and other methods for automatically generating training data that should be discussed as background and used to highlight the strengths of this work. These approaches are especially common in clinical concept recognition, but (as the authors note) this area is under-explored in multilingual settings. There are a few nice surveys of recent methods</p>
    <p>- "Modern Clinical Text Mining: A Guide and Review." Bethany Percha. Annual Review of Biomedical Data Science. 2021</p>
    <p>- "Clinical Concept Extraction: a Methodology Review." Fu et al. Journal of Biomedical Informatics. 2020</p>
    <p>- "Ontology-driven weak supervision for clinical entity classification in electronic health records." Fries et al. Nature Communications. 2021</p>
    <p>Misc Comments</p>
    <p>====================================</p>
    <p>+ (Line 280) The 1-2 weeks doesn't provide a very meaningful estimate of compute costs since in conflates multiple sources of compute/time costs (e.g., download time, data preprocessing, indexing, SVM training). Does the pipeline benefit from multiprocessing or support a distributed/cluster setup? It would be more helpful to describe the compute costs more precisely and provide more details, e.g., some definition of throughput based on number of candidate entities processed, # of wiki pages, etc</p>
    <p>Example Annotation Case</p>
    <p>====================================</p>
    <p>+ As a quick test, I ran this de-identified clinical text snipped from MIMIC-III on the public demo at <ext-link xlink:href="https://textmining.misit-augsburg.de/" ext-link-type="uri">https://textmining.misit-augsburg.de/</ext-link></p>
    <p>and using the filter rules for non-stopwords and min length of 2, we get the following results</p>
    <p>"""</p>
    <p>Reason: assess for gastric distention, gastric bubble</p>
    <p>Admitting Diagnosis: GASTROINTESTINAL BLEED</p>
    <p>66 [[year]] old [[man]] s/p R [[colectomy]] on [**3-9**] and [[CREST syndrome]] w/ ongoing [[nausea]].</p>
    <p>A wedge-shaped area of increased density is seen on the lateral view, which I believe is corresponding to the [[left lower lobe]]. This has features of subsegmental [[atelectasis]], but a follow-up is recommended to evaluate for progression, as might be seen with a [[pneumonia]]. The remainder of the study shows no [[air]]-space [[disease]]. There is no evidence for congestive features nor pleural effusions.</p>
    <p>"""</p>
    <p>(enclosing double brackets indicate a detected entity , i.e., "[[ (entity) ]]")</p>
    <p>We miss "gastric distention", "gastric bubble", "GASTROINTESTINAL BLEED", "pleural effusions", partially match "air-space disease" and "subsegmental atelectasis", and have a number of false positives ("year", "man")</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/digitalhealth/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p>For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>**********</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pdig.0000086.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000086.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pdig.0000086" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">26 Nov 2021</named-content>
    </p>
    <supplementary-material id="pdig.0000086.s001" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">RebuttalLetter.pdf</named-content></p>
      </caption>
      <media xlink:href="pdig.0000086.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pdig.0000086.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000086.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Banerjee</surname>
          <given-names>Imon</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Imon Banerjee</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Imon Banerjee</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pdig.0000086" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">27 Apr 2022</named-content>
    </p>
    <p>PDIG-D-21-00039R1</p>
    <p>DrNote: An open medical annotation service</p>
    <p>PLOS Digital Health</p>
    <p>Dear Dr. Frei,</p>
    <p>Thank you for submitting your manuscript to PLOS Digital Health. After careful consideration, we feel that it has merit but does not fully meet PLOS Digital Health's publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Please submit your revised manuscript by Jun 26 2022 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>digitalhealth@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pdig/" ext-link-type="uri">https://www.editorialmanager.com/pdig/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:</p>
    <p>* A rebuttal letter that responds to each point raised by the editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p>
    <p>* A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p>
    <p>* An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Imon Banerjee</p>
    <p>Section Editor</p>
    <p>PLOS Digital Health</p>
    <p>Journal Requirements:</p>
    <p>1. Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article's retracted status in the References list and also include a citation and full reference for the retraction notice.</p>
    <p>Additional Editor Comments (if provided):</p>
    <p>Congratulation to the authors for substantially improving the manuscript in the first revision. As per the suggestion of the reviewer 1, I would strongly suggest the authors to add comparative analysis with the existing/traditional baseline.</p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.<!-- </font> --></p>
    <p>Reviewer #1: (No Response)</p>
    <p>Reviewer #2: All comments have been addressed</p>
    <p>--------------------</p>
    <p><!-- <font color="black"> -->2. Does this manuscript meet PLOS Digital Health’s <ext-link xlink:href="https://journals.plos.org/digitalhealth/s/journal-information#loc-criteria-for-publication" ext-link-type="uri">publication criteria</ext-link>? Is the manuscript technically sound, and do the data support the conclusions? The manuscript must describe methodologically and ethically rigorous research with conclusions that are appropriately drawn based on the data presented.<!-- </font> --></p>
    <p>Reviewer #1: Partly</p>
    <p>Reviewer #2: Yes</p>
    <p>--------------------</p>
    <p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously?<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>--------------------</p>
    <p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available (please refer to the Data Availability Statement at the start of the manuscript PDF file)?</p>
    <p> The <ext-link xlink:href="https://journals.plos.org/digitalhealth/s/data-availability" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception. The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>--------------------</p>
    <p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS Digital Health does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>--------------------</p>
    <p><!-- <font color="black"> -->6. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: The authors are yet to bring out uniqueness of this approach compared to other available applications. Only providing references is not sufficient.</p>
    <p>Reviewer #2: The authors have nicely addressed all my concerns and have substantially improved the manuscript with the addition of the empirical evaluation.</p>
    <p>--------------------</p>
    <p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/digitalhealth/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p>For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> -->
</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>--------------------</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pdig.0000086.r004">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000086.r004</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 1</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pdig.0000086" id="rel-obj004" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">25 Jun 2022</named-content>
    </p>
    <supplementary-material id="pdig.0000086.s002" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">RebuttalLetter_V2.pdf</named-content></p>
      </caption>
      <media xlink:href="pdig.0000086.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pdig.0000086.r005" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000086.r005</article-id>
    <title-group>
      <article-title>Decision Letter 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Banerjee</surname>
          <given-names>Imon</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2022 Imon Banerjee</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Imon Banerjee</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pdig.0000086" id="rel-obj005" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">12 Jul 2022</named-content>
    </p>
    <p>DrNote: An open medical annotation service</p>
    <p>PDIG-D-21-00039R2</p>
    <p>Dear Mr. Frei,</p>
    <p>We are pleased to inform you that your manuscript 'DrNote: An open medical annotation service' has been provisionally accepted for publication in PLOS Digital Health.</p>
    <p>Before your manuscript can be formally accepted you will need to complete some formatting changes, which you will receive in a follow-up email from a member of our team. </p>
    <p>Please note that your manuscript will not be scheduled for publication until you have made the required changes, so a swift response is appreciated.</p>
    <p>IMPORTANT: The editorial review process is now complete. PLOS will only permit corrections to spelling, formatting or significant scientific errors from this point onwards. Requests for major changes, or any which affect the scientific understanding of your work, will cause delays to the publication date of your manuscript.</p>
    <p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they'll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>digitalhealth@plos.org</email>.</p>
    <p>Thank you again for supporting Open Access publishing; we are looking forward to publishing your work in PLOS Digital Health.</p>
    <p>Best regards,</p>
    <p>Imon Banerjee</p>
    <p>Section Editor</p>
    <p>PLOS Digital Health</p>
    <p>***********************************************************</p>
    <p>Reviewer Comments (if any, and for reference):</p>
  </body>
</sub-article>
