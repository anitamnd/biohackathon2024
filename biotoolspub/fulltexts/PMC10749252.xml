<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_CSBJ2415 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEga1 jpg ?>
<?FILEmmc1 pdf ?>
<?FILEmmc2 pptx ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Struct Biotechnol J</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Struct Biotechnol J</journal-id>
    <journal-title-group>
      <journal-title>Computational and Structural Biotechnology Journal</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2001-0370</issn>
    <publisher>
      <publisher-name>Research Network of Computational and Structural Biotechnology</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10749252</article-id>
    <article-id pub-id-type="pii">S2001-0370(23)00452-X</article-id>
    <article-id pub-id-type="doi">10.1016/j.csbj.2023.11.037</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TCR-ESM: Employing protein language embeddings to predict TCR-peptide-MHC binding</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Yadav</surname>
          <given-names>Shashank</given-names>
        </name>
        <xref rid="aff0005" ref-type="aff">a</xref>
        <xref rid="fn1" ref-type="fn">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Vora</surname>
          <given-names>Dhvani Sandip</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="fn1" ref-type="fn">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Sundar</surname>
          <given-names>Durai</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au0020">
        <name>
          <surname>Dhanjal</surname>
          <given-names>Jaspreet Kaur</given-names>
        </name>
        <email>jaspreet@iiitd.ac.in</email>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="aff0005"><label>a</label>Department of Biomedical Engineering, University of Arizona, Tucson 85721, AZ, USA</aff>
      <aff id="aff0010"><label>b</label>Department of Biochemical Engineering and Biotechnology, Indian Institute of Technology Delhi, New Delhi 110016, India</aff>
      <aff id="aff0015"><label>c</label>Department of Computational Biology, Indraprastha Institute of Information Technology, Delhi, New Delhi 110020, India</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding author. <email>jaspreet@iiitd.ac.in</email></corresp>
      <fn id="fn1">
        <label>1</label>
        <p id="ntp0005">Equal contribution</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <volume>23</volume>
    <fpage>165</fpage>
    <lpage>173</lpage>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>19</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>11</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 The Authors</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>Cognate target identification for T-cell receptors (TCRs) is a significant barrier in T-cell therapy development, which may be overcome by accurately predicting TCR interaction with peptide-bound major histocompatibility complex (pMHC). In this study, we have employed peptide embeddings learned from a large protein language model- Evolutionary Scale Modeling (ESM), to predict TCR-pMHC binding. The TCR-ESM model presented outperforms existing predictors. The complementarity-determining region 3 (CDR3) of the hypervariable TCR is located at the center of the paratope and plays a crucial role in peptide recognition. TCR-ESM trained on paired TCR data with both CDR3α and CDR3β chain information performs significantly better than those trained on data with only CDR3β, suggesting that both TCR chains contribute to specificity, the relative importance however depends on the specific peptide-MHC targeted. The study illuminates the importance of MHC information in TCR-peptide binding which remained inconclusive so far and was thought dependent on the dataset characteristics. TCR-ESM outperforms existing approaches on external datasets, suggesting generalizability. Overall, the potential of deep learning for predicting TCR-pMHC interactions and improving the understanding of factors driving TCR specificity are highlighted. The prediction model is available at http://tcresm.dhanjal-lab.iiitd.edu.in/ as an online tool.</p>
    </abstract>
    <abstract abstract-type="graphical" id="ab0015">
      <title>Graphical abstract</title>
      <p>
        <fig id="fig0030" position="anchor">
          <alt-text id="at0030">ga1</alt-text>
          <graphic xlink:href="ga1" id="lk0030"/>
        </fig>
      </p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>T-cell therapy</kwd>
      <kwd>TCR-pMHC interactions</kwd>
      <kwd>Protein language models</kwd>
      <kwd>TCR specificity</kwd>
      <kwd>Peptide embeddings</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0010">The surveillance against pathogens and pathological cells of the body is carried out by the adaptive immune system. A cornerstone of the adaptive immune response system is the presentation of peptides by major histocompatibility complexes (MHC) class I or class II, expressed on the cell surfaces. The human MHCs are also called Human Leukocyte Antigens (HLAs) and are classified in three gene classes based on structure and function of the gene products. Class I gene products, encoded by three distinct genomic loci, HLA-A, HLA-B and HLA-C present endogenous peptides to CD8<sup>+</sup> T-cells. The letters “A”, “B” or “C” are assigned based on the antigens defined by serology. The peptide-MHC complex presented to T-cells enables recognition of the antigen via the T-cell receptors (TCR). Upon activation, the T cells undergo clonal expansion <xref rid="bib1" ref-type="bibr">[1]</xref>. A fraction of this clonally expanded repertoire is retained as long-living memory against the antigen <xref rid="bib2" ref-type="bibr">[2]</xref>. The affinity of the TCR for any peptide is governed by the heterodimeric TCRs consisting of the <italic>α</italic> and <italic>β</italic> subunits. Both chains have been reported to affect the binding of the TCR to the peptide-MHC complex (TCR-pMHC), however, prediction of TCR-pMHC binding has been carried out with high accuracy with only the <italic>β</italic> chain <xref rid="bib3" ref-type="bibr">[3]</xref>.</p>
    <p id="p0015">Within the <italic>β</italic> chain of the TCR, the three complementarity determining regions (CDRs) make primary contacts with the MHC (CDR1 and CDR2), and the peptide (CDR3), recent studies suggest contributions of the alpha chain and other CDRs as well <xref rid="bib4" ref-type="bibr">[4]</xref>. In both the <italic>α</italic> and <italic>β</italic> chains, the CD3 loops represent the region of the highest sequence diversity and hence, are the regions that determine receptor binding specificity <xref rid="bib5" ref-type="bibr">[5]</xref>, <xref rid="bib6" ref-type="bibr">[6]</xref>. The CDR3 diversity is defined by multiple genomic recombination events in the ‘Variable’ (V), ‘Diversity’ (D) and ‘Joining’ (J) TCR-related genes. The V- and J- recombinations make up the α-chain while the β-chain is a result of the V-, D- and J genes generating a broader diversity. Hence, most of the previous studies have focused only on the β-chain.</p>
    <p id="p0020">The Immune Epitope database, VDJDB and McPAS-TCR primarily contains information on CDR3β and houses a large fraction of the publicly available TCR-pMHC binding data <xref rid="bib7" ref-type="bibr">[7]</xref>, <xref rid="bib8" ref-type="bibr">[8]</xref>, <xref rid="bib9" ref-type="bibr">[9]</xref>. Recent studies illuminate the importance of CDR3 of both α- and β-chains in driving specificity of the TCR <xref rid="bib10" ref-type="bibr">[10]</xref>, <xref rid="bib11" ref-type="bibr">[11]</xref>. While single-cell based high-throughput techniques for assessing TCR-pMHC binding are available, determining the role of individual components remains a time- and resource-intensive pursuit <xref rid="bib12" ref-type="bibr">[12]</xref>, <xref rid="bib13" ref-type="bibr">[13]</xref>.</p>
    <p id="p0025">Various studies have reported TCR-pMHC data modeling and prediction techniques, mostly based on the data from VDJDB, IEDB and McPAS-TCR, using either or both CDR3 α- and β-sequences. These previous studies have employed Gaussian processes, position-specific scoring matrices, deep learning methods <xref rid="bib14" ref-type="bibr">[14]</xref>, <xref rid="bib15" ref-type="bibr">[15]</xref>, <xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib17" ref-type="bibr">[17]</xref> as well as advanced methods employing Natural Language Processing (NLP) <xref rid="bib3" ref-type="bibr">[3]</xref>. The performance of current methods is limited by the paucity of available data. The applicability in terms of generalizability of the predictors is also hindered by the redundancy in epitope specific TCR sequences. Extracting relevant information from sequence data, labeled and unlabeled, has been demonstrated by NLP-based self-supervised learning algorithms. One such algorithm, Bidirectional Encoder Representations from Transformers (BERT), has been reported to reliably capture biological properties of proteins <xref rid="bib18" ref-type="bibr">[18]</xref>. Large protein language models such as ESM (Evolutionary Scale Model) <xref rid="bib19" ref-type="bibr">[19]</xref> and its variants have been used to predict biological structure and function of proteins. Also, the embeddings learned by the model have been fine-tuned for downstream tasks such as protein-drug interactions prediction <xref rid="bib20" ref-type="bibr">[20]</xref>, protein variant effect prediction <xref rid="bib21" ref-type="bibr">[21]</xref> and gene ontology annotation <xref rid="bib22" ref-type="bibr">[22]</xref>.</p>
    <p id="p0030">Here, we present TCR-ESM, a deep learning-based model to predict TCR-peptide-MHC binding. TCR-ESM is a feedforward neural network trained on embeddings extracted from ESM, a protein language model <xref rid="bib23" ref-type="bibr">[23]</xref>. ESM1v - a variant in the ESM family of protein language models has been used to generate sequence length-independent embeddings for the three protein moieties involved in the binding. The encoded protein sequence information is fed into a feedforward neural network to predict possibility of interaction. The positive data class consists of experimentally validated pairs of class 1 and class 2 MHC-peptide which bind to the TCRs. The negative data is generated by mismatching the positive dataset and ensuring the new combinations are absent in the positive class. Ablation analysis has also been carried out to qualitatively determine the importance of the TCRα, TCRβ and MHC components in the classifier's predictions. The study has been benchmarked against current TCR-pMHC prediction models such as pEptide tcR matchinG predictiOn (ERGO II) <xref rid="bib4" ref-type="bibr">[4]</xref> and netTCR2.0 <xref rid="bib24" ref-type="bibr">[24]</xref> using the netTCR2.0, McPAS and VDJDB datasets <xref rid="bib3" ref-type="bibr">[3]</xref>, <xref rid="bib9" ref-type="bibr">[9]</xref>, <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib25" ref-type="bibr">[25]</xref>. Our model, TCR-ESM has also been tested on the external dataset MIRA, as reported in the netTCR2.0 study as well as an additional independent external test set pMTnet <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib26" ref-type="bibr">[26]</xref>. We report improved prediction capacity based on the Matthews correlation coefficient (MCC) score, which has been established as a more reliable performance metrics in binary classification on imbalanced data rather than precision, recall and ROC AUC <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib28" ref-type="bibr">[28]</xref>. The MCC score ranges from 0, indicating poor model predictive performance, to 1, signifying ideal model performance. However, we additionally report model performance on precision-recall, ROC AUC as well as the F1 score. We also observe that fine tuning the embeddings extracted from large protein language models can preserve both local and global information towards specific objectives.</p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Results</title>
    <p id="p0035">The TCR-ESM prediction model was trained on the peptide, TCR and MHC embeddings as detailed in <xref rid="fig0005" ref-type="fig">Fig. 1</xref>. The peptide, TCR and MHC sequence information was fed into the neural network after embeddings were generated from the penultimate layer of the ESM1v model (<xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>a</bold>). The feedforward neural network was trained to predict TCR-peptide binding pairs as 1, and non-interacting pairs as 0. Performance was evaluated over MCC scores, area under the receiver operating characteristic (AUC-ROC), area under the Precision-Recall curve (AU-PR) and F1 scores. The choice of model architecture was governed by the feature set in consideration. For instance, for predicting CDR3α-CDR3β-peptide binding the model illustrated in <xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>b</bold> was used. Similarly, <xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>c</bold> illustrates the model used for CDR3α-CDR3β-peptide-MHC binding. For CDR3α-peptide, CDR3β-peptide, CDR3α-peptide-MHC, CDR3β-peptide-MHC binding prediction, the model architectures are illustrated in <xref rid="sec0085" ref-type="sec">Supplementary Figure 1a, 1b, 1c and 1d</xref>, respectively.<fig id="fig0005"><label>Fig. 1</label><caption><p><bold>:</bold> Schematic of the method followed. (a) The ESM1v protein language model was employed to extract the sequence information in the form of 1280-dimensional embeddings for each of the three components- TCR, peptide and MHC. (b) Architecture of the neural network employed for the TCR(CDR3α+CDR3β)-peptide binding classification task. (c) The neural network architecture employed for the TCR(CDR3α+CDR3β)-peptide-MHC binding prediction task.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1" id="lk0005"/></fig></p>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Model performance evaluation on CDR3β data</title>
      <p id="p0040">The probability of the TCR-peptide binding predicted by TCR-ESM on the netTCR2.0 CDR3β dataset was evaluated. A side-by-side comparison of TCR-ESM with the 1D CNN-based netTCR2.0 was carried out. The data was prepared and partitioned the same as the netTCR2.0 study <xref rid="bib24" ref-type="bibr">[24]</xref>. The netTCR2.0, ERGO-AE, ERGO-LSTM and the classifier presented in this study- TCR-ESM were trained, and cross-validation was carried out on the CDR3β data. Same as netTCR2.0, five different MIRA datasets were obtained by imposing a separation from the training set of 90 %, 92 %, 94 %, 99 %, and 100 % similarity. That is, MIRA 94 % TCRs do not share more than 94% Levenshtein similarity to any of the TCRs in the training set. These datasets were used as independent test sets. Our model outperformed netTCR2.0 on all similarity-based partition thresholds (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>a,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1a</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Figs. S2, S3 and S4</xref>.<fig id="fig0010"><label>Fig. 2</label><caption><p><bold>:</bold> Model performance benchmarking. (a) Comparison of TCR-ESM with netTCR2.0 on the external MIRA dataset as test set for different partitioning thresholds. (b) Comparison of TCR-ESM with netTCR2.0 on the MIRA dataset as test set specific to the most common peptide in the dataset, ‘GILGFVFTL’. (c) Comparison of TCR-ESM with netTCR2.0 on the MIRA dataset as test set specific to the second most common peptide ‘GLCTLVAML’. 5-fold cross validation is run independently 10 times to compare the model performance and the distribution is represented by the box-whisker plots to compare the performance of TCR-ESM with netTCR2.0 at (d) 90% partitioning threshold and (e) 95% partitioning threshold for different prediction tasks such as TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, and TCR(CDR3α+CDR3β)+peptide. All statistical comparisons were done using Mann-Whitney U test with Benjamini-Hochberg correction (ns: p &gt; 5.00e-02, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2" id="lk0010"/></fig></p>
      <p id="p0045">We then compared the peptide-specific outperformance for the two most abundant peptides, GILGFVFTL (GIL) from Influenza A virus and GLCTLVAML (GLC) from Human herpesvirus 4 (Epstein–Barr virus) for all partitioning thresholds (<xref rid="fig0010" ref-type="fig">Figs. 2</xref><bold>b,</bold>
<xref rid="fig0010" ref-type="fig">2</xref><bold>c,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1a</xref>).</p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>Model performance evaluation and ablation analysis on paired CDR3α and β</title>
      <p id="p0050">In addition to the CDR3β information, to check whether CDR3α information or paired CDR3αβ information is beneficial for the prediction of peptide binding by the TCR, the TCR-ESM model was cross-validated and benchmarked against netTCR2.0. <xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>d</bold> shows the TCR-ESM and netTCR2.0 models evaluated with 5-fold cross-validation run 10 times independently on the sequence similarity-based partitioned datasets as is from the netTCR2.0 study with the CDR3 α-chain, CDR3 β-chain, and both α- and β-chains of CDR3. The TCR-ESM model significantly outperforms (p-value &lt;= 0.05) the netTCR2.0 model on all three datasets (CDR3α only, CDR3β only, and paired). We also obtained similar outperformance for the 95% partitioned dataset (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>e,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1b</xref>). We validated this observation by comparing netTCR2.0 model performance on the three datasets (CDR3α only, CDR3β only, and paired) and found that models trained on paired chain information outperformed models trained only on single CDR3 chains. (<xref rid="sec0085" ref-type="sec">Supplementary Fig. S5</xref>).</p>
      <p id="p0055">To further validate the performance of the TCR-ESM model, we compared our model with the ERGO II model. The ERGO II model is available in two types, namely ERGO II-Autoencoder (ERGO II-AE) and ERGO II-Long Short-Term Memory (ERGO II-LSTM). Since ERGO II-AE and ERGO II-LSTM were originally benchmarked on the McPAS and VDJDB data, we utilized these datasets with exactly the same train-test splits as provided. We observed that our model outperforms netTCR2.0, ERGO II-AE and ERGO II-LSTM model for both McPAS and VDJDB paired chain datasets (10-fold cross validation, p-value&lt;=0.05, p-value correction with Benjamini-Hochberg method) (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>a,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Tables S2</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Figs. S6, S7, S8</xref>. Both McPAS and VDJDB subsets 1 lack MHC information while subsets 2 include MHC information. We cross-validated these models on the McPAS data subset-1. We also observed a similar trend on test-set MCC where our model performed better when compared to the other three models (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>b</bold>). We observe a similar trend of TCR-ESM outperforming in the VDJDB data subset-1 on both cross validation and test setting as illustrated in <xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>c</bold> and <xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>d</bold>.<fig id="fig0015"><label>Fig. 3</label><caption><p><bold>:</bold> Feature importance as determined by ablation. The box-whisker plots show model performance distribution on 10-fold cross-validation using the TCR-ESM predictor, netTCR2.0, ERGO II-AE and ERGO II-LSTM for different prediction tasks- TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, and TCR(CDR3α+CDR3β)+peptide on (a) McPAS data subset-1, (c) VDJDB data subset-1. Similarly, hold-out testing set comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model for the three different prediction tasks on (b) McPAS data subset-1, and (d) VDJDB data subset-1. 10-fold cross validated comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model for different prediction tasks such as TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, TCR(CDR3α + CDR3β) + peptide, TCR(CDR3α)+peptide+MHC, TCR(CDR3β)+peptide+MHC and TCR(CDR3α + CDR3β) + peptide+MHC on (e) McPAS data subset-2 and (g) VDJDB data subset-2. Similarly, hold-out testing set comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model was performed for the different prediction tasks on (f) McPAS data subset-2 and (h) VDJDB data subset-2. All statistical comparisons were done using Mann-Whitney U test with Bejamini-Hochberg correction (ns: p &gt; 5.00e-02, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3" id="lk0015"/></fig></p>
      <p id="p0060">Further supporting analysis on whether CDR3 paired chain information can predict the TCR-peptide binding better than single chains was carried out. We performed 10-fold cross-validation for all the four models (netTCR2.0, ERGO II-AE, ERGO II-LSTM and our TCR-ESM) on paired CDR3 in the McPAS data subset-1 as well single chains, and observed that paired CDR3 information improves the MCC significantly (t-test p-value&lt;=0.05, p-value correction with Benjamini-Hochberg method) when compared to the model trained only on CDR3α and CDR3β <bold>(</bold><xref rid="sec0085" ref-type="sec">Supplementary Figs. S9, S10</xref><bold>)</bold>. We observe a similar trend of model outperformance with paired CDR3 information on the VDJDB data subset-1 (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S6, S7, S8</xref>).</p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Model performance evaluation on paired CDR3 with MHC information and ablation analysis</title>
      <p id="p0065">The contribution of different features was further illustrated by performing ablation analysis on McPAS data subset-2 and VDJDB data subset-2, which contains MHC information. Since there are three components, CDR3α, CDR3β, and MHC, six feature sets were constructed- CDR3α only, CDR3β only, paired CDR3α-CDR3β, CDR3α-MHC, CDR3β-MHC and combined CDR3α-CDR3β-MHC. The TCR-ESM-MHC model was compared with ERGO II-AE and ERGO II-LSTM models on McPAS data subset-2 (containing MHC information) for each of the six feature sets. TCR-ESM-MHC is shown to outperform the ERGO-AE model on all six feature sets during cross-validation and on the test set, while also outperforming ERGO-LSTM on four of the six sets during cross-validation and on the test set (<xref rid="fig0015" ref-type="fig">Figs. 3</xref><bold>e,</bold>
<xref rid="fig0015" ref-type="fig">3</xref><bold>f)</bold>. TCR-ESM-MHC also outperformed on the VDJDB data subset-2 (VDJDB with MHC information) as compared to both ERGO II-AE and ERGO II-LSTM model on 10-fold cross validation and test set (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>g,</bold>
<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>h</bold>). For the ablation experiment, the ERGO II-AE, ERGO II-LSTM and TCR-ESM-MHC models were trained individually on the six feature sets. The feature importance of the MHC based on increase in MCC scores is dataset- and method-dependant. For the McPAS data subset- 2, when analysed with ERGO II-AE, addition of the MHC features significantly improved model performance indicating high feature importance. However, when the McPAS data subset-2 was analysed with ERGO II-LSTM and the TCR-ESM-MHC models, inclusion of the MHC information did not significantly improve performance reflecting low feature importance (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S8, S9, S10</xref>). Contrarily, for the VDJDB data subset-2, there was a statistically significant improvement in performance upon inclusion of the MHC features for all the models trained- ERGO II-AE, ERGO II-LSTM and TCR-ESM-MHC. The observed increase in MCC scores indicated that the MHC sequence information plays an important role in driving model output and therefore is an important feature (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S8, S9, S10</xref>).</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Analysis of embeddings learned by the TCR-ESM model</title>
      <p id="p0070">The outputs from different layers of the TCR-ESM-MHC model were extracted to understand how the output of the model is driven, t-SNE was used to reduce the layer output to two dimensions. t-SNE enables capturing local relationships while also capturing non-linear relationships in the data. This is significant to determine if the embeddings can be repurposed for related tasks. We compared the embeddings of binding TCR to non-binding TCR in the input layer, concatenation layer and penultimate dense layer. For the McPAS dataset, the most common peptide ‘GILGFVFTL’ was selected from the test set. As one progresses through the layers of our model, the outputs generated become more abstract and less directly tied to specific features in the input data. Later layers then use these abstractions to construct more sophisticated features that are better suited for specific tasks. This can lead to the outputs of the later layers being more separable, or easier to distinguish from one another, compared to the outputs of the earlier layers. The results showed that the learned embeddings became more distinct as the model was trained, with positive TCR interactions and negative TCR interactions in the independent dataset for specific peptides being mixed at the input layer (<xref rid="fig0020" ref-type="fig">Figs. 4</xref><bold>a,</bold>
<xref rid="fig0020" ref-type="fig">4</xref><bold>b</bold>). The subsequent neural network layers learn the embeddings of the multiple inputs jointly, following the input layer where the information is supplied separately. Gradually the learned embeddings can be distinguished at the concatenation and penultimate dense layers which also capture the information of binding and non-binding CDR3α and CDR3β sequences (<xref rid="fig0020" ref-type="fig">Figs. 4</xref><bold>c,</bold>
<xref rid="fig0020" ref-type="fig">4</xref><bold>d</bold>). Similarly, for the VDJDB dataset, we picked the most common ‘NLVPMVATV’ peptide and performed a similar analysis of the input, concatenation and penultimate dense layer embeddings of binding and non-binding CDRα and CDR3β sequences, as illustrated in <xref rid="sec0085" ref-type="sec">Supplementary Fig. S11</xref><bold>.</bold> A similar analysis was performed for two other randomly selected peptides, also demonstrating separability as shown in <xref rid="sec0085" ref-type="sec">Supplementary Fig. S12</xref><bold>.</bold> A layer-wise analysis of the separation obtained is studied by employing a random forest classifier at each layer and evaluating the MCC scores (<xref rid="sec0085" ref-type="sec">Supplementary Fig. S13</xref>). We observed that the model learns a joint embedding for CDR3α and CDR3β and shows separation between positive and negative TCR samples for specific peptides.<fig id="fig0020"><label>Fig. 4</label><caption><p><bold>:</bold> (a) Predictive capacity of the different layers of the TCR-ESM classifier for randomly selected peptides ‘GILGFVFTL’, ‘SSYRRPVGI’ and ‘SSLENFRAYV’. Comparison of two-dimensional t-SNE embeddings for positive and negative (b) TCR(CDR3α) and (c) TCR(CDR3β) for the most common peptide ‘GILGFVFTL’ from the Input Layer of model (TCR(CDR3α + CDR3β) + peptide) trained on McPAS dataset. Comparison of jointly learned two-dimensional T-SNE embeddings for positive and negative TCR(CDR3α + CDR3β) for the most common peptide ‘GILGFVFTL’ from the (d) Concatenation Layer and (e) Penultimate Dense Layer of model (TCR(CDR3α + CDR3β) + peptide) trained on McPAS dataset.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4" id="lk0020"/></fig></p>
    </sec>
    <sec id="sec0035">
      <label>2.5</label>
      <title>External testing analysis</title>
      <p id="p0075">The level of dissimilarity between CDR3β and peptide sequences in the pMTnet dataset with the McPAS and VDJDB dataset was determined. For CDR3β sequences, pMTnet had only one (1 in 272; 0.4% identical) CDR3β sequence which was common with CDR3β in McPAS dataset. Similarly, for the VDJDB dataset, we found that the pMTnet dataset has 39 (39 in 272; 14.7% identical) common CDR3β sequences. Comparing peptides, pMTnet data has 21 (21 in 224; 9.38% identical) common peptides with McPAS data and 42 (42 in 224; 19.6% identical) common peptides with VDJDB data.</p>
      <p id="p0080">Separate models were trained on the McPAS and VDJDB dataset and tested on the pMTnet dataset to evaluate how the models perform in an external setting (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>a</bold>). Since there were some common peptides between models trained on McPAS and VDJDB with the external pMTNet test set, the models were evaluated after removing the common peptides as well (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>b</bold>). Further stringent testing was carried out by removing peptides with 90% and 80% sequence similarity to any peptide in train sets (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>c, d</bold>). The TCR-ESM model was shown to perform significantly better than the netTCR2.0, ERGO II-AE and ERGO II-LSTM models on both McPAS and VDJDB datasets. TCR-ESM also showed a higher performance on the test sets when trained on VDJDB as compared to McPAS, even after filtering similar sequences (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Fig. S14</xref>). Overall, the TCR-ESM-MHC model showed improved performance on an external dataset, indicating that the approach has promising generalization capabilities. The results are encouraging because it suggests that the model is not simply memorizing the training data, but rather learning more generalizable features that can be applied to different types of data. Further testing on a variety of external datasets will be necessary to confirm the robustness of this approach, nevertheless, the initial results seem promising.<fig id="fig0025"><label>Fig. 5</label><caption><p><bold>:</bold> Comparison on external test set performance for netTCR2.0, ERGO II-AE, ERGO II-LSTM and TCR-ESM models. Models were trained on McPAS and VDJDB datasets and tested on PMTNet dataset (a), after removing peptides from the test set that are common to the training sets (b), after removing peptides that share 90% similarity with any peptide in the train sets (c) and after filtering 80% similar peptides (d). (e) Two-dimensional t-SNE embeddings for positive and negative peptides for an external dataset TCR(CDR3β) ‘CASPGLAGEYEQYF’ from the Penultimate Dense Layer of model (TCR(CDR3β) + peptide). Two-dimensional t-SNE of ESM-generated embeddings of (f) test set peptides which bind to different MHC-I types (HLA-A vs HLA-B), and (g) different MHC-I subtypes (HLA-A, HLA-B, and HLA-C). All statistical comparisons were done using Mann-Whitney U test using Benjamini-Hochberg correction (ns: p &lt; = 1.00e+00, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5" id="lk0025"/></fig></p>
      <p id="p0085">Next, the embeddings learned by the model in this external set case were evaluated. One particular case was identified where the model generalizes for the CDR3β sequence ‘CASPGLAGEYEQYF’ which is not present in the training set. The embeddings learned by the penultimate layer of the TCR-ESM-MHC model were able to reliably differentiate between positive and negative peptides which can bind to ‘CASPGLAGEYEQYF’ (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>e</bold>).</p>
      <p id="p0090">The embeddings learned by the model were observed to help differentiate between peptides which bind to HLA-A versus peptides which bind to HLA-B (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>f</bold>). The embeddings were able to capture this information and encode it in a way that allows the model to accurately predict the binding status of a given peptide. It suggests that models trained on embeddings learned by large protein language models can also be used to predict the immunogenicity of different peptides and other related tasks. The nature of the HLA subtype with which a peptide is presented to T cells determines the immunogenicity, the <xref rid="fig0025" ref-type="fig">Fig. 5</xref> shows that the embeddings can learn the differences in these HLA subtypes. While it is true that the immunogenicity of a peptide cannot be predicted directly by the embeddings of the HLA, extracting meaningful features is a key step in building powerful prediction models. Also, the embeddings could distinguish between the HLA types for the positive peptides present in the test data (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>g</bold>).</p>
    </sec>
  </sec>
  <sec id="sec0040">
    <label>3</label>
    <title>Discussion</title>
    <p id="p0095">One major obstacle in the creation of T-cell therapies is the difficulty of identifying the specific targets, known as cognate targets, that are recognized by T-cell receptors (TCRs). This is a crucial step in the development of these therapies because the TCRs are responsible for recognizing and binding to these targets in order to initiate an immune response. Without the ability to identify and target these cognate targets, it is difficult to effectively design and implement T-cell therapies. By creating models that can anticipate TCR-pMHC interactions based on the amino acid sequences of the peptide and CDR3 region of the TCR chains, we present a study that aims to address this bottleneck using learned representations of peptides extracted using large protein language models. There were several model designs examined, ranging from single chain CDR3α-peptide binding prediction to paired CDR3α-CDR3β-peptide-MHC binding. The models were built utilizing rigorous data-redundancy reduction guidelines, trained using cross-validation, and verified using independent assessment data.</p>
    <p id="p0100">Models that used data from paired TCR category, included both CDR3α and CDR3β information, performed significantly better when compared to models trained on data with only CDR3β information. The results from the proposed study support the idea that both TCR chains contribute to TCR specificity, and that their relative importance varies depending on the specific pMHC being targeted. Considering that the datasets of McPAS and VDJDB are vastly different, the results comparing model performance on the two sets should be taken with a pinch of salt. However, on the same dataset, for example, McPAS, the TCR-ESM model does not show significant improvement in performance as opposed to ERGO II, which shows significant improvement upon inclusion of MHC data. This could be attributed to the nature of the prediction model itself. TCR-ESM is able to learn the distinguishing properties between the two classes completely based on the CDR3 sequence information. The McPAS dataset has more variable MHC chain information and the MCC score of TCR-ESM is lesser than that for the MCC on the VDJDB set, with less variable MHC information. This could be a case of the model being overfit on the limited data.</p>
    <p id="p0105">Furthermore, the inclusion of MHC information in the prediction task of TCR-peptide binding may improve the performance of the model. The impact of MHC on TCR-peptide binding is highly dataset specific and can vary depending on the characteristics of the dataset being used. The role of MHC in TCR recognition is highly complex and context-dependent, influenced by factors such as MHC polymorphism, peptide binding motifs, and peptide-MHC interactions. These factors can introduce variability in TCR-peptide binding across different datasets. Although the dataset specificity of MHC influence presents a challenge, our proposed method aims to capture and model the general principles underlying TCR-peptide binding, while acknowledging the dataset-specific nuances. By incorporating a diverse range of training data that covers various MHC alleles and peptide sequences, the model developed captures the common features and patterns of TCR-peptide binding. Furthermore, during the development and evaluation of the method, steps have been taken to address dataset specificity. It is ensured that the training dataset comprises a broad representation of MHC alleles to account for the variability in MHC-specific effects. This allows the model to learn generalizable features that are not overly biased towards any specific MHC allele.</p>
    <p id="p0110">Another limitation of the study being that it is important to carefully evaluate the impact of MHC on model performance for each specific dataset in order to determine the most effective approach for modeling TCR-peptide binding. This may be attributed to multiple peptides being generally presented by the same MHC allotypes and also multiple MHC allotypes presenting similar peptides, depending on the peptide processing and presentation pathway of the host organism.</p>
    <p id="p0115">Both negative and positive samples are essential to train a binary classifier. In the absence of negative instances derived experimentally, data points were generated by shuffling the positive set, as was derived from previous studies as described in the Methods section. However, the approaches assume that TCRs show no cross-reactivity. However, this assumption, due to challenges in obtaining negative training data, may limit the model's utility, especially in predicting the behavior of promiscuous TCRs, with the capacity to bind diverse peptide-MHC complexes. TCRs exhibit varying degrees of cross-reactivity, recognizing structurally similar peptides presented by different MHC molecules. Without accounting for cross-reactivity, predictions for promiscuous TCRs may be inaccurate, struggling to capture nuanced interactions with diverse peptide-MHC ligands. To improve the method's utility, researchers could explore ways to incorporate cross-reactivity, possibly through additional features capturing structural and biochemical properties influencing cross-reactivity. Strategies like transfer learning or advanced architectures capable of learning hierarchical representations could be considered. Including limited experimental data on cross-reactive TCRs may further improve the model's generalization beyond training data.</p>
    <p id="p0120">The power of utilizing embeddings learned by large protein language models was determined. When these embeddings are learned by large language models, they can capture the complex relationships and patterns present in the data. By using these learned embeddings as inputs to simpler machine learning models, such as multi-layer perceptrons (MLPs), we can train these models more efficiently compared to using more complex models like convolutional neural networks (CNNs), autoencoders (AEs), or long short-term memory (LSTM) networks. In the context of peptides, utilizing learned embeddings from large protein language models and then fine-tuning the embeddings can be particularly useful for tasks such as classification. The fine-tuned embeddings can be specific to the problem being addressed, in this case, they capture the interactions between proteins, such as TCRs, antigens, and MHCs. By training a classifier in the feature space of the fine-tuned protein language model, we can learn better representations of these proteins, which may lead to improved classification performance compared to traditional approaches.</p>
    <p id="p0125">Once the embeddings have been learned, they can be used as input to other machine learning models, such as classifiers or clustering algorithms. These models can then be trained on the compressed, lower-dimensional representation of the data, rather than the original high-dimensional representation. This can lead to more efficient training and faster model convergence, as well as improved performance on downstream tasks. One potential benefit of using embeddings learned by a language model instead of an autoencoder is that the embeddings capture the relationships between elements in the data, such as amino acids in a protein sequence. This can be particularly useful for biological data, where the relationships between elements can be important for understanding the structure and function of the data. In contrast, autoencoders are generally agnostic to the relationships between elements in the data, and simply learn a compressed representation based on the patterns present in the data.</p>
    <p id="p0130">In conclusion, we have developed a model to predict the interactions between TCRs and their cognate peptides and MHC molecules. Our results indicate that accurate predictions can only be achieved through the use of data from paired TCR α and β chains. While the model’s current capabilities are limited to a specific set of peptides due to a lack of training data, we expect that its predictive ability will improve as more data becomes available, enabling it to accurately predict interactions with novel peptides. Additionally, the model framework is adaptable and can easily incorporate MHC molecules or TCRα chains when data becomes available, providing a comprehensive approach for predicting TCR-pMHC interactions.</p>
  </sec>
  <sec id="sec0045">
    <label>4</label>
    <title>Methods</title>
    <sec id="sec0050">
      <label>4.1</label>
      <title>Data collection</title>
      <p id="p0135">We download four TCR-peptide binding datasets from the GitHub repositories of netTCR2.0 (https://GitHub.com/mnielLab/NetTCR-2.0), ERGO II (https://GitHub.com/IdoSpringer/ERGO II-II) and pMTnet (https://GitHub.com/tianshilu/pMTnet). The ERGO II repository contains McPAS and VDJDB datasets. Since multiple peptides may be presented by the same MHC alleles, the MHC-peptide information may be repeated in the positive and negative classes. However, the peptide-TCR pairs experimentally validated were labeled as the positive class, the negative set was generated by generating random TCR-peptide combinations and ensuring these pairs are absent from the positive dataset. The training and test datasets were obtained from the ERGO II and netTCR2.0 repositories. The external test dataset, MIRA, was also obtained from the netTCR2.0 GitHub repository. The MIRA dataset contained 376 CDR3β-peptide pairs associated with HLA-A* 02:01. We used partitioned data as detailed in netTCR2.0 and ERGO II. The pMTnet dataset was used as an external test dataset. A detailed summary of all the datasets used in this work is provided in <xref rid="sec0085" ref-type="sec">Supplementary Table 3</xref> and <xref rid="sec0085" ref-type="sec">Supplementary Table 4</xref>.</p>
      <p id="p0140">The McPAS and VDJDB datasets were processed to give two working datasets for model training and testing. The peptide and HLA counts of the two datasets are indicated in <xref rid="sec0085" ref-type="sec">Supplementary Figure 15</xref>. Subset-1 contains paired CDR3α, CDR3β and peptide information only. Subset-2 contains paired CDR3α, CDR3β, peptide and MHC information. We utilized the fair-esm python library provided by the ESM project to extract the embeddings for the TCR, peptide and MHC sequences <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>. First, a FASTA file was created for each dataset. The FASTA files were parsed to the ESM1v model to extract the pre-final layer embeddings of size 1280 for each sequence. The embeddings would have the size of 1280 * peptide length (L). Global average pooling was then employed to convert it to a 1 * 1280-dimensional vector.</p>
    </sec>
    <sec id="sec0055">
      <label>4.2</label>
      <title>Model training and performance evaluation metrics</title>
      <p id="p0145">The ESM1v protein model was employed as mentioned in the original paper without finetuning <xref rid="bib19" ref-type="bibr">[19]</xref>. ESM1v-extracted embeddings encode the TCR, peptide and MHC information. The embeddings were fed into a feedforward neural network to predict binding. Grid search was used to optimize model hyperparameters such as learning rate (ranging from 10<sup>−1</sup> to 10<sup>−4</sup>), dropout rate (ranging from 0.2 to 0.5), number of hidden layers (ranging from 1 to 2) and number of nodes (ranging from 2<sup>2</sup> to 2<sup>7</sup>) in each layer. netTCR2.0 and ERGO II models were run on the datasets as baselines to independently calculate the MCC value for the benchmarking task. The performance was compared with the reported performance values for netTCR2.0 and ERGO II, to verify accurate reproduction of results.</p>
      <p id="p0150">The model uses the GELU activation function <xref rid="bib29" ref-type="bibr">[29]</xref> in all of its hidden layers and the binary cross-entropy loss function for optimization. During training, the learning rate was set to 0.08 and was reduced by 5% if the validation MCC did not improve after 50 epochs. This was done using a learning rate scheduler to adapt to the changing dynamics of the training data and potentially improve model performance.</p>
      <p id="p0155">The model prediction performance was tested mainly based on MCC, which is reported to be a reliable statistical measure over other metrics such as AUC-ROC and AUC-PR since we performed classification on imbalance datasets <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib30" ref-type="bibr">[30]</xref>. The MCC is defined as the correlation between the observed and predicted binary classifications. It ranges from − 1–1, with values closer to 1 or − 1 indicating a stronger correlation and a better model performance. A value of 0 indicates no correlation, while negative values indicate an inverse correlation. The MCC results in a high score only when the predictions are reliable on all of the four categories- true and false positives as well as true and false negatives, while being proportional to the size of positive and negative samples in the dataset <xref rid="bib31" ref-type="bibr">[31]</xref>. The model performance is also tested and reported on the area under the receiver operating characteristic (AUC-ROC), area under the precision-recall curve (AU-PR) as well as F1 scores. The metrics are calculated as:<disp-formula id="eqn0005"><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0010"><mml:math id="M2" altimg="si0002.svg"><mml:mrow><mml:mi mathvariant="italic">Recall</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0015"><mml:math id="M3" altimg="si0003.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mi mathvariant="italic">score</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow></mml:mfrac><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0020"><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:mi mathvariant="italic">MCC</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow><mml:mrow><mml:mo>√</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where TN: true negatives, TP: true positives, FN: false negatives and FP: false positives.</p>
    </sec>
    <sec id="sec0060">
      <label>4.3</label>
      <title>Feature importance determination (ablation experiment)</title>
      <p id="p0160">Feature importance was determined through ablation studies, which involve systematically removing or "ablating" each feature from the model one at a time and measuring the impact on model performance. By comparing the model's performance with and without a given feature, one can determine the importance of that feature in driving the model output. In the context of TCR-peptide binding, feature importance determination and ablation studies can be used to identify which CDR3 chains in the TCR has significant contribution towards binding the peptides. In cases when MHC information is added to the model, ablation studies help determine whether the added information is useful or not. For TCR-peptide binding prediction, we created three different feature subsets: CDR3α-peptide, CDR3β-peptide and CDR3α-CDR3β-peptide. Similarly, for TCR-pMHC binding, we created six different feature subsets such as CDR3α-peptide, CDR3β-peptide, CDR3α-CDR3β-peptide, CDR3α-peptide-MHC, CDR3β-peptide-MHC and CDR3α-CDR3β-peptide-MHC to calculate if adding more features improves the performance of the TCR-pMHC binding prediction. Individual models such as ERGO II-Autoencoder (ERGO II-AE), ERGO II-LSTM and TCR-ESM (developed in this study), were trained for these subsets and the MCC metric was calculated to test the performance. We checked for statistical significance of performance using T-test and used Benjamini-Hochberg (BH) p-value correction to account for multiple testing <xref rid="bib32" ref-type="bibr">[32]</xref>.</p>
    </sec>
    <sec id="sec0065">
      <label>4.4</label>
      <title>Analysis of fine-tuned embeddings</title>
      <p id="p0165">The output of the intermediate and penultimate layers was extracted from the TCR-ESM feedforward neural network for the most frequent peptides in both McPAS and VDJDB dataset. t-distributed Stochastic Neighbor Embedding (t-SNE) was then performed on the output embeddings to reduce them to 2D for visualizing if the positive and negative TCRs cluster separately.</p>
    </sec>
    <sec id="sec0070">
      <label>4.5</label>
      <title>External testing analysis</title>
      <p id="p0170">A crucial component of assessing deep learning models is external testing. The model performance is tested on data samples taken from an external, other than the training data. Model performance on external samples can reveal information about how well it generalizes, or how well it can make predictions about unknown data. The model, when used in settings where it is likely to encounter data that differs from the training data, such as in the real world, external testing is especially important. We checked the generalizability by testing the TCR-ESM model on an independent dataset obtained from pMTnet <xref rid="bib26" ref-type="bibr">[26]</xref> (<xref rid="sec0085" ref-type="sec">Supplementary Table S5</xref>), which is a recently reported experimental dataset of TCR-peptide-MHC binding. pMTnet contains CDR3-peptide sequences which are different from CDR3-peptides sequences present in the McPAS and VDJDB datasets, however, there are some common peptides. The TCR-ESM models trained on McPAS and VDJDB were tested on the pMTNet set as is, after removing the common peptides and also after filtering based on 90 % and 80 % sequence similarity (sim) score measured by aligning the peptides pairwise and normalizing the alignment scores by length of the peptide.<disp-formula id="eqn0025"><mml:math id="M5" altimg="si0005.svg"><mml:mrow><mml:mi mathvariant="italic">sim</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="italic">score</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">len</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="italic">len</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>Where A is the set of all local alignments between sequences S<sub>1</sub> and S<sub>2</sub>, and a is the alignment with the highest score score(a).</p>
    </sec>
  </sec>
  <sec id="sec0075">
    <title>Author Statement</title>
    <p id="p0175">We confirm that the manuscript has been read and approved by all authors.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing Interest</title>
    <p id="p0180">The authors declare no conflict of interest.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>S.-Q.</given-names>
          </name>
          <name>
            <surname>Parker</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>K.-Y.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Z.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Direct measurement of T cell receptor affinity and sequence from naïve antiviral T cells</article-title>
        <source>Sci Transl Med</source>
        <volume>8</volume>
        <issue>341</issue>
        <year>2016</year>
        <comment>341ra377-341ra377</comment>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Sprent</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Surh</surname>
            <given-names>C.D.</given-names>
          </name>
        </person-group>
        <article-title>T cell memory</article-title>
        <source>Annu Rev Immunol</source>
        <volume>20</volume>
        <issue>1</issue>
        <year>2002</year>
        <fpage>551</fpage>
        <lpage>579</lpage>
        <pub-id pub-id-type="pmid">11861612</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Springer</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Besser</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Tickotsky-Moskovitz</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Dvorkin</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Louzoun</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of specific TCR-peptide binding from large dictionaries of TCR-peptide pairs</article-title>
        <source>Front Immunol</source>
        <volume>11</volume>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Springer</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Tickotsky</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Louzoun</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Contribution of T cell receptor alpha and beta CDR3, MHC typing, V and J genes to peptide binding prediction</article-title>
        <source>Front Immunol</source>
        <volume>12</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">664514</object-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>Bjorkman</surname>
            <given-names>P.J.</given-names>
          </name>
        </person-group>
        <article-title>T-cell antigen receptor genes and T-cell recognition</article-title>
        <source>Nature</source>
        <volume>334</volume>
        <issue>6181</issue>
        <year>1988</year>
        <fpage>395</fpage>
        <lpage>402</lpage>
        <pub-id pub-id-type="pmid">3043226</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Krogsgaard</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>M.M.</given-names>
          </name>
        </person-group>
        <article-title>How T cells' see'antigen</article-title>
        <source>Nat Immunol</source>
        <volume>6</volume>
        <issue>3</issue>
        <year>2005</year>
        <fpage>239</fpage>
        <lpage>245</lpage>
        <pub-id pub-id-type="pmid">15716973</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>La Gruta</surname>
            <given-names>N.L.</given-names>
          </name>
          <name>
            <surname>Gras</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Daley</surname>
            <given-names>S.R.</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>P.G.</given-names>
          </name>
          <name>
            <surname>Rossjohn</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Understanding the drivers of MHC restriction of T cell receptors</article-title>
        <source>Nat Rev Immunol</source>
        <volume>18</volume>
        <issue>7</issue>
        <year>2018</year>
        <fpage>467</fpage>
        <lpage>478</lpage>
        <pub-id pub-id-type="pmid">29636542</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Bagaev</surname>
            <given-names>D.V.</given-names>
          </name>
          <name>
            <surname>Vroomans</surname>
            <given-names>R.M.A.</given-names>
          </name>
          <name>
            <surname>Samir</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Stervbo</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Rius</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Dolton</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>VDJdb in 2019: database extension, new analysis infrastructure and a T-cell receptor motif compendium</article-title>
        <source>Nucleic Acids Res</source>
        <volume>48</volume>
        <issue>D1</issue>
        <year>2020</year>
        <fpage>D1057</fpage>
        <lpage>D1062</lpage>
        <pub-id pub-id-type="pmid">31588507</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Tickotsky</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Sagiv</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Prilusky</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Shifrut</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>McPAS-TCR: a manually curated catalogue of pathology-associated T cell receptor sequences</article-title>
        <source>Bioinformatics</source>
        <volume>33</volume>
        <issue>18</issue>
        <year>2017</year>
        <fpage>2924</fpage>
        <lpage>2929</lpage>
        <pub-id pub-id-type="pmid">28481982</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Lanzarotti</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Marcatili</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>T-cell receptor cognate target prediction based on paired α and β chain sequence and structural CDR loop similarities</article-title>
        <source>Front Immunol</source>
        <volume>10</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">2080</object-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Dash</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Fiore-Gartland</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Hertz</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G.C.</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Souquette</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantifiable predictive features define epitope-specific T cell receptor repertoires</article-title>
        <source>Nature</source>
        <volume>547</volume>
        <issue>7661</issue>
        <year>2017</year>
        <fpage>89</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="pmid">28636592</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>Y.C.</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Lowery</surname>
            <given-names>F.J.</given-names>
          </name>
          <name>
            <surname>Gartner</surname>
            <given-names>J.J.</given-names>
          </name>
          <name>
            <surname>Prickett</surname>
            <given-names>T.D.</given-names>
          </name>
          <name>
            <surname>Robbins</surname>
            <given-names>P.F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Direct identification of neoantigen-specific TCRs from tumor specimens by high-throughput single-cell sequencing</article-title>
        <source>J Immunother Cancer</source>
        <volume>9</volume>
        <issue>7</issue>
        <year>2021</year>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Lundegaard</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lund</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Predictions versus high-throughput experiments in T-cell epitope discovery: competition or synergy?</article-title>
        <source>Expert Rev Vaccin</source>
        <volume>11</volume>
        <issue>1</issue>
        <year>2012</year>
        <fpage>43</fpage>
        <lpage>54</lpage>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Jokinen</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Huuhtanen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mustjoki</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Heinonen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lähdesmäki</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>
        <source>PLOS Comp Biol</source>
        <volume>17</volume>
        <issue>3</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e1008814</object-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>Gielis</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Moris</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bittremieux</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>De Neuter</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Ogunjimi</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Laukens</surname>
            <given-names>K.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Detection of enriched T cell epitope specificity in full T cell receptor sequence repertoires</article-title>
        <source>Front Immunol</source>
        <volume>10</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">2820</object-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Jurtz</surname>
            <given-names>V.I.</given-names>
          </name>
          <name>
            <surname>Jessen</surname>
            <given-names>L.E.</given-names>
          </name>
          <name>
            <surname>Bentzen</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Jespersen</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Mahajan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vita</surname>
            <given-names>R.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NetTCR: sequence-based prediction of TCR binding to peptide-MHC complexes using convolutional neural networks</article-title>
        <source>BioRxiv</source>
        <year>2018</year>
        <object-id pub-id-type="publisher-id">433706</object-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Isacchini</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Walczak</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Mora</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Nourmohammad</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Deep generative selection models of T and B cell receptor repertoires with soNNia</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <volume>118</volume>
        <issue>14</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e2023141118</object-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Vig</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Madani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Varshney</surname>
            <given-names>L.R.</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Socher</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Rajani</surname>
            <given-names>N.F.</given-names>
          </name>
        </person-group>
        <article-title>BERTology meets biology: interpreting attention in protein language models</article-title>
        <source>arXiv Prepr</source>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Rives</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Meier</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sercu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Goyal</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <volume>118</volume>
        <issue>15</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e2016239118</object-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Kalakoti</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yadav</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sundar</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>TransDTI: transformer-based language models for estimating DTIs and building a drug recommendation workflow</article-title>
        <source>ACS Omega</source>
        <volume>7</volume>
        <issue>3</issue>
        <year>2022</year>
        <fpage>2706</fpage>
        <lpage>2717</lpage>
        <pub-id pub-id-type="pmid">35097268</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Meier</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Verkuil</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sercu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Rives</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Language models enable zero-shot prediction of the effects of mutations on protein function</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <volume>34</volume>
        <year>2021</year>
        <fpage>29287</fpage>
        <lpage>29303</lpage>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Littmann</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Heinzinger</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Dallago</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Olenyi</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Embeddings from deep learning transfer GO annotations beyond homology</article-title>
        <source>Sci Rep</source>
        <volume>11</volume>
        <issue>1</issue>
        <year>2021</year>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="pmid">33414495</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Akin</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Hie</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>W.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>
        <source>Science</source>
        <volume>379</volume>
        <issue>6637</issue>
        <year>2023</year>
        <fpage>1123</fpage>
        <lpage>1130</lpage>
        <pub-id pub-id-type="pmid">36927031</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>Montemurro</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Schuster</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Povlsen</surname>
            <given-names>H.R.</given-names>
          </name>
          <name>
            <surname>Bentzen</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Jurtz</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Chronister</surname>
            <given-names>W.D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NetTCR-2.0 enables accurate prediction of TCR-peptide binding by using paired TCRα and β sequence data</article-title>
        <source>Commun Biol</source>
        <volume>4</volume>
        <issue>1</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">1060</object-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Shugay</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bagaev</surname>
            <given-names>D.V.</given-names>
          </name>
          <name>
            <surname>Zvyagin</surname>
            <given-names>I.V.</given-names>
          </name>
          <name>
            <surname>Vroomans</surname>
            <given-names>R.M.</given-names>
          </name>
          <name>
            <surname>Crawford</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Dolton</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>VDJdb: a curated database of T-cell receptor sequences with known antigen specificity</article-title>
        <source>Nucleic Acids Res</source>
        <volume>46</volume>
        <issue>D1</issue>
        <year>2018</year>
        <fpage>D419</fpage>
        <lpage>D427</lpage>
        <pub-id pub-id-type="pmid">28977646</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning-based prediction of the T cell receptor–antigen binding specificity</article-title>
        <source>Nat Mach Intell</source>
        <volume>3</volume>
        <issue>10</issue>
        <year>2021</year>
        <fpage>864</fpage>
        <lpage>875</lpage>
        <pub-id pub-id-type="pmid">36003885</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</article-title>
        <source>BMC Genom</source>
        <volume>21</volume>
        <issue>1</issue>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">6</object-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sbref28">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The Matthews correlation coefficient (MCC) should replace the ROC AUC as the standard metric for assessing binary classification</article-title>
        <source>BioData Min</source>
        <volume>16</volume>
        <issue>1</issue>
        <year>2023</year>
        <object-id pub-id-type="publisher-id">4</object-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="journal" id="sbref29">
        <person-group person-group-type="author">
          <name>
            <surname>Hendrycks</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Gimpel</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Gaussian error linear units (gelus)</article-title>
        <source>arXiv Prepr</source>
        <year>2016</year>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sbref30">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Tötsch</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation</article-title>
        <source>BioData Min</source>
        <volume>14</volume>
        <issue>1</issue>
        <year>2021</year>
        <fpage>1</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="pmid">33430939</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sbref31">
        <person-group person-group-type="author">
          <name>
            <surname>Boughorbel</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Jarray</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>El-Anbari</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Optimal classifier for imbalanced data using Matthews correlation coefficient metric</article-title>
        <source>PLOS One</source>
        <volume>12</volume>
        <issue>6</issue>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">e0177678</object-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sbref32">
        <person-group person-group-type="author">
          <name>
            <surname>Benjamini</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hochberg</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>
        <source>J R Stat Soc: Ser B (Methodol)</source>
        <volume>57</volume>
        <issue>1</issue>
        <year>1995</year>
        <fpage>289</fpage>
        <lpage>300</lpage>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="sec0085" sec-type="supplementary-material">
    <label>Appendix A</label>
    <title>Supplementary material</title>
    <p id="p0190"><supplementary-material content-type="local-data" id="ec0005"><caption><p>Supplementary material</p></caption><media xlink:href="mmc1.pdf"/></supplementary-material>.</p>
    <p id="p0195"><supplementary-material content-type="local-data" id="ec0010"><caption><p>Supplementary material</p></caption><media xlink:href="mmc2.pptx"/></supplementary-material>.</p>
  </sec>
  <sec sec-type="data-availability" id="da0005">
    <title>Data availability</title>
    <p id="p0005">Raw data can be downloaded from the GitHub links as mentioned in the methods section. Processed data and the working code are available at https://GitHub.com/dhanjal-lab/tcr-esm.</p>
  </sec>
  <fn-group>
    <fn id="sec0080" fn-type="supplementary-material">
      <label>Appendix A</label>
      <p id="p0185">Supplementary data associated with this article can be found in the online version at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.csbj.2023.11.037" id="ir0005">doi:10.1016/j.csbj.2023.11.037</ext-link>.</p>
    </fn>
  </fn-group>
</back>
<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_CSBJ2415 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEga1 jpg ?>
<?FILEmmc1 pdf ?>
<?FILEmmc2 pptx ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Struct Biotechnol J</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Struct Biotechnol J</journal-id>
    <journal-title-group>
      <journal-title>Computational and Structural Biotechnology Journal</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2001-0370</issn>
    <publisher>
      <publisher-name>Research Network of Computational and Structural Biotechnology</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10749252</article-id>
    <article-id pub-id-type="pii">S2001-0370(23)00452-X</article-id>
    <article-id pub-id-type="doi">10.1016/j.csbj.2023.11.037</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TCR-ESM: Employing protein language embeddings to predict TCR-peptide-MHC binding</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Yadav</surname>
          <given-names>Shashank</given-names>
        </name>
        <xref rid="aff0005" ref-type="aff">a</xref>
        <xref rid="fn1" ref-type="fn">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Vora</surname>
          <given-names>Dhvani Sandip</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="fn1" ref-type="fn">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Sundar</surname>
          <given-names>Durai</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au0020">
        <name>
          <surname>Dhanjal</surname>
          <given-names>Jaspreet Kaur</given-names>
        </name>
        <email>jaspreet@iiitd.ac.in</email>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="aff0005"><label>a</label>Department of Biomedical Engineering, University of Arizona, Tucson 85721, AZ, USA</aff>
      <aff id="aff0010"><label>b</label>Department of Biochemical Engineering and Biotechnology, Indian Institute of Technology Delhi, New Delhi 110016, India</aff>
      <aff id="aff0015"><label>c</label>Department of Computational Biology, Indraprastha Institute of Information Technology, Delhi, New Delhi 110020, India</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding author. <email>jaspreet@iiitd.ac.in</email></corresp>
      <fn id="fn1">
        <label>1</label>
        <p id="ntp0005">Equal contribution</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <volume>23</volume>
    <fpage>165</fpage>
    <lpage>173</lpage>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>19</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>11</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 The Authors</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>Cognate target identification for T-cell receptors (TCRs) is a significant barrier in T-cell therapy development, which may be overcome by accurately predicting TCR interaction with peptide-bound major histocompatibility complex (pMHC). In this study, we have employed peptide embeddings learned from a large protein language model- Evolutionary Scale Modeling (ESM), to predict TCR-pMHC binding. The TCR-ESM model presented outperforms existing predictors. The complementarity-determining region 3 (CDR3) of the hypervariable TCR is located at the center of the paratope and plays a crucial role in peptide recognition. TCR-ESM trained on paired TCR data with both CDR3α and CDR3β chain information performs significantly better than those trained on data with only CDR3β, suggesting that both TCR chains contribute to specificity, the relative importance however depends on the specific peptide-MHC targeted. The study illuminates the importance of MHC information in TCR-peptide binding which remained inconclusive so far and was thought dependent on the dataset characteristics. TCR-ESM outperforms existing approaches on external datasets, suggesting generalizability. Overall, the potential of deep learning for predicting TCR-pMHC interactions and improving the understanding of factors driving TCR specificity are highlighted. The prediction model is available at http://tcresm.dhanjal-lab.iiitd.edu.in/ as an online tool.</p>
    </abstract>
    <abstract abstract-type="graphical" id="ab0015">
      <title>Graphical abstract</title>
      <p>
        <fig id="fig0030" position="anchor">
          <alt-text id="at0030">ga1</alt-text>
          <graphic xlink:href="ga1" id="lk0030"/>
        </fig>
      </p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>T-cell therapy</kwd>
      <kwd>TCR-pMHC interactions</kwd>
      <kwd>Protein language models</kwd>
      <kwd>TCR specificity</kwd>
      <kwd>Peptide embeddings</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0010">The surveillance against pathogens and pathological cells of the body is carried out by the adaptive immune system. A cornerstone of the adaptive immune response system is the presentation of peptides by major histocompatibility complexes (MHC) class I or class II, expressed on the cell surfaces. The human MHCs are also called Human Leukocyte Antigens (HLAs) and are classified in three gene classes based on structure and function of the gene products. Class I gene products, encoded by three distinct genomic loci, HLA-A, HLA-B and HLA-C present endogenous peptides to CD8<sup>+</sup> T-cells. The letters “A”, “B” or “C” are assigned based on the antigens defined by serology. The peptide-MHC complex presented to T-cells enables recognition of the antigen via the T-cell receptors (TCR). Upon activation, the T cells undergo clonal expansion <xref rid="bib1" ref-type="bibr">[1]</xref>. A fraction of this clonally expanded repertoire is retained as long-living memory against the antigen <xref rid="bib2" ref-type="bibr">[2]</xref>. The affinity of the TCR for any peptide is governed by the heterodimeric TCRs consisting of the <italic>α</italic> and <italic>β</italic> subunits. Both chains have been reported to affect the binding of the TCR to the peptide-MHC complex (TCR-pMHC), however, prediction of TCR-pMHC binding has been carried out with high accuracy with only the <italic>β</italic> chain <xref rid="bib3" ref-type="bibr">[3]</xref>.</p>
    <p id="p0015">Within the <italic>β</italic> chain of the TCR, the three complementarity determining regions (CDRs) make primary contacts with the MHC (CDR1 and CDR2), and the peptide (CDR3), recent studies suggest contributions of the alpha chain and other CDRs as well <xref rid="bib4" ref-type="bibr">[4]</xref>. In both the <italic>α</italic> and <italic>β</italic> chains, the CD3 loops represent the region of the highest sequence diversity and hence, are the regions that determine receptor binding specificity <xref rid="bib5" ref-type="bibr">[5]</xref>, <xref rid="bib6" ref-type="bibr">[6]</xref>. The CDR3 diversity is defined by multiple genomic recombination events in the ‘Variable’ (V), ‘Diversity’ (D) and ‘Joining’ (J) TCR-related genes. The V- and J- recombinations make up the α-chain while the β-chain is a result of the V-, D- and J genes generating a broader diversity. Hence, most of the previous studies have focused only on the β-chain.</p>
    <p id="p0020">The Immune Epitope database, VDJDB and McPAS-TCR primarily contains information on CDR3β and houses a large fraction of the publicly available TCR-pMHC binding data <xref rid="bib7" ref-type="bibr">[7]</xref>, <xref rid="bib8" ref-type="bibr">[8]</xref>, <xref rid="bib9" ref-type="bibr">[9]</xref>. Recent studies illuminate the importance of CDR3 of both α- and β-chains in driving specificity of the TCR <xref rid="bib10" ref-type="bibr">[10]</xref>, <xref rid="bib11" ref-type="bibr">[11]</xref>. While single-cell based high-throughput techniques for assessing TCR-pMHC binding are available, determining the role of individual components remains a time- and resource-intensive pursuit <xref rid="bib12" ref-type="bibr">[12]</xref>, <xref rid="bib13" ref-type="bibr">[13]</xref>.</p>
    <p id="p0025">Various studies have reported TCR-pMHC data modeling and prediction techniques, mostly based on the data from VDJDB, IEDB and McPAS-TCR, using either or both CDR3 α- and β-sequences. These previous studies have employed Gaussian processes, position-specific scoring matrices, deep learning methods <xref rid="bib14" ref-type="bibr">[14]</xref>, <xref rid="bib15" ref-type="bibr">[15]</xref>, <xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib17" ref-type="bibr">[17]</xref> as well as advanced methods employing Natural Language Processing (NLP) <xref rid="bib3" ref-type="bibr">[3]</xref>. The performance of current methods is limited by the paucity of available data. The applicability in terms of generalizability of the predictors is also hindered by the redundancy in epitope specific TCR sequences. Extracting relevant information from sequence data, labeled and unlabeled, has been demonstrated by NLP-based self-supervised learning algorithms. One such algorithm, Bidirectional Encoder Representations from Transformers (BERT), has been reported to reliably capture biological properties of proteins <xref rid="bib18" ref-type="bibr">[18]</xref>. Large protein language models such as ESM (Evolutionary Scale Model) <xref rid="bib19" ref-type="bibr">[19]</xref> and its variants have been used to predict biological structure and function of proteins. Also, the embeddings learned by the model have been fine-tuned for downstream tasks such as protein-drug interactions prediction <xref rid="bib20" ref-type="bibr">[20]</xref>, protein variant effect prediction <xref rid="bib21" ref-type="bibr">[21]</xref> and gene ontology annotation <xref rid="bib22" ref-type="bibr">[22]</xref>.</p>
    <p id="p0030">Here, we present TCR-ESM, a deep learning-based model to predict TCR-peptide-MHC binding. TCR-ESM is a feedforward neural network trained on embeddings extracted from ESM, a protein language model <xref rid="bib23" ref-type="bibr">[23]</xref>. ESM1v - a variant in the ESM family of protein language models has been used to generate sequence length-independent embeddings for the three protein moieties involved in the binding. The encoded protein sequence information is fed into a feedforward neural network to predict possibility of interaction. The positive data class consists of experimentally validated pairs of class 1 and class 2 MHC-peptide which bind to the TCRs. The negative data is generated by mismatching the positive dataset and ensuring the new combinations are absent in the positive class. Ablation analysis has also been carried out to qualitatively determine the importance of the TCRα, TCRβ and MHC components in the classifier's predictions. The study has been benchmarked against current TCR-pMHC prediction models such as pEptide tcR matchinG predictiOn (ERGO II) <xref rid="bib4" ref-type="bibr">[4]</xref> and netTCR2.0 <xref rid="bib24" ref-type="bibr">[24]</xref> using the netTCR2.0, McPAS and VDJDB datasets <xref rid="bib3" ref-type="bibr">[3]</xref>, <xref rid="bib9" ref-type="bibr">[9]</xref>, <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib25" ref-type="bibr">[25]</xref>. Our model, TCR-ESM has also been tested on the external dataset MIRA, as reported in the netTCR2.0 study as well as an additional independent external test set pMTnet <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib26" ref-type="bibr">[26]</xref>. We report improved prediction capacity based on the Matthews correlation coefficient (MCC) score, which has been established as a more reliable performance metrics in binary classification on imbalanced data rather than precision, recall and ROC AUC <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib28" ref-type="bibr">[28]</xref>. The MCC score ranges from 0, indicating poor model predictive performance, to 1, signifying ideal model performance. However, we additionally report model performance on precision-recall, ROC AUC as well as the F1 score. We also observe that fine tuning the embeddings extracted from large protein language models can preserve both local and global information towards specific objectives.</p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Results</title>
    <p id="p0035">The TCR-ESM prediction model was trained on the peptide, TCR and MHC embeddings as detailed in <xref rid="fig0005" ref-type="fig">Fig. 1</xref>. The peptide, TCR and MHC sequence information was fed into the neural network after embeddings were generated from the penultimate layer of the ESM1v model (<xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>a</bold>). The feedforward neural network was trained to predict TCR-peptide binding pairs as 1, and non-interacting pairs as 0. Performance was evaluated over MCC scores, area under the receiver operating characteristic (AUC-ROC), area under the Precision-Recall curve (AU-PR) and F1 scores. The choice of model architecture was governed by the feature set in consideration. For instance, for predicting CDR3α-CDR3β-peptide binding the model illustrated in <xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>b</bold> was used. Similarly, <xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>c</bold> illustrates the model used for CDR3α-CDR3β-peptide-MHC binding. For CDR3α-peptide, CDR3β-peptide, CDR3α-peptide-MHC, CDR3β-peptide-MHC binding prediction, the model architectures are illustrated in <xref rid="sec0085" ref-type="sec">Supplementary Figure 1a, 1b, 1c and 1d</xref>, respectively.<fig id="fig0005"><label>Fig. 1</label><caption><p><bold>:</bold> Schematic of the method followed. (a) The ESM1v protein language model was employed to extract the sequence information in the form of 1280-dimensional embeddings for each of the three components- TCR, peptide and MHC. (b) Architecture of the neural network employed for the TCR(CDR3α+CDR3β)-peptide binding classification task. (c) The neural network architecture employed for the TCR(CDR3α+CDR3β)-peptide-MHC binding prediction task.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1" id="lk0005"/></fig></p>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Model performance evaluation on CDR3β data</title>
      <p id="p0040">The probability of the TCR-peptide binding predicted by TCR-ESM on the netTCR2.0 CDR3β dataset was evaluated. A side-by-side comparison of TCR-ESM with the 1D CNN-based netTCR2.0 was carried out. The data was prepared and partitioned the same as the netTCR2.0 study <xref rid="bib24" ref-type="bibr">[24]</xref>. The netTCR2.0, ERGO-AE, ERGO-LSTM and the classifier presented in this study- TCR-ESM were trained, and cross-validation was carried out on the CDR3β data. Same as netTCR2.0, five different MIRA datasets were obtained by imposing a separation from the training set of 90 %, 92 %, 94 %, 99 %, and 100 % similarity. That is, MIRA 94 % TCRs do not share more than 94% Levenshtein similarity to any of the TCRs in the training set. These datasets were used as independent test sets. Our model outperformed netTCR2.0 on all similarity-based partition thresholds (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>a,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1a</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Figs. S2, S3 and S4</xref>.<fig id="fig0010"><label>Fig. 2</label><caption><p><bold>:</bold> Model performance benchmarking. (a) Comparison of TCR-ESM with netTCR2.0 on the external MIRA dataset as test set for different partitioning thresholds. (b) Comparison of TCR-ESM with netTCR2.0 on the MIRA dataset as test set specific to the most common peptide in the dataset, ‘GILGFVFTL’. (c) Comparison of TCR-ESM with netTCR2.0 on the MIRA dataset as test set specific to the second most common peptide ‘GLCTLVAML’. 5-fold cross validation is run independently 10 times to compare the model performance and the distribution is represented by the box-whisker plots to compare the performance of TCR-ESM with netTCR2.0 at (d) 90% partitioning threshold and (e) 95% partitioning threshold for different prediction tasks such as TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, and TCR(CDR3α+CDR3β)+peptide. All statistical comparisons were done using Mann-Whitney U test with Benjamini-Hochberg correction (ns: p &gt; 5.00e-02, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2" id="lk0010"/></fig></p>
      <p id="p0045">We then compared the peptide-specific outperformance for the two most abundant peptides, GILGFVFTL (GIL) from Influenza A virus and GLCTLVAML (GLC) from Human herpesvirus 4 (Epstein–Barr virus) for all partitioning thresholds (<xref rid="fig0010" ref-type="fig">Figs. 2</xref><bold>b,</bold>
<xref rid="fig0010" ref-type="fig">2</xref><bold>c,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1a</xref>).</p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>Model performance evaluation and ablation analysis on paired CDR3α and β</title>
      <p id="p0050">In addition to the CDR3β information, to check whether CDR3α information or paired CDR3αβ information is beneficial for the prediction of peptide binding by the TCR, the TCR-ESM model was cross-validated and benchmarked against netTCR2.0. <xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>d</bold> shows the TCR-ESM and netTCR2.0 models evaluated with 5-fold cross-validation run 10 times independently on the sequence similarity-based partitioned datasets as is from the netTCR2.0 study with the CDR3 α-chain, CDR3 β-chain, and both α- and β-chains of CDR3. The TCR-ESM model significantly outperforms (p-value &lt;= 0.05) the netTCR2.0 model on all three datasets (CDR3α only, CDR3β only, and paired). We also obtained similar outperformance for the 95% partitioned dataset (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>e,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1b</xref>). We validated this observation by comparing netTCR2.0 model performance on the three datasets (CDR3α only, CDR3β only, and paired) and found that models trained on paired chain information outperformed models trained only on single CDR3 chains. (<xref rid="sec0085" ref-type="sec">Supplementary Fig. S5</xref>).</p>
      <p id="p0055">To further validate the performance of the TCR-ESM model, we compared our model with the ERGO II model. The ERGO II model is available in two types, namely ERGO II-Autoencoder (ERGO II-AE) and ERGO II-Long Short-Term Memory (ERGO II-LSTM). Since ERGO II-AE and ERGO II-LSTM were originally benchmarked on the McPAS and VDJDB data, we utilized these datasets with exactly the same train-test splits as provided. We observed that our model outperforms netTCR2.0, ERGO II-AE and ERGO II-LSTM model for both McPAS and VDJDB paired chain datasets (10-fold cross validation, p-value&lt;=0.05, p-value correction with Benjamini-Hochberg method) (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>a,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Tables S2</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Figs. S6, S7, S8</xref>. Both McPAS and VDJDB subsets 1 lack MHC information while subsets 2 include MHC information. We cross-validated these models on the McPAS data subset-1. We also observed a similar trend on test-set MCC where our model performed better when compared to the other three models (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>b</bold>). We observe a similar trend of TCR-ESM outperforming in the VDJDB data subset-1 on both cross validation and test setting as illustrated in <xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>c</bold> and <xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>d</bold>.<fig id="fig0015"><label>Fig. 3</label><caption><p><bold>:</bold> Feature importance as determined by ablation. The box-whisker plots show model performance distribution on 10-fold cross-validation using the TCR-ESM predictor, netTCR2.0, ERGO II-AE and ERGO II-LSTM for different prediction tasks- TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, and TCR(CDR3α+CDR3β)+peptide on (a) McPAS data subset-1, (c) VDJDB data subset-1. Similarly, hold-out testing set comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model for the three different prediction tasks on (b) McPAS data subset-1, and (d) VDJDB data subset-1. 10-fold cross validated comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model for different prediction tasks such as TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, TCR(CDR3α + CDR3β) + peptide, TCR(CDR3α)+peptide+MHC, TCR(CDR3β)+peptide+MHC and TCR(CDR3α + CDR3β) + peptide+MHC on (e) McPAS data subset-2 and (g) VDJDB data subset-2. Similarly, hold-out testing set comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model was performed for the different prediction tasks on (f) McPAS data subset-2 and (h) VDJDB data subset-2. All statistical comparisons were done using Mann-Whitney U test with Bejamini-Hochberg correction (ns: p &gt; 5.00e-02, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3" id="lk0015"/></fig></p>
      <p id="p0060">Further supporting analysis on whether CDR3 paired chain information can predict the TCR-peptide binding better than single chains was carried out. We performed 10-fold cross-validation for all the four models (netTCR2.0, ERGO II-AE, ERGO II-LSTM and our TCR-ESM) on paired CDR3 in the McPAS data subset-1 as well single chains, and observed that paired CDR3 information improves the MCC significantly (t-test p-value&lt;=0.05, p-value correction with Benjamini-Hochberg method) when compared to the model trained only on CDR3α and CDR3β <bold>(</bold><xref rid="sec0085" ref-type="sec">Supplementary Figs. S9, S10</xref><bold>)</bold>. We observe a similar trend of model outperformance with paired CDR3 information on the VDJDB data subset-1 (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S6, S7, S8</xref>).</p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Model performance evaluation on paired CDR3 with MHC information and ablation analysis</title>
      <p id="p0065">The contribution of different features was further illustrated by performing ablation analysis on McPAS data subset-2 and VDJDB data subset-2, which contains MHC information. Since there are three components, CDR3α, CDR3β, and MHC, six feature sets were constructed- CDR3α only, CDR3β only, paired CDR3α-CDR3β, CDR3α-MHC, CDR3β-MHC and combined CDR3α-CDR3β-MHC. The TCR-ESM-MHC model was compared with ERGO II-AE and ERGO II-LSTM models on McPAS data subset-2 (containing MHC information) for each of the six feature sets. TCR-ESM-MHC is shown to outperform the ERGO-AE model on all six feature sets during cross-validation and on the test set, while also outperforming ERGO-LSTM on four of the six sets during cross-validation and on the test set (<xref rid="fig0015" ref-type="fig">Figs. 3</xref><bold>e,</bold>
<xref rid="fig0015" ref-type="fig">3</xref><bold>f)</bold>. TCR-ESM-MHC also outperformed on the VDJDB data subset-2 (VDJDB with MHC information) as compared to both ERGO II-AE and ERGO II-LSTM model on 10-fold cross validation and test set (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>g,</bold>
<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>h</bold>). For the ablation experiment, the ERGO II-AE, ERGO II-LSTM and TCR-ESM-MHC models were trained individually on the six feature sets. The feature importance of the MHC based on increase in MCC scores is dataset- and method-dependant. For the McPAS data subset- 2, when analysed with ERGO II-AE, addition of the MHC features significantly improved model performance indicating high feature importance. However, when the McPAS data subset-2 was analysed with ERGO II-LSTM and the TCR-ESM-MHC models, inclusion of the MHC information did not significantly improve performance reflecting low feature importance (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S8, S9, S10</xref>). Contrarily, for the VDJDB data subset-2, there was a statistically significant improvement in performance upon inclusion of the MHC features for all the models trained- ERGO II-AE, ERGO II-LSTM and TCR-ESM-MHC. The observed increase in MCC scores indicated that the MHC sequence information plays an important role in driving model output and therefore is an important feature (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S8, S9, S10</xref>).</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Analysis of embeddings learned by the TCR-ESM model</title>
      <p id="p0070">The outputs from different layers of the TCR-ESM-MHC model were extracted to understand how the output of the model is driven, t-SNE was used to reduce the layer output to two dimensions. t-SNE enables capturing local relationships while also capturing non-linear relationships in the data. This is significant to determine if the embeddings can be repurposed for related tasks. We compared the embeddings of binding TCR to non-binding TCR in the input layer, concatenation layer and penultimate dense layer. For the McPAS dataset, the most common peptide ‘GILGFVFTL’ was selected from the test set. As one progresses through the layers of our model, the outputs generated become more abstract and less directly tied to specific features in the input data. Later layers then use these abstractions to construct more sophisticated features that are better suited for specific tasks. This can lead to the outputs of the later layers being more separable, or easier to distinguish from one another, compared to the outputs of the earlier layers. The results showed that the learned embeddings became more distinct as the model was trained, with positive TCR interactions and negative TCR interactions in the independent dataset for specific peptides being mixed at the input layer (<xref rid="fig0020" ref-type="fig">Figs. 4</xref><bold>a,</bold>
<xref rid="fig0020" ref-type="fig">4</xref><bold>b</bold>). The subsequent neural network layers learn the embeddings of the multiple inputs jointly, following the input layer where the information is supplied separately. Gradually the learned embeddings can be distinguished at the concatenation and penultimate dense layers which also capture the information of binding and non-binding CDR3α and CDR3β sequences (<xref rid="fig0020" ref-type="fig">Figs. 4</xref><bold>c,</bold>
<xref rid="fig0020" ref-type="fig">4</xref><bold>d</bold>). Similarly, for the VDJDB dataset, we picked the most common ‘NLVPMVATV’ peptide and performed a similar analysis of the input, concatenation and penultimate dense layer embeddings of binding and non-binding CDRα and CDR3β sequences, as illustrated in <xref rid="sec0085" ref-type="sec">Supplementary Fig. S11</xref><bold>.</bold> A similar analysis was performed for two other randomly selected peptides, also demonstrating separability as shown in <xref rid="sec0085" ref-type="sec">Supplementary Fig. S12</xref><bold>.</bold> A layer-wise analysis of the separation obtained is studied by employing a random forest classifier at each layer and evaluating the MCC scores (<xref rid="sec0085" ref-type="sec">Supplementary Fig. S13</xref>). We observed that the model learns a joint embedding for CDR3α and CDR3β and shows separation between positive and negative TCR samples for specific peptides.<fig id="fig0020"><label>Fig. 4</label><caption><p><bold>:</bold> (a) Predictive capacity of the different layers of the TCR-ESM classifier for randomly selected peptides ‘GILGFVFTL’, ‘SSYRRPVGI’ and ‘SSLENFRAYV’. Comparison of two-dimensional t-SNE embeddings for positive and negative (b) TCR(CDR3α) and (c) TCR(CDR3β) for the most common peptide ‘GILGFVFTL’ from the Input Layer of model (TCR(CDR3α + CDR3β) + peptide) trained on McPAS dataset. Comparison of jointly learned two-dimensional T-SNE embeddings for positive and negative TCR(CDR3α + CDR3β) for the most common peptide ‘GILGFVFTL’ from the (d) Concatenation Layer and (e) Penultimate Dense Layer of model (TCR(CDR3α + CDR3β) + peptide) trained on McPAS dataset.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4" id="lk0020"/></fig></p>
    </sec>
    <sec id="sec0035">
      <label>2.5</label>
      <title>External testing analysis</title>
      <p id="p0075">The level of dissimilarity between CDR3β and peptide sequences in the pMTnet dataset with the McPAS and VDJDB dataset was determined. For CDR3β sequences, pMTnet had only one (1 in 272; 0.4% identical) CDR3β sequence which was common with CDR3β in McPAS dataset. Similarly, for the VDJDB dataset, we found that the pMTnet dataset has 39 (39 in 272; 14.7% identical) common CDR3β sequences. Comparing peptides, pMTnet data has 21 (21 in 224; 9.38% identical) common peptides with McPAS data and 42 (42 in 224; 19.6% identical) common peptides with VDJDB data.</p>
      <p id="p0080">Separate models were trained on the McPAS and VDJDB dataset and tested on the pMTnet dataset to evaluate how the models perform in an external setting (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>a</bold>). Since there were some common peptides between models trained on McPAS and VDJDB with the external pMTNet test set, the models were evaluated after removing the common peptides as well (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>b</bold>). Further stringent testing was carried out by removing peptides with 90% and 80% sequence similarity to any peptide in train sets (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>c, d</bold>). The TCR-ESM model was shown to perform significantly better than the netTCR2.0, ERGO II-AE and ERGO II-LSTM models on both McPAS and VDJDB datasets. TCR-ESM also showed a higher performance on the test sets when trained on VDJDB as compared to McPAS, even after filtering similar sequences (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Fig. S14</xref>). Overall, the TCR-ESM-MHC model showed improved performance on an external dataset, indicating that the approach has promising generalization capabilities. The results are encouraging because it suggests that the model is not simply memorizing the training data, but rather learning more generalizable features that can be applied to different types of data. Further testing on a variety of external datasets will be necessary to confirm the robustness of this approach, nevertheless, the initial results seem promising.<fig id="fig0025"><label>Fig. 5</label><caption><p><bold>:</bold> Comparison on external test set performance for netTCR2.0, ERGO II-AE, ERGO II-LSTM and TCR-ESM models. Models were trained on McPAS and VDJDB datasets and tested on PMTNet dataset (a), after removing peptides from the test set that are common to the training sets (b), after removing peptides that share 90% similarity with any peptide in the train sets (c) and after filtering 80% similar peptides (d). (e) Two-dimensional t-SNE embeddings for positive and negative peptides for an external dataset TCR(CDR3β) ‘CASPGLAGEYEQYF’ from the Penultimate Dense Layer of model (TCR(CDR3β) + peptide). Two-dimensional t-SNE of ESM-generated embeddings of (f) test set peptides which bind to different MHC-I types (HLA-A vs HLA-B), and (g) different MHC-I subtypes (HLA-A, HLA-B, and HLA-C). All statistical comparisons were done using Mann-Whitney U test using Benjamini-Hochberg correction (ns: p &lt; = 1.00e+00, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5" id="lk0025"/></fig></p>
      <p id="p0085">Next, the embeddings learned by the model in this external set case were evaluated. One particular case was identified where the model generalizes for the CDR3β sequence ‘CASPGLAGEYEQYF’ which is not present in the training set. The embeddings learned by the penultimate layer of the TCR-ESM-MHC model were able to reliably differentiate between positive and negative peptides which can bind to ‘CASPGLAGEYEQYF’ (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>e</bold>).</p>
      <p id="p0090">The embeddings learned by the model were observed to help differentiate between peptides which bind to HLA-A versus peptides which bind to HLA-B (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>f</bold>). The embeddings were able to capture this information and encode it in a way that allows the model to accurately predict the binding status of a given peptide. It suggests that models trained on embeddings learned by large protein language models can also be used to predict the immunogenicity of different peptides and other related tasks. The nature of the HLA subtype with which a peptide is presented to T cells determines the immunogenicity, the <xref rid="fig0025" ref-type="fig">Fig. 5</xref> shows that the embeddings can learn the differences in these HLA subtypes. While it is true that the immunogenicity of a peptide cannot be predicted directly by the embeddings of the HLA, extracting meaningful features is a key step in building powerful prediction models. Also, the embeddings could distinguish between the HLA types for the positive peptides present in the test data (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>g</bold>).</p>
    </sec>
  </sec>
  <sec id="sec0040">
    <label>3</label>
    <title>Discussion</title>
    <p id="p0095">One major obstacle in the creation of T-cell therapies is the difficulty of identifying the specific targets, known as cognate targets, that are recognized by T-cell receptors (TCRs). This is a crucial step in the development of these therapies because the TCRs are responsible for recognizing and binding to these targets in order to initiate an immune response. Without the ability to identify and target these cognate targets, it is difficult to effectively design and implement T-cell therapies. By creating models that can anticipate TCR-pMHC interactions based on the amino acid sequences of the peptide and CDR3 region of the TCR chains, we present a study that aims to address this bottleneck using learned representations of peptides extracted using large protein language models. There were several model designs examined, ranging from single chain CDR3α-peptide binding prediction to paired CDR3α-CDR3β-peptide-MHC binding. The models were built utilizing rigorous data-redundancy reduction guidelines, trained using cross-validation, and verified using independent assessment data.</p>
    <p id="p0100">Models that used data from paired TCR category, included both CDR3α and CDR3β information, performed significantly better when compared to models trained on data with only CDR3β information. The results from the proposed study support the idea that both TCR chains contribute to TCR specificity, and that their relative importance varies depending on the specific pMHC being targeted. Considering that the datasets of McPAS and VDJDB are vastly different, the results comparing model performance on the two sets should be taken with a pinch of salt. However, on the same dataset, for example, McPAS, the TCR-ESM model does not show significant improvement in performance as opposed to ERGO II, which shows significant improvement upon inclusion of MHC data. This could be attributed to the nature of the prediction model itself. TCR-ESM is able to learn the distinguishing properties between the two classes completely based on the CDR3 sequence information. The McPAS dataset has more variable MHC chain information and the MCC score of TCR-ESM is lesser than that for the MCC on the VDJDB set, with less variable MHC information. This could be a case of the model being overfit on the limited data.</p>
    <p id="p0105">Furthermore, the inclusion of MHC information in the prediction task of TCR-peptide binding may improve the performance of the model. The impact of MHC on TCR-peptide binding is highly dataset specific and can vary depending on the characteristics of the dataset being used. The role of MHC in TCR recognition is highly complex and context-dependent, influenced by factors such as MHC polymorphism, peptide binding motifs, and peptide-MHC interactions. These factors can introduce variability in TCR-peptide binding across different datasets. Although the dataset specificity of MHC influence presents a challenge, our proposed method aims to capture and model the general principles underlying TCR-peptide binding, while acknowledging the dataset-specific nuances. By incorporating a diverse range of training data that covers various MHC alleles and peptide sequences, the model developed captures the common features and patterns of TCR-peptide binding. Furthermore, during the development and evaluation of the method, steps have been taken to address dataset specificity. It is ensured that the training dataset comprises a broad representation of MHC alleles to account for the variability in MHC-specific effects. This allows the model to learn generalizable features that are not overly biased towards any specific MHC allele.</p>
    <p id="p0110">Another limitation of the study being that it is important to carefully evaluate the impact of MHC on model performance for each specific dataset in order to determine the most effective approach for modeling TCR-peptide binding. This may be attributed to multiple peptides being generally presented by the same MHC allotypes and also multiple MHC allotypes presenting similar peptides, depending on the peptide processing and presentation pathway of the host organism.</p>
    <p id="p0115">Both negative and positive samples are essential to train a binary classifier. In the absence of negative instances derived experimentally, data points were generated by shuffling the positive set, as was derived from previous studies as described in the Methods section. However, the approaches assume that TCRs show no cross-reactivity. However, this assumption, due to challenges in obtaining negative training data, may limit the model's utility, especially in predicting the behavior of promiscuous TCRs, with the capacity to bind diverse peptide-MHC complexes. TCRs exhibit varying degrees of cross-reactivity, recognizing structurally similar peptides presented by different MHC molecules. Without accounting for cross-reactivity, predictions for promiscuous TCRs may be inaccurate, struggling to capture nuanced interactions with diverse peptide-MHC ligands. To improve the method's utility, researchers could explore ways to incorporate cross-reactivity, possibly through additional features capturing structural and biochemical properties influencing cross-reactivity. Strategies like transfer learning or advanced architectures capable of learning hierarchical representations could be considered. Including limited experimental data on cross-reactive TCRs may further improve the model's generalization beyond training data.</p>
    <p id="p0120">The power of utilizing embeddings learned by large protein language models was determined. When these embeddings are learned by large language models, they can capture the complex relationships and patterns present in the data. By using these learned embeddings as inputs to simpler machine learning models, such as multi-layer perceptrons (MLPs), we can train these models more efficiently compared to using more complex models like convolutional neural networks (CNNs), autoencoders (AEs), or long short-term memory (LSTM) networks. In the context of peptides, utilizing learned embeddings from large protein language models and then fine-tuning the embeddings can be particularly useful for tasks such as classification. The fine-tuned embeddings can be specific to the problem being addressed, in this case, they capture the interactions between proteins, such as TCRs, antigens, and MHCs. By training a classifier in the feature space of the fine-tuned protein language model, we can learn better representations of these proteins, which may lead to improved classification performance compared to traditional approaches.</p>
    <p id="p0125">Once the embeddings have been learned, they can be used as input to other machine learning models, such as classifiers or clustering algorithms. These models can then be trained on the compressed, lower-dimensional representation of the data, rather than the original high-dimensional representation. This can lead to more efficient training and faster model convergence, as well as improved performance on downstream tasks. One potential benefit of using embeddings learned by a language model instead of an autoencoder is that the embeddings capture the relationships between elements in the data, such as amino acids in a protein sequence. This can be particularly useful for biological data, where the relationships between elements can be important for understanding the structure and function of the data. In contrast, autoencoders are generally agnostic to the relationships between elements in the data, and simply learn a compressed representation based on the patterns present in the data.</p>
    <p id="p0130">In conclusion, we have developed a model to predict the interactions between TCRs and their cognate peptides and MHC molecules. Our results indicate that accurate predictions can only be achieved through the use of data from paired TCR α and β chains. While the model’s current capabilities are limited to a specific set of peptides due to a lack of training data, we expect that its predictive ability will improve as more data becomes available, enabling it to accurately predict interactions with novel peptides. Additionally, the model framework is adaptable and can easily incorporate MHC molecules or TCRα chains when data becomes available, providing a comprehensive approach for predicting TCR-pMHC interactions.</p>
  </sec>
  <sec id="sec0045">
    <label>4</label>
    <title>Methods</title>
    <sec id="sec0050">
      <label>4.1</label>
      <title>Data collection</title>
      <p id="p0135">We download four TCR-peptide binding datasets from the GitHub repositories of netTCR2.0 (https://GitHub.com/mnielLab/NetTCR-2.0), ERGO II (https://GitHub.com/IdoSpringer/ERGO II-II) and pMTnet (https://GitHub.com/tianshilu/pMTnet). The ERGO II repository contains McPAS and VDJDB datasets. Since multiple peptides may be presented by the same MHC alleles, the MHC-peptide information may be repeated in the positive and negative classes. However, the peptide-TCR pairs experimentally validated were labeled as the positive class, the negative set was generated by generating random TCR-peptide combinations and ensuring these pairs are absent from the positive dataset. The training and test datasets were obtained from the ERGO II and netTCR2.0 repositories. The external test dataset, MIRA, was also obtained from the netTCR2.0 GitHub repository. The MIRA dataset contained 376 CDR3β-peptide pairs associated with HLA-A* 02:01. We used partitioned data as detailed in netTCR2.0 and ERGO II. The pMTnet dataset was used as an external test dataset. A detailed summary of all the datasets used in this work is provided in <xref rid="sec0085" ref-type="sec">Supplementary Table 3</xref> and <xref rid="sec0085" ref-type="sec">Supplementary Table 4</xref>.</p>
      <p id="p0140">The McPAS and VDJDB datasets were processed to give two working datasets for model training and testing. The peptide and HLA counts of the two datasets are indicated in <xref rid="sec0085" ref-type="sec">Supplementary Figure 15</xref>. Subset-1 contains paired CDR3α, CDR3β and peptide information only. Subset-2 contains paired CDR3α, CDR3β, peptide and MHC information. We utilized the fair-esm python library provided by the ESM project to extract the embeddings for the TCR, peptide and MHC sequences <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>. First, a FASTA file was created for each dataset. The FASTA files were parsed to the ESM1v model to extract the pre-final layer embeddings of size 1280 for each sequence. The embeddings would have the size of 1280 * peptide length (L). Global average pooling was then employed to convert it to a 1 * 1280-dimensional vector.</p>
    </sec>
    <sec id="sec0055">
      <label>4.2</label>
      <title>Model training and performance evaluation metrics</title>
      <p id="p0145">The ESM1v protein model was employed as mentioned in the original paper without finetuning <xref rid="bib19" ref-type="bibr">[19]</xref>. ESM1v-extracted embeddings encode the TCR, peptide and MHC information. The embeddings were fed into a feedforward neural network to predict binding. Grid search was used to optimize model hyperparameters such as learning rate (ranging from 10<sup>−1</sup> to 10<sup>−4</sup>), dropout rate (ranging from 0.2 to 0.5), number of hidden layers (ranging from 1 to 2) and number of nodes (ranging from 2<sup>2</sup> to 2<sup>7</sup>) in each layer. netTCR2.0 and ERGO II models were run on the datasets as baselines to independently calculate the MCC value for the benchmarking task. The performance was compared with the reported performance values for netTCR2.0 and ERGO II, to verify accurate reproduction of results.</p>
      <p id="p0150">The model uses the GELU activation function <xref rid="bib29" ref-type="bibr">[29]</xref> in all of its hidden layers and the binary cross-entropy loss function for optimization. During training, the learning rate was set to 0.08 and was reduced by 5% if the validation MCC did not improve after 50 epochs. This was done using a learning rate scheduler to adapt to the changing dynamics of the training data and potentially improve model performance.</p>
      <p id="p0155">The model prediction performance was tested mainly based on MCC, which is reported to be a reliable statistical measure over other metrics such as AUC-ROC and AUC-PR since we performed classification on imbalance datasets <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib30" ref-type="bibr">[30]</xref>. The MCC is defined as the correlation between the observed and predicted binary classifications. It ranges from − 1–1, with values closer to 1 or − 1 indicating a stronger correlation and a better model performance. A value of 0 indicates no correlation, while negative values indicate an inverse correlation. The MCC results in a high score only when the predictions are reliable on all of the four categories- true and false positives as well as true and false negatives, while being proportional to the size of positive and negative samples in the dataset <xref rid="bib31" ref-type="bibr">[31]</xref>. The model performance is also tested and reported on the area under the receiver operating characteristic (AUC-ROC), area under the precision-recall curve (AU-PR) as well as F1 scores. The metrics are calculated as:<disp-formula id="eqn0005"><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0010"><mml:math id="M2" altimg="si0002.svg"><mml:mrow><mml:mi mathvariant="italic">Recall</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0015"><mml:math id="M3" altimg="si0003.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mi mathvariant="italic">score</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow></mml:mfrac><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0020"><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:mi mathvariant="italic">MCC</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow><mml:mrow><mml:mo>√</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where TN: true negatives, TP: true positives, FN: false negatives and FP: false positives.</p>
    </sec>
    <sec id="sec0060">
      <label>4.3</label>
      <title>Feature importance determination (ablation experiment)</title>
      <p id="p0160">Feature importance was determined through ablation studies, which involve systematically removing or "ablating" each feature from the model one at a time and measuring the impact on model performance. By comparing the model's performance with and without a given feature, one can determine the importance of that feature in driving the model output. In the context of TCR-peptide binding, feature importance determination and ablation studies can be used to identify which CDR3 chains in the TCR has significant contribution towards binding the peptides. In cases when MHC information is added to the model, ablation studies help determine whether the added information is useful or not. For TCR-peptide binding prediction, we created three different feature subsets: CDR3α-peptide, CDR3β-peptide and CDR3α-CDR3β-peptide. Similarly, for TCR-pMHC binding, we created six different feature subsets such as CDR3α-peptide, CDR3β-peptide, CDR3α-CDR3β-peptide, CDR3α-peptide-MHC, CDR3β-peptide-MHC and CDR3α-CDR3β-peptide-MHC to calculate if adding more features improves the performance of the TCR-pMHC binding prediction. Individual models such as ERGO II-Autoencoder (ERGO II-AE), ERGO II-LSTM and TCR-ESM (developed in this study), were trained for these subsets and the MCC metric was calculated to test the performance. We checked for statistical significance of performance using T-test and used Benjamini-Hochberg (BH) p-value correction to account for multiple testing <xref rid="bib32" ref-type="bibr">[32]</xref>.</p>
    </sec>
    <sec id="sec0065">
      <label>4.4</label>
      <title>Analysis of fine-tuned embeddings</title>
      <p id="p0165">The output of the intermediate and penultimate layers was extracted from the TCR-ESM feedforward neural network for the most frequent peptides in both McPAS and VDJDB dataset. t-distributed Stochastic Neighbor Embedding (t-SNE) was then performed on the output embeddings to reduce them to 2D for visualizing if the positive and negative TCRs cluster separately.</p>
    </sec>
    <sec id="sec0070">
      <label>4.5</label>
      <title>External testing analysis</title>
      <p id="p0170">A crucial component of assessing deep learning models is external testing. The model performance is tested on data samples taken from an external, other than the training data. Model performance on external samples can reveal information about how well it generalizes, or how well it can make predictions about unknown data. The model, when used in settings where it is likely to encounter data that differs from the training data, such as in the real world, external testing is especially important. We checked the generalizability by testing the TCR-ESM model on an independent dataset obtained from pMTnet <xref rid="bib26" ref-type="bibr">[26]</xref> (<xref rid="sec0085" ref-type="sec">Supplementary Table S5</xref>), which is a recently reported experimental dataset of TCR-peptide-MHC binding. pMTnet contains CDR3-peptide sequences which are different from CDR3-peptides sequences present in the McPAS and VDJDB datasets, however, there are some common peptides. The TCR-ESM models trained on McPAS and VDJDB were tested on the pMTNet set as is, after removing the common peptides and also after filtering based on 90 % and 80 % sequence similarity (sim) score measured by aligning the peptides pairwise and normalizing the alignment scores by length of the peptide.<disp-formula id="eqn0025"><mml:math id="M5" altimg="si0005.svg"><mml:mrow><mml:mi mathvariant="italic">sim</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="italic">score</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">len</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="italic">len</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>Where A is the set of all local alignments between sequences S<sub>1</sub> and S<sub>2</sub>, and a is the alignment with the highest score score(a).</p>
    </sec>
  </sec>
  <sec id="sec0075">
    <title>Author Statement</title>
    <p id="p0175">We confirm that the manuscript has been read and approved by all authors.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing Interest</title>
    <p id="p0180">The authors declare no conflict of interest.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>S.-Q.</given-names>
          </name>
          <name>
            <surname>Parker</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>K.-Y.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Z.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Direct measurement of T cell receptor affinity and sequence from naïve antiviral T cells</article-title>
        <source>Sci Transl Med</source>
        <volume>8</volume>
        <issue>341</issue>
        <year>2016</year>
        <comment>341ra377-341ra377</comment>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Sprent</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Surh</surname>
            <given-names>C.D.</given-names>
          </name>
        </person-group>
        <article-title>T cell memory</article-title>
        <source>Annu Rev Immunol</source>
        <volume>20</volume>
        <issue>1</issue>
        <year>2002</year>
        <fpage>551</fpage>
        <lpage>579</lpage>
        <pub-id pub-id-type="pmid">11861612</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Springer</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Besser</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Tickotsky-Moskovitz</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Dvorkin</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Louzoun</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of specific TCR-peptide binding from large dictionaries of TCR-peptide pairs</article-title>
        <source>Front Immunol</source>
        <volume>11</volume>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Springer</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Tickotsky</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Louzoun</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Contribution of T cell receptor alpha and beta CDR3, MHC typing, V and J genes to peptide binding prediction</article-title>
        <source>Front Immunol</source>
        <volume>12</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">664514</object-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>Bjorkman</surname>
            <given-names>P.J.</given-names>
          </name>
        </person-group>
        <article-title>T-cell antigen receptor genes and T-cell recognition</article-title>
        <source>Nature</source>
        <volume>334</volume>
        <issue>6181</issue>
        <year>1988</year>
        <fpage>395</fpage>
        <lpage>402</lpage>
        <pub-id pub-id-type="pmid">3043226</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Krogsgaard</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>M.M.</given-names>
          </name>
        </person-group>
        <article-title>How T cells' see'antigen</article-title>
        <source>Nat Immunol</source>
        <volume>6</volume>
        <issue>3</issue>
        <year>2005</year>
        <fpage>239</fpage>
        <lpage>245</lpage>
        <pub-id pub-id-type="pmid">15716973</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>La Gruta</surname>
            <given-names>N.L.</given-names>
          </name>
          <name>
            <surname>Gras</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Daley</surname>
            <given-names>S.R.</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>P.G.</given-names>
          </name>
          <name>
            <surname>Rossjohn</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Understanding the drivers of MHC restriction of T cell receptors</article-title>
        <source>Nat Rev Immunol</source>
        <volume>18</volume>
        <issue>7</issue>
        <year>2018</year>
        <fpage>467</fpage>
        <lpage>478</lpage>
        <pub-id pub-id-type="pmid">29636542</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Bagaev</surname>
            <given-names>D.V.</given-names>
          </name>
          <name>
            <surname>Vroomans</surname>
            <given-names>R.M.A.</given-names>
          </name>
          <name>
            <surname>Samir</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Stervbo</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Rius</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Dolton</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>VDJdb in 2019: database extension, new analysis infrastructure and a T-cell receptor motif compendium</article-title>
        <source>Nucleic Acids Res</source>
        <volume>48</volume>
        <issue>D1</issue>
        <year>2020</year>
        <fpage>D1057</fpage>
        <lpage>D1062</lpage>
        <pub-id pub-id-type="pmid">31588507</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Tickotsky</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Sagiv</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Prilusky</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Shifrut</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>McPAS-TCR: a manually curated catalogue of pathology-associated T cell receptor sequences</article-title>
        <source>Bioinformatics</source>
        <volume>33</volume>
        <issue>18</issue>
        <year>2017</year>
        <fpage>2924</fpage>
        <lpage>2929</lpage>
        <pub-id pub-id-type="pmid">28481982</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Lanzarotti</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Marcatili</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>T-cell receptor cognate target prediction based on paired α and β chain sequence and structural CDR loop similarities</article-title>
        <source>Front Immunol</source>
        <volume>10</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">2080</object-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Dash</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Fiore-Gartland</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Hertz</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G.C.</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Souquette</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantifiable predictive features define epitope-specific T cell receptor repertoires</article-title>
        <source>Nature</source>
        <volume>547</volume>
        <issue>7661</issue>
        <year>2017</year>
        <fpage>89</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="pmid">28636592</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>Y.C.</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Lowery</surname>
            <given-names>F.J.</given-names>
          </name>
          <name>
            <surname>Gartner</surname>
            <given-names>J.J.</given-names>
          </name>
          <name>
            <surname>Prickett</surname>
            <given-names>T.D.</given-names>
          </name>
          <name>
            <surname>Robbins</surname>
            <given-names>P.F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Direct identification of neoantigen-specific TCRs from tumor specimens by high-throughput single-cell sequencing</article-title>
        <source>J Immunother Cancer</source>
        <volume>9</volume>
        <issue>7</issue>
        <year>2021</year>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Lundegaard</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lund</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Predictions versus high-throughput experiments in T-cell epitope discovery: competition or synergy?</article-title>
        <source>Expert Rev Vaccin</source>
        <volume>11</volume>
        <issue>1</issue>
        <year>2012</year>
        <fpage>43</fpage>
        <lpage>54</lpage>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Jokinen</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Huuhtanen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mustjoki</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Heinonen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lähdesmäki</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>
        <source>PLOS Comp Biol</source>
        <volume>17</volume>
        <issue>3</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e1008814</object-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>Gielis</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Moris</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bittremieux</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>De Neuter</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Ogunjimi</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Laukens</surname>
            <given-names>K.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Detection of enriched T cell epitope specificity in full T cell receptor sequence repertoires</article-title>
        <source>Front Immunol</source>
        <volume>10</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">2820</object-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Jurtz</surname>
            <given-names>V.I.</given-names>
          </name>
          <name>
            <surname>Jessen</surname>
            <given-names>L.E.</given-names>
          </name>
          <name>
            <surname>Bentzen</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Jespersen</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Mahajan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vita</surname>
            <given-names>R.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NetTCR: sequence-based prediction of TCR binding to peptide-MHC complexes using convolutional neural networks</article-title>
        <source>BioRxiv</source>
        <year>2018</year>
        <object-id pub-id-type="publisher-id">433706</object-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Isacchini</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Walczak</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Mora</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Nourmohammad</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Deep generative selection models of T and B cell receptor repertoires with soNNia</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <volume>118</volume>
        <issue>14</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e2023141118</object-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Vig</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Madani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Varshney</surname>
            <given-names>L.R.</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Socher</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Rajani</surname>
            <given-names>N.F.</given-names>
          </name>
        </person-group>
        <article-title>BERTology meets biology: interpreting attention in protein language models</article-title>
        <source>arXiv Prepr</source>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Rives</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Meier</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sercu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Goyal</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <volume>118</volume>
        <issue>15</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e2016239118</object-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Kalakoti</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yadav</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sundar</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>TransDTI: transformer-based language models for estimating DTIs and building a drug recommendation workflow</article-title>
        <source>ACS Omega</source>
        <volume>7</volume>
        <issue>3</issue>
        <year>2022</year>
        <fpage>2706</fpage>
        <lpage>2717</lpage>
        <pub-id pub-id-type="pmid">35097268</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Meier</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Verkuil</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sercu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Rives</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Language models enable zero-shot prediction of the effects of mutations on protein function</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <volume>34</volume>
        <year>2021</year>
        <fpage>29287</fpage>
        <lpage>29303</lpage>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Littmann</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Heinzinger</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Dallago</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Olenyi</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Embeddings from deep learning transfer GO annotations beyond homology</article-title>
        <source>Sci Rep</source>
        <volume>11</volume>
        <issue>1</issue>
        <year>2021</year>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="pmid">33414495</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Akin</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Hie</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>W.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>
        <source>Science</source>
        <volume>379</volume>
        <issue>6637</issue>
        <year>2023</year>
        <fpage>1123</fpage>
        <lpage>1130</lpage>
        <pub-id pub-id-type="pmid">36927031</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>Montemurro</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Schuster</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Povlsen</surname>
            <given-names>H.R.</given-names>
          </name>
          <name>
            <surname>Bentzen</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Jurtz</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Chronister</surname>
            <given-names>W.D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NetTCR-2.0 enables accurate prediction of TCR-peptide binding by using paired TCRα and β sequence data</article-title>
        <source>Commun Biol</source>
        <volume>4</volume>
        <issue>1</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">1060</object-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Shugay</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bagaev</surname>
            <given-names>D.V.</given-names>
          </name>
          <name>
            <surname>Zvyagin</surname>
            <given-names>I.V.</given-names>
          </name>
          <name>
            <surname>Vroomans</surname>
            <given-names>R.M.</given-names>
          </name>
          <name>
            <surname>Crawford</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Dolton</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>VDJdb: a curated database of T-cell receptor sequences with known antigen specificity</article-title>
        <source>Nucleic Acids Res</source>
        <volume>46</volume>
        <issue>D1</issue>
        <year>2018</year>
        <fpage>D419</fpage>
        <lpage>D427</lpage>
        <pub-id pub-id-type="pmid">28977646</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning-based prediction of the T cell receptor–antigen binding specificity</article-title>
        <source>Nat Mach Intell</source>
        <volume>3</volume>
        <issue>10</issue>
        <year>2021</year>
        <fpage>864</fpage>
        <lpage>875</lpage>
        <pub-id pub-id-type="pmid">36003885</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</article-title>
        <source>BMC Genom</source>
        <volume>21</volume>
        <issue>1</issue>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">6</object-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sbref28">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The Matthews correlation coefficient (MCC) should replace the ROC AUC as the standard metric for assessing binary classification</article-title>
        <source>BioData Min</source>
        <volume>16</volume>
        <issue>1</issue>
        <year>2023</year>
        <object-id pub-id-type="publisher-id">4</object-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="journal" id="sbref29">
        <person-group person-group-type="author">
          <name>
            <surname>Hendrycks</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Gimpel</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Gaussian error linear units (gelus)</article-title>
        <source>arXiv Prepr</source>
        <year>2016</year>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sbref30">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Tötsch</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation</article-title>
        <source>BioData Min</source>
        <volume>14</volume>
        <issue>1</issue>
        <year>2021</year>
        <fpage>1</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="pmid">33430939</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sbref31">
        <person-group person-group-type="author">
          <name>
            <surname>Boughorbel</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Jarray</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>El-Anbari</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Optimal classifier for imbalanced data using Matthews correlation coefficient metric</article-title>
        <source>PLOS One</source>
        <volume>12</volume>
        <issue>6</issue>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">e0177678</object-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sbref32">
        <person-group person-group-type="author">
          <name>
            <surname>Benjamini</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hochberg</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>
        <source>J R Stat Soc: Ser B (Methodol)</source>
        <volume>57</volume>
        <issue>1</issue>
        <year>1995</year>
        <fpage>289</fpage>
        <lpage>300</lpage>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="sec0085" sec-type="supplementary-material">
    <label>Appendix A</label>
    <title>Supplementary material</title>
    <p id="p0190"><supplementary-material content-type="local-data" id="ec0005"><caption><p>Supplementary material</p></caption><media xlink:href="mmc1.pdf"/></supplementary-material>.</p>
    <p id="p0195"><supplementary-material content-type="local-data" id="ec0010"><caption><p>Supplementary material</p></caption><media xlink:href="mmc2.pptx"/></supplementary-material>.</p>
  </sec>
  <sec sec-type="data-availability" id="da0005">
    <title>Data availability</title>
    <p id="p0005">Raw data can be downloaded from the GitHub links as mentioned in the methods section. Processed data and the working code are available at https://GitHub.com/dhanjal-lab/tcr-esm.</p>
  </sec>
  <fn-group>
    <fn id="sec0080" fn-type="supplementary-material">
      <label>Appendix A</label>
      <p id="p0185">Supplementary data associated with this article can be found in the online version at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.csbj.2023.11.037" id="ir0005">doi:10.1016/j.csbj.2023.11.037</ext-link>.</p>
    </fn>
  </fn-group>
</back>
<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_CSBJ2415 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEga1 jpg ?>
<?FILEmmc1 pdf ?>
<?FILEmmc2 pptx ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Struct Biotechnol J</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Struct Biotechnol J</journal-id>
    <journal-title-group>
      <journal-title>Computational and Structural Biotechnology Journal</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2001-0370</issn>
    <publisher>
      <publisher-name>Research Network of Computational and Structural Biotechnology</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10749252</article-id>
    <article-id pub-id-type="pii">S2001-0370(23)00452-X</article-id>
    <article-id pub-id-type="doi">10.1016/j.csbj.2023.11.037</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TCR-ESM: Employing protein language embeddings to predict TCR-peptide-MHC binding</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Yadav</surname>
          <given-names>Shashank</given-names>
        </name>
        <xref rid="aff0005" ref-type="aff">a</xref>
        <xref rid="fn1" ref-type="fn">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Vora</surname>
          <given-names>Dhvani Sandip</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="fn1" ref-type="fn">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Sundar</surname>
          <given-names>Durai</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au0020">
        <name>
          <surname>Dhanjal</surname>
          <given-names>Jaspreet Kaur</given-names>
        </name>
        <email>jaspreet@iiitd.ac.in</email>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="aff0005"><label>a</label>Department of Biomedical Engineering, University of Arizona, Tucson 85721, AZ, USA</aff>
      <aff id="aff0010"><label>b</label>Department of Biochemical Engineering and Biotechnology, Indian Institute of Technology Delhi, New Delhi 110016, India</aff>
      <aff id="aff0015"><label>c</label>Department of Computational Biology, Indraprastha Institute of Information Technology, Delhi, New Delhi 110020, India</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Corresponding author. <email>jaspreet@iiitd.ac.in</email></corresp>
      <fn id="fn1">
        <label>1</label>
        <p id="ntp0005">Equal contribution</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>11</month>
      <year>2023</year>
    </pub-date>
    <volume>23</volume>
    <fpage>165</fpage>
    <lpage>173</lpage>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>19</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>11</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 The Authors</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>Cognate target identification for T-cell receptors (TCRs) is a significant barrier in T-cell therapy development, which may be overcome by accurately predicting TCR interaction with peptide-bound major histocompatibility complex (pMHC). In this study, we have employed peptide embeddings learned from a large protein language model- Evolutionary Scale Modeling (ESM), to predict TCR-pMHC binding. The TCR-ESM model presented outperforms existing predictors. The complementarity-determining region 3 (CDR3) of the hypervariable TCR is located at the center of the paratope and plays a crucial role in peptide recognition. TCR-ESM trained on paired TCR data with both CDR3α and CDR3β chain information performs significantly better than those trained on data with only CDR3β, suggesting that both TCR chains contribute to specificity, the relative importance however depends on the specific peptide-MHC targeted. The study illuminates the importance of MHC information in TCR-peptide binding which remained inconclusive so far and was thought dependent on the dataset characteristics. TCR-ESM outperforms existing approaches on external datasets, suggesting generalizability. Overall, the potential of deep learning for predicting TCR-pMHC interactions and improving the understanding of factors driving TCR specificity are highlighted. The prediction model is available at http://tcresm.dhanjal-lab.iiitd.edu.in/ as an online tool.</p>
    </abstract>
    <abstract abstract-type="graphical" id="ab0015">
      <title>Graphical abstract</title>
      <p>
        <fig id="fig0030" position="anchor">
          <alt-text id="at0030">ga1</alt-text>
          <graphic xlink:href="ga1" id="lk0030"/>
        </fig>
      </p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>T-cell therapy</kwd>
      <kwd>TCR-pMHC interactions</kwd>
      <kwd>Protein language models</kwd>
      <kwd>TCR specificity</kwd>
      <kwd>Peptide embeddings</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0010">The surveillance against pathogens and pathological cells of the body is carried out by the adaptive immune system. A cornerstone of the adaptive immune response system is the presentation of peptides by major histocompatibility complexes (MHC) class I or class II, expressed on the cell surfaces. The human MHCs are also called Human Leukocyte Antigens (HLAs) and are classified in three gene classes based on structure and function of the gene products. Class I gene products, encoded by three distinct genomic loci, HLA-A, HLA-B and HLA-C present endogenous peptides to CD8<sup>+</sup> T-cells. The letters “A”, “B” or “C” are assigned based on the antigens defined by serology. The peptide-MHC complex presented to T-cells enables recognition of the antigen via the T-cell receptors (TCR). Upon activation, the T cells undergo clonal expansion <xref rid="bib1" ref-type="bibr">[1]</xref>. A fraction of this clonally expanded repertoire is retained as long-living memory against the antigen <xref rid="bib2" ref-type="bibr">[2]</xref>. The affinity of the TCR for any peptide is governed by the heterodimeric TCRs consisting of the <italic>α</italic> and <italic>β</italic> subunits. Both chains have been reported to affect the binding of the TCR to the peptide-MHC complex (TCR-pMHC), however, prediction of TCR-pMHC binding has been carried out with high accuracy with only the <italic>β</italic> chain <xref rid="bib3" ref-type="bibr">[3]</xref>.</p>
    <p id="p0015">Within the <italic>β</italic> chain of the TCR, the three complementarity determining regions (CDRs) make primary contacts with the MHC (CDR1 and CDR2), and the peptide (CDR3), recent studies suggest contributions of the alpha chain and other CDRs as well <xref rid="bib4" ref-type="bibr">[4]</xref>. In both the <italic>α</italic> and <italic>β</italic> chains, the CD3 loops represent the region of the highest sequence diversity and hence, are the regions that determine receptor binding specificity <xref rid="bib5" ref-type="bibr">[5]</xref>, <xref rid="bib6" ref-type="bibr">[6]</xref>. The CDR3 diversity is defined by multiple genomic recombination events in the ‘Variable’ (V), ‘Diversity’ (D) and ‘Joining’ (J) TCR-related genes. The V- and J- recombinations make up the α-chain while the β-chain is a result of the V-, D- and J genes generating a broader diversity. Hence, most of the previous studies have focused only on the β-chain.</p>
    <p id="p0020">The Immune Epitope database, VDJDB and McPAS-TCR primarily contains information on CDR3β and houses a large fraction of the publicly available TCR-pMHC binding data <xref rid="bib7" ref-type="bibr">[7]</xref>, <xref rid="bib8" ref-type="bibr">[8]</xref>, <xref rid="bib9" ref-type="bibr">[9]</xref>. Recent studies illuminate the importance of CDR3 of both α- and β-chains in driving specificity of the TCR <xref rid="bib10" ref-type="bibr">[10]</xref>, <xref rid="bib11" ref-type="bibr">[11]</xref>. While single-cell based high-throughput techniques for assessing TCR-pMHC binding are available, determining the role of individual components remains a time- and resource-intensive pursuit <xref rid="bib12" ref-type="bibr">[12]</xref>, <xref rid="bib13" ref-type="bibr">[13]</xref>.</p>
    <p id="p0025">Various studies have reported TCR-pMHC data modeling and prediction techniques, mostly based on the data from VDJDB, IEDB and McPAS-TCR, using either or both CDR3 α- and β-sequences. These previous studies have employed Gaussian processes, position-specific scoring matrices, deep learning methods <xref rid="bib14" ref-type="bibr">[14]</xref>, <xref rid="bib15" ref-type="bibr">[15]</xref>, <xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib17" ref-type="bibr">[17]</xref> as well as advanced methods employing Natural Language Processing (NLP) <xref rid="bib3" ref-type="bibr">[3]</xref>. The performance of current methods is limited by the paucity of available data. The applicability in terms of generalizability of the predictors is also hindered by the redundancy in epitope specific TCR sequences. Extracting relevant information from sequence data, labeled and unlabeled, has been demonstrated by NLP-based self-supervised learning algorithms. One such algorithm, Bidirectional Encoder Representations from Transformers (BERT), has been reported to reliably capture biological properties of proteins <xref rid="bib18" ref-type="bibr">[18]</xref>. Large protein language models such as ESM (Evolutionary Scale Model) <xref rid="bib19" ref-type="bibr">[19]</xref> and its variants have been used to predict biological structure and function of proteins. Also, the embeddings learned by the model have been fine-tuned for downstream tasks such as protein-drug interactions prediction <xref rid="bib20" ref-type="bibr">[20]</xref>, protein variant effect prediction <xref rid="bib21" ref-type="bibr">[21]</xref> and gene ontology annotation <xref rid="bib22" ref-type="bibr">[22]</xref>.</p>
    <p id="p0030">Here, we present TCR-ESM, a deep learning-based model to predict TCR-peptide-MHC binding. TCR-ESM is a feedforward neural network trained on embeddings extracted from ESM, a protein language model <xref rid="bib23" ref-type="bibr">[23]</xref>. ESM1v - a variant in the ESM family of protein language models has been used to generate sequence length-independent embeddings for the three protein moieties involved in the binding. The encoded protein sequence information is fed into a feedforward neural network to predict possibility of interaction. The positive data class consists of experimentally validated pairs of class 1 and class 2 MHC-peptide which bind to the TCRs. The negative data is generated by mismatching the positive dataset and ensuring the new combinations are absent in the positive class. Ablation analysis has also been carried out to qualitatively determine the importance of the TCRα, TCRβ and MHC components in the classifier's predictions. The study has been benchmarked against current TCR-pMHC prediction models such as pEptide tcR matchinG predictiOn (ERGO II) <xref rid="bib4" ref-type="bibr">[4]</xref> and netTCR2.0 <xref rid="bib24" ref-type="bibr">[24]</xref> using the netTCR2.0, McPAS and VDJDB datasets <xref rid="bib3" ref-type="bibr">[3]</xref>, <xref rid="bib9" ref-type="bibr">[9]</xref>, <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib25" ref-type="bibr">[25]</xref>. Our model, TCR-ESM has also been tested on the external dataset MIRA, as reported in the netTCR2.0 study as well as an additional independent external test set pMTnet <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib26" ref-type="bibr">[26]</xref>. We report improved prediction capacity based on the Matthews correlation coefficient (MCC) score, which has been established as a more reliable performance metrics in binary classification on imbalanced data rather than precision, recall and ROC AUC <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib28" ref-type="bibr">[28]</xref>. The MCC score ranges from 0, indicating poor model predictive performance, to 1, signifying ideal model performance. However, we additionally report model performance on precision-recall, ROC AUC as well as the F1 score. We also observe that fine tuning the embeddings extracted from large protein language models can preserve both local and global information towards specific objectives.</p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Results</title>
    <p id="p0035">The TCR-ESM prediction model was trained on the peptide, TCR and MHC embeddings as detailed in <xref rid="fig0005" ref-type="fig">Fig. 1</xref>. The peptide, TCR and MHC sequence information was fed into the neural network after embeddings were generated from the penultimate layer of the ESM1v model (<xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>a</bold>). The feedforward neural network was trained to predict TCR-peptide binding pairs as 1, and non-interacting pairs as 0. Performance was evaluated over MCC scores, area under the receiver operating characteristic (AUC-ROC), area under the Precision-Recall curve (AU-PR) and F1 scores. The choice of model architecture was governed by the feature set in consideration. For instance, for predicting CDR3α-CDR3β-peptide binding the model illustrated in <xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>b</bold> was used. Similarly, <xref rid="fig0005" ref-type="fig">Fig. 1</xref><bold>c</bold> illustrates the model used for CDR3α-CDR3β-peptide-MHC binding. For CDR3α-peptide, CDR3β-peptide, CDR3α-peptide-MHC, CDR3β-peptide-MHC binding prediction, the model architectures are illustrated in <xref rid="sec0085" ref-type="sec">Supplementary Figure 1a, 1b, 1c and 1d</xref>, respectively.<fig id="fig0005"><label>Fig. 1</label><caption><p><bold>:</bold> Schematic of the method followed. (a) The ESM1v protein language model was employed to extract the sequence information in the form of 1280-dimensional embeddings for each of the three components- TCR, peptide and MHC. (b) Architecture of the neural network employed for the TCR(CDR3α+CDR3β)-peptide binding classification task. (c) The neural network architecture employed for the TCR(CDR3α+CDR3β)-peptide-MHC binding prediction task.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1" id="lk0005"/></fig></p>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Model performance evaluation on CDR3β data</title>
      <p id="p0040">The probability of the TCR-peptide binding predicted by TCR-ESM on the netTCR2.0 CDR3β dataset was evaluated. A side-by-side comparison of TCR-ESM with the 1D CNN-based netTCR2.0 was carried out. The data was prepared and partitioned the same as the netTCR2.0 study <xref rid="bib24" ref-type="bibr">[24]</xref>. The netTCR2.0, ERGO-AE, ERGO-LSTM and the classifier presented in this study- TCR-ESM were trained, and cross-validation was carried out on the CDR3β data. Same as netTCR2.0, five different MIRA datasets were obtained by imposing a separation from the training set of 90 %, 92 %, 94 %, 99 %, and 100 % similarity. That is, MIRA 94 % TCRs do not share more than 94% Levenshtein similarity to any of the TCRs in the training set. These datasets were used as independent test sets. Our model outperformed netTCR2.0 on all similarity-based partition thresholds (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>a,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1a</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Figs. S2, S3 and S4</xref>.<fig id="fig0010"><label>Fig. 2</label><caption><p><bold>:</bold> Model performance benchmarking. (a) Comparison of TCR-ESM with netTCR2.0 on the external MIRA dataset as test set for different partitioning thresholds. (b) Comparison of TCR-ESM with netTCR2.0 on the MIRA dataset as test set specific to the most common peptide in the dataset, ‘GILGFVFTL’. (c) Comparison of TCR-ESM with netTCR2.0 on the MIRA dataset as test set specific to the second most common peptide ‘GLCTLVAML’. 5-fold cross validation is run independently 10 times to compare the model performance and the distribution is represented by the box-whisker plots to compare the performance of TCR-ESM with netTCR2.0 at (d) 90% partitioning threshold and (e) 95% partitioning threshold for different prediction tasks such as TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, and TCR(CDR3α+CDR3β)+peptide. All statistical comparisons were done using Mann-Whitney U test with Benjamini-Hochberg correction (ns: p &gt; 5.00e-02, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2" id="lk0010"/></fig></p>
      <p id="p0045">We then compared the peptide-specific outperformance for the two most abundant peptides, GILGFVFTL (GIL) from Influenza A virus and GLCTLVAML (GLC) from Human herpesvirus 4 (Epstein–Barr virus) for all partitioning thresholds (<xref rid="fig0010" ref-type="fig">Figs. 2</xref><bold>b,</bold>
<xref rid="fig0010" ref-type="fig">2</xref><bold>c,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1a</xref>).</p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>Model performance evaluation and ablation analysis on paired CDR3α and β</title>
      <p id="p0050">In addition to the CDR3β information, to check whether CDR3α information or paired CDR3αβ information is beneficial for the prediction of peptide binding by the TCR, the TCR-ESM model was cross-validated and benchmarked against netTCR2.0. <xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>d</bold> shows the TCR-ESM and netTCR2.0 models evaluated with 5-fold cross-validation run 10 times independently on the sequence similarity-based partitioned datasets as is from the netTCR2.0 study with the CDR3 α-chain, CDR3 β-chain, and both α- and β-chains of CDR3. The TCR-ESM model significantly outperforms (p-value &lt;= 0.05) the netTCR2.0 model on all three datasets (CDR3α only, CDR3β only, and paired). We also obtained similar outperformance for the 95% partitioned dataset (<xref rid="fig0010" ref-type="fig">Fig. 2</xref><bold>e,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Table S1b</xref>). We validated this observation by comparing netTCR2.0 model performance on the three datasets (CDR3α only, CDR3β only, and paired) and found that models trained on paired chain information outperformed models trained only on single CDR3 chains. (<xref rid="sec0085" ref-type="sec">Supplementary Fig. S5</xref>).</p>
      <p id="p0055">To further validate the performance of the TCR-ESM model, we compared our model with the ERGO II model. The ERGO II model is available in two types, namely ERGO II-Autoencoder (ERGO II-AE) and ERGO II-Long Short-Term Memory (ERGO II-LSTM). Since ERGO II-AE and ERGO II-LSTM were originally benchmarked on the McPAS and VDJDB data, we utilized these datasets with exactly the same train-test splits as provided. We observed that our model outperforms netTCR2.0, ERGO II-AE and ERGO II-LSTM model for both McPAS and VDJDB paired chain datasets (10-fold cross validation, p-value&lt;=0.05, p-value correction with Benjamini-Hochberg method) (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>a,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Tables S2</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Figs. S6, S7, S8</xref>. Both McPAS and VDJDB subsets 1 lack MHC information while subsets 2 include MHC information. We cross-validated these models on the McPAS data subset-1. We also observed a similar trend on test-set MCC where our model performed better when compared to the other three models (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>b</bold>). We observe a similar trend of TCR-ESM outperforming in the VDJDB data subset-1 on both cross validation and test setting as illustrated in <xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>c</bold> and <xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>d</bold>.<fig id="fig0015"><label>Fig. 3</label><caption><p><bold>:</bold> Feature importance as determined by ablation. The box-whisker plots show model performance distribution on 10-fold cross-validation using the TCR-ESM predictor, netTCR2.0, ERGO II-AE and ERGO II-LSTM for different prediction tasks- TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, and TCR(CDR3α+CDR3β)+peptide on (a) McPAS data subset-1, (c) VDJDB data subset-1. Similarly, hold-out testing set comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model for the three different prediction tasks on (b) McPAS data subset-1, and (d) VDJDB data subset-1. 10-fold cross validated comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model for different prediction tasks such as TCR(CDR3α)+peptide, TCR(CDR3β)+peptide, TCR(CDR3α + CDR3β) + peptide, TCR(CDR3α)+peptide+MHC, TCR(CDR3β)+peptide+MHC and TCR(CDR3α + CDR3β) + peptide+MHC on (e) McPAS data subset-2 and (g) VDJDB data subset-2. Similarly, hold-out testing set comparison of TCR-ESM model with netTCR2.0, ERGO II-AE and ERGO II-LSTM model was performed for the different prediction tasks on (f) McPAS data subset-2 and (h) VDJDB data subset-2. All statistical comparisons were done using Mann-Whitney U test with Bejamini-Hochberg correction (ns: p &gt; 5.00e-02, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3" id="lk0015"/></fig></p>
      <p id="p0060">Further supporting analysis on whether CDR3 paired chain information can predict the TCR-peptide binding better than single chains was carried out. We performed 10-fold cross-validation for all the four models (netTCR2.0, ERGO II-AE, ERGO II-LSTM and our TCR-ESM) on paired CDR3 in the McPAS data subset-1 as well single chains, and observed that paired CDR3 information improves the MCC significantly (t-test p-value&lt;=0.05, p-value correction with Benjamini-Hochberg method) when compared to the model trained only on CDR3α and CDR3β <bold>(</bold><xref rid="sec0085" ref-type="sec">Supplementary Figs. S9, S10</xref><bold>)</bold>. We observe a similar trend of model outperformance with paired CDR3 information on the VDJDB data subset-1 (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S6, S7, S8</xref>).</p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Model performance evaluation on paired CDR3 with MHC information and ablation analysis</title>
      <p id="p0065">The contribution of different features was further illustrated by performing ablation analysis on McPAS data subset-2 and VDJDB data subset-2, which contains MHC information. Since there are three components, CDR3α, CDR3β, and MHC, six feature sets were constructed- CDR3α only, CDR3β only, paired CDR3α-CDR3β, CDR3α-MHC, CDR3β-MHC and combined CDR3α-CDR3β-MHC. The TCR-ESM-MHC model was compared with ERGO II-AE and ERGO II-LSTM models on McPAS data subset-2 (containing MHC information) for each of the six feature sets. TCR-ESM-MHC is shown to outperform the ERGO-AE model on all six feature sets during cross-validation and on the test set, while also outperforming ERGO-LSTM on four of the six sets during cross-validation and on the test set (<xref rid="fig0015" ref-type="fig">Figs. 3</xref><bold>e,</bold>
<xref rid="fig0015" ref-type="fig">3</xref><bold>f)</bold>. TCR-ESM-MHC also outperformed on the VDJDB data subset-2 (VDJDB with MHC information) as compared to both ERGO II-AE and ERGO II-LSTM model on 10-fold cross validation and test set (<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>g,</bold>
<xref rid="fig0015" ref-type="fig">Fig. 3</xref><bold>h</bold>). For the ablation experiment, the ERGO II-AE, ERGO II-LSTM and TCR-ESM-MHC models were trained individually on the six feature sets. The feature importance of the MHC based on increase in MCC scores is dataset- and method-dependant. For the McPAS data subset- 2, when analysed with ERGO II-AE, addition of the MHC features significantly improved model performance indicating high feature importance. However, when the McPAS data subset-2 was analysed with ERGO II-LSTM and the TCR-ESM-MHC models, inclusion of the MHC information did not significantly improve performance reflecting low feature importance (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S8, S9, S10</xref>). Contrarily, for the VDJDB data subset-2, there was a statistically significant improvement in performance upon inclusion of the MHC features for all the models trained- ERGO II-AE, ERGO II-LSTM and TCR-ESM-MHC. The observed increase in MCC scores indicated that the MHC sequence information plays an important role in driving model output and therefore is an important feature (<xref rid="sec0085" ref-type="sec">Supplementary Figs. S8, S9, S10</xref>).</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Analysis of embeddings learned by the TCR-ESM model</title>
      <p id="p0070">The outputs from different layers of the TCR-ESM-MHC model were extracted to understand how the output of the model is driven, t-SNE was used to reduce the layer output to two dimensions. t-SNE enables capturing local relationships while also capturing non-linear relationships in the data. This is significant to determine if the embeddings can be repurposed for related tasks. We compared the embeddings of binding TCR to non-binding TCR in the input layer, concatenation layer and penultimate dense layer. For the McPAS dataset, the most common peptide ‘GILGFVFTL’ was selected from the test set. As one progresses through the layers of our model, the outputs generated become more abstract and less directly tied to specific features in the input data. Later layers then use these abstractions to construct more sophisticated features that are better suited for specific tasks. This can lead to the outputs of the later layers being more separable, or easier to distinguish from one another, compared to the outputs of the earlier layers. The results showed that the learned embeddings became more distinct as the model was trained, with positive TCR interactions and negative TCR interactions in the independent dataset for specific peptides being mixed at the input layer (<xref rid="fig0020" ref-type="fig">Figs. 4</xref><bold>a,</bold>
<xref rid="fig0020" ref-type="fig">4</xref><bold>b</bold>). The subsequent neural network layers learn the embeddings of the multiple inputs jointly, following the input layer where the information is supplied separately. Gradually the learned embeddings can be distinguished at the concatenation and penultimate dense layers which also capture the information of binding and non-binding CDR3α and CDR3β sequences (<xref rid="fig0020" ref-type="fig">Figs. 4</xref><bold>c,</bold>
<xref rid="fig0020" ref-type="fig">4</xref><bold>d</bold>). Similarly, for the VDJDB dataset, we picked the most common ‘NLVPMVATV’ peptide and performed a similar analysis of the input, concatenation and penultimate dense layer embeddings of binding and non-binding CDRα and CDR3β sequences, as illustrated in <xref rid="sec0085" ref-type="sec">Supplementary Fig. S11</xref><bold>.</bold> A similar analysis was performed for two other randomly selected peptides, also demonstrating separability as shown in <xref rid="sec0085" ref-type="sec">Supplementary Fig. S12</xref><bold>.</bold> A layer-wise analysis of the separation obtained is studied by employing a random forest classifier at each layer and evaluating the MCC scores (<xref rid="sec0085" ref-type="sec">Supplementary Fig. S13</xref>). We observed that the model learns a joint embedding for CDR3α and CDR3β and shows separation between positive and negative TCR samples for specific peptides.<fig id="fig0020"><label>Fig. 4</label><caption><p><bold>:</bold> (a) Predictive capacity of the different layers of the TCR-ESM classifier for randomly selected peptides ‘GILGFVFTL’, ‘SSYRRPVGI’ and ‘SSLENFRAYV’. Comparison of two-dimensional t-SNE embeddings for positive and negative (b) TCR(CDR3α) and (c) TCR(CDR3β) for the most common peptide ‘GILGFVFTL’ from the Input Layer of model (TCR(CDR3α + CDR3β) + peptide) trained on McPAS dataset. Comparison of jointly learned two-dimensional T-SNE embeddings for positive and negative TCR(CDR3α + CDR3β) for the most common peptide ‘GILGFVFTL’ from the (d) Concatenation Layer and (e) Penultimate Dense Layer of model (TCR(CDR3α + CDR3β) + peptide) trained on McPAS dataset.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4" id="lk0020"/></fig></p>
    </sec>
    <sec id="sec0035">
      <label>2.5</label>
      <title>External testing analysis</title>
      <p id="p0075">The level of dissimilarity between CDR3β and peptide sequences in the pMTnet dataset with the McPAS and VDJDB dataset was determined. For CDR3β sequences, pMTnet had only one (1 in 272; 0.4% identical) CDR3β sequence which was common with CDR3β in McPAS dataset. Similarly, for the VDJDB dataset, we found that the pMTnet dataset has 39 (39 in 272; 14.7% identical) common CDR3β sequences. Comparing peptides, pMTnet data has 21 (21 in 224; 9.38% identical) common peptides with McPAS data and 42 (42 in 224; 19.6% identical) common peptides with VDJDB data.</p>
      <p id="p0080">Separate models were trained on the McPAS and VDJDB dataset and tested on the pMTnet dataset to evaluate how the models perform in an external setting (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>a</bold>). Since there were some common peptides between models trained on McPAS and VDJDB with the external pMTNet test set, the models were evaluated after removing the common peptides as well (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>b</bold>). Further stringent testing was carried out by removing peptides with 90% and 80% sequence similarity to any peptide in train sets (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>c, d</bold>). The TCR-ESM model was shown to perform significantly better than the netTCR2.0, ERGO II-AE and ERGO II-LSTM models on both McPAS and VDJDB datasets. TCR-ESM also showed a higher performance on the test sets when trained on VDJDB as compared to McPAS, even after filtering similar sequences (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>,</bold>
<xref rid="sec0085" ref-type="sec">Supplementary Fig. S14</xref>). Overall, the TCR-ESM-MHC model showed improved performance on an external dataset, indicating that the approach has promising generalization capabilities. The results are encouraging because it suggests that the model is not simply memorizing the training data, but rather learning more generalizable features that can be applied to different types of data. Further testing on a variety of external datasets will be necessary to confirm the robustness of this approach, nevertheless, the initial results seem promising.<fig id="fig0025"><label>Fig. 5</label><caption><p><bold>:</bold> Comparison on external test set performance for netTCR2.0, ERGO II-AE, ERGO II-LSTM and TCR-ESM models. Models were trained on McPAS and VDJDB datasets and tested on PMTNet dataset (a), after removing peptides from the test set that are common to the training sets (b), after removing peptides that share 90% similarity with any peptide in the train sets (c) and after filtering 80% similar peptides (d). (e) Two-dimensional t-SNE embeddings for positive and negative peptides for an external dataset TCR(CDR3β) ‘CASPGLAGEYEQYF’ from the Penultimate Dense Layer of model (TCR(CDR3β) + peptide). Two-dimensional t-SNE of ESM-generated embeddings of (f) test set peptides which bind to different MHC-I types (HLA-A vs HLA-B), and (g) different MHC-I subtypes (HLA-A, HLA-B, and HLA-C). All statistical comparisons were done using Mann-Whitney U test using Benjamini-Hochberg correction (ns: p &lt; = 1.00e+00, *: 1.00e-02 &lt; p &lt; = 5.00e-02, **: 1.00e-03 &lt; p &lt; = 1.00e-02, ***: 1.00e-04 &lt; p &lt; = 1.00e-03, ****: p &lt; = 1.00e-04).</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5" id="lk0025"/></fig></p>
      <p id="p0085">Next, the embeddings learned by the model in this external set case were evaluated. One particular case was identified where the model generalizes for the CDR3β sequence ‘CASPGLAGEYEQYF’ which is not present in the training set. The embeddings learned by the penultimate layer of the TCR-ESM-MHC model were able to reliably differentiate between positive and negative peptides which can bind to ‘CASPGLAGEYEQYF’ (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>e</bold>).</p>
      <p id="p0090">The embeddings learned by the model were observed to help differentiate between peptides which bind to HLA-A versus peptides which bind to HLA-B (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>f</bold>). The embeddings were able to capture this information and encode it in a way that allows the model to accurately predict the binding status of a given peptide. It suggests that models trained on embeddings learned by large protein language models can also be used to predict the immunogenicity of different peptides and other related tasks. The nature of the HLA subtype with which a peptide is presented to T cells determines the immunogenicity, the <xref rid="fig0025" ref-type="fig">Fig. 5</xref> shows that the embeddings can learn the differences in these HLA subtypes. While it is true that the immunogenicity of a peptide cannot be predicted directly by the embeddings of the HLA, extracting meaningful features is a key step in building powerful prediction models. Also, the embeddings could distinguish between the HLA types for the positive peptides present in the test data (<xref rid="fig0025" ref-type="fig">Fig. 5</xref><bold>g</bold>).</p>
    </sec>
  </sec>
  <sec id="sec0040">
    <label>3</label>
    <title>Discussion</title>
    <p id="p0095">One major obstacle in the creation of T-cell therapies is the difficulty of identifying the specific targets, known as cognate targets, that are recognized by T-cell receptors (TCRs). This is a crucial step in the development of these therapies because the TCRs are responsible for recognizing and binding to these targets in order to initiate an immune response. Without the ability to identify and target these cognate targets, it is difficult to effectively design and implement T-cell therapies. By creating models that can anticipate TCR-pMHC interactions based on the amino acid sequences of the peptide and CDR3 region of the TCR chains, we present a study that aims to address this bottleneck using learned representations of peptides extracted using large protein language models. There were several model designs examined, ranging from single chain CDR3α-peptide binding prediction to paired CDR3α-CDR3β-peptide-MHC binding. The models were built utilizing rigorous data-redundancy reduction guidelines, trained using cross-validation, and verified using independent assessment data.</p>
    <p id="p0100">Models that used data from paired TCR category, included both CDR3α and CDR3β information, performed significantly better when compared to models trained on data with only CDR3β information. The results from the proposed study support the idea that both TCR chains contribute to TCR specificity, and that their relative importance varies depending on the specific pMHC being targeted. Considering that the datasets of McPAS and VDJDB are vastly different, the results comparing model performance on the two sets should be taken with a pinch of salt. However, on the same dataset, for example, McPAS, the TCR-ESM model does not show significant improvement in performance as opposed to ERGO II, which shows significant improvement upon inclusion of MHC data. This could be attributed to the nature of the prediction model itself. TCR-ESM is able to learn the distinguishing properties between the two classes completely based on the CDR3 sequence information. The McPAS dataset has more variable MHC chain information and the MCC score of TCR-ESM is lesser than that for the MCC on the VDJDB set, with less variable MHC information. This could be a case of the model being overfit on the limited data.</p>
    <p id="p0105">Furthermore, the inclusion of MHC information in the prediction task of TCR-peptide binding may improve the performance of the model. The impact of MHC on TCR-peptide binding is highly dataset specific and can vary depending on the characteristics of the dataset being used. The role of MHC in TCR recognition is highly complex and context-dependent, influenced by factors such as MHC polymorphism, peptide binding motifs, and peptide-MHC interactions. These factors can introduce variability in TCR-peptide binding across different datasets. Although the dataset specificity of MHC influence presents a challenge, our proposed method aims to capture and model the general principles underlying TCR-peptide binding, while acknowledging the dataset-specific nuances. By incorporating a diverse range of training data that covers various MHC alleles and peptide sequences, the model developed captures the common features and patterns of TCR-peptide binding. Furthermore, during the development and evaluation of the method, steps have been taken to address dataset specificity. It is ensured that the training dataset comprises a broad representation of MHC alleles to account for the variability in MHC-specific effects. This allows the model to learn generalizable features that are not overly biased towards any specific MHC allele.</p>
    <p id="p0110">Another limitation of the study being that it is important to carefully evaluate the impact of MHC on model performance for each specific dataset in order to determine the most effective approach for modeling TCR-peptide binding. This may be attributed to multiple peptides being generally presented by the same MHC allotypes and also multiple MHC allotypes presenting similar peptides, depending on the peptide processing and presentation pathway of the host organism.</p>
    <p id="p0115">Both negative and positive samples are essential to train a binary classifier. In the absence of negative instances derived experimentally, data points were generated by shuffling the positive set, as was derived from previous studies as described in the Methods section. However, the approaches assume that TCRs show no cross-reactivity. However, this assumption, due to challenges in obtaining negative training data, may limit the model's utility, especially in predicting the behavior of promiscuous TCRs, with the capacity to bind diverse peptide-MHC complexes. TCRs exhibit varying degrees of cross-reactivity, recognizing structurally similar peptides presented by different MHC molecules. Without accounting for cross-reactivity, predictions for promiscuous TCRs may be inaccurate, struggling to capture nuanced interactions with diverse peptide-MHC ligands. To improve the method's utility, researchers could explore ways to incorporate cross-reactivity, possibly through additional features capturing structural and biochemical properties influencing cross-reactivity. Strategies like transfer learning or advanced architectures capable of learning hierarchical representations could be considered. Including limited experimental data on cross-reactive TCRs may further improve the model's generalization beyond training data.</p>
    <p id="p0120">The power of utilizing embeddings learned by large protein language models was determined. When these embeddings are learned by large language models, they can capture the complex relationships and patterns present in the data. By using these learned embeddings as inputs to simpler machine learning models, such as multi-layer perceptrons (MLPs), we can train these models more efficiently compared to using more complex models like convolutional neural networks (CNNs), autoencoders (AEs), or long short-term memory (LSTM) networks. In the context of peptides, utilizing learned embeddings from large protein language models and then fine-tuning the embeddings can be particularly useful for tasks such as classification. The fine-tuned embeddings can be specific to the problem being addressed, in this case, they capture the interactions between proteins, such as TCRs, antigens, and MHCs. By training a classifier in the feature space of the fine-tuned protein language model, we can learn better representations of these proteins, which may lead to improved classification performance compared to traditional approaches.</p>
    <p id="p0125">Once the embeddings have been learned, they can be used as input to other machine learning models, such as classifiers or clustering algorithms. These models can then be trained on the compressed, lower-dimensional representation of the data, rather than the original high-dimensional representation. This can lead to more efficient training and faster model convergence, as well as improved performance on downstream tasks. One potential benefit of using embeddings learned by a language model instead of an autoencoder is that the embeddings capture the relationships between elements in the data, such as amino acids in a protein sequence. This can be particularly useful for biological data, where the relationships between elements can be important for understanding the structure and function of the data. In contrast, autoencoders are generally agnostic to the relationships between elements in the data, and simply learn a compressed representation based on the patterns present in the data.</p>
    <p id="p0130">In conclusion, we have developed a model to predict the interactions between TCRs and their cognate peptides and MHC molecules. Our results indicate that accurate predictions can only be achieved through the use of data from paired TCR α and β chains. While the model’s current capabilities are limited to a specific set of peptides due to a lack of training data, we expect that its predictive ability will improve as more data becomes available, enabling it to accurately predict interactions with novel peptides. Additionally, the model framework is adaptable and can easily incorporate MHC molecules or TCRα chains when data becomes available, providing a comprehensive approach for predicting TCR-pMHC interactions.</p>
  </sec>
  <sec id="sec0045">
    <label>4</label>
    <title>Methods</title>
    <sec id="sec0050">
      <label>4.1</label>
      <title>Data collection</title>
      <p id="p0135">We download four TCR-peptide binding datasets from the GitHub repositories of netTCR2.0 (https://GitHub.com/mnielLab/NetTCR-2.0), ERGO II (https://GitHub.com/IdoSpringer/ERGO II-II) and pMTnet (https://GitHub.com/tianshilu/pMTnet). The ERGO II repository contains McPAS and VDJDB datasets. Since multiple peptides may be presented by the same MHC alleles, the MHC-peptide information may be repeated in the positive and negative classes. However, the peptide-TCR pairs experimentally validated were labeled as the positive class, the negative set was generated by generating random TCR-peptide combinations and ensuring these pairs are absent from the positive dataset. The training and test datasets were obtained from the ERGO II and netTCR2.0 repositories. The external test dataset, MIRA, was also obtained from the netTCR2.0 GitHub repository. The MIRA dataset contained 376 CDR3β-peptide pairs associated with HLA-A* 02:01. We used partitioned data as detailed in netTCR2.0 and ERGO II. The pMTnet dataset was used as an external test dataset. A detailed summary of all the datasets used in this work is provided in <xref rid="sec0085" ref-type="sec">Supplementary Table 3</xref> and <xref rid="sec0085" ref-type="sec">Supplementary Table 4</xref>.</p>
      <p id="p0140">The McPAS and VDJDB datasets were processed to give two working datasets for model training and testing. The peptide and HLA counts of the two datasets are indicated in <xref rid="sec0085" ref-type="sec">Supplementary Figure 15</xref>. Subset-1 contains paired CDR3α, CDR3β and peptide information only. Subset-2 contains paired CDR3α, CDR3β, peptide and MHC information. We utilized the fair-esm python library provided by the ESM project to extract the embeddings for the TCR, peptide and MHC sequences <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>. First, a FASTA file was created for each dataset. The FASTA files were parsed to the ESM1v model to extract the pre-final layer embeddings of size 1280 for each sequence. The embeddings would have the size of 1280 * peptide length (L). Global average pooling was then employed to convert it to a 1 * 1280-dimensional vector.</p>
    </sec>
    <sec id="sec0055">
      <label>4.2</label>
      <title>Model training and performance evaluation metrics</title>
      <p id="p0145">The ESM1v protein model was employed as mentioned in the original paper without finetuning <xref rid="bib19" ref-type="bibr">[19]</xref>. ESM1v-extracted embeddings encode the TCR, peptide and MHC information. The embeddings were fed into a feedforward neural network to predict binding. Grid search was used to optimize model hyperparameters such as learning rate (ranging from 10<sup>−1</sup> to 10<sup>−4</sup>), dropout rate (ranging from 0.2 to 0.5), number of hidden layers (ranging from 1 to 2) and number of nodes (ranging from 2<sup>2</sup> to 2<sup>7</sup>) in each layer. netTCR2.0 and ERGO II models were run on the datasets as baselines to independently calculate the MCC value for the benchmarking task. The performance was compared with the reported performance values for netTCR2.0 and ERGO II, to verify accurate reproduction of results.</p>
      <p id="p0150">The model uses the GELU activation function <xref rid="bib29" ref-type="bibr">[29]</xref> in all of its hidden layers and the binary cross-entropy loss function for optimization. During training, the learning rate was set to 0.08 and was reduced by 5% if the validation MCC did not improve after 50 epochs. This was done using a learning rate scheduler to adapt to the changing dynamics of the training data and potentially improve model performance.</p>
      <p id="p0155">The model prediction performance was tested mainly based on MCC, which is reported to be a reliable statistical measure over other metrics such as AUC-ROC and AUC-PR since we performed classification on imbalance datasets <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib30" ref-type="bibr">[30]</xref>. The MCC is defined as the correlation between the observed and predicted binary classifications. It ranges from − 1–1, with values closer to 1 or − 1 indicating a stronger correlation and a better model performance. A value of 0 indicates no correlation, while negative values indicate an inverse correlation. The MCC results in a high score only when the predictions are reliable on all of the four categories- true and false positives as well as true and false negatives, while being proportional to the size of positive and negative samples in the dataset <xref rid="bib31" ref-type="bibr">[31]</xref>. The model performance is also tested and reported on the area under the receiver operating characteristic (AUC-ROC), area under the precision-recall curve (AU-PR) as well as F1 scores. The metrics are calculated as:<disp-formula id="eqn0005"><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0010"><mml:math id="M2" altimg="si0002.svg"><mml:mrow><mml:mi mathvariant="italic">Recall</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0015"><mml:math id="M3" altimg="si0003.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mi mathvariant="italic">score</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow></mml:mfrac><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0020"><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:mi mathvariant="italic">MCC</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow><mml:mrow><mml:mo>√</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where TN: true negatives, TP: true positives, FN: false negatives and FP: false positives.</p>
    </sec>
    <sec id="sec0060">
      <label>4.3</label>
      <title>Feature importance determination (ablation experiment)</title>
      <p id="p0160">Feature importance was determined through ablation studies, which involve systematically removing or "ablating" each feature from the model one at a time and measuring the impact on model performance. By comparing the model's performance with and without a given feature, one can determine the importance of that feature in driving the model output. In the context of TCR-peptide binding, feature importance determination and ablation studies can be used to identify which CDR3 chains in the TCR has significant contribution towards binding the peptides. In cases when MHC information is added to the model, ablation studies help determine whether the added information is useful or not. For TCR-peptide binding prediction, we created three different feature subsets: CDR3α-peptide, CDR3β-peptide and CDR3α-CDR3β-peptide. Similarly, for TCR-pMHC binding, we created six different feature subsets such as CDR3α-peptide, CDR3β-peptide, CDR3α-CDR3β-peptide, CDR3α-peptide-MHC, CDR3β-peptide-MHC and CDR3α-CDR3β-peptide-MHC to calculate if adding more features improves the performance of the TCR-pMHC binding prediction. Individual models such as ERGO II-Autoencoder (ERGO II-AE), ERGO II-LSTM and TCR-ESM (developed in this study), were trained for these subsets and the MCC metric was calculated to test the performance. We checked for statistical significance of performance using T-test and used Benjamini-Hochberg (BH) p-value correction to account for multiple testing <xref rid="bib32" ref-type="bibr">[32]</xref>.</p>
    </sec>
    <sec id="sec0065">
      <label>4.4</label>
      <title>Analysis of fine-tuned embeddings</title>
      <p id="p0165">The output of the intermediate and penultimate layers was extracted from the TCR-ESM feedforward neural network for the most frequent peptides in both McPAS and VDJDB dataset. t-distributed Stochastic Neighbor Embedding (t-SNE) was then performed on the output embeddings to reduce them to 2D for visualizing if the positive and negative TCRs cluster separately.</p>
    </sec>
    <sec id="sec0070">
      <label>4.5</label>
      <title>External testing analysis</title>
      <p id="p0170">A crucial component of assessing deep learning models is external testing. The model performance is tested on data samples taken from an external, other than the training data. Model performance on external samples can reveal information about how well it generalizes, or how well it can make predictions about unknown data. The model, when used in settings where it is likely to encounter data that differs from the training data, such as in the real world, external testing is especially important. We checked the generalizability by testing the TCR-ESM model on an independent dataset obtained from pMTnet <xref rid="bib26" ref-type="bibr">[26]</xref> (<xref rid="sec0085" ref-type="sec">Supplementary Table S5</xref>), which is a recently reported experimental dataset of TCR-peptide-MHC binding. pMTnet contains CDR3-peptide sequences which are different from CDR3-peptides sequences present in the McPAS and VDJDB datasets, however, there are some common peptides. The TCR-ESM models trained on McPAS and VDJDB were tested on the pMTNet set as is, after removing the common peptides and also after filtering based on 90 % and 80 % sequence similarity (sim) score measured by aligning the peptides pairwise and normalizing the alignment scores by length of the peptide.<disp-formula id="eqn0025"><mml:math id="M5" altimg="si0005.svg"><mml:mrow><mml:mi mathvariant="italic">sim</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>max</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="italic">score</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">len</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="italic">len</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>Where A is the set of all local alignments between sequences S<sub>1</sub> and S<sub>2</sub>, and a is the alignment with the highest score score(a).</p>
    </sec>
  </sec>
  <sec id="sec0075">
    <title>Author Statement</title>
    <p id="p0175">We confirm that the manuscript has been read and approved by all authors.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing Interest</title>
    <p id="p0180">The authors declare no conflict of interest.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>S.-Q.</given-names>
          </name>
          <name>
            <surname>Parker</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>K.-Y.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Z.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Direct measurement of T cell receptor affinity and sequence from naïve antiviral T cells</article-title>
        <source>Sci Transl Med</source>
        <volume>8</volume>
        <issue>341</issue>
        <year>2016</year>
        <comment>341ra377-341ra377</comment>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Sprent</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Surh</surname>
            <given-names>C.D.</given-names>
          </name>
        </person-group>
        <article-title>T cell memory</article-title>
        <source>Annu Rev Immunol</source>
        <volume>20</volume>
        <issue>1</issue>
        <year>2002</year>
        <fpage>551</fpage>
        <lpage>579</lpage>
        <pub-id pub-id-type="pmid">11861612</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Springer</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Besser</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Tickotsky-Moskovitz</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Dvorkin</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Louzoun</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of specific TCR-peptide binding from large dictionaries of TCR-peptide pairs</article-title>
        <source>Front Immunol</source>
        <volume>11</volume>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Springer</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Tickotsky</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Louzoun</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Contribution of T cell receptor alpha and beta CDR3, MHC typing, V and J genes to peptide binding prediction</article-title>
        <source>Front Immunol</source>
        <volume>12</volume>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">664514</object-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>Bjorkman</surname>
            <given-names>P.J.</given-names>
          </name>
        </person-group>
        <article-title>T-cell antigen receptor genes and T-cell recognition</article-title>
        <source>Nature</source>
        <volume>334</volume>
        <issue>6181</issue>
        <year>1988</year>
        <fpage>395</fpage>
        <lpage>402</lpage>
        <pub-id pub-id-type="pmid">3043226</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Krogsgaard</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>M.M.</given-names>
          </name>
        </person-group>
        <article-title>How T cells' see'antigen</article-title>
        <source>Nat Immunol</source>
        <volume>6</volume>
        <issue>3</issue>
        <year>2005</year>
        <fpage>239</fpage>
        <lpage>245</lpage>
        <pub-id pub-id-type="pmid">15716973</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>La Gruta</surname>
            <given-names>N.L.</given-names>
          </name>
          <name>
            <surname>Gras</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Daley</surname>
            <given-names>S.R.</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>P.G.</given-names>
          </name>
          <name>
            <surname>Rossjohn</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Understanding the drivers of MHC restriction of T cell receptors</article-title>
        <source>Nat Rev Immunol</source>
        <volume>18</volume>
        <issue>7</issue>
        <year>2018</year>
        <fpage>467</fpage>
        <lpage>478</lpage>
        <pub-id pub-id-type="pmid">29636542</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Bagaev</surname>
            <given-names>D.V.</given-names>
          </name>
          <name>
            <surname>Vroomans</surname>
            <given-names>R.M.A.</given-names>
          </name>
          <name>
            <surname>Samir</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Stervbo</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Rius</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Dolton</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>VDJdb in 2019: database extension, new analysis infrastructure and a T-cell receptor motif compendium</article-title>
        <source>Nucleic Acids Res</source>
        <volume>48</volume>
        <issue>D1</issue>
        <year>2020</year>
        <fpage>D1057</fpage>
        <lpage>D1062</lpage>
        <pub-id pub-id-type="pmid">31588507</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Tickotsky</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Sagiv</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Prilusky</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Shifrut</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>McPAS-TCR: a manually curated catalogue of pathology-associated T cell receptor sequences</article-title>
        <source>Bioinformatics</source>
        <volume>33</volume>
        <issue>18</issue>
        <year>2017</year>
        <fpage>2924</fpage>
        <lpage>2929</lpage>
        <pub-id pub-id-type="pmid">28481982</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Lanzarotti</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Marcatili</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>T-cell receptor cognate target prediction based on paired α and β chain sequence and structural CDR loop similarities</article-title>
        <source>Front Immunol</source>
        <volume>10</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">2080</object-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Dash</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Fiore-Gartland</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Hertz</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G.C.</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Souquette</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantifiable predictive features define epitope-specific T cell receptor repertoires</article-title>
        <source>Nature</source>
        <volume>547</volume>
        <issue>7661</issue>
        <year>2017</year>
        <fpage>89</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="pmid">28636592</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>Y.C.</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Lowery</surname>
            <given-names>F.J.</given-names>
          </name>
          <name>
            <surname>Gartner</surname>
            <given-names>J.J.</given-names>
          </name>
          <name>
            <surname>Prickett</surname>
            <given-names>T.D.</given-names>
          </name>
          <name>
            <surname>Robbins</surname>
            <given-names>P.F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Direct identification of neoantigen-specific TCRs from tumor specimens by high-throughput single-cell sequencing</article-title>
        <source>J Immunother Cancer</source>
        <volume>9</volume>
        <issue>7</issue>
        <year>2021</year>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Lundegaard</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lund</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Predictions versus high-throughput experiments in T-cell epitope discovery: competition or synergy?</article-title>
        <source>Expert Rev Vaccin</source>
        <volume>11</volume>
        <issue>1</issue>
        <year>2012</year>
        <fpage>43</fpage>
        <lpage>54</lpage>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Jokinen</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Huuhtanen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mustjoki</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Heinonen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lähdesmäki</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>
        <source>PLOS Comp Biol</source>
        <volume>17</volume>
        <issue>3</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e1008814</object-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>Gielis</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Moris</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bittremieux</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>De Neuter</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Ogunjimi</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Laukens</surname>
            <given-names>K.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Detection of enriched T cell epitope specificity in full T cell receptor sequence repertoires</article-title>
        <source>Front Immunol</source>
        <volume>10</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">2820</object-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Jurtz</surname>
            <given-names>V.I.</given-names>
          </name>
          <name>
            <surname>Jessen</surname>
            <given-names>L.E.</given-names>
          </name>
          <name>
            <surname>Bentzen</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Jespersen</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Mahajan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Vita</surname>
            <given-names>R.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NetTCR: sequence-based prediction of TCR binding to peptide-MHC complexes using convolutional neural networks</article-title>
        <source>BioRxiv</source>
        <year>2018</year>
        <object-id pub-id-type="publisher-id">433706</object-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Isacchini</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Walczak</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Mora</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Nourmohammad</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Deep generative selection models of T and B cell receptor repertoires with soNNia</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <volume>118</volume>
        <issue>14</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e2023141118</object-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Vig</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Madani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Varshney</surname>
            <given-names>L.R.</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Socher</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Rajani</surname>
            <given-names>N.F.</given-names>
          </name>
        </person-group>
        <article-title>BERTology meets biology: interpreting attention in protein language models</article-title>
        <source>arXiv Prepr</source>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Rives</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Meier</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sercu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Goyal</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <volume>118</volume>
        <issue>15</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e2016239118</object-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Kalakoti</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yadav</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sundar</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>TransDTI: transformer-based language models for estimating DTIs and building a drug recommendation workflow</article-title>
        <source>ACS Omega</source>
        <volume>7</volume>
        <issue>3</issue>
        <year>2022</year>
        <fpage>2706</fpage>
        <lpage>2717</lpage>
        <pub-id pub-id-type="pmid">35097268</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Meier</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Verkuil</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sercu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Rives</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Language models enable zero-shot prediction of the effects of mutations on protein function</article-title>
        <source>Adv Neural Inf Process Syst</source>
        <volume>34</volume>
        <year>2021</year>
        <fpage>29287</fpage>
        <lpage>29303</lpage>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Littmann</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Heinzinger</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Dallago</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Olenyi</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Embeddings from deep learning transfer GO annotations beyond homology</article-title>
        <source>Sci Rep</source>
        <volume>11</volume>
        <issue>1</issue>
        <year>2021</year>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="pmid">33414495</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Akin</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Hie</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>W.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>
        <source>Science</source>
        <volume>379</volume>
        <issue>6637</issue>
        <year>2023</year>
        <fpage>1123</fpage>
        <lpage>1130</lpage>
        <pub-id pub-id-type="pmid">36927031</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>Montemurro</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Schuster</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Povlsen</surname>
            <given-names>H.R.</given-names>
          </name>
          <name>
            <surname>Bentzen</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Jurtz</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Chronister</surname>
            <given-names>W.D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NetTCR-2.0 enables accurate prediction of TCR-peptide binding by using paired TCRα and β sequence data</article-title>
        <source>Commun Biol</source>
        <volume>4</volume>
        <issue>1</issue>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">1060</object-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Shugay</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bagaev</surname>
            <given-names>D.V.</given-names>
          </name>
          <name>
            <surname>Zvyagin</surname>
            <given-names>I.V.</given-names>
          </name>
          <name>
            <surname>Vroomans</surname>
            <given-names>R.M.</given-names>
          </name>
          <name>
            <surname>Crawford</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Dolton</surname>
            <given-names>G.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>VDJdb: a curated database of T-cell receptor sequences with known antigen specificity</article-title>
        <source>Nucleic Acids Res</source>
        <volume>46</volume>
        <issue>D1</issue>
        <year>2018</year>
        <fpage>D419</fpage>
        <lpage>D427</lpage>
        <pub-id pub-id-type="pmid">28977646</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep learning-based prediction of the T cell receptor–antigen binding specificity</article-title>
        <source>Nat Mach Intell</source>
        <volume>3</volume>
        <issue>10</issue>
        <year>2021</year>
        <fpage>864</fpage>
        <lpage>875</lpage>
        <pub-id pub-id-type="pmid">36003885</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</article-title>
        <source>BMC Genom</source>
        <volume>21</volume>
        <issue>1</issue>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">6</object-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sbref28">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The Matthews correlation coefficient (MCC) should replace the ROC AUC as the standard metric for assessing binary classification</article-title>
        <source>BioData Min</source>
        <volume>16</volume>
        <issue>1</issue>
        <year>2023</year>
        <object-id pub-id-type="publisher-id">4</object-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="journal" id="sbref29">
        <person-group person-group-type="author">
          <name>
            <surname>Hendrycks</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Gimpel</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Gaussian error linear units (gelus)</article-title>
        <source>arXiv Prepr</source>
        <year>2016</year>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sbref30">
        <person-group person-group-type="author">
          <name>
            <surname>Chicco</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Tötsch</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Jurman</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation</article-title>
        <source>BioData Min</source>
        <volume>14</volume>
        <issue>1</issue>
        <year>2021</year>
        <fpage>1</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="pmid">33430939</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sbref31">
        <person-group person-group-type="author">
          <name>
            <surname>Boughorbel</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Jarray</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>El-Anbari</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Optimal classifier for imbalanced data using Matthews correlation coefficient metric</article-title>
        <source>PLOS One</source>
        <volume>12</volume>
        <issue>6</issue>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">e0177678</object-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sbref32">
        <person-group person-group-type="author">
          <name>
            <surname>Benjamini</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hochberg</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>
        <source>J R Stat Soc: Ser B (Methodol)</source>
        <volume>57</volume>
        <issue>1</issue>
        <year>1995</year>
        <fpage>289</fpage>
        <lpage>300</lpage>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="sec0085" sec-type="supplementary-material">
    <label>Appendix A</label>
    <title>Supplementary material</title>
    <p id="p0190"><supplementary-material content-type="local-data" id="ec0005"><caption><p>Supplementary material</p></caption><media xlink:href="mmc1.pdf"/></supplementary-material>.</p>
    <p id="p0195"><supplementary-material content-type="local-data" id="ec0010"><caption><p>Supplementary material</p></caption><media xlink:href="mmc2.pptx"/></supplementary-material>.</p>
  </sec>
  <sec sec-type="data-availability" id="da0005">
    <title>Data availability</title>
    <p id="p0005">Raw data can be downloaded from the GitHub links as mentioned in the methods section. Processed data and the working code are available at https://GitHub.com/dhanjal-lab/tcr-esm.</p>
  </sec>
  <fn-group>
    <fn id="sec0080" fn-type="supplementary-material">
      <label>Appendix A</label>
      <p id="p0185">Supplementary data associated with this article can be found in the online version at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.csbj.2023.11.037" id="ir0005">doi:10.1016/j.csbj.2023.11.037</ext-link>.</p>
    </fn>
  </fn-group>
</back>
