<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Bioinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2673-7647</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9581036</article-id>
    <article-id pub-id-type="publisher-id">627626</article-id>
    <article-id pub-id-type="doi">10.3389/fbinf.2021.627626</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Bioinformatics</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AutoScanJ: A Suite of ImageJ Scripts for Intelligent Microscopy</article-title>
      <alt-title alt-title-type="left-running-head">Tosi et al.</alt-title>
      <alt-title alt-title-type="right-running-head">Intelligent Microscopy with AutoScanJ</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Tosi</surname>
          <given-names>Sébastien</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/694840/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lladó</surname>
          <given-names>Anna</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bardia</surname>
          <given-names>Lídia</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rebollo</surname>
          <given-names>Elena</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Godo</surname>
          <given-names>Anna</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Stockinger</surname>
          <given-names>Petra</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Colombelli</surname>
          <given-names>Julien</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/660184/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label><sup>1</sup></label>Institute for Research in Biomedicine, IRB Barcelona, Barcelona Institute of Science and Technology, BIST, <addr-line>Barcelona</addr-line>, <country>Spain</country></aff>
    <aff id="aff2"><label><sup>2</sup></label>Molecular Imaging Platform, Molecular Biology institute of Barcelona IBMB-CSIC, <addr-line>Barcelona</addr-line>, <country>Spain</country></aff>
    <aff id="aff3"><label><sup>3</sup></label>Genetics of Male Fertility Group, Cell Biology Unit, Faculty of Biosciences, Autonomous University of Barcelona, <addr-line>Bellaterra</addr-line>, <country>Spain</country></aff>
    <aff id="aff4"><label><sup>4</sup></label>Center for Genomic Regulation, CRG, Barcelona Institute of Science and Technology, BIST, <addr-line>Barcelona</addr-line>, <country>Spain</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/369374/overview" ext-link-type="uri">Jan Eglinger</ext-link>, Friedrich Miescher Institute for Biomedical Research (FMI), Switzerland</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1142164/overview" ext-link-type="uri">Romain Laine</ext-link>, University College London, United Kingdom</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/709903/overview" ext-link-type="uri">Siân Culley</ext-link>, University College London, United Kingdom</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/1155040/overview" ext-link-type="uri">Nico Stuurman</ext-link>, University of California, United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Sébastien Tosi, <email>sebastien.tosi@irbbarcelona.org</email>
</corresp>
      <fn fn-type="other">
        <p>This article was submitted to Computational BioImaging, a section of the journal Frontiers in Bioinformatics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>1</volume>
    <elocation-id>627626</elocation-id>
    <history>
      <date date-type="received">
        <day>09</day>
        <month>11</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>02</day>
        <month>2</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2021 Tosi, Lladó, Bardia, Rebollo, Godo, Stockinger and Colombelli.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Tosi, Lladó, Bardia, Rebollo, Godo, Stockinger and Colombelli</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>We developed AutoscanJ, a suite of ImageJ scripts enabling to image targets of interest by automatically driving a motorized microscope at the corresponding locations. For live samples, our software can sequentially detect biological events from their onset and further image them at high resolution, an action that would be impractical by user operation. For fixed samples, the software can dramatically reduce the amount of data acquired and the acquisition duration in situations where statistically few targets of interest are observed per field of view. AutoScanJ is compatible with motorized fluorescence microscopes controlled by Leica LAS AF/X or Micro-Manager. The software is straightforward to set up and new custom image analysis workflows to detect targets of interest can be simply implemented and shared with minimal efforts as independent ImageJ macro functions. We illustrate five different application scenarios with the system ranging from samples fixed on micropatterned surfaces to live cells undergoing several rounds of division. The target detection functions for these applications are provided and can be used as a starting point and a source of inspiration for new applications. Overall, AutoScanJ helps to optimize microscope usage by autonomous operation, and it opens up new experimental avenues by enabling the real-time detection and selective imaging of transient events in live microscopy.</p>
    </abstract>
    <kwd-group>
      <kwd>light microscopy</kwd>
      <kwd>bioimage analysis</kwd>
      <kwd>intelligent microscopy</kwd>
      <kwd>imagej</kwd>
      <kwd>micro-manager</kwd>
      <kwd>events detection</kwd>
      <kwd>objects detection</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>Introduction</title>
    <p>High-resolution fluorescence microscopy can generate an overwhelming amount of data and require a prohibitive acquisition time when imaging a wide sample area. Additionally, for live microscopy, guaranteeing sample integrity also puts hard limits on acquisition speed and maximum light dose. Fortunately, it often turns out that only part of the data acquired is useful to an experimenter interested in rare events or sparsely spread objects. Image acquisition can then naturally be re-organized in two sequential scans: 1) a scan covering a large sample area with resolution adjusted to allow the reliable detection of the targets of interest (primary scan) and 2) a higher resolution scan with fields of views selectively centered on the targets of interest (secondary scan). We refer to this technique as <italic>Intelligent Microscopy</italic> [a.k.a <italic>Intelligent Acquisition</italic> (<xref rid="B11" ref-type="bibr">Micro-Manager, 2020</xref>) or <italic>Online Feedback Analysis Microscopy</italic> (<xref rid="B20" ref-type="bibr">Zeiss, 2020</xref>)].</p>
    <p>The proprietary acquisition software of commercial microscopes now often offer advanced protocols combining imaging modalities, <italic>mosaic</italic> scans, high content screening, and partial support for Intelligent Microscopy (<xref rid="B9" ref-type="bibr">Leica, 2020</xref>; <xref rid="B12" ref-type="bibr">Nikon, 2020</xref>; <xref rid="B20" ref-type="bibr">Zeiss, 2020</xref>). In practice however, the inherent fragmentation of the market makes it difficult to share reproducible Intelligent Microscopy protocols across laboratories, and no turnkey solution is currently provided for the selective imaging of events of interest in live samples. Open source software for image acquisition (<xref rid="B7" ref-type="bibr">Edelstein et al., 2010</xref>) and image analysis (<xref rid="B6" ref-type="bibr">de Chaumont et al., 2012</xref>; <xref rid="B17" ref-type="bibr">Schneider et al., 2012</xref>; <xref rid="B10" ref-type="bibr">McQuin et al., 2018</xref>; <xref rid="B2" ref-type="bibr">Berg et al., 2019</xref>) are overall more interoperable and easier to deploy anywhere. For instance, Micro-Manager (<xref rid="B7" ref-type="bibr">Edelstein et al., 2010</xref>) is a versatile open source software to control camera-based microscopes which naturally integrates with ImageJ, one of the most widely used bioimage analysis software. Micro-Manager offers two plugins (<xref rid="B14" ref-type="bibr">Pinkard et al., 2016</xref>; <xref rid="B11" ref-type="bibr">Micro-Manager, 2020</xref>) to perform Intelligent Microscopy. The first one is designed to selectively image objects of interest in fixed samples while the second can map a 3D sample at coarse resolution and restrict posterior image acquisition (e.g. only to sample surface) with the target acquisition settings for the application.</p>
    <p>AutoScanJ is compatible with Micro-Manager (<xref rid="s8" ref-type="sec">Supplementary Data S0.0</xref>) and it brings a new dimension to Intelligent Microscopy by enabling the real-time detection of events of interest in live samples. For increased flexibility, the software is also compatible with Leica confocal microscopes<xref rid="fn1" ref-type="fn"><sup>1</sup></xref> (<xref rid="s8" ref-type="sec">Supplementary Data S7.1</xref>). Several acquisition modes are supported to adapt to the organization of the sample, and the Image analysis workflows used for target detection of new applications can be simply developed and loaded as ImageJ macro functions independent from the main software. Finally, the client-server architecture of the software enables offloading particularly demanding image analysis to a dedicated distant workstation over a network. We illustrate this flexibility for a broad range of applications both for fixed and live samples.</p>
  </sec>
  <sec sec-type="materials|methods" id="s2">
    <title>Method</title>
    <p>AutoScanJ is distributed as a suite of four ImageJ macros corresponding to the possible combinations of these acquisition scenarios: 1) fixed or live sample and 2) continuous mosaic (tiled map) or regular/freely defined acquisition locations (block mode), as illustrated in <xref rid="F1" ref-type="fig">Figure 1</xref>. The software, documentation and test data can be found at: <ext-link xlink:href="https://github.com/SebastienTs/AutoScanJ" ext-link-type="uri">https://github.com/SebastienTs/AutoScanJ</ext-link>.</p>
    <fig position="float" id="F1">
      <label>FIGURE 1</label>
      <caption>
        <p>AutoScanJ acquisition modes for fixed and live samples experiments. <bold>(A)</bold> The microscope’s parameters are set by the user before launching AutoscanJ, in particular the starting position(s) of the “Primary Scan”. <bold>(B)</bold> AutoscanJ is run with one of four modalities by launching an ImageJ macro of choice. Commands are sent through the network (vertical arrows between boxes) when using a remote workstation for processing. <bold>(C)</bold> The sample is monitored by periodically tiling a large area at low resolution (primary scan). For fixed samples <bold>(Left)</bold>, a single Tiled Map (i.e. Mosaic large area) or multiple Tiled maps (“Blocks”) are scanned, while for Live Imaging <bold>(Right)</bold> a Tiled map or user selected positions are continuously acquired. <bold>(D)</bold> The images acquired are analyzed to find events of interest. For fixed samples <bold>(Left)</bold>, the entire datasets are processed to detect targets in the images. The single Tiled Map returns an interactive montage displaying all targets detected in a tight grid, where the user can optionally discard targets (i.e. false positive ones) and set a fixed number to be acquired. A list of X,Y coordinates is built and used for the secondary scan. For Live Imaging <bold>(Right)</bold>, AutoscanJ must process at least three time points to detect rare events, and the primary scan runs “on the fly” until a “hit” is found, which triggers the secondary scan for a defined duration. <bold>(E)</bold> Secondary scan: in Live mode, when an event is detected the microscope switches to secondary scan to acquire a fixed length high-resolution time-lapse centered on the detected event. After this, the microscope switches back to primary scan monitoring until the next event is detected and AutoscanJ stops after the user-defined number of events is detected. With fixed samples, AutoscanJ stops after the secondary scan. Light blue boxes: Microscope operations, Light yellow boxes: AutoscanJ, image analysis workstation operations, Green boxes: User interventions (optional).</p>
      </caption>
      <graphic xlink:href="fbinf-01-627626-g001" position="float"/>
    </fig>
    <sec id="s2-1">
      <title>Tiled Map</title>
      <p>This operation mode is useful to monitor large regions of a sample by acquiring adjacent image tiles (<xref rid="F1" ref-type="fig">Figure 1C</xref>). After acquisition, the tiles are automatically laid side by side, maximum intensity projected, and the primary scan map is handed to a custom image analysis function (<xref rid="F1" ref-type="fig">Figure 1D</xref>). This function is expected to return a list of target coordinates (ImageJ multi-point selection) that is subsequently sent to the acquisition software to sequentially acquire higher resolution images of the targets during the secondary scan (<xref rid="F1" ref-type="fig">Figure 1E</xref>).</p>
      <p>For fixed samples, the primary map is acquired only once and the target selection can optionally be validated and refined by the user from an interactive montage (<xref rid="F1" ref-type="fig">Figure 1D</xref>, <xref rid="F2" ref-type="fig">Figure 2I</xref>) showing cropped regions around the targets. It is also possible to limit the number of targets acquired during the secondary scan (<xref rid="s8" ref-type="sec">Supplementary Data S0.2</xref>).</p>
      <fig position="float" id="F2">
        <label>FIGURE 2</label>
        <caption>
          <p>Acquiring mitotic cells at high resolution with AutoScanJ (confocal fluorescence microscopy). A to F Image analysis workflow with a cropped region from the primary scan map and a single mitotic cell closer view (inset). <bold>(A)</bold> Raw image, <bold>(B)</bold> Median filter, <bold>(C)</bold> ImageJ <italic>Remove outliers</italic>, <bold>(D)</bold> Subtracting image C to image B, <bold>(E)</bold> Thresholding non-zero pixels, <bold>(F)</bold> Connected particles of area greater or equal than 12 pixels (in red) overlaid over image A. <bold>(G)</bold> Mitotic cells detected during primary scan (yellow crosses from ImageJ, enhanced in inset). <bold>(H)</bold> Zoomed area with four mitotic cells (colour boxes).<bold>(I)</bold> Interactive montage of all detected mitotic cells, including corresponding colour boxes of H]. <bold>(J)</bold> Zoomed image of a detected mitotic cell (primary scan) and <bold>(K)</bold> The same cell acquired during the secondary scan, DNA (green), tubulin (red) and centrosomes (blue). All the images shown are z-stacks maximum intensity projections. Scale bars: A–F, H - 50 µm, G - 500 µm, H - 50 µm, K - 5 µm.</p>
        </caption>
        <graphic xlink:href="fbinf-01-627626-g002" position="float"/>
      </fig>
      <p>For live samples, primary scan maps are periodically acquired (<xref rid="F1" ref-type="fig">Figure 1C</xref>), and the maps from the three last time frames are automatically queued and handed in to the target detection function. When a target of interest is detected in a given time frame, the system immediately switches to secondary scan (without user validation) and it acquires a fixed-length time-lapse centered on the detected target before switching back to primary scan (until the next target detection). In effect, the system is consequently “blind” to new events occurring while acquiring secondary scan images (until switching back to primary scan mode) and optimized for fast live imaging of single targets.</p>
    </sec>
    <sec id="s2-2">
      <title>Block Mode</title>
      <p>In block mode, during the primary scan, the images are acquired as independent fields of view (or small tiled grids) centered around regularly spaced (or user defined) positions (<xref rid="F1" ref-type="fig">Figure 1C</xref>). This mode is to be favored when the sample naturally shows a regular organization [e.g. multi-well plates, micropatterned cells (<xref rid="B18" ref-type="bibr">Théry, 2010</xref>)], to detect events from slowly moving objects in live experiments, or if the amount of data acquired during the primary scan is too large to be comfortably processed as a single batch in the memory of the workstation.</p>
      <p>For fixed samples, all the blocks are analyzed sequentially (<xref rid="F1" ref-type="fig">Figure 1D</xref>), targets are accumulated to a list, and a single secondary scan is launched to acquire all targets once all the blocks have been analyzed. Target refinement is usually disabled since typically many targets are detected and their visual inspection would be too demanding. It is however possible to do it, for instance for debugging purposes, or to only check the first blocks of an experiment.</p>
      <p>For live samples, all the blocks are continuously monitored during primary scan and the software switches to secondary scan (<xref rid="F1" ref-type="fig">Figure 1E</xref>) immediately after an event is detected in the block currently analyzed (<xref rid="F1" ref-type="fig">Figure 1D</xref>). The primary scan monitoring of all the blocks is only resumed after acquiring a fixed-length time-lapse centered on the detected event.</p>
    </sec>
    <sec id="s2-3">
      <title>Client-Server and <italic>Offline</italic> Operation</title>
      <p>AutoScanJ is built around a client-server architecture (<xref rid="s8" ref-type="sec">Supplementary Data S0.1</xref>), which makes it very easy to offload heavy computations to a dedicated image analysis workstation. The communication between AutoScanJ macro and the acquisition software (Micro-Manager or Leica LAS AF/X) relies on a subset of Leica CAM protocol network commands (<xref rid="s8" ref-type="sec">Supplementary Data S0.3</xref>), and the image files are exchanged through a network folder. However, unless the image analysis task at hand is really demanding (e.g. high memory requirements), it is possible to use a single workstation both to control the microscope and to analyze the images. The software can also conveniently run in <italic>offline</italic> mode, by using previously acquired primary scan images (<xref rid="s8" ref-type="sec">Supplementary Data S2</xref>). This can be useful to test the software without a microscope connected, or to debug the target detection image analysis workflow after having acquired some representative primary scan images (<xref rid="s8" ref-type="sec">Supplementary Data S5</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3-1">
      <title>Imaging Mitotic Cells (Tiled Map/Fixed Sample)</title>
      <p>We used AutoScanJ to perform Intelligent Microscopy of asynchronously dividing HeLa cells stained with DAPI nuclear DNA dye (<xref rid="s8" ref-type="sec">Supplementary Data S6-M1</xref>). During the primary scan, a low resolution tiled map of 10 x 10 images was acquired (<xref rid="s8" ref-type="sec">Supplementary Data S2-D1</xref>) and analyzed by a custom ImageJ macro to identify sparsely spread mitotic cells based on the increased fluorescence from DNA condensation (<xref rid="F2" ref-type="fig">Figure 2</xref>). This ImageJ macro is available as <bold><italic>_Metaphase_detector</italic> AutoScanJ</bold> sample workflow. The mitotic cells were then reviewed by the user from a montage generated by the software (<xref rid="F2" ref-type="fig">Figure 2I</xref>) before acquiring these cells at higher resolution during the secondary scan (<xref rid="F2" ref-type="fig">Figure 2K</xref>). The image resolution was dramatically lower during the primary scan than during the secondary scan (<xref rid="F2" ref-type="fig">Figure 2J</xref>), but still sufficient to enable the reliable detection of mitotic cells. The same objective lens was used for both scans but the primary scan was greatly accelerated by decreasing the confocal zoom, the number of pixels per field of view and the number of Z slices acquired (with larger pinhole). Also, a single fluorescence channel (DAPI) was acquired during the primary scan while multiple channels were acquired during the secondary scan.</p>
      <p>For this application, 900 image tiles would have been required to cover the primary scan sample region at the resolution of the secondary scan. Each tile would have held 195 image slices (3 channels, 65 Z slices), totaling 175.500 images (171.4 GB). In contrast only 1.5 GB was acquired with AutoScanJ for the same relevant content to the study, and the whole experiment could be performed in less than 2 h. This is about two orders of magnitudes less than the time that would have been required to acquire the same sample region with the secondary scan acquisition settings.</p>
    </sec>
    <sec id="s3-2">
      <title><italic>Fishing</italic> Nuclei With Abnormal FISH Signature (Tiled Map/Fixed Sample)</title>
      <p>In this study, human spermatozoa exhibiting abnormal genotypes (e.g. the presence or absence of specific chromosomes) were studied from Fluorescence <italic>in situ</italic> Hybridization (FISH) probes labeling the chromosomes of interest (e.g. X, Y and 18, <xref rid="s8" ref-type="sec">Supplementary Data S6-M2</xref>). The project aimed at acquiring high resolution 3D images of nuclei showing a set of abnormal phenotypes so as to analyze the location of the chromosomes within these abnormal nuclei. Due to the low occurrence of some abnormal genotypes (e.g. less than 1%) tens of thousands of spermatozoa would theoretically have to be acquired at high resolution so that a sufficient number of abnormal spermatozoa could be studied. To reduce the amount of data collected, we used AutoScanJ to 1) find abnormal spermatozoa from a low resolution primary scan (<xref rid="F3" ref-type="fig">Figure 3</xref>) and 2) selectively acquire them at higher resolution in order to study chromosome territories inside the nuclei (<xref rid="s8" ref-type="sec">Supplementary Figure S3.3</xref> and <xref rid="s8" ref-type="sec">Supplementary video S1-V7</xref>). Abnormal spermatozoa were detected from a primary scan covering a large region of the sample. The detection was performed from the nuclear label and aimed at segmenting isolated (or confidently split) nuclei and classifying them based on the FISH signals that were detected inside. The target detection function supported the detection of multiple phenotypes during the same experiment (<xref rid="s8" ref-type="sec">Supplementary Data S3.3</xref>). To ensure a fast primary scan at a resolution adapted to the reliable detection of the FISH signals, a widefield microscope with optimized filter wheels was employed (<xref rid="s8" ref-type="sec">Supplementary Data S7.2</xref>). The speed of the primary scan was further increased by using camera binning and by limiting the number of Z slices acquired to the bare minimum (three slices). This was enabled by first estimating a coarse focus map interpolated from the corners of the regions acquired and then running Micro-Manager Autofocus prior to acquiring each secondary scan target (<xref rid="s8" ref-type="sec">Supplementary Data S0.2</xref>). Primary scans were typically completed in less than 1 h and could be analyzed in only a few minutes by the target detection function we developed, while several days would have probably been required by a trained experimenter to reliably mark all abnormal nuclei. An added advantage of AutoScanJ is that all detected targets could be inspected side by side at a glance, which greatly helped their validation and refinement. Secondary scans were launched overnight and typically yielded up to fifty high resolution image stacks of abnormal spermatozoa, that were used to study the accurate 3D localizations of the chromosomes in the nuclei (chromosome territories) as normalized longitudinal (xy) and radial (xz) positioning inside sperm nuclei. AutoScanJ also makes it possible to re-acquire the same secondary targets multiple times. This could for instance be useful to perform rounds of washing and staining of the same sample to obtain richer information (<xref rid="s8" ref-type="sec">Supplementary Data S0.2</xref>).</p>
      <fig position="float" id="F3">
        <label>FIGURE 3</label>
        <caption>
          <p>Imaging spermatozoa exhibiting a specific abnormal genotype with AutoScanJ (widefield fluorescence microscopy). <bold>(A)</bold> Primary scan map (DAPI channel). <bold>(B)</bold> Zoomed area showing DAPI (white) and three FISH channels (red, green, blue). <bold>(C)</bold> Same image with an overlay displaying the nuclei and FISH signals detected. The nuclei contours are color coded based on their FISH content and the cells missing the chromosome associated with the green FISH signal are detected as targets of interest (white crosses). Nuclei circled in red are excluded due to their invalid shape or size. All the images shown are z-stacks maximum intensity projections. Scale bars: A- 250 µm, B-C 5 µm. See Supplementary Material for secondary scan images.</p>
        </caption>
        <graphic xlink:href="fbinf-01-627626-g003" position="float"/>
      </fig>
    </sec>
    <sec id="s3-3">
      <title>Studying Isolated Cells on Fibronectin Micropatterned Surfaces (Block/Fixed sample)</title>
      <p>In this application we were interested in finding single isolated HeLa cells sitting on Fibronectin micropatterned surfaces (<xref rid="s8" ref-type="sec">Supplementary Data S6-M3</xref>). The micropatterns CYTOO starter chip (<xref rid="B18" ref-type="bibr">Théry, 2010</xref>) used for this experiment was made of 144 blocks, each holding a grid of 12x12 patterns with different shapes (four different shapes and three different sizes). We used it as a proof of concept to demonstrate the automated imaging and processing of whole CYTOO chips, and report single cell pattern frequency for varying pattern size (final statistics not shown in this study). The output of this experiment could also be used as the basis to build an <italic>average cell</italic> atlas (<xref rid="B18" ref-type="bibr">Théry, 2010</xref>) in a fully automated fashion, for instance to study how the geometry of the patterns influences cell polarization. In our hands, even for optimized cell seeding conditions, only a few patterns featured a single cell, most patterns being either empty or holding more than one cell. Scanning the whole chip at high resolution would hence be very inefficient. Accordingly, AutoScanJ was employed and low resolution images of every block were acquired during the primary scan. The image analysis workflow was designed to first localize valid patterns from their fluorescent label channel (<xref rid="F4" ref-type="fig">Figure 4A</xref>
<bold>)</bold>, and then analyze the content of the nuclear channel inside a square bounding box circling valid patterns (<xref rid="F4" ref-type="fig">Figure 4B</xref>). The corresponding image analysis workflow is provided as <bold><italic>_Cytoo_Isolated_Nucleus_Confocal</italic></bold> AutoScanJ sample target function. To determine if a single cell was sitting on a given pattern, significant intensity minima were counted inside the associated pattern bounding box after enhancing the nuclei by Laplacian of Gaussian filtering of the DAPI images (<xref rid="s8" ref-type="sec">Supplementary Data S3.1</xref>). Only the bounding boxes holding exactly one nucleus were selected and accumulated to a list of positions acquired during the secondary scan (<xref rid="F4" ref-type="fig">Figure 4C</xref>). Since only a single micropattern could be imaged per field of view at the target resolution, 20.736 (144 blocks x 144 patterns) fields of view (each a 75 image stack) would be required to cover the whole chip, totaling 1.555.200 images (388.8 GB). In practice, the cell seeding density yielded an average of about 15% isolated cells per block. The total amount of data acquired could then be theoretically reduced to some 58 GB. In practice, only a fixed number of cells (typically 100) were acquired, further reducing the amount of data. Even then, AutoScanJ provided a helpful overview of single cell occupancy over the whole chip, which helped optimizing the seeding density. Sample data from the primary scan imaging of four CYTOO blocks are available for testing <italic>offline</italic> (<xref rid="s8" ref-type="sec">Supplementary Data S2-D2).</xref>
</p>
      <fig position="float" id="F4">
        <label>FIGURE 4</label>
        <caption>
          <p>One of the 144 blocks of a CYTOO <italic>starter chip</italic> (confocal fluorescence microscopy). <bold>(A)</bold> Detected micropatterns in Fibronectin-Alexa 647 channel circled in gray. <bold>(B)</bold> DAPI channel: white boxes correspond to detected isolated nuclei showing individual cells on patterns; dimmer boxes are patterns with no or more than one nucleus. <bold>(C)</bold> An image from the secondary scan showing a single-cell-on-pattern HeLa cell expressing GFP-LC3 and stained with DAPI. All the images shown are z-stacks maximum intensity projections. Scale bars: A,B - 100 µm, C - 10 µm.</p>
        </caption>
        <graphic xlink:href="fbinf-01-627626-g004" position="float"/>
      </fig>
    </sec>
    <sec id="s3-4">
      <title>Acquiring Mitosis Events From Their Onset (Tiled map/Live sample)</title>
      <p>LLC-PK cell division was studied from high resolution time-lapses capturing mitosis events from their onsets. The cells were stably expressing mCherry-α-tubulin and GFP-Centrin (<xref rid="s8" ref-type="sec">Supplementary Data S6-M4</xref>) and mitosis onset was identified by detecting the nuclear membrane breakdown when α-tubulin invades the space formerly occupied by the nucleus to interlace with chromatin (<xref rid="F5" ref-type="fig">Figures 5B,C</xref>) right before mitosis (<xref rid="F5" ref-type="fig">Figures 5D,E</xref>). During a 16 h operator-free experiment, an extended region of the sample (<xref rid="F5" ref-type="fig">Figure 5A</xref>) was monitored by periodic primary scans (<xref rid="s8" ref-type="sec">Supplementary Data S2-D4</xref>). During this experiment, 14 mitosis events could be detected (<xref rid="s8" ref-type="sec">Supplementary data S1-V1 and S1-V2</xref>) by the image analysis workflow described in <xref rid="F5" ref-type="fig">Figures 5F–J</xref>, and no incorrect event was detected and acquired during the secondary scan. Each time, a 1 h high-resolution time-lapse of the mitosis was successfully recorded around the detected positions (<xref rid="F5" ref-type="fig">Figure 5K</xref>
<bold>)</bold>. The microscope was hence imaging at the target resolution about 90% of the time while it was monitoring the sample in primary scan about 10% of the time.</p>
      <fig position="float" id="F5">
        <label>FIGURE 5</label>
        <caption>
          <p>Capturing mitosis events from their onsets with AutoScanJ (LLC-PK cells, α-tubulin, confocal fluorescence microscopy). <bold>(A)</bold> A frame (at time t’<sub>-1</sub>) of the 3x2 tiled primary scan map showing a positive event at the onset of a mitosis is detected (white circle). <bold>(B,C)</bold> time sequence of the detected mitotic cell before switching to secondary scan: t’ and t’’ are start- and end-time points of secondary scan, indices are frame numbers. <bold>(D,E)</bold> The same cell after mitosis in the next primary scan. <bold>(F–J)</bold>] Associated image analysis workflow (cropped region from orange box in A] including the mitotic cell). Frame t’<sub>-2</sub>
<bold>(F)</bold> is subtracted to frame t’<sub>-1</sub>
<bold>(G)</bold>, and the result is median-filtered and thresholded <bold>(I)</bold>. Particles resembling a nucleus in size and shape (see the largest particle in I) are added to a pool of candidates, and validated as “detected mitosis” if a nucleus was detected inside (see crosses in J) in frame t<sub>−2</sub>. Nuclei are detected as local intensity minima from frame t<sub>-2</sub> LoG filtered image (H, shown with inverted contrast), and reported as white/red crosses in final image <bold>(J)</bold>. K] A montage of secondary scan images from 14 mitotic cells (green: α-tubulin, red: Centrin) detected during a 16 h long experiment. The same first time frame at t’ is represented for all mitoses. <bold>(L–N)</bold> Three selected time lapse sequences of the secondary scan from t’ to t’, acquired every 5 min. All images shown are z-stacks maximum intensity projections. Scale bars: A - 100 µm, K - 20 µm.</p>
        </caption>
        <graphic xlink:href="fbinf-01-627626-g005" position="float"/>
      </fig>
      <p>The same kind of experiment was also performed using <italic>Drosophila</italic> neuroblast primary cultures (<xref rid="s8" ref-type="sec">Supplementary Data S6-M5</xref>). This time, a nuclear marker (His2Av) was used to detect the asymmetric division of neuroblasts into daughter cells (<xref rid="s8" ref-type="sec">Supplementary Data S1-V3, S1-V4, S1-V5 and S1-V6</xref>) and the primary scan was set as 12 independent fields of view (block mode), initially centered by the user around neuroblasts and simultaneously monitored during the experiment. The image analysis workflow used for target detection is relatively simpler than for the previous application but due to the very high motility of the sample, great care was taken in designing a mechanism to limit the false positive rate of target detections (<xref rid="s8" ref-type="sec">Supplementary Data S3.2</xref>). Despite this, the false positive rate was found around 25%, but it could probably be greatly reduced by relying on properly trained deep learning networks such as U-Nets (<xref rid="B16" ref-type="bibr">Ronneberger et al., 2015</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>While it might be practically feasible to inspect a fixed sample through the oculars of a microscope and manually mark a few positions of interest, this is virtually impossible to achieve when thousands of objects have to be carefully inspected individually, or when transient events have to be quickly spotted in live samples. We have demonstrated the capability of AutoScanJ to address these two challenges for five applications performed in the context of various scientific projects.</p>
    <p>Most microscope manufacturers nowadays offer integrated tools for complex acquisition protocols including support for image analysis feedback, but these tools only provide turnkey solutions for some fixed samples experiments, and they are invariably sold as add-on modules with significant price tag. Additionally, image analysis is bound to proprietary modules (<xref rid="B12" ref-type="bibr">Nikon, 2020</xref>; Zeiss, 2020), which compromises reproducibility and limits flexibility. Open source solutions are available for Intelligent Microscopy but they either consist in charting a 2D (<xref rid="B4" ref-type="bibr">Carro et al., 2015</xref>) or 3D (<xref rid="B13" ref-type="bibr">Peravali et al., 2011</xref>; <xref rid="B14" ref-type="bibr">Pinkard et al., 2016</xref>) sample so as to restrict the imaging area, or they are designed for target detection from still images (<xref rid="B19" ref-type="bibr">Tischer et al., 2014</xref>; <xref rid="B3" ref-type="bibr">Booth et al., 2018</xref>; <xref rid="B11" ref-type="bibr">Micro-Manager, 2020</xref>) (even though live microscopy can be performed at the detected positions). An exception is Micro-pilot (<xref rid="B5" ref-type="bibr">Conrad et al., 2011</xref>), a pioneering project designed for the real-time detection of cell mitosis (and their subsequent FRAP manipulation), but this software is difficult to adapt to other applications since it was crafted for this specific application and developed in a low level language for a set of very specific microscopes. Other related feedback microscopy projects (see <xref rid="s8" ref-type="sec">Supplementary Table S1</xref>) either aim at detecting events from live microscopy time-lapses to trigger hardware devices (<xref rid="B1" ref-type="bibr">Almada et al., 2019</xref>), track moving objects/regions to adjust the acquisition position (<xref rid="B15" ref-type="bibr">Rabut and Ellenberg, 2004</xref>), or perform optogenetics photo-manipulation (<xref rid="B8" ref-type="bibr">Leifer et al., 2011</xref>).</p>
    <p>In turn, AutoScanJ is intended to democratize the access to Intelligent Microscopy. It is built around the paradigm of primary and secondary scans triggered from target detection and it aims at reusability, flexibility and versatility (<xref rid="s8" ref-type="sec">Supplementary Table S1</xref>). This is achieved by supporting two microscope control platforms (Micro-Manager and Leica LAS AF/X) able to control all main microscopy modalities, by supporting both fixed and live target detection and two acquisition modes (tiled region or regular/user defined positions), by enabling user intervention to refine target detection, and by supporting a client-server architecture to perform offload demanding image analysis to a dedicated workstation. AutoscanJ is easy to set up, fully documented (<xref rid="s8" ref-type="sec">Supplementary Data S4</xref>), relies on the simple ImageJ macro language for target detection and it comes with four primary scan sample datasets (<xref rid="s8" ref-type="sec">Supplementary Data S2</xref>) and associated image analysis workflows that aim to bring a good starting point and source of inspiration to tackle developing new target detection function for other applications (<xref rid="s8" ref-type="sec">Supplementary Data S5</xref>). To further help users getting started, we also provide a target detection function detecting targets in tissues, e.g. kidney glomeruli, that can be easily reproduced by using the same commercial sample slide (<xref rid="s8" ref-type="sec">Supplementary Data S2-D3</xref>) and similar imaging conditions (<xref rid="s8" ref-type="sec">Supplementary Data S6-M6</xref>). Finally, AutoScanJ is very modular since target detection functions can be easily appended to independent macro files (one for each of the four possible scenarios), which are automatically registered and made available from AutoScanJ main dialogue box.</p>
    <sec id="s4-1">
      <title>Perspectives</title>
      <p>Even though AutoScanJ already covers a wide range of acquisition modalities, some useful applications tackled by other software are not supported (<xref rid="s8" ref-type="sec">Supplementary Table S1</xref>). To remedy this, we especially plan a new AutoScanJ modality (ImageJ macro) for which targets are detected from still images during the primary scan and then subsequently and cyclically imaged during interleaved parallel secondary time-lapses. We also plan a tighter integration with Micro-Manager functionalities (e.g. position list and stage control) to support freely defined primary scan positions for this platform (currently only supported with Leica LAS AF/X), and the possible control of hardware triggers. Developing custom image analysis scripts to tackle new applications in ImageJ macro language should be relatively straightforward but we are aware that this might still be a hurdle for some inexperienced users. Also, the range of possible applications might be limited by the complexity of the underlying analysis. As such, we plan to tighten the links with emerging ImageJ deep learning frameworks and model zoos, for instance as a new AutoScanJ module meant to train deep learning networks from annotated primary scans, and then make using this classifier in an AutoScanJ target detection function straightforward. Finally, while we expect that most microscopy modalities should be supported by the combination of Micro-Manager and one of the main commercial microscope manufacturers, we would like to support more commercial systems and simplify bridging AutoScanJ to open microscopy projects and custom systems (e.g. Labview based). To facilitate this, we plan to provision pre-packaged bridges for a number of microscope manufacturers. If these acquisition platforms do not enable network message triggered events in the acquisition protocols, we will consider Daemon like applications running in the background and bridging AutoScanJ network messages to their respective external communication protocols.</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to thank Leica Microsystems for their support in the testing of the software, especially Juan Monteagudo and Paco Porto for their availability at the microscope, Frank Sieckmann for the technical support with Leica Computer Aided Microscopy module, and Olga Sanchez and Raniero Centrone who contributed to set up the collaboration. We are grateful to Arthur D. Edelstein and Nico Stuurman from Vale lab (Micro-Manager, UCSF) for helping us write missing drivers to control all the components of the widefield microscope we used for the experiments. We would also like to thank Sara Sdelci, Caroline Mauvezin and Nicolas Lecland (IRB Barcelona) for providing some of the biological samples used to test the system, and Constantin Nelep (CYTOO SA) for providing consultancy and consumables. The samples prepared for the FISH application were part of a project supported by the 2017/SGR-503 project (Agency for Management of University and Research Grants, Spain) and UAB CF-180034 grant (Autonomous University of Barcelona).</p>
  </ack>
  <fn-group>
    <fn id="fn1">
      <label>1</label>
      <p>Driven from LAS AF or LAS X (from 1.x to 3.x), with both Matrix and Computer Assisted Microscopy modules installed.</p>
    </fn>
  </fn-group>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession numbers can be found in the article/<xref rid="s8" ref-type="sec">Supplementary Material.</xref>
</p>
  </sec>
  <sec id="s6">
    <title>Author Contributions</title>
    <p>ST developed the software and wrote the manuscript. LB, AL, AG and PS prepared samples, performed microscopy experiments, and helped testing and improving the software. ER provided feedback and access/support for the Micro-Manager control of the widefied microscope used for some of the experiments. JC supervised the project, helped set up colaborations and provided guidance and feedback during the whole project. All authors contributed to writing the manuscript.</p>
  </sec>
  <sec sec-type="COI-statement" id="s7">
    <title>Conflict of Interest</title>
    <p>The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    <p>The Reviewer NS declared working on microscope drivers for this research and confirms the absence of any other collaboration with the authors to the handling editor.</p>
  </sec>
  <sec id="s8">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fbinf.2021.627626/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fbinf.2021.627626/full#supplementary-material</ext-link>.</p>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="datasheet1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Almada</surname><given-names>P.</given-names></name><name><surname>Pereira</surname><given-names>P. M.</given-names></name><name><surname>Culley</surname><given-names>S.</given-names></name><name><surname>Caillol</surname><given-names>G.</given-names></name><name><surname>Boroni-Rueda</surname><given-names>F.</given-names></name><name><surname>Dix</surname><given-names>C. L.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Automating multimodal microscopy with NanoJ-Fluidics</article-title>. <source>Nat. Commun.</source>
<volume>10</volume>, <fpage>1223</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-019-09231-9</pub-id>
<pub-id pub-id-type="pmid">30874553</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname><given-names>S.</given-names></name><name><surname>Kutra</surname><given-names>D.</given-names></name><name><surname>Kroeger</surname><given-names>T.</given-names></name><name><surname>Straehle</surname><given-names>C. N.</given-names></name><name><surname>Kausler</surname><given-names>B. X.</given-names></name><name><surname>Haubold</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Ilastik: interactive machine learning for (bio)image analysis</article-title>. <source>Nat. Methods</source>
<volume>16</volume>, <fpage>1226</fpage>–<lpage>1232</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0582-9</pub-id>
<pub-id pub-id-type="pmid">31570887</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Booth</surname><given-names>B. W.</given-names></name><name><surname>McParland</surname><given-names>C.</given-names></name><name><surname>Beattie</surname><given-names>K.</given-names></name><name><surname>Fisher</surname><given-names>W. W.</given-names></name><name><surname>Hammonds</surname><given-names>A. S.</given-names></name><name><surname>Celniker</surname><given-names>S. E.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>OpenHiCAMM: High-content screening software for complex microscope imaging workflows</article-title>. <source>iScience</source>
<volume>2</volume>, <fpage>136</fpage>–<lpage>140</lpage>. <pub-id pub-id-type="doi">10.1016/j.isci.2018.03.017</pub-id>
<pub-id pub-id-type="pmid">29888763</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carro</surname><given-names>A.</given-names></name><name><surname>Perez-Martinez</surname><given-names>M.</given-names></name><name><surname>Soriano</surname><given-names>J.</given-names></name><name><surname>Pisano</surname><given-names>D. G.</given-names></name><name><surname>Megias</surname><given-names>D.</given-names></name></person-group> (<year>2015</year>). <article-title>iMSRC: Converting a standard automated microscope into an intelligent screening platform</article-title>. <source>Sci. Rep.</source>
<volume>5</volume>, <fpage>10502</fpage>. <pub-id pub-id-type="doi">10.1038/srep10502</pub-id>
<pub-id pub-id-type="pmid">26015081</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conrad</surname><given-names>C.</given-names></name><name><surname>Wünsche</surname><given-names>A.</given-names></name><name><surname>Tan</surname><given-names>T. H.</given-names></name><name><surname>Bulkescher</surname><given-names>J.</given-names></name><name><surname>Sieckmann</surname><given-names>F.</given-names></name><name><surname>Verissimo</surname><given-names>F.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Micropilot: Automation of fluorescence microscopy-based imaging for systems biology</article-title>. <source>Nat. Methods</source>
<volume>8</volume>, <fpage>246</fpage>–<lpage>249</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.1558</pub-id>
<pub-id pub-id-type="pmid">21258339</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Chaumont</surname><given-names>F.</given-names></name><name><surname>Dallongeville</surname><given-names>S.</given-names></name><name><surname>Chenouard</surname><given-names>N.</given-names></name><name><surname>Hervé</surname><given-names>N.</given-names></name><name><surname>Pop</surname><given-names>S.</given-names></name><name><surname>Provoost</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Icy: An open bioimage informatics platform for extended reproducible research</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>690</fpage>–<lpage>696</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.2075</pub-id>
<pub-id pub-id-type="pmid">22743774</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edelstein</surname><given-names>A.</given-names></name><name><surname>Amodaj</surname><given-names>N.</given-names></name><name><surname>Hoover</surname><given-names>K.</given-names></name><name><surname>Vale</surname><given-names>R.</given-names></name><name><surname>Stuurman</surname><given-names>N.</given-names></name></person-group> (<year>2010</year>). <article-title>Computer control of microscopes using µManager</article-title>. <source>Curr. Protoc. Mol. Biol.</source>
<volume>Chapter 14</volume>, <fpage>Unit14</fpage>. <pub-id pub-id-type="doi">10.1002/0471142727.mb1420s92</pub-id>
</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leifer</surname><given-names>A. M.</given-names></name><name><surname>Fang-Yen</surname><given-names>C.</given-names></name><name><surname>Gershow</surname><given-names>M.</given-names></name><name><surname>Alkema</surname><given-names>M. J.</given-names></name><name><surname>Samuel</surname><given-names>A. D.</given-names></name></person-group> (<year>2011</year>). <article-title>Optogenetic manipulation of neural activity in freely moving Caenorhabditis elegans</article-title>. <source>Nat. Methods</source>
<volume>8</volume>, <fpage>147</fpage>–<lpage>152</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.1554</pub-id>
<pub-id pub-id-type="pmid">21240279</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="webpage"><collab>Leica</collab> (<year>2020</year>). <comment>Available at: <ext-link xlink:href="https://www.leica-microsystems.com/products/microscope-accessories/p/leica-hcs-a/" ext-link-type="uri">https://www.leica-microsystems.com/products/microscope-accessories/p/leica-hcs-a/</ext-link>
</comment>.</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McQuin</surname><given-names>C.</given-names></name><name><surname>Goodman</surname><given-names>A.</given-names></name><name><surname>Chernyshev</surname><given-names>V.</given-names></name><name><surname>Kamentsky</surname><given-names>L.</given-names></name><name><surname>Cimini</surname><given-names>B. A.</given-names></name><name><surname>Karhohs</surname><given-names>K. W.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>CellProfiler 3.0: next-generation image processing for biology</article-title>. <source>Plos Biol.</source>
<volume>16</volume> (<issue>7</issue>), <fpage>e2005970</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pbio.2005970</pub-id>
<pub-id pub-id-type="pmid">29969450</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="webpage"><collab>Micro-Manager</collab> (<year>2020</year>). <comment>Available at: <ext-link xlink:href="http://valelab.ucsf.edu/%7EMM/MMwiki/index.php/Intelligent_Acquisition" ext-link-type="uri">http://valelab.ucsf.edu/∼MM/MMwiki/index.php/Intelligent_Acquisition</ext-link>
</comment>.</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="webpage"><collab>Nikon</collab> (<year>2020</year>). <comment>Available at: <ext-link xlink:href="https://www.microscope.healthcare.nikon.com/en_EU/products/software/nis-elements/nis-elements-jobs" ext-link-type="uri">https://www.microscope.healthcare.nikon.com/en_EU/products/software/nis-elements/nis-elements-jobs</ext-link>
</comment>.</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peravali</surname><given-names>R.</given-names></name><name><surname>Gehrig</surname><given-names>J.</given-names></name><name><surname>Giselbrecht</surname><given-names>S.</given-names></name><name><surname>Lütjohann</surname><given-names>D. S.</given-names></name><name><surname>Hadzhiev</surname><given-names>Y.</given-names></name><name><surname>Müller</surname><given-names>F.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Automated feature detection and imaging for high-resolution screening of zebrafish embryos</article-title>. <source>BioTechniques</source>
<volume>50</volume>, <fpage>319</fpage>–<lpage>324</lpage>. <pub-id pub-id-type="doi">10.2144/000113669</pub-id>
<pub-id pub-id-type="pmid">21548893</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinkard</surname><given-names>H.</given-names></name><name><surname>Stuurman</surname><given-names>N.</given-names></name><name><surname>Corbin</surname><given-names>K.</given-names></name><name><surname>Vale</surname><given-names>R.</given-names></name><name><surname>Krummel</surname><given-names>M. F.</given-names></name></person-group> (<year>2016</year>). <article-title>Micro-Magellan: open-source, sample-adaptive, acquisition software for optical microscopy</article-title>. <source>Nat. Methods</source>
<volume>13</volume> (<issue>10</issue>), <fpage>807</fpage>–<lpage>809</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.3991</pub-id>
<pub-id pub-id-type="pmid">27684577</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabut</surname><given-names>G.</given-names></name><name><surname>Ellenberg</surname><given-names>J.</given-names></name></person-group> (<year>2004</year>). <article-title>Automatic real-time three-dimensional cell tracking by fluorescence microscopy</article-title>. <source>J. Microsc.</source>
<volume>216</volume>, <fpage>131</fpage>–<lpage>137</lpage>. <pub-id pub-id-type="doi">10.1111/j.0022-2720.2004.01404.x</pub-id>
<pub-id pub-id-type="pmid">15516224</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O.</given-names></name><name><surname>Fischer</surname><given-names>P.</given-names></name><name><surname>Brox</surname><given-names>T.</given-names></name></person-group> (<year>2015</year>). <article-title>“U-Net: convolutional networks for biomedical image segmentation,” in Medical image computing and computer-assisted intervention - MICCAI 2015. Lecture Notes in Computer Science. Editors N. Navab, J. Hornegger, W. Wells, and A. Frangi (Cham: Springer), Vol. 9351</article-title>. <pub-id pub-id-type="doi">10.1007/978-3-319-24574-4-28</pub-id>
</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>C. A.</given-names></name><name><surname>Rasband</surname><given-names>W. S.</given-names></name><name><surname>Eliceiri</surname><given-names>K. W.</given-names></name></person-group> (<year>2012</year>). <article-title>NIH Image to ImageJ: 25 years of image analysis</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>671</fpage>–<lpage>675</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.2089</pub-id>
<pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Théry</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>Micropatterning as a tool to decipher cell morphogenesis and functions</article-title>. <source>J. Cel Sci.</source>
<volume>123</volume>, <fpage>4201</fpage>–<lpage>4213</lpage>. <pub-id pub-id-type="doi">10.1242/jcs.075150</pub-id>
</mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tischer</surname><given-names>C.</given-names></name><name><surname>Hilsenstein</surname><given-names>V.</given-names></name><name><surname>Hanson</surname><given-names>K.</given-names></name><name><surname>Pepperkok</surname><given-names>R.</given-names></name></person-group> (<year>2014</year>). <article-title>Adaptive fluorescence microscopy by online feedback image analysis</article-title>. <source>Methods Cel. Biol.</source>
<volume>123</volume>, <fpage>489</fpage>–<lpage>503</lpage>. <pub-id pub-id-type="doi">10.1016/B978-0-12-420138-5.00026-4</pub-id>
</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="webpage"><collab>Zeiss</collab> (<year>2020</year>). <comment>Available at: <ext-link xlink:href="https://github.com/zeiss-microscopy/OAD/tree/master/Guided" ext-link-type="uri">https://github.com/zeiss-microscopy/OAD/tree/master/Guided</ext-link>_Acquisition (Accessed October 13, 2020)</comment>.</mixed-citation>
    </ref>
  </ref-list>
</back>
