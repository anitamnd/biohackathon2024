<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5196</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">3893567</article-id>
    <article-id pub-id-type="doi">10.3389/fninf.2013.00050</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Original Research Article</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Fast parallel image registration on CPU and GPU for diagnostic classification of Alzheimer's disease</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Shamonin</surname>
          <given-names>Denis P.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bron</surname>
          <given-names>Esther E.</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lelieveldt</surname>
          <given-names>Boudewijn P. F.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Smits</surname>
          <given-names>Marion</given-names>
        </name>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Klein</surname>
          <given-names>Stefan</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Staring</surname>
          <given-names>Marius</given-names>
        </name>
        <xref ref-type="author-notes" rid="fn001">
          <sup>*</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <collab>for the Alzheimer's Disease Neuroimaging Initiative</collab>
        <xref ref-type="author-notes" rid="fn003">
          <sup>†</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1">
      <sup>1</sup>
      <institution>Division of Image Processing (LKEB), Department of Radiology, Leiden University Medical Center</institution>
      <country>Leiden, Netherlands</country>
    </aff>
    <aff id="aff2">
      <sup>2</sup>
      <institution>Biomedical Imaging Group Rotterdam, Departments of Medical Informatics and Radiology</institution>
      <country>Erasmus MC, Rotterdam, Netherlands</country>
    </aff>
    <aff id="aff3">
      <sup>3</sup>
      <institution>Intelligent Systems Group, Faculty of EEMCS, Delft University of Technology</institution>
      <country>Delft, Netherlands</country>
    </aff>
    <aff id="aff4">
      <sup>4</sup>
      <institution>Department of Radiology</institution>
      <country>Erasmus MC, Rotterdam, Netherlands</country>
    </aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Brian Avants, University of Pennsylvania, USA</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Tjeerd O. Scheper, Oxford Brookes University, UK; Baohua Wu, University of Pennsylvania, USA</p>
      </fn>
      <corresp id="fn001">*Correspondence: Marius Staring, Division of Image Processing (LKEB), Department of Radiology, Leiden University Medical Center, PO Box 9600, 2300 RC Leiden, Netherlands e-mail: <email xlink:type="simple">m.staring@lumc.nl</email></corresp>
      <fn fn-type="other" id="fn002">
        <p>This article was submitted to the journal Frontiers in Neuroinformatics.</p>
      </fn>
      <fn fn-type="present-address" id="fn003">
        <p>† Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: <ext-link ext-link-type="uri" xlink:href="http://adni.loni.ucla.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf">http://adni.loni.ucla.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf</ext-link></p>
      </fn>
    </author-notes>
    <pub-date pub-type="epreprint">
      <day>05</day>
      <month>12</month>
      <year>2013</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>1</month>
      <year>2014</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2013</year>
    </pub-date>
    <volume>7</volume>
    <elocation-id>50</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>8</month>
        <year>2013</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>12</month>
        <year>2013</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2014 Shamonin, Bron, Lelieveldt, Smits, Klein and Staring.</copyright-statement>
      <copyright-year>2014</copyright-year>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Nonrigid image registration is an important, but time-consuming task in medical image analysis. In typical neuroimaging studies, multiple image registrations are performed, i.e., for atlas-based segmentation or template construction. Faster image registration routines would therefore be beneficial. In this paper we explore acceleration of the image registration package <monospace>elastix</monospace> by a combination of several techniques: (i) parallelization on the CPU, to speed up the cost function derivative calculation; (ii) parallelization on the GPU building on and extending the OpenCL framework from ITKv4, to speed up the Gaussian pyramid computation and the image resampling step; (iii) exploitation of certain properties of the B-spline transformation model; (iv) further software optimizations. The accelerated registration tool is employed in a study on diagnostic classification of Alzheimer's disease and cognitively normal controls based on T1-weighted MRI. We selected 299 participants from the publicly available Alzheimer's Disease Neuroimaging Initiative database. Classification is performed with a support vector machine based on gray matter volumes as a marker for atrophy. We evaluated two types of strategies (voxel-wise and region-wise) that heavily rely on nonrigid image registration. Parallelization and optimization resulted in an acceleration factor of 4–5x on an 8-core machine. Using OpenCL a speedup factor of 2 was realized for computation of the Gaussian pyramids, and 15–60 for the resampling step, for larger images. The voxel-wise and the region-wise classification methods had an area under the receiver operator characteristic curve of 88 and 90%, respectively, both for standard and accelerated registration. We conclude that the image registration package <monospace>elastix</monospace> was substantially accelerated, with nearly identical results to the non-optimized version. The new functionality will become available in the next release of <monospace>elastix</monospace> as open source under the BSD license.</p>
    </abstract>
    <kwd-group>
      <kwd>image registration</kwd>
      <kwd>parallelization</kwd>
      <kwd>acceleration</kwd>
      <kwd>OpenCL</kwd>
      <kwd>
        <monospace>elastix</monospace>
      </kwd>
      <kwd>Alzheimer's disease</kwd>
    </kwd-group>
    <counts>
      <fig-count count="18"/>
      <table-count count="3"/>
      <equation-count count="6"/>
      <ref-count count="45"/>
      <page-count count="15"/>
      <word-count count="10880"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1. Introduction</title>
    <p>Image registration is a frequently used technique in medical image processing. It refers to the process of automatically aligning imaging data, where a <italic>moving (target) image I<sub>M</sub></italic> is deformed to mimick a <italic>fixed (reference) image I<sub>F</sub></italic>. In other words, registration is the problem of finding a coordinate transformation <italic><bold>T</bold></italic> that makes <italic>I<sub>M</sub></italic>(<italic><bold>T</bold></italic>) spatially aligned with <italic>I<sub>F</sub></italic>. The quality of alignment is defined by a cost function <graphic xlink:href="fninf-07-00050-i0003.jpg" position="float"/>. The optimal coordinate transformation is estimated by minimizing the cost function with respect to <italic><bold>T</bold></italic>, usually by means of an iterative optimization method embedded in a hierarchical (multiresolution) scheme. Extensive reviews on the subject of image registration are given in Brown (<xref ref-type="bibr" rid="B8">1992</xref>); Maintz and Viergever (<xref ref-type="bibr" rid="B29">1998</xref>). Areas of application include the alignment of data sets from different modalities (Mattes et al., <xref ref-type="bibr" rid="B30">2003</xref>) to fuse information, comparison of follow-up with baseline scans (Staring et al., <xref ref-type="bibr" rid="B41">2007</xref>) to follow disease development, alignment of different MR sequences for extraction of quantitative MR parameters such as in diffusion tensor imaging or MR relaxometry (Alexander et al., <xref ref-type="bibr" rid="B1">2001</xref>; Bron et al., <xref ref-type="bibr" rid="B7">2013</xref>), alignment of pre- and post-contrast images (Rueckert et al., <xref ref-type="bibr" rid="B35">1999</xref>) to aid breast cancer detection and diagnosis, and updating treatment plans for radiotherapy and surgery (Pennec et al., <xref ref-type="bibr" rid="B32">2003</xref>).</p>
    <p>Accordingly, most neuroimaging research also requires image registration. Registration is mainly needed to create a reference frame, which enables comparison between subjects, between image sequences and over time. This reference framework can either be a common template space to which every subject's image is registered (Mazziotta et al., <xref ref-type="bibr" rid="B31">1995</xref>; Seghers et al., <xref ref-type="bibr" rid="B37">2004</xref>; Ashburner, <xref ref-type="bibr" rid="B3">2007</xref>), or a region-labeling system for example obtained with multi-atlas segmentation (Heckemann et al., <xref ref-type="bibr" rid="B18">2006</xref>). Many different neuroimaging applications rely on such a reference framework: statistical group comparisons (Friston et al., <xref ref-type="bibr" rid="B15">1994</xref>), voxel-based morphometry (Ashburner and Friston, <xref ref-type="bibr" rid="B4">2000</xref>), tissue segmentation (Fischl et al., <xref ref-type="bibr" rid="B14">2002</xref>; Ashburner and Friston, <xref ref-type="bibr" rid="B5">2005</xref>), and diagnostic classification (Klöppel et al., <xref ref-type="bibr" rid="B25">2008</xref>; Magnin et al., <xref ref-type="bibr" rid="B28">2009</xref>; Cuingnet et al., <xref ref-type="bibr" rid="B11">2011</xref>). In these applications, registration methods are used to align the data with the reference frame.</p>
    <p>To create a reference frame that maps between different subjects, nonrigid image registration is applied, which can be very time-consuming. Runtime depends on the specific cost function, transformation complexity, data size, and optimization strategy. The first three items have increased in complexity over the years: more complex cost functions were needed for multi-modal image registration (Maes et al., <xref ref-type="bibr" rid="B27">1997</xref>), nonrigid transformations have many parameters frequently generating a 10<sup>6</sup> dimensional space to be optimized, and data sizes have increased tremendously with the advent of new scanners. This results in a typical runtime of registration algorithms in the order of at best 15 min, up to hours (Klein et al., <xref ref-type="bibr" rid="B21">2009a</xref>); future acquisition-side improvements in image resolution may even increase that number. Moreover, for creating a reference frame, many registrations are required: every subject needs to be aligned with the template space, or, when using multi-atlas segmentation, every atlas image needs to be aligned with every subject image.</p>
    <p>One of the neuroimaging applications mentioned above is diagnostic classification. As the incidence of Alzheimer's Disease (AD) as well as the need for early and accurate diagnosis is dramatically growing (Alzheimer's Association, <xref ref-type="bibr" rid="B2">2012</xref>), automated classification is an emerging research field. To advance the diagnosis of AD in individual patients, machine-learning techniques can be applied to imaging or other data. These techniques use labeled data to train a classifier to categorize two groups (e.g., patients and controls). Several studies demonstrated the successful classification of dementia based on atrophy using such machine-learning methods (e.g., Fan et al., <xref ref-type="bibr" rid="B13">2008</xref>; Klöppel et al., <xref ref-type="bibr" rid="B25">2008</xref>; Vemuri et al., <xref ref-type="bibr" rid="B43">2008</xref>; Magnin et al., <xref ref-type="bibr" rid="B28">2009</xref>; Cuingnet et al., <xref ref-type="bibr" rid="B11">2011</xref>; Koikkalainen et al., <xref ref-type="bibr" rid="B26">2012</xref>). The atrophy features used in these studies are derived from structural MR using two main approaches: voxel-wise (e.g., Klöppel et al., <xref ref-type="bibr" rid="B25">2008</xref>) and region-wise (e.g., Magnin et al., <xref ref-type="bibr" rid="B28">2009</xref>) feature extraction. Voxel-wise methods use a feature for each voxel in the brain, for example the gray matter (GM) density as an atrophy measure. In the region-wise approach, a region-labeling consisting of a set of brain regions is used to calculate a feature, for example the GM volume in each region of interest (ROI). Both approaches require many nonrigid image registrations: in the voxel-wise approach, to align all scans in a template space, and in the region-wise approach, to obtain a region-labeling for each individual scan using multi-atlas segmentation.</p>
    <p>In this paper we explore the acceleration of image registration in the context of neuroimaging applications, by a combination of methods. Critical registration components are parallelized, utilizing the CPU as well as the GPU, certain properties of the B-spline transformation model are exploited, and source code is optimized. These efforts are integrated in the popular open source registration toolkit <monospace>elastix</monospace> (Klein et al., <xref ref-type="bibr" rid="B23">2010</xref>), which is based on the Insight ToolKit (ITK, (Ibánez et al., <xref ref-type="bibr" rid="B19">2005</xref>)). <monospace>elastix</monospace> aims to deliver convenient access to a wide range of image registration algorithms to end-users (researchers as well as medical practitioners). For the GPU implementation, the recently introduced OpenCL functionality in ITKv4 was improved, extended and exploited. The developed functionality will become available in the next release of <monospace>elastix</monospace>, as open source under the BSD license.</p>
    <p>Others have also addressed registration performance by means of parallel processing. An overview of both CPU and GPU work is given by Shams et al. (<xref ref-type="bibr" rid="B39">2010b</xref>). Many authors use derivative-free optimization techniques, and therefore focus on low dimensional transformations, on a cluster of computers (Warfield et al., <xref ref-type="bibr" rid="B44">1998</xref>), using a GPU (Shams et al., <xref ref-type="bibr" rid="B38">2010a</xref>) or an FPGA (Castro-Pareja et al., <xref ref-type="bibr" rid="B9">2003</xref>). Rohlfing and Maurer (<xref ref-type="bibr" rid="B34">2003</xref>) proposed a scheme for nonrigid registration using finite differences for the derivative computation, distributing the elements of the derivative over the processing elements. Results were evaluated by visual inspection. Saxena et al. (<xref ref-type="bibr" rid="B36">2010</xref>) implemented an analytical derivative based nonrigid registration scheme on the GPU for mutual information, using CUDA. In this paper we present methods that (i) exploit both the CPU and hardware accelerators (GPU, and potentially also the FPGA), (ii) do not require a cluster of computers but runs on a single computer, (iii) are based on the analytical cost function derivative, enabling gradient based (stochastic) optimization, (iv) work for 2D and 3D image registration, implemented for various metrics and various transformation types, (v) will be made freely available, and (vi) are quantitatively validated to obtain similar results as the unoptimized registration method.</p>
    <p>The paper is outlined as follows. In Section 2 preliminary information is given about image registration, <monospace>elastix</monospace>, OpenCL and ITK. The registration accelerations are described in Section 3, together with the methodology for voxel-wise and region-wise diagnostic classification of AD. Experiments and results are given in Section 4, detailing the obtained speedup factors (Section 4.2 and 4.3). In Section 4.4 an accuracy analysis is made comparing original and optimized versions of <monospace>elastix</monospace>. For this evaluation, we used structural MR data of AD patients and healthy volunteers from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The paper is concluded in Section 5.</p>
  </sec>
  <sec>
    <title>2. Preliminaries</title>
    <sec>
      <title>2.1. Image registration</title>
      <p>Image registration is the process of aligning images, and can be defined as an optimization problem:</p>
      <p>
        <graphic xlink:href="fninf-07-00050-i0002.jpg" position="float"/>
      </p>
      <p>with <italic>I<sub>F</sub></italic>(<italic><bold>x</bold></italic>): <italic><bold>x</bold></italic> ∈ Ω<sub><italic>F</italic></sub> → ℝ and <italic>I<sub>M</sub></italic>(<italic><bold>x</bold></italic>): <italic><bold>x</bold></italic> ∈ Ω<sub><italic>M</italic></sub> → ℝ the <italic>d</italic>-dimensional fixed and moving image, respectively, on their domains Ω<sub><italic>F</italic></sub> and Ω<sub><italic>M</italic></sub>, and <bold>μ</bold> the vector of parameters of size <italic>N</italic> that model the transformation <italic><bold>T</bold></italic><sub>μ</sub>. The cost function <graphic xlink:href="fninf-07-00050-i0003.jpg" position="float"/> consists of a similarity measure <graphic xlink:href="fninf-07-00050-i0004.jpg" position="float"/>(<italic>I</italic><sub><italic>F</italic></sub>, <italic>I<sub>M</sub></italic>; <bold>μ</bold>) that defines the quality of alignment, and optionally a regularizer. Examples of the first are the mean square difference (MSD), normalized correlation (NC), and mutual information (MI) (Maes et al., <xref ref-type="bibr" rid="B27">1997</xref>) measure; examples of the last are the bending energy (Rueckert et al., <xref ref-type="bibr" rid="B35">1999</xref>) and rigidity penalty term (Staring et al., <xref ref-type="bibr" rid="B41">2007</xref>). Optimization is frequently performed using a form of gradient descent:</p>
      <p>
        <graphic xlink:href="fninf-07-00050-i0005.jpg" position="float"/>
      </p>
      <p>with <italic>a<sub>k</sub></italic> the step size at iteration <italic>k</italic>. The derivative of the cost function can commonly be written as</p>
      <p>
        <graphic xlink:href="fninf-07-00050-i0006.jpg" position="float"/>
      </p>
      <p>with ξ(·) a continuous function mapping to ℝ, <inline-formula><mml:math id="M4"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic> a discrete set of coordinates from Ω<italic><sub>F</sub></italic>, and η = 1 / |<inline-formula><mml:math id="M5"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic>| a normalization factor. For the MSD metric for example we have ξ(·) = <italic>I<sub>F</sub></italic>(<italic><bold>x</bold></italic>) − <italic>I<sub>M</sub></italic>(<italic><bold>T</bold></italic>(<italic><bold>x</bold></italic>)). This form holds for all the above mentioned similarity metrics, while for regularizers a similar form can be derived. In this paper we focus on stochastic optimization methods (Klein et al., <xref ref-type="bibr" rid="B24">2007</xref>), where the derivative is computed with a small number |<inline-formula><mml:math id="M6"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic>| of randomly drawn samples, newly selected in each iteration <italic>k</italic>. Specifically, we use the adaptive stochastic gradient descent optimizer (Klein et al., <xref ref-type="bibr" rid="B22">2009b</xref>), which automatically computes the step size <italic>a<sub>k</sub></italic>. The computation time of this step is addressed in other work (Qiao et al., <xref ref-type="bibr" rid="B33">2014</xref>).</p>
      <p>Image registration is usually embedded in a multi-resolution framework, and after the optimization procedure (1) has finished, a resampling of the moving image is desired to generate the registration result <inline-formula><mml:math id="M7"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
    </sec>
    <sec>
      <title>2.2. GPUs and OpenCL</title>
      <p>Multi-core computers have enabled the acceleration of a wide variety of computationally intensive applications. Nowadays, another type of hardware promises even higher computational performance: the graphics processing unit (GPU), which has a highly parallel hardware structure. This makes them more effective than general purpose CPUs for algorithms where processing of large blocks of data can be performed in parallel. The increasing computing power of GPUs gives them considerably higher peak computing power than CPUs. For example, NVidia's GeForce GTX 780 GPU provides 3977 Gflop/s and AMDs HD7970 GPU 3788 Gflop/s, while Intels Xeon X5675 CPU reaches only 144 Gflop/s.</p>
      <p>Writing parallel programs to take full advantage of this GPU power is still a challenge. The OpenCL C programming language (<ext-link ext-link-type="uri" xlink:href="http://www.khronos.org/opencl/">www.khronos.org/opencl/</ext-link>) can be used to create programs that can be executed on one or more heterogeneous devices such as CPUs, GPUs, FPGAs and potentially other devices developed in the future. CUDA (<ext-link ext-link-type="uri" xlink:href="http://www.nvidia.com/object/cuda_home_new.html">www.nvidia.com/object/cuda_home_new.html</ext-link>) on the other hand is NVidia's C language targeted to NVidia GPUs only. OpenCL is maintained by the non-profit technology consortium Khronos Group. An OpenCL program is similar to a dynamic library, and an OpenCL kernel is similar to an exported function from the dynamic library. In OpenCL programmers can use OpenCL command queue execution and events to explicitly specify runtime dependencies between arbitrary queued commands, which is different from C(++) where sequential execution of commands is always implied. OpenCL is based on the C99 language specification with some restrictions and specific extensions to the language for parallelism.</p>
      <p>In this project we decided to adopt OpenCL for algorithm implementation for two reasons: (i) OpenCL solutions are independent of the GPU hardware vendor, and can even be run on other hardware accelerators, thereby broadening the applicability of this work; (ii) Our image registration package <monospace>elastix</monospace> is largely based on the Insight Toolkit (ITK), in which OpenCL also was adopted recently.</p>
    </sec>
    <sec>
      <title>2.3. <monospace>elastix</monospace> and ITKv4</title>
      <p>Parallelization is performed in the context of the image registration software <monospace>elastix</monospace> (Klein et al., <xref ref-type="bibr" rid="B23">2010</xref>), available at <ext-link ext-link-type="uri" xlink:href="http://elastix.isi.uu.nl">http://elastix.isi.uu.nl</ext-link>. The software is distributed as open source via periodic software releases under a BSD license. The software consists of a collection of algorithms that are commonly used to solve (medical) image registration problems. The modular design of <monospace>elastix</monospace> allows the user to quickly configure, test, and compare different registration methods for a specific application. A command-line interface enables automated processing of large numbers of data sets, by means of scripting.</p>
      <p><monospace>elastix</monospace> is based on the well-known open source Insight Segmentation and Registration Toolkit (ITK) (Ibánez et al., <xref ref-type="bibr" rid="B19">2005</xref>) available at <ext-link ext-link-type="uri" xlink:href="http://www.itk.org">www.itk.org</ext-link>. This library contains a lot of image processing functionality, and delivers an extremely well tested coding framework. The ITK is implemented in C++, nightly tested, has a rigorous collaboration process, and works on many platforms and compilers. The use of the ITK in <monospace>elastix</monospace> implies that the low-level functionality (image classes, memory allocation, etc.) is thoroughly tested. Naturally, all image formats supported by the ITK are supported by <monospace>elastix</monospace> as well. <monospace>elastix</monospace> can be compiled on multiple operating systems (Windows, Linux, Mac OS X), using various compilers (MS Visual Studio, Clang, GCC), and supports both 32 and 64 bit systems.</p>
    </sec>
  </sec>
  <sec id="s2">
    <title>3. Methods</title>
    <p>As described in Section 2.1 the image registration algorithm consists of multiple parts: general tasks such as image reading and setting up the registration pipeline, pyramid construction, then iteratively derivative computation and updating of the parameter vector using (2), and finally resampling. To accelerate the registration algorithm, we identified the pyramid construction, the optimization routine and the resampling step as the most dominant parts in terms of performance. Acceleration possibilities for the optimization routine are identified by recognizing parallelization options, by manual inspection of the source code, and by the use of the Callgrind profiling tool (Weidendorfer et al., <xref ref-type="bibr" rid="B45">2004</xref>), see Section 3.1. This component of the registration algorithm is performed on the CPU. Both pyramid construction and resampling are in this work off-loaded to the GPU, because these components exhibit clear opportunities for massive data parallelization, see Section 3.2. Finally, in Section 3.3, we present the methods used for validation of the optimized registration procedure with an experiment on diagnostic classification of AD which heavily relies on image registration.</p>
    <sec>
      <title>3.1. CPU</title>
      <p>Considering Equation (3) we see that image registration constitutes a loop over the image samples as a key component of the algorithm. This part can be computed in parallel by distributing the image samples in <inline-formula><mml:math id="M8"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic> over different threads. This is implemented by a fork-and-join model using the thread system of the ITK: in each iteration <italic>T</italic> threads are created (forking), <italic>T</italic> derivatives <italic><bold>g</bold><sup>t</sup><sub>k</sub></italic> = ∂<graphic xlink:href="fninf-07-00050-i0003.jpg" position="float"/><italic><sup>t</sup></italic> / ∂<bold>μ</bold> over the sample subsets are computed in parallel (<italic>t</italic> denoting the thread id), and the results are joined into a single derivative. Functions that are used by the different threads were made thread-safe, and preparation functionality was refactored and called only once by the master thread. Where possible, we avoided false sharing of data (Bolosky and Scott, <xref ref-type="bibr" rid="B6">1993</xref>), which can substantially affect performance. This recipe was implemented in <monospace>elastix</monospace> for several similarity measures (MSD, NC, MI, kappa statistic), and the bending energy penalty term.</p>
      <p>Parallel computation was also implemented at several other places, namely for aggregation of the thread derivatives <italic><bold>g</bold><sup>t</sup><sub>k</sub></italic> to a single derivative <italic><bold>g</bold><sub>k</sub></italic>, and for performing the update step of the optimizer, see Equation (2). At these places some straightforward vector arithmetic is performed on <italic><bold>g</bold><sub>k</sub></italic> and <bold>μ</bold><italic><sub>k</sub></italic>, which are vectors of possibly very long size (up to 10<sup>6</sup>). Parallelization can be performed here by threads working on disjoint parts of the vectors. Implementations using the ITK thread model and OpenMP were created.</p>
      <p>Again considering Equation (3) we can see that part of the computation is in calculating ∂ <italic><bold>T</bold></italic> / ∂<bold>μ</bold> ≐ <italic><bold>J</bold></italic>. The Callgrind profiler confirmed this as a performance bottleneck. For the general case the matrix <italic><bold>J</bold></italic> has size <italic>d</italic> × <italic>N, N</italic> being the size of <bold>μ</bold>. In case of a B-spline transformation however, this matrix is mostly empty due to the compact support of the B-spline basis function, resulting in a matrix of size <italic>d</italic> × <italic>dP, P</italic> = (<italic>O</italic> + 1)<italic><sup>d</sup></italic> « <italic>N</italic>, with <italic>O</italic> the B-spline order (usually equal to 3). This much smaller matrix has the form:
<disp-formula id="E1"><label>(4)</label><mml:math id="M1"><mml:mrow><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≐</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>μ</mml:mi></mml:mstyle></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi>j</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>⋯</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>⋯</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>⋯</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi>j</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>⋯</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>⋯</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>⋯</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi>j</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <italic>j<sub>i</sub></italic> are products of the B-spline basis functions, following from the definition (Rueckert et al., <xref ref-type="bibr" rid="B35">1999</xref>). The derivative of the B-spline transformation is therefore a relatively small and sparse matrix, with repetitive elements, thus only <italic>P</italic> elements need to be computed instead of <italic>d</italic><sup>2</sup><italic>P</italic> or even <italic>d</italic><italic>N</italic>. Again examining (3) we can see that the multiplication <inline-formula><mml:math id="M9"><mml:mrow><mml:msup><mml:mi>J</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> can also be accelerated by omitting the empty parts.</p>
      <p>Further optimizations to the source code resulted from a combination of Callgrind profiling and visual inspection of the source code, and include: (i) Allocated large vectors or matrices only once and re-use them throughout the registration. Examples include the cost function derivative <italic><bold>g</bold><sub>k</sub></italic>, the transformation parameters <bold>μ</bold><italic><sub>k</sub></italic> and the transformation derivative <italic><bold>J</bold></italic>, and in the optimizer the new position <bold>μ</bold><sub><italic>k</italic> + 1</sub>; (ii) Avoided repeated initializations of large arrays (fill with zeros), and additionally optimized this operation using <monospace>std::fill</monospace> (contributed back to ITKv4); (iii) Optimized some often used functions by avoiding ITK iterators, the use of loop unrolling, memcpy, etc; (iv) Compared to the previous implementation the amount of memory accesses were reduced when interpolating the moving image value and gradient; (v) Implemented gradient computation for the linear interpolator, which can compute the moving image gradient ∂ <italic>I<sub>M</sub></italic> / ∂ <italic><bold>x</bold></italic> [see Equation (3)] much faster than the existing implementation of the first order B-spline interpolator; (vi) Made use of a new ‘scan line’ iterator from ITKv4 with low overhead.</p>
    </sec>
    <sec>
      <title>3.2. GPU</title>
      <p>For implementing algorithms on the GPU we have chosen to build on ITKv4's recent addition for GPU acceleration. This module wraps the OpenCL 1.2 API in an ITK-style API, while taking care of OpenCL initialization, program compilation, and kernel execution. It also provides convenience classes for interfacing with ITK image classes and filtering pipelines.</p>
      <p>In the OpenCL design of ITKv4 important parts of the OpenCL specification were missing, most notably the queueing mechanisms and event objects. We implemented a large part of the OpenCL class diagram, where classes are responsible for a specific task conforming to the OpenCL standard. OpenCL event objects are used to synchronize execution of multiple kernels, in case a program consists of multiple kernels. We take advantage of the scheduling and synchronization mechanisms of OpenCL for the implementation of the GPU version of the resampler, see Section 3.2.2, where individual kernels have to be executed in order. In addition, we have added debugging and profiling functionality, which are useful features during development and for understanding performance bottlenecks of GPU architectures. A number of modifications have been made to improve design, implementation, and platform support (Intel, AMD, NVidia), thereby enhancing the existing ITKv4 GPU design.</p>
      <p>We identified two independent registration components that allow for parallelism: the Gaussian pyramids and the resampling step. The Gaussian filtering relies on a line-by-line causal and anti-causal filtering, where all image scan lines can be independently processed; The resampling step requires for every voxel the same independent operation (transformation followed by interpolation).</p>
      <sec>
        <title>3.2.1. Pyramids</title>
        <p>It is common to start the registration process (1) using images that have lower complexity, to increase the chance of successful registration. To this end images are smoothed and optionally downsampled, the latter either using linear interpolation (resampling) or by subsampling without interpolation (shrinking). The Gaussian pyramid is by far the most common one for image registration, and the computation of this pyramid we target to accelerate. The Gaussian filter computes infinite impulse response convolution with an approximation of the Gaussian kernel <inline-formula><mml:math id="M10"><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (Deriche, <xref ref-type="bibr" rid="B12">1990</xref>). This filter smoothes the image in a single direction only, and is therefore subsequently called for each direction to perform full smoothing.</p>
        <p>The filter performs execution row-by-row for the direction <italic>x</italic> or column-by-column for the direction <italic>y</italic>, and similarly for direction <italic>z</italic>. All rows or columns can be processed independently, but columns can only be processed when all rows have finished. This execution model is therefore suitable for the GPU, by assigning each row or column to a different thread, which can then be executed in parallel. The column kernel is scheduled to start after the row kernel, using the OpenCL queues.</p>
        <p>To achieve better performance each thread uses the local GPU memory, which is fastest, but this introduces a limitation on the input image size. Current GPUs usually only have 16kB of local memory, and the algorithm allocates three floating point buffers the size of the row/column (input, output plus temporary buffer). This results in a maximum image size of 1365 pixels, and therefore our GPU implementation works only for images of maximum size [1365,1365] or [1365,1365,1365]. This limitation can be avoided by using other platforms with a larger local memory (e.g., Intel CPUs allow 32kB), or by changing the algorithm altogether (e.g., by direct convolution with a truncated Gaussian kernel).</p>
      </sec>
      <sec>
        <title>3.2.2. Resampling</title>
        <p>Resampling is the process of computing the value <italic>I<sub>M</sub></italic>(<italic><bold>T</bold></italic>(<italic><bold>x</bold></italic>)) for every voxel <italic><bold>x</bold></italic> inside some domain. Usually, the fixed image domain Ω<italic><sub>F</sub></italic> is chosen, meaning that the computational complexity is linearly dependent on the number of voxels in the fixed image. The procedure is simple: 1) loop over all voxels <italic><bold>x</bold></italic> ∈ Ω<italic><sub>F</sub></italic>, 2) compute its mapped position <italic><bold>y</bold></italic> = <italic><bold>T</bold></italic>(<italic><bold>x</bold></italic>), 3) obtain the moving image intensity <italic>I<sub>M</sub></italic>(<italic><bold>y</bold></italic>) by interpolation, since <italic><bold>y</bold></italic> is generally a non-voxel position, and 4) copy this value to the output image.</p>
        <p>Notice from above that the procedure is dependent on a choice of the interpolator and the transform. Several methods for interpolation exist, varying in quality and speed. Available implementations in <monospace>elastix</monospace> are nearest neighbor, linear and B-spline interpolation. There are also many flavors of transformations. The ones available in <monospace>elastix</monospace> in order of increasing flexibility, are the translation, the rigid, the similarity, the affine, the nonrigid B-spline and the nonrigid thin-plate-spline-like transformations, as well as arbitrary combinations of them by function composition, i.e., <italic><bold>T</bold></italic>(<italic><bold>x</bold></italic>) = <italic><bold>T</bold></italic><italic><sub>n</sub></italic>(… <italic><bold>T</bold></italic><sub>2</sub>(<italic><bold>T</bold></italic><sub>1</sub>(<italic><bold>x</bold></italic>))). The latter is frequently used in image registration, for example when a rigid or affine registration is performed prior to a nonrigid B-spline registration.</p>
        <p>In the ITK C++ implementation the flexibility to use any transformation in combination with any interpolator is achieved using classes and virtual methods. This flexibility introduces a major challenge when implementing a GPU version of the resampler. As mentioned earlier, OpenCL is a simplified C language specification, which does not provide a way of implementing virtuality on kernels, or the use of function pointers. In order to solve this issue, we propose to split the OpenCL kernel for the resampler in three groups of kernels, see also Figure <xref ref-type="fig" rid="F1">1</xref>:
<list list-type="simple"><list-item><p>Initialization: The first part is an OpenCL kernel responsible for the initialization of the deformation field buffer.</p></list-item><list-item><p>Transformation: This part consists of multiple OpenCL kernels each performing a single transformation <italic><bold>T</bold></italic><italic><sub>i</sub></italic> sequentially.</p></list-item><list-item><p>Interpolation: The last part is an OpenCL kernel performing the interpolation <italic>I<sub>M</sub></italic>(<italic><bold>T</bold></italic>(<italic><bold>x</bold></italic>)).</p></list-item></list></p>
        <fig id="F1" position="float">
          <label>Figure 1</label>
          <caption>
            <p><bold>Design of the resample filter on the GPU</bold>. We select a chunk of the output image, initialize it (red kernel), and for that chunk a series of transformations <italic><bold>T</bold></italic><italic><sub>n</sub></italic>(… <italic><bold>T</bold></italic><sub>2</sub>(<italic><bold>T</bold></italic><sub>1</sub>(<italic><bold>x</bold></italic>))) are computed and stored in the intermediate transformation field (green kernels). After these transformation kernels have finished, the input image is interpolated and the result is stored in the output image chunk (blue kernel). Then we proceed to the next chunk. The loops in purple are computed in parallel.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0001"/>
        </fig>
        <p>The OpenCL queueing mechanism utilizing OpenCL event lists, is employed for scheduling, to make sure that all kernels are executed successively. Within a kernel voxels are processed in parallel. A transformation field buffer is required to store the intermediate result of all sub-transformation kernels implementing <italic><bold>T</bold></italic><italic><sub>i</sub></italic>. The resample kernel code is constructed from these multiple kernels during instantiation of the resample filter. Construction of all kernels is performed on the host (the CPU) at runtime. All initialization, transformation and interpolation kernels are sequentially scheduled on the target device (GPU) using the event list functionality. All kernels are provided with their arguments (inputs), such as input image, resampling domain, etc. The thus generated code is compiled for the GPU at runtime, and then executed. NVidia has implemented a mechanism to cache the compiled GPU binaries, thereby avoiding the need to re-compile the code after the first run. To be able to process large 3D images that may not fit on the GPU memory entirely, we additionally implemented a mechanism to process the input data in chunks, see Figure <xref ref-type="fig" rid="F1">1</xref>. While the input (<italic>I<sub>M</sub></italic>) and output (<italic>I<sub>M</sub></italic>(<italic><bold>T</bold></italic>)) images are loaded resp. allocated entirely, only a relatively small amount of memory is then needed for the intermediate transformation field. This buffer is reused until the full image is resampled.</p>
        <p>GPU versions of all common transformations and interpolators were implemented, as well as arbitrary compositions of them.</p>
      </sec>
    </sec>
    <sec>
      <title>3.3. Diagnostic classification of AD</title>
      <p>The optimized registration procedure was validated with an experiment of classification of AD patients and healthy controls. The classification was based on two types of features, voxel-wise and region-wise features, which were extracted from structural MRI. These feature extraction approaches involve numerous image registrations steps, which were performed with both the accelerated version of <monospace>elastix</monospace> and the most recent release <monospace>elastix</monospace> v4.6. The classification performances were compared between the two versions, because then we can see in practice, in an application that makes heavy use of rigid and nonrigid registration, if and how much the results are affected by the acceleration. In this section the methods for the classification experiment are explained.</p>
      <sec>
        <title>3.3.1. Data</title>
        <p>Data from the ADNI<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref> database was used. The ADNI cohort used for our experiments is adopted from the study of Cuingnet et al. (<xref ref-type="bibr" rid="B11">2011</xref>), from which we selected the AD patient group and the normal elderly control group. The inclusion criteria for participants were defined in the ADNI GO protocol (<ext-link ext-link-type="uri" xlink:href="http://www.adni-info.org/Scientists/AboutADNI.aspx\#">www.adni-info.org/Scientists/AboutADNI.aspx\#</ext-link>). The patient group consisted of 137 patients (67 males, age = 76.0 ± 7.3 years, Mini Mental State Examination (MMSE) score = 23.2 ± 2.0), and the control group of 162 participants (76 males, age = 76.3 ± 5.4 years, MMSE = 29.2 ± 1.0). The participants were randomly split into two groups of the same size, a training set and a test set, while preserving the age and sex distribution (Cuingnet et al., <xref ref-type="bibr" rid="B11">2011</xref>). Structural MRI (T1w) data were acquired at 1.5T according to the ADNI acquisition protocol (Jack et al., <xref ref-type="bibr" rid="B20">2008</xref>).</p>
      </sec>
      <sec>
        <title>3.3.2. Image processing</title>
        <p>Tissue segmentations were obtained for GM, white matter (WM), and cerebrospinal fluid (CSF) using SPM8 (Statistical Parametric Mapping, London, UK). For estimation of intracranial volume, a brain mask was required for each subject. This brain mask was constructed using a multi-atlas segmentation approach using 30 atlases (see Section 3.3.3). We performed brain extraction (Smith, <xref ref-type="bibr" rid="B40">2002</xref>) on the T1w images associated with the 30 atlases (Hammers et al., <xref ref-type="bibr" rid="B17">2003</xref>; Gousias et al., <xref ref-type="bibr" rid="B16">2008</xref>), checked the brain extractions visually, and adjusted extraction parameters if needed. The extracted brains were transformed to each subject's image and the labels were fused, resulting in a brain mask for each subject.</p>
      </sec>
      <sec>
        <title>3.3.3. Image registration: template space and ROI labeling</title>
        <p>Voxel-wise features were extracted in a common template space (Ω<sub>Template</sub>, see Figure <xref ref-type="fig" rid="F2">2</xref>) based on the data of the training set. This common template space was constructed using a procedure that avoids bias toward any of the individual training images (Seghers et al., <xref ref-type="bibr" rid="B37">2004</xref>). In this approach, the coordinate transformations from the template space to the subject's image space (<bold>V</bold><italic><sub>i</sub></italic>: Ω<sub>Template</sub> → Ω<italic><sub>I<sub>i</sub></sub></italic>) were derived from pairwise image registrations. For computation of <bold>V</bold><italic><sub>i</sub></italic>, the image of an individual training subject (<italic>I<sub>i</sub></italic>) was registered to all other training images (<italic>I<sub>j</sub></italic>) using <italic>I<sub>i</sub></italic> as the fixed image. This resulted in a set of transformations <bold>W</bold><italic><sub>i,j</sub></italic> : Ω<sub><italic>I<sub>i</sub></italic></sub>→Ω<sub><italic>I<sub>j</sub></italic></sub>. By averaging the transformations <bold>W</bold><italic><sub>i, j</sub></italic>, the transformation <bold>U</bold><italic><sub>i</sub></italic> : Ω<sub><italic>I<sub>i</sub></italic></sub>→Ω<sub>Template</sub> was calculated:
<disp-formula id="E2"><label>(5)</label><mml:math id="M2"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>U</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
The transformation <bold>V</bold><italic><sub>i</sub></italic> was calculated as an inversion of <bold>U</bold><italic><sub>i</sub></italic>: <bold>V</bold><italic><sub>i</sub></italic> = <bold>U</bold><italic><sub>i</sub></italic><sup>−1</sup>. Note that the identity transformation <bold>W</bold><italic><sub>i,i</sub></italic> is also included in (5). The pairwise registrations were performed using a similarity (rigid plus isotropic scaling), affine, and nonrigid B-spline transformation model consecutively. The nonrigid B-spline registration used a three-level multi-resolution framework with isotropic control-point spacings of 24, 12, and 6 mm in the three resolutions respectively.</p>
        <fig id="F2" position="float">
          <label>Figure 2</label>
          <caption>
            <p><bold>Image spaces defined within the ADNI structural MRI data: image space (Ω<italic><sub>I</sub></italic>) and the template space (Ω<sub>Template</sub>)</bold>. Another image space (Ω<sub>Atlas</sub>) is defined for the 30 atlas images. Transformations between the image spaces are indicated by <bold>S</bold>, <bold>U</bold>, <bold>V</bold>, and <bold>W</bold>. The arrows are pointing from the fixed to the moving domain. Different subjects are represented by <italic>i</italic> and <italic>j</italic>, the different atlas images are represented by <italic>k</italic>. From all <italic>I<sub>i</sub></italic>, a template space image (<overline><italic>I</italic></overline>) is calculated (Section 3.3.3).</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0002"/>
        </fig>
        <p>A template image was built using: <inline-formula><mml:math id="M11"><mml:mrow><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>V</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> with <italic>I<sub>i</sub></italic>(<bold>V</bold><italic><sub>i</sub></italic>) representing the deformed individual training images. The test images were not included in the construction of Ω<sub>Template</sub>. For the test images, the transformation to template space (<bold>V</bold><italic><sub>i</sub></italic>) was obtained using the same procedure described above: using pairwise registration of each image with all training images, followed by averaging and inversion. Brain masks and tissue maps were transformed to template space using <bold>V</bold><italic><sub>i</sub></italic>.</p>
        <p>For extraction of the region-wise features, a set of 72 brain ROIs was defined for each subject individually in subject space (Ω<italic><sub>I</sub></italic>) using a multi-atlas segmentation procedure (Figure <xref ref-type="fig" rid="F3">3</xref>). Thirty labeled T1w images containing 83 ROIs each (Hammers et al., <xref ref-type="bibr" rid="B17">2003</xref>; Gousias et al., <xref ref-type="bibr" rid="B16">2008</xref>) were used as atlas images. The atlas images were registered to the subject's T1w image using a rigid, affine, and nonrigid B-spline transformation model consecutively resulting in transformation <bold>S</bold><italic><sub>i,k</sub></italic> : Ω<italic><sub>I<sub>i</sub></sub></italic> → Ω<sub>Atlas<italic><sub>k</sub></italic></sub>. Registration was performed by maximization of mutual information within dilated brain masks (Smith, <xref ref-type="bibr" rid="B40">2002</xref>). For initialization, the dilated brain masks were rigidly registered. For nonrigid registration, the same multi-resolution settings were used as in the template space construction. For this step, the subjects' images were corrected for inhomogeneities (Tustison et al., <xref ref-type="bibr" rid="B42">2010</xref>). Labels were propagated to Ω<sub><italic>I<sub>i</sub></italic></sub> using <bold>S</bold><italic><sub>i,k</sub></italic> and fused using a majority voting algorithm (Heckemann et al., <xref ref-type="bibr" rid="B18">2006</xref>). The brain stem, corpus callosum, third ventricle, lateral ventricles, cerebellum, and substantia nigra were excluded.</p>
        <fig id="F3" position="float">
          <label>Figure 3</label>
          <caption>
            <p><bold>The region labeling consisting of 72 ROIs in the brain</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0003"/>
        </fig>
      </sec>
      <sec>
        <title>3.3.4. Classification</title>
        <p>Linear SVM classification was used with the LibSVM software package (Chang and Lin, <xref ref-type="bibr" rid="B10">2011</xref>). Classification performance was assessed on the separate test set and quantified by the area under the receiver-operator characteristic curve (AUC). The SVM C-parameter was optimized using gridsearch on the training set.</p>
        <p>Voxel-wise features were defined as GM probabilistic segmentations in the template space (Ω<sub>Template</sub>) (Klöppel et al., <xref ref-type="bibr" rid="B25">2008</xref>; Cuingnet et al., <xref ref-type="bibr" rid="B11">2011</xref>). A modulation step was performed, i.e., multiplication by the Jacobian determinant of the deformation field (Figure <xref ref-type="fig" rid="F2">2</xref>, transformation <bold>V</bold><italic><sub>i</sub></italic>), to take account of compression and expansion (Ashburner and Friston, <xref ref-type="bibr" rid="B4">2000</xref>). This modulation step ensures that the overall GM volume was not changed by the transformation to template space.</p>
        <p>The region-wise features were calculated in subject space (Ω<italic><sub>I</sub></italic>) as the GM volume in each ROI obtained from the probabilistic GM maps (Magnin et al., <xref ref-type="bibr" rid="B28">2009</xref>; Cuingnet et al., <xref ref-type="bibr" rid="B11">2011</xref>). To correct for head size, these features were divided by intracranial volume. All features were normalized to have zero mean and unit variance.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4. Experiments and results</title>
    <sec>
      <title>4.1. Overview</title>
      <p>For the evaluation we compare the accelerated implementations with the original implementations. Both runtime performance and accuracy are investigated.</p>
      <p>To evaluate performance we compare the runtime per iteration between both algorithms, <italic>t</italic><sub>old</sub> and <italic>t</italic><sub>new</sub>. The speedup factor is defined as <graphic xlink:href="fninf-07-00050-i0007.jpg" position="float"/> = <italic>t</italic><sub>old</sub> / <italic>t</italic><sub>new</sub>. The speedup will depend on the number of threads <italic>T</italic> that are used for parallelization. The parallelization efficiency is a measure expressing how much a program is accelerated compared to an ideal speedup equal to the number of threads, i.e., ℰ = <graphic xlink:href="fninf-07-00050-i0007.jpg" position="float"/> / <italic>T</italic>.</p>
      <p>To evaluate accuracy we use a combination of measures, to make sure that the accelerated registration still returns similar results as the original. GPU pyramid and resampler results by OpenCL are compared with their original CPU version as a baseline, using the normalized root mean square error (nRMSE) as a measure of accuracy:
<disp-formula id="E3"><label>(6)</label><mml:math id="M3"><mml:mrow><mml:mtext>nRMSE</mml:mtext><mml:mo>=</mml:mo><mml:mtext>​​</mml:mtext><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>CPU</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mtext>​</mml:mtext><mml:mo>−</mml:mo><mml:mtext>​</mml:mtext><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>GPU</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>CPU</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
All timings were measured on a second run of the program, where the pre-compiled GPU kernel is loaded from cache. CPU optimizations were evaluated using the Alzheimer classification application to compare original with optimized methods, see Section 4.4.</p>
      <p>While in our automatic testing environment (using CTest, part of the CMake package, <ext-link ext-link-type="uri" xlink:href="http://www.cmake.org">www.cmake.org</ext-link>) we perform nightly evaluation on both 2D and 3D data, in this paper we only report 3D results. All timing experiments were run on a linux system, detailed in Table <xref ref-type="table" rid="T1">1</xref>. This systems contains an NVidia GTX 480 graphical card (market launch March 2010), while currently (August 2013) the GTX 780 generation is available. All registrations for the diagnostic classification of AD were run on a cluster of linux systems.</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p><bold>Details of the system used for the timing tests</bold>.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">OS</td>
              <td align="left" rowspan="1" colspan="1">Linux Ubuntu 12.04.2 LTS, 64 bit</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">CPU</td>
              <td align="left" rowspan="1" colspan="1">Intel Xeon E5620, 8 cores @ 2.4 GHz</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GPU</td>
              <td align="left" rowspan="1" colspan="1">NVidia Geforce GTX 480</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">compiler</td>
              <td align="left" rowspan="1" colspan="1">gcc 4.6.3</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">OpenCL</td>
              <td align="left" rowspan="1" colspan="1">NVIDIA UNIX <monospace>x86_64</monospace> Kernel Module 290.10</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>4.2. Parallelization and optimization on the CPU</title>
      <p>CPU accelerations are evaluated by comparing the baseline algorithms with accelerated version, using various numbers of threads (<italic>T</italic> ∈ {1, 2, 3, 4, 8, 16}). We show registration results for the B-spline transformation, using a first order B-spline and a linear interpolator for the baseline and accelerated algorithms, respectively, with 3 resolutions and 1000 iterations per resolution. The B-spline grid is refined from the first to the last resolution, so that a progressively larger number of parameters <italic>N</italic> is used. In the experiments we inspect the influence of the number of samples |<inline-formula><mml:math id="M12"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic>| (2000 vs. 20,000), the B-spline grid spacing in the last resolution (10 mm vs. 5 mm, resulting in <italic>N</italic> = 2·10<sup>3</sup>, 9·10<sup>3</sup>, 5·10<sup>4</sup> vs. <italic>N</italic> = 9·10<sup>3</sup>, 5·10<sup>5</sup>, 3·10<sup>5</sup> parameters at each resolution, respectively), and the cost function (MSD vs. NC vs. MI).</p>
      <p>Figure <xref ref-type="fig" rid="F4">4</xref> displays the performance results for MI, 2000 samples, <italic>N</italic> = 5·10<sup>4</sup>, showing the reduction in runtime per iteration, the speedup factor and the parallelization efficiency. It can be seen that using more threads steadily increases the performance, until <italic>T</italic> matches the number of CPU cores. Further increasing parallelization decreases performance. The efficiency plot shows that although the performance increases with increasing <italic>T</italic>, the benefits are gradually diminished. An efficiency of 60–70% (Figure <xref ref-type="fig" rid="F4">4C</xref>) was obtained for 8 threads, which is influenced by the overhead of thread creation and destruction and by the fact that derivative joining (aggregating <italic><bold>g</bold><sup>t</sup><sub>k</sub></italic> to <italic><bold>g</bold><sub>k</sub></italic>) is not free of cost. Comparing the columns “b” and “1” we can see that the general optimizations described in Section 3.1 already reduce runtime from 27 ms to 18 ms per iteration (R<sub>2</sub>), showing the overall benefits of these modifications. Separate tests used during development showed for example that computing ∂ <italic>I<sub>M</sub></italic> / ∂ <italic><bold>x</bold></italic> using the linear interpolator instead of a first order B-spline was about 10–15x faster stand-alone, and using the new scan line iterator from ITKv4 when computing <italic><bold>T</bold></italic>(<italic><bold>x</bold></italic>) for the B-spline transform was about 15% faster. Overall, the image registration was accelerated by a factor of 4–5x, when using 8 threads on our 8-core machine.</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p><bold>Registration performance as a function of the number of threads</bold>. R<italic><sub>i</sub></italic> denotes the resolution number, b refers to the baseline un-accelerated algorithm, and the numbers 1–16 refer to the number of threads used when running the parallel accelerated algorithm. The blue line shows ideal linear speedup. Results are shown for MI, <italic>N</italic> = 5·10<sup>4</sup>, |<inline-formula><mml:math id="M13"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic>| = 2000. <bold>(A)</bold> Shows the runtime per iteration, <bold>(B)</bold> the speedup factor <graphic xlink:href="fninf-07-00050-i0007"/>, and <bold>(C)</bold> the efficiency <bold>ℰ</bold>.</p>
        </caption>
        <graphic xlink:href="fninf-07-00050-g0004"/>
      </fig>
      <p>Figure <xref ref-type="fig" rid="F5">5</xref> shows the experimental results when varying the number of samples |<inline-formula><mml:math id="M14"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic>|, parameters length <italic>N</italic> and cost function type. The speedup remains much closer to the theoretical limit when using 20,000 samples instead of 2000 (Figure <xref ref-type="fig" rid="F5">5A</xref>), although of course the former is 10 times as slow. This may be attributed to the fact that for many samples the overhead of thread creation and destruction is relatively small wrt computation time. In our current design we employ ITK's threading mechanism, which may be suboptimal for short tasks. Figure <xref ref-type="fig" rid="F5">5B</xref> shows that speedup decreases when the number of parameters is large (R<sub>2</sub>). In this case vector arithmetic [joining the derivatives <italic><bold>g</bold><sup>t</sup><sub>k</sub></italic> and performing the optimization step (2)] is starting to take a larger portion of an iteration. According to the Callgrind profiler about 15% of the time was spend for derivative joining and an additional ~7% for threading related initialization, and ~3% for the optimization step. In a separate test program we tested the performance of these operations comparing three versions: single threaded, multi-threaded using ITK and multi-threaded using OpenMP. We found that multi-threading was unsuccessful for the optimization step, only deteriorating performance, and successful for derivative joining, mostly so when using OpenMP. We therefore opted to only use multi-threading with OpenMP for the derivative joining. Finally, Figure <xref ref-type="fig" rid="F5">5C</xref> shows that all metrics almost equally well benefit from parallelization. Overall, the accelerations reduced the registration runtimes from 52, 57, and 80s to 10, 12, and 17 s for MSD, NC and MI, respectively (|<inline-formula><mml:math id="M15"><mml:mover accent="true"><mml:mi>Ω</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></inline-formula><italic><sub>F</sub></italic>| = 2000, <italic>N</italic> = 5·10<sup>4</sup>), excluding optimization step size computation (~22s) of the ASGD optimizer.</p>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p><bold>Registration performance as a function of the number of threads</bold>. R<italic><sub>i</sub></italic> denotes the resolution number, b refers to the baseline un-accelerated algorithm, and the numbers 1–16 refer to the number of threads used when running the parallel accelerated algorithm. The blue line shows ideal linear speedup. Varying the number of samples <bold>(A)</bold>, the number of registration parameters <bold>(B)</bold>, and the cost function <bold>(C)</bold>.</p>
        </caption>
        <graphic xlink:href="fninf-07-00050-g0005"/>
      </fig>
    </sec>
    <sec>
      <title>4.3. Parallelization on the GPU</title>
      <sec>
        <title>4.3.1. Gaussian image pyramids</title>
        <p>For testing the Gaussian pyramid accelerations we chose default scaling and smoothing schedules using 4 resolutions: images were downsized by a factor of 8, 4, 2, and 1 and smoothed with a Gaussian kernel with σ = 4, 2, 1 and 0 for the four resolutions, respectively. The results are shown in Table <xref ref-type="table" rid="T2">2</xref>.</p>
        <table-wrap id="T2" position="float">
          <label>Table 2</label>
          <caption>
            <p><bold>Results of the multi-resolution pyramid filter</bold>.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">
                  <bold>Image size</bold>
                </th>
                <th align="left" rowspan="1" colspan="1">
                  <bold>Resize</bold>
                </th>
                <th align="left" rowspan="1" colspan="1">
                  <italic>t</italic>
                  <bold>
                    <sub>CPU</sub>
                  </bold>
                </th>
                <th align="left" rowspan="1" colspan="1">
                  <italic>t</italic>
                  <bold>
                    <sub>GPU</sub>
                  </bold>
                </th>
                <th align="left" rowspan="1" colspan="1">
                  <graphic xlink:href="fninf-07-00050-i0007"/>
                </th>
                <th align="left" rowspan="1" colspan="1">
                  <bold>nRMSE</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">100 x 100 x 100</td>
                <td align="left" rowspan="1" colspan="1">Off</td>
                <td align="left" rowspan="1" colspan="1">0.05</td>
                <td align="left" rowspan="1" colspan="1">0.02</td>
                <td align="left" rowspan="1" colspan="1">2.3</td>
                <td align="left" rowspan="1" colspan="1">0.55 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Resampler</td>
                <td align="left" rowspan="1" colspan="1">0.06</td>
                <td align="left" rowspan="1" colspan="1">0.03</td>
                <td align="left" rowspan="1" colspan="1">1.9</td>
                <td align="left" rowspan="1" colspan="1">0.52 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Shrinker</td>
                <td align="left" rowspan="1" colspan="1">0.04</td>
                <td align="left" rowspan="1" colspan="1">0.02</td>
                <td align="left" rowspan="1" colspan="1">2.0</td>
                <td align="left" rowspan="1" colspan="1">0.55 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">256 x 256 x 256</td>
                <td align="left" rowspan="1" colspan="1">Off</td>
                <td align="left" rowspan="1" colspan="1">0.84</td>
                <td align="left" rowspan="1" colspan="1">0.33</td>
                <td align="left" rowspan="1" colspan="1">2.5</td>
                <td align="left" rowspan="1" colspan="1">0.56 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Resampler</td>
                <td align="left" rowspan="1" colspan="1">0.98</td>
                <td align="left" rowspan="1" colspan="1">0.58</td>
                <td align="left" rowspan="1" colspan="1">1.7</td>
                <td align="left" rowspan="1" colspan="1">0.52 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Shrinker</td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.31</td>
                <td align="left" rowspan="1" colspan="1">2.8</td>
                <td align="left" rowspan="1" colspan="1">0.56 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">512 x 512 x 256</td>
                <td align="left" rowspan="1" colspan="1">Off</td>
                <td align="left" rowspan="1" colspan="1">4.07</td>
                <td align="left" rowspan="1" colspan="1">2.51</td>
                <td align="left" rowspan="1" colspan="1">1.6</td>
                <td align="left" rowspan="1" colspan="1">0.57 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Resampler</td>
                <td align="left" rowspan="1" colspan="1">4.68</td>
                <td align="left" rowspan="1" colspan="1">2.19</td>
                <td align="left" rowspan="1" colspan="1">2.1</td>
                <td align="left" rowspan="1" colspan="1">0.53 × 10<sup>−6</sup></td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Shrinker</td>
                <td align="left" rowspan="1" colspan="1">4.07</td>
                <td align="left" rowspan="1" colspan="1">1.58</td>
                <td align="left" rowspan="1" colspan="1">2.6</td>
                <td align="left" rowspan="1" colspan="1">0.57 × 10<sup>−6</sup></td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p>Timings shown are for all four levels in total.</p>
          </table-wrap-foot>
        </table-wrap>
        <p>The imprecision as measured by the nRMSE was quite small (&lt;10<sup>−6</sup>), meaning that the the CPU and GPU returns almost exactly identical smoothed images. Small speedup factors of about two were measured, which may be an indication that the specific Gaussian smoothing algorithm is not very well suited for acceleration on the GPU.</p>
      </sec>
      <sec>
        <title>4.3.2. Image resampling</title>
        <p>We tested the GPU resampling filter with different combinations of interpolators and transformations. For the B-spline interpolator and B-spline transform we have used third order splines. For brief notation we introduce the symbols <italic>T</italic>, <italic>R</italic>, <italic>S</italic>, <italic>A</italic> and <italic>B</italic> for the translation, rigid, similarity (rigid + isotropic scaling), affine and B-spline transformation, respectively. Detailed results are shown in Table <xref ref-type="table" rid="T3">3</xref> and Figure <xref ref-type="fig" rid="F6">6</xref>.</p>
        <table-wrap id="T3" position="float">
          <label>Table 3</label>
          <caption>
            <p><bold>Results of the resampling filter</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-i0001"/>
          <table-wrap-foot>
            <p>Timings are shown in seconds. sz denotes image size. First, second and third number in each column denote the result for the nearest neighbor (NN), linear (L) and B-spline (B) interpolator, respectively. <bold>T</bold><sub>1</sub> − <bold>T</bold><sub>5</sub> are the composite transforms T, A, B, A ◦ B and T◦A◦B◦R◦S, respectively.</p>
          </table-wrap-foot>
        </table-wrap>
        <fig id="F6" position="float">
          <label>Figure 6</label>
          <caption>
            <p><bold>Speedup factors</bold><graphic xlink:href="fninf-07-00050-i0007"/><bold>for the GPU resampling framework</bold>. Results are shown for the nearest neighbor <bold>(A)</bold>, the linear <bold>(B)</bold>, and the 3rd order B-spline interpolator <bold>(C)</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0006"/>
        </fig>
        <p>The GPU results for resampling were very close in terms of nRMSE to the output produced by the ITK CPU code. Only for the nearest neighbor interpolator in combination with the affine transformation higher errors are reported. This difference is due to floating point differences between CPU and GPU, sometimes leading to different rounding behavior. Example results are shown in Figure <xref ref-type="fig" rid="F7">7</xref>.</p>
        <fig id="F7" position="float">
          <label>Figure 7</label>
          <caption>
            <p><bold>Resample example for the highest nRMSE of Table <xref ref-type="table" rid="T3">3</xref> (NN, A, 100<sup>3</sup>)</bold>. Differences are due to 79 isolated voxels in the range [−743, 502]. Shown are the result for the CPU <bold>(A)</bold>, the GPU <bold>(B)</bold>, and their difference <bold>(C)</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0007"/>
        </fig>
        <p>Figure <xref ref-type="fig" rid="F6">6</xref> shows that linear transformations are accelerated less well than nonlinear transformations. This can be explained by (i) the small runtime of the linear transformations on the CPU, which is due to the CPU resampler implementing a highly optimized path for these cases, not possible for the GPU, and (ii) the lower computational complexity of these transformations (commonly more complex operations give more speedup on the GPU since GPU overhead is relatively small in those cases). Note that the B-spline interpolator yields higher speedup factors than the nearest neighbor and linear interpolator, for linear transformations (15–20 vs. 1–3), but lower speedup factors for nonrigid transformations (35–45 vs. 45–65). We remark that the reported speedup factors are a mixture of the speedup factors for the transformation and the interpolation step, related to the time spent in each step. For lower computationally complex transformations, the B-spline interpolator speedup will mostly determine the overall speedup, while for the more complex transformations both speedup factors determine the overall speedup. As a final observation, note the trend that more speedup is obtained for larger images, likely due to a better occupancy of the GPU combined with the copying overhead being less prominent in those cases.</p>
        <p>Summarizing, speedups were obtained in the range 15–60x using more complex transformations, with no degradation for setups that were already very fast on the CPU. Using a B-spline interpolator and transform on a larger image, a common use-case, the execution time was 67 s on an 8 core CPU, while with a GPU this was reduced to &lt;1 s.</p>
      </sec>
    </sec>
    <sec>
      <title>4.4. Diagnostic classification of AD</title>
      <sec>
        <title>4.4.1. Registrations</title>
        <p>To evaluate the registration results in the AD classification experiment, we compared the deformation fields obtained with the original and accelerated version of <monospace>elastix</monospace>. The RMSE between the two deformation fields was calculated. In the voxel-wise approach all 299 subjects' images were registered to the images of the 150 training subjects, which resulted in a mean ± std RMSE of the deformation field of 0.52 ± 0.46 mm (range: 0.0001–20.01 mm). In the region-wise approach 30 atlas T1w images were registered to all subjects' T1w scans. The RMSE was calculated in the same brain mask that was used for registration, which resulted in a RMSE of 0.75 ± 0.45 mm (range: 0.14–8.42 mm). The voxel sizes of the image is 0.95 × 0.95 × 1.20 mm<sup>3</sup>, so the average RMSE is smaller than the voxel dimension. Figure <xref ref-type="fig" rid="F8">8</xref> shows an example of the registration with median RMSE for the voxel-wise approach. Registration time for the described setup reduced from ~13.1 to ~3.6 min per patient, of which optimization step size computation took 1.2 min.</p>
        <fig id="F8" position="float">
          <label>Figure 8</label>
          <caption>
            <p><bold>Registration result for the median case of the voxel-wise method with a RMSE of 0.419 mm</bold>. The fixed T1w image, the transformed moving T1w image registered with the original and the accelerated version of <monospace>elastix</monospace> and the difference between the two resulting images are shown.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0008"/>
        </fig>
      </sec>
      <sec>
        <title>4.4.2. Features</title>
        <p>For the region-labeling, a high overlap was found between the ROIs using the two versions of the registration methods, resulting in a Dice coefficient of 0.97 ± 0.02 (mean ± std) over all ROIs in all subjects. Figure <xref ref-type="fig" rid="F9">9</xref> shows a Bland-Altman plot for the region-wise features. The difference in the region volumes between the original and accelerated versions of the registration methods is very small compared to the mean.</p>
        <fig id="F9" position="float">
          <label>Figure 9</label>
          <caption>
            <p><bold>Bland-Altman plot of the region-wise features for the original and accelerated versions of <monospace>elastix</monospace></bold>. The features represent the GM volume per brain ROI divided by the intracranial volume. The average features were grouped in bins of width 0.001, for each bin a boxplot is shown. 72 features for 299 subjects are included. The mean difference between the features is 1.0 · 10<sup>−7</sup> (CI: −5.2· 10<sup>−5</sup> ; 5.2· 10<sup>−7</sup>), mean and CI are indicated with the striped and dotted lined in the figure.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0009"/>
        </fig>
        <p>The voxel-wise features cannot be compared directly as they are calculated in separate template spaces. Figure <xref ref-type="fig" rid="F10">10</xref> shows the template spaces constructed with the original and accelerated version of the registration method. Although the template spaces show no visually observable differences, they do slightly differ (Figure <xref ref-type="fig" rid="F10">10C</xref>). The magnitude of the difference is much smaller than the magnitude of the template images. There seems to be a slight shift in the z-direction between the template spaces calculated with the two <monospace>elastix</monospace> versions.</p>
        <fig id="F10" position="float">
          <label>Figure 10</label>
          <caption>
            <p><bold>Template space for the voxel-wise features constructed with the original version of <monospace>elastix</monospace> (top row) and the accelerated version (middle row)</bold>. The difference between the two is shown at the <bold>bottom</bold> row.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0010"/>
        </fig>
      </sec>
      <sec>
        <title>4.4.3. Classification performance</title>
        <p>Figure <xref ref-type="fig" rid="F11">11</xref> shows the receiver-operator characteristic (ROC) curves for the classifications on the test set. The area under this curve (AUC) is a measure for classification performance. For the voxel-wise classifications, the features calculated with the original version of the registration software gave an AUC of 88.4%. The accelerated version resulted in a very similar AUC: 88.3%. For all test subjects (<italic>n</italic> = 149), the predicted labels were the same using both registration methods. For the region-wise method, performance was slighly better than for the voxel-wise method. Here, the original version resulted in a slightly higher AUC than the accelerated version (90.3% vs. 89.6%). Only three test subjects had a different prediction. To assess the difference between the two registrations methods, McNemar's binomial exact test was performed. For both voxel- and region-wise methods, the tests showed no significant difference (<italic>p</italic> = 1 in both cases).</p>
        <fig id="F11" position="float">
          <label>Figure 11</label>
          <caption>
            <p><bold>Receiver-operator characteristic (ROC) curves for the classification based on voxel-wise (red, blue) and region-wise features (magenta, green) calculated with the original and accelerated versions of <monospace>elastix</monospace></bold>. Between brackets, the area under the curve (AUC) is given as performance measure.</p>
          </caption>
          <graphic xlink:href="fninf-07-00050-g0011"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>5. Discussion and conclusion</title>
    <p>In this paper we present a number of CPU and GPU optimizations for the image registration package <monospace>elastix</monospace>. The accelerated version of <monospace>elastix</monospace> was compared with the original in a study to automatically discriminate between AD patients and age- and gender-matched cognitively normal controls, based on T1w MRI.</p>
    <p>Parallelization was used at several places of the image registration framework, exploiting the fork-and-join thread model of ITK, i.e., for computation of the cost function derivatives and for joining the results of the several threads. In addition, throughout the registration framework optimizations were performed, for example exploiting the sparseness of the derivative of the B-spline transformation, resulting in an overall increase in performance.</p>
    <p>Compared to the original framework the optimizations only (no parallelization) accelerated image registration by 40–50%, see Figures <xref ref-type="fig" rid="F4">4</xref>, <xref ref-type="fig" rid="F5">5</xref>. Parallelization increases performance until the used number of threads reaches the number of CPU cores. We obtained an overall speedup of 4–5x, using 8 threads on an 8 core system. All registration similarity metrics almost equally well benefit from parallelization.</p>
    <p>In addition to accelerating the core registration algorithm using the CPU, the GPU was used to accelerate two potentially computationally intensive components that are part of the algorithm. In this paper we accelerated computation of the multi-resolution Gaussian pyramid and the final resampling step, using OpenCL. A generic OpenCL framework was first developed, based on the existing ITKv4 GPU acceleration design. To this end a large part of the OpenCL specification was wrapped in ITK classes, following the OpenCL class diagram and inspired by current ITKv4 design. This generic architecture and close integration with ITK will ease adoption of OpenCL for general image processing tasks, not only for image registration. Subsequently, we designed a pipeline for pyramid computation and resampling, exploiting the design, notably the OpenCL queueing and synchronization mechanisms. The developed code is generic and allows extension to other geometric transformations and interpolators. The use of OpenCL furthermore enables targeting of most accelerator devices (GPU, FPGA) available today.</p>
    <p>For the GPU optimizations speedup factors of ~2x were achieved for the image pyramids and 15–60x for the resampling, on larger images, using an NVidia Geforce GTX 480. For resampling, the increase in performance was negligible when using simple transformations (translation, affine) in combination with simple interpolators (nearest neighbor, linear), since in these cases the CPU computation was already quite fast (&lt;1 s). For more complex operations (B-spline interpolator and/or B-spline transformation) the GPU is very beneficial.</p>
    <p>To compare registration accuracy between original and accelerated versions of <monospace>elastix</monospace>, ~54k T1w image registrations have been performed with each version in the setting of an AD classification experiment. Registration results were similar as shown by visual inspection of the median result and the RMSE of the deformations field: 0.521 ± 0.460 mm (voxel-wise) and 0.749 ± 0.446 mm (region-wise). In addition, the classification features calculated with the two <monospace>elastix</monospace> versions were very similar. The differences in features between the two versions of the registration software were much smaller than the features themselves: for the voxel-wise approach the template spaces looked very similar, and for the region-wise approach the Dice overlap of the ROIs was very high and the differences between the GM volumes were relatively small. This resulted in a high classification performance, which was not significantly different between the two <monospace>elastix</monospace> versions.</p>
    <p>Remaining differences between original and accelerated algorithms are attributed to a combination of algorithmic changes and hardware effects. For example, where in the original version the sample contributions (see Equation (3)) are directly accumulated in a single derivative, in the parallel version multiple derivatives are created, which are later joined to a single derivative. This changes the order and amount of arithmetic operations, and depending on machine precision this will lead to slightly different results. In addition, since image registration is an iterative process, small differences will be propagated until the end. In general, all implementation choices influence the final result. In the neuroimaging application the differences in the features (GM volumes) and classification results provide information on the impact of these imprecisions on the final result, which appears to be small.</p>
    <p>Fast registration algorithms have most impact when used in a time-critical setting. An example would be the diagnostic classification of a single patient on a clinical workstation, performed by a neuro-radiologist. Generally, interactive speed is desired in such a user setting. The multiple registrations needed for the classification would be performed in parallel on a computing cluster, as was done in this work, which means that total classification time is limited by the runtime of a single registration. An example from outside the image-guided therapeutic domain would be (near) realtime motion compensation for radiation therapy. For research, fast registration enables testing of a wider range of algorithm parameters, or enables testing on large groups of patients within reasonable time. Given the general nature of similarity based image registration the results are naturally applicable to a wide range of image registration problems.</p>
    <p>There are several areas in which our work can be improved and extended. For the CPU the total efficiency was 60–70% using 8 threads. When thread overhead is small compared to the computation, a much larger efficiency was obtained, see Figure <xref ref-type="fig" rid="F5">5A</xref>. This suggests that for short iteration times (5–6 ms, due to heavy stochastic subsampling during the optimization) the thread overhead is not negligible. The implementation of thread pools, that do not create and destruct threads every iteration, may mitigate this problem. Registration problems which need a high number of transformation parameters (large images and/or fine deformations) obtained only a small overall speedup (&lt;3). In the current implementation the algorithmic steps related to vector arithmetics were found to be difficult to parallelize, and better methods have to be found. Further accelerations may be found by performing a comprehensive complexity analysis for each stage of the registration procedure, identifying the theoretical data transfer and computational requirements. Moreover, the use of more advanced profiling tools, such as the Intel VTune Amplifier, could be investigated. For the GPU we consider the use of pre-compiled binaries to completely remove compilation overhead at runtime. This functionally is available since the OpenCL 1.2 standard. Offloading of more parts of the registration algorithm to the GPU can also be considered. Considerable estimation time is still required by the ASGD optimizer (Klein et al., <xref ref-type="bibr" rid="B22">2009b</xref>), which we addressed in separate work (Qiao et al., <xref ref-type="bibr" rid="B33">2014</xref>).</p>
    <p>The OpenCL implementation was additionally tested with an AMD Radeon HD 7900 card, and we can confirm portability of the solution. The AMD OpenCL compiler currently does not support caching of compiled binaries, making a timing comparison difficult. The CPU accelerations will be made available as open source in the next release of <monospace>elastix</monospace>. The GPU extensions are already incorporated in the <monospace>elastix</monospace> testing framework, but are not yet fully integrated in the <monospace>elastix</monospace> pyramids and resampler.</p>
    <p>In conclusion, the proposed parallelization and optimizations substantially improve the runtime performance of image registration as implemented in the publicly available registration software <monospace>elastix</monospace>. This will facilitate medical practitioners and neuroimaging researchers, who commonly rely on image registration to label brain data, classify patients, compare between subjects or image sequences and to perform patient followup. It was shown in a large experiment on public data of patients with Alzheimer's disease that the registration results of the accelerated version are very close to the original. This work therefore makes substantially accelerated image registration accessible to a wide audience.</p>
    <sec>
      <title>Conflict of interest statement</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <p>Data collection and sharing for this project was funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: Alzheimer's Association; Alzheimer's Drug Discovery Foundation; BioClinica, Inc.; Biogen Idec Inc.; Bristol-Myers Squibb Company; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; GE Healthcare; Innogenetics, N.V.; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC.; Johnson &amp; Johnson Pharmaceutical Research &amp; Development LLC.; Medpace, Inc.; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Synarc Inc.; and Takeda Pharmaceutical Company. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are Rev November 7, 2012 facilitated by the Foundation for the National Institutes of Health (<ext-link ext-link-type="uri" xlink:href="http://www.fnih.org">www.fnih.org</ext-link>). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer's Disease Cooperative Study at the University of California, San Diego. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of California, Los Angeles. This research was also supported by NIH grants P30 AG010129 and K01 AG030514.</p>
  </ack>
  <fn-group>
    <fn id="fn0001">
      <p><sup>1</sup>The ADNI was launched in 2003 by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, the Food and Drug Administration, private pharmaceutical companies and non-profit organizations, as a $60 million, 5-year public-private partnership. The primary goal of ADNI has been to test whether serial MRI, positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early AD.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Funding</title>
    <p>This research was funded by the Netherlands Organization for Scientific Research (NWO), grants NWO VENI 639.021.919 and 639.021.124 and NWO NRG-2010.02, and by an Erasmus MC grant on “Advanced MR neuroimaging in presenile dementia.”</p>
  </sec>
  <sec sec-type="supplementary material" id="s5">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="http://www.frontiersin.org/journal/10.3389/fninf.2013.00050/abstract">http://www.frontiersin.org/journal/10.3389/fninf.2013.00050/abstract</ext-link></p>
    <supplementary-material content-type="local-data">
      <media xlink:href="Presentation1.PDF">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>D.</given-names></name><name><surname>Pierpaoli</surname><given-names>C.</given-names></name><name><surname>Basser</surname><given-names>P.</given-names></name><name><surname>Gee</surname><given-names>J.</given-names></name></person-group> (<year>2001</year>). <article-title>Spatial transformation of diffusion tensor magnetic resonance images</article-title>. <source>IEEE Trans. Med. Imag</source>. <volume>20</volume>, <fpage>1131</fpage>–<lpage>1139</lpage>
<pub-id pub-id-type="doi">10.1109/42.963816</pub-id><?supplied-pmid 11700739?><pub-id pub-id-type="pmid">11700739</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>Alzheimer's Association.</collab></person-group> (<year>2012</year>). <article-title>2012 Alzheimer's disease facts and figures</article-title>. <source>Alzheimers Dement</source>. <volume>8</volume>, <fpage>113</fpage>–<lpage>168</lpage>
<pub-id pub-id-type="doi">10.1016/j.jalz.2012.02.001</pub-id><?supplied-pmid 22404854?><pub-id pub-id-type="pmid">22404854</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>A fast diffeomorphic image registration algorithm</article-title>. <source>Neuroimage</source>
<volume>38</volume>, <fpage>95</fpage>–<lpage>113</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.07.007</pub-id><?supplied-pmid 17761438?><pub-id pub-id-type="pmid">17761438</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Friston</surname><given-names>K.</given-names></name></person-group> (<year>2000</year>). <article-title>Voxel-based morphometry–the methods</article-title>. <source>Neuroimage</source>
<volume>11</volume>, <fpage>805</fpage>–<lpage>821</lpage>
<pub-id pub-id-type="doi">10.1006/nimg.2000.0582</pub-id><?supplied-pmid 10860804?><pub-id pub-id-type="pmid">10860804</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Friston</surname><given-names>K.</given-names></name></person-group> (<year>2005</year>). <article-title>Unified segmentation</article-title>. <source>Neuroimage</source>
<volume>26</volume>, <fpage>839</fpage>–<lpage>851</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.02.018</pub-id><?supplied-pmid 15955494?><pub-id pub-id-type="pmid">15955494</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bolosky</surname><given-names>W.</given-names></name><name><surname>Scott</surname><given-names>M.</given-names></name></person-group> (<year>1993</year>). <article-title>False sharing and its effect on shared memory performance</article-title>, in <source>SEDMS IV</source> (<publisher-loc>San Diego, CA</publisher-loc>), <fpage>57</fpage>–<lpage>71</lpage></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bron</surname><given-names>E.</given-names></name><name><surname>van Tiel</surname><given-names>J.</given-names></name><name><surname>Smit</surname><given-names>H.</given-names></name><name><surname>Poot</surname><given-names>D.</given-names></name><name><surname>Niessen</surname><given-names>W.</given-names></name><name><surname>Krestin</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Image registration improves human knee cartilage T1 mapping with delayed gadolinium-enhanced MRI of cartilage (dGEMRIC)</article-title>. <source>Eur. Radiol</source>. <volume>23</volume>, <fpage>246</fpage>–<lpage>252</lpage>
<pub-id pub-id-type="doi">10.1007/s00330-012-2590-3</pub-id><?supplied-pmid 22865226?><pub-id pub-id-type="pmid">22865226</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>L.</given-names></name></person-group> (<year>1992</year>). <article-title>A survey of image registration techniques</article-title>. <source>ACM Comput. Surv</source>. <volume>24</volume>, <fpage>325</fpage>–<lpage>376</lpage>
<pub-id pub-id-type="doi">10.1145/146370.146374</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castro-Pareja</surname><given-names>C. R.</given-names></name><name><surname>Jagadeesh</surname><given-names>J. M.</given-names></name><name><surname>Shekhar</surname><given-names>R.</given-names></name></person-group> (<year>2003</year>). <article-title>FAIR: a hardware architecture for real-time 3-D</article-title> image registration. <source>IEEE Trans. Info. Tech. Biomed</source>. <volume>7</volume>, <fpage>426</fpage>–<lpage>434</lpage>
<pub-id pub-id-type="doi">10.1109/TITB.2003.821370</pub-id><?supplied-pmid 15000369?><pub-id pub-id-type="pmid">15000369</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C.</given-names></name><name><surname>Lin</surname><given-names>C.</given-names></name></person-group> (<year>2011</year>). <article-title>LIBSVM: a library for support vector machines</article-title>. <source>ACM TIST</source>
<volume>2</volume>, <fpage>27:1</fpage>–<lpage>27:27</lpage>
<pub-id pub-id-type="doi">10.1145/1961189.1961199</pub-id><?supplied-pmid 17217518?><pub-id pub-id-type="pmid">17217518</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuingnet</surname><given-names>R.</given-names></name><name><surname>Gerardin</surname><given-names>E.</given-names></name><name><surname>Tessieras</surname><given-names>J.</given-names></name><name><surname>Auzias</surname><given-names>G.</given-names></name><name><surname>Lehéricy</surname><given-names>S.</given-names></name><name><surname>Habert</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Automatic classification of patients with Alzheimer's</article-title> disease from structural MRI: a comparison of ten methods using the ADNI database. <source>Neuroimage</source>
<volume>56</volume>, <fpage>766</fpage>–<lpage>781</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.06.013</pub-id><?supplied-pmid 20542124?><pub-id pub-id-type="pmid">20542124</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deriche</surname><given-names>R.</given-names></name></person-group> (<year>1990</year>). <article-title>Fast algorithms for low-level vision</article-title>. <source>IEEE Trans. Pattern. Anal. Mach. Intell</source>. <volume>12</volume>, <fpage>78</fpage>–<lpage>87</lpage>
<pub-id pub-id-type="doi">10.1109/34.41386</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Y.</given-names></name><name><surname>Resnick</surname><given-names>S.</given-names></name><name><surname>Wu</surname><given-names>X.</given-names></name><name><surname>Davatzikos</surname><given-names>C.</given-names></name></person-group> (<year>2008</year>). <article-title>Structural and functional biomarkers of prodromal Alzheimer's disease: a high-dimensional pattern classification study</article-title>. <source>Neuroimage</source>
<volume>41</volume>, <fpage>277</fpage>–<lpage>285</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.02.043</pub-id><?supplied-pmid 18400519?><pub-id pub-id-type="pmid">18400519</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Salat</surname><given-names>D.</given-names></name><name><surname>Busa</surname><given-names>E.</given-names></name><name><surname>Albert</surname><given-names>M.</given-names></name><name><surname>Dieterich</surname><given-names>M.</given-names></name><name><surname>Haselgrove</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2002</year>). <article-title>Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain</article-title>. <source>Neuron</source>
<volume>33</volume>, <fpage>341</fpage>–<lpage>355</lpage>
<pub-id pub-id-type="doi">10.1016/S0896-6273(02)00569-X</pub-id><?supplied-pmid 11832223?><pub-id pub-id-type="pmid">11832223</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K.</given-names></name><name><surname>Holmes</surname><given-names>A.</given-names></name><name><surname>Worsley</surname><given-names>K.</given-names></name><name><surname>Poline</surname><given-names>J.-P.</given-names></name><name><surname>Frith</surname><given-names>C.</given-names></name><name><surname>Frackowiak</surname><given-names>R.</given-names></name></person-group> (<year>1994</year>). <article-title>Statistical parametric maps in functional imaging: a general linear approach</article-title>. <source>Hum. Brain Mapp</source>. <volume>2</volume>, <fpage>189</fpage>–<lpage>210</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.460020402</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gousias</surname><given-names>I.</given-names></name><name><surname>Rueckert</surname><given-names>D.</given-names></name><name><surname>Heckemann</surname><given-names>R.</given-names></name><name><surname>Dyet</surname><given-names>L.</given-names></name><name><surname>Boardman</surname><given-names>J.</given-names></name><name><surname>Edwards</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Automatic segmentation of brain MRIs of 2-year-olds into 83 regions of interest</article-title>. <source>Neuroimage</source>
<volume>40</volume>, <fpage>672</fpage>–<lpage>684</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.11.034</pub-id><?supplied-pmid 18234511?><pub-id pub-id-type="pmid">18234511</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hammers</surname><given-names>A.</given-names></name><name><surname>Allom</surname><given-names>R.</given-names></name><name><surname>Koepp</surname><given-names>M. J.</given-names></name><name><surname>Free</surname><given-names>S. L.</given-names></name><name><surname>Myers</surname><given-names>R.</given-names></name><name><surname>Lemieux</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2003</year>). <article-title>Three-dimensional maximum probability atlas of the human brain, with particular reference to the temporal lobe</article-title>. <source>Hum. Brain Mapp</source>. <volume>19</volume>, <fpage>224</fpage>–<lpage>247</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.10123</pub-id><?supplied-pmid 12874777?><pub-id pub-id-type="pmid">12874777</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heckemann</surname><given-names>R.</given-names></name><name><surname>Hajnal</surname><given-names>J.</given-names></name><name><surname>Aljabar</surname><given-names>P.</given-names></name><name><surname>Rueckert</surname><given-names>D.</given-names></name><name><surname>Hammers</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>Automatic anatomical brain MRI</article-title> segmentation combining label propagation and decision fusion. <source>Neuroimage</source>
<volume>33</volume>, <fpage>115</fpage>–<lpage>126</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.05.061</pub-id><?supplied-pmid 16860573?><pub-id pub-id-type="pmid">16860573</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ibánez</surname><given-names>L.</given-names></name><name><surname>Schroeder</surname><given-names>W.</given-names></name><name><surname>Ng</surname><given-names>L.</given-names></name><name><surname>Cates</surname><given-names>J.</given-names></name></person-group> (<year>2005</year>). <source>The ITK Software Guide</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Kitware Inc</publisher-name></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jack</surname><given-names>C.</given-names></name><name><surname>Bernstein</surname><given-names>M.</given-names></name><name><surname>Fox</surname><given-names>N.</given-names></name><name><surname>Thompson</surname><given-names>P.</given-names></name><name><surname>Alexander</surname><given-names>G.</given-names></name><name><surname>Harvey</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>The Alzheimer's disease neuroimaging initiative (ADNI): MRI methods</article-title>. <source>J. Magn. Reson. Imag</source>. <volume>27</volume>, <fpage>685</fpage>–<lpage>691</lpage>
<pub-id pub-id-type="doi">10.1002/jmri.21049</pub-id><?supplied-pmid 18302232?><pub-id pub-id-type="pmid">18302232</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>A.</given-names></name><name><surname>Andersson</surname><given-names>J.</given-names></name><name><surname>Ardekani</surname><given-names>B.</given-names></name><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Avants</surname><given-names>B.</given-names></name><name><surname>Chiang</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2009a</year>). <article-title>Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI</article-title> registration. <source>Neuroimage</source>
<volume>46</volume>, <fpage>786</fpage>–<lpage>802</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.12.037</pub-id><?supplied-pmid 19195496?><pub-id pub-id-type="pmid">19195496</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>S.</given-names></name><name><surname>Pluim</surname><given-names>J.</given-names></name><name><surname>Staring</surname><given-names>M.</given-names></name><name><surname>Viergever</surname><given-names>M.</given-names></name></person-group> (<year>2009b</year>). <article-title>Adaptive stochastic gradient descent optimisation for image registration</article-title>. <source>Int. J. Comput. Vis</source>. <volume>81</volume>, <fpage>227</fpage>–<lpage>239</lpage>
<pub-id pub-id-type="doi">10.1007/s11263-008-0168-y</pub-id><?supplied-pmid 21995072?><pub-id pub-id-type="pmid">21995072</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>S.</given-names></name><name><surname>Staring</surname><given-names>M.</given-names></name><name><surname>Murphy</surname><given-names>K.</given-names></name><name><surname>Viergever</surname><given-names>M.</given-names></name><name><surname>Pluim</surname><given-names>J.</given-names></name></person-group> (<year>2010</year>). <article-title><monospace>elastix</monospace></article-title>: a toolbox for intensity-based medical image registration. <source>IEEE Trans. Med. Imag</source>. <volume>29</volume>, <fpage>196</fpage>–<lpage>205</lpage>
<pub-id pub-id-type="doi">10.1109/TMI.2009.2035616</pub-id><?supplied-pmid 19923044?><pub-id pub-id-type="pmid">19923044</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>S.</given-names></name><name><surname>Staring</surname><given-names>M.</given-names></name><name><surname>Pluim</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>Evaluation of optimization methods for nonrigid medical image registration using mutual information and B</article-title>-splines. <source>IEEE Trans. Image. Proc</source>. <volume>16</volume>, <fpage>2879</fpage>–<lpage>2890</lpage>
<pub-id pub-id-type="doi">10.1109/TIP.2007.909412</pub-id><?supplied-pmid 18092588?><pub-id pub-id-type="pmid">18092588</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klöoppel</surname><given-names>S.</given-names></name><name><surname>Stonnington</surname><given-names>C.</given-names></name><name><surname>Chu</surname><given-names>C.</given-names></name><name><surname>Draganski</surname><given-names>B.</given-names></name><name><surname>Scahill</surname><given-names>R.</given-names></name><name><surname>Rohrer</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Automatic classification of MR scans in Alzheimer's disease</article-title>. <source>Brain</source>
<volume>131</volume>, <fpage>681</fpage>–<lpage>689</lpage>
<pub-id pub-id-type="doi">10.1093/brain/awm319</pub-id><?supplied-pmid 18202106?><pub-id pub-id-type="pmid">18202106</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koikkalainen</surname><given-names>J.</given-names></name><name><surname>Pölönen</surname><given-names>H.</given-names></name><name><surname>Mattila</surname><given-names>J.</given-names></name><name><surname>van Gils</surname><given-names>M.</given-names></name><name><surname>Soininen</surname><given-names>H.</given-names></name><name><surname>Lötjönen</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Improved classification of Alzheimer's disease data via removal of nuisance variability</article-title>. <source>PLoS ONE</source>
<volume>7</volume>:<fpage>e31112</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0031112</pub-id><?supplied-pmid 22348041?><pub-id pub-id-type="pmid">22348041</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maes</surname><given-names>F.</given-names></name><name><surname>Collignon</surname><given-names>A.</given-names></name><name><surname>Vandermeulen</surname><given-names>D.</given-names></name><name><surname>Marchal</surname><given-names>G.</given-names></name><name><surname>Suetens</surname><given-names>P.</given-names></name></person-group> (<year>1997</year>). <article-title>Multimodality image registration by maximization of mutual information</article-title>. <source>IEEE Trans. Med. Imag</source>. <volume>16</volume>, <fpage>187</fpage>–<lpage>198</lpage>
<pub-id pub-id-type="doi">10.1109/42.563664</pub-id><?supplied-pmid 9101328?><pub-id pub-id-type="pmid">9101328</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magnin</surname><given-names>B.</given-names></name><name><surname>Mesrob</surname><given-names>L.</given-names></name><name><surname>Kinkingnéhun</surname><given-names>S.</given-names></name><name><surname>Pélégrini-Issac</surname><given-names>M.</given-names></name><name><surname>Colliot</surname><given-names>O.</given-names></name><name><surname>Sarazin</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2009</year>). <article-title>Support vector machine-based classification of Alzheimer's disease from whole-brain anatomical MRI</article-title>. <source>Neuroradiology</source>
<volume>51</volume>, <fpage>73</fpage>–<lpage>83</lpage>
<pub-id pub-id-type="doi">10.1007/s00234-008-0463-x</pub-id><?supplied-pmid 18846369?><pub-id pub-id-type="pmid">18846369</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maintz</surname><given-names>J.</given-names></name><name><surname>Viergever</surname><given-names>M.</given-names></name></person-group> (<year>1998</year>). <article-title>A survey of medical image registration</article-title>. <source>Med. Image. Anal</source>. <volume>2</volume>, <fpage>1</fpage>–<lpage>36</lpage>
<pub-id pub-id-type="doi">10.1016/S1361-8415(01)80026-8</pub-id><?supplied-pmid 10638851?><pub-id pub-id-type="pmid">10638851</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattes</surname><given-names>D.</given-names></name><name><surname>Haynor</surname><given-names>D.</given-names></name><name><surname>Vesselle</surname><given-names>H.</given-names></name><name><surname>Lewellen</surname><given-names>T.</given-names></name><name><surname>Eubank</surname><given-names>W.</given-names></name></person-group> (<year>2003</year>). <article-title>PET-CT</article-title> image registration in the chest using free-form deformations. <source>IEEE Trans. Med. Imag</source>. <volume>22</volume>, <fpage>120</fpage>–<lpage>128</lpage>
<pub-id pub-id-type="doi">10.1109/TMI.2003.809072</pub-id><?supplied-pmid 12703765?><pub-id pub-id-type="pmid">12703765</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazziotta</surname><given-names>J.</given-names></name><name><surname>Toga</surname><given-names>A.</given-names></name><name><surname>Evans</surname><given-names>A.</given-names></name><name><surname>Fox</surname><given-names>P.</given-names></name><name><surname>Lancaster</surname><given-names>J.</given-names></name></person-group> (<year>1995</year>). <article-title>A probabilistic atlas of the human brain: theory and rationale for its development the international consortium for brain mapping (ICBM</article-title>). <source>Neuroimage</source>
<volume>2</volume>, <fpage>89</fpage>–<lpage>101</lpage>
<pub-id pub-id-type="doi">10.1006/nimg.1995.1012</pub-id><?supplied-pmid 9343592?><pub-id pub-id-type="pmid">9343592</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pennec</surname><given-names>X.</given-names></name><name><surname>Cachier</surname><given-names>P.</given-names></name><name><surname>Ayache</surname><given-names>N.</given-names></name></person-group> (<year>2003</year>). <article-title>Tracking brain deformations in time sequences of 3D</article-title> US images. <source>Pattern Recognit. Lett</source>. <volume>24</volume>, <fpage>801</fpage>–<lpage>813</lpage>
<pub-id pub-id-type="doi">10.1016/S0167-8655(02)00183-6</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>Y.</given-names></name><name><surname>Lelieveldt</surname><given-names>B.</given-names></name><name><surname>Staring</surname><given-names>M.</given-names></name></person-group> (<year>2014</year>). <article-title>Fast automatic estimation of the optimization step size for nonrigid image registration</article-title>, in <source>SPIE Medical Imaging: Image Processing, Proceedings of SPIE</source> eds <person-group person-group-type="editor"><name><surname>Karssemeijer</surname><given-names>N.</given-names></name><name><surname>Samei</surname><given-names>E.</given-names></name></person-group> (<publisher-loc>San Diego, CA</publisher-loc>).</mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohlfing</surname><given-names>T.</given-names></name><name><surname>Maurer</surname><given-names>C.</given-names><suffix>Jr.</suffix></name></person-group> (<year>2003</year>). <article-title>Nonrigid image registration in shared-memory multiprocessor environments with application to brains, breasts, and bees</article-title>. <source>IEEE Trans. Inf. Technol. Biomed</source>. <volume>7</volume>, <fpage>16</fpage>–<lpage>25</lpage>
<pub-id pub-id-type="doi">10.1109/TITB.2003.808506</pub-id><?supplied-pmid 12670015?><pub-id pub-id-type="pmid">12670015</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rueckert</surname><given-names>D.</given-names></name><name><surname>Sonoda</surname><given-names>L.</given-names></name><name><surname>Hayes</surname><given-names>C.</given-names></name><name><surname>Hill</surname><given-names>D.</given-names></name><name><surname>Leach</surname><given-names>M.</given-names></name><name><surname>Hawkes</surname><given-names>D.</given-names></name></person-group> (<year>1999</year>). <article-title>Nonrigid registration using free-form deformations: application to breast MR</article-title> images. <source>IEEE Trans. Med. Imag</source>. <volume>18</volume>, <fpage>712</fpage>–<lpage>721</lpage>
<pub-id pub-id-type="doi">10.1109/42.796284</pub-id><?supplied-pmid 10534053?><pub-id pub-id-type="pmid">10534053</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Saxena</surname><given-names>V.</given-names></name><name><surname>Rohrer</surname><given-names>J.</given-names></name><name><surname>Gong</surname><given-names>L.</given-names></name></person-group> (<year>2010</year>). <article-title>A parallel GPU algorithm for mutual information based 3D nonrigid image registration</article-title> in <source>Euro-Par 2010 - Parallel Processing</source>, <volume>Vol. 6272</volume> of <italic>LNCS</italic> (<publisher-loc>Ischia</publisher-loc>), <fpage>223</fpage>–<lpage>234</lpage></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Seghers</surname><given-names>D.</given-names></name><name><surname>D'Agostino</surname><given-names>E.</given-names></name><name><surname>Maes</surname><given-names>F.</given-names></name><name><surname>Vandermeulen</surname><given-names>D.</given-names></name><name><surname>Suetens</surname><given-names>P.</given-names></name></person-group> (<year>2004</year>). <article-title>Construction of a brain template from MR images using state-of-the-art registration and segmentation techniques</article-title>, in <source>Proceedings of International Conference Medical Image Computing and Computer-Assisted Intervention</source> (<publisher-loc>Berlin/Heidelberg</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>), <fpage>696</fpage>–<lpage>703</lpage></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shams</surname><given-names>R.</given-names></name><name><surname>Sadeghi</surname><given-names>P.</given-names></name><name><surname>Kennedy</surname><given-names>R.</given-names></name><name><surname>Hartley</surname><given-names>R.</given-names></name></person-group> (<year>2010a</year>). <article-title>Parallel computation of mutual information on the GPU</article-title> with application to real-time registration of 3D medical images. <source>Comput. Methods Prog. Biomed</source>. <volume>99</volume>, <fpage>133</fpage>–<lpage>146</lpage>
<pub-id pub-id-type="doi">10.1016/j.cmpb.2009.11.004</pub-id><?supplied-pmid 20004493?><pub-id pub-id-type="pmid">20004493</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shams</surname><given-names>R.</given-names></name><name><surname>Sadeghi</surname><given-names>P.</given-names></name><name><surname>Kennedy</surname><given-names>R.</given-names></name><name><surname>Hartley</surname><given-names>R.</given-names></name></person-group> (<year>2010b</year>). <article-title>A survey of medical image registration on multicore and the GPU</article-title>. <source>Signal Process. Mag. IEEE</source>
<volume>27</volume>, <fpage>50</fpage>–<lpage>60</lpage>
<pub-id pub-id-type="doi">10.1109/MSP.2009.935387</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>S.</given-names></name></person-group> (<year>2002</year>). <article-title>Fast robust automated brain extraction</article-title>. <source>Hum. Brain Map</source>. <volume>17</volume>, <fpage>143</fpage>–<lpage>155</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.10062</pub-id><?supplied-pmid 12391568?><pub-id pub-id-type="pmid">12391568</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staring</surname><given-names>M.</given-names></name><name><surname>Klein</surname><given-names>S.</given-names></name><name><surname>Pluim</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>A rigidity penalty term for nonrigid registration</article-title>. <source>Med. Phys</source>. <volume>34</volume>, <fpage>4098</fpage>–<lpage>4108</lpage>
<pub-id pub-id-type="doi">10.1118/1.2776236</pub-id><?supplied-pmid 18072476?><pub-id pub-id-type="pmid">18072476</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tustison</surname><given-names>N.</given-names></name><name><surname>Avants</surname><given-names>B.</given-names></name><name><surname>Cook</surname><given-names>P.</given-names></name><name><surname>Zheng</surname><given-names>Y.</given-names></name><name><surname>Egan</surname><given-names>A.</given-names></name><name><surname>Yushkevich</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>N4ITK: improved N3 bias correction</article-title>. <source>IEEE Trans. Med. Imag</source>. <volume>29</volume>, <fpage>1310</fpage>–<lpage>1320</lpage>
<pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id><?supplied-pmid 20378467?><pub-id pub-id-type="pmid">20378467</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vemuri</surname><given-names>P.</given-names></name><name><surname>Gunter</surname><given-names>J.</given-names></name><name><surname>Senjem</surname><given-names>M.</given-names></name><name><surname>Whitwell</surname><given-names>J.</given-names></name><name><surname>Kantarci</surname><given-names>K.</given-names></name><name><surname>Knopman</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Alzheimer's disease diagnosis in individual subjects using structural MR images: validation studies</article-title>. <source>Neuroimage</source>
<volume>39</volume>, <fpage>1186</fpage>–<lpage>1197</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.073</pub-id><?supplied-pmid 18054253?><pub-id pub-id-type="pmid">18054253</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warfield</surname><given-names>S.</given-names></name><name><surname>Jolesz</surname><given-names>F.</given-names></name><name><surname>Kikinis</surname><given-names>R.</given-names></name></person-group> (<year>1998</year>). <article-title>A high performance computing approach to the registration of medical imaging data</article-title>. <source>Parallel Comput</source>. <volume>24</volume>, <fpage>1345</fpage>–<lpage>1368</lpage>
<pub-id pub-id-type="doi">10.1016/S0167-8191(98)00061-1</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Weidendorfer</surname><given-names>J.</given-names></name><name><surname>Kowarschik</surname><given-names>M.</given-names></name><name><surname>Trinitis</surname><given-names>C.</given-names></name></person-group> (<year>2004</year>). <article-title>A tool suite for simulation based analysis of memory access behavior</article-title>, in <source>Proceedings of 4th International Conference on Computatation Science</source> (<publisher-loc>Krakow</publisher-loc>), <fpage>440</fpage>–<lpage>447</lpage></mixed-citation>
    </ref>
  </ref-list>
</back>
