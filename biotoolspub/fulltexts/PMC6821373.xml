<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6821373</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz251</article-id>
    <article-id pub-id-type="publisher-id">btz251</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Genome Analysis</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>HiCNN: a very deep convolutional neural network to better enhance the resolution of Hi-C data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Tong</given-names>
        </name>
        <xref ref-type="aff" rid="btz251-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Zheng</given-names>
        </name>
        <xref ref-type="corresp" rid="btz251-cor1"/>
        <!--<email>zheng.wang@miami.edu</email>-->
        <xref ref-type="aff" rid="btz251-aff1"/>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Hancock</surname>
          <given-names>John</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btz251-aff1"><institution>Department of Computer Science, University of Miami</institution>, Coral Gables, FL, USA</aff>
    <author-notes>
      <corresp id="btz251-cor1">To whom correspondence should be addressed. E-mail: <email>zheng.wang@miami.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>01</day>
      <month>11</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-04-09">
      <day>09</day>
      <month>4</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>09</day>
      <month>4</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>21</issue>
    <fpage>4222</fpage>
    <lpage>4228</lpage>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>11</month>
        <year>2018</year>
      </date>
      <date date-type="rev-recd">
        <day>07</day>
        <month>3</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>05</day>
        <month>4</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz251.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>High-resolution Hi-C data are indispensable for the studies of three-dimensional (3D) genome organization at kilobase level. However, generating high-resolution Hi-C data (e.g. 5 kb) by conducting Hi-C experiments needs millions of mammalian cells, which may eventually generate billions of paired-end reads with a high sequencing cost. Therefore, it will be important and helpful if we can enhance the resolutions of Hi-C data by computational methods.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We developed a new computational method named HiCNN that used a 54-layer very deep convolutional neural network to enhance the resolutions of Hi-C data. The network contains both global and local residual learning with multiple speedup techniques included resulting in fast convergence. We used mean squared errors and Pearson’s correlation coefficients between real high-resolution and computationally predicted high-resolution Hi-C data to evaluate the method. The evaluation results show that HiCNN consistently outperforms HiCPlus, the only existing tool in the literature, when training and testing data are extracted from the same cell type (i.e. GM12878) and from two different cell types in the same or different species (i.e. GM12878 as training with K562 as testing, and GM12878 as training with CH12-LX as testing). We further found that the HiCNN-enhanced high-resolution Hi-C data are more consistent with real experimental high-resolution Hi-C data than HiCPlus-enhanced data in terms of indicating statistically significant interactions. Moreover, HiCNN can efficiently enhance low-resolution Hi-C data, which eventually helps recover two chromatin loops that were confirmed by 3D-FISH.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>HiCNN is freely available at <ext-link ext-link-type="uri" xlink:href="http://dna.cs.miami.edu/HiCNN/">http://dna.cs.miami.edu/HiCNN/</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Institutes of Health</named-content>
          <named-content content-type="funder-identifier">10.13039/100000002</named-content>
        </funding-source>
        <award-id>R15GM120650</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">University of Miami</named-content>
          <named-content content-type="funder-identifier">10.13039/100006686</named-content>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The Hi-C technique (<xref rid="btz251-B15" ref-type="bibr">Lieberman-Aiden <italic>et al.</italic>, 2009</xref>) was developed to indicate three-dimensional (3D) conformation of the genome. Compared with previous chromosome conformation capture techniques, including 3C (<xref rid="btz251-B3" ref-type="bibr">Dekker <italic>et al.</italic>, 2002</xref>), 4C (<xref rid="btz251-B25" ref-type="bibr">Zhao <italic>et al.</italic>, 2006</xref>) and 5C (<xref rid="btz251-B6" ref-type="bibr">Dostie <italic>et al.</italic>, 2006</xref>), the main advantage of Hi-C method is that it can capture potential contacts across the entire genome (<xref rid="btz251-B15" ref-type="bibr">Lieberman-Aiden <italic>et al.</italic>, 2009</xref>), which provides an opportunity to reconstruct the 3D structures of the whole genome (<xref rid="btz251-B10" ref-type="bibr">Hu <italic>et al.</italic>, 2013</xref>; <xref rid="btz251-B22" ref-type="bibr">Varoquaux <italic>et al.</italic>, 2014</xref>). Hi-C data have also been applied to the areas of predicting DNA methylation (<xref rid="btz251-B23" ref-type="bibr">Wang <italic>et al.</italic>, 2016</xref>) and exploring the relationship between Xist lncRNA and 3D genome architecture (<xref rid="btz251-B7" ref-type="bibr">Engreitz <italic>et al.</italic>, 2013</xref>). By systematically analyzing Hi-C data, researchers have found significant conformational characteristics of the genome including: open and close compartments (<xref rid="btz251-B15" ref-type="bibr">Lieberman-Aiden <italic>et al.</italic>, 2009</xref>) and their successors six subcompartments (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>), topologically associating domains (TADs) (<xref rid="btz251-B4" ref-type="bibr">Dixon <italic>et al.</italic>, 2012</xref>), and Hi-C peaks that indicate chromatin loops (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>). Low-resolution Hi-C data (e.g. 1 Mb and 500 kb) consist of blurred boundaries of TADs and Hi-C peaks, which makes it difficult to accurately identify the locations of TADs and peaks. Recently, experimental high-resolution Hi-C data are available, such as at 40 kb (<xref rid="btz251-B4" ref-type="bibr">Dixon <italic>et al.</italic>, 2012</xref>), 10 kb (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>) and 1 kb (<xref rid="btz251-B2" ref-type="bibr">Bonev <italic>et al.</italic>, 2017</xref>) resolutions, which makes the identifications of TADs and Hi-C peaks more efficient and accurate. It is apparent that high-resolution Hi-C data are progressively in demand for researchers when they try to explore the complex 3D structures of chromosomes at kilobase resolution.</p>
    <p>The publicly available high-resolution Hi-C data are mostly generated from time-consuming Hi-C experiments (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>), which needs millions of mammalian cells and with a large amount of sequencing cost involved. Therefore, it will be more efficient and economical if we can develop computational methods to enhance the resolutions of Hi-C data. Since the high-resolution Hi-C contact matrices include repeatable patterns (<xref rid="btz251-B4" ref-type="bibr">Dixon <italic>et al.</italic>, 2012</xref>; <xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>), it is feasible to let machine learning algorithms to learn from these patterns and then use the learned models to reveal the patterns that are unobvious in the low-resolution Hi-C data. Zhang <italic>et al.</italic> (<xref rid="btz251-B24" ref-type="bibr">Zhang <italic>et al.</italic>, 2018</xref>) developed the state-of-the-art computational method named HiCPlus to enhance the resolutions of Hi-C data, which uses a three-layer convolutional neural network (ConvNet) to learn the mapping between low-resolution and high-resolution Hi-C contact matrices. They first proved that the entries in the Hi-C contact matrices can be reliably predicted from their <italic>n </italic>×<italic> n</italic> surrounding matrices and found that when <italic>n</italic> equals 13 the accuracy reaches a high plateau. HiCPlus outperforms other types of interpolation methods (<xref rid="btz251-B24" ref-type="bibr">Zhang <italic>et al.</italic>, 2018</xref>) including random forest and Gaussian smoothing. The Pearson’s correlation coefficients between HiCPlus-enhanced and experimental high-resolution Hi-C are even larger than those between two experimental replicates.</p>
    <p>There is still room for improvement for HiCPlus. The task of resolution enhancement is analogous to the problem of single image super-resolution (SR) in the field of computer vision. In the past four years, several outstanding ConvNet-based SR methods were developed. SRCNN (<xref rid="btz251-B5" ref-type="bibr">Dong <italic>et al.</italic>, 2014</xref>) first introduced the deep learning method for image SR, which used a three-layer convolutional neural network to learn an end-to-end mapping between low- and high-resolution images. VDSR (<xref rid="btz251-B12" ref-type="bibr">Kim <italic>et al.</italic>, 2016</xref>) used a very deep ConvNet (20 layers), first introduced global residual learning for SR, and increased convergence speed by adjustable gradient clipping, which makes it outperform SRCNN. DRRN (<xref rid="btz251-B19" ref-type="bibr">Tai <italic>et al.</italic>, 2017</xref>) used a further deeper ConvNet (52 layers) and adopted global and local residual learning by introducing recursive learning. Its evaluation results indicate that DRRN outperforms several methods, including VDSR and DRCN (<xref rid="btz251-B13" ref-type="bibr">Kim <italic>et al.</italic>, 2016</xref>). The architectures of recent published ConvNet-based SR methods [e.g. MemNet (<xref rid="btz251-B20" ref-type="bibr">Tai <italic>et al.</italic>, 2017</xref>) and CMSC (<xref rid="btz251-B11" ref-type="bibr">Hu <italic>et al.</italic>, 2018</xref>)] are all based on global and local residual learning. In general, VDSR (<xref rid="btz251-B12" ref-type="bibr">Kim <italic>et al.</italic>, 2016</xref>) proved that deeper ConvNets and global residual learning are effective to achieve better performance than SRCNN. DRRN (<xref rid="btz251-B19" ref-type="bibr">Tai <italic>et al.</italic>, 2017</xref>) concluded that local residual learning along with much deeper ConvNets than VDSR can further improve the accuracy.</p>
    <p>In this study, we developed a new ConvNet-based computational method named HiCNN for resolution enhancement of Hi-C data. Our method directly learns the mapping function between low-resolution and high-resolution Hi-C contact matrices via a very deep convolutional neural network (54 layers). The first two layers are designed for pattern extraction and representation, which is similar to the first layer in HiCPlus and SRCNN. The following 52 layers are designed to implement global and local residual learning in our ConvNet, because several ConvNet-based SR methods have proved that these two residual learning manners significantly improve the performance of resolution enhancement. The number of layers was predefined to 54 and easy to be altered if needed. Our evaluation results show that HiCNN outperforms HiCPlus in multiple evaluation criteria, which further supports the observation that deeper ConvNets along with global and local residual learning can significantly improve SR performance on Hi-C data.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Hi-C data preprocessing and contact matrix generation</title>
      <p>The high-resolution Hi-C datasets are from GEO GSE63525 in which Rao <italic>et al.</italic> (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>) provided high-resolution Hi-C paired-end reads that were mapped to the corresponding reference genomes of eight different cell types. We used three of the eight cell types including GM12878 (human), K562 (human) and CH12-LX (mouse), and downloaded corresponding Hi-C paired-end reads that were uniquely mapped to reference genomes with MAPQ scores from BWA (<xref rid="btz251-B14" ref-type="bibr">Li and Durbin 2010</xref>) larger than zero. Since Rao <italic>et al.</italic> (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>) also released a high-resolution replicate on GM12878, we used four Hi-C datasets in total including GM12878, GM12878 replicate, K562 and CH12-LX. In this way, we can use the Hi-C data from GM12878 replicate to evaluate the enhanced Hi-C data of GM12878 and use Hi-C data from GM12878 and K562 to test if our computational method can effectively enhance Hi-C resolutions of one cell type by using the Hi-C data from another cell type as training data. We can also use Hi-C data from GM12878 and CH12-LX to see if our enhancement method can be applied to different species.</p>
      <p>For each of the four datasets, we first looped through all paired-end reads, and then picked up those fallen into the same chromosome. The real high-resolution Hi-C contact matrix of a single chromosome is generated by counting all paired-end reads related to the chromosome. The low-resolution Hi-C contact matrix of a given chromosome is obtained from the following two steps: (i) determining a down sampling ratio and randomly selecting part of the paired-end reads by the ratio; for example, ratio 1/16 means that we randomly select 1/16 of all reads; (ii) generating a low-resolution Hi-C contact matrix using the Hi-C paired-end reads from step 1.</p>
      <p>The training data were extracted from low-resolution Hi-C contact matrices (10 kb) of five individual chromosomes including chromosomes 1, 3, 5, 7 and 9 in GM12878 with different down sampling ratios including 1/8, 1/16 and 1/25. The entire big Hi-C contact matrix for each individual chromosome was subdivided into thousands of 40 × 40 small submatrices. We concatenated all the submatrices as the final training data. The generation of target data was the same as the process of generating training data but using the high-resolution Hi-C contact matrices. We used different overlapping size of submatrices to control the size of training datasets. For example, using overlapping size of two columns as increment will result in four times reduction of training data compared with using increment of one column. The validation dataset (containing both low-resolution and corresponding high-resolution Hi-C contact submatrices) was extracted on chromosome 2 in GM12878. We selected chromosome 2 for validation dataset because it has a relatively larger size.</p>
    </sec>
    <sec>
      <title>2.2 A very deep convolutional neural network</title>
      <p>We built a very deep convolutional neural network (ConvNet) with the number of layers as 54. The details of its architecture are shown in <xref ref-type="fig" rid="btz251-F1">Figure 1</xref>. The input of this ConvNet is a set of low-resolution Hi-C contact submatrices with shape equal to (<italic>n</italic>, 1, 40, 40) where <italic>n</italic> is the total number of samples (i.e. number of submatrices), ‘1’ corresponds to the input channel size of the first layer, and the last two dimensions (40, 40) are the size of the submatrices. Given a training and target set <inline-formula id="IE1"><mml:math id="IM1"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, where <inline-formula id="IE2"><mml:math id="IM2"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE3"><mml:math id="IM3"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the low-resolution and the corresponding high-resolution Hi-C contact submatrices, respectively. The loss function of our ConvNet is
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mi>L</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="true">‖</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>
where <italic>F</italic> is the mapping function from <inline-formula id="IE4"><mml:math id="IM4"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to <inline-formula id="IE5"><mml:math id="IM5"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that we are trying to learn, and Θ denotes the parameter set.
</p>
      <fig id="btz251-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>The architecture of our convolutional neural network. There are five types of layers, including conv1, conv2, conv3, conv4R and conv5. Edge ‘1’ marks the global residual learning, and Edge ‘2’ marks the local residual learning. The dashed box highlights a building block for local residual learning. ⊕ denotes element-wise addition</p>
        </caption>
        <graphic xlink:href="btz251f1"/>
      </fig>
      <p>There are five different types of layers in our architecture, including conv1, conv2, conv3, conv4R and conv5. The first type (i.e. conv1 in <xref ref-type="fig" rid="btz251-F1">Fig. 1</xref>), containing 13 × 13 filters followed by a Rectified Linear Unit (ReLU) (<xref rid="btz251-B16" ref-type="bibr">Nair and Hinton, 2010</xref>), is designed to extract and represent Hi-C patterns. The second type (i.e. conv2 in <xref ref-type="fig" rid="btz251-F1">Fig. 1</xref>), containing a 1 × 1 filter followed by a ReLU, is used to reduce its input channels to one for the afterwards residual learning layers. The shape of the output of conv2 will be (<italic>n</italic>, 1, 28, 28). The rest part of the architecture after conv2 in <xref ref-type="fig" rid="btz251-F1">Fig. 1</xref> is designed to implement global and local residual learning to make it a deep recursive residual network (DRRN) (<xref rid="btz251-B19" ref-type="bibr">Tai <italic>et al.</italic>, 2017</xref>). The third type (i.e. conv3 in <xref ref-type="fig" rid="btz251-F1">Fig. 1</xref>), containing 3 × 3 filters with zero padding of size 1 (to preserve the size of submatrices), can increase the output channels for the afterwards local residual learning blocks. The fourth type (i.e. conv4R in <xref ref-type="fig" rid="btz251-F1">Fig. 1</xref>), containing 3 × 3 filters with zero padding of size 1, is the basic unit of our local residual learning. The fifth type (i.e., conv5 in <xref ref-type="fig" rid="btz251-F1">Fig. 1</xref>) is used to reduce the output channel size to match the shape of conv2's output for global residual learning and final prediction output.</p>
      <p>We implemented our ConvNet in this study via Pytorch (<xref rid="btz251-B17" ref-type="bibr">Paszke <italic>et al.</italic>, 2017</xref>). The weight parameters were initialized using the He initialization method with ReLU (<xref rid="btz251-B9" ref-type="bibr">He <italic>et al.</italic>, 2015</xref>). We used stochastic gradient descent (SGD) with a mini-batch size of 256, a momentum of 0.9, and a weight decay of 0.0001. The learning rate was initially set to 0.1 and was reduced by a factor of 0.1 (i.e. a factor times current learning rate equals new learning rate) when the mean squared error from the validation process has stopped reducing. We used adjustable gradient clipping technique as in (<xref rid="btz251-B12" ref-type="bibr">Kim <italic>et al.</italic>, 2016</xref>; <xref rid="btz251-B19" ref-type="bibr">Tai <italic>et al.</italic>, 2017</xref>) with θ equal to 0.01 to increase convergence speed.</p>
    </sec>
    <sec>
      <title>2.3 HiCNN pipeline</title>
      <p>Our method HiCNN includes three main steps: (i) learning the mapping function by doing training and validation processes to obtain optimal weight parameters; (ii) splitting the big low-resolution Hi-C contact matrix of one individual chromosome into thousands of 40 × 40 input submatrices, and predicting their corresponding high-resolution 28 × 28 output submatrices using the best model we obtained in step 1; (iii) predicting the high-resolution Hi-C contact matrix of the individual chromosome by rearranging the 28 × 28 output submatrices into a new matrix according to their indexes.</p>
      <p>Similar to HiCPlus, the size of the output submatrices is smaller compared to the size of input submatrices. For HiCNN, the input submatrices are 40 × 40 and output submatrices 28 × 28. This is because we use the 13 × 13 surrounding values to make prediction for the central entry in the low-resolution big Hi-C matrix, e.g. the Hi-C map for an entire chromosome (every time a submatrix is input into the ConvNet). Therefore, predictions for some values in the input big matrix are not made, named as margin values, e.g. the first six values in the first row. In these cases, zero will be put in the output big matrix as placeholders, which makes the input (low-resolution) big matrix and the output (predicted high-resolution) big matrix having the same numbers of rows and columns.</p>
      <p>Notice that the goal of this research is not to increase the number of rows and columns of the low-resolution big matrix. Instead, our HiCNN, and also HiCPlus, are designed to make the zero-inflated or sparse matrix to contain more meaningful values. For example, in order to increase the resolution of the Hi-C matrix of chromosome 1 from 40 into 5 kb, we first convert the 40 kb Hi-C matrix into a 5 kb matrix that usually is very sparse. After that, HiCNN will be executed to predict new values in the matrix while maintaining the same number of rows and columns as the 5 kb sparse matrix.</p>
      <p>In order to still be able to make predictions for most of the margin values, we overlap the input submatrices. For example, if a low-resolution submatrix covers the rows of [1, 40] and columns of [1, 40] in the input big matrix. It corresponds to the rows and columns of [7, 34] and [7, 34] in the high-resolution big matrix. To fill up the gaps caused by the shrinking of size for the output submatrix, we make the next input submatrix at rows [1, 40] and columns [29, 68], which leads to rows and columns of [7, 34] and [35, 62] in the output matrix. In this way, the margin values on the right of the first input submatrix will be covered and have values predicted.</p>
    </sec>
    <sec>
      <title>2.4 Evaluation methods</title>
      <p>In addition to Pearson’s correlation coefficient that HiCPlus used to evaluate its predictions, we also used a more constringent evaluation measure, mean squared error (MSE). MSE is used to measure the average of the squared errors between computational enhanced high-resolution Hi-C data and experimental (i.e. real) high-resolution Hi-C data in terms of genomic distance. Since we represent Hi-C data as a <italic>n</italic>-by-<italic>n</italic> bin-based contact matrix, genomic distances in this context mean bin separations where the size of a bin is the resolution of interest. A smaller MSE indicates that on average the predicted Hi-C contacts are more similar to the real ones. Pearson’s correlation coefficient is used to measure the linear correlation between computationally predicted and experimental high-resolution Hi-C data, which is also in terms of genomic distances. A higher Pearson’s correlation indicates that the predicted Hi-C data better match the real Hi-C data.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Training of the very deep convolutional neural network</title>
      <p>We used all of the training examples to train HiCPlus, but only used 1/14 of the training data to train our HiCNN. However, we find that we still achieve better performance compared to HiCPlus (details will be discussed in Sections 3.2–3.6). Moreover, the speedup techniques we used made our ConvNet to be able to converge earlier with less epochs. Our training process can be converged in about 200 epochs with no overfitting being observed (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1</xref>). Training the very deep ConvNet of our HiCNN (200 epochs needed for convergence) took about 12 h on a NVIDIA V100 GPU with 16 Gb memory, whereas training the ConvNet of HiCPlus (≥2000 epochs needed for better convergence) took about 28 h on the same GPU. Therefore, even though our ConvNet is much deeper than the one of HiCPlus, our training process is much faster.</p>
      <p>The input/output channels for the five types of layers (i.e. conv1, conv2, conv3, conv4R and conv5) are 1/8, 8/1, 1/128, 128/128 and 128/1, respectively. We tested several other configurations by increasing channels (increasing all 8 channels to 16 and increasing all 128 channels to 256) but did not obtain noticeable improvement in performance. We have tested different numbers of layers (i.e. 14, 24, 44, 54, 64, 74 and 104 layers) by changing the number of local residual learning blocks and found that (i) ConvNet with the number of layers larger than 14 performs noticeably better than the ConvNet with 14 layers; (ii) the performance of ConvNet is not sensitive to the number of layers when it is larger than 24 (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S2</xref>).</p>
    </sec>
    <sec>
      <title>3.2 Resolution enhancement in one cell type using different down sampling ratios</title>
      <p>The evaluations in this section were performed on one cell type, that is, GM12878. Since we used Hi-C contact matrices of chromosomes 1, 3, 5, 7 and 9 to extract training data and Hi-C contact matrix of chromosome 2 to extract validation data, we randomly chose two other chromosomes 6 and 12 to extract blind test data. We first tested down sampling ratio 1/16; and the results shown in <xref ref-type="fig" rid="btz251-F2">Figure 2</xref> are the mean squared errors (MSEs) and Pearson’s correlation coefficients between the real high-resolution Hi-C data and each of the following four Hi-C datasets on GM12878: low-resolution, HiCNN-enhanced, HiCPlus-enhanced and high-resolution biological replicate. It can be found that for both of the two chromosomes (i.e. 6 and 12) HiCNN outperforms HiCPlus, and both HiCNN and HiCPlus perform better than low-resolution Hi-C and high-resolution Hi-C replicate. We can draw the same conclusions if we set the down sampling ratio to 1/8 (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S3</xref>) and to 1/25 (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S4</xref>).
</p>
      <fig id="btz251-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>The evaluation results (i.e. mean squared error and Pearson correlation) on one cell type GM12878 between experimental high-resolution Hi-C and each of the four Hi-C datasets, including low-resolution from down sampling ratio equal to 1/16, HiCNN-enhanced, HiCPlus-enhanced and biologically experimental replicate</p>
        </caption>
        <graphic xlink:href="btz251f2"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Resolution enhancement between two different cell types and two different species</title>
      <p>We conducted more experiments to test whether (i) our convolutional model trained on one cell type can be directly used to enhance the Hi-C matrices of another cell type with the same species; (ii) our convolutional model trained on one species can be directly used on enhancing the Hi-C matrices of another species. We used the model trained on GM12878 (human) with down sampling ratio equal to 1/8. We first used this model to enhance the Hi-C matrices of K562 (human), specifically on two randomly selected chromosomes (i.e. 5 and 15). The results are shown in <xref ref-type="fig" rid="btz251-F3">Figure 3</xref>, indicating that HiCPlus and HiCNN can both efficiently enhance resolutions of Hi-C data of K562 but HiCNN performs consistently better than HiCPlus in terms of all genomic distances. We next used the same model to enhance the Hi-C resolutions of CH12-LX (mouse). We also used two chromosomes 5 and 15 in CH12-LX to create blind test data. The results are shown in <xref ref-type="fig" rid="btz251-F4">Figure 4</xref>. The same conclusions can be drawn as in the previous evaluations conducted on K562.
</p>
      <fig id="btz251-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>The evaluation results (i.e. mean squared error and Pearson correlation) on K562 in human between experimental high-resolution Hi-C and each of the three Hi-C datasets, including low-resolution from down sampling ratio equal to 1/8, HiCNN-enhanced, and HiCPlus-enhanced. The models HiCNN and HiCPlus use to predict are trained on dataset from GM12878 in human</p>
        </caption>
        <graphic xlink:href="btz251f3"/>
      </fig>
      <fig id="btz251-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>The evaluation results (i.e. mean squared error and Pearson correlation) on CH12-LX in mouse between experimental high-resolution Hi-C and each of the three Hi-C datasets, including low-resolution from down sampling ratio equal to 1/8, HiCNN-enhanced, and HiCPlus-enhanced. The models HiCNN and HiCPlus use to predict are trained on dataset from GM12878 in human</p>
        </caption>
        <graphic xlink:href="btz251f4"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Resolution enhancement from real low-resolution Hi-C data</title>
      <p>We evaluated HiCNN on two sets of real low-resolution Hi-C data compared with the previous low-resolution Hi-C data generated from down sampling. The first real low-resolution dataset is from GEO GSM1551620 (HIC071) on K562 (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>). Since the high-resolution data in (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>) are built by combining multiple independent <italic>in situ</italic> Hi-C samples, we consider each of the Hi-C samples as data generated from a low-resolution experiment. We used the ConvNet model trained on GM12878 with down sampling ratio 1/16 to enhance the low-resolution K562 data. The evaluation results on chromosomes 5 and 15 are shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S5</xref>, indicating that HiCNN outperforms HiCPlus.</p>
      <p>The second real low-resolution Hi-C dataset is from GEO GSE35156 (<xref rid="btz251-B4" ref-type="bibr">Dixon <italic>et al.</italic>, 2012</xref>) with the HindIII restriction enzyme in mouse embryonic stem (ES) cells, which can reach a 40 kb resolution. We used the ConvNet trained on GM12878 with down sampling ratio 1/8 to enhance the resolution to 5 kb. We used the ultrahigh-resolution Hi-C data from GEO GSE96107 (<xref rid="btz251-B2" ref-type="bibr">Bonev <italic>et al.</italic>, 2017</xref>) with the Mbol restriction enzyme to evaluate our predictions. Since the two Hi-C datasets are generated from two different restriction enzymes (i.e. HindIII and Mbol), we used Spearman’s rank correlation coefficient instead of MSE as the evaluation measure (different enzymes result in different scales for the number of Hi-C contacts making MSE not an ideal measure). The evaluation results are shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S6</xref>, indicating that both HiCNN and HiCPlus can noticeably improve the real low-resolution Hi-C data and HiCNN outperforms HiCPlus in terms of Spearman’s rank correlation.</p>
    </sec>
    <sec>
      <title>3.5 Evaluating HiCNN in terms of the abilities to help recover significant interactions and indicate chromatin states</title>
      <p>We used Fit-Hi-C (<xref rid="btz251-B1" ref-type="bibr">Ay <italic>et al.</italic>, 2014</xref>) to call statistically significant interactions (<italic>q</italic>-value &lt; 1 × 10<sup>-</sup><sup>6</sup>) in low-resolution, HiCPlus-enhanced, HiCNN-enhanced, and real high-resolution Hi-C contact matrices. We conducted the evaluations on the chromosome 12 of GM12878 within the genomic distances from 50 kb to 2 Mb and with down sampling ratio 1/16. In total, Fit-Hi-C detected 67, 729, 1324, 1421 significant interaction pairs in low-resolution, HiCPlus-enhanced, HiCNN-enhanced, and experimental high-resolution Hi-C contact matrices, respectively. The low-resolution, HiCPlus-enhanced, and HiCNN-enhanced Hi-C contact matrices have 22, 660, 1116 common significant interaction pairs with the interaction pairs detected from real high-resolution Hi-C, respectively (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S7</xref>). HiCNN performs significantly better than HiCPlus. Specifically, the Hi-C contact matrices enhanced by HiCNN lead to 1116 out of 1421 (79%) significant interactions, which is 30% higher than from the Hi-C contact matrices enhanced by HiCPlus, although both are higher than the number of interactions detected from low-resolution Hi-C. We also conducted the same analysis on chromosome 6 (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S8</xref>) and can draw the same conclusions as we did on chromosome 12.</p>
      <p>We found that the chromatin loops (Hi-C peaks) reported in <xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic> (2014)</xref>, which are called by HiCCUPS, highly overlap with the significant interactions called by Fit-Hi-C. As shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>, HiCCUPS detects 434 peaks on chromosome 12 in GM12878. With <italic>q</italic>-value &lt;1 ×10<sup>-</sup><sup>6</sup> Fit-Hi-C can successfully detect 300 out of 434 peaks on real high-resolution Hi-C data. HiCNN (266 out of 434) outperforms HiCPlus (218 out of 434) and low-resolution (114 out of 434). When we increase the <italic>q</italic>-value, the size of the mutual set between the Hi-C peaks called by HiCCUPS and the significant interactions called by Fit-Hi-C increase. HiCNN and HiCPlus perform almost equally well on chromosome 6; and more common peaks are found in both HiCNN-enhanced and HiCPlus-enhanced Hi-C data compared to the common peaks found from the low-resolution Hi-C data.</p>
      <p>We compared the CTCF-mediated interactions ensured by ChIA-PET (<xref rid="btz251-B21" ref-type="bibr">Tang <italic>et al.</italic>, 2015</xref>) with the significant interactions detected from the following Hi-C datasets: low-resolution with down sampling ratio 1/16, real high-resolution, HiCPlus-enhanced, and HiCNN-enhanced. These four Hi-C datasets have 36, 77, 70 and 70 interactions in common with the 5, 600 CTCF interacting pairs on chromosome 6 in GM12878. HiCNN and HiCPlus perform equally better than low-resolution. We did the same analysis on chromosome 12 in GM12878; and the four numbers are 46, 48, 40 and 45 of the 5, 135 CTCF interacting pairs, indicating that HiCNN outperforms HiCPlus.</p>
      <p>We conducted evaluations from the perspective of chromatin states. The definitions of chromatin states of GM12878 were downloaded from <ext-link ext-link-type="uri" xlink:href="http://rohsdb.cmb.usc.edu/GBshape/cgi-bin/hgFileUi?db=hg19&amp;g=wgEncodeAwgSegmentation">http://rohsdb.cmb.usc.edu/GBshape/cgi-bin/hgFileUi? db=hg19&amp;g=wgEncodeAwgSegmentation</ext-link>, which was generated by the software ChromHMM (<xref rid="btz251-B8" ref-type="bibr">Ernst and Kellis, 2012</xref>) based on ENCODE data. Using Fit-Hi-C, we detected significant interactions based on real high-resolution Hi-C data. The chromatin segments where the significant interactions locate were gathered in a pool. ChromHMM was then executed on the pool of chromatin segments to call 10 types of chromatin states. In this way, an enrichment profile (indicated by the value of fold enrichment in <xref ref-type="fig" rid="btz251-F5">Fig. 5</xref>) of the 10 chromatin states was generated for the interactions detected on real high-resolution Hi-C data. We performed the same procedures on low-resolution (down sampling ratio 1/16), HiCPlus-enhanced, and our HiCNN-enhanced Hi-C data. <xref ref-type="fig" rid="btz251-F5">Figure 5</xref> shows that the enrichment pattern related to HiCNN-enhanced Hi-C data is more similar to the enrichment pattern related to real high-resolution Hi-C data particularly on chromosome 6. This shows that our HiCNN can better enhance the low-resolution Hi-C data so that the interactions detected on the enhanced Hi-C data better fit the real high-resolution Hi-C data in terms of chromatin states.
</p>
      <fig id="btz251-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>The evaluation results (i.e. fold enrichment of 10 states) for segments that significant interactions residue in. We did the analysis on two chromosomes 6 and 12 in GM12878 for Fit-Hi-C-detected significant interactions from four Hi-C datasets, including real high-resolution, low-resolution from down sampling ratio equal to 1/16, HiCNN-enhanced, and HiCPlus-enhanced</p>
        </caption>
        <graphic xlink:href="btz251f5"/>
      </fig>
    </sec>
    <sec>
      <title>3.6 Cross-validation with 3D fluorescence <italic>in situ</italic> hybridization</title>
      <p>The Hi-C detected interactions can be evaluated by cross-validation with 3D fluorescence <italic>in situ</italic> hybridization (FISH) (<xref rid="btz251-B4" ref-type="bibr">Dixon <italic>et al.</italic>, 2012</xref>; <xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>). Rao <italic>et al.</italic> (<xref rid="btz251-B18" ref-type="bibr">Rao <italic>et al.</italic>, 2014</xref>) conducted 3D-FISH experiments to validate four loops that were indicated by Hi-C peaks. Two of the four loops were selected here, on which we could barely observe the existence of the peaks from their low-resolution (down sampling ratio equal to 1/16) Hi-C heatmaps. We used HiCPlus and HiCNN to enhance the resolutions of chromosomes 13 and 14 where the two loops locate and plotted the Hi-C heatmaps of low-resolution (1/16), real high-resolution, HiCNN-enhanced, and HiCPlus-enhanced data. It can be found that both HiCNN and HiCPlus can successfully help reveal the two peaks by enhancing low-resolution Hi-C data. This example indicates that computational methods for enhancing Hi-C resolutions can be used to call Hi-C peaks and explore the properties of these peaks (<xref ref-type="fig" rid="btz251-F6">Fig. 6</xref>).
</p>
      <fig id="btz251-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>The Hi-C heat maps of chromosomes 13 (85.3–86.5 Mb) and 14 (71.4–73.0 Mb) from four Hi-C datasets, including low-resolution with down sampling ratio equal to 1/16, real high-resolution, HiCNN-enhanced, and HiCPlus-enhanced. HiCNN and HiCPlus can successfully recover the two Hi-C Peaks on the two chromosomes in GM12878</p>
        </caption>
        <graphic xlink:href="btz251f6"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>In this study, we developed a new computational method HiCNN to better enhance the resolutions of Hi-C contact matrices. We designed a very deep convolutional neural network to learn the mapping function between low-resolution and high-resolution Hi-C contact matrices. The number of layers we used in our ConvNet is 54 and easy to go deeper by increasing the number of local residual learning blocks. Because we used multiple speedup techniques, the training process is much faster than HiCPlus. We compared our method HiCNN with the state-of-the-art method (HiCPlus) and found that HiCNN consistently outperforms HiCPlus and a high-resolution replicate Hi-C dataset. We may conclude that a well-trained ConvNet model can be used on different cell types and in different species (human and mouse), and the mapping function between low- and high-resolution Hi-C contact matrices may be shared across different cell types and species.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Institutes of Health R15GM120650 to Z.W. and start-up funding from the University of Miami to Z.W.</p>
    <p><italic>Conflict of Interest:</italic> none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz251_Supplementary_Material</label>
      <media xlink:href="btz251_supplementary_material.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz251-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ay</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Statistical confidence estimation for Hi-C data reveals regulatory chromatin contacts</article-title>. <source>Genome Res</source>., <volume>24</volume>, <fpage>999</fpage>–<lpage>1011</lpage>.<pub-id pub-id-type="pmid">24501021</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bonev</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Multiscale 3D genome rewiring during mouse neural development</article-title>. <source>Cell</source>, <volume>171</volume>, <fpage>557</fpage>–<lpage>572</lpage>.<pub-id pub-id-type="pmid">29053968</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dekker</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Capturing chromosome conformation</article-title>. <source>Science</source>, <volume>295</volume>, <fpage>1306</fpage>–<lpage>1311</lpage>.<pub-id pub-id-type="pmid">11847345</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dixon</surname><given-names>J.R.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Topological domains in mammalian genomes identified by analysis of chromatin interactions</article-title>. <source>Nature</source>, <volume>485</volume>, <fpage>376</fpage>–<lpage>380</lpage>.<pub-id pub-id-type="pmid">22495300</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B5">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Dong</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Learning a deep convolutional network for image super-resolution</article-title>. In: <source>European Conference on Computer Vision</source>, 2014. pp. <fpage>184</fpage>–<lpage>199</lpage>. 
<publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btz251-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dostie</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Chromosome conformation capture carbon copy (5C): a massively parallel solution for mapping interactions between genomic elements</article-title>. <source>Genome Res</source>., <volume>16</volume>, <fpage>1299</fpage>–<lpage>1309</lpage>.<pub-id pub-id-type="pmid">16954542</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Engreitz</surname><given-names>J.M.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>The Xist lncRNA exploits three-dimensional genome architecture to spread across the X chromosome</article-title>. <source>Science</source>, <volume>341</volume>, <fpage>1237973</fpage>.<pub-id pub-id-type="pmid">23828888</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ernst</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Kellis</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>) 
<article-title>ChromHMM: automating chromatin-state discovery and characterization</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>215</fpage>.<pub-id pub-id-type="pmid">22373907</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>He</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) Delving deep into rectifiers: surpassing human-level performance on imagenet classification. In: <italic>Proceedings of the IEEE International Conference on Computer Vision</italic>, 2015. pp. <fpage>1026</fpage>–<lpage>1034</lpage>.</mixed-citation>
    </ref>
    <ref id="btz251-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hu</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Bayesian inference of spatial organizations of chromosomes</article-title>. <source>PLoS Comput. Biol</source>., <volume>9</volume>, <fpage>e1002893</fpage>.<pub-id pub-id-type="pmid">23382666</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Hu</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) Single image super-resolution via cascaded multi-scale cross network. <italic>preprint arXiv: 1802.08808</italic>.</mixed-citation>
    </ref>
    <ref id="btz251-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Accurate image super-resolution using very deep convolutional networks. In: <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, 2016. pp. <fpage>1646</fpage>–<lpage>1654</lpage>.</mixed-citation>
    </ref>
    <ref id="btz251-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Deeply-recursive convolutional network for image super-resolution. In: <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic> 2016. pp. <fpage>1637</fpage>–<lpage>1645</lpage>.</mixed-citation>
    </ref>
    <ref id="btz251-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Durbin</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>) 
<article-title>Fast and accurate long-read alignment with Burrows–Wheeler transform</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>589</fpage>–<lpage>595</lpage>.<pub-id pub-id-type="pmid">20080505</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lieberman-Aiden</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Comprehensive mapping of long-range interactions reveals folding principles of the human genome</article-title>. <source>Science</source>, <volume>326</volume>, <fpage>289</fpage>–<lpage>293</lpage>.<pub-id pub-id-type="pmid">19815776</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Nair</surname><given-names>V.</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>G.E.</given-names></name></person-group> Rectified linear units improve restricted boltzmann machines. In: <italic>Proceedings of the 27th International Conference on Machine Learning (ICML-10)</italic>, <year>2010</year> pp. <fpage>807</fpage>–<lpage>814</lpage>.</mixed-citation>
    </ref>
    <ref id="btz251-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Paszke</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Automatic differentiation in pytorch. In: <italic>NIPS 2017 Autodiff Workshop: The Future of Gradient-based Machine Learning Software and Techniques</italic>, 2017.</mixed-citation>
    </ref>
    <ref id="btz251-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rao</surname><given-names>S.S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>A 3D map of the human genome at kilobase resolution reveals principles of chromatin looping</article-title>. <source>Cell</source>, <volume>159</volume>, <fpage>1665</fpage>–<lpage>1680</lpage>.<pub-id pub-id-type="pmid">25497547</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Tai</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> Image super-resolution via deep recursive residual network. In: <italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>
<year>2017</year> p. <fpage>5</fpage>.</mixed-citation>
    </ref>
    <ref id="btz251-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Tai</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> Memnet: a persistent memory network for image restoration. In: <italic>Proceedings of the IEEE International Conference on Computer Vision</italic>
<year>2017</year> pp. <fpage>4539</fpage>–<lpage>4547</lpage>.</mixed-citation>
    </ref>
    <ref id="btz251-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tang</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>CTCF-mediated human 3D genome architecture reveals chromatin topology for transcription</article-title>. <source>Cell</source>, <volume>163</volume>, <fpage>1611</fpage>–<lpage>1627</lpage>.<pub-id pub-id-type="pmid">26686651</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Varoquaux</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>A statistical approach for inferring the 3D structure of the genome</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>i26</fpage>–<lpage>i33</lpage>.<pub-id pub-id-type="pmid">24931992</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Predicting DNA methylation state of CpG dinucleotide using genome topological features and deep networks</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>19598</fpage>.<pub-id pub-id-type="pmid">26797014</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Enhancing Hi-C data resolution with deep convolutional neural network HiCPlus</article-title>. <source>Nat. Commun</source>., <volume>9</volume>, <fpage>750</fpage>.<pub-id pub-id-type="pmid">29467363</pub-id></mixed-citation>
    </ref>
    <ref id="btz251-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhao</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Circular chromosome conformation capture (4C) uncovers extensive networks of epigenetically regulated intra-and interchromosomal interactions</article-title>. <source>Nat. Genet</source>., <volume>38</volume>, <fpage>1341</fpage>–<lpage>1347</lpage>.<pub-id pub-id-type="pmid">17033624</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
