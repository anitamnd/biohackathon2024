<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9563680</article-id>
    <article-id pub-id-type="pmid">36053172</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac598</article-id>
    <article-id pub-id-type="publisher-id">btac598</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>BERN2: an advanced neural biomedical named entity recognition and normalization tool</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7978-8114</contrib-id>
        <name>
          <surname>Sung</surname>
          <given-names>Mujeen</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Korea University</institution>, Seoul 02841, <country country="KR">Republic of Korea</country></aff>
        <xref rid="btac598-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1346-730X</contrib-id>
        <name>
          <surname>Jeong</surname>
          <given-names>Minbyul</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Korea University</institution>, Seoul 02841, <country country="KR">Republic of Korea</country></aff>
        <xref rid="btac598-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5709-9898</contrib-id>
        <name>
          <surname>Choi</surname>
          <given-names>Yonghwa</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Korea University</institution>, Seoul 02841, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8224-8354</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Donghyeon</given-names>
        </name>
        <aff><institution>AIRS Company, Hyundai Motor Group</institution>, Seoul 06620, <country country="KR">Republic of Korea</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4972-239X</contrib-id>
        <name>
          <surname>Lee</surname>
          <given-names>Jinhyuk</given-names>
        </name>
        <!--jinhyuk_lee@korea.ac.kr-->
        <aff><institution>Department of Computer Science and Engineering, Korea University</institution>, Seoul 02841, <country country="KR">Republic of Korea</country></aff>
        <xref rid="btac598-cor1" ref-type="corresp"/>
        <xref rid="btac598-FM2" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6798-9106</contrib-id>
        <name>
          <surname>Kang</surname>
          <given-names>Jaewoo</given-names>
        </name>
        <!--kangj@korea.ac.kr-->
        <aff><institution>Department of Computer Science and Engineering, Korea University</institution>, Seoul 02841, <country country="KR">Republic of Korea</country></aff>
        <aff><institution>AIGEN Sciences</institution>, Seoul 04778, <country country="KR">Republic of Korea</country></aff>
        <xref rid="btac598-cor1" ref-type="corresp"/>
        <xref rid="btac598-FM2" ref-type="author-notes"/>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Borgwardt</surname>
          <given-names>Karsten</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <fn id="btac598-FM1">
        <label>†</label>
        <p>The authors wish it to be known that, in their opinion, Mujeen Sung and Minbyul Jeong should be regarded as Joint First Authors.</p>
      </fn>
      <fn id="btac598-FM2">
        <label>‡</label>
        <p>The authors wish it to be known that, in their opinion, Jinhyuk Lee and Jaewoo Kang should be regarded as Joint Last Authors.</p>
      </fn>
      <corresp id="btac598-cor1">To whom correspondence should be addressed. <email>jinhyuk_lee@korea.ac.kr</email> or <email>kangj@korea.ac.kr</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>10</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-09-02">
      <day>02</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>02</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>20</issue>
    <fpage>4837</fpage>
    <lpage>4839</lpage>
    <history>
      <date date-type="received">
        <day>06</day>
        <month>1</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>09</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>19</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>31</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>21</day>
        <month>9</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac598.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title> </title>
        <p>In biomedical natural language processing, named entity recognition (NER) and named entity normalization (NEN) are key tasks that enable the automatic extraction of biomedical entities (e.g. diseases and drugs) from the ever-growing biomedical literature. In this article, we present BERN2 (Advanced Biomedical Entity Recognition and Normalization), a tool that improves the previous neural network-based NER tool by employing a multi-task NER model and neural network-based NEN models to achieve much faster and more accurate inference. We hope that our tool can help annotate large-scale biomedical texts for various tasks such as biomedical knowledge graph construction.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>Web service of BERN2 is publicly available at <ext-link xlink:href="http://bern2.korea.ac.kr" ext-link-type="uri">http://bern2.korea.ac.kr</ext-link>. We also provide local installation of BERN2 at <ext-link xlink:href="https://github.com/dmis-lab/BERN2" ext-link-type="uri">https://github.com/dmis-lab/BERN2</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Research Foundation of Korea</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003725</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>NRF-2020R1A2C3010638</award-id>
        <award-id>NRF-2014M3C9A3063541</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ministry of Health &amp; Welfare, Republic of Korea</institution>
          </institution-wrap>
        </funding-source>
        <award-id>HR20C0021</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>ICT Creative Consilience program</institution>
          </institution-wrap>
        </funding-source>
        <award-id>IITP-2021-0-01819</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>IITP (Institute for Information &amp; communications Technology Planning &amp; Evaluation</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="3"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Biomedical text mining is becoming increasingly important due to the constantly growing volume of biomedical texts. From these texts, biomedical entities of various types such as gene/protein or disease can be automatically annotated with named entity recognition (NER) and linked to concept unique IDs (CUIs) with named entity normalization (NEN). Many biomedical text mining tools combine NER and NEN in a single pipeline to support large-scale annotation of biomedical texts. One popular example is PubTator Central (PTC) (<xref rid="btac598-B17" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2019</xref>). With recent progress in biomedical language models (<xref rid="btac598-B3" ref-type="bibr">Gu <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac598-B9" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2020</xref>), biomedical text mining tools that are more accurate than PTC have been introduced (<xref rid="btac598-B4" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2019</xref>) and they are often used for downstream tasks such as biomedical knowledge graph construction (<xref rid="btac598-B18" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2020</xref>) and biomedical search engine (<xref rid="btac598-B6" ref-type="bibr">Köksal <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
    <p>However, existing biomedical text mining tools for biomedical NER, which often come with NEN, have several limitations. First, they provide annotations for a small number of biomedical entity types (e.g. five entity types in <xref rid="btac598-B14" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>). Second, they often use multiple single-type NER models to annotate entities of different types (<xref rid="btac598-B4" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2019</xref>), which require larger Graphics Processing Unit (GPU) memory for parallelization, but are very slow at inference when used sequentially. Lastly, many tools employ NEN models based on pre-defined rules with dictionaries (<xref rid="btac598-B4" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac598-B17" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2019</xref>), but they cannot cover complex morphological variations of biomedical entity mentions. For instance, a simple dictionary-matching NEN model cannot normalize ‘oxichlorochine’ into its canonical mention ‘hydroxychloroquine’ (mesh: D006886) unless the dictionary explicitly contains the mention ‘oxichlorochine’.</p>
    <p>As shown in <xref rid="btac598-T1" ref-type="table">Table 1</xref>, our proposed tool, BERN2 (Advanced Biomedical Entity Recognition and Normalization) addresses these challenges by (i) supporting nine biomedical entity types, which are the largest among other commonly used tools listed in the table, (ii) dramatically reducing the annotation time by using a single multi-task NER model and (iii) combining rule-based and neural network-based NEN models to improve the quality of entity normalization. We provide BERN2 as a web service with RESTful Application Programming Interface (API) and also allow users to locally install it. The usage of BERN2 is detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Data A</xref>.</p>
    <table-wrap position="float" id="btac598-T1">
      <label>Table 1.</label>
      <caption>
        <p>Comparison of different biomedical text mining tools</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="center" span="1"/>
          <col valign="top" align="center" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Tool</th>
            <th rowspan="1" colspan="1">NER →NEN</th>
            <th rowspan="1" colspan="1">Supported types</th>
            <th colspan="2" rowspan="1">Sec/abstract<hr/></th>
          </tr>
          <tr>
            <th rowspan="1" colspan="1"/>
            <th rowspan="1" colspan="1"/>
            <th rowspan="1" colspan="1"/>
            <th rowspan="1" colspan="1">Plain text</th>
            <th rowspan="1" colspan="1">PMID</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">PTC</td>
            <td rowspan="1" colspan="1">ML → Rule</td>
            <td rowspan="1" colspan="1">Ge/Di/Dr/Sp/Mu/CL</td>
            <td rowspan="1" colspan="1">N/A</td>
            <td rowspan="1" colspan="1">0.86 ± 0.20<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <sc>Hun</sc>
              <sc>Flair</sc>
            </td>
            <td rowspan="1" colspan="1">Neural → N/A</td>
            <td rowspan="1" colspan="1">Ge/Di/Dr/Sp/CL</td>
            <td rowspan="1" colspan="1">0.53 ± 0.24</td>
            <td rowspan="1" colspan="1">N/A</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">BERN</td>
            <td rowspan="1" colspan="1">Neural → Rule</td>
            <td rowspan="1" colspan="1">Ge/Di/Dr/Sp/Mu</td>
            <td rowspan="1" colspan="1">1.08 ± 0.31</td>
            <td rowspan="1" colspan="1">1.43 ± 0.19</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">BERN2</td>
            <td rowspan="1" colspan="1">Neural → Rule and Neural</td>
            <td rowspan="1" colspan="1">Ge/Di/Dr/Sp/Mu/CL/CT/DNA/RNA</td>
            <td rowspan="1" colspan="1">
              <bold>0.33 ± 0.29</bold>
            </td>
            <td rowspan="1" colspan="1">
              <bold>0.03 ± 0.09</bold>
            </td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tblfn1">
          <p><italic toggle="yes">Note</italic>: ML, machine learning models such as HMM, CRF, etc.; Rule, dictionary and rule-based models; Neural, neural network-based models; Ge, gene/protein; Di, disease; Dr, drug/chemical; Sp, species; Mu, mutation; CL, cell line; CT, cell type; Sec/Abstract, average time in second (± std.) taken to annotate a PubMed abstract; computed over randomly sampled 30K abstracts using local installation.</p>
        </fn>
        <fn id="tblfn2">
          <label>a</label>
          <p>Measured from web service due to the lack of local installation support.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>BERN2 is designed to recognize and normalize nine types of biomedical entities (gene/protein, disease, drug/chemical, species, mutation, cell line, cell type, DNA and RNA). As illustrated in <xref rid="btac598-F1" ref-type="fig">Figure 1</xref>, we support two input formats: plain text and PubMed ID (PMID).</p>
    <fig position="float" id="btac598-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>An overview of BERN2. Given plain text or a PubMed ID (PMID), BERN2 recognizes nine biomedical entity types and normalizes each concept</p>
      </caption>
      <graphic xlink:href="btac598f1" position="float"/>
    </fig>
    <p>When plain text is given, a multi-task NER model of BERN2 first extracts the exact positions and types of biomedical named entities in the text (see Section 2.1 for a detailed description of the multi-task NER model). For example, for plain text ‘… tumor growth through arginine…,’ our NER model locates the positions of ‘tumor’ and ‘arginine’ in the text and classifies them as disease and drug/chemical types, respectively. These named entities are then normalized into corresponding CUIs in designated dictionaries by our NEN models. We use hybrid NEN models for three entity types (gene/protein, disease and drug/chemical) to increase the number of entities being normalized correctly (see Section 2.2 for a detailed description of the hybrid NEN model). For example, our NEN model normalizes a gene/protein mention ‘atg7’ into ‘NCBIGene: 10533’ and a drug/chemical mention ‘arginine’ into ‘mesh: D001120’.</p>
    <p>We use the plain text annotation mode described above to pre-compute the annotations of PubMed articles (abstracts only), which are stored in an external database. Hence, when PMIDs are given, BERN2 returns pre-computed annotations from its database whenever possible, which is much faster than annotating the plain text as shown in <xref rid="btac598-T1" ref-type="table">Table 1</xref>. If an abstract of a PubMed article has not been pre-computed (i.e. not found in the database), BERN2 annotates it and stores the annotation results in the database.</p>
    <sec>
      <title>2.1 Multi-task named entity recognition</title>
      <p>While BERN (<xref rid="btac598-B4" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2019</xref>) employs accurate NER models based on a pre-trained biomedical language model (<xref rid="btac598-B9" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2020</xref>), it uses multiple single-type NER models (i.e. four BioBERT models to annotate four entity types except for mutation), which requires a large amount of GPU memory for parallelization but makes the entire pipeline slow without such parallel inference. BERN2 adopts a multi-task NER model that supports efficient parallel inference for eight entity types (except for mutation).</p>
      <p>Following <xref rid="btac598-B13" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> (2019)</xref>, our multi-task NER model consists of a shared backbone model and a separate task-specific layer for each entity type. We use Bio-LM (<xref rid="btac598-B10" ref-type="bibr">Lewis <italic toggle="yes">et al.</italic>, 2020</xref>), a state-of-the-art pre-trained biomedical language model, as our backbone model and use two-layer MLP with ReLU activation as a task-specific layer. Each task-specific layer outputs probabilities of whether each token is the beginning, inside or outside (BIO) of named entities. During training, we merge five training sets of all entity types. We use BC2GM (<xref rid="btac598-B11" ref-type="bibr">Smith <italic toggle="yes">et al.</italic>, 2008</xref>) for gene/protein, NCBI-disease (<xref rid="btac598-B1" ref-type="bibr">Doğan <italic toggle="yes">et al.</italic>, 2014</xref>) for disease, BC4CHEMD (<xref rid="btac598-B7" ref-type="bibr">Krallinger <italic toggle="yes">et al.</italic>, 2015</xref>) for drug/chemical, Linnaeus (<xref rid="btac598-B2" ref-type="bibr">Gerner <italic toggle="yes">et al.</italic>, 2010</xref>) for species and JNLPBA (<xref rid="btac598-B5" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2004</xref>) for cell line, cell type, DNA and RNA.</p>
      <p>At inference, our NER model takes an input text and outputs predictions from all task-specific layers in parallel. In fact, the multi-task NER model in BERN2 only consumes a small amount of GPU memory that is on par with using a single pre-trained LM since having multiple task-specific layers—two-layer MLP each—only adds a small number of parameters. This also allows us to adopt a larger pre-trained language model on a single GPU, which often outperforms smaller models. In this work, we use the large version of Bio-LM. (We use the <italic toggle="yes">RoBERTa-large-PM-M3-Voc</italic> checkpoint from <ext-link xlink:href="https://github.com/facebookresearch/bio-lm" ext-link-type="uri">https://github.com/facebookresearch/bio-lm</ext-link>.) Compared to BERN whose NER model has approximately 432M parameters (i.e. four LMs with 108M parameters each) and takes 600 ms to annotate four entity types, our multi-task NER model in BERN2 has approximately 365M parameters (i.e. a single LM with 365M parameters) and takes 200 ms to annotate eight entity types while also enjoying the expressiveness of a large pre-trained LM. Note that due to the lack of public training sets for mutations, both BERN and BERN2 use tmVar2.0 (<xref rid="btac598-B16" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2018</xref>) for mutation NER. We refer interested readers to <xref rid="sup1" ref-type="supplementary-material">Supplementary Data B</xref> for a detailed description of the NER model used by BERN2.</p>
    </sec>
    <sec>
      <title>2.2 Hybrid named entity normalization</title>
      <p>Rule-based NEN models that are often used by biomedical text mining tools (<xref rid="btac598-B4" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2019</xref>) cannot handle all morphological variations of biomedical named entities. Instead, <xref rid="btac598-B12" ref-type="bibr">Sung <italic toggle="yes">et al.</italic> (2020)</xref> introduce BioSyn, a neural network-based biomedical NEN model that leverages vector representations of entities to cover such variations. Specifically, BioSyn builds a dictionary embedding matrix from an entity encoder, where each row vector denotes the representation of an entity name in the dictionary. The input mention embedding is computed from the same entity encoder and BioSyn retrieves an entity name from the dictionary matrix that has the highest inner product score with the input mention embedding. Each mention is then normalized into the CUI of the retrieved entity.</p>
      <p>BERN2 first tries rule-based normalization on each named entity and only the ones that were not normalized by the rule-based models are then normalized by BioSyn. We employ this hybrid approach for three entity types (gene/protein, disease and drug/chemical) where fine-tuned BioSyn is available. (We use the checkpoints <italic toggle="yes">biosyn-sapbert-bc2gn</italic> for gene/protein, <italic toggle="yes">biosyn-sapbert-bc5cdr-disease</italic> for disease and <italic toggle="yes">biosyn-sapbert-bc5cdr-chemical</italic> for drug/chemical from <ext-link xlink:href="https://github.com/dmis-lab/BioSyn" ext-link-type="uri">https://github.com/dmis-lab/BioSyn</ext-link>.) Other types are processed by rule-based models. With our hybrid NEN model, we safely increase the number of correctly normalized entities. For the sake of users, we also show whether each entity has been normalized by the rule-based NEN model or BioSyn in the annotation results. <xref rid="sup1" ref-type="supplementary-material">Supplementary Data C</xref> provides details of our normalization model.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Named entity recognition</title>
      <p><xref rid="btac598-T2" ref-type="table">Table 2</xref> shows the NER performance of different biomedical text mining tools including PTC (<xref rid="btac598-B17" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2019</xref>), <sc>Hun</sc><sc>Flair</sc> (<xref rid="btac598-B14" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2021</xref>), BERN (<xref rid="btac598-B4" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2019</xref>) and BERN2. While BERN2 supports the largest number of entity types, it also outperforms other tools on most types except on the species type.</p>
      <table-wrap position="float" id="btac598-T2">
        <label>Table 2.</label>
        <caption>
          <p>Results on biomedical NER benchmarks</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">Type</th>
              <th rowspan="1" colspan="1">PTC</th>
              <th rowspan="1" colspan="1">
                <sc>Hun</sc>
                <sc>Flair</sc>
              </th>
              <th rowspan="1" colspan="1">BERN</th>
              <th rowspan="1" colspan="1">BERN2</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">BC2GM</td>
              <td rowspan="1" colspan="1">Gene/protein</td>
              <td rowspan="1" colspan="1">78.8</td>
              <td rowspan="1" colspan="1">77.9</td>
              <td rowspan="1" colspan="1">83.4</td>
              <td rowspan="1" colspan="1">
                <bold>83.7</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">NCBI-disease</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">81.5</td>
              <td rowspan="1" colspan="1">85.4</td>
              <td rowspan="1" colspan="1">88.3</td>
              <td rowspan="1" colspan="1">
                <bold>88.6</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC4CHEMD</td>
              <td rowspan="1" colspan="1">Drug/chemical</td>
              <td rowspan="1" colspan="1">86.7</td>
              <td rowspan="1" colspan="1">88.9</td>
              <td rowspan="1" colspan="1">91.2</td>
              <td rowspan="1" colspan="1">
                <bold>92.8</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">tmVar2</td>
              <td rowspan="1" colspan="1">Mutation</td>
              <td rowspan="1" colspan="1">
                <bold>93.7</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td rowspan="1" colspan="1">
                <bold>93.7</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>93.7</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Linnaeus</td>
              <td rowspan="1" colspan="1">Species</td>
              <td rowspan="1" colspan="1">85.6</td>
              <td rowspan="1" colspan="1">
                <bold>93.2</bold>
              </td>
              <td rowspan="1" colspan="1">88.0</td>
              <td rowspan="1" colspan="1">92.7</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">JNLPBA</td>
              <td rowspan="1" colspan="1">Cell line</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td rowspan="1" colspan="1">64.9</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td rowspan="1" colspan="1">
                <bold>78.6</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Cell type</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td rowspan="1" colspan="1">
                <bold>80.7</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">DNA</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td rowspan="1" colspan="1">
                <bold>77.8</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">RNA</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
              <td rowspan="1" colspan="1">
                <bold>76.5</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic toggle="yes">Note</italic>: F1 score is reported.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.2 Named entity normalization</title>
      <p><xref rid="btac598-T3" ref-type="table">Table 3</xref> shows the normalization accuracy of the BC2GN (gene/protein) and BC5CDR (disease and drug/chemical) test sets. Again, BERN2 that uses hybrid NEN (rule-based + BioSyn) outperforms other tools.</p>
      <table-wrap position="float" id="btac598-T3">
        <label>Table 3.</label>
        <caption>
          <p>Results on biomedical NEN benchmarks</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">Type</th>
              <th rowspan="1" colspan="1">
                <bold>PTC</bold>
                <xref rid="tblfn6" ref-type="table-fn">
                  <sup>a</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">BERN</th>
              <th rowspan="1" colspan="1">
                <bold>BioSyn</bold>
                <xref rid="tblfn7" ref-type="table-fn">
                  <sup>b</sup>
                </xref>
              </th>
              <th rowspan="1" colspan="1">BERN2</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">BC2GN</td>
              <td rowspan="1" colspan="1">Gene/protein</td>
              <td rowspan="1" colspan="1">93.8</td>
              <td rowspan="1" colspan="1">93.8</td>
              <td rowspan="1" colspan="1">91.3</td>
              <td rowspan="1" colspan="1">
                <bold>95.9</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BC5CDR</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">88.9</td>
              <td rowspan="1" colspan="1">90.7</td>
              <td rowspan="1" colspan="1">93.5</td>
              <td rowspan="1" colspan="1">
                <bold>93.9</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Drug/chemical</td>
              <td rowspan="1" colspan="1">94.1</td>
              <td rowspan="1" colspan="1">92.8</td>
              <td rowspan="1" colspan="1">
                <bold>96.6</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>96.6</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <p><italic toggle="yes">Note</italic>: Accuracy is reported.</p>
          </fn>
          <fn id="tblfn5">
            <p>The highest scores in each row are boldfaced.</p>
          </fn>
          <fn id="tblfn6">
            <label>a</label>
            <p><xref rid="btac598-B15" ref-type="bibr">Wei <italic toggle="yes">et al.</italic> (2015)</xref> for BC2GN and <xref rid="btac598-B8" ref-type="bibr">Leaman and Lu (2016)</xref> for BC5CDR.</p>
          </fn>
          <fn id="tblfn7">
            <label>b</label>
            <p>A single NEN model (not a text mining tool) evaluated on each test set.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this article, we present BERN2, a biomedical text mining tool for accurate and efficient biomedical NER and NEN. With a multi-task NER model and hybrid NEN models, BERN2 outperforms existing biomedical text mining tools while providing annotations more efficiently. We support both web service and local installation of BERN2 for the ease of employing BERN2 in other systems. <xref rid="sup1" ref-type="supplementary-material">Supplementary Data D</xref> provides example usages where BERN can be easily replaced with BERN2.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by National Research Foundation of Korea (NRF-2020R1A2C3010638, NRF-2014M3C9A3063541), the Ministry of Health &amp; Welfare, Republic of Korea (HR20C0021) and the ICT Creative Consilience program (IITP-2021-0-01819) supervised by the IITP (Institute for Information &amp; communications Technology Planning &amp; Evaluation).</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac598_Supplementary_Data</label>
      <media xlink:href="btac598_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac598-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doğan</surname><given-names>R.I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>NCBI disease corpus: a resource for disease name recognition and concept normalization</article-title>. <source>J. Biomed. Informatics</source>, <volume>47</volume>, <fpage>1</fpage>.</mixed-citation>
    </ref>
    <ref id="btac598-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gerner</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>Linnaeus: a species name identification system for biomedical literature</article-title>. <source>BMC Bioinformatics</source>, <volume>11</volume>, <fpage>85</fpage>.<pub-id pub-id-type="pmid">20149233</pub-id></mixed-citation>
    </ref>
    <ref id="btac598-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gu</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2022</year>) <article-title>Domain-specific language model pretraining for biomedical natural language processing</article-title>. <source>ACM Trans. Comput. Healthcare (HEALTH)</source>, <volume>3</volume>, <fpage>1</fpage>–<lpage>23</lpage>.</mixed-citation>
    </ref>
    <ref id="btac598-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>A neural named entity recognition and multi-type normalization tool for biomedical text mining</article-title>. <source>IEEE Access</source>, <volume>7</volume>, <fpage>73729</fpage>–<lpage>73740</lpage>.</mixed-citation>
    </ref>
    <ref id="btac598-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>J.-D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2004</year>) Introduction to the bio-entity recognition task at JNLPBA. In: <italic toggle="yes">Proceedings of the 3rd Clinical Natural Language Processing Workshop, Geneva, Switzerland,</italic> COLING, pp. 73–78.</mixed-citation>
    </ref>
    <ref id="btac598-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Köksal</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Vapur: a search engine to find related protein-compound pairs in covid-19 literature. In: <italic toggle="yes">Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020,</italic> Association for Computational Linguistics.</mixed-citation>
    </ref>
    <ref id="btac598-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krallinger</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>The CHEMDNER corpus of chemicals and drugs and its annotation principles</article-title>. <source>J. Cheminform</source>., <volume>7</volume>, <fpage>S2</fpage>.<pub-id pub-id-type="pmid">25810773</pub-id></mixed-citation>
    </ref>
    <ref id="btac598-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leaman</surname><given-names>R.</given-names></string-name>, <string-name><surname>Lu</surname><given-names>Z.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Taggerone: joint named entity recognition and normalization with semi-Markov models</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>2839</fpage>–<lpage>2846</lpage>.<pub-id pub-id-type="pmid">27283952</pub-id></mixed-citation>
    </ref>
    <ref id="btac598-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>.</mixed-citation>
    </ref>
    <ref id="btac598-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lewis</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Pretrained language models for biomedical and clinical tasks: Understanding and extending the state-of-the-art. In: <italic toggle="yes">Proceedings of the 3rd Clinical Natural Language Processing Workshop,</italic> Association for Computational Linguistics, pp. 146–157.</mixed-citation>
    </ref>
    <ref id="btac598-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Overview of biocreative II gene mention recognition</article-title>. <source>Genome Biol</source>., <volume>9, S2</volume>.</mixed-citation>
    </ref>
    <ref id="btac598-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Sung</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) Biomedical entity representations with synonym marginalization. In: <italic toggle="yes">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</italic>, Association for Computational Linguistics, pp. <fpage>3641</fpage>–<lpage>3650</lpage>.</mixed-citation>
    </ref>
    <ref id="btac598-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Cross-type biomedical named entity recognition with deep multi-task learning</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>1745</fpage>–<lpage>1752</lpage>.<pub-id pub-id-type="pmid">30307536</pub-id></mixed-citation>
    </ref>
    <ref id="btac598-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weber</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Hunflair: an easy-to-use tool for state-of-the-art biomedical named entity recognition</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>2792</fpage>–<lpage>2794</lpage>.</mixed-citation>
    </ref>
    <ref id="btac598-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>C.-H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Gnormplus: an integrative approach for tagging genes, gene families, and protein domains</article-title>. <source>Biomed Res. Int</source>., <volume>2015</volume>, <fpage>918710</fpage>.<pub-id pub-id-type="pmid">26380306</pub-id></mixed-citation>
    </ref>
    <ref id="btac598-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>C.-H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>tmVar 2.0: integrating genomic variant information from literature with dbSNP and ClinVar for precision medicine</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>80</fpage>–<lpage>87</lpage>.<pub-id pub-id-type="pmid">28968638</pub-id></mixed-citation>
    </ref>
    <ref id="btac598-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>C.-H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>PubTator Central: automated concept annotation for biomedical full text articles</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>W587</fpage>–<lpage>W593</lpage>.<pub-id pub-id-type="pmid">31114887</pub-id></mixed-citation>
    </ref>
    <ref id="btac598-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Building a PubMed knowledge graph</article-title>. <source>Sci. Data</source>, <volume>7</volume>, 205.</mixed-citation>
    </ref>
  </ref-list>
</back>
