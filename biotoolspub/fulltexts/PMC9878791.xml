<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9878791</article-id>
    <article-id pub-id-type="publisher-id">5111</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-05111-0</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Gdaphen, R pipeline to identify the most important qualitative and quantitative predictor variables from phenotypic data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Muñiz Moreno</surname>
          <given-names>Maria del Mar</given-names>
        </name>
        <address>
          <email>munizmorenomariadelmar@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gavériaux-Ruff</surname>
          <given-names>Claire</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7049-6900</contrib-id>
        <name>
          <surname>Herault</surname>
          <given-names>Yann</given-names>
        </name>
        <address>
          <email>herault@igbmc.fr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.11843.3f</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 9291</institution-id><institution>Université de Strasbourg, CNRS UMR7104, INSERM U1258, Institut de Génétique, Biologie Moléculaire Et Cellulaire (IGBMC), </institution></institution-wrap>1 Rue Laurent Fries, 67404 Illkirch Graffenstaden, France </aff>
      <aff id="Aff2"><label>2</label>Université de Strasbourg, CNRS, INSERM, CELPHEDIA, PHENOMIN-Institut Clinique de La Souris (ICS), 1 Rue Laurent Fries, 67404 Illkirch Graffenstaden, France </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.26790.3a</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8606</institution-id><institution>Present Address: John P. Hussman Institute for Human Genomics, </institution><institution>University of Miami, Miller School of Medicine, </institution></institution-wrap>Miami, FL 33136 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>26</day>
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>24</volume>
    <elocation-id>28</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">In individuals or animals suffering from genetic or acquired diseases, it is important to identify which clinical or phenotypic variables can be used to discriminate between disease and non-disease states, the response to treatments or sexual dimorphism. However, the data often suffers from low number of samples, high number of variables or unbalanced experimental designs. Moreover, several parameters can be recorded in the same test. Thus, correlations should be assessed, and a more complex statistical framework is necessary for the analysis. Packages already exist that provide analysis tools, but they are not found together, rendering the decision method and implementation difficult for non-statisticians.</p>
      </sec>
      <sec>
        <title>Result</title>
        <p id="Par2">We present Gdaphen, a fast joint-pipeline allowing the identification of most important qualitative and quantitative predictor variables to discriminate between genotypes, treatments, or sex. Gdaphen takes as input behavioral/clinical data and uses a Multiple Factor Analysis (MFA) to deal with groups of variables recorded from the same individuals or anonymize genotype-based recordings. Gdaphen uses as optimized input the non-correlated variables with 30% correlation or higher on the MFA-Principal Component Analysis (PCA), increasing the discriminative power and the classifier’s predictive model efficiency. Gdaphen can determine the strongest variables that predict gene dosage effects thanks to the General Linear Model (GLM)-based classifiers or determine the most discriminative not linear distributed variables thanks to Random Forest (RF) implementation. Moreover, Gdaphen provides the efficacy of each classifier and several visualization options to fully understand and support the results as easily readable plots ready to be included in publications. We demonstrate Gdaphen capabilities on several datasets and provide easily followable vignettes.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Gdaphen makes the analysis of phenotypic data much easier for medical or preclinical behavioral researchers, providing an integrated framework to perform: (1) pre-processing steps as data imputation or anonymization; (2) a full statistical assessment to identify which variables are the most important discriminators; and (3) state of the art visualizations ready for publication to support the conclusions of the analyses. Gdaphen is open-source and freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/munizmom/gdaphen">https://github.com/munizmom/gdaphen</ext-link>, together with vignettes, documentation for the functions and examples to guide you in each own implementation.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-022-05111-0.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>R package</kwd>
      <kwd>Phenotypic data</kwd>
      <kwd>Clinical data</kwd>
      <kwd>Discrimination</kwd>
      <kwd>Generalized linear models</kwd>
      <kwd>Random forest</kwd>
      <kwd>Imputation</kwd>
      <kwd>Model</kwd>
      <kwd>Prediction</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Bootstrapping</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Agence Nationale de la recherche (FR)</institution>
        </funding-source>
        <award-id>ANR-10-IDEX-0002-02</award-id>
        <award-id>ANR-17-EURE-0023</award-id>
        <award-id>ANR 20-SFRI-0012</award-id>
        <award-id>ANR-10-INBS-07</award-id>
        <principal-award-recipient>
          <name>
            <surname>Herault</surname>
            <given-names>Yann</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id>
            <institution>Horizon 2020 Framework Programme</institution>
          </institution-wrap>
        </funding-source>
        <award-id>848077</award-id>
        <principal-award-recipient>
          <name>
            <surname>Herault</surname>
            <given-names>Yann</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par23">In individuals or animal models suffering from a disease or with another condition, the identification of selective discriminating variables is important to understand the differences between disease and non-disease states, to detect the response to treatments or to discern sexual dimorphism. The current behavioral data are generally complex multifactorial datasets. Those datasets may contain plenty of both qualitative and quantitative information, in some cases structured in groups when several features are measured in the same test. The data recorded can include the performance of each individual in the different tests, or the performance of paired or grouped animals in sociability or mating studies, and can contain extensive medical information about phenotypes, weight, health problems and other molecular records such as gene expression.</p>
    <p id="Par24">The analysis of these data allows to get new insights into the genotype–phenotype relationships and identify key behaviors or clinical biomarkers that are more correlated with genotype, disease state or treatment effect. However, the recorded experimental data have specific particularities and often suffers from several problems making the statistical analysis really challenging.</p>
    <p id="Par25">First, small sample size or number of experimental observations increase the error margins and decrease the confidence in the results and the statistical power over the features [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Second, a high number of independent variables referred normally as predictor variables or features, together with the small sample size bring the curse of dimensionality when requiring statistical significance to obtain reliable results and is a challenge due to the high number of features [<xref ref-type="bibr" rid="CR3">3</xref>]. Thus, there is an increase in the dimensions of the analysis and the available data becomes sparse.</p>
    <p id="Par26">Third, a critical point arises when analyzing data produced by unbalanced experimental designs [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>] where for example, the number of observations per group or condition is not balanced or even more, when some variables could not be recorded for all the individuals per group, so there are missing values (often noted as Not available, “NAs”) or when each feature was measured in different individuals that just have in common being members of the same group [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p id="Par27">Fourth, several features can be recorded in the same tests and some within-test features are highly correlated, thus the not-independent features should be identified and removed as part of the feature selection, to not run into a multicollinearity problem [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. This is because highly correlated features do not provide new information and instead will add noise that will weaken the model, and even more when considering low samples sizes. In fact, the coefficient estimates of the features will impact on the dependent variable and will give larger standard errors (increasing the type II error) and reduce the efficiency of the model predictions when applied to a new set of data. In addition, within-test features could belong to different distribution families. Then, it should be considered to apply the appropriate statistical analyses to reach accurate results.</p>
    <p id="Par28">Regarding all these core challenges embedded in the experimental data itself, it is clear that a more complex statistical framework is necessary to identify the most discriminative variables among dependent variables and give them reliable and comparable coefficients of importance.</p>
    <p id="Par29">Currently, there is an array of packages in R programming environment that provide tools and functions targeting different parts of the analysis from data cleaning with NAs imputation (MICE [<xref ref-type="bibr" rid="CR9">9</xref>], amelia [<xref ref-type="bibr" rid="CR10">10</xref>], missForest [<xref ref-type="bibr" rid="CR11">11</xref>], Hmisc [<xref ref-type="bibr" rid="CR12">12</xref>], bcv [<xref ref-type="bibr" rid="CR13">13</xref>]), correlation analyses (Hmisc [<xref ref-type="bibr" rid="CR12">12</xref>], corrplot [<xref ref-type="bibr" rid="CR14">14</xref>], polycor [<xref ref-type="bibr" rid="CR15">15</xref>], caret [<xref ref-type="bibr" rid="CR16">16</xref>]), feature selection (MASS [<xref ref-type="bibr" rid="CR17">17</xref>], caret [<xref ref-type="bibr" rid="CR16">16</xref>], mlr [<xref ref-type="bibr" rid="CR18">18</xref>]), statistical modellization (caret [<xref ref-type="bibr" rid="CR16">16</xref>], glmNet [<xref ref-type="bibr" rid="CR19">19</xref>], randomForest [<xref ref-type="bibr" rid="CR20">20</xref>]) and multifactor analyses (PCAmixdata [<xref ref-type="bibr" rid="CR21">21</xref>], FactoMineR [<xref ref-type="bibr" rid="CR22">22</xref>], factoextra [<xref ref-type="bibr" rid="CR23">23</xref>]). However, they are not found together in a joint-pipeline. Thus, for the biologist and medical community that are non-statisticians with little knowledge about machine learning techniques and functions, it can be difficult to decide and implement these methods. Moreover, in most cases the visualizations produced by existing tools cannot be used in publications as they are difficult to read, explain or customize in both the colors and sizes of the plots.</p>
    <p id="Par30">To address these limitations and answer to the community needs, we developed Gdaphen (Genotype discrimination using phenotypic features), a pipeline in R containing a suite of functions capable of dealing with all the key analytical steps. Gdaphen includes, from preprocessing steps such as data anonymization or imputation of missing values, to feature selection where a new modeling method is implemented based on selecting features contributing more than 30% to explain the variance in the data, and visualization. Gdaphen is freely available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/munizmom/gdaphen">https://github.com/munizmom/gdaphen</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://github.com/YaH44/GDAPHEN">https://github.com/YaH44/GDAPHEN</ext-link>).</p>
    <p id="Par31">Gdaphen was especially designed to be used by the communities working with data collected from (1) genetic models carrying single gene mutations, (2) models with multiple gene modifications like duplications and/or deletions, (3) models carrying a gene dosage mimicking the one observed in diseases like Down syndrome [<xref ref-type="bibr" rid="CR24">24</xref>]. Indeed, Gdaphen includes modelling methods based first on GLMs, to elucidate which variables are discriminative of dosage effects as the method will identify linear relationships between the dependent and explanatory variables. In addition, GLMs allows to model data from the exponential family not limiting all the recorded variables to follow strictly a Gaussian distribution. Second, to identify the best predictor variables even if there is a non-linear relationship between the dependent and explanatory variables, we implemented a machine learning bootstrapping-based algorithm, the random forest classifier.</p>
    <p id="Par32">Next, to overcome the curse of dimensionality in the data imputation, Gdaphen uses another machine learning bootstrapping-based algorithm aregImpute. Gdaphen allows to perform the discrimination analysis using three different models of features. First, Gdaphen considers all the features in a dataset and perform two methods of features selection (1) eliminating the highly correlated variables (2) selecting the variables accounts for more than a certain percentage of the variability in the dataset. Thanks to these multimodal analyses, Gdaphen can provide an in-depth analysis of all the features, focus on the identification of multicollinearity to decipher its biological relevance and assess the necessity, efficiency, and suitability of employing feature selection methods considering the data at hand.</p>
    <p id="Par33">Finally, in the visualization module, Gdaphen allows to resize or choose the colors assigned to each feature or group of features for each model analyzed. The plots produced can be used directly in the publications with good quality and readability. Moreover, as the color representing thoses variables can be chosen, the comparison of results between your different publications and analyses is made easier.</p>
    <p id="Par34">Overall, Gdaphen main goal is to provide the guided computational framework to answer the following questions.<list list-type="order"><list-item><p id="Par35">Assess the efficiency reached by each classifier (GLM or RF), on the three different input datasets, the original dataset carrying highly correlated features and the datasets ready for the analysis generated by performing the two feature selection methods. The feature selection methods help to denoise the data and reach statistically reliable results.</p></list-item><list-item><p id="Par36">Assess feature correlation and provide the statistical assessment for each found correlated pair.</p></list-item><list-item><p id="Par37">Identify the grouped/non-grouped features that are more relevant to discriminate between genotypes, sexes, mouse line backgrounds or treatments effects. And in the case of gene or treatment dosages, identify the features following a linear dosage effect.</p></list-item></list>
In this paper we give an overview of Gdaphen main features (Fig. <xref rid="Fig1" ref-type="fig">1</xref>; Table <xref rid="Tab1" ref-type="table">1</xref>) and show two examples of the application of Gdaphen to phenotypic datasets of mouse models of neuropathic pain. The datasets show increased complexity and some results of the application of GDAPHEN are published as part of the deep statistical analyses performed over the phenotypic characterization of these models [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>].<fig id="Fig1"><label>Fig. 1</label><caption><p>Gdaphen workflow. Scheme highlighting the functionalities that Gdaphen can help to implement. From the data organized with individuals in rows and parameters measured in columns, Gdaphen comprises three modules. The first module deals with data pre-processing to shape the data in the input needed to perform the different analyses. Next, the module Analysis is where MFA, feature selection and classification strategies are performed. Last, the module visualization contains the functions that will generate the plots ready for the publications. As shown in the figure, a dotplot is implemented to show the classifiers results in the importance of each variable to the discrimination of your variable of interest. Then the MFA results are shown using different visualizations</p></caption><graphic xlink:href="12859_2022_5111_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Gdaphen goals and more relevant features described for each module: pre-processing, analysis and visualization</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Gdaphen module</th><th align="left">Step</th><th align="left">Goal</th><th align="left">Relevant features</th></tr></thead><tbody><tr><td align="left">Pre-processing</td><td align="left">Pre-processing</td><td align="left">Prepare the data for the analysis</td><td align="left"><p>Anonymization of the samples/ individuals in case we work with human datasets. Renaming the identifiers, noted as "Ind" of each animal if there are duplicated when considered per genotype/sex</p><p>Imputation of NAs using two methods (a) the mean if only one value is mising. (b) Using aregImpute from Hmisc package [<xref ref-type="bibr" rid="CR12">12</xref>] to perform a Multiple Imputation using Additive Regression, Bootstrapping, and Predictive Mean Matching</p><p>Removal of quantitative features with less than 3 unique values</p><p>Removal of qualitative features with less than two factors</p><p>Scaling of the data to standardize the features</p></td></tr><tr><td align="left">Analysis</td><td align="left">Feature selection</td><td align="left">Analyze the correlation in the explanatory variables or features</td><td align="left">Identification of the highly correlated variable setting up a threshold of correlation decided by the experimenter/analyst</td></tr><tr><td align="left"/><td align="left"/><td align="left">Apply methods for pre-selection of features to decrease the noise of the data using the low correlated features</td><td align="left"><p>Methods for pre-selection of features based on:</p><p>(a) The removal of highly correlated features</p><p>(b) A novel approach selection of explanatory features contributing to the discrimination more than a 30% after running the MFA analysis</p></td></tr><tr><td align="left">Analysis</td><td align="left">Multi factor analysis (MFA)</td><td align="left">A multiple factor analysis (MFA) to identify the weight of each feature/group of features to the prediction</td><td align="left"><p>Perform a Multivariate Analysis of Mixed Data using the package PCAmixdata [<xref ref-type="bibr" rid="CR21">21</xref>] the function MFAmix. Some of the outputs of the function are the following:</p><p> Squared loadings</p><p> Eig matrix with eigenvalues</p><p> Results for qualitative or quantitative features apart</p><p> Results for the levels of each qualitative feature</p><p> Coordinates of groups</p><p> Partial individual coordinates</p><p> The coefficients of the linear combinations of features</p></td></tr><tr><td align="left"/><td align="left"/><td align="left">Cosine similarity distances to identify the degree of similarity between the dependent feature and the explanatory features in the PCA dimensional space. Method developed by Escoffier and Pages [<xref ref-type="bibr" rid="CR28">28</xref>]</td><td align="left">Calculate the cosine similarity distance matrixes</td></tr><tr><td align="left">Analysis</td><td align="left">Classification</td><td align="left">Several classifiers’ algorithms to identify the main discriminative explanatory variables some specially elected to identify variables affected by gene dosage as GLM, multiGLM and GLMNet. And a supervised method Random Forest</td><td align="left"><p>Generalized linear regression model, noted as GLM. Computed by the function train of the package caret, setting the parameter method = "glm”</p><p>Penalized Multinomial Regression also called multinomial log-linear models via neural networks method, noted as multiGLM using the function multinom from the package net [<xref ref-type="bibr" rid="CR27">27</xref>]</p><p>Elastic Net method, noted as GLM-Net model, fits a generalized linear model in more than two factors by using a penalization maximum likelihood by combination of the ridge and lasso shrinkages and optimizing the parameter lambda and alfa. Is computed using the function train of the package caret, setting the parameter method = "glmnet”. Requires de package glint and Matrix. The theory is described in Friedman et al. [<xref ref-type="bibr" rid="CR29">29</xref>], Simon et al. [<xref ref-type="bibr" rid="CR30">30</xref>]</p><p>A random forest, noted RF, supervised algorithm. Is computed using the function train of the package caret, setting the parameter method = “rf”</p></td></tr><tr><td align="left">Analysis</td><td align="left"/><td align="left"/><td align="left">Calculi of the mean, SD, error and upper and lower confidence intervals for each feature. Computed using the function ggparcoord from the ggally package [<xref ref-type="bibr" rid="CR31">31</xref>]</td></tr><tr><td align="left">Visualization</td><td align="left">Classification results</td><td align="left"><p>Asses the efficiency of the classifier</p><p>We provide a table and plots where the scaled importance of each feature relativized to the most important one is shown for all the variables</p></td><td align="left">Produce plots and tables containing the scaled importance of each feature after running the glm/glmNet/multiGLM/RF classifiers for the three-input data (features selected and not selected)</td></tr><tr><td align="left">Visualization</td><td align="left">MFA results</td><td align="left">9 plots that show the individual observations distribution in the in the top dimensions of the three main principal components of the PCA (quantitative data)/MCA (qualitative data) and the contribution of each feature or grouped feature in the main principal components</td><td align="left"><p>1.Variance explained by top ten PCA components &amp; cumulative variance</p><p>2.Variables contribution/correlation with the three main principal components: grouped-features correlation partial axes plot</p><p>3.Grouped features correlation to the three main principal components dimensions PCA plot</p><p>4.Observations distribution to the classifier discrimination of qualitative variables in the principal components three top dimensions using 2D and 3D PCA plot visualizations</p><p>5.Squared loadings of the quantitative and qualitative features and the principal components</p><p>6.Features correlation with the three main principal components: all variables’ correlations</p><p>7.Qualitative features discrimination: Qualitative features distribution in the main dimensional spaces</p><p>8.Parallel coordinates plots with scaling and nots scaling of features to visualize the differences between your dependent variable factors</p><p>9.Scaled importance of each variable after running the glm/glmNet/multiGLM/RF classifiers</p></td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <p id="Par38">We now describe in detail Gdaphen framework main features separated in three modules, (1) the pre-processing, (2) the analysis and (3) the visualization modules.</p>
    <sec id="Sec3">
      <title>Pre-processing module</title>
      <sec id="Sec4">
        <title>Data import and preprocessing</title>
        <p id="Par39">The first and more important step is to collect all the phenotypic/clinical features or gene expression measurements variables recorded for each individual and prepare the data for the analysis. As the scientific community finds more suitable to work and manipulate excel files, Gdaphen takes as input data an excel table (file extension “.xlsx”). The file should contain the collected information per individual in rows and all the features or variables recorded in columns. Considering that in some behavioral or clinical tests several variables were recorded in the same tests, we can group those variables with the same “group label” to be able to identify the importance for the discrimination of (1) each variable alone, (2) the overall contribution of the group. This grouping is decided by the analyst and specified in the excel file by using the “::” separator. After the importing step, the input file is stored in a dataframe object that will be subjected to several pre-processing steps to make it complete and ready for running Gdaphen. Gdaphen will help you perform the following tasks:<list list-type="bullet"><list-item><p id="Par40"><italic>Identifier anonymization</italic> Gdaphen will automatically perform this task. The experimenter can choose to perform a data identifier anonymization, creating a unique identifier per subject or instead use the identifiers provided in the input file if they have not duplicated values. In this regard, Gdaphen will consider two individuals have a duplicated identifier, noted as “IND” after regarding the features selected as conditionate like genotype, sex and treatment state.</p></list-item><list-item><p id="Par41"><italic>Imputation of missing values if they exist</italic> There are several methods of imputation of missing values (NAs) widely used in biology. The most common one when only one NA exist, is to impute using the mean or the median for each group of individuals. The group is shaped considering the features selected as conditioning, (like genotype, sex and treatment state). In this case the experimenter can already replace the missing value by his chosen mean/median value. Although we recommend that no imputation method should be used if the number of individuals per group is less than 10 or if the distribution of the values is broad and the standard deviation too high. On these cases, if imputation is really insisted on, it could be better to select a random number considering your sampling size.</p><p id="Par42">Instead, if more than one missing value exist considering the features selected as conditioning, Gdaphen guides you in the examples to implement a method for imputation using Additive Regression, Bootstrapping, and Predictive Mean Matching based on closest random sampling implemented over the aregImpute function from the Hmisc R package [<xref ref-type="bibr" rid="CR12">12</xref>]. One of the interesting features that made us select this method of imputation is that it won’t select the mean or closest to mean values for the group, instead it computes the K number of closer neighbors and randomly chosen, and as many as you need to impute. Introducing this randomness in the selection, allowed us to introduce a model closer to the variability observed on biological replicates. Finally, in this module Gdaphen will automatically perform the tasks below:</p></list-item><list-item><p id="Par43"><italic>Consider quantitative variables with enough different unique values</italic> to calculate minimal errors or standard deviation.</p></list-item><list-item><p id="Par44">Consider qualitative variables with at least two different categories to perform the discriminative analysis.</p></list-item><list-item><p id="Par45"><italic>Standardization of the data</italic> by scaling: this step is necessary as each independent variable has a different range of values that are observed. The re-scaling allows to calculate the contribution of each variable in a comparable way as all variables will have the same range of values observed and/or the same variance.</p></list-item></list></p>
      </sec>
    </sec>
    <sec id="Sec5">
      <title>Analysis module</title>
      <sec id="Sec6">
        <title>Data classification and identification of the most relevant variables to the discrimination</title>
        <p id="Par46">The classification of the data in one of the possible set of “classes” or categories of a dependent variable previously defined by the analyst is the aim of using the classifiers. We decided to use two different classifiers to give answer to two different questions.<list list-type="simple"><list-item><label>A.</label><p id="Par47">A generalized linear model or Lasso and Elastic-Net Regularized Generalized Linear Model, noted as GLM or GLM-Net. Generalized linear models are more suitable to discover variables influenced by gene dosage effects as they will identify which phenotypic variables or “predicting variables”. In addition, GLMs can discriminate since their linear combination is influencing the value of the response variable. Moreover, the use of these models instead of just linear models allow to consider variables following not only a normal distribution but a distribution from the exponential family. This broadens the scope of the features that can be recognized as relevant to the prediction even when the sample size is low.</p></list-item><list-item><label>B.</label><p id="Par48">A random forest, noted RF, is a supervised algorithm that will recognize the most relevant phenotypic variables for the discrimination even though those features may not follow a distribution from the exponential family and even if non-linear relationships exist between the predicting variables and the response variable.</p></list-item></list></p>
        <p id="Par49">Both functions are taken from the caret and nnet R packages [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR27">27</xref>]. As an output a table is obtained with all the predictive variables measures of importance in a relative scale to the most important one that have a maximum value of 100. In addition, this analysis provides an easy visualization in a dot plot shape, where it is straightforward to identify the top discriminant variables for each factor level of the dependent variable.</p>
      </sec>
      <sec id="Sec7">
        <title>Identification of grouped features contributions to the predictions</title>
        <p id="Par50">We included a Multiple Factor Analysis (MFA) to assess the groups or “test-specific” contribution to the discrimination and the weight of each individual/grouped variable to the prediction. This method can deal with groups of variables, both qualitative and quantitative, recorded from the same individuals. The MFA performs a normalization or “weighting” on each group by dividing all the variables belonging to the group by the first eigenvalue coming from the principal component analysis (PCA) of the group. This procedure is done to avoid giving more weight to groups that have recorded a higher number of parameters. Then a PCA on all the weighted variables is applied to (1) identify the correlation between the qualitative or quantitative variables grouped or ungrouped, and the principal component dimensions, (2) identify the individual coordinates of each observation on the PCA dimensions. The method is implemented using the MFAmix function from the PCAmixdata R package [<xref ref-type="bibr" rid="CR21">21</xref>]. Moreover, we chose a vectorization visualization approach as the one implemented in PCAmixdata were we included the cosine similarity distance to further highlight the parameters that follows the same or opposing trajectory for each category of our dependent variable. Thus, those parameters are contributing to the separation of the individual data on the same dimensions defined by their cosine similarity distance.</p>
      </sec>
      <sec id="Sec8">
        <title>Pre-selection of phenotypic variables</title>
        <p id="Par51">Gdaphen was designed to perform the analyses using all the features provided by the experimenter. We noted the results of this analysis as the “full model”. In addition, Gdaphen implements two methods to pre-select the explanatory variables considered.<list list-type="order"><list-item><p id="Par52">The first method runs by default and is advised to use always to identify and remove the highly correlated variables as they lack independency and should not be included in any statistical assessment. The highly correlated variables could be regarded in a table where the correlation matrix is provided highlighting those correlated with a higher index than the one set off by the analyst as a threshold. Identifying correlated variables and further understanding why the correlation exists from a biological point of view can be extremely important to understand the in-depth nature of the variables recorded. In addition, can aid in identifying interesting and biologically meaningful relationships in the data. For example, in mice weight and sex are two variables that are highly correlated. We recommend for downstream classification analyses to not allow variables with a correlation index higher than r = 0.75.</p></list-item><list-item><p id="Par53">The second pre-selection method is an optional one, the main purpose is to reduce the p &gt; n dimensionality problem by reducing the number of explanatory variables (p) compared to the number of observations (n) and increase the data variance explained by the models built by the classifiers to finally strengthen the classification. This pre-selection is done based on the phenotypic variables identified to contribute to the discrimination at more than 30% after running the MFA analysis using all variables without the highly correlated ones and measuring the correlation between the quantitative ungrouped phenotypic variables with the main three dimensions of the PCA. To assure that Gdaphen is performing as good with this model than with the model created using all the variables, we calculated the variance of the data we are able to explain over the first 10 dimensions and the accuracy of the models to answer to how well they can correctly predict each individual observation to the correct class of the dependent variable. The results are visually highlighted in the plot labelled cumulative variance</p></list-item></list></p>
      </sec>
    </sec>
    <sec id="Sec9">
      <title>Visualization module</title>
      <p id="Par54">Resulting from the analysis, Gdaphen generates nine plots that are ready to be included in formal publications and where we leave certain aesthetic parameters to be defined by the analyst to assure the good sizing of their plots depending on the number of explanatory variables and number of categories of dependent variables.<list list-type="order"><list-item><p id="Par55">Grouped features correlation to the three main principal components dimensions partial axes plot. Stored in partialAxes_Plot1 folder</p></list-item><list-item><p id="Par56">Variables contribution/correlation with the three main principal components: grouped-features correlation PCA plot. Stored in groupContribution_Plot2 folder.</p></list-item><list-item><p id="Par57">Observations distribution to the classifier discrimination of qualitative variables in the principal components three top dimensions using 2D and 3D PCA plot visualizations. Stored in individualCoordinates_Plot3 folder</p></list-item><list-item><p id="Par58">Squared loadings of the quantitative &amp; qualitative features and the principal components. Stored in sqload_Plot4 folder.</p></list-item><list-item><p id="Par59">Features correlation with the three main principal components: all variables’ correlations. Stored in quantitativeVarCoordinates_Plot5 folder.</p></list-item><list-item><p id="Par60">Qualitative features discrimination: Qualitative features distribution in the main dimensional spaces. Stored in levelsComponents_Plot6 folder</p></list-item><list-item><p id="Par61">Parallel coordinates plots with scaling and nots scaling of features to visualize the differences between your dependent variable factors. Stored inside the paralelPlot folder.</p></list-item><list-item><p id="Par62">Scaled importance of each variable after running the glm/glmNet/multiGLM/RF classifiers. Stored inside the importance_variables folder.</p></list-item><list-item><p id="Par63">Variance explained by top ten PCA components &amp; cumulative variance. Stored in cumulative Variance folder.</p></list-item></list></p>
      <sec id="Sec10">
        <title>Benchmarking Gdaphen: results</title>
        <p id="Par64">We have run Gdaphen pipeline on the phenotypic data scored for two novel mouse genetic models showing an increased pain behavior (1) <italic>Scn10a</italic><sup><italic>G1662S</italic></sup> Point Mutation, and (2) <italic>Scn9a</italic><sup><italic>R185H</italic></sup> point mutation. We also tested successfully Gdaphen with RT-qPCR data (data not shown, the sample size was low).</p>
        <p id="Par65">A part of the analysis performed on the mouse models for <italic>Scn10a</italic> [<xref ref-type="bibr" rid="CR25">25</xref>] and <italic>Scn9a</italic> [<xref ref-type="bibr" rid="CR26">26</xref>] genes is already available in the publications containing the molecular and phenotypic characterization of these models.<list list-type="order"><list-item><p id="Par66">For the <italic>Scn10a</italic><sup><italic>G1662S</italic></sup> murine model, 112 animals including males and females (57 females and 55 males) and a total of 36 wild-type, 39 heterozygous, 37 homozygous animals were challenged in a phenotypic pipeline and the data from 14 variables was collected for the analysis. These variables included genotype, sex, and 12 phenotypic traits (Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Table S2). None were correlated more than a 75% (Additional file <xref rid="MOESM3" ref-type="media">3</xref>: Table S3) and so we considered there was no strong multicollinearity and proceeded to perform the second feature selection. Seven variables plus sex and genotype were contributing to explain the variability of the dataset in more than a 30% and were thus identified as the most discriminative variables for the three genotypes. When examining the cumulative variance considering the first 10 dimensions (plot cumulative variance, Fig. <xref rid="Fig2" ref-type="fig">2</xref>A, B) we observed that feature selection helps to denoise the data. Indeed, the sel30% model shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>B explained a higher % of the variance of the data (100%) than using the full model containing 14 variables (86%) shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>A. The individual clustering based on genotype and sex, shown more differences between homozygous and wildtypes in the 3D-PCA space and a slight deviation of the center of the clusters when considering female observations or male observations (Fig. <xref rid="Fig2" ref-type="fig">2</xref>C). Indeed, the first two dimensions appear to explain the most the genotype and sex variability (Fig. <xref rid="Fig2" ref-type="fig">2</xref>F, G), where dimension 1 helps more in discriminating the homozygous and dimension 2 and 3 the three genotypes. In fact, it can be clearly seen at the spread clustering that the mutants (homozygous and heterozygous) show differences in comparison with the wild types without producing a strong phenotype difference (Fig. <xref rid="Fig2" ref-type="fig">2</xref>C, F). Looking at the results for classifiers, nine variables (sel30% model) were selected: acetone test, coping reactions and latency on 50 °C hot plate, coping reactions on the 54 °C and 47 °C hot plate, number of paw lifts and jumps on a 5 °C cold plate, sex, tail pressure and von Frey (Fig. <xref rid="Fig2" ref-type="fig">2</xref>D). The classifiers GLM-Net and RF identified von Frey as the main variable for genotype discrimination. In addition, both classifiers also identified acetone test, number of coping reactions and latency time on 50 °C hot plate as key explanatory variables. Tail pressure was only identified by RF. When compared to the full model, the variables highlighted in the sel30 model are emphasized. In addition, tail flick and plantar Hargreaves can help in the discrimination of 2 out of the three genotypes. However, these two variables do not produce a better discrimination analysis considering the variance explained by the models. In support of the classifiers results for the sel30% model, the multi factor analysis (MFA) square loading plot (Fig. <xref rid="Fig2" ref-type="fig">2</xref>H) show that von Frey and number of copying reactions in Hot plate 47 and 50 degrees are the most strongly influencing variables in our dataset in dimensions 1 and 2 and dimensions 2 and 3. Tail pressure was also contributing weakly to those dimensions for the genotype discrimination. In addition, the number of paw-lifts and jumps on the 5 °C cold plate contributes to the discrimination in dimensions 2 and 3. Coping reactions on the 50 °C and 54 °C hot plates contributed the most in dimension 1 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>H). Moreover, examining the correlation between the location of each vectorized variable with each genotype on the principal components by the cosine similarity distance (F<xref rid="Fig2" ref-type="fig">i</xref>g. <xref rid="Fig2" ref-type="fig">2</xref>I), we reach the same conclusions.</p></list-item><list-item><p id="Par67">For <italic>Scn9a</italic><sup><italic>R185H</italic></sup> murine model, 73 animals including males and females (34 females and 39 males) and 24 wild-type, 28 heterozygous and 21 homozygous individuals, were challenged in a specific phenotypic pipeline and the data from 18 variables was collected for the analysis. Those variables included genotype, sex, and 16 phenotypic traits (Additional file <xref rid="MOESM4" ref-type="media">4</xref>: Table S4). None were correlated more than a 75%. Six variables were identified as the most relevant (sel30%) to discriminate the three genotypes. These variables were von Frey, number of paw lifts on cold plate, number of paw reactions and duration of paw reaction in the acetone test, latency in tail flick test and sex (Fig. <xref rid="Fig3" ref-type="fig">3</xref>E). When comparing the cumulative variances (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A, B) the sel30% model explained a higher % of the variance of the data (100%) than using the full model containing 18 variables (84%).</p></list-item></list><fig id="Fig2"><label>Fig. 2</label><caption><p>Example <italic>Scn10a</italic><sup><italic>G1662S</italic></sup> Gdaphen analysis. <bold>A</bold> Variance explained by the top ten PCA components and cumulative variance using the full model containing the 14 variables. <bold>B</bold> Variance explained by the top ten PCA components and cumulative variance using the sel30% model containing 9 variables. <bold>C</bold> 3D-PCA plots showing the individuals clustering on the first 3 dimensions coloring based on each genotype and sex combination. Left panel shows all the genotypes and sexes, the middle plot shows only wild type and heterozygous data, and the right plot shows only wildtype and heterozygous data. <bold>D</bold> Classifiers results for the 9 variables included in the Sel30% model showing the most important variables to genotype discrimination after scaling to the top discriminative one. <bold>E</bold> Classifiers results for all the 14 variables included in the full model showing the most important variables to genotype discrimination after scaling to the top discriminative one. <bold>F</bold> 2D-PCA plots showing the individuals clustering on the first 3 dimensions and colored based on each genotype and sex combination. <bold>G</bold> Categorical variables discrimination component map. The panels show the distribution in 2 dimensions of the categorical variables PCA coordinates calculated in the MFA analysis using the MFAmix function from PCAmixdata R package [<xref ref-type="bibr" rid="CR21">21</xref>]. <bold>H</bold> Square loadings plot with coordinates calculated in the MFA analysis using the MFAmix function from PCAmixdata R package [<xref ref-type="bibr" rid="CR21">21</xref>]. <bold>I</bold> Cosine similarity distance coordinates drawn in each principal component for the selected 30% variables of the analyses calculated by the MFAmix function. The arrow length measures the contribution of each variable to the discrimination on each dimension. Arrows that follow similar trajectories (stronger cosine similarity distance) contribute to the discrimination of the data in the same dimensions</p></caption><graphic xlink:href="12859_2022_5111_Fig2_HTML" id="MO2"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>Example <italic>Scn9a</italic><sup><italic>R185H</italic></sup> Gdaphen analysis. <bold>A</bold> Variance explained by top the ten PCA components and cumulative variance using the full model containing the 14 variables. <bold>B</bold> Variance explained by top the ten PCA components and cumulative variance using the sel30% model containing 9 variables. <bold>C</bold> 3D-PCA plots showing the individuals clustering on the first 3 dimensions and colored based on each genotype and sex combination. Left panel shows all the genotypes and sexes, the middle plot shows only wild-type and heterozygous data, and the right plot shows only wild-type and homozygous data. <bold>D</bold> Classifiers results for the 6 variables included in the Sel30% model showing the most important variables to genotype discrimination after scaling to the top discriminative one. <bold>E</bold> Classifiers results for all the 18 variables included in the full model showing the most important variables to genotype discrimination after scaling to the top discriminative one. <bold>F</bold> 2D-PCA plots showing the individuals clustering on the first 3 dimensions. On the upper panel coloring is based on genotype and sex combinations. On the lower panel coloring is just by genotype. <bold>G</bold> Categorical variables discrimination component map. The panels show the distribution in 2 dimensions of the categorical variables PCA coordinates calculated in the MFA analysis using the MFAmix function from PCAmixdata R package [<xref ref-type="bibr" rid="CR21">21</xref>]. <bold>H</bold> Square loadings plot with coordinates calculated in the MFA analysis using the MFAmix function from PCAmixdata R package [<xref ref-type="bibr" rid="CR21">21</xref>]. <bold>I</bold> Parallel plot showing the non-scaled results of the most influencing variables to the discrimination colored by genotype and sex showing the mean of the variable per group of genotype and sex. In the left parallel, the plot using all the genotypes and sex data. The middle panel shows only heterozygous and wild-types and the right panel only homozygous and wild-types</p></caption><graphic xlink:href="12859_2022_5111_Fig3_HTML" id="MO3"/></fig></p>
        <p id="Par68">The individual clustering based on genotype and sex showed more differences between homozygous and wild-types in the 3D-PCA space with heterozygous in between, and the sex differences was mainly collected in dimension 2 (Fig. <xref rid="Fig3" ref-type="fig">3</xref>C, F). In fact, the first dimension mainly explains the genotype differences with heterozygous clustering in between the other genotypes correlating well with the milder phenotypes observed in this model. In addition, dimension 3 seems to differentiate well the heterozygous from the other two genotypes (Fig. <xref rid="Fig3" ref-type="fig">3</xref>F, G). The classifiers, out of the six variables selected with GLM, did identify the numbers of paw lifts in the cold plate as the most discriminative variable. The other variables important for the discrimination were von Frey, the duration of paw lifts in the acetone test and the tail flicks, all following a linear gene dosage effect. In addition to these, RF also selected the number of paw reactions in the acetone test. Moreover, considering the full model, most of the variables scored in the hot plate could contribute to discriminate between certain pairwise combinations of genotypes. However, considering that those variables did not produce a better discrimination as shown by the variance explained by the models, they were not included in the sel30% model (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A, B). In support of the classifiers results for the sel30% model, the multi factor analysis (MFA) square loading plot (Fig. <xref rid="Fig3" ref-type="fig">3</xref>H) shows that numbers of paw lifts in the cold plate contribute the most in dimensions 1 and 2. The two parameters scored in the acetone test contribute the most and highly similarly in dimension 2 and 3 and just the duration of paw lifts in dimension 1 too. Von Frey contributed only to dimension 1 and tail flick in dimension 1 and 2. Finally, we show also the visual aid that the parallel plot can provide to identify the differences between the scored variables and the genotypes-sex, before or after scaling you can visually discriminate the differences pointing to the same results already discussed above. In addition, we can visually discriminate easily using the parallel plots the most discriminative variables for each condition of interest (Fig. <xref rid="Fig3" ref-type="fig">3</xref>I).</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec11">
    <title>Conclusions/discussion</title>
    <p id="Par69">Taking advantage of the R programming software and the existence of state-of-the-art packages to implement statistical analyses, Gdaphen provides an open-source integrated computational framework for variable discrimination based on phenotypic data that is easily accessible for medical and behavioral researchers. Considering the real challenge and burden the analysis of these data represents for our community, we saw the need to create and distribute this package. Hence Gdaphen, definitively a versatile and adaptable pipeline can become a valuable implementation in the R phenotypic-based statistical research ecosystem.</p>
    <p id="Par70">Moreover, Gdaphen gathers functions for the analysis and visualization of the most important predictor qualitative and quantitative variables for the discrimination between groups. In addition, Gdaphen allows the analysis of grouped variables where the analyst can freely establish the groups. Finally, Gdaphen includes examples to guide you along the pipeline to allow non expert R users to perform their own analyses and take their own decisions depending on their datasets.</p>
    <p id="Par71">A certain limitation of this pipeline exists in the fact that we did not introduce phenotypic regression algorithms to predict the expected phenotypes based on the associations between single nucleotide variants (SNVs) identified by genome-wide association studies (GWAS) data, splicing or expression quantitative trait loci (QTLs) and linkage disequilibrium to mention some. Instead, we decided to implement uniquely classification analyses, because our final goal was to identify categorial responses in the dependent variable as for example genotype, sex, treated versus controls, etc. On these cases we use as explanatory variables data measured from phenotypic analyses, clinical data, histopathological measurements, or genetic information in shape of gene expression measurements coming from RT-qPCR, dd-PCRs or RNA-Seq analyses. Thus, Gdaphen is not suitable in the package current form to address phenotypic regression problems although this can be part of a future implementation.</p>
    <p id="Par72">The relevance of Gdaphen implementation and suitability to provide better insights into the data is without question, as proven in the two example cases shown here. The biological relevance can be even higher if dealing with analyses of multiple diseases or more complex experimental designs containing several variables of interest to study like genotype, sex, different diseases models or treatments versus control cases. Gdaphen can aid in the decision of which variables to score and preserve or disregard in phenotypic pipelines. This will allow to avoid losing experimental time in scoring variables or test that would not have a strong impact in the discrimination. Thus, there is a lot of potential in applying Gdaphen for complex datasets to unravel the biology under them and to establish experiment pipelines.</p>
  </sec>
  <sec id="Sec12">
    <title>Methods</title>
    <sec id="Sec13">
      <title>Implementation</title>
      <p id="Par73">Gdaphen is a R pipeline that allows the identification of the most important predictor qualitative and quantitative variables for a specific dependent variable discrimination in animal models of diseases. The dependent variable can be freely setup by the analyst but should be of categorical nature. As an example, Gdaphen was primary developed to identify the variables most important for genotype discrimination or to uncover the variables more influenced by sex or treatments responses. Gdaphen can be run in RStudio or in shell R. Gdaphen pipeline is freely available on GitHub accompanied by one vignette in classical format and another as an RStudio project object (<ext-link ext-link-type="uri" xlink:href="https://github.com/munizmom/gdaphen">https://github.com/munizmom/gdaphen</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://github.com/YaH44/GDAPHEN">https://github.com/YaH44/GDAPHEN</ext-link>).</p>
      <p id="Par74">Gdaphen main features include the availability in the same pipeline of the functionalities and visualizations as summarized in Fig. <xref rid="Fig1" ref-type="fig">1</xref> and Table<xref rid="Tab1" ref-type="table">1</xref>. The full list of packages and dependencies needed to run Gdaphen is shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1.</p>
    </sec>
    <sec id="Sec14">
      <title>Availability and requirements</title>
      <p id="Par75">Project name: Gdaphen: R pipeline to identify the most important predictor qualitative and quantitative variables from phenotypic data for the discrimination of your variable of interest. Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/munizmom/gdaphen">https://github.com/munizmom/gdaphen</ext-link>. <ext-link ext-link-type="uri" xlink:href="https://github.com/YaH44/GDAPHEN">https://github.com/YaH44/GDAPHEN</ext-link>. Operating system: Mac/Linux/Windows. Programming language: R. Other requirements: Installation of R runtime library R2019a (9.6) and several R packages as specified in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1. Can run in bash R or R Studio. License: GNU GPL 3.0. Any restrictions to use by non-academics: None.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec15">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_5111_MOESM1_ESM.xlsx">
            <caption>
              <p><bold>Additional file 1. Table S1: </bold>List of R packages implemented on Gdaphen.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2022_5111_MOESM2_ESM.xlsx">
            <caption>
              <p><bold>Additional file 2. Table S2: </bold>Input data of <italic>Scn10aG1662</italic> mutant mouse line. Each row shows data from one individual and each column all the features quantified and metadata.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12859_2022_5111_MOESM3_ESM.xlsx">
            <caption>
              <p><bold>Additional file 3. Table S3: </bold>Correlation matrix results for all the variables in the <italic>Scn10aG1662</italic> mutant mouse line. The values shown are r values.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="12859_2022_5111_MOESM4_ESM.xlsx">
            <caption>
              <p><bold>Additional file 4. Table S4: </bold>Input data of <italic>Scn9aR185H</italic> mutant mouse line. Each row shows data from one individual and each column all the features quantified and metadata.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>2D</term>
        <def>
          <p id="Par4">Two dimensions</p>
        </def>
      </def-item>
      <def-item>
        <term>3D</term>
        <def>
          <p id="Par5">Three dimensions</p>
        </def>
      </def-item>
      <def-item>
        <term>NA/NAs</term>
        <def>
          <p id="Par6">Missing values</p>
        </def>
      </def-item>
      <def-item>
        <term>IND</term>
        <def>
          <p id="Par7">Individuals or independent observations</p>
        </def>
      </def-item>
      <def-item>
        <term>DD-PCR</term>
        <def>
          <p id="Par8">Digital droplet polymerase chain reaction</p>
        </def>
      </def-item>
      <def-item>
        <term>GLM</term>
        <def>
          <p id="Par9">Generalized linear model.</p>
        </def>
      </def-item>
      <def-item>
        <term>GLM-Net</term>
        <def>
          <p id="Par10">Lasso and Elastic-Net Regularized Generalized Linear Models</p>
        </def>
      </def-item>
      <def-item>
        <term>GWAS</term>
        <def>
          <p id="Par11">Genome-wide association studies</p>
        </def>
      </def-item>
      <def-item>
        <term>MFA</term>
        <def>
          <p id="Par12">Multi factor analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>Parameters</term>
        <def>
          <p id="Par13">Are the variables scored in the phenotypic test or the genes measured in the gene expression experiments</p>
        </def>
      </def-item>
      <def-item>
        <term>PCA</term>
        <def>
          <p id="Par14">Principal component analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>QTLs</term>
        <def>
          <p id="Par15">Quantitative trait loci</p>
        </def>
      </def-item>
      <def-item>
        <term>R</term>
        <def>
          <p id="Par16">R software for statistical computing</p>
        </def>
      </def-item>
      <def-item>
        <term>RF</term>
        <def>
          <p id="Par17">Random forest</p>
        </def>
      </def-item>
      <def-item>
        <term>RTq-PCR</term>
        <def>
          <p id="Par18">Real time quantitative polymerase chain reaction</p>
        </def>
      </def-item>
      <def-item>
        <term>SNVs</term>
        <def>
          <p id="Par19">Single nucleotide variants</p>
        </def>
      </def-item>
      <def-item>
        <term>Variables</term>
        <def>
          <p id="Par20">Are the parameters scored in the phenotypic test or the genes measured in the gene expression experiments</p>
        </def>
      </def-item>
      <def-item>
        <term>
          <italic>Scn9a</italic>
          <sup>
            <italic>R185H</italic>
          </sup>
        </term>
        <def>
          <p id="Par21">Mouse model with a point mutation identified in chronic pain patients and found to produce a pain phenotype in the mutant mice</p>
        </def>
      </def-item>
      <def-item>
        <term>
          <italic>Scn10a</italic>
          <sup>
            <italic>G1662S</italic>
          </sup>
        </term>
        <def>
          <p id="Par22">Mouse model with a point mutation identified in chronic pain patients and found to produce a pain phenotype in the mutant mice</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank Drs Yaping Xue and Celeste Chidiac for providing their dataset with the phenotypic information. Thanks to Dr Arnaud Duchon for providing several datasets as the RT-qPCR data and phenotypic data for Down syndrome models. Thanks to Corentin Guioullier who tried out the Gdaphen scripts and benchmarked it on Jupyter notebook. Thanks to Gopal Krishna and Valerie Herault for interesting discussions about the working of the package and for testing it.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>MdM and YH conceived the idea. MdM performed conceptual work, designed and developed the pipeline. MdM, CGR and YH provided critical input for the pipeline development. MdM, CGR and YH tested the pipeline. CGR and YH generated the test dataset and MdM analyzed it using the pipeline. MdM, CGR and YH wrote the manuscript and approved the final manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the National Centre for Scientific Research (CNRS), the French National Institute of Health and Medical Research (INSERM), the University of Strasbourg (Unistra), French government funds through the “Agence Nationale de la Recherche” in the framework of the Investissements d’Avenir program by IdEx Unistra (ANR-10-IDEX-0002), a SFRI-STRAT’US project (ANR 20-SFRI-0012), EUR IMCBio (ANR-17-EURE-0023) and INBS PHENOMIN (ANR-10-INBS-07 PHENOMIN and also provided by the Joint Programming Initiative Neurodegenerative Diseases (JPND) multinational research project HEROES (ANR-17-JPCD-0003) to YH. This project received funding from the European Union’s Horizon 2020 research and innovation program under grant agreement GO-DS21 No 848077 to YH. The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>Data and source code in an R package are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/munizmom/gdaphen">https://github.com/munizmom/gdaphen</ext-link><ext-link ext-link-type="uri" xlink:href="https://github.com/YaH44/GDAPHEN">https://github.com/YaH44/GDAPHEN</ext-link></p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par76">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent to publication</title>
      <p id="Par77">Not applicable (public data).</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par78">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Serdar</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Cihan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yücel</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Serdar</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>Sample size, power and effect size revisited: simplified and practical approaches in pre-clinical, clinical and laboratory studies</article-title>
        <source>Biochem Med (Zagreb)</source>
        <year>2021</year>
        <volume>31</volume>
        <issue>1</issue>
        <fpage>010502</fpage>
        <pub-id pub-id-type="doi">10.11613/BM.2021.010502</pub-id>
        <pub-id pub-id-type="pmid">33380887</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Faber</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fonseca</surname>
            <given-names>LM</given-names>
          </name>
        </person-group>
        <article-title>How sample size influences research outcomes</article-title>
        <source>Dental Press J Orthod.</source>
        <year>2014</year>
        <volume>19</volume>
        <issue>4</issue>
        <fpage>27</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1590/2176-9451.19.4.027-029.ebo</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barbour</surname>
            <given-names>DL</given-names>
          </name>
        </person-group>
        <article-title>Precision medicine and the cursed dimensions</article-title>
        <source>NPJ Digit Med</source>
        <year>2019</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>4</fpage>
        <pub-id pub-id-type="doi">10.1038/s41746-019-0081-5</pub-id>
        <pub-id pub-id-type="pmid">31304354</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vanhoeyveld</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Martens</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Imbalanced classification in sparse and large behaviour datasets</article-title>
        <source>Data Min Knowl Discov</source>
        <year>2018</year>
        <volume>32</volume>
        <issue>1</issue>
        <fpage>25</fpage>
        <lpage>82</lpage>
        <pub-id pub-id-type="doi">10.1007/s10618-017-0517-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Cnudde</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ramon</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Martens</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Provost</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Deep learning on big, sparse</article-title>
        <source>Behav Data Big Data</source>
        <year>2019</year>
        <volume>7</volume>
        <issue>4</issue>
        <fpage>286</fpage>
        <lpage>307</lpage>
        <pub-id pub-id-type="doi">10.1089/big.2019.0095</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rubin</surname>
            <given-names>LH</given-names>
          </name>
          <name>
            <surname>Witkiewitz</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>St Andre</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Reilly</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Methods for handling missing data in the behavioral neurosciences: don’t throw the baby rat out with the bath water</article-title>
        <source>J Undergrad Neurosci Educ</source>
        <year>2007</year>
        <volume>5</volume>
        <issue>2</issue>
        <fpage>A71</fpage>
        <lpage>A77</lpage>
        <pub-id pub-id-type="pmid">23493038</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mukaka</surname>
            <given-names>MM</given-names>
          </name>
        </person-group>
        <article-title>Statistics corner: a guide to appropriate use of correlation coefficient in medical research</article-title>
        <source>Malawi Med J</source>
        <year>2012</year>
        <volume>24</volume>
        <issue>3</issue>
        <fpage>69</fpage>
        <lpage>71</lpage>
        <pub-id pub-id-type="pmid">23638278</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Freckleton</surname>
            <given-names>RP</given-names>
          </name>
        </person-group>
        <article-title>Dealing with collinearity in behavioural and ecological data: model averaging and the problems of measurement error</article-title>
        <source>Behav Ecol Sociobiol</source>
        <year>2011</year>
        <volume>65</volume>
        <issue>1</issue>
        <fpage>91</fpage>
        <lpage>101</lpage>
        <pub-id pub-id-type="doi">10.1007/s00265-010-1045-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>van Buuren</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Groothuis-Oudshoorn</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Mice: multivariate imputation by chained equations in R</article-title>
        <source>J Stat Softw.</source>
        <year>2011</year>
        <volume>45</volume>
        <issue>3</issue>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.18637/jss.v045.i03</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Honaker</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>King</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Blackwell</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Amelia II: a program for missing data</article-title>
        <source>J Stat Softw.</source>
        <year>2011</year>
        <volume>45</volume>
        <issue>7</issue>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.18637/jss.v045.i07</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Stekhoven DJ, Bühlmann P. MissForest—nonparametric missing value imputation for mixed-type data. 2011. Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/missForest/missForest.pdf">https://cran.r-project.org/web/packages/missForest/missForest.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Harrell FE. Hmisc: a package of miscellaneous R functions. 2020. Available from: <ext-link ext-link-type="uri" xlink:href="http://biostat.mc.vanderbilt.edu/Hmisc/">http://biostat.mc.vanderbilt.edu/Hmisc/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Perry PO. bcv: cross-validation for the SVD (bi-cross-validation). CRAN [Internet]. 2009. Available from: <ext-link ext-link-type="uri" xlink:href="https://rdrr.io/cran/bcv/man/bcv-package.html">https://rdrr.io/cran/bcv/man/bcv-package.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Wei T, Simko V. R package “corrplot”: visualization of a correlation matrix. 2021. Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/corrplot/corrplot.pdf">https://cran.r-project.org/web/packages/corrplot/corrplot.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Fox J. Polycor: polychoric and polyserial correlations. 2022. Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/polycor/index.html">https://cran.r-project.org/web/packages/polycor/index.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuhn</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Building predictive models in R using the caret package</article-title>
        <source>J Stat Softw.</source>
        <year>2008</year>
        <volume>28</volume>
        <issue>5</issue>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.18637/jss.v028.i05</pub-id>
        <pub-id pub-id-type="pmid">27774042</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Venables</surname>
            <given-names>WN</given-names>
          </name>
          <name>
            <surname>Ripley</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <source>Modern applied statistics with S (statistics and computing)</source>
        <year>2002</year>
        <edition>4</edition>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bischl</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Lang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kotthoff</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Schiffner</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Richter</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Studerus</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>mlr: machine learning in R</article-title>
        <source>J Mach Learn Res</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>170</issue>
        <fpage>1</fpage>
        <lpage>5</lpage>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Simon</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Regularization paths for Cox’s proportional hazards model via coordinate descent</article-title>
        <source>J Stat Softw.</source>
        <year>2011</year>
        <volume>39</volume>
        <issue>5</issue>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.18637/jss.v039.i05</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Liaw A, Wiener M. Classification and regression by randomForest. 2002. Available from: <ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/doc/Rnews/">http://CRAN.R-project.org/doc/Rnews/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Chavent M, Kuentz-Simonet V, Labenne A, Saracco J. Multivariate analysis of mixed data: the R package PCAmixdata. 2014. Available from: 10.48550/arXiv.1411.4911.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lê</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Josse</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Husson</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>FactoMineR: an R package for multivariate analysis</article-title>
        <source>J Stat Softw.</source>
        <year>2008</year>
        <volume>25</volume>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.18637/jss.v025.i01</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Kassambara A, Mundt F. Factoextra: extract and visualize the results of multivariate data analyses. 2020. Available from: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=factoextra">https://CRAN.R-project.org/package=factoextra</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duchon</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Muniz Moreno</surname>
            <given-names>MDM</given-names>
          </name>
          <name>
            <surname>Martin Lorenzo</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Silva de Souza</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Chevalier</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Nalesso</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multi-influential genetic interactions alter behaviour and cognition through six main biological cascades in down syndrome mouse models</article-title>
        <source>Hum Mol Genet.</source>
        <year>2021</year>
        <volume>30</volume>
        <issue>9</issue>
        <fpage>771</fpage>
        <lpage>88</lpage>
        <pub-id pub-id-type="doi">10.1093/hmg/ddab012</pub-id>
        <pub-id pub-id-type="pmid">33693642</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chidiac</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Xue</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Muniz Moreno</surname>
            <given-names>MDM</given-names>
          </name>
          <name>
            <surname>Bakr Rasheed</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Lorentz</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Birling</surname>
            <given-names>MC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The human SCN10AG1662S point mutation established in mice impacts on mechanical, heat, and cool sensitivity</article-title>
        <source>Front Pharmacol.</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.3389/fphar.2021.780132</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xue</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Kremer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Muniz Moreno</surname>
            <given-names>MDM</given-names>
          </name>
          <name>
            <surname>Chidiac</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lorentz</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Birling</surname>
            <given-names>MC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The human SCN9AR185H point mutation induces pain hypersensitivity and spontaneous pain in mice</article-title>
        <source>Front Mol Neurosci.</source>
        <year>2022</year>
        <volume>15</volume>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.3389/fnmol.2022.913990</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Ripley BD, Venables WN. nnet: feed-forward neural networks and multinomial log-linear models. 2022; Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/nnet/nnet.pdf">https://cran.r-project.org/web/packages/nnet/nnet.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Escoffier B, Pages J. Analyse factorielle simple et multiple. DUNOD; 1983.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Friedman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Regularization paths for generalized linear models via coordinate descent</article-title>
        <source>J Stat Softw</source>
        <year>2010</year>
        <volume>33</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="doi">10.18637/jss.v033.i01</pub-id>
        <pub-id pub-id-type="pmid">20808728</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Simon</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>A sparse-group lasso</article-title>
        <source>J Comput Graph Stat</source>
        <year>2013</year>
        <volume>22</volume>
        <issue>2</issue>
        <fpage>231</fpage>
        <lpage>245</lpage>
        <pub-id pub-id-type="doi">10.1080/10618600.2012.681250</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Schloerke B, Cook D, Larmarange J, Briatte F. Ggally: extension to ggplot2. 2021. Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/GGally/GGally.pdf">https://cran.r-project.org/web/packages/GGally/GGally.pdf</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
