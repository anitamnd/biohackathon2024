<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Med Imaging</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Med Imaging</journal-id>
    <journal-title-group>
      <journal-title>BMC Medical Imaging</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2342</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9308199</article-id>
    <article-id pub-id-type="publisher-id">849</article-id>
    <article-id pub-id-type="doi">10.1186/s12880-022-00849-8</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SAFARI: shape analysis for AI-segmented images</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Fernández</surname>
          <given-names>Esteban</given-names>
        </name>
        <address>
          <email>esteban.fernandezmorales@utdallas.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Shengjie</given-names>
        </name>
        <address>
          <email>shengjie.yang@utsouthwestern.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chiou</surname>
          <given-names>Sy Han</given-names>
        </name>
        <address>
          <email>schiou@utdallas.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Moon</surname>
          <given-names>Chul</given-names>
        </name>
        <address>
          <email>chulm@mail.smu.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Cong</given-names>
        </name>
        <address>
          <email>cong.zhang3@utdallas.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yao</surname>
          <given-names>Bo</given-names>
        </name>
        <address>
          <email>bo.yao@utsouthwestern.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xiao</surname>
          <given-names>Guanghua</given-names>
        </name>
        <address>
          <email>guanghua.xiao@utsouthwestern.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1020-3050</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Qiwei</given-names>
        </name>
        <address>
          <email>qiwei.li@utdallas.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.267323.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 2151 7939</institution-id><institution>Department of Mathematical Sciences, </institution><institution>The University of Texas at Dallas, </institution></institution-wrap>Richardson, TX USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.267313.2</institution-id><institution-id institution-id-type="ISNI">0000 0000 9482 7121</institution-id><institution>Quantitative Biomedical Research Center, Department of Population and Data Sciences, </institution><institution>The University of Texas Southwestern Medical Center, </institution></institution-wrap>Dallas, TX USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.263864.d</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7929</institution-id><institution>Department of Statistical Science, </institution><institution>Southern Methodist University, </institution></institution-wrap>Dallas, TX USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>22</volume>
    <elocation-id>129</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>5</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>1</day>
        <month>7</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Recent developments to segment and characterize the regions of interest (ROI) within medical images have led to promising shape analysis studies. However, the procedures to analyze the ROI are arbitrary and vary by study. A tool to translate the ROI to analyzable shape representations and features is greatly needed.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We developed SAFARI (shape analysis for AI-segmented images), an open-source R package with a user-friendly online tool kit for ROI labelling and shape feature extraction of segmented maps, provided by AI-algorithms or manual segmentation. We demonstrated that half of the shape features extracted by SAFARI were significantly associated with survival outcomes in a case study on 143 consecutive patients with stage I–IV lung cancer and another case study on 61 glioblastoma patients.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">SAFARI is an efficient and easy-to-use toolkit for segmenting and analyzing ROI in medical images. It can be downloaded from the comprehensive R archive network (CRAN) and accessed at <ext-link ext-link-type="uri" xlink:href="https://lce.biohpc.swmed.edu/safari/">https://lce.biohpc.swmed.edu/safari/</ext-link>.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12880-022-00849-8.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Medical imaging</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Shape representations</kwd>
      <kwd>Shape descriptors</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>1R01GM140012</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004917</institution-id>
            <institution>Cancer Prevention and Research Institute of Texas</institution>
          </institution-wrap>
        </funding-source>
        <award-id>RP190107</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>1R01GM141519</award-id>
        <principal-award-recipient>
          <name>
            <surname>Xiao</surname>
            <given-names>Guanghua</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000121</institution-id>
            <institution>Division of Mathematical Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2210912</award-id>
        <principal-award-recipient>
          <name>
            <surname>Li</surname>
            <given-names>Qiwei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>National Institutes of Health</institution>
        </funding-source>
        <award-id>1R01DE030656</award-id>
        <award-id>1U01CA249245</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>National Institutes of Health</institution>
        </funding-source>
        <award-id>2P30CA142543</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par15">Medical images are produced from different modalities such as X-ray, computational tomography (CT), magnetic resonance imaging (MRI), whole-slide imaging (WSI). These procedures produce massive imaging data, which capture the anatomy and physiological processes of the body or histological details in high spatial resolution. Recent developments in deep-learning methods have enabled the automatic detection of regions of interest (ROI), such as tumor regions, in medical images [<xref ref-type="bibr" rid="CR1">1</xref>]. These newly developed methods and other standard image processing algorithms produce pixel-based representations of the medical images, known as artificial intelligence (AI)-segmented images. These segmented images facilitate the identification and analysis of the ROI within the raw images.</p>
    <p id="Par16">Analyses of these ROIs can produce clinically meaningful information that characterizes conditions or diseases and predict patient outcomes. Multiple studies in brain, breast, and lung cancer have used tumor shape to predict patient prognosis [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. A recent study in lung cancer used digital hematoxylin and eosin (H &amp;E)-stained pathology images to associate certain shape characteristics with patient survival outcomes [<xref ref-type="bibr" rid="CR1">1</xref>]. These studies generally rely on shape features such as boundary descriptors [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>], geometric descriptors [<xref ref-type="bibr" rid="CR1">1</xref>], landmark-based descriptors [<xref ref-type="bibr" rid="CR7">7</xref>], and topological summaries [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. Such shape features are computed by various shape representations that characterize the ROI in one or two dimensions. For the shape features to be meaningful, they should (1) quantify the shape, geometry, and topology of the regions; (2) be translation, rotation, and scale-invariant; and (3) be application-dependent with a low computational complexity [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>].</p>
    <p id="Par17">While these studies have relied on raw or segmented images, the data processing and quality control steps are usually arbitrary, study-dependent, and rely on some software tool or programming script. As a result, there lacks an open-source implementation that can translate different shape representations, extract quantitative shape features from the ROI, and summarize the results. To meet the increasing demand for such a tool, we developed an open-source R package, SAFARI (Shape Analysis for AI-segmented Images), for ROI labelling, representation, feature extraction, and visualization. These procedures and the preliminary steps to prepare images for SAFARI are shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Additionally, we provide a user-friendly online analytic tool.<fig id="Fig1"><label>Fig. 1</label><caption><p>SAFARI package workflow: (1) whole-slide image is processed by an Automated Tumor Recognition System (ATRS) and converted into a binary format, (2) ROI are identified and segmentedfrom the input binary image, (3) shape features are simultaneously computed for the downstream analysis</p></caption><graphic xlink:href="12880_2022_849_Fig1_HTML" id="MO1"/></fig></p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <p id="Par18">SAFARI is an open-source R package with a user-friendly online tool. The graphical interface offers a demonstration of the package’s capabilities. Given a valid segmented image, SAFARI can automatically detect, segment, and quantify the ROI. The main deliverables of the SAFARI package are listed in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1. When using the online tool, the resulting segments will be displayed on the website alongside a table corresponding to the shape features of each segment (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). While the current version of our R package supports up to three-class segmented images, the online tool only accepts binary images (PNG/GIF <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt;\,3$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mspace width="0.166667em"/><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq1.gif"/></alternatives></inline-formula> MB). The latest development and released versions of the R package are available on GitHub [<xref ref-type="bibr" rid="CR11">11</xref>] and CRAN [<xref ref-type="bibr" rid="CR12">12</xref>], respectively.<fig id="Fig2"><label>Fig. 2</label><caption><p>SAFARI online analysis interface, instructions, and results page</p></caption><graphic xlink:href="12880_2022_849_Fig2_HTML" id="MO2"/></fig></p>
    <p id="Par19">We implemented a processing procedure to (1) segment the ROI from an AI-segmented image, (2) translate to different shape representations, and (3) extract a variety of shape features based on those representations. The development of this pipeline is motivated by the “AI-segmented image” case study in [<xref ref-type="bibr" rid="CR1">1</xref>], but we note that our tool can be used for the analysis of any binary and three-class image.</p>
    <sec id="Sec3">
      <title>ROI labelling</title>
      <p id="Par20">Standard image processing methods, including newly-developed deep-learning techniques [<xref ref-type="bibr" rid="CR1">1</xref>], generate pixel-based image representations that are easy to manipulate, process, and store. These methods map the regions within the image to integer codings, referred to as categories. In X-rays, these categories represent the empty and skeletal structures. In pathology images, they represent the empty, malignant, and non-malignant regions. We show an example of an H &amp;E-stained pathology image, converted to a three-class segmented image in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1. We can easily identify ROI made up of these categories through this process, such as tumors tissues.</p>
      <p id="Par21">Individual ROI are identified and segmentedby standard morphological operations, based on a 4-connectivity [<xref ref-type="bibr" rid="CR13">13</xref>]. To reduce the influence of smaller regions, two filtering methods are available based on a user specifying a minimum net area or the largest <italic>n</italic> regions to keep. The resulting ROI, stored in a single integer matrix, are labeled from largest to smallest in area.</p>
    </sec>
    <sec id="Sec4">
      <title>Shape representations</title>
      <p id="Par22">Shape objects are then created from the segmentedROI; specifically, for each region, a binary matrix that indicates the object and a polygonal chain of its boundary (see an example in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S2). We can derive further shape representations, such as the (normalized) radial lengths and (curvature) chain codes from the polygonal chain. These are one-dimensional and are able to quantify the contour and directional changes in the boundary. Additional properties can be computed from the polygonal chain, which are the convex hull and minimum bounding box. For more details, regarding the six primary and derived shape objects, see Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Section S1 and Table S2.</p>
    </sec>
    <sec id="Sec5">
      <title>Feature extraction</title>
      <p id="Par23">The resulting shape objects provide a heterogeneous feature extraction that is able to quantify different information about the ROI. Various measurements that quantify the shape, geometry, and topology of the regions are computed, and categorized as geometric, boundary, and topological shape features. About 30 shape features, properly categorized, are shown in Table <xref rid="Tab1" ref-type="table">1</xref> and detailed in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3 by their formulae and properties. The dependencies between shape representations and features are shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S3, respectively. These region-level shape features can be used in supervised and unsupervised applications. More importantly, they can further serve to characterize patients and the underlying condition or disease of interest.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Overview of the 29 shape features in three categories</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Category</th><th align="left">Features</th></tr></thead><tbody><tr><td align="left">Geometric</td><td align="left">Net area, thickness, elongation, filled area, perimeter, circularity, fibre length, fibre width, convex area, convex perimeter, roundness, convexity, solidity, major axis length, major axis angle, minor axis length, bounding box area, eccentricity, and curl</td></tr><tr><td align="left">Boundary</td><td align="left">Bending energy, total absolute curvature, radial mean, radial standard deviation, entropy, area ratio, zero crossing count, and normalized moment classifier</td></tr><tr><td align="left">Topological</td><td align="left">Number of holes and number of protrusions</td></tr></tbody></table><table-wrap-foot><p>For a full table and a diagram, refer to Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3 and Fig. S3, respectively</p></table-wrap-foot></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec6">
    <title>Results</title>
    <p id="Par24">We studied the relationship between tumor shape and survival outcomes in lung and brain cancer patients, extending the work in [<xref ref-type="bibr" rid="CR1">1</xref>] and following a similar methodological approach as in [<xref ref-type="bibr" rid="CR8">8</xref>], respectively. All analyses were performed with the R software, version 4.0.3, and R packages survival (version 3.2-7) and glmnet (version 4.1) [<xref ref-type="bibr" rid="CR14">14</xref>–<xref ref-type="bibr" rid="CR16">16</xref>].</p>
    <sec id="Sec7">
      <title>Dataset A</title>
      <p id="Par25">We used 246 pathology images from 143 consecutive patients with stage I–IV non-small-cell lung cancer in the National Lung Screening Trial (NLST) [<xref ref-type="bibr" rid="CR17">17</xref>]. The patient characteristics are summarized in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4. All patients had undergone surgical procedures as treatment. The survival time was defined as the period from the time of the surgery until death or the final date of the study (December 31, 2009). Forty-five patients had died during this time period, and the remaining 98 were still alive at the final date of the study. As a result, the survival time of the alive patients was censored. There were multiple tissue slides scanned at <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$40\times$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mn>40</mml:mn><mml:mo>×</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq2.gif"/></alternatives></inline-formula> magnification for each patient. The median size of the slides was <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$24,244 \times 19, 261$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mn>24</mml:mn><mml:mo>,</mml:mo><mml:mn>244</mml:mn><mml:mo>×</mml:mo><mml:mn>19</mml:mn><mml:mo>,</mml:mo><mml:mn>261</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq3.gif"/></alternatives></inline-formula> pixels. Based on a convolutional neural network, the automated tumor recognition system developed by [<xref ref-type="bibr" rid="CR1">1</xref>] created a segmentedthree-class image of each slide. A binary version of the three-class image was created, where the holes within the tumors represent the empty and non-malignant regions.</p>
    </sec>
    <sec id="Sec8">
      <title>Downstream analysis I: association study</title>
      <p id="Par26">Before starting the downstream analyses, we first implemented a quality control step. Any ROIs with a net area less than one-fourth of the largest ROI of each slide were removed. The 29 tumor-level features extracted by SAFARI were then average at the slide level.</p>
      <p id="Par27">To investigate the association with overall survival, we fit a separate univariate Cox proportional-hazards (CoxPH) model to each shape feature at the slide level. We summarize the results in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S5, where the shape features were centered and scaled, and patients with multiple slide images were accounted for by clustering. Notably, 14 of the 29 features were statistically significant (<italic>p</italic> value <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le$$\end{document}</tex-math><mml:math id="M8"><mml:mo>≤</mml:mo></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq4.gif"/></alternatives></inline-formula> 0.05). Out of the 14 features, 12 were geometric, and two were topological. Additionally, all significant features had negative effects to a poor survival outcome (hazard ratio <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&gt;\, 1$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mspace width="0.166667em"/><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq5.gif"/></alternatives></inline-formula>). Finally, the major axis angle served as a negative control and was not statistically significant, as expected, with a <italic>p</italic> value of approximately 0.86 (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S5). Since our methodology is an extension to [<xref ref-type="bibr" rid="CR1">1</xref>], we compare their results to ours where 4 shape features were statistically significant (<italic>p</italic> value <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le$$\end{document}</tex-math><mml:math id="M12"><mml:mo>≤</mml:mo></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq6.gif"/></alternatives></inline-formula> 0.05) and not included in the original study (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S6).</p>
    </sec>
    <sec id="Sec9">
      <title>Downstream analysis II: predictive performance</title>
      <p id="Par28">We choose a small subset of features by fitting a regularized CoxPH model with a LASSO penalty to prevent overfitting. The tuning parameter <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M14"><mml:mi>λ</mml:mi></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq7.gif"/></alternatives></inline-formula> was selected by ten-fold cross-validation [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. The selected features were the major axis length, circularity, and eccentricity. We show the cross-validation results and the importance of each selected feature in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S4. To evaluate the prognostic performance of the selected shape features, we predicted the risk scores using leave-one-out cross-validation. Within each cross-validation fold, a single sample was chosen where we predicted its risk score by training a CoxPH model on the remaining 245 samples. The predicted risk scores, based on the relative risk of the fitted models, were averaged for each patient. Subsequently, the patients were dichotomized into high and low-risk groups, using the median patient-wise risk score and resulting in two groups with 71 and 72 samples, respectively. A Kaplan–Meier plot of the high and low-risk groups is shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. The <italic>p</italic> value of the log-rank test was 0.0035, demonstrating a separation between the two groups. Additionally, the prognostic performance of the shape-based risk scores was validated by a multivariable CoxPH model. After adjusting for clinical variables, including age, gender, smoking status, and stage, the predicted risk groups independently predicted prognosis (high-risk vs. low-risk, hazard ratio = 2.32, <italic>p</italic> value = 0.0134, see Table <xref rid="Tab2" ref-type="table">2</xref>).<fig id="Fig3"><label>Fig. 3</label><caption><p>Survival curves, estimated using the Kaplan-Meier method, for both high-risk and low-risk groups</p></caption><graphic xlink:href="12880_2022_849_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab2"><label>Table 2</label><caption><p>Multivariable analysis of the predicted risk group</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Hazard Ratio (HR) with <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$95\%$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mn>95</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq8.gif"/></alternatives></inline-formula> confidence interval (CI)</th><th align="left"><italic>p</italic> value*</th></tr></thead><tbody><tr><td align="left">High-risk versus low-risk</td><td char="(" align="char">2.32 (1.19–4.52)</td><td char="." align="char"><bold>0.0134</bold></td></tr><tr><td align="left">Age</td><td char="(" align="char">1.09 (1.03–1.16)</td><td char="." align="char"><bold>0.0040</bold></td></tr><tr><td align="left">Male versus female</td><td char="(" align="char">0.92 (0.49-1.74)</td><td char="." align="char">0.7964</td></tr><tr><td align="left">Smoker versus non-smoker</td><td char="(" align="char">0.94 (0.51–1.72)</td><td char="." align="char">0.8429</td></tr><tr><td align="left">Stage II versus stage I</td><td char="(" align="char">1.30 (0.44–3.88)</td><td char="." align="char">0.6323</td></tr><tr><td align="left">Stage III versus stage I</td><td char="(" align="char">3.79 (1.93–7.45)</td><td char="." align="char">≤ <bold>0.001</bold></td></tr><tr><td align="left">Stage IV versus stage I</td><td char="(" align="char">4.26 (1.67–10.83)</td><td char="." align="char"><bold>0.0024</bold></td></tr></tbody></table><table-wrap-foot><p>A Cox proportional-hazards (CoxPH) model was fitted to test the predictive performance of the predicted risk score, adjusted for clinical variables and based on the leave-one-out cross-validation results</p><p>*Bolding signifies features with <italic>p</italic> value ≤ 0.05.</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec10">
      <title>Dataset B</title>
      <p id="Par29">We used the MRI scans of 61 patients with Glioblastoma (GBM), the most common malignant grade IV brain tumor, obtained from The Cancer Imaging Archive (TCIA) [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>] and their clinical data retrieved from The Cancer Genome Atlas (TCGA) [<xref ref-type="bibr" rid="CR20">20</xref>]. The patient characteristics are summarized in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4. All MRI images were segmented into tumor and non-tumor regions using the Medical Imaging Interaction Toolkit (MITK) with augmented tools for segmentation [<xref ref-type="bibr" rid="CR21">21</xref>]. The size of the scans are either <inline-formula id="IEq11"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$256 \times 256$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq11.gif"/></alternatives></inline-formula> or <inline-formula id="IEq12"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$512 \times 512$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mn>512</mml:mn><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq12.gif"/></alternatives></inline-formula>, and each patient has approximately 23–25 MRI images. We followed the data pre-processing steps in [<xref ref-type="bibr" rid="CR8">8</xref>].</p>
    </sec>
    <sec id="Sec11">
      <title>Downstream analysis III: association study</title>
      <p id="Par30">We followed a similar procedure as in the first case study. A quality control step was first implemented, followed by investigating the association with overall survival. Since brain tumor images are represented by two-dimensional slices, some of which do not contain any region of the tumor, we chose the slice level with the largest tumor size. As a result, we obtained 29 shape features for each patient.</p>
      <p id="Par31">To investigate the association with overall survival, we fit a separate univariate Cox proportional-hazards model (CoxPH) to each shape feature at the patient level. We summarize the results in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S7, where the shape features were centered and scaled. Notably, 11 of the 29 features were statistically significant (<italic>p</italic> value <inline-formula id="IEq13"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le$$\end{document}</tex-math><mml:math id="M22"><mml:mo>≤</mml:mo></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq13.gif"/></alternatives></inline-formula> 0.05). Out of the 11 features, 10 were geometric, and one was topological. Additionally, all significant features had negative effects to a poor survival outcome (hazard ratio <inline-formula id="IEq14"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&gt;\, 1$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mspace width="0.166667em"/><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12880_2022_849_Article_IEq14.gif"/></alternatives></inline-formula>).</p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Discussion</title>
    <p id="Par32">The methodology used in the previous section is similar to the one used in [<xref ref-type="bibr" rid="CR1">1</xref>], but we extend the study to highlight the capabilities of our tool. We increased and diversified the potential predictors of prognosis in lung cancer, by computing shape features on various shape representations, such as the chain codes, polygonal chain, radial lengths, etc. By clustering at the patient-level, we correct the standard errors and capture the heterogeneity of the tumors. This provides a different approach from [<xref ref-type="bibr" rid="CR1">1</xref>] where they summarize the shape features at the patient-level, potentially, affecting the results due to outliers. We also applied our software to an additional case study. The results shown in the association study were promising. This evidence suggests that the shape features provided could work for a variety of datasets, especially if we consider the topological differences between lung and brain tumors.</p>
    <p id="Par33">Shape analysis has been widely studied and its usefulness has already been demonstrated in many different problems, such as lesion detection [<xref ref-type="bibr" rid="CR22">22</xref>], classification [<xref ref-type="bibr" rid="CR22">22</xref>–<xref ref-type="bibr" rid="CR24">24</xref>], survival analysis [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], and tissue segmentation [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>], but the lack of complete shape analysis tools in the R environment motives our work. Although there are tools available in CRAN and Bioconductor, none have a full pipeline [<xref ref-type="bibr" rid="CR26">26</xref>], support as many shape features and representations [<xref ref-type="bibr" rid="CR27">27</xref>], or have applications to medical imaging [<xref ref-type="bibr" rid="CR28">28</xref>] as our tool. Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S8 compares a sample of the shape analysis tools available in the R environment to SAFARI.</p>
    <p id="Par34">While our proposed tool provides a complete, easy-to-use, and open-source shape analysis pipeline, it still has some limitations. First, the pipeline does not include the image segmentation step and heavily depends on the quality of the original segmentation. While the goodness of the segmentation stage will influence the final results, the contribution of our tool is its (1) diverse set of shape features to benchmark novel approaches, (2) simplicity for clinicians and pathologists, and (3) offline and online access. Additionally, we intend to integrate automatic segmentation in the future for specific applications. Second, we need to include more novel shape features such as boundary features proposed in [<xref ref-type="bibr" rid="CR7">7</xref>] and topological features proposed in [<xref ref-type="bibr" rid="CR8">8</xref>]. Since we incorporate standard shape features found in older literature, it would be best to adapt to new methods for quantifying the shape, boundary, and topology of shapes.</p>
    <p id="Par35">A final detail that needs to be considered is the case of multi-label segmentation outputs, which result in heatmaps for different classes that will be represented along channels. For this scenario, we encourage users to treat each channel separately, equivalent to the binary image consideration, when using our tool for ROI labelling and feature extraction. Since this output type is necessary for most AI-algorithms, we will consider adding functionality for segmented maps with multiple channels in a future update.</p>
  </sec>
  <sec id="Sec13">
    <title>Conclusion</title>
    <p id="Par36">We developed SAFARI, an open-source R package with its accompanying user-friendly online tool, to segment ROIs and characterize their shapes from AI-segmented images. Our lung cancer case study demonstrated how tumor shape features could predict patients’ survival outcomes. The results of this study provide new biomarkers for prognosis and further evidence of the underlying association between shape and disease progression. To our knowledge, SAFARI is one of the few tools in the R environment with such capabilities. We believe that this tool will facilitate the analysis of ROI in a plethora of applications and boost methodological research in shape analysis.</p>
  </sec>
  <sec id="Sec14">
    <title>Availability and requirements</title>
    <p id="Par37">
      <list list-type="bullet">
        <list-item>
          <p id="Par38">Project name: Shape analysis for AI-segmented images.</p>
        </list-item>
        <list-item>
          <p id="Par39">Project home page: <ext-link ext-link-type="uri" xlink:href="https://lce.biohpc.swmed.edu/safari/">https://lce.biohpc.swmed.edu/safari/</ext-link>.</p>
        </list-item>
        <list-item>
          <p id="Par40">Archived version: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/SAFARI/index.html">https://cran.r-project.org/web/packages/SAFARI/index.html</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/estfernandez/SAFARI">https://github.com/estfernandez/SAFARI</ext-link>.</p>
        </list-item>
        <list-item>
          <p id="Par41">Operating system(s): Platform independent.</p>
        </list-item>
        <list-item>
          <p id="Par42">Programming language: R.</p>
        </list-item>
        <list-item>
          <p id="Par43">Other requirements: EBImage 4.32.0 or higher.</p>
        </list-item>
        <list-item>
          <p id="Par44">License: GNU General Public License v3.0.</p>
        </list-item>
        <list-item>
          <p id="Par45">Any restrictions to use by non-academics: None.</p>
        </list-item>
      </list>
    </p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec15">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12880_2022_849_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1.</bold> Supplementary tables an figures.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>CT</term>
        <def>
          <p id="Par4">Computational tomography</p>
        </def>
      </def-item>
      <def-item>
        <term>MRI</term>
        <def>
          <p id="Par5">Magnetic resonance imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>WSI</term>
        <def>
          <p id="Par6">Whole-slide imaging</p>
        </def>
      </def-item>
      <def-item>
        <term>ROI</term>
        <def>
          <p id="Par7">Regions of interest</p>
        </def>
      </def-item>
      <def-item>
        <term>SAFARI</term>
        <def>
          <p id="Par8">Shape analysis for AI-segmented images</p>
        </def>
      </def-item>
      <def-item>
        <term>HR</term>
        <def>
          <p id="Par9">Hazard ratio</p>
        </def>
      </def-item>
      <def-item>
        <term>SE</term>
        <def>
          <p id="Par10">Standard error</p>
        </def>
      </def-item>
      <def-item>
        <term>CI</term>
        <def>
          <p id="Par11">Confidence interval</p>
        </def>
      </def-item>
      <def-item>
        <term>NLST</term>
        <def>
          <p id="Par12">National lung screening trial</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par13">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>CoxPH</term>
        <def>
          <p id="Par14">Cox proportional-hazards model</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors would like to thank Jessie Norris for helping us in proofreading the manuscript.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>EFM has written the manuscript, developed the R package, and performed the statistical analysis. SY and BY have created the new online software in the study. EFM, SHC, CM, and CZ have performed the statistical analysis and interpreted the results in the study. CM and GX has processed and provided the AI-segmented images for the study. QL has conceived and initiated the study, supervised the entire project, and contributed to the writing and revision of the manuscript. All authors have read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work has been supported by the National Science Foundation [DMS-2210912], National Institutes of Health [1R01GM140012, 1R01GM141519, 1R01DE030656, 1U01CA249245, 2P30CA142543], and the Cancer Prevention and Research Institute of Texas [RP190107]. The funding bodies had no role in the design, collection, analysis, or interpretation of data in this study.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Dataset A: The H&amp;E-stained pathology images and patient clinical information were taken directly from the NLST web portal (<ext-link ext-link-type="uri" xlink:href="https://cdas.cancer.gov/learn/nlst/home/">https://cdas.cancer.gov/learn/nlst/home/</ext-link>). The access to the raw images must be applied through the website. The AI-segmented images analyzed in this study are available from the corresponding authors upon reasonable request. Dataset B: The MRI scans and patient clinical information were taken directly from the TCGA web portal (<ext-link ext-link-type="uri" xlink:href="https://wiki.cancerimagingarchive.net/display/Public/TCGA-GBM">https://wiki.cancerimagingarchive.net/display/Public/TCGA-GBM</ext-link>). No application is needed to access the raw images. The AI-segmented images analyzed in this study are available from the corresponding author upon reasonable request.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par46">Not applicable.</p>
    </notes>
    <notes id="FPar3">
      <title>Consent for publication</title>
      <p id="Par47">Not applicable.</p>
    </notes>
    <notes id="FPar2" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par48">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cai</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Fujimoto</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comprehensive analysis of lung cancer pathology images to discover tumor shape and boundary features that predict survival outcome</article-title>
        <source>Sci Rep</source>
        <year>2018</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>10393</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-018-27707-4</pub-id>
        <pub-id pub-id-type="pmid">29991684</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kilday</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Palmieri</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>MD</given-names>
          </name>
        </person-group>
        <article-title>Classifying mammographic lesions using computerized image analysis</article-title>
        <source>IEEE Trans Med Imaging</source>
        <year>1993</year>
        <volume>12</volume>
        <issue>4</issue>
        <fpage>664</fpage>
        <lpage>669</lpage>
        <pub-id pub-id-type="doi">10.1109/42.251116</pub-id>
        <pub-id pub-id-type="pmid">18218460</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pohlman</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Powell</surname>
            <given-names>KA</given-names>
          </name>
          <name>
            <surname>Obuchowski</surname>
            <given-names>NA</given-names>
          </name>
          <name>
            <surname>Chilcote</surname>
            <given-names>WA</given-names>
          </name>
          <name>
            <surname>Grundfest-Broniatowski</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Quantitative classification of breast tumors in digitized mammograms</article-title>
        <source>Med Phys</source>
        <year>1996</year>
        <volume>23</volume>
        <issue>8</issue>
        <fpage>1337</fpage>
        <lpage>1345</lpage>
        <pub-id pub-id-type="doi">10.1118/1.597707</pub-id>
        <pub-id pub-id-type="pmid">8873030</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>KH</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Berry</surname>
            <given-names>GJ</given-names>
          </name>
          <name>
            <surname>Altman</surname>
            <given-names>RB</given-names>
          </name>
          <name>
            <surname>Ré</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rubin</surname>
            <given-names>DL</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features</article-title>
        <source>Nat Commun</source>
        <year>2016</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>12474</fpage>
        <pub-id pub-id-type="doi">10.1038/ncomms12474</pub-id>
        <pub-id pub-id-type="pmid">27527408</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Rodriguez-Canales</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comprehensive computational pathological image analysis predicts lung cancer prognosis</article-title>
        <source>J Thor Oncol</source>
        <year>2017</year>
        <volume>12</volume>
        <issue>3</issue>
        <fpage>501</fpage>
        <lpage>509</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtho.2016.10.017</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crawford</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Monod</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>AX</given-names>
          </name>
          <name>
            <surname>Mukherjee</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rabadán</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Predicting clinical outcomes in glioblastoma: an application of topological and functional data analysis</article-title>
        <source>J Am Stat Assoc</source>
        <year>2020</year>
        <volume>115</volume>
        <issue>531</issue>
        <fpage>1139</fpage>
        <lpage>1150</lpage>
        <pub-id pub-id-type="doi">10.1080/01621459.2019.1671198</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Zhang C, Xiao G, Moon C, Chen M, Li Q. Bayesian landmark-based shape analysis of tumor pathology images. 2020. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2012.01149">arXiv:2012.01149</ext-link> [stat].</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Moon C, Li Q, Xiao G. Predicting survival outcomes using topological features of tumor pathology images. 2020. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2012.12102">arXiv:2012.12102</ext-link> [cs, stat].</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Review of shape representation and description techniques</article-title>
        <source>Pattern Recognit</source>
        <year>2004</year>
        <volume>37</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2003.07.008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Mingqiang Y, Kidiyo K, Joseph R. A survey of shape feature extraction techniques. HAL. 2008.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Fernandez Morales E, Li Q. SAFARI: shape analysis for AI-reconstructed images. 2021. R package version 0.1.1. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/estfernandez/SAFARI">https://github.com/estfernandez/SAFARI</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Fernandez Morales E, Li Q. SAFARI: shape analysis for AI-reconstructed images. 2021. R package version 0.1.0. Available from: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=SAFARI">https://cran.r-project.org/package=SAFARI</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Gonzalez</surname>
            <given-names>RC</given-names>
          </name>
          <name>
            <surname>Woods</surname>
            <given-names>RE</given-names>
          </name>
          <name>
            <surname>Eddins</surname>
            <given-names>SL</given-names>
          </name>
        </person-group>
        <source>Digital image processing using MATLAB</source>
        <year>2020</year>
        <edition>3</edition>
        <publisher-loc>Knoxville</publisher-loc>
        <publisher-name>Gatesmark Publishing</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Therneau</surname>
            <given-names>TM</given-names>
          </name>
          <name>
            <surname>Grambsch</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <source>Modeling survival data: extending the Cox model</source>
        <year>2000</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Simon</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Regularization paths for Cox’s proportional hazards model via coordinate descent</article-title>
        <source>J Stat Softw</source>
        <year>2011</year>
        <volume>39</volume>
        <issue>5</issue>
        <fpage>1</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.18637/jss.v039.i05</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">R Core Team. R: a language and environment for statistical computing. Vienna, Austria: R Foundation for Statistical Computing; 2020. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/">https://www.r-project.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>Team NLSTR</collab>
        </person-group>
        <article-title>The national lung screening trial: overview and study design</article-title>
        <source>Radiology</source>
        <year>2011</year>
        <volume>258</volume>
        <issue>1</issue>
        <fpage>243</fpage>
        <lpage>253</lpage>
        <pub-id pub-id-type="doi">10.1148/radiol.10091808</pub-id>
        <pub-id pub-id-type="pmid">21045183</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Clark</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Vendt</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Freymann</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kirby</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Koppel</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The cancer imaging archive (TCIA): maintaining and operating a public information repository</article-title>
        <source>J Digit Imaging</source>
        <year>2013</year>
        <volume>26</volume>
        <issue>6</issue>
        <fpage>1045</fpage>
        <lpage>1057</lpage>
        <pub-id pub-id-type="doi">10.1007/s10278-013-9622-7</pub-id>
        <pub-id pub-id-type="pmid">23884657</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scarpace</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Mikkelsen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cha</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Tekchandani</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gutman</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Radiology data from the cancer genome atlas glioblastoma multiforme [TCGA-GBM] collection</article-title>
        <source>Cancer Imaging Arch</source>
        <year>2016</year>
        <volume>11</volume>
        <issue>4</issue>
        <fpage>1</fpage>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Network CGATR, et al. Comprehensive genomic characterization defines human glioblastoma genes and core pathways. Nature. 2008;455(7216):1061.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wolf</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Vetter</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wegner</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Böttger</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Nolden</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schöbinger</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The medical imaging interaction toolkit</article-title>
        <source>Med Image Anal</source>
        <year>2005</year>
        <volume>9</volume>
        <issue>6</issue>
        <fpage>594</fpage>
        <lpage>604</lpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2005.04.005</pub-id>
        <pub-id pub-id-type="pmid">15896995</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Seoud</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hurtut</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Chelbi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheriet</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Langlois</surname>
            <given-names>JMP</given-names>
          </name>
        </person-group>
        <article-title>Red lesion detection using dynamic shape features for diabetic retinopathy screening</article-title>
        <source>IEEE Trans Med Imaging</source>
        <year>2016</year>
        <volume>35</volume>
        <issue>4</issue>
        <fpage>1116</fpage>
        <lpage>1126</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2015.2509785</pub-id>
        <pub-id pub-id-type="pmid">26701180</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Claridge E, Hall PN, Keefe M, Allen JP. Shape analysis for classification of malignant melanoma. J Biomed Eng. 1992;14(3):229–234. Annual scientific meeting.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kashyap</surname>
            <given-names>KL</given-names>
          </name>
          <name>
            <surname>Bajpai</surname>
            <given-names>MK</given-names>
          </name>
          <name>
            <surname>Khanna</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>An efficient algorithm for mass detection and shape analysis of different masses present in digital mammograms</article-title>
        <source>Multimedia Tools Appl</source>
        <year>2018</year>
        <volume>77</volume>
        <issue>8</issue>
        <fpage>9249</fpage>
        <lpage>9269</lpage>
        <pub-id pub-id-type="doi">10.1007/s11042-017-4751-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bharath</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kurtek</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Baladandayuthapani</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Radiologic image-based statistical shape analysis of brain tumours</article-title>
        <source>J R Stat Soc Ser C Appl Stat</source>
        <year>2018</year>
        <volume>67</volume>
        <issue>5</issue>
        <fpage>1357</fpage>
        <pub-id pub-id-type="doi">10.1111/rssc.12272</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Sugiyama J, Kobayashi K. wvtool: image tools for automated wood identification. 2016. R package version 1.0. Available from: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=wvtool">https://CRAN.R-project.org/package=wvtool</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pau</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Fuchs</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Sklyar</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Boutros</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>EBImage—an R package for image processing with applications to cellular phenotypes</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>7</issue>
        <fpage>979</fpage>
        <lpage>981</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq046</pub-id>
        <pub-id pub-id-type="pmid">20338898</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Dryden IL. Shapes: statistical shape analysis. 2021. R package version 1.2.6. Available from: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=shapes">https://CRAN.R-project.org/package=shapes</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
