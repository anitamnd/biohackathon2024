<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Genomics</journal-id>
    <journal-title-group>
      <journal-title>BMC Genomics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2164</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8788131</article-id>
    <article-id pub-id-type="pmid">35078402</article-id>
    <article-id pub-id-type="publisher-id">8310</article-id>
    <article-id pub-id-type="doi">10.1186/s12864-022-08310-4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AMPlify: attentive deep learning model for discovery of novel antimicrobial peptides effective against WHO priority pathogens</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Chenkai</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sutherland</surname>
          <given-names>Darcy</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hammond</surname>
          <given-names>S. Austin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Chen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Taho</surname>
          <given-names>Figali</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bergman</surname>
          <given-names>Lauren</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Houston</surname>
          <given-names>Simon</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Warren</surname>
          <given-names>René L.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wong</surname>
          <given-names>Titus</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hoang</surname>
          <given-names>Linda M. N.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cameron</surname>
          <given-names>Caroline E.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
        <xref ref-type="aff" rid="Aff7">7</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Helbing</surname>
          <given-names>Caren C.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0950-7839</contrib-id>
        <name>
          <surname>Birol</surname>
          <given-names>Inanc</given-names>
        </name>
        <address>
          <email>ibirol@bcgsc.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff8">8</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.248762.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 0702 3000</institution-id><institution>Canada’s Michael Smith Genome Sciences Centre, BC Cancer Agency, </institution></institution-wrap>Vancouver, BC V5Z 4S6 Canada </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03rmrcq20</institution-id><institution-id institution-id-type="GRID">grid.17091.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2288 9830</institution-id><institution>Bioinformatics Graduate Program, </institution><institution>University of British Columbia, </institution></institution-wrap>Vancouver, BC V6T 1Z4 Canada </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.418246.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 0352 641X</institution-id><institution>Public Health Laboratory, British Columbia Centre for Disease Control, </institution></institution-wrap>Vancouver, BC V5Z 4R4 Canada </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03rmrcq20</institution-id><institution-id institution-id-type="GRID">grid.17091.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2288 9830</institution-id><institution>Department of Pathology and Laboratory Medicine, </institution><institution>University of British Columbia, </institution></institution-wrap>Vancouver, BC V6T 1Z4 Canada </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04s5mat29</institution-id><institution-id institution-id-type="GRID">grid.143640.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9465</institution-id><institution>Department of Biochemistry and Microbiology, </institution><institution>University of Victoria, </institution></institution-wrap>Victoria, BC V8P 5C3 Canada </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02zg69r60</institution-id><institution-id institution-id-type="GRID">grid.412541.7</institution-id><institution-id institution-id-type="ISNI">0000 0001 0684 7796</institution-id><institution>Medical Microbiology Laboratory, </institution><institution>Vancouver General Hospital, </institution></institution-wrap>Vancouver, BC V5Z 1M9 Canada </aff>
      <aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00cvxb145</institution-id><institution-id institution-id-type="GRID">grid.34477.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2298 6657</institution-id><institution>Division of Infectious Diseases, Department of Medicine, </institution><institution>University of Washington, </institution></institution-wrap>Seattle, WA 98195 USA </aff>
      <aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03rmrcq20</institution-id><institution-id institution-id-type="GRID">grid.17091.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2288 9830</institution-id><institution>Department of Medical Genetics, </institution><institution>University of British Columbia, </institution></institution-wrap>Vancouver, BC V6H 3N1 Canada </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>25</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>25</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>77</elocation-id>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>1</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Antibiotic resistance is a growing global health concern prompting researchers to seek alternatives to conventional antibiotics. Antimicrobial peptides (AMPs) are attracting attention again as therapeutic agents with promising utility in this domain, and using in silico methods to discover novel AMPs is a strategy that is gaining interest. Such methods can sift through large volumes of candidate sequences and reduce lab screening costs.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here we introduce AMPlify, an attentive deep learning model for AMP prediction, and demonstrate its utility in prioritizing peptide sequences derived from the <italic>Rana [Lithobates] catesbeiana</italic> (bullfrog) genome. We tested the bioactivity of our predicted peptides against a panel of bacterial species, including representatives from the World Health Organization’s priority pathogens list. Four of our novel AMPs were active against multiple species of bacteria, including a multi-drug resistant isolate of carbapenemase-producing <italic>Escherichia coli</italic>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">We demonstrate the utility of deep learning based tools like AMPlify in our fight against antibiotic resistance. We expect such tools to play a significant role in discovering novel candidates of peptide-based alternatives to classical antibiotics.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12864-022-08310-4.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Antimicrobial peptide</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Attention mechanism</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100008762</institution-id>
            <institution>Genome Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>281ANV</award-id>
        <award-id>291PEP</award-id>
        <principal-award-recipient>
          <name>
            <surname>Birol</surname>
            <given-names>Inanc</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000051</institution-id>
            <institution>National Human Genome Research Institute</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2R01HG007182-04A1</award-id>
        <principal-award-recipient>
          <name>
            <surname>Birol</surname>
            <given-names>Inanc</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Canada-BC Agri-Innovation Program</institution>
        </funding-source>
        <award-id>INV106</award-id>
        <principal-award-recipient>
          <name>
            <surname>Birol</surname>
            <given-names>Inanc</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000233</institution-id>
            <institution>Genome British Columbia</institution>
          </institution-wrap>
        </funding-source>
        <award-id>291PEP</award-id>
        <award-id>281ANV</award-id>
        <principal-award-recipient>
          <name>
            <surname>Birol</surname>
            <given-names>Inanc</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par33">As reported by the World Health Organization (WHO), the decreasing effectiveness of antibiotics and other antimicrobial agents indicates the world is at a risk of entering a “post-antibiotic era” [<xref ref-type="bibr" rid="CR1">1</xref>]. To counter this threat, new drugs or effective substitutes for conventional antibiotics are urgently needed. Antimicrobial peptides (AMPs) are one such alternative. AMPs are host defense molecules produced by all forms of life, including multicellular organisms as part of their innate immunity against microbes. Within their respective hosts, eukaryotic AMPs have co-evolved with microorganisms to serve as a defense against bacterial [<xref ref-type="bibr" rid="CR2">2</xref>], fungal [<xref ref-type="bibr" rid="CR3">3</xref>] and even viral infections [<xref ref-type="bibr" rid="CR4">4</xref>]. Unlike most conventional antibiotics, which have specific functional or structural targets, AMPs act directly on the microorganisms, often causing cell lysis, or modulate the host immunity to enhance defense against microorganisms [<xref ref-type="bibr" rid="CR5">5</xref>]. Also, they act faster than conventional antibiotics [<xref ref-type="bibr" rid="CR6">6</xref>], have a narrower active concentration window for killing [<xref ref-type="bibr" rid="CR7">7</xref>], and do not typically damage the DNA of their targets [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>]. As a result, they do not induce resistance to the extent that is observed with conventional antibiotics [<xref ref-type="bibr" rid="CR10">10</xref>]. Nevertheless, if bacteria are exposed to AMPs for extended periods of time, they can and do develop resistance even to peptide-based drugs including the last resort and life-saving drug, colistin [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>]. Hence, fast and accurate methods would be valuable tools to discover and design effective AMPs to enhance our repertoire of alternative therapeutics.</p>
    <p id="Par34">Direct, large scale discovery of novel AMPs through wet lab screening is time-consuming, labor-intensive and costly [<xref ref-type="bibr" rid="CR12">12</xref>]. For these reasons, various computational models have been developed over the last few years [<xref ref-type="bibr" rid="CR12">12</xref>] to streamline in silico AMP prediction. Despite the rapid progress in the field, currently available models still have substantial room for improvement.</p>
    <p id="Par35">The AMP prediction module in the Collection of Antimicrobial Peptides (CAMP) database [<xref ref-type="bibr" rid="CR13">13</xref>] includes four different models: random forest, support vector machine, discriminant analysis, and a single-hidden-layer feed-forward neural network with 64 designed features [<xref ref-type="bibr" rid="CR14">14</xref>]. The iAMP-2L online server adopts fuzzy <italic>K</italic>-nearest neighbor algorithm, taking pseudo amino acid compositions (PseAAC) with five physicochemical properties as input features to predict AMPs as well as their potential microorganism targets [<xref ref-type="bibr" rid="CR15">15</xref>]. The iAMPpred online server for AMP prediction and classification is based on support vector machine and uses PseAAC with compositional, physicochemical, and structural features [<xref ref-type="bibr" rid="CR16">16</xref>]. All three of these tools employ conventional machine learning methods and rely on pre-designed features, requiring prior expertise in AMP structure and mechanism for effective engineering.</p>
    <p id="Par36">Alternatively, deep learning methods can automatically learn high-level features and usually outperform conventional methods in many bioinformatics tasks [<xref ref-type="bibr" rid="CR17">17</xref>]. Recently, few teams developed deep learning models for the AMP prediction task. Youmans and co-workers demonstrated the feasibility of using a bidirectional long short-term memory [<xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR20">20</xref>] (Bi-LSTM) recurrent neural network (RNN) for AMP prediction [<xref ref-type="bibr" rid="CR21">21</xref>], but the authors do not offer any public code or tool that implements their model. The Deep-AmPEP30 online server applies a convolutional neural network (CNN) for AMP prediction [<xref ref-type="bibr" rid="CR22">22</xref>], though the tool is restricted to working with short peptides up to 30 amino acids (aa) in length. The Deep-ABPpred online server adopts Bi-LSTM with word2vec [<xref ref-type="bibr" rid="CR23">23</xref>], also for short (≤ 30 aa) peptides [<xref ref-type="bibr" rid="CR24">24</xref>]. The Bi-LSTM model from Wang and co-workers is designed for even shorter peptides (≤ 20 aa) and specializes to predicting AMPs against <italic>Escherichia coli</italic> [<xref ref-type="bibr" rid="CR25">25</xref>]. They also provide a workflow for designing novel AMPs. Veltri and co-workers introduced a deep neural network classifier with embedding, convolutional, max pooling, and long short-term memory (LSTM) recurrent layers which is available as an online server, AMP Scanner Vr.2, as its user interface [<xref ref-type="bibr" rid="CR26">26</xref>]. AMP Scanner Vr.2 is the only tool in the deep learning category that does not have a strong limitation in input sequence lengths; it can handle sequences up to 200 aa.</p>
    <p id="Par37">While AMP Scanner Vr.2 outperforms the conventional machine learning methods cited above, we note that its neural network architecture is not designed for extracting long-range information along peptide sequences. Common deep learning methods for sequence classification include recurrent neural networks (RNNs) and convolutional neural networks (CNNs), as employed in combination by AMP Scanner Vr.2. RNNs can learn remote dependencies inside a sequence, but suffer from vanishing gradients [<xref ref-type="bibr" rid="CR27">27</xref>]. Similarly, while CNNs can extract local information well, it ignores long-range dependencies [<xref ref-type="bibr" rid="CR28">28</xref>].</p>
    <p id="Par38">Recently, deep neural networks with attention mechanisms have gained interest, notably for natural language processing [<xref ref-type="bibr" rid="CR29">29</xref>–<xref ref-type="bibr" rid="CR31">31</xref>] and computer vision [<xref ref-type="bibr" rid="CR32">32</xref>] applications. Attention mechanisms, as the name suggests, are inspired by our brains’ ability to prioritize segments of information when processing textual or visual input. In sequence analysis, attention mechanisms are modeled by weights assigned to different positions in a sequence. These weights amplify or attenuate information from a given position to help encode the global information of the sequence.</p>
    <p id="Par39">Here, we introduce AMPlify, an attentive deep learning model that improves in silico AMP prediction by applying two types of attention mechanisms layered on a bidirectional long short-term memory [<xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR20">20</xref>] (Bi-LSTM) layer (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The Bi-LSTM layer in the model, as a variant of RNN, encodes positional information from the input sequence in a recurrent manner. Subsequently, the multi-head scaled dot-product attention [<xref ref-type="bibr" rid="CR30">30</xref>] (MHSDPA) layer computes a refined representation of the sequence using multiple weight vectors. The last hidden layer of context attention [<xref ref-type="bibr" rid="CR31">31</xref>] (CA) generates a single summary vector using weighted average, learning contextual information gained from the previous layer. The AMPlify model is trained on a set of known AMPs and a select list of non-AMP sequences, and adopts ensemble learning to further improve its performance. To the best of our knowledge, AMPlify is the first machine learning application that applies attention mechanisms for in silico AMP prediction. We note that non-standard amino acids are not taken into consideration in this study, and we mainly focus on AMPs from multicellular organisms for discovery.<fig id="Fig1"><label>Fig. 1</label><caption><p>Model architecture of AMPlify. Residues of a peptide sequence are one-hot encoded and passed to three hidden layers in order: the bidirectional long short-term memory (Bi-LSTM) layer, the multi-head scaled dot-product attention (MHSDPA) layer and the context attention (CA) layer. The output layer generates the probability that the input sequence is an AMP</p></caption><graphic xlink:href="12864_2022_8310_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par40">To illustrate the utility of our model, a discovery pipeline based on AMPlify was used to mine the AMP-rich North American bullfrog (<italic>Rana [Lithobates] catesbeiana</italic>) genome for novel natural AMPs. Previously, the North American bullfrog has been described as a rich source for natural AMPs, yielding potent classes of bioactive molecules such as ranateurins, ranacyclins, temporins, and palustrins [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>]. In our tests, AMPlify successfully identified these previously reported AMPs, along with four novel AMPs with biological activity in vitro.</p>
    <p id="Par41">The WHO has a published list of priority pathogens for which new antibiotics are urgently needed [<xref ref-type="bibr" rid="CR35">35</xref>]. This list includes bacterial species that are increasingly resistant to multiple antibiotics<italic>.</italic> We tested the efficacy of our discovered, putative AMPs against selected Priority Pathogens, including: 1) <italic>Pseudomonas aeruginosa</italic> and <italic>Escherichia coli</italic> strains, including a multi-drug resistant (MDR) carbapenemase-producing (CPO) strain of <italic>E. coli</italic> reflective of WHO’s “Priority 1” pathogens; and 2) a <italic>Staphylococcus aureus</italic> strain reflective of WHO’s “Priority 2” methicillin-resistant (MRSA) and vancomycin-resistant (VRSA) strains. A <italic>Streptococcus pyogenes</italic> strain was included as an additional Gram-positive bacterial species that causes human disease, while this bacterial species has demonstrated antibiotic resistance in some earlier works [<xref ref-type="bibr" rid="CR36">36</xref>].</p>
    <p id="Par42">In our tests, four of the 16 novel AMPs discovered show considerable antimicrobial potency against one or more of the organisms examined, including the clinical MDR isolate of CPO <italic>E. coli.</italic> These results highlight the potential of AMPlify to accelerate AMP discovery, the first step towards facilitating peptide-based therapeutics.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>Evaluation of model architecture</title>
      <p id="Par43">To demonstrate the effectiveness of each component within our model, we evaluated the model architecture starting from a single Bi-LSTM layer and then gradually adding attention layers over it. Supplementary Table S<xref rid="MOESM1" ref-type="media">1</xref> summarizes the results of our ablation study, comparing different model architectures using stratified 5-fold cross-validation on the training set with regard to five different measures of (1) accuracy, (2) sensitivity, (3) specificity, (4) F1 score, and (5) area under the receiver operating characteristic curve (AUROC). The first section of the table compares the performance of the complete architecture of AMPlify, with and without ensemble learning, with simpler variations, which include fewer hidden layers. The architecture of the only deep learning based comparator, AMP Scanner Vr.2, was cross-validated on our training set for comparison using two different stopping settings: the optimal fixed number of epochs as stated in their manuscript [<xref ref-type="bibr" rid="CR26">26</xref>] and early stopping as described in this paper (Supplementary Table S<xref rid="MOESM1" ref-type="media">1</xref>, second section). Although overall performance of AMP Scanner Vr.2 is not strongly influenced by early stopping, it does lead to smaller performance variability as measured by standard deviation values in tests, indicating that the model trained using early stopping is more robust than using a default of 10 epochs.</p>
      <p id="Par44">By adding a single CA layer atop the Bi-LSTM layer, the model performs similarly to AMP Scanner Vr.2 based on cross-validation results, with differences smaller than 1% in all metrics except specificity (&lt; 1.4%). After inserting an MHSDPA layer in the middle, the cross-validation results for our model reach 91.70% in accuracy, 91.40% in sensitivity, 92.00% in specificity, 91.68% in F1 score, and 96.92% in AUROC – an overall improvement compared with the architecture without this layer. This indicates that the attention layer learns discriminating features of sequences processed by the Bi-LSTM layer. We note that the final AMPlify architecture already outperforms the AMP Scanner Vr.2 architecture in all metrics in our cross-validation tests. After applying ensemble learning to the proposed architecture, the cross-validation performance is further improved to 92.79% for accuracy, 92.12% for sensitivity, 93.47% for specificity, 92.74% for F1 score and 97.44% for AUROC.</p>
      <p id="Par45">To test whether the improvement of our model is statistically significant, we performed paired Student t-tests based on cross-validation results. These tests indicate statistically significant increase in performance of AMPlify over AMP Scanner Vr.2 (early stopped) with regard to all five metrics (<italic>p</italic> &lt; 0.05). The better performance of AMPlify without ensemble learning (i.e. Bi-LSTM+MHSDPA+CA) over the simple Bi-LSTM model is also statistically significant in all metrics (<italic>p</italic> &lt; 0.05), suggesting that the attention layers play an important role in the model’s performance.</p>
      <p id="Par46">Further, we cross-validated AMPlify on the dataset provided by AMP Scanner Vr.2 and observed that the deep neural network architecture chosen in AMPlify is overall better for the AMP prediction task compared with the architecture of AMP Scanner Vr.2 (Supplementary Note S<xref rid="MOESM1" ref-type="media">1</xref>, Supplementary Table S<xref rid="MOESM1" ref-type="media">2</xref>).</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison with state-of-the-art methods</title>
      <p id="Par47">With the set of hyperparameters tuned through stratified 5-fold cross-validation, the final model of AMPlify was trained using the entire training set, with each of the five single sub-models trained on five different subsets. Here, single sub-model refers to the model with full architecture (Bi-LSTM+MHSDPA+CA) before ensemble learning. AMPlify, along with its single sub-models, were compared on our test set with three other state-of-the-art tools: iAMP-2L [<xref ref-type="bibr" rid="CR15">15</xref>], iAMPpred [<xref ref-type="bibr" rid="CR16">16</xref>] and AMP Scanner Vr.2 [<xref ref-type="bibr" rid="CR26">26</xref>] (Table <xref rid="Tab1" ref-type="table">1</xref>). All the tools were evaluated with their original trained models reported. In this list of comparators, AMP Scanner Vr.2 could be trained using third party datasets through a utility provided by the authors (personal communication with Daniel Veltri), and was re-trained on our training set with two different stopping conditions, as previously stated.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Performance comparison among different tools on the test set. Performance of different tools are presented with five metrics in percentage: accuracy (acc), sensitivity (sens), specificity (spec), F1 score (F1) and area under the receiver operating characteristic curve (AUROC)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Tool</th><th>Model</th><th>Acc</th><th>Sens</th><th>Spec</th><th>F1</th><th>AUROC</th></tr></thead><tbody><tr><td>iAMPpred</td><td>original<sup>a</sup></td><td>74.01</td><td>87.90</td><td>60.12</td><td>77.18</td><td>80.70</td></tr><tr><td>iAMP-2L</td><td>original<sup>a</sup></td><td>77.96</td><td>88.26</td><td>67.66</td><td>80.02</td><td>–</td></tr><tr><td rowspan="3">AMP Scanner Vr.2</td><td>original<sup>a</sup></td><td>78.50</td><td>90.66</td><td>66.35</td><td>80.83</td><td>88.33</td></tr><tr><td>re-trained, 10 epochs<sup>b</sup></td><td>90.66</td><td>91.14</td><td>90.18</td><td>90.70</td><td>97.40</td></tr><tr><td>re-trained, early stopped<sup>c</sup></td><td>91.20</td><td>90.42</td><td>91.98</td><td>91.13</td><td>97.03</td></tr><tr><td rowspan="6">AMPlify</td><td>single sub-model 1</td><td>92.40</td><td>90.90</td><td>93.89</td><td>92.28</td><td>97.54</td></tr><tr><td>single sub-model 2</td><td>91.98</td><td>91.02</td><td>92.93</td><td>91.90</td><td>97.40</td></tr><tr><td>single sub-model 3</td><td>92.51</td><td>92.69</td><td>92.34</td><td>92.53</td><td>97.82</td></tr><tr><td>single sub-model 4</td><td>92.10</td><td>90.90</td><td>93.29</td><td>92.00</td><td>97.27</td></tr><tr><td>single sub-model 5</td><td>92.57</td><td>92.57</td><td>92.57</td><td>92.57</td><td>97.98</td></tr><tr><td><bold>ensemble</bold></td><td><bold>93.71</bold></td><td><bold>92.93</bold></td><td><bold>94.49</bold></td><td><bold>93.66</bold></td><td><bold>98.37</bold></td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>Models presented in the referenced papers are available through online servers</p><p><sup>b</sup>The best hyperparameter as stated in the referenced paper</p><p><sup>c</sup>The optimal number of training epochs determined by early stopping is 16</p></table-wrap-foot></table-wrap></p>
      <p id="Par48">Among the original models of the three comparators, AMP Scanner Vr.2 performs the best on our data in general, except for its specificity, which is 1.31% lower than iAMP-2L. The accuracy, specificity, F1 score, and AUROC of AMP Scanner Vr.2 were all improved after re-training, with only small changes in sensitivity (&lt; 0.5%). Still, in our benchmarks AMPlify outperforms the comparators tested, including the two re-trained versions of AMP Scanner Vr.2. AMPlify achieves the highest accuracy (93.71%), F1 score (93.66%) and AUROC (98.37%), improving upon the performance of the next-best, the re-trained versions of AMP Scanner Vr.2, by 2.51, 2.53 and 0.97% respectively. AMPlify also shows the highest sensitivity (92.93%) and specificity (94.49%) in our tests, suggesting that the model can concurrently reduce false negative and false positive predictions. We have also analyzed the performance of different tools by stratifying the test set based on sequence similarities to their training sets, again showing how AMPlify performs favourably across this spectrum (Fig. <xref rid="Fig2" ref-type="fig">2</xref>, Supplementary Note S<xref rid="MOESM1" ref-type="media">2</xref>).<fig id="Fig2"><label>Fig. 2</label><caption><p>Performance comparison of different AMP prediction tools based on the test sequence similarities to their corresponding training sets. F1 scores of AMP prediction tools were calculated on test subsets based on similarities to sequences in the training sets. All the AMP/non-AMP test subsets were derived from the AMPlify test data, with subsets containing 10 or fewer sequences removed. The size of the round makers indicates the number of sequences remaining in the test subset given the similarity threshold</p></caption><graphic xlink:href="12864_2022_8310_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par49">Further, all five single sub-models of AMPlify yield favourable performance in accuracy (91.98–92.57%), specificity (92.34–93.89%) and F1 score (91.90–92.57%), despite each single sub-model being trained on 80% of the entire training set (see <xref rid="Sec9" ref-type="sec">9</xref>). The sensitivity values of the five single sub-models range from 90.90 to 92.69%, with two of them being better than the performance of all comparators, while the remaining three being slightly lower than the performance of the re-trained, 10 epochs model of AMP Scanner Vr.2 (&lt; 0.25%). Still, the lower standard deviation values from cross-validation analysis indicate that those single sub-models of AMPlify are more robust compared with the re-trained, 10 epochs model of AMP Scanner Vr.2 (Supplementary Table S<xref rid="MOESM1" ref-type="media">1</xref>). Similarly, our single sub-models score higher than the comparators in AUROC, except one of them being on par with the best AMP Scanner Vr.2 model and another scoring lower by 0.13%. The specificity values of the original models of the three comparators are relatively low (&lt; 70%), likely due to their less stringent selection criteria when building their non-AMP sets. The specificity values of AMP Scanner Vr.2 improved substantially after being re-trained on our training set (90.18% or 91.98%, depending on the number of epochs trained, Table <xref rid="Tab1" ref-type="table">1</xref>). We have also conducted a cross-comparison of AMPlify with AMP Scanner Vr.2, re-training our tool on the dataset provided by the AMP Scanner Vr.2 publication [<xref ref-type="bibr" rid="CR26">26</xref>], illustrating the improved learning capability of our chosen architecture for the AMP prediction task (Supplementary Note S<xref rid="MOESM1" ref-type="media">1</xref>, Supplementary Table S<xref rid="MOESM1" ref-type="media">3</xref>, Supplementary Fig. S<xref rid="MOESM1" ref-type="media">1</xref>).</p>
      <p id="Par50">For a comparison of the classification performance of each tool with regard to different classification thresholds, Fig. <xref rid="Fig3" ref-type="fig">3</xref>a presents a series of receiver operating characteristic (ROC) curves for the models compared. The AUROC results shown in Table <xref rid="Tab1" ref-type="table">1</xref> correspond to these ROC curves. Note that the iAMP-2L online server does not allow for parameterization, hence the tool is represented by a single data point and no AUROC value. The ROC curves indicate that AMPlify is Pareto-optimal in our tests for any classification threshold.<fig id="Fig3"><label>Fig. 3</label><caption><p>Visualization of AMPlify model performance and the AMP discovery pipeline application results. <bold>a</bold> Receiver operating characteristic (ROC) curves of AMPlify and comparators are plotted, with round dots marking the performance at the threshold of 0.5. The iAMP-2L online server only output labels of AMP/non-AMP without the corresponding probabilities, so it appears as a single point on the plot. <bold>b</bold> AMPlify prediction scores against peptide lengths of 101 sequences analyzed by AMPlify. The grey dotted line represents the score threshold of 0.5 used to distinguish AMPs from non-AMPs. Inset shows amplified view of the upper left region of the plot to enhance visualization of the majority of the selected sequences</p></caption><graphic xlink:href="12864_2022_8310_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>AMP discovery</title>
      <p id="Par51">Previous studies have shown that the skin secretions of amphibians are rich in AMPs, which help the animals prevent infection by harmful microorganisms [<xref ref-type="bibr" rid="CR37">37</xref>]. For this reason, mining the genomes of various frog species for novel AMPs is an attractive proposition. To demonstrate AMPlify’s practical application, it was embedded into a bioinformatics pipeline to find novel AMPs from the North American bullfrog (<italic>Rana [Lithobates] catesbeiana</italic>) genome [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>]. For antimicrobial susceptibility testing (AST), we focus on cationic AMPs acting directly on biological membranes, the activities of which can be directly observed in vitro. Most amphibian AMP precursors possess highly conserved N-terminal prepro regions and hypervariable C-terminal antimicrobial domains [<xref ref-type="bibr" rid="CR37">37</xref>]. The prepro regions usually end with a lysine-arginine signal for cleavage to produce bioactive AMPs [<xref ref-type="bibr" rid="CR37">37</xref>]. Based on this, we identified candidate precursors from the bullfrog genome using homology search and genome annotation tools. We then derived candidate mature sequences from those precursors to use as input for AMPlify (see <xref rid="Sec9" ref-type="sec">9</xref> for pipeline details). This resulted in 101 candidate mature sequences, which we fed into AMPlify, predicting 75 of them to be putative AMPs. We selected peptides between five to 35 amino acids in length with a positive charge for further analysis, yielding a final list of 16 peptides (Table <xref rid="Tab2" ref-type="table">2</xref>), five of which were previously reported sequences [<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>]. The remaining 11 peptides were synthesized and evaluated in vitro. The UpSet plot in Supplementary Fig. S<xref rid="MOESM1" ref-type="media">2</xref> summarizes the results obtained by applying different combinations of the aforementioned three filters (AMPlify prediction score, length, and charge) to the 101 candidate mature sequences. Figure <xref rid="Fig3" ref-type="fig">3</xref>b shows a visualization of AMPlify prediction results for the 101 candidate mature sequences.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Putative and reported AMP sequences discovered from <italic>Rana [Lithobates] catesbeiana</italic>. Genomic and transcriptomic resources from <italic>Rana [Lithobates] catesbeiana</italic> [<xref ref-type="bibr" rid="CR33">33</xref>] were mined using the AMP discovery pipeline based on AMPlify. Top-scoring peptide sequences were selected for synthesis and validation in vitro</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Peptide Name</th><th>Sequence</th><th># aa</th><th>Net Charge<sup>a</sup></th><th>MW (Da)</th><th>AMPlify Score</th></tr></thead><tbody><tr><td><bold>RaCa-1</bold></td><td>GLLDIIKTTGKDFAVKILDNLKCKLAGGCPP</td><td>31</td><td>2</td><td>3242.93</td><td>1.0000</td></tr><tr><td><bold>RaCa-2</bold></td><td>FFPIIARLAAKVIPSLVCAVTKKC</td><td>24</td><td>4</td><td>2589.28</td><td>1.0000</td></tr><tr><td><bold>Ranatuerin-2PRc*</bold></td><td>AFLSTVKNTLTNVAGTMIDTFKCKITGVC</td><td>29</td><td>2</td><td>3077.66</td><td>1.0000</td></tr><tr><td><bold>Temporin-1Cb*</bold><sup><bold>+</bold></sup></td><td>FLFPLITSFLSKFLGK</td><td>16</td><td>2</td><td>1858.30</td><td>1.0000</td></tr><tr><td><bold>Palustrin-Ca*</bold></td><td>GFLDIIKDTGKEFAVKILNNLKCKLAGGCPP</td><td>31</td><td>2</td><td>3303.97</td><td>1.0000</td></tr><tr><td><bold>Ranatuerin-2RC*</bold></td><td>GLFLDTLKGAAKDVAGKLLEGLKCKITGCKP</td><td>31</td><td>3</td><td>3188.88</td><td>1.0000</td></tr><tr><td><bold>RaCa-3</bold></td><td>GLWETIKTTGKSIALNLLDKIKCKIAGGCPP</td><td>31</td><td>3</td><td>3269.95</td><td>1.0000</td></tr><tr><td><bold>Ranatuerin-2C*</bold></td><td>GVFLDTLKGLAGKMLESLKCKIAGCKP</td><td>27</td><td>3</td><td>2821.49</td><td>0.9999</td></tr><tr><td><bold>RaCa-4</bold></td><td>FLTFPGMTFGKLLGK</td><td>15</td><td>2</td><td>1657.05</td><td>0.9997</td></tr><tr><td><bold>RaCa-5</bold></td><td>GLLDIIKDTGKTTGILMDTLKCQMTGRCPPSS</td><td>32</td><td>1</td><td>3395.02</td><td>0.9996</td></tr><tr><td><bold>RaCa-6</bold></td><td>ATAWRIPPPGMQPIIPIRIRPLCGKQ</td><td>26</td><td>4</td><td>2910.58</td><td>0.9994</td></tr><tr><td><bold>RaCa-7</bold></td><td>FFPRVLPLANKFLPTIYCALPKSVGN</td><td>26</td><td>3</td><td>2906.52</td><td>0.9985</td></tr><tr><td><bold>RaCa-8</bold></td><td>FPAIICKVSKNC</td><td>12</td><td>2</td><td>1322.65</td><td>0.9961</td></tr><tr><td><bold>RaCa-9</bold></td><td>FYFPVSRKFGGK</td><td>12</td><td>3</td><td>1432.69</td><td>0.9412</td></tr><tr><td><bold>RaCa-10</bold></td><td>ALVAKIQKFPVFNTLKLCKLELEII</td><td>25</td><td>2</td><td>2872.59</td><td>0.6063</td></tr><tr><td><bold>RaCa-11</bold></td><td>SNRDFFKVNIFRLCG</td><td>15</td><td>2</td><td>1816.11</td><td>0.6058</td></tr></tbody></table><table-wrap-foot><p>*Previously reported amphibian peptide sequences [<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>]</p><p><sup>+</sup>Previously reported as a full-length AMP precursor sequence. Uniprot ID: C5IB07</p><p><sup>a</sup>Net charge at pH = 7</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec6">
      <title>Antimicrobial susceptibility testing (AST)</title>
      <p id="Par52">A panel composed of six bacteria was selected to test candidate AMP sequences identified using AMPlify: <italic>Staphylococcus aureus</italic> ATCC 6538P, <italic>Streptococcus pyogenes</italic> (unknown strain; hospital isolate), <italic>Pseudomonas aeruginosa</italic> ATCC 10148, <italic>Escherichia coli</italic> ATCC 9723H and ATCC 29522, and an MDR carbapenemase-producing New-Delhi metallobetalactamase (CPO-NDM) <italic>Escherichia coli</italic> clinical isolate. <italic>E. coli</italic> ATCC 29522 was used as a wild-type drug susceptible control strain. Results from AST are presented in Table <xref rid="Tab3" ref-type="table">3</xref>. Supplementary Table S<xref rid="MOESM1" ref-type="media">4</xref> provides additional data with results shown in μg/mL.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Minimum inhibitory concentrations (MIC) and minimum bactericidal concentrations (MBC) of selected AMP candidates following antimicrobial susceptibility testing (AST) in vitro. Candidate antimicrobial peptides were synthesized and purchased from Genscript. AST, and MIC/MBC determination was performed as outlined by the Clinical and Laboratory Standards Institute (CLSI) [<xref ref-type="bibr" rid="CR40">40</xref>], with modification as recommended by Hancock [<xref ref-type="bibr" rid="CR41">41</xref>]. Data is presented as the lowest effective peptide concentration range (μM) observed in three independent experiments. LL37, human cathelicidin and a peptide from Tp0751 from <italic>Treponema pallidum</italic> were used as the positive and negative control peptides [<xref ref-type="bibr" rid="CR34">34</xref>], respectively</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th colspan="2"><bold><italic>S. aureus</italic></bold><sup>a</sup>
ATCC 6538P</th><th colspan="2"><bold><italic>S. pyogenes</italic></bold><sup>b</sup></th><th colspan="2"><bold><italic>P. aeruginosa</italic></bold><sup>a</sup>
ATCC 10148</th><th colspan="2"><bold><italic>E. coli</italic></bold><sup>a</sup>
ATCC 9723H</th><th colspan="2"><bold><italic>E. coli</italic></bold><sup>c</sup>
ATCC 25922</th><th colspan="2">MDR <bold><italic>E. coli</italic></bold><sup>d</sup>
(CPO-NDM)</th></tr><tr><th/><th colspan="2">Gram-positive</th><th colspan="2">Gram-positive</th><th colspan="2">Gram-negative</th><th colspan="2">Gram-negative</th><th colspan="2">Gram-negative</th><th colspan="2">Gram-negative</th></tr><tr><th>(μM)</th><th>MIC</th><th>MBC</th><th>MIC</th><th>MBC</th><th>MIC</th><th>MBC</th><th>MIC</th><th>MBC</th><th>MIC</th><th>MBC</th><th>MIC</th><th>MBC</th></tr></thead><tbody><tr><td><bold>RaCa-1</bold></td><td>NI</td><td>NI</td><td>79</td><td>≥ 79</td><td>NI</td><td>NI</td><td>20 – 39</td><td>39 – 79</td><td>10 – 20</td><td>10 – 39</td><td>20 – 39</td><td>20 – 39</td></tr><tr><td><bold>RaCa-2</bold></td><td>1 – 2</td><td>1 – 2</td><td>25 – 49</td><td>25 – 49</td><td>25 – 49</td><td>49 – ≥99</td><td>3 – 6</td><td>3 – 6</td><td>2 – 6</td><td>2 – 6</td><td>2 – 6</td><td>2 – 6</td></tr><tr><td><bold>RaCa-3</bold></td><td>≥78</td><td>NI</td><td>39</td><td>39 – ≥ 78</td><td>20 – ≥78</td><td>39 – ≥78</td><td>5 – 10</td><td>5 – 10</td><td>2 – 5</td><td>2 – 5</td><td>5 – 10</td><td>5 – 20</td></tr><tr><td><bold>RaCa-4</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td><bold>RaCa-5</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td></tr><tr><td><bold>RaCa-6</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td></tr><tr><td><bold>RaCa-7</bold></td><td>≥ 88</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>11 – 22</td><td>11 – 88</td><td>6 – 44</td><td>6 – 44</td><td>6 – 44</td><td>6 – 44</td></tr><tr><td><bold>RaCa-8</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td></tr><tr><td><bold>RaCa-9</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td><bold>RaCa-10</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td></tr><tr><td><bold>RaCa-11</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td><bold>LL37</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>7 – ≥57</td><td>7 – ≥57</td><td>2 – 4</td><td>4 – 7</td><td>2 – 4</td><td>2 – 4</td><td>2 – 4</td><td>2 – 4</td></tr><tr><td><bold>Tp0751</bold></td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td><td>NI</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>Bacteria obtained and tested at the University of Victoria</p><p><sup>b</sup>Unknown strain; hospital isolate</p><p><sup>c</sup>ATCC quality control strain #25922 purchased from Cedarlane Laboratories (Burlington, Ontario, Canada)</p><p><sup>d</sup>Clinical isolate obtained and tested at the British Columbia Centre for Disease Control</p><p>NI, no inhibition observed in vitro</p><p>‘—’ = not tested</p><p>Abbreviations: <italic>Staphylococcus aureus</italic>, <italic>Streptococcus pyogenes</italic>, <italic>Pseudomonas aeruginosa</italic>, <italic>Escherichia coli</italic>, <italic>ATCC</italic> American Type Culture Collection, <italic>CPO</italic> carbapenemase-producing organism, <italic>MDR</italic> multi-drug resistant, <italic>NDM</italic> New-Delhi Metallo-beta-lactamase</p></table-wrap-foot></table-wrap></p>
      <p id="Par53">The 11 putative AMP sequences were selected for in vitro AST experiments, and four of them displayed antimicrobial activity against the targets tested: RaCa-1, RaCa-2, RaCa-3, and RaCa-7. RaCa-1 was antibacterial against all <italic>E. coli</italic> strains tested (MIC = 10–39 μM, MBC = 10–79 μM). RaCa-1 also showed minimal antimicrobial activity against <italic>S. pyogenes</italic> (MIC/MBC ≥ 79 μM) with no observed inhibition against the <italic>S. aureus</italic> and <italic>P. aeruginosa</italic> isolates. RaCa-2 and RaCa-3 inhibited all bacterial strains tested. RaCa-2 possessed the strongest antibacterial activity against <italic>S. aureus</italic> and <italic>E. coli</italic> isolates, preventing growth of both species of bacteria at concentrations of 1–2 μM and 2–6 μM, respectively. Specifically, this peptide was bactericidal against <italic>E. coli</italic> ATCC 9723H (MIC/MBC = 3–6 μM), with similar activity observed against <italic>E. coli</italic> ATCC 25922 and the MDR <italic>E. coli</italic> CPO-NDM isolates (MIC/MBC = 2–6 μM). RaCa-2 was also the only AMP tested to have robust bactericidal action against both <italic>S. aureus</italic> (MIC/MBC = 1–2 μM) and <italic>S. pyogenes</italic> (MIC/MBC = 25–49 μM). Comparably, RaCa-3 was considerably potent in vitro against <italic>S. pyogenes</italic> (MIC = 39 μM, MBC = 39–≥78 μM), <italic>P. aeruginosa</italic> (MIC = 20–≥78 μM, MBC = 39–≥78 μM), <italic>E. coli</italic> (MIC = 2–10 μM, MBC = 2–20 μM), and to a lesser extent <italic>S. aureus</italic> (MIC ≥78 μM, MBC = NI). RaCa-7 was active against all strains of <italic>E. coli</italic> (MIC = 6–44 μM, MBC = 6–88 μM), with minimal inhibition of <italic>S. aureus</italic> (MIC ≥88 μM, MBC = NI), and no activity against the other two species. Overall, the four novel AMP sequences displayed the strongest activity against the tested <italic>E. coli</italic> strains. RaCa-2 and RaCa-3 each had potent antibacterial action against the MDR <italic>E. coli</italic> (CPO-NDM) inhibiting bacterial growth at ≤10 μM. Of particular note, there was little or no observed shift in MIC and MBC values when comparing the CPO-NDM <italic>E. coli</italic> isolate to the ATCC 25922 wild-type control strain.</p>
      <p id="Par54">The positive control peptide LL37 [<xref ref-type="bibr" rid="CR34">34</xref>] displayed potent antimicrobial activity against all strains of <italic>E. coli</italic> (MIC = 2–4 μM, MBC = 2–7 μM) and <italic>P. aeruginosa</italic> (MIC = 7–≥57 μM, MBC = 7–≥57 μM). However, this peptide had no activity against the tested strains of <italic>S. aureus</italic> and <italic>S. pyogenes</italic>, respectively. The negative control peptide, Tp0751, a non-functional truncated section of a <italic>Treponema pallidum</italic> protein with similar characteristics to AMPs [<xref ref-type="bibr" rid="CR42">42</xref>], was inactive against all organisms.</p>
    </sec>
  </sec>
  <sec id="Sec7">
    <title>Discussion</title>
    <p id="Par55">Here we present AMPlify, a robust attentive deep learning model for AMP prediction, and demonstrate its utility in identifying novel AMPs with broad antimicrobial activities. It implements ensemble learning by partitioning its training set – a novel approach – and outperforms existing machine learning methods, including a leading deep learning based model. The two attention mechanisms in AMPlify are inspired by how humans perceive natural language, paying closer attention to regions or words of interest in a sentence. We have observed that single sub-models of AMPlify were able to outperform the state-of-the-art methods without ensemble learning, and we were able to trace the source of this favourable performance to the inclusion of attention layers.</p>
    <p id="Par56">Although machine learning methods in general, and AMPlify in particular, perform well in predicting AMPs, their performance can be limited by a paucity of detailed AMP sequence data available for training. First, the models do not usually consider the potential target microorganisms for the predicted AMPs. Although some methods report success at that level of granularity using public data [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], incomplete and incorrect annotations in AMP databases are confounding. Second, the models cannot distinguish whether an AMP acts directly on biological membranes and/or by modulating the host immunity, since there is no consistently available data on these features. AMPs acting only in the latter mode require separate assays and might differ in activity within different species. Third, the size of the training data is still small relative to the data typically employed in most deep learning applications. Specially, having more similar sequences with different antimicrobial activities (i.e. non-AMPs that are similar to known AMPs) in the training set might help the model to be more sensitive to small changes in the sequences for prediction. However, availability of such information is limited. As a result, all the publicly available AMP prediction tools face difficulty in differentiating between AMPs and non-AMPs that are highly similar in their sequences (Supplementary Note S<xref rid="MOESM1" ref-type="media">3</xref>, Supplementary Table S<xref rid="MOESM1" ref-type="media">5</xref>). We expect this limitation to be gradually alleviated as more AMPs are discovered and more AMP mutation and truncation studies are done, inspired by tools like AMPlify. Although the size of the training data is unlikely to ever match what is available in natural language processing, image classification, and social network analysis domains, to name a few, AMP prediction tools can still find practical applications as demonstrated here.</p>
    <p id="Par57">Using AMPlify, four novel AMPs were identified with proven activity against a variety of bacterial isolates. Promisingly, two of the four presented AMPs demonstrate potent antibacterial activity against the MDR <italic>E. coli</italic> tested, and there was little or no observed shift in MIC when comparing the MDR and drug-susceptible strains. This suggests that the mechanism-of-action of these AMPs is unlike those used by conventional antibiotics. Thus, AMPs, such as those presented in the current study, have the potential to be used in future drug and clinical development studies as peptide-based substitutes to classical antibiotics. Although several candidates identified using this pipeline did not show any in vitro activity against the bacteria tested, we speculate that they still may possess activity against other bacterial species or other microorganisms (e.g. fungi, virus), or may demonstrate activity in vivo via host immune response modulation. Further, the structures of these sequences are highly dynamic and susceptible to change in response to the surrounding microenvironment, as is frequently the case with amphipathic alpha helices. These AMPs may act as monomers or form multimeric complexes, with their secondary structure flexibly changing in response to interaction with membranes or free divalent cations [<xref ref-type="bibr" rid="CR43">43</xref>]. Further studies are required to interrogate AMP mechanisms as these phenomena are not readily observed using classical in vitro methods.</p>
    <p id="Par58">Of course, the utility of tools like AMPlify is not limited to discovering AMPs from the bullfrog genome; they can be generically applied to any input sequence. As such, they have the potential to play a role in de novo AMP design or enhancement. In conclusion, with their various use cases, we foresee tools like AMPlify as being instrumental in expanding the current arsenal of antimicrobial agents effective against WHO priority pathogens.</p>
  </sec>
  <sec id="Sec8">
    <title>Conclusions</title>
    <p id="Par59">This study introduces a novel attentive deep learning model, AMPlify, for AMP prediction, and has identified four novel AMPs from the bullfrog genome with promising antibacterial activity against an MDR WHO priority pathogen. We illustrate the value of attention mechanisms and a novel ensemble approach in mining genome resources for novel AMPs, comparing the performance of AMPlify to the state-of-the art machine learning models. AMPlify is released as an open source tool (<ext-link ext-link-type="uri" xlink:href="https://github.com/bcgsc/AMPlify">https://github.com/bcgsc/AMPlify</ext-link>) under the GPL-3.0 license.</p>
  </sec>
  <sec id="Sec9">
    <title>Methods</title>
    <sec id="Sec10">
      <title>Generation of the datasets</title>
      <p id="Par60">We used publicly available AMP sequences to train and test AMP predictors. In order to build a non-redundant AMP dataset, we first downloaded all available sequences from two manually curated databases: Antimicrobial Peptide Database [<xref ref-type="bibr" rid="CR44">44</xref>] (APD3, <ext-link ext-link-type="uri" xlink:href="http://aps.unmc.edu/AP">http://aps.unmc.edu/AP</ext-link>) and Database of Anuran Defense Peptides [<xref ref-type="bibr" rid="CR39">39</xref>] (DADP, <ext-link ext-link-type="uri" xlink:href="http://split4.pmfst.hr/dadp">http://split4.pmfst.hr/dadp</ext-link>). Since APD3 is being frequently updated, we used a static version that was scraped from the website on March 20, 2019 comprising 3061 sequences. Version 1.6 of DADP contains 1923 distinct mature AMPs. We concatenated these two sets and removed duplicate sequences, producing a non-redundant (positive) set of 4173 distinct, mature AMP sequences, all 200 amino acid residues in length or shorter. AMPs that are highly similar to each other at the sequence level were kept as separate entries, since small changes in amino acid compositions may lead to large changes in AMP activity [<xref ref-type="bibr" rid="CR45">45</xref>]. Also, it is important to maintain as big a dataset as possible for better training of a deep learning model [<xref ref-type="bibr" rid="CR17">17</xref>].</p>
      <p id="Par61">Training and testing binary classification models require a negative set, a collection of peptides known not to have any antimicrobial activity. Since there are no sequence catalogs for peptides devoid of antimicrobial activity, studies in the field typically select their non-AMP sequences from UniProt [<xref ref-type="bibr" rid="CR46">46</xref>] (<ext-link ext-link-type="uri" xlink:href="https://www.uniprot.org">https://www.uniprot.org</ext-link>). This may involve excluding several simple keywords (e.g. antimicrobial, antibiotic) to filter out potential AMPs [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>], or additionally removing all secretory proteins [<xref ref-type="bibr" rid="CR26">26</xref>] as AMPs are characteristically secreted peptides [<xref ref-type="bibr" rid="CR47">47</xref>]. The former proposition is not sufficiently rigorous, because AMP annotation is not consistent and varies between sources. While keyword filtering may leave in the set some differently annotated AMPs, filtering of secretory proteins creates a learning gap for the model regarding such proteins without antimicrobial activities. Thus, it is important to balance these two strategies when selecting non-AMP sequences.</p>
      <p id="Par62">We designed a rigorous selection strategy for our non-AMP sequences (Supplementary Fig. S<xref rid="MOESM1" ref-type="media">3</xref>), using sequences from the UniProtKB/Swiss-Prot database [<xref ref-type="bibr" rid="CR46">46</xref>] (2019_02 release), which only contains manually annotated and reviewed records from the UniProt database. First, we downloaded sequences that are 200 amino acid residues or shorter in length (matching the maximum peptide length in the AMP set), excluding those with annotations containing any of the 16 following keywords related to antimicrobial activities: {antimicrobial, antibiotic, antibacterial, antiviral, antifungal, antimalarial, antiparasitic, anti-protist, anticancer, defense, defensin, cathelicidin, histatin, bacteriocin, microbicidal, fungicide}. Second, duplicates and sequences with residues other than the 20 standard amino acids were removed. Third, a set of potential AMP sequences annotated with any of the 16 selected keywords were downloaded and compared with our candidate negative set. We noted instances where a sequence with multiple functions was annotated separately in multiple records within the database, and removed sequences in common between candidate non-AMPs and potential AMPs. The candidate non-AMP sequences were also checked against the positive set to remove AMP sequences that lack the annotation in UniProtKB/Swiss-Prot. Finally, 4173 sequences were sampled from the remaining set of 128,445 non-AMPs, matching the number and length distribution of sequences in the positive set. An exception to the length distribution matching occurred when the length of a particular AMP sequence did not have a perfect match in the set of non-AMP sequences. In these instances, we chose the non-AMP sequence with the closest length. The matched length distributions were selected so that the model did not learn to distinguish classes based on sequence lengths.</p>
      <p id="Par63">The positive and negative sets were both split 80%/20% (3338/835) into training and test sets, respectively. We note that AMP sequences in our test partition have no overlap with the training sets of iAMPpred and iAMP-2L, but do share 196 sequences with the training set of AMP Scanner Vr.2.</p>
    </sec>
    <sec id="Sec11">
      <title>Model implementation</title>
      <p id="Par64">AMPlify is implemented in Python 3.6.7, using Keras library 2.2.4 [<xref ref-type="bibr" rid="CR48">48</xref>] with Tensorflow 1.12.0 [<xref ref-type="bibr" rid="CR49">49</xref>] as the backend. The raw output of the model can be interpreted as a probability score, thus sequences with scores &gt; 0.5 are considered as AMPs and those ≤0.5 as non-AMPs. We used binary cross-entropy as the loss function, and the Adam algorithm [<xref ref-type="bibr" rid="CR50">50</xref>] for optimizing weights. Dropout technique [<xref ref-type="bibr" rid="CR51">51</xref>] was applied during training to prevent the model from over-fitting. The original positive and negative training sets were both split into sets of {667, 667, 668, 668, 668} sequences, and five training and validation set pairs were constructed by leaving one set out for validation to build five single sub-models. To optimize computational time and avoid overfitting, we applied early stopping during the training of each single sub-model. The validation accuracy was monitored at each training epoch, and the training process was stopped if there appeared to be no improvement for the next 50 epochs. The model weights from the epoch with the best validation accuracy were selected as the optimal weights. The output probabilities from the five single sub-models were averaged to yield an ensemble model.</p>
      <p id="Par65">Reflecting the composition of the sequences in the positive and negative sets, AMPlify only considers sequence lengths of 200 or shorter containing the 20 standard amino acid residues.</p>
    </sec>
    <sec id="Sec12">
      <title>Hyperparameter tuning and model architecture</title>
      <p id="Par66">In deep neural networks, the optimal hyperparameters, unlike model weights, cannot be learned directly from the training process, but they do play an important role in model performance. Thus, various combinations of hyperparameters must be compared in order to select the best set. Here we applied stratified 5-fold cross-validation on the entire training set to tune the model and find the best set of hyperparameters for the model architecture, as well as for training settings, including dropout rates and optimizer settings. For a fair comparison, we kept the same splits of sequences within cross-validation across all hyperparameter combinations. During hyperparameter tuning, we monitored the average performance on the validation partitions of cross-validation. Note that these validation partitions within cross-validation are different from the validation sets for early stopping, while the latter being additionally derived from the training partitions during the cross-validation process. The set of hyperparameters with the highest average cross-validation accuracy was chosen to train the final prediction model.</p>
      <p id="Par67">The AMPlify architecture includes three main components: 1) a bidirectional long short-term memory (Bi-LSTM) layer, 2) a multi-head scaled dot-product attention (MHSDPA) layer, and 3) a context attention (CA) layer (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). To convert the original peptides into a mathematically processable format, each sequence is represented by a series of one-hot encoded vectors over an alphabet of 20 amino acids, yielding <bold>x</bold><sub><bold>1</bold></sub>, <bold>x</bold><sub><bold>2</bold></sub>, …, <bold>x</bold><sub><bold>L</bold></sub>, where <italic>L</italic> is the length of the sequence and each <bold>x</bold><sub><bold>t</bold></sub> is a 20-dimensional vector of zeros and ones with ‖<bold>x</bold><sub><bold>t</bold></sub>‖<sub><bold>1</bold></sub> = 1 (<italic>t</italic> = 1, 2, …, <italic>L</italic>). The Bi-LSTM layer takes those one-hot encoded vectors as input and encodes positional information for each residue from both forward and backward directions, and the output vector for each residue is represented as a concatenation of the vectors from both directions. The best tuned dimensionality for each direction of Bi-LSTM layer was 512, resulting in the entire Bi-LSTM layer to be <italic>d</italic><sub><italic>h</italic></sub> = 512 × 2 = 1024 dimensional. Outputs from all residue positions of the Bi-LSTM layer are returned as the input for the next layer. The best tuned dropout rate of 0.5 was applied to the input of the Bi-LSTM layer. Encoding from the Bi-LSTM layer for residues within a given sequence can be represented as a series of vectors <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{h}}_{\mathbf{t}}\in {\mathbb{R}}^{d_h}$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi mathvariant="bold">t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq1.gif"/></alternatives></inline-formula> (<italic>t</italic> = 1, 2, …, <italic>L</italic>), and the entire sequence can be represented as a matrix with all <bold>h</bold><sub><bold>t</bold></sub> s packed as<disp-formula id="Equa"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H={\left({\mathbf{h}}_{\mathbf{1}},{\mathbf{h}}_{\mathbf{2}},\dots, {\mathbf{h}}_{\mathbf{L}}\right)}^{\mathrm{T}}\in {\mathbb{R}}^{L\times {d}_h}.$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi mathvariant="bold">L</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par68">Next, the MHSDPA layer searches for relations between different residues in <italic>n</italic> different representation subspaces [<xref ref-type="bibr" rid="CR30">30</xref>] (i.e. different attention heads) to further encode the sequence, where <italic>n</italic> is a hyperparameter to be tuned. Each residue first gets an intermediate representation within each head by calculating a weighted average over transformed vectors of all residues derived from their Bi-LSTM representations. The results from each head are then concatenated and mapped back to the original dimensionality. We adapted Vaswani and co-workers’ approach [<xref ref-type="bibr" rid="CR30">30</xref>] to calculate the attention weights and outputs for the MHSDPA layer. The implementation was adapted from the GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/CyberZHG/keras-multi-head">https://github.com/CyberZHG/keras-multi-head</ext-link>, where rectified linear unit (ReLU) activation functions and bias terms were added to all linear transformations.</p>
      <p id="Par69">In further detail, to obtain attention weights for different residues of a sequence within a head <italic>i</italic>, we calculate a set of queries <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Q}^i\in {\mathbb{R}}^{L\times {d}_k}$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:msup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq2.gif"/></alternatives></inline-formula>, keys <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}^i\in {\mathbb{R}}^{L\times {d}_k}$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq3.gif"/></alternatives></inline-formula>, and values <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${V}^i\in {\mathbb{R}}^{L\times {d}_v}$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq4.gif"/></alternatives></inline-formula> by transforming <italic>H</italic> as follows:<disp-formula id="Equb"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Q}^i=\mathrm{ReLU}\left(H{W}^{Q^i}+{B}^{Q^i}\right)$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced close=")" open="("><mml:mi>H</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equb.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equc"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}^i=\mathrm{ReLU}\left(H{W}^{K^i}+{B}^{K^i}\right)$$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced close=")" open="("><mml:mi>H</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equc.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equd"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${V}^i=\mathrm{ReLU}\left(H{W}^{V^i}+{B}^{V^i}\right)$$\end{document}</tex-math><mml:math id="M16" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced close=")" open="("><mml:mi>H</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equd.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq5"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^{Q^i},{W}^{K^i}\in {\mathbb{R}}^{d_h\times {d}_k}$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq5.gif"/></alternatives></inline-formula> and <inline-formula id="IEq6"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^{V^i}\in {\mathbb{R}}^{d_h\times {d}_v}$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq6.gif"/></alternatives></inline-formula> are weight matrices, and <inline-formula id="IEq7"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${B}^{Q^i}={\left({\mathbf{b}}^{{\mathbf{Q}}^{\mathbf{i}}},{\mathbf{b}}^{{\mathbf{Q}}^{\mathbf{i}}},\dots, {\mathbf{b}}^{{\mathbf{Q}}^{\mathbf{i}}}\right)}^{\mathrm{T}}\in {\mathbb{R}}^{L\times {d}_k}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq7.gif"/></alternatives></inline-formula>, <inline-formula id="IEq8"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${B}^{K^i}={\left({\mathbf{b}}^{{\mathbf{K}}^{\mathbf{i}}},{\mathbf{b}}^{{\mathbf{K}}^{\mathbf{i}}},\dots, {\mathbf{b}}^{{\mathbf{K}}^{\mathbf{i}}}\right)}^{\mathrm{T}}\in {\mathbb{R}}^{L\times {d}_k}$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq8.gif"/></alternatives></inline-formula> and <inline-formula id="IEq9"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${B}^{V^i}={\left({\mathbf{b}}^{{\mathbf{V}}^{\mathbf{i}}},{\mathbf{b}}^{{\mathbf{V}}^{\mathbf{i}}},\dots, {\mathbf{b}}^{{\mathbf{V}}^{\mathbf{i}}}\right)}^{\mathrm{T}}\in {\mathbb{R}}^{L\times {d}_v}$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msup></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq9.gif"/></alternatives></inline-formula> are bias matrices. We set transformation dimensions as <italic>nd</italic><sub><italic>k</italic></sub> = <italic>nd</italic><sub><italic>v</italic></sub> = <italic>d</italic><sub><italic>h</italic></sub> following what has been previously proposed [<xref ref-type="bibr" rid="CR30">30</xref>]. A square matrix <italic>A</italic><sup><italic>i</italic></sup> ∈ <italic>ℝ</italic><sup><italic>L</italic> × <italic>L</italic></sup>, which contains weight vectors to calculate intermediate representations of all residues within head <italic>i</italic>, is computed as:<disp-formula id="Eque"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A}^i={\mathrm{softmax}}_{\mathrm{row}}\left(\frac{Q^i{K^i}^{\mathrm{T}}}{\sqrt{d_k}}\right)$$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">softmax</mml:mi><mml:mi mathvariant="normal">row</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msup><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:msup><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Eque.gif" position="anchor"/></alternatives></disp-formula>where dot-product of queries and keys are scaled by a factor <inline-formula id="IEq10"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{1}{\sqrt{d_k}}$$\end{document}</tex-math><mml:math id="M30"><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq10.gif"/></alternatives></inline-formula>, and the softmax function is applied to each row of the matrix for normalization. The intermediate representation of the sequence within head <italic>i</italic> is then computed by:<disp-formula id="Equf"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Z}^i={\left({\mathbf{z}}_{\mathbf{1}}^{\mathbf{i}},{\mathbf{z}}_{\mathbf{2}}^{\mathbf{i}},\dots, {\mathbf{z}}_{\mathbf{L}}^{\mathbf{i}}\right)}^{\mathrm{T}}={A}^i{V}^i\in {\mathbb{R}}^{L\times {d}_v}$$\end{document}</tex-math><mml:math id="M32" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mn mathvariant="bold">2</mml:mn></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mi mathvariant="bold">L</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msubsup></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equf.gif" position="anchor"/></alternatives></disp-formula>where each single vector <inline-formula id="IEq11"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{z}}_{\mathbf{t}}^{\mathbf{i}}\in {\mathbb{R}}^{{\mathrm{d}}_v}$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mi mathvariant="bold">t</mml:mi></mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mi mathvariant="normal">d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq11.gif"/></alternatives></inline-formula> (<italic>t</italic> = 1, 2, …, <italic>L</italic>) denotes the intermediate representation of each residue of the sequence with dimensionality <italic>d</italic><sub><italic>v</italic></sub>. The concatenated matrix <inline-formula id="IEq12"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z=\left({Z}_{L\times {d}_v}^1,{Z}_{L\times {d}_v}^2,\dots, {Z}_{L\times {d}_v}^n\right)\in {\mathbb{R}}^{L\times {nd}_v}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mfenced><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">nd</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq12.gif"/></alternatives></inline-formula> is further transformed to get the final output of the current layer as follows:<disp-formula id="Equg"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M={\left({\mathbf{m}}_{\mathbf{1}},{\mathbf{m}}_{\mathbf{2}},\dots, {\mathbf{m}}_{\mathbf{L}}\right)}^{\mathrm{T}}=\mathrm{ReLU}\left[Z{W}^O+{B}^O\right]\in {\mathbb{R}}^{L\times {d}_h}$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="bold">m</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">m</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">m</mml:mi><mml:mi mathvariant="bold">L</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">ReLU</mml:mi><mml:mfenced close="]" open="["><mml:mi>Z</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>O</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>O</mml:mi></mml:msup></mml:mfenced><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equg.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq13"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^O\in {\mathbb{R}}^{nd_v\times {d}_h}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>O</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq13.gif"/></alternatives></inline-formula> is a weight matrix and <inline-formula id="IEq14"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${B}^O={\left({\mathbf{b}}^{\mathbf{O}},{\mathbf{b}}^{\mathbf{O}},\dots, {\mathbf{b}}^{\mathbf{O}}\right)}^{\mathrm{T}}\in {\mathbb{R}}^{L\times {d}_h}$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mi>O</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">O</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">O</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mi mathvariant="bold">O</mml:mi></mml:msup></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq14.gif"/></alternatives></inline-formula> is a bias matrix. Each vector <inline-formula id="IEq15"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{m}}_{\mathbf{t}}\in {\mathbb{R}}^{{\mathrm{d}}_h}$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:msub><mml:mi mathvariant="bold">m</mml:mi><mml:mi mathvariant="bold">t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mi mathvariant="normal">d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq15.gif"/></alternatives></inline-formula> (<italic>t</italic> = 1, 2, …, <italic>L</italic>) denotes the new representation of the corresponding residue of the sequence with dimensionality <italic>d</italic><sub><italic>h</italic></sub>. The best head number tuned for this layer was <italic>n</italic> = 32, with <italic>d</italic><sub><italic>k</italic></sub> = <italic>d</italic><sub><italic>v</italic></sub> = 32.</p>
      <p id="Par70">Finally, the CA layer gathers information from the MHSDPA layer by reducing <italic>L</italic> encoded vectors into a single weighted average summary vector <bold>s</bold>. We followed Yang and co-workers’ approach [<xref ref-type="bibr" rid="CR31">31</xref>] to perform this operation, and adapted the implementation from the GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/lzfelix/keras_attention">https://github.com/lzfelix/keras_attention</ext-link>. The weight vector <bold>α</bold> ∈ <italic>ℝ</italic><sup><italic>L</italic></sup> is calculated using<disp-formula id="Equh"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\boldsymbol{\upalpha} =\mathrm{softmax}\left(\left(\tanh \left( MW+B\right)\right)\mathbf{u}\right)$$\end{document}</tex-math><mml:math id="M46" display="block"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">α</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">softmax</mml:mi><mml:mfenced close=")" open="("><mml:mfenced close=")" open="("><mml:mo>tanh</mml:mo><mml:mfenced close=")" open="("><mml:mi>M</mml:mi><mml:mi>W</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi></mml:mfenced></mml:mfenced><mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equh.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq16"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W\in {\mathbb{R}}^{d_h\times {d}_h}$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq16.gif"/></alternatives></inline-formula> is a weight matrix, <inline-formula id="IEq17"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$B={\left(\mathbf{b},\mathbf{b},\dots, \mathbf{b}\right)}^{\mathrm{T}}\in {\mathbb{R}}^{L\times {d}_h}$$\end{document}</tex-math><mml:math id="M50"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="bold">b</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq17.gif"/></alternatives></inline-formula> is a bias matrix, <inline-formula id="IEq18"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf{u}\in {\mathbb{R}}^{d_h}$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mi mathvariant="bold">u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq18.gif"/></alternatives></inline-formula> is a context vector, and the softmax function provides weight normalization. The summary vector <inline-formula id="IEq19"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf{s}\in {\mathbb{R}}^{d_h}$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12864_2022_8310_Article_IEq19.gif"/></alternatives></inline-formula> is then computed as:<disp-formula id="Equi"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf{s}={M}^{\mathrm{T}}\boldsymbol{\upalpha} =\sum_{t=1}^L{\alpha}_t{\mathbf{m}}_{\mathbf{t}}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mrow><mml:mi mathvariant="bold">α</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">m</mml:mi><mml:mi mathvariant="bold">t</mml:mi></mml:msub></mml:mrow></mml:math><graphic xlink:href="12864_2022_8310_Article_Equi.gif" position="anchor"/></alternatives></disp-formula>where <italic>α</italic><sub><italic>t</italic></sub> denotes each component in the weight vector. Vector <bold>s</bold> summarizes information of the entire sequence into a single vector, and it is passed through the output layer of a single neuron with a sigmoid activation function for classification. The best tuned dropout rate of 0.2 was applied to the input of the CA layer during training.</p>
      <p id="Par71">In addition to the hyperparameters of the model architecture, the hyperparameters of the optimizer were optimized through cross-validation. A batch size of 32 and a default learning rate of 0.001 were found to be the best for the AMP prediction task.</p>
    </sec>
    <sec id="Sec13">
      <title>Model evaluation</title>
      <p id="Par72">The performance of AMPlify was evaluated using five metrics: accuracy, sensitivity, specificity, F1 score and area under the receiver operating characteristic curve (AUROC).</p>
      <p id="Par73">The architecture of AMPlify was compared with its simpler variations with fewer hidden layers using stratified 5-fold cross-validation on the training set to measure the value added by each layer as the architecture grew more complex. The final version of AMPlify trained on the entire training set, as well as its five single sub-models, were compared with three other tools: iAMP-2L [<xref ref-type="bibr" rid="CR15">15</xref>], iAMPpred [<xref ref-type="bibr" rid="CR16">16</xref>] and AMP Scanner Vr.2 [<xref ref-type="bibr" rid="CR26">26</xref>], on the test set we built. All comparators were evaluated with their original models online.</p>
      <p id="Par74">In addition, as the only comparator with methods for re-training, AMP Scanner Vr.2 was cross-validated and re-trained on our training set for a fairer comparison. We note that, since our dataset is slightly different from those used by other methods, the number of epochs required to get a deep learning model well trained on different datasets might differ. Keeping all other hyperparameters the same as the original model, we cross-validated and re-trained AMP Scanner Vr.2 with two different stopping settings: using the optimal fixed number of epochs as reported [<xref ref-type="bibr" rid="CR26">26</xref>], and using early stopping.</p>
    </sec>
    <sec id="Sec14">
      <title>AMP discovery pipeline</title>
      <p id="Par75">A primarily homology-based approach was used to supply novel candidate AMP sequences to AMPlify for further evaluation. The pipeline and its results are summarized in Supplementary Fig. S<xref rid="MOESM1" ref-type="media">4</xref> and are detailed below.</p>
      <p id="Par76">Sequences matching the search phrase “((antimicrobial) AND precursor) AND amphibian” were downloaded from the NCBI Nucleotide database on January 4th, 2016 and aligned to the draft bullfrog genome [<xref ref-type="bibr" rid="CR33">33</xref>] (version 3) using GMAP [<xref ref-type="bibr" rid="CR52">52</xref>] (version 20170424) with the following parameters: -A --max-intronlength-ends = 200000 -O -n20 --nofails.</p>
      <p id="Par77">To refine the putative AMP loci, the gene prediction pipeline MAKER2 [<xref ref-type="bibr" rid="CR53">53</xref>] (version 2.31.8 running under PERL version 5.24.0 with augustus [<xref ref-type="bibr" rid="CR54">54</xref>] version 3.2.1, exonerate [<xref ref-type="bibr" rid="CR55">55</xref>] version 2.2.0, genemark [<xref ref-type="bibr" rid="CR56">56</xref>] version 2.3c, and snap [<xref ref-type="bibr" rid="CR57">57</xref>] version 2006-07-28) was applied to the 231 genomic scaffolds with alignment hits from GMAP using default settings. The MAKER2 pipeline can use orthogonal evidence from related protein or transcript sequences when available to generate a list of high confidence genes. Protein evidence consisted of three sets of sequences: sequences matching the search phrase “((antimicrobial) AND precursor) AND amphibian” from the NCBI protein database that were downloaded on December 31st, 2015; experimentally validated non-synthetic amphibian antibacterial peptide sequences downloaded from CAMP [<xref ref-type="bibr" rid="CR13">13</xref>] on March 4th, 2016; and sequences from APD3 [<xref ref-type="bibr" rid="CR44">44</xref>] downloaded on September 29th, 2017. For transcript evidence, the set of cDNA sequences supplied to GMAP above was supplemented with selected bullfrog transcript sequences from the Bullfrog Annotation Reference for the Transcriptome [<xref ref-type="bibr" rid="CR33">33</xref>] (BART). Blastn [<xref ref-type="bibr" rid="CR58">58</xref>] (version 2.31.1) was used to align the initial cDNA sequences from NCBI to BART, and BART sequences with an alignment of greater than 90% identity and 100% coverage were selected. A custom repeat element library was constructed from predicted repeats previously identified in the bullfrog genome [<xref ref-type="bibr" rid="CR33">33</xref>] and supplied to MAKER2 for use by RepeatMasker [<xref ref-type="bibr" rid="CR59">59</xref>]. The annotation pipeline was run with the snap hidden Markov model that produced the version 2 bullfrog gene predictions [<xref ref-type="bibr" rid="CR33">33</xref>].</p>
      <p id="Par78">The MAKER2 gene predictions were filtered in two stages. First, sequences containing the highly conserved lysine-arginine enzymatic cleavage motif were selected and the sequence of the putative mature peptide, produced via in silico cleavage at the C-terminal side of the cleavage motif, was extracted. Second, only putative mature sequences of 200 amino acid residues or less were included. Sequences with non-standard amino acid residues were excluded. The resulting peptide sequences from these filters were fed into AMPlify for prediction. From the predicted putative AMPs, only short cationic sequences with lengths between five and 35 amino acid residues were chosen for synthesis and validation in vitro. We prioritized short cationic sequences as shorter sequences are more structurally stable in various environments (e.g. in vitro and in vivo) [<xref ref-type="bibr" rid="CR60">60</xref>] lending to easier therapeutic applicability.</p>
    </sec>
    <sec id="Sec15">
      <title>Antimicrobial susceptibility testing (AST)</title>
      <p id="Par79">From the novel candidate AMP sequences predicted by AMPlify, 11 were selected for validation in vitro. Minimum inhibitory concentrations (MIC) and minimum bactericidal concentrations (MBC) were obtained using the AST procedures outlined by the Clinical and Laboratory Standards Institute (CLSI) [<xref ref-type="bibr" rid="CR40">40</xref>], with the recommended adaptations for testing cationic AMPs described by Hancock [<xref ref-type="bibr" rid="CR41">41</xref>].</p>
      <sec id="Sec16">
        <title>Bacterial isolates</title>
        <p id="Par80">A panel of two Gram-positive and four Gram-negative bacterial isolates was generated to test predicted AMPs. <italic>Staphylococcus aureus</italic> ATCC 6538P, <italic>Streptococcus pyogenes</italic> (hospital isolate, unknown strain), <italic>Pseudomonas aeruginosa</italic> ATCC 10148, and <italic>Escherichia coli</italic> ATCC 9723H were obtained and tested at the University of Victoria. Additionally, a multi-drug resistant (MDR), carbapenemase-producing New-Delhi metallobetalactamase (CPO-NDM) clinical isolate of <italic>Escherichia coli</italic> was obtained from the BC Centre for Disease Control. <italic>E. coli</italic> ATCC 29522 was purchased from Cedarlane Laboratories (Burlington, Ontario, Canada) for comparison of AMP activity between a wild type, drug-susceptible control and the MDR strain. The latter two strains were tested at the BC Centre for Disease Control using identical AST procedures.</p>
      </sec>
      <sec id="Sec17">
        <title>Determination of MIC</title>
        <p id="Par81">Bacteria were streaked onto nonselective nutrient agar from frozen stocks and incubated for 18–24 h at 37 °C. To prepare a standardized bacterial inoculum, isolated colonies were suspended in Mueller-Hinton Broth (MHB) and adjusted to an optical density of 0.08–0.1 at 600 nm, equivalent to a 0.5 McFarland standard and representing approximately 1–2 × 10<sup>8</sup> CFU/mL (CFU: colony forming units). The inoculum was diluted 1/250 in MHB to the target concentration of (5 ± 3) × 10<sup>5</sup> CFU/mL. Total viability counts from the final inoculum were examined to confirm the target bacterial density was obtained.</p>
        <p id="Par82">Selected candidate AMPs were purchased from Genscript (Piscataway, NJ), where they were synthesized using the vendor’s Flexpeptide platform. Lyophilized peptides were suspended in sterile ultrapure water or filter-sterilized 0.2% acetic acid as recommended by solubility testing reports provided with the GenScript synthesis. AMPs were diluted from 2560 to 5 μg/mL by a two-fold serial dilution in a 96-well polypropylene microtitre plate before 100 μl of the standardized bacterial inoculum of (5 ± 3) × 10<sup>5</sup> CFU/mL was added to each well. This generated a final test range of 256 to 0.5 μg/mL. MIC values were reported as the peptide concentration that produced no visible bacterial growth after a 16–24 h incubation at 37 °C.</p>
      </sec>
      <sec id="Sec18">
        <title>Determination of MBC</title>
        <p id="Par83">For each AMP dilution series, the contents of the MIC well and the two adjacent wells containing two- and four-fold MIC were plated onto nonselective nutrient agar and incubated for 24 h at 37 °C. The concentration which killed 99.9% of the initial inoculum was determined to be the MBC.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec19">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12864_2022_8310_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1: Supplementary Note S1</bold>: Performance comparison of AMP Scanner Vr.2 and AMPlify re-trained on the AMP Scanner Vr.2 dataset. <bold>Supplementary Note S2</bold>: Performance comparison of different AMP prediction tools based on the test sequence similarities to their corresponding training sets. <bold>Supplementary Note S3</bold>: Comparison of different AMP prediction tools tested on similar sequences with different labels. <bold>Supplementary Figure S1</bold>: Learning curve comparison (on the validation sets for early stopping) of single sub-models of AMPlify trained on two different datasets. (a) Single sub-models of AMPlify trained on our own training set; (b) Single sub-models of AMPlify trained on the AMP Scanner Vr.2 “Train+Tune” partitions. Square markers denote the best epochs chosen by early stopping, and the x-axes have been set in the same range in order for a clearer comparison. <bold>Supplementary Figure S2</bold>: UpSet plot of the 101 candidate mature sequences with regard to the three filters. This plot visualizes the results obtained by applying different combinations of filters to the 101 candidate mature sequences. <bold>Supplementary Figure S3</bold>: Workflow of selecting the non-AMP sequences from the UniProtKB/Swiss-Prot database. <bold>Supplementary Figure S4</bold>: Workflow of the AMP discovery pipeline. The process describes how 75 putative AMPs were identified from the bullfrog genome. Invalid sequences denote those not suitable for AMPlify prediction, with lengths outside the range 2 to 200 amino acids or with non-standard amino acids. <bold>Supplementary Table S1</bold>: Stratified 5-fold cross-validation results of different architectures on the training set. The top section compares the architecture of AMPlify, with and without ensemble learning, with its simpler variations. The second section shows the architecture of AMP Scanner Vr.2 cross-validated on our training set. Values of accuracy (acc), sensitivity (sens), specificity (spec), F1 score (F1) and area under the receiver operating characteristic curve (AUROC) are presented along with their standard deviations in percentage. <bold>Supplementary Table S2</bold>: Comparison between AMP Scanner Vr.2 and AMPlify cross-validated on all data provided by AMP Scanner Vr.2 (“Train+Tune+Test” partitions). This table shows the 10-fold cross-validation results of AMP Scanner Vr.2 and AMPlify on all data provided by AMP Scanner Vr.2. Values of accuracy (acc), sensitivity (sens), specificity (spec) and area under the receiver operating characteristic curve (AUROC) are presented along with their standard deviations in percentage. <bold>Supplementary Table S3</bold>: Performance comparison between AMP Scanner Vr.2 and AMPlify re-trained on the AMP Scanner Vr.2 “Train+Tune” partitions and tested on their “Test” partition. Since AMPlify applies early stopping and the exact size of training set for each single sub-model is smaller, the exact training size for each model is listed here in the second column. Values of accuracy (acc), sensitivity (sens), specificity (spec) and area under the receiver operating characteristic curve (AUROC) are presented in percentage. <bold>Supplementary Table S4</bold>: Minimum inhibitory concentrations (MIC) and minimum bactericidal concentrations (MBC) of selected AMP candidates following antimicrobial susceptibility testing (AST) in vitro. This is a supplementary table to Table <xref rid="Tab3" ref-type="table">3</xref>. Candidate antimicrobial peptides were synthesized and purchased from Genscript. AST, and MIC/MBC determination was performed as outlined by the Clinical and Laboratory Standards Institute (CLSI), with modification as recommended by Hancock. Data is presented as the lowest effective peptide concentration range (μg/mL) observed in three independent experiments. LL37, human cathelicidin and a peptide from Tp0751 from <italic>Treponema pallidum</italic> were used as the positive and negative control peptides, respectively. <bold>Supplementary Table S5</bold>: Predictions of Gaegurin 5 (GGN5) and its analogues by different AMP prediction tools. Antimicrobial activity data of GGN5 and its analogues were taken from the work by Won and con-workers. The analogues were generated by truncating the parent peptide into shorter fragments and/or by amino acid substitutions. Prediction results of AMPlify, AMP Scanner Vr.2, and iAMPpred were listed for comparison.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>Acc</term>
        <def>
          <p id="Par4">Accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>AMP</term>
        <def>
          <p id="Par5">Antimicrobial peptide</p>
        </def>
      </def-item>
      <def-item>
        <term>APD</term>
        <def>
          <p id="Par6">Antimicrobial Peptide Database</p>
        </def>
      </def-item>
      <def-item>
        <term>AST</term>
        <def>
          <p id="Par7">Antimicrobial susceptibility testing</p>
        </def>
      </def-item>
      <def-item>
        <term>ATCC</term>
        <def>
          <p id="Par8">American Type Culture Collection</p>
        </def>
      </def-item>
      <def-item>
        <term>AUROC</term>
        <def>
          <p id="Par9">Area under the receiver operating characteristic curve</p>
        </def>
      </def-item>
      <def-item>
        <term>BART</term>
        <def>
          <p id="Par10">Bullfrog Annotation Reference for the Transcriptome</p>
        </def>
      </def-item>
      <def-item>
        <term>Bi-LSTM</term>
        <def>
          <p id="Par11">Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>CA</term>
        <def>
          <p id="Par12">Context attention</p>
        </def>
      </def-item>
      <def-item>
        <term>CAMP</term>
        <def>
          <p id="Par13">Collection of Antimicrobial Peptides</p>
        </def>
      </def-item>
      <def-item>
        <term>CLSI</term>
        <def>
          <p id="Par14">Clinical and Laboratory Standards Institute</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par15">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>CPO</term>
        <def>
          <p id="Par16">Carbapenemase-producing organism</p>
        </def>
      </def-item>
      <def-item>
        <term>DADP</term>
        <def>
          <p id="Par17">Database of Anuran Defense Peptides</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p id="Par18">Long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>MBC</term>
        <def>
          <p id="Par19">Minimum bactericidal concentration</p>
        </def>
      </def-item>
      <def-item>
        <term>MDR</term>
        <def>
          <p id="Par20">Multi-drug resistant</p>
        </def>
      </def-item>
      <def-item>
        <term>MHB</term>
        <def>
          <p id="Par21">Mueller-Hinton Broth</p>
        </def>
      </def-item>
      <def-item>
        <term>MHSDPA</term>
        <def>
          <p id="Par22">Multi-head scaled dot-product attention</p>
        </def>
      </def-item>
      <def-item>
        <term>MIC</term>
        <def>
          <p id="Par23">Minimum inhibitory concentration</p>
        </def>
      </def-item>
      <def-item>
        <term>MRSA</term>
        <def>
          <p id="Par24">Methicillin-resistant <italic>Staphylococcus aureus</italic></p>
        </def>
      </def-item>
      <def-item>
        <term>NDM</term>
        <def>
          <p id="Par25">New-Delhi Metallo-beta-lactamase</p>
        </def>
      </def-item>
      <def-item>
        <term>PseAAC</term>
        <def>
          <p id="Par26">Pseudo amino acid compositions</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par27">Recurrent neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>ROC</term>
        <def>
          <p id="Par28">Receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>Sens</term>
        <def>
          <p id="Par29">Sensitivity</p>
        </def>
      </def-item>
      <def-item>
        <term>Spec</term>
        <def>
          <p id="Par30">Specificity</p>
        </def>
      </def-item>
      <def-item>
        <term>VRSA</term>
        <def>
          <p id="Par31">Vancomycin-resistant <italic>Staphylococcus aureus</italic></p>
        </def>
      </def-item>
      <def-item>
        <term>WHO</term>
        <def>
          <p id="Par32">World Health Organization</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank Dr. Hong Yu and Dr. Karuna Karunakaran for their generous efforts when establishing the laboratory at the BCCDC. We would also like to thank Dr. Anat Yanai for useful suggestions for the manuscript development, and Zhuyi Xue for helpful discussions on the design of the model.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>IB, CCH, CEC, LMNH, and TW conceived of the presented work. IB and CL designed the AMPlify model with help from CY. CL implemented the model with help from CY, FT, and RLW. IB and SAH designed the AMP discovery pipeline with help from CL. CEC, LMNH, and TW provided the bacterial strains tested. SH, CCH, CEC, LMNH, and TW developed the antimicrobial susceptibility testing protocol with input from DS, LB, and SAH. DS, LB, SAH, and SH conducted antimicrobial susceptibility testing. CL, DS, and SAH drafted the manuscript, and all authors were involved in its revision. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by Genome BC and Genome Canada [281ANV; 291PEP]; and the National Institutes of Health [2R01HG007182-04A1]. The content of this paper is solely the responsibility of the authors, and does not necessarily represent the official views of our funding organizations. Additional support was provided by the Canadian Agricultural Partnership, a federal-provincial-territorial initiative, under the Canada-BC Agri-Innovation Program. The program is delivered by the Investment Agriculture Foundation of BC. The Government of Canada, the BC Ministry of Agriculture, Food and Fisheries, and its directors, agents, employees, or contractors will not be liable for any claims, damages, or losses of any kind whatsoever arising out of the use of, or reliance upon, this information.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The source code for AMPlify and the trained models are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/bcgsc/AMPlify">https://github.com/bcgsc/AMPlify</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par84">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par85">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par86">IB is a co-founder of and executive at Amphoraxe Life Sciences Inc.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Reardon</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Antibiotic resistance sweeping developing world</article-title>
        <source>Nature.</source>
        <year>2014</year>
        <volume>509</volume>
        <fpage>141</fpage>
        <lpage>142</lpage>
        <pub-id pub-id-type="doi">10.1038/509141a</pub-id>
        <?supplied-pmid 24805322?>
        <pub-id pub-id-type="pmid">24805322</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brandenburg</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Heinbockel</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Correa</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lohner</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Peptides with dual mode of action: killing bacteria and preventing endotoxin-induced sepsis</article-title>
        <source>Biochim Biophys Acta Biomembr</source>
        <year>2016</year>
        <volume>1858</volume>
        <fpage>971</fpage>
        <lpage>979</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bbamem.2016.01.011</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>De Lucca</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Walsh</surname>
            <given-names>TJ</given-names>
          </name>
        </person-group>
        <article-title>Antifungal peptides: novel therapeutic compounds against emerging pathogens</article-title>
        <source>Antimicrob Agents Chemother</source>
        <year>1999</year>
        <volume>43</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="doi">10.1128/AAC.43.1.1</pub-id>
        <?supplied-pmid 9869556?>
        <pub-id pub-id-type="pmid">9869556</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klotman</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>TL</given-names>
          </name>
        </person-group>
        <article-title>Defensins in innate antiviral immunity</article-title>
        <source>Nat Rev Immunol</source>
        <year>2006</year>
        <volume>6</volume>
        <fpage>447</fpage>
        <lpage>456</lpage>
        <pub-id pub-id-type="doi">10.1038/nri1860</pub-id>
        <?supplied-pmid 16724099?>
        <pub-id pub-id-type="pmid">16724099</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gallo</surname>
            <given-names>RL</given-names>
          </name>
        </person-group>
        <article-title>Antimicrobial peptides</article-title>
        <source>Curr Biol</source>
        <year>2016</year>
        <volume>26</volume>
        <fpage>R14</fpage>
        <lpage>R19</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2015.11.017</pub-id>
        <?supplied-pmid 26766224?>
        <pub-id pub-id-type="pmid">26766224</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fantner</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Barbero</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Gray</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Belcher</surname>
            <given-names>AM</given-names>
          </name>
        </person-group>
        <article-title>Kinetics of antimicrobial peptide activity measured on individual bacterial cells using high-speed atomic force microscopy</article-title>
        <source>Nat Nanotechnol</source>
        <year>2010</year>
        <volume>5</volume>
        <fpage>280</fpage>
        <lpage>285</lpage>
        <pub-id pub-id-type="doi">10.1038/nnano.2010.29</pub-id>
        <?supplied-pmid 20228787?>
        <pub-id pub-id-type="pmid">20228787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Baeder</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Regoes</surname>
            <given-names>RR</given-names>
          </name>
          <name>
            <surname>Rolff</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Predicting drug resistance evolution: insights from antimicrobial peptides and antibiotics</article-title>
        <source>Proc R Soc B Biol Sci</source>
        <year>2018</year>
        <volume>285</volume>
        <fpage>20172687</fpage>
        <pub-id pub-id-type="doi">10.1098/rspb.2017.2687</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rodríguez-Rojas</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Makarova</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Rolff</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Antimicrobials, stress and mutagenesis. Zasloff M, editor</article-title>
        <source>PLoS Pathog</source>
        <year>2014</year>
        <volume>10</volume>
        <fpage>e1004445</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.ppat.1004445</pub-id>
        <?supplied-pmid 25299705?>
        <pub-id pub-id-type="pmid">25299705</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rodríguez-Rojas</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Makarova</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Rolff</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Cationic Peptides Facilitate Iron-induced Mutagenesis in Bacteria</article-title>
        <source>PLOS Genet</source>
        <year>2015</year>
        <volume>11</volume>
        <fpage>e1005546</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pgen.1005546</pub-id>
        <?supplied-pmid 26430769?>
        <pub-id pub-id-type="pmid">26430769</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boman</surname>
            <given-names>HG</given-names>
          </name>
        </person-group>
        <article-title>Antibacterial peptides: basic facts and emerging concepts</article-title>
        <source>J Intern Med</source>
        <year>2003</year>
        <volume>254</volume>
        <fpage>197</fpage>
        <lpage>215</lpage>
        <pub-id pub-id-type="doi">10.1046/j.1365-2796.2003.01228.x</pub-id>
        <?supplied-pmid 12930229?>
        <pub-id pub-id-type="pmid">12930229</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aghapour</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Gholizadeh</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ganbarov</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Bialvaei</surname>
            <given-names>AZ</given-names>
          </name>
          <name>
            <surname>Mahmood</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Tanomand</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Molecular mechanisms related to colistin resistance in Enterobacteriaceae</article-title>
        <source>Infect Drug Resist</source>
        <year>2019</year>
        <volume>12</volume>
        <fpage>965</fpage>
        <lpage>975</lpage>
        <pub-id pub-id-type="doi">10.2147/IDR.S199844</pub-id>
        <?supplied-pmid 31190901?>
        <pub-id pub-id-type="pmid">31190901</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Ke</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Recent Progress in machine learning-based prediction of peptide activity for drug discovery</article-title>
        <source>Curr Top Med Chem</source>
        <year>2019</year>
        <volume>19</volume>
        <fpage>4</fpage>
        <lpage>16</lpage>
        <pub-id pub-id-type="doi">10.2174/1568026619666190122151634</pub-id>
        <?supplied-pmid 30674262?>
        <pub-id pub-id-type="pmid">30674262</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Waghu</surname>
            <given-names>FH</given-names>
          </name>
          <name>
            <surname>Barai</surname>
            <given-names>RS</given-names>
          </name>
          <name>
            <surname>Gurung</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Idicula-Thomas</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>CAMPR3: A database on sequences, structures and signatures of antimicrobial peptides</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <fpage>D1094</fpage>
        <lpage>D1097</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv1051</pub-id>
        <?supplied-pmid 26467475?>
        <pub-id pub-id-type="pmid">26467475</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Waghu</surname>
            <given-names>FH</given-names>
          </name>
          <name>
            <surname>Gopi</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Barai</surname>
            <given-names>RS</given-names>
          </name>
          <name>
            <surname>Ramteke</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Nizami</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Idicula-Thomas</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>CAMP: collection of sequences and structures of antimicrobial peptides</article-title>
        <source>Nucleic Acids Res</source>
        <year>2014</year>
        <volume>42</volume>
        <fpage>D1154</fpage>
        <lpage>D1158</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkt1157</pub-id>
        <?supplied-pmid 24265220?>
        <pub-id pub-id-type="pmid">24265220</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>W-Z</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>J-H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <article-title>iAMP-2L: A two-level multi-label classifier for identifying antimicrobial peptides and their functional types</article-title>
        <source>Anal Biochem</source>
        <year>2013</year>
        <volume>436</volume>
        <fpage>168</fpage>
        <lpage>177</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2013.01.019</pub-id>
        <?supplied-pmid 23395824?>
        <pub-id pub-id-type="pmid">23395824</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meher</surname>
            <given-names>PK</given-names>
          </name>
          <name>
            <surname>Sahu</surname>
            <given-names>TK</given-names>
          </name>
          <name>
            <surname>Saini</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>AR</given-names>
          </name>
        </person-group>
        <article-title>Predicting antimicrobial peptides with improved accuracy by incorporating the compositional, physico-chemical and structural features into Chou’s general PseAAC</article-title>
        <source>Sci Rep</source>
        <year>2017</year>
        <volume>7</volume>
        <fpage>42362</fpage>
        <pub-id pub-id-type="doi">10.1038/srep42362</pub-id>
        <?supplied-pmid 28205576?>
        <pub-id pub-id-type="pmid">28205576</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Deep learning in bioinformatics: introduction, application, and perspective in the big data era</article-title>
        <source>Methods.</source>
        <year>2019</year>
        <volume>166</volume>
        <fpage>4</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ymeth.2019.04.008</pub-id>
        <?supplied-pmid 31022451?>
        <pub-id pub-id-type="pmid">31022451</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <?supplied-pmid 9377276?>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gers</surname>
            <given-names>FA</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cummins</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Learning to forget: continual prediction with LSTM</article-title>
        <source>Neural Comput</source>
        <year>2000</year>
        <volume>12</volume>
        <fpage>2451</fpage>
        <lpage>2471</lpage>
        <pub-id pub-id-type="doi">10.1162/089976600300015015</pub-id>
        <?supplied-pmid 11032042?>
        <pub-id pub-id-type="pmid">11032042</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schuster</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>KK</given-names>
          </name>
        </person-group>
        <article-title>Bidirectional recurrent neural networks</article-title>
        <source>IEEE Trans Signal Process</source>
        <year>1997</year>
        <volume>45</volume>
        <fpage>2673</fpage>
        <lpage>2681</lpage>
        <pub-id pub-id-type="doi">10.1109/78.650093</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Youmans M, Spainhour C, Qiu P. Long short-term memory recurrent neural networks for antibacterial peptide identification. In: 2017 IEEE Int Conf Bioinforma biomed: IEEE; 2017. p. 498–502.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bhadra</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sethiya</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Qin</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Tai</surname>
            <given-names>HK</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep-AmPEP30: improve short antimicrobial peptides prediction with deep learning</article-title>
        <source>Mol Ther Nucleic Acids</source>
        <year>2020</year>
        <volume>20</volume>
        <fpage>882</fpage>
        <lpage>894</lpage>
        <pub-id pub-id-type="doi">10.1016/j.omtn.2020.05.006</pub-id>
        <?supplied-pmid 32464552?>
        <pub-id pub-id-type="pmid">32464552</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Mikolov</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Corrado</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Efficient estimation of word representations in vector space. 1st Int Conf learn represent ICLR 2013 - Work Track Proc</source>
        <year>2013</year>
        <fpage>1</fpage>
        <lpage>12</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sharma</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Shrivastava</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar Singh</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Saxena</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Deep-ABPpred: identifying antibacterial peptides in protein sequences using bidirectional LSTM with word2vec</article-title>
        <source>Brief Bioinform</source>
        <year>2021</year>
        <volume>00</volume>
        <fpage>1</fpage>
        <lpage>19</lpage>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Garlick</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zloh</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for novel antimicrobial peptide design</article-title>
        <source>Biomolecules.</source>
        <year>2021</year>
        <volume>11</volume>
        <fpage>471</fpage>
        <pub-id pub-id-type="doi">10.3390/biom11030471</pub-id>
        <?supplied-pmid 33810011?>
        <pub-id pub-id-type="pmid">33810011</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Veltri</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Kamath</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Shehu</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Deep learning improves antimicrobial peptide recognition</article-title>
        <source>Bioinformatics.</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>2740</fpage>
        <lpage>2747</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty179</pub-id>
        <?supplied-pmid 29590297?>
        <pub-id pub-id-type="pmid">29590297</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Li S, Li W, Cook C, Zhu C, Gao Y. Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN. In: Proceedings of the IEEE Conference on CVPR; 2018. p. 5457–66.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hazarika</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Poria</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cambria</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Recent trends in deep learning based natural language processing [review article]</article-title>
        <source>IEEE Comput Intell Mag</source>
        <year>2018</year>
        <volume>13</volume>
        <fpage>55</fpage>
        <lpage>75</lpage>
        <pub-id pub-id-type="doi">10.1109/MCI.2018.2840738</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bahdanau</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Neural machine translation by jointly learning to align and translate</article-title>
        <source>3rd Int Conf learn represent ICLR 2015 - Conf Track Proc</source>
        <year>2015</year>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. Attention is all you need. In: Advances in Neural Information Processing Systems; 2017. p. 6000–10.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dyer</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Smola</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hovy</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <source>Hierarchical Attention Networks for Document Classification. Proc 2016 Conf north am chapter Assoc Comput linguist hum Lang Technol</source>
        <year>2016</year>
        <publisher-loc>Stroudsburg, PA, USA</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
        <fpage>1480</fpage>
        <lpage>1489</lpage>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kiros</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Show, Attend and tell: neural image caption generation with visual attention</article-title>
        <source>32nd Int Conf Mach Learn ICML 2015</source>
        <year>2015</year>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hammond</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Warren</surname>
            <given-names>RL</given-names>
          </name>
          <name>
            <surname>Vandervalk</surname>
            <given-names>BP</given-names>
          </name>
          <name>
            <surname>Kucuk</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Gibb</surname>
            <given-names>EA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The north American bullfrog draft genome provides insight into hormonal regulation of long noncoding RNA</article-title>
        <source>Nat Commun</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>1433</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-017-01316-7</pub-id>
        <?supplied-pmid 29127278?>
        <pub-id pub-id-type="pmid">29127278</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Helbing</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Hammond</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Jackman</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Houston</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Warren</surname>
            <given-names>RL</given-names>
          </name>
          <name>
            <surname>Cameron</surname>
            <given-names>CE</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Antimicrobial peptides from Rana [Lithobates] catesbeiana: gene structure and bioinformatic identification of novel forms from tadpoles</article-title>
        <source>Sci Rep</source>
        <year>2019</year>
        <volume>9</volume>
        <fpage>1529</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-018-38442-1</pub-id>
        <?supplied-pmid 30728430?>
        <pub-id pub-id-type="pmid">30728430</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">World Health Organization. WHO publishes list of bacteria for which new antibiotics are urgently needed [Internet]. 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/en/news-room/detail/27-02-2017-who-publishes-list-of-bacteria-for-which-new-antibiotics-are-urgently-needed">https://www.who.int/en/news-room/detail/27-02-2017-who-publishes-list-of-bacteria-for-which-new-antibiotics-are-urgently-needed</ext-link>. Accessed 22 Sept 2017.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bingen</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fitoussi</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Doit</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Tanna</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>George</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Resistance to macrolides in streptococcus pyogenes in France in pediatric patients</article-title>
        <source>Antimicrob Agents Chemother</source>
        <year>2000</year>
        <volume>44</volume>
        <fpage>1453</fpage>
        <lpage>1457</lpage>
        <pub-id pub-id-type="doi">10.1128/AAC.44.6.1453-1457.2000</pub-id>
        <?supplied-pmid 10817692?>
        <pub-id pub-id-type="pmid">10817692</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vanhoye</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bruston</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Nicolas</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Amiche</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Antimicrobial peptides from hylid and ranin frogs originated from a 150-million-year-old ancestral precursor with a conserved signal peptide but a hypermutable antimicrobial domain</article-title>
        <source>Eur J Biochem</source>
        <year>2003</year>
        <volume>270</volume>
        <fpage>2068</fpage>
        <lpage>2081</lpage>
        <pub-id pub-id-type="doi">10.1046/j.1432-1033.2003.03584.x</pub-id>
        <?supplied-pmid 12709067?>
        <pub-id pub-id-type="pmid">12709067</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Zhao R-L, Han J-Y, Han W-Y, He H-X, Ma J-F. Effects of two novel peptides from skin of <italic>Lithobates Catesbeianus</italic> on tumor cell morphology and proliferation. In: Mol Cloning - Sel Appl Med Biol: InTech; 2011.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Novković M, Simunić J, Bojović V, Tossi A, Juretić D. DADP: the database of anuran defense peptides. Bioinformatics. 2012;28:1406–7.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Clinical and Laboratory Standards Institute. Methods for dilution antimicrobial susceptibility tests for bacteria that grow aerobically: approved standard. CLSI document M07-A10. Wayne, PA: Clinical and Laboratory Standards Institute; 2015.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Hancock REW. Modified MIC method for cationic antimicrobial peptides [Internet]. 1999. Available from: <ext-link ext-link-type="uri" xlink:href="http://cmdr.ubc.ca/bobh/method/modified-mic-method-for-cationic-antimicrobial-peptides/">http://cmdr.ubc.ca/bobh/method/modified-mic-method-for-cationic-antimicrobial-peptides/</ext-link>. Accessed 22 Sept 2017.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cameron</surname>
            <given-names>CE</given-names>
          </name>
          <name>
            <surname>Brouwer</surname>
            <given-names>NL</given-names>
          </name>
          <name>
            <surname>Tisch</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Kuroiwa</surname>
            <given-names>JMY</given-names>
          </name>
        </person-group>
        <article-title>Defining the interaction of the Treponema pallidum Adhesin Tp0751 with laminin</article-title>
        <source>Infect Immun</source>
        <year>2005</year>
        <volume>73</volume>
        <fpage>7485</fpage>
        <lpage>7494</lpage>
        <pub-id pub-id-type="doi">10.1128/IAI.73.11.7485-7494.2005</pub-id>
        <?supplied-pmid 16239550?>
        <pub-id pub-id-type="pmid">16239550</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lorenzon</surname>
            <given-names>EN</given-names>
          </name>
          <name>
            <surname>Piccoli</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Santos-Filho</surname>
            <given-names>NA</given-names>
          </name>
          <name>
            <surname>Cilli</surname>
            <given-names>EM</given-names>
          </name>
        </person-group>
        <article-title>Dimerization of antimicrobial peptides: A promising strategy to enhance antimicrobial peptide activity</article-title>
        <source>Protein Pept Lett</source>
        <year>2019</year>
        <volume>26</volume>
        <fpage>98</fpage>
        <lpage>107</lpage>
        <pub-id pub-id-type="doi">10.2174/0929866526666190102125304</pub-id>
        <?supplied-pmid 30605048?>
        <pub-id pub-id-type="pmid">30605048</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>APD3: the antimicrobial peptide database as a tool for research and education</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <fpage>D1087</fpage>
        <lpage>D1093</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv1278</pub-id>
        <?supplied-pmid 26602694?>
        <pub-id pub-id-type="pmid">26602694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Won</surname>
            <given-names>H-S</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>S-J</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>HE</given-names>
          </name>
          <name>
            <surname>Seo</surname>
            <given-names>M-D</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>B-J</given-names>
          </name>
        </person-group>
        <article-title>Systematic peptide engineering and structural characterization to search for the shortest antimicrobial peptide analogue of gaegurin 5</article-title>
        <source>J Biol Chem</source>
        <year>2004</year>
        <volume>279</volume>
        <fpage>14784</fpage>
        <lpage>14791</lpage>
        <pub-id pub-id-type="doi">10.1074/jbc.M309822200</pub-id>
        <?supplied-pmid 14739294?>
        <pub-id pub-id-type="pmid">14739294</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">The UniProt Consortium. UniProt: a worldwide hub of protein knowledge, vol. 47: Nucleic Acids Res Oxford University Press; 2019. p. D506–15.</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">Bals R. Epithelial antimicrobial peptides in host defense against infection. Respir Res. 2000;1:5.</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Chollet F. Keras [Internet]. 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://keras.io">https://keras.io</ext-link>. Accessed 17 Apr 2019.</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, et al. TensorFlow: large-scale machine learning on heterogeneous systems [Internet]. 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org">https://www.tensorflow.org</ext-link>. Accessed 17 Apr 2019.</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Kingma</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Ba</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Adam: A method for stochastic optimization</article-title>
        <source>3rd Int Conf learn represent ICLR 2015 - Conf Track Proc</source>
        <year>2015</year>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R. Dropout: A simple way to prevent neural networks from overfitting. J Mach Learn Res. 2014;15:1929−58.</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Nacu</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Fast and SNP-tolerant detection of complex variants and splicing in short reads</article-title>
        <source>Bioinformatics.</source>
        <year>2010</year>
        <volume>26</volume>
        <fpage>873</fpage>
        <lpage>881</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq057</pub-id>
        <?supplied-pmid 20147302?>
        <pub-id pub-id-type="pmid">20147302</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Holt</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yandell</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>MAKER2: an annotation pipeline and genome-database management tool for second-generation genome projects</article-title>
        <source>BMC Bioinformatics.</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>491</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-12-491</pub-id>
        <?supplied-pmid 22192575?>
        <pub-id pub-id-type="pmid">22192575</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keller</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Kollmar</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Stanke</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Waack</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>A novel hybrid gene prediction method employing protein multiple sequence alignments</article-title>
        <source>Bioinformatics.</source>
        <year>2011</year>
        <volume>27</volume>
        <fpage>757</fpage>
        <lpage>763</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr010</pub-id>
        <?supplied-pmid 21216780?>
        <pub-id pub-id-type="pmid">21216780</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <mixed-citation publication-type="other">Slater GSC, Birney E. Automated generation of heuristics for biological sequence comparison. BMC Bioinformatics. 2005;6:31.</mixed-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lomsadze</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Gene identification in novel eukaryotic genomes by self-training algorithm</article-title>
        <source>Nucleic Acids Res</source>
        <year>2005</year>
        <volume>33</volume>
        <fpage>6494</fpage>
        <lpage>6506</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gki937</pub-id>
        <?supplied-pmid 16314312?>
        <pub-id pub-id-type="pmid">16314312</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Korf I. Gene finding in novel genomes. BMC Bioinformatics. 2004;5:59.</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Camacho C, Coulouris G, Avagyan V, Ma N, Papadopoulos J, Bealer K, et al. BLAST+: architecture and applications. BMC Bioinformatics. 2009;10:421.</mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">Smit A, Hubley R, Grenn P. RepeatMasker Open-4.0 [Internet]. 2015. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.repeatmasker.org">http://www.repeatmasker.org</ext-link>. Accessed 30 Jan 2020.</mixed-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>LT</given-names>
          </name>
          <name>
            <surname>Chau</surname>
            <given-names>JK</given-names>
          </name>
          <name>
            <surname>Perry</surname>
            <given-names>NA</given-names>
          </name>
          <name>
            <surname>de Boer</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zaat</surname>
            <given-names>SAJ</given-names>
          </name>
          <name>
            <surname>Vogel</surname>
            <given-names>HJ</given-names>
          </name>
        </person-group>
        <article-title>Serum stabilities of short tryptophan- and arginine-rich antimicrobial peptide analogs. Vij N, editor</article-title>
        <source>PLoS One</source>
        <year>2010</year>
        <volume>5</volume>
        <fpage>e12684</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0012684</pub-id>
        <?supplied-pmid 20844765?>
        <pub-id pub-id-type="pmid">20844765</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
