<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6933638</article-id>
    <article-id pub-id-type="publisher-id">3279</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-019-3279-2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Fast and accurate microRNA search using CNN</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tang</surname>
          <given-names>Xubo</given-names>
        </name>
        <address>
          <email>xubotang2-c@my.cityu.edu.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1373-8023</contrib-id>
        <name>
          <surname>Sun</surname>
          <given-names>Yanni</given-names>
        </name>
        <address>
          <email>yannisun@cityu.edu.hk</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1">Department of Electronic Engineering, City University of Hong Kong, Kowloon Tong, Hong Kong SAR </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <issue>Suppl 23</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. Supplement Editors were not responsible for the review of papers they had authored. No other competing interests were declared.</issue-sponsor>
    <elocation-id>646</elocation-id>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>11</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>18</day>
        <month>11</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">There are many different types of microRNAs (miRNAs) and elucidating their functions is still under intensive research. A fundamental step in functional annotation of a new miRNA is to classify it into characterized miRNA families, such as those in Rfam and miRBase. With the accumulation of annotated miRNAs, it becomes possible to use deep learning-based models to classify different types of miRNAs. In this work, we investigate several key issues associated with successful application of deep learning models for miRNA classification. First, as secondary structure conservation is a prominent feature for noncoding RNAs including miRNAs, we examine whether secondary structure-based encoding improves classification accuracy. Second, as there are many more non-miRNA sequences than miRNAs, instead of assigning a negative class for all non-miRNA sequences, we test whether using softmax output can distinguish in-distribution and out-of-distribution samples. Finally, we investigate whether deep learning models can correctly classify sequences from small miRNA families.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We present our trained convolutional neural network (CNN) models for classifying miRNAs using different types of feature learning and encoding methods. In the first method, we explicitly encode the predicted secondary structure in a matrix. In the second method, we use only the primary sequence information and one-hot encoding matrix. In addition, in order to reject sequences that should not be classified into targeted miRNA families, we use a threshold derived from softmax layer to exclude out-of-distribution sequences, which is an important feature to make this model useful for real transcriptomic data. The comparison with the state-of-the-art ncRNA classification tools such as Infernal shows that our method can achieve comparable sensitivity and accuracy while being significantly faster.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">Automatic feature learning in CNN can lead to better classification accuracy and sensitivity for miRNA classification and annotation. The trained models and also associated codes are freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/HubertTang/DeepMir">https://github.com/HubertTang/DeepMir</ext-link>.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Convolution neural network (CNN)</kwd>
      <kwd>Deep learning</kwd>
      <kwd>microRNA</kwd>
      <kwd>Open set problem</kwd>
    </kwd-group>
    <conference xlink:href="https://www.abacbs.org/conference2019/about">
      <conf-name>Joint 30th International Conference on Genome Informatics (GIW) &amp; Australian Bioinformatics and Computational Biology Society (ABACBS) Annual Conference</conf-name>
      <conf-loc>Sydney, Australia</conf-loc>
      <conf-date>9-11 December 2019</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p>Non-coding RNAs (ncRNAs) refer to the RNAs that do not encode proteins and function directly as RNAs. Genome annotation of many different genomes show that ncRNAs are ubiquitous and have various important functions [<xref ref-type="bibr" rid="CR1">1</xref>]. Besides commonly seen house-keeping ncRNAs such as transfer RNAs (tRNAs), ribosome RNAs (rRNAs), many small ncRNAs play important roles in gene regulation. This work is mainly concerned with a type of small ncRNA, microRNA (miRNA), which act as key regulators of gene expression at post-transcriptional level in different species [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR5">5</xref>]. In metazoans, mature miRNAs bind to the 3’-UTR of target mRNAs and can repress translation or promote mRNA degradation. As an miRNA can bind to multiple mRNA transcripts, a large number of protein-coding genes can be regulated by miRNAs [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>].</p>
    <p>Because miRNAs’ important functions and their associations with complicated diseases in human, there are intensive research about miRNA gene annotation, target search, function identification etc. A fundamental step in miRNA research is the identification of miRNA genes in genomes. In the canonical miRNA biogenesis pathway, miRNAs are processed from longer transcripts named as primary miRNAs (pri-miRNAs) [<xref ref-type="bibr" rid="CR3">3</xref>]. The hairpin structures of pri-miRNAs are cleaved by a member of RNase II family of enzymes, Drosha and produce precursor miRNA (pre-miRNA) in the nucleus [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>]. Pre-miRNAs are then exported to the cytoplasm, where Dicer cleaves off the loop region of the hairpin and further processes it to mature miRNA(s) of about 21 nucleotides [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>]. MiRNA gene annotation usually refers to identification of pre-miRNAs and mature miRNAs.</p>
    <p>Existing miRNA annotation tools can be generally divided into two groups depending on whether reference miRNA genes are used. Homology-based miRNA search identifies pre-miRNAs by conducting sequence and/or secondary structural similarity search against existing miRNA genes. Like other ncRNAs, pre-miRNAs preserve strong secondary structures [<xref ref-type="bibr" rid="CR2">2</xref>]. Thus, homology search models [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>] that can explicitly encode both sequence and structural similarities usually achieve high sensitivity and accuracy in classifying query sequences into their originating homologous families. However, the high sensitivity comes with a price of high computational cost. For example, structural homology search models based on context-free grammar have cubic running time complexity [<xref ref-type="bibr" rid="CR14">14</xref>]. Even with various heuristic filtration techniques, it can be still very time-consuming to conduct large-scale sequence classification using both sequence and structural alignments. Sequence similarity-based homology search tools such as BLAST [<xref ref-type="bibr" rid="CR15">15</xref>] can be also applied to classify pre-miRNAs to their native families. However, remote homologs with high structural but low sequence conservation tend to be missed. Another group of tools [<xref ref-type="bibr" rid="CR16">16</xref>–<xref ref-type="bibr" rid="CR18">18</xref>] do not use reference sequences for pre-miRNA search. These de novo miRNA search methods mainly use features such as hairpin structures of pre-miRNAs to identify putative pre-miRNAs in genomes. As a large number of regions in a genome can form hair-pin structures, features from RNA-Seq [<xref ref-type="bibr" rid="CR19">19</xref>] data such as expression levels and read mapping patterns are often used to reduce the false positive rate of miRNA search [<xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR23">23</xref>]. Both types of tools are useful for miRNA search and annotation. De novo methods have the advantage of identifying possibly novel miRNAs but additional processing is needed to validate the findings.</p>
    <p>Homology search-based miRNA search methods can take advantage of accumulating characterized miRNAs. For example, MiRBase [<xref ref-type="bibr" rid="CR24">24</xref>] is an online database for miRNA sequences and annotation. The current release 22 contains 1983 miRNA families from 271 organisms, including 38,589 pre-miRNAs and 48,860 mature miRNAs. Rfam [<xref ref-type="bibr" rid="CR25">25</xref>] is a comprehensive ncRNA family database with over 3,000 ncRNA families. The release 14.1 contains 529 pre-miRNA families and 215,122 precursor sequences.</p>
    <p>These classified pre-miRNA sequences can be used as training data for deep learning based models. Depending on the choice of the training sequences and the design of the model architecture, deep learning-based miRNA search can be applied to distinguish miRNAs from other types of ncRNAs and also to conduct finer scale classification for different types of miRNAs. In this work, we explore whether using convolutional neural network (CNN) has advantages in distinguishing different types of miRNAs over powerful covariance models. In particular, we investigated how the input sequence encoding and training set construction affect the performance of miRNA characterization using CNN.</p>
    <p>We choose CNN as the deep learning model because of its recent success in other sequence classification studies [<xref ref-type="bibr" rid="CR26">26</xref>–<xref ref-type="bibr" rid="CR29">29</xref>]. Empirical analyses have shown that CNN can be applied to extract “motifs” from a set of homologous sequences. Motifs are essential features to distinguishing different groups of sequence families including miRNAs. DeepBind [<xref ref-type="bibr" rid="CR26">26</xref>] used a single convolution layer to capture the motif from protein binding sites. DeepFam [<xref ref-type="bibr" rid="CR29">29</xref>] applied the CNN on the protein classification and found that the frequently activated convolution filters are consistent with known motifs. As different miRNA families tend to have different conserved sequences, the convolution layers in CNN are expected to capture distinctive features for fine-grained classification. DanQ [<xref ref-type="bibr" rid="CR30">30</xref>], proposed by Qiang et al., added additional long short term memory (LSTM) layers above the convolution layers to capture the dependency between the separated motifs extracted by convolution layers. But as miRNAs are relatively short, the sequential features within a filter are sufficient for classification.</p>
    <sec id="Sec2">
      <title>Related work</title>
      <p>In this section, we summarize related work on homology search-based miRNA identification. Some homology search tools are designed for comprehensive ncRNA search and can divide miRNAs into different types. For example, there are hundreds of different miRNA families in Rfam. The associated tool, Infernal [<xref ref-type="bibr" rid="CR12">12</xref>], conducts homology search by incorporating both sequence and secondary structure similarities in context-free grammar based models. Input sequences can be classified into different miRNA families for functional inference. For identifying miRNAs with high sequence similarity, generic homology search tools such as BLASTn [<xref ref-type="bibr" rid="CR15">15</xref>] can be applied as well.</p>
      <p>Most tools designed specifically for miRNA search aim to distinguish miRNAs from other types of sequences [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>]. The most successful ones usually employ transcriptomic data to improve the identification accuracy. When the reference genomes are available, reads from small RNA-Seq data are mapped to the reference genomes to locate possible pre-miRNA genes. Features such as the conserved hairpin structure, read mapping patterns on the mature miRNA vs. other regions, expression levels across multiple samples are utilized to screen miRNAs in those candidate regions. From the perspective of machine learning, distinguishing miRNAs from other regions can be formulated as a binary classification problem. Pre-miRNAs have the positive label and all others have the negative label. Classification models such as SVM [<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR35">35</xref>], Random Forest [<xref ref-type="bibr" rid="CR36">36</xref>], and CNN [<xref ref-type="bibr" rid="CR37">37</xref>] have been applied for miRNA search. Being different from these binary classification tools, ours focuses on classifying input sequences into different miRNA families for more detailed function annotation. Unrelated sequences including other types of ncRNAs are rejected using a threshold in the softmax value.</p>
      <p>CNN was also employed by Genta Aoki [<xref ref-type="bibr" rid="CR38">38</xref>] for ncRNA classification. The authors took ncRNA pairwise alignments and associated features as input to CNN and got 98% accuracy for 6 types of ncRNA.</p>
      <p>Advances of feature selection and classification models in machine learning have enhanced the sensitivity and precision for miRNA search. However, highly unbalanced training set is still a challenge for various learning models [<xref ref-type="bibr" rid="CR39">39</xref>]. Being formulated as a binary classification problem, there are significantly more negative samples (non-miRNAs) than positive samples (miRNAs). In addition, there are many different types of non-miRNA sequences. It is not clear how to compose the negative training data from such large and highly diverse sequences.</p>
      <p>In this study, we intend to formulate miRNA search as a multi-label classification problem. Instead of using non-miRNAs as training data, we reject those un-relevant sequences using methods from open set problem [<xref ref-type="bibr" rid="CR40">40</xref>]. In addition, we implemented two types of encoding methods based on whether we explicitly encode the secondary structure information.</p>
    </sec>
  </sec>
  <sec id="Sec3">
    <title>Method</title>
    <p>The deep learning model we choose is Convolutional Neural Network (CNN), which has demonstrated some success in ncRNAs classification [<xref ref-type="bibr" rid="CR38">38</xref>]. We implemented and compared two different encoding methods for CNN-based miRNA classification. In the first encoding method, we explicitly encode secondary structure information into matrices and use these matrices as training/testing data. In the second method, we use one-hot encoding matrix to represent the input sequences and do not take into account predicted secondary structures.</p>
    <sec id="Sec4">
      <title>Explicitly encode secondary structures into matrices</title>
      <p>We implemented three types of matrix to encode the secondary structure information from sequences: <bold>probability matrix, pair matrix, and mixed matrix</bold>. The first two are inspired from adjacency matrix for modeling secondary structures. The structural information is derived from the sequences using RNAfold [<xref ref-type="bibr" rid="CR41">41</xref>], which is one module in the ViennaRNA [<xref ref-type="bibr" rid="CR41">41</xref>] package. As the optimal structure predicted based on Minimum Free Energy (MFE) is often not accurate, we use RNAfold to output both the optimal and suboptimal structures. In addition, we also use the base pairing probabilities computed by the software.</p>
      <p><bold><italic>Probability matrix</italic></bold> simply contains the values of the base pairing probability outputted by RNAfold. For a sequence <italic>s</italic>, the size of the matrix is |<italic>s</italic>|×|<italic>s</italic>|. <italic>P</italic><sub><italic>i</italic>,<italic>j</italic></sub> is the predicted base pairing probability between the <italic>i</italic>th and <italic>j</italic>th base in <italic>s</italic> if the probability <italic>p</italic> is above a given threshold <italic>T</italic>. The equation for defining the value of each cell can be found below.
<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$P_{i,j(probability\ matrix)} =\left\{ \begin{array}{rcl} p &amp; &amp; {if\ p\ \geq\ T}\\ 0 &amp; &amp; {if\ p\ &lt;\ T.} \end{array} \right. $$ \end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>(</mml:mo><mml:mtext mathvariant="italic">probability</mml:mtext><mml:mspace width="1em"/><mml:mtext mathvariant="italic">matrix</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mspace width="1em"/><mml:mo>≥</mml:mo><mml:mspace width="1em"/><mml:mi>T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mspace width="1em"/><mml:mo>&lt;</mml:mo><mml:mspace width="1em"/><mml:mi>T.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2019_3279_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Being different from probability matrix, <bold><italic>pair matrix</italic></bold> distinguishes different base pairs including Watson-Crick pairs and G-U pair. If the base pairing probability is above a given threshold, we will record this base pair using its ID number, which is used to distinguish different base pairs. Depending on whether we take into account the order of the bases in a base pair, different base pairs can be converted into 6 or 3 different values. The conversion rules are summarized in the following equations. <italic>X</italic><sub><italic>i</italic>,<italic>j</italic></sub> refers to an element at position (<italic>i</italic>,<italic>j</italic>) in a pair matrix. <italic>s</italic><sub><italic>i</italic></sub> refers to the <italic>i</italic>th base in sequence <italic>s</italic>. <italic>T</italic> is a given threshold.
<disp-formula id="Equb"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ X_{i,j(pair\ matrix\ with\ order)} = \left\{\begin{array}{ll} 0, &amp;\text{if } {p} &lt; \mathrm{T} \\ 1/6, &amp;\text{if}\ (s_{i} s_{j}=AU)\ \text{and}\ p \geq \mathrm{T} \\ 2/6, &amp;\text{if}\ (s_{i} s_{j}=UA)\ \text{and}\ p \geq \mathrm{T} \\ 3/6, &amp;\text{if}\ (s_{i} s_{j}=CG)\ \text{and}\ p \geq \mathrm{T} \\ 4/6, &amp;\text{if}\ (s_{i} s_{j}=GC)\ \text{and}\ p \geq \mathrm{T} \\ 5/6, &amp;\text{if}\ (s_{i} s_{j}=GU)\ \text{and}\ p \geq \mathrm{T} \\ 6/6, &amp;\text{if}\ (s_{i} s_{j}=UG)\ \text{and}\ p \geq \mathrm{T} \end{array}\right. $$ \end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mspace width="-15.0pt"/><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>(</mml:mo><mml:mtext mathvariant="italic">pair</mml:mtext><mml:mspace width="1em"/><mml:mtext mathvariant="italic">matrix</mml:mtext><mml:mspace width="1em"/><mml:mtext mathvariant="italic">with</mml:mtext><mml:mspace width="1em"/><mml:mtext mathvariant="italic">order</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">AU</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">UA</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">CG</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>4</mml:mn><mml:mo>/</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">GC</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>5</mml:mn><mml:mo>/</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">GU</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>6</mml:mn><mml:mo>/</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">UG</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2019_3279_Article_Equb.gif" position="anchor"/></alternatives></disp-formula> or
<disp-formula id="Equc"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $${\begin{aligned} X_{i,j(pair\ matrix\ without\ order)}\! =&amp;\\ &amp;\left\{\begin{array}{ll} \!0, &amp;\text{if } {p} &lt; \mathrm{T} \\ \!1/3, &amp;\text{if}\ (s_{i} s_{j}\,=\,AU \text{or}\ s_{i} s_{j}\,=\,UA)\!\ \text{and}\ p \geq \mathrm{T} \\ \!2/3, &amp;\text{if}\ (s_{i} s_{j}\,=\,CG \text{or}\ s_{i} s_{j}\,=\,GC)\!\ \text{and}\ p \geq \mathrm{T} \\ \!3/3, &amp;\text{if}\ (s_{i} s_{j}\,=\,GU \text{or}\ s_{i} s_{j}\,=\,UG)\!\ \text{and}\ p \geq \mathrm{T} \end{array}\right. \end{aligned}} $$ \end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>(</mml:mo><mml:mtext mathvariant="italic">pair matrix</mml:mtext><mml:mspace width="1em"/><mml:mtext mathvariant="italic">without</mml:mtext><mml:mspace width="1em"/><mml:mtext mathvariant="italic">order</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mspace width="0.3em"/><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mspace width="0.3em"/><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="0.3em"/><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mtext mathvariant="italic">AU or</mml:mtext><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mtext mathvariant="italic">UA</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="0.3em"/><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="0.3em"/><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mtext mathvariant="italic">CG or</mml:mtext><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mtext mathvariant="italic">GC</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="0.3em"/><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="0.3em"/><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mtext mathvariant="italic">GU or</mml:mtext><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mtext mathvariant="italic">UG</mml:mtext><mml:mo>)</mml:mo><mml:mspace width="0.3em"/><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">T</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2019_3279_Article_Equc.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Combining these two features together, the original 2D matrix will become a 3D matrix with two layers, which is called <bold><italic>mixed matrix</italic></bold>, as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>c. One layer of size |<italic>s</italic>|×|<italic>s</italic>| is the probability matrix and another layer of the same size is the pair matrix. Essentially, this matrix integrates different base pairs with the predicted pairing intensities.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Examples of different encoding matrices. (<bold>a</bold>) Probability matrix; (<bold>b</bold>) Pair matrix; (<bold>c</bold>) Mixed matrix; (<bold>d</bold>) One-hot encoding matrix</p></caption><graphic xlink:href="12859_2019_3279_Fig1_HTML" id="MO1"/></fig></p>
      <p>The pair and mixed matrices can be conveniently visualized as images. We presented the corresponding images for one miRNA and one tRNA in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The threshold <italic>T</italic> is 0.0001 in all the matrices. It is not hard to observe the stacking base pairs of the hairpin and cloverleaf structures of the miRNA and tRNA, respectively. The secondary structures are less obvious in the pair matrix because the cell values in the pair matrix are decided by the base pairs rather than the base pairing probabilities. Given a small <italic>T</italic>, cells with low pairing probabilities might still get a relatively big value because of the conversion rules.
<fig id="Fig2"><label>Fig. 2</label><caption><p>The probability, pair and mixed matrix images of miRNA and tRNA. (<bold>a</bold>), (<bold>b</bold>), (<bold>c</bold>) correspond to probability matrix, ordered pair matrix, mixed matrix of a miRNA sequence respectively. (<bold>d</bold>), (<bold>e</bold>), (<bold>f</bold>) correspond to probability matrix, ordered pair matrix, mixed matrix of a tRNA sequence respectively. For the mixed matrices, the color green is from the layer of probability matrix while blue represents the layer of the pair matrix</p></caption><graphic xlink:href="12859_2019_3279_Fig2_HTML" id="MO2"/></fig></p>
      <sec id="Sec5">
        <title>CNN architecture for the matrices containing base pairing information</title>
        <p>The CNN model contains two convolutional layers, followed by max pooling layers and three fully connected layers. Figure <xref rid="Fig3" ref-type="fig">3</xref> sketches this architecture. To prevent overfitting, dropout is also applied. During the training of the CNN model, several hyperparameters were tuned within the given ranges, which are shown in Table <xref rid="Tab1" ref-type="table">1</xref>. The parameters with best performance were selected. Finally, the hyperparameters were set as follows: number of convolution layers = 2, kernel size for each convolution layer = 2, the number of kernels in the two convolution layer = 64: 128, pooling method = max pooling, number of units in two fully connected layer = 256: 128, learning algorithm = Adam, dropout rate = 0.5, learning rate = 0.001, batch size = 32. The CNN model was implemented in Keras [<xref ref-type="bibr" rid="CR42">42</xref>].
<fig id="Fig3"><label>Fig. 3</label><caption><p>CNN structure of the probability/pair/mixed matrix</p></caption><graphic xlink:href="12859_2019_3279_Fig3_HTML" id="MO3"/></fig>
<table-wrap id="Tab1"><label>Table 1</label><caption><p>The list of the tuned hyperparameters</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Hyperparameter</th><th align="left">Prob/pair/mixed matrix</th><th align="left">One-hot matrix</th></tr></thead><tbody><tr><td align="justify">Number of convolution layers</td><td align="justify">2, 4, 6</td><td align="justify">1</td></tr><tr><td align="justify">Kernel size for convolution</td><td align="justify">2, 3, 5</td><td align="justify">[8, 16], [4, 8, 12, 16], [2, 4, 6, 8, 10, 12, 14, 16]</td></tr><tr><td align="justify"/><td align="justify"/><td align="justify">[2, 4, 6, 8, 10, 12, 14, 16]</td></tr><tr><td align="justify"/><td align="justify"/><td align="justify">[2, 4, 6, 8, 10, 12, 14, 16]</td></tr><tr><td align="justify">Number of kernels (1st convolution layer)</td><td align="justify">16, 32, 64</td><td align="justify">64, 128, 256, 512</td></tr><tr><td align="justify">Number of kernels (2nd convolution layer)</td><td align="justify">32, 64, 128</td><td align="justify">not applicable</td></tr><tr><td align="left">Pooling method</td><td align="justify">Max pooling, average pooling</td><td align="justify"/></tr><tr><td align="justify">Number of units (1st fully connected layer)</td><td align="justify">64, 128,256</td><td align="justify">128, 256, 512</td></tr><tr><td align="justify">Number of units (2nd fully connected layer)</td><td align="justify">32, 64, 128</td><td align="justify">not applicable</td></tr><tr><td align="left">Learning algorithm</td><td align="justify">Adam, SGD</td><td align="justify"/></tr><tr><td align="left">Dropout rate</td><td align="justify">0.7, 0.5</td><td align="justify"/></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
    <sec id="Sec6">
      <title>Encoding the sequence using one-hot matrix</title>
      <p>One-hot encoding matrix has been successfully used in encoding genomic sequences for deep learning models. Essentially, the sequence is converted to a |<italic>s</italic>|×4 one-hot encodidng matrix, where |<italic>s</italic>| is the length of an input sequence and 4 is the number of different bases. Let the matrix be <italic>M</italic>, where <italic>M</italic><sub><italic>i</italic>,<italic>j</italic></sub> is 1 if the <italic>i</italic>th base in the input sequence is the <italic>j</italic>th character in the alphabet. For any other characters, <italic>M</italic><sub><italic>i</italic>,<italic>j</italic></sub> is 0 (<italic>k</italic>≠<italic>j</italic>). An example one-hot encoding matrix is given in Fig. <xref rid="Fig1" ref-type="fig">1</xref>d.</p>
      <sec id="Sec7">
        <title>The CNN architecture for one-hot encoding matrices</title>
        <p>Inspired by Yoon Kim’s work in sentence classification [<xref ref-type="bibr" rid="CR43">43</xref>], a similar model is used in this work. Several convolution layers with different size of kernels, followed by global max pooling layer, are connected to input layer directly. The outputs of all pooling layers are concatenated together and then fed into two fully connected layers. Dropout is also employed to overcome overfitting. Tuned parameters are shown in Table <xref rid="Tab1" ref-type="table">1</xref>. Finally, the hyperparameters are set as follow: the number of convolution layers = 1, the size of the convolution filters = [2, 4, 6, 8, 10, 12, 14, 16], the number of kernel in convolutional layer = 512, the number of units in first fully connected layer = 1024, dropout rate = 0.7, learning rate = 0.001, learning algorithm = Adam, batch size = 64. Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the architecture.
<fig id="Fig4"><label>Fig. 4</label><caption><p>The CNN architecture of the one-hot encoding matrix encoding method</p></caption><graphic xlink:href="12859_2019_3279_Fig4_HTML" id="MO4"/></fig></p>
      </sec>
    </sec>
    <sec id="Sec8">
      <title>Excluding other ncRNA sequences using softmax probability threshold</title>
      <p>As next-generation sequencing data such as small RNA-Seq data have become the major source of new miRNA discovery, useful miRNA search tools should be able to distinguish miRNAs from other types of ncRNAs, which usually co-exist with miRNAs in RNA-Seq data. Identifying miRNAs in RNA-Seq data is open set and thus any useful system must reject unknown/unseen classes in test set [<xref ref-type="bibr" rid="CR40">40</xref>]. Existing binary classification tools often treat all the non-miRNA sequences as negative and need to choose non-miRNAs as the negative training samples. This often creates a highly unbalanced training set because there are significantly more non-miRNAs than miRNAs. In addition, it is not clear how to sample negative training sequences from many different types of ncRNAs. Our CNN model does not use an extra label for other ncRNAs. Instead, we reject out-of-distribution samples using the probability output of the softmax layer [<xref ref-type="bibr" rid="CR44">44</xref>].</p>
      <p>There are previous studies showing that the softmax probabilities of out-of-distribution samples are smaller than the probabilities of targeted samples [<xref ref-type="bibr" rid="CR44">44</xref>]. Intuitively, out-of-distribution queries tend to produce a softmax probability vector with similar (small) values while an in-distribution query often yields a large softmax probability for one class. Thus, we will use carefully chosen softmax probability threshold to reject out-of-distribution samples, which in our case can be other types of ncRNAs in small RNA-Seq data. In addition, not all miRNA families are used in our training data. Any unseen miRNA families are also out-of-distribution samples. The softmax probability threshold should be used to reject them as well. We will use ROC curves to empirically choose a threshold.</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Experimental results</title>
    <p>We will first compare the classification accuracy of the two types of encoding methods. In particular, we will examine whether explicitly encoding the structural information in input matrices can improve the performance of miRNA classification. As real data such as small RNA-Seq data contain different types of transcripts, we will examine whether the softmax output can be used to reject non-miRNA sequences. Then, we will compare the performance of the CNN-based miRNA classification with other ncRNA classification tools.</p>
    <sec id="Sec10">
      <title>Experimental data and pre-processing</title>
      <p>For most of our training process, we use pre-miRNA families from Rfam as the training and testing data because we would like to compare our method with Infernal [<xref ref-type="bibr" rid="CR12">12</xref>], which can conveniently use trained covariance models from Rfam. The current release of Rfam contains 529 pre-miRNA families and 215,122 precursor sequences. Another popular miRNA database is miRBase [<xref ref-type="bibr" rid="CR24">24</xref>], which currently contains 1983 miRNA families from 271 organisms, including 38,589 pre-miRNAs and 48,860 mature miRNAs. In the experiment where we only use the mature miRNAs as the training data, we use miRBase because miRBase provides easy access to collect all the mature miRNAs.</p>
      <p>We noticed that some of the pre-miRNA families in Rfam contain repeated sequences. Thus, in our pre-processing step, we will remove all the redundant sequences from the 529 pre-miRNA families in Rfam. As a result, 17.6% sequences were removed and 177,160 sequences were kept for downstream analysis. Each family contained different number of sequences (from 1 to 95,247) with different length. The distribution of the family size is shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Rfam characteristics. Percentage of families in family size</p></caption><graphic xlink:href="12859_2019_3279_Fig5_HTML" id="MO5"/></fig></p>
      <p>To train in mini-batch, a fixed size of the input matrix should be set. Although there are a few pre-miRNA families with particularly long sequences, 96.88% miRNAs in Rfam were less than 200nt. Thus, we only keep the families with size at most 200nt. Although commonly seen pre-miRNAs are about 70nt, we did not exclude the long ones, such as those occurring in plant genomes, before pre-processing. The input matrix has size 200. All the shorter sequences were converted into 200nt sequences by inserting zero padding at the end. These padded zeros will lead to zero during the scanning of a convolution filter and thus won’t affect the downstream layers after maxpooling.</p>
    </sec>
    <sec id="Sec11">
      <title>Classification performance of probability and pair matrix</title>
      <p>Following our definition of the probability and pair matrix, a threshold <italic>T</italic> is needed to decide the values of these matrices. In this experiment, we evaluate the change of <italic>T</italic> on the classification performance. At the same time, we also compare the performance of ordered and unordered pair matrices. These experiments were conducted using 30 randomly selected pre-miRNA families with at least 100 member sequences.</p>
      <p>Considering that the probabilities may not be linearly distributed from 0 to 1, we sorted all the pairing probabilities (greater than 0.0001) of each miRNA sequence in Rfam and then used the values of different percentiles as the thresholds. The 0th, 10th, 20th, 30th and 40th percentile are selected; the corresponding values are 0.0001, 0.00487, 0.00772, 0.01307, and 0.02411.</p>
      <p>For the 30 pre-miRNA families, 100 sequences were randomly selected from all member sequences. Then we used 5-fold cross validation so that there were 80 training sequences vs. 20 test sequences. CNN models with 30 classes are trained using different types of encoding methods. As there are 10 different types of matrices using 5 thresholds combined with two types of base pairs (ordered vs. unordered), 10 CNNs are trained. Note that the test sequences are encoded using the same method as the corresponding training data. We first compared the classification accuracy of using different thresholds with boxplot in Fig. <xref rid="Fig6" ref-type="fig">6</xref>a. For each threshold, there are 10 classification accuracy values for 5-fold cross validation results of both ordered and unordered cases. The comparison shows that allowing small base pairing probabilities yields higher average accuracy but also a slightly larger deviation. Overall, because of the higher average accuracy, we set the default threshold <italic>T</italic> as 0.0001 in all the following experiments. Figure <xref rid="Fig6" ref-type="fig">6</xref>b compares the classification accuracy of ordered vs. unordered matrices. The results show that they have very similar accuracy, with median accuracy around 0.92. By default, we use ordered base pairs in the pair matrix.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Performance comparison on classification accuracy using different secondary structure encoding methods. <bold>a</bold> 5 different thresholds (<italic>T</italic>) of base pairing probabilities. <bold>b</bold> ordered vs. unordered base pairs</p></caption><graphic xlink:href="12859_2019_3279_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
    <sec id="Sec12">
      <title>Performance on pre-miRNAs classification</title>
      <p>One-hot encoding matrix has been widely adopted for converting genomic data as inputs to deep learning models. Although it does not explicitly incorporate any structure information from the sequences, it has successful applications in protein homology search [<xref ref-type="bibr" rid="CR29">29</xref>]. Thus, we will conduct a comprehensive experiment to compare the performance of one-hot encoding matrix and probability/pair matrix using pre-miRNA families from Rfam.</p>
      <p>As different pre-miRNA families have different numbers of sequences, which can affect the performance of classification, we built 4 different datasets based on the size of families. Each dataset has different number of “classes” or “labels”. The details about the four groups can be found in Table <xref rid="Tab2" ref-type="table">2</xref>. Taken the Rfam-300 dataset as an example, there are 47 families in this dataset and each family contains 300 sequences (including 250 training sequences and 50 testing sequences). The model trained using this dataset needs to classify queries into one of the 47 families (or classes). We will compare the classification performance of CNNs on the four groups of training data and examine how the training set size affects the accuracy.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Four groups of pre-miRNA families with different training set sizes</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasets</th><th align="left">No. of families (i.e. classes)</th><th align="left">No. of sequences per family (<italic>t</italic><italic>r</italic><italic>a</italic><italic>i</italic><italic>n</italic>:<italic>t</italic><italic>e</italic><italic>s</italic><italic>t</italic>)</th></tr></thead><tbody><tr><td align="justify">Rfam-300</td><td align="justify">47</td><td align="justify">300 (250:50)</td></tr><tr><td align="justify">Rfam-120</td><td align="justify">106</td><td align="justify">120 (100:20)</td></tr><tr><td align="justify">Rfam-60</td><td align="justify">165</td><td align="justify">60 (50:10)</td></tr><tr><td align="justify">Rfam-30</td><td align="justify">241</td><td align="justify">30 (25:5)</td></tr></tbody></table></table-wrap></p>
      <p>In order to quantify the prediction performance, we use two metrics: accuracy and F-score <inline-formula id="IEq1"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left (F-score = \frac {2 \times Precision \times Recall}{Precision+Recall}\right)$\end{document}</tex-math><mml:math id="M8"><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>F</mml:mi><mml:mo>−</mml:mo><mml:mtext mathvariant="italic">score</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mtext mathvariant="italic">Precision</mml:mtext><mml:mo>×</mml:mo><mml:mtext mathvariant="italic">Recall</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">Precision</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">Recall</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2019_3279_Article_IEq1.gif"/></alternatives></inline-formula>. Classification accuracy quantifies the percentage of the correct predictions in all the test sequences. For each family, we also computed the recall <inline-formula id="IEq2"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left (Recall=\frac {TP}{TP+FN}\right)$\end{document}</tex-math><mml:math id="M10"><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mtext mathvariant="italic">Recall</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">FN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2019_3279_Article_IEq2.gif"/></alternatives></inline-formula> and precision <inline-formula id="IEq3"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left (Precision=\frac {TP}{TP+FP}\right)$\end{document}</tex-math><mml:math id="M12"><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mtext mathvariant="italic">Precision</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">FP</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2019_3279_Article_IEq3.gif"/></alternatives></inline-formula>. Here, TP, TN, FP, and FN correspond to the numbers of true positive, true negative, false positive, and false negative, respectively. The average F-score for all different families for one trained CNN is reported in Table <xref rid="Tab3" ref-type="table">3</xref>. We evaluated the performance by the average accuracy of 5 independent experiments, each of which was measured with randomly selected testing sequences.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Prediction accuracy(%) and F-score(%) of CNNs trained on families of different sizes</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left" colspan="2">Rfam-300</th><th align="left" colspan="2">Rfam-120</th><th align="left" colspan="2">Rfam-60</th><th align="left" colspan="2">Rfam-30</th></tr><tr><th align="left"/><th align="left">Acc.<sup>1</sup></th><th align="left">F-score</th><th align="left">Acc.</th><th align="left">F-score</th><th align="left">Acc.</th><th align="left">F-score</th><th align="left">Acc.</th><th align="left">F-score</th></tr></thead><tbody><tr><td align="left">Pair matrix</td><td align="left">89.91</td><td align="left">89.99</td><td align="left">77.71</td><td align="left">76.87</td><td align="left">71.27</td><td align="left">68.82</td><td align="left">60.60</td><td align="left">56.32</td></tr><tr><td align="left">Prob matrix</td><td align="left">83.69</td><td align="left">83.28</td><td align="left">72.86</td><td align="left">71.61</td><td align="left">69.83</td><td align="left">67.66</td><td align="left">59.37</td><td align="left">54.72</td></tr><tr><td align="left">Mixed matrix</td><td align="left">87.78</td><td align="left">87.32</td><td align="left">74.94</td><td align="left">73.67</td><td align="left">66.15</td><td align="left">63.67</td><td align="left">53.31</td><td align="left">48.71</td></tr><tr><td align="left">One-hot matrix</td><td align="left">99.25</td><td align="left">99.25</td><td align="left">98.87</td><td align="left">98.88</td><td align="left">98.48</td><td align="left">98.45</td><td align="left">97.76</td><td align="left">97.71</td></tr></tbody></table><table-wrap-foot><p><sup>1</sup>Acc. refers to accuracy (%)</p></table-wrap-foot></table-wrap></p>
      <p>The results show that using one-hot encoding matrix led to much better performance than other methods even though it does not integrate base pairing information. In addition, it was less susceptible to the reduction of training data size. On the other hand, matrices focusing on base pairs need bigger training data to achieve better classification accuracy. These comparisons indicate that using one-hot encoding matrices is able to distinguish different types of miRNA families. One possible reason behind the inferior performance of using base pairing information is that all these pre-miRNA families have similar secondary structures and thus it is more difficult to conduct finer scale classification within the big family of miRNAs. For using one-hot matrix is less vulnerable to the decreased size of the training dataset, one possible reason is that one-hot matrix model has much fewer trainable parameters. For example, inputting the same sequence of length 200nt, one-hot model can update 4,485,255 parameters while the pair matrix model can update 78,748,399 parameters. Fewer parameters can help the model maintain high accuracy even if the training set is relatively small.</p>
      <p>However, our additional experiments (next section) showed that these matrices cannot distinguish miRNAs from C/D box snoRNAs with high accuracy either, probably because of the similarity in the secondary structures, indicating that it is more difficult to train effective CNNs for matrices encoding base pairs. Larger training data are needed to improve the classification accuracy, which may not be always available for some miRNA families.</p>
    </sec>
    <sec id="Sec13">
      <title>Use softmax probability threshold to reject other types of ncRNA sequences</title>
      <p>Transcriptomic data such as small RNA-seq data can contain reads from other types of ncRNAs or miRNA families that are different from the many data. In this experiment, we will show that appropriate softmax probability value can be chosen as the threshold to distinguish targeted miRNAs from out-of-distribution samples.</p>
      <p>As an example, we demonstrate the softmax output using the CNN model trained on Rfam-60 dataset (including 165 miRNA families). The positive set includes 155,392 test sequences from the Rfam-60 dataset while the negative (i.e. out-of-distribution) set contains all sequences from untrained miRNA families and randomly selected sequences from all other types of ncRNA in Rfam. There are 186,112 sequences in the out-of-distribution set. For each test sequence, the softmax layer will output a vector of normalized probabilities for all the 165 classes. The test sequence is assigned to the class with the the highest probability in the vector. We will set a threshold on this value so that a test sequence with maximum softmax output below this threshold will be rejected. We empirically determined the threshold by analyzing the distribution of the maximum softmax values for each input sequences.</p>
      <p>We first plot the distribution of softmax values of the targeted miRNAs and other ncRNAs. Then we show the receiver operating characteristic (ROC) curve, which is constructed using <italic>f</italic><italic>a</italic><italic>l</italic><italic>s</italic><italic>e</italic>
<italic>p</italic><italic>o</italic><italic>s</italic><italic>i</italic><italic>t</italic><italic>i</italic><italic>v</italic><italic>e</italic>
<italic>r</italic><italic>a</italic><italic>t</italic><italic>e</italic><inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left (FPR=\frac {FP}{FP+TN}\right)$\end{document}</tex-math><mml:math id="M14"><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mtext mathvariant="italic">FPR</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">FP</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">FP</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">TN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2019_3279_Article_IEq4.gif"/></alternatives></inline-formula> and <italic>t</italic><italic>r</italic><italic>u</italic><italic>e</italic>
<italic>p</italic><italic>o</italic><italic>s</italic><italic>i</italic><italic>t</italic><italic>i</italic><italic>v</italic><italic>e</italic>
<italic>r</italic><italic>a</italic><italic>t</italic><italic>e</italic><inline-formula id="IEq5"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left (TPR=\frac {TP}{TP+FN}\right)$\end{document}</tex-math><mml:math id="M16"><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mtext mathvariant="italic">TPR</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">FN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2019_3279_Article_IEq5.gif"/></alternatives></inline-formula> computed under different thresholds. Figure <xref rid="Fig7" ref-type="fig">7</xref>a and c show the distribution of the softmax probabilities for targeted miRNAs and negative samples. The comparison of (a) and (c) shows that using one-hot encoding matrix leads to smaller overlaps between the two distributions, which is consistent to the comparison of the ROC curves in Fig. <xref rid="Fig7" ref-type="fig">7</xref>b and d. Most of softmax values of the targeted miRNAs are greater than 0.9 and the area under the ROC curve for one-hot encoding matrix is very close to 1. By using one-hot encoding matrix, we can find an appropriate probability threshold to reject a majority of the negative samples (high precision) while still keeping targeted pre-miRNAs (high sensitivity). According to Fig. <xref rid="Fig7" ref-type="fig">7</xref>b, we choose the threshold leading to a large F-score. The default softmax value threshold for our trained CNNs is 0.977, with associated FPR of 0.05. Any test sequence with maximum softmax probability below 0.977 will be rejected.
<fig id="Fig7"><label>Fig. 7</label><caption><p>Choosing appropriate softmax probability threshold to reject out-of-distribution samples.</p></caption><graphic xlink:href="12859_2019_3279_Fig7_HTML" id="MO7"/></fig></p>
      <p>We hypothesized that using pair and probability matrix cannot distinguish different pre-miRNA families because of their similar secondary structures. These matrices should thus be able to distinguish different types of ncRNAs with different secondary structures. Thus, we constructed a smaller negative data set containing tRNA, C/D box snoRNA, and other unseen miRNA families, including 20,000, 60,000 and 6,500 sequences, respectively. The secondary structure of tRNA is cloverleaf, which is very different from miRNA’s hairpin structure. But the C/D box’s stem box structure is somewhat similar to miRNA’s. According to Fig. <xref rid="Fig8" ref-type="fig">8</xref>b, probability/pair matrix can distinguish tRNA from miRNA well, but still has difficulty rejecting C/D box snoRNAs. Considering that different types of ncRNAs might share globally or locally similar structures, pair and probability matrices have limited utilities in ncRNA classification.
<fig id="Fig8"><label>Fig. 8</label><caption><p>Distribution of softmax values for unseen miRNAs, tRNAs, and C/D box snoRNAs. In both plots, the bin width is 0.01. (<bold>a</bold>) uses the one-hot encoding matrix model; (<bold>b</bold>) uses the pair matrix model</p></caption><graphic xlink:href="12859_2019_3279_Fig8_HTML" id="MO8"/></fig></p>
    </sec>
    <sec id="Sec14">
      <title>Directly classifying mature miRNAs</title>
      <p>As many small RNA-seq datasets contain only mature miRNA, we evaluated whether deep learning could be used to directly classify mature miRNAs. As mature miRNAs in the same family can be well conserved because of their binding preference, using either mature miRNAs or pre-miRNAs as the training data may lead to similar classification accuracy for mature miRNAs. We again conduct the comparison using Rfam-60 set, where 50 sequences are used for training and 10 for testing. As we cannot conveniently obtain the mature miRNA annotation in the pre-miRNA families in Rfam, we downloaded the mature miRNAs from MiRBase. Thus, two CNN models are trained on pre-miRNAs and mature miRNAs, respectively. All the test sequences are mature miRNAs. For all the sequences, only one-hot matrix is used because of its superior performance. The mature miRNA classification accuracy of using pre-miRNAs and mature miRNAs as training data is 65.26% and 92.43%, respectively. Thus, when there are no reference genomes and read mapping cannot be used to identify possible pre-miRNAs, mature miRNAs should be used as training data for CNNs.</p>
    </sec>
    <sec id="Sec15">
      <title>Performance on the input sequences with extra bases</title>
      <p>Determining the exact boundary of pre-miRNAs in genomes is still challenging. For example, reads from small-RNA seq data can be mapped to reference genomes to identify possible mature miRNAs. Then those regions plus possibly mapped miRNA regions will be extended to identify candidate pre-miRNAs. The extension can go beyond the true pre-miRNA boundaries. Thus, we investigate whether having extra bases affects the classification accuracy. We still use Rfam-60 as our dataset, but 5, 10, 15 or 20 random nucleotides are added around each test sequence. The results can be found in Table <xref rid="Tab4" ref-type="table">4</xref>.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Classification performance on the test sequences with added bases</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Number of added bases</th><th align="left">Accuracy</th><th align="left">F-score</th></tr></thead><tbody><tr><td align="left">5</td><td align="left">97.52%</td><td align="left">97.63%</td></tr><tr><td align="left">10</td><td align="left">96.88%</td><td align="left">97.16%</td></tr><tr><td align="left">15</td><td align="left">95.47%</td><td align="left">95.27%</td></tr><tr><td align="left">20</td><td align="left">94.70%</td><td align="left">94.48%</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec16">
      <title>Comparison with other tools</title>
      <p>In addition to the classification accuracy, the running time is also an important consideration for practical applications, especially when identifying miRNAs from next-generation sequencing data. Here, we compared the classification accuracy and running time of our trained CNNs with Infernal and miRClassify [<xref ref-type="bibr" rid="CR45">45</xref>]. We also evaluated the performance of each method as the number of miRNA families (i.e. classes) increased. Four testing dataset were constructed by randomly selecting 1000 sequences from Rfam-300, Rfam-120, Rfam-60, and Rfam-30 respectively. Note that all these testing sequences are chosen from the set excluding training sequences and thus have no overlap with the training data for our CNN models. This experiment was repeated for five times and the average performance was reported in Table <xref rid="Tab5" ref-type="table">5</xref>. The variance of each experiment in one-hot matrix method and Infernal is very small (less than 5<italic>e</italic>- 3). And for the miRClassify, the variance is slightly bigger and the biggest variance is 0.02. In order to run Infernal, we directly downloaded the covariance models associated with the corresponding dataset from Rfam. Thus, it is possible that some of these test sequences were used for training the covariance models. MiRClassify uses a hierarchical random forest model to classify the miRNAs into different families. The models of MiRClassify were downloaded from their website and they were constructed from miRBase version 16.0.
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Comparison with Infernal and miRClassify</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Tool</th><th align="left" colspan="2">Rfam-300</th><th align="left" colspan="2">Rfam-120</th><th align="left" colspan="2">Rfam-60</th><th align="left" colspan="2">Rfam-30</th></tr><tr><th align="left"/><th align="left">Acc.<sup>1</sup></th><th align="left">Time<sup>2</sup></th><th align="left">Acc.</th><th align="left">Time</th><th align="left">Acc.</th><th align="left">Time</th><th align="left">Acc.</th><th align="left">Time</th></tr></thead><tbody><tr><td align="left">one-hot matrix</td><td align="left">98.94</td><td align="left">4.52</td><td align="left">98.60</td><td align="left">4.53</td><td align="left">97.86</td><td align="left">4.52</td><td align="left">97.45</td><td align="left">4.54</td></tr><tr><td align="left">Infernal</td><td align="left">98.30</td><td align="left">265.92</td><td align="left">99.06</td><td align="left">322.43</td><td align="left">99.34</td><td align="left">405.15</td><td align="left">99.42</td><td align="left">486.78</td></tr><tr><td align="left">miRClassify</td><td align="left">36.50</td><td align="left">250.53</td><td align="left">46.23</td><td align="left">252.76</td><td align="left">48.24</td><td align="left">254.56</td><td align="left">48.80</td><td align="left">258.12</td></tr></tbody></table><table-wrap-foot><p><sup>1</sup>Acc. refers to accuracy (%).</p><p><sup>2</sup>Time refers to running time (s)</p></table-wrap-foot></table-wrap></p>
      <p>To ensure a fair comparison in the running time, we used single core for all the three tools because miRClassify is single-threaded. For Infernal, we set the option ‘–cpu’ as 1. All other options for Infernal are the default parameters. The command is:</p>
      <p>&gt;<italic>cmscan –cpu 1 rfam_60.cm rfam_60.fa</italic></p>
      <p>Here, ‘rfam_60.cm’ contained all the required covariance models and ‘rfam_60.fa’ is the test sequence set. For each query sequence, Infernal might generate several hits. In that case, we only kept the one with the lowest E-value. CNN model was implemented by Keras so we added extra commands to make sure only one core was used. In addition, the mini-batch size used in CNN was 64. Table <xref rid="Tab5" ref-type="table">5</xref> summarized the results.</p>
      <p>The result in Table <xref rid="Tab5" ref-type="table">5</xref> shows that despite the possible overlaps between training and testing data for Infernal and MiRClassify, our trained CNN models still have high accuracy with minimum running time. We then conducted the <italic>χ</italic><sup>2</sup>-test between the 20 accuracy values output by the three methods. The <italic>p</italic>-value between the one-hot matrix method and Infernal was very close to 1 (0.999), indicating that their accuracy is comparable. On the other hand, the <italic>p</italic>-value between ours and miRClassify is 4.59<italic>e</italic>- 275. The running time comparison also shows that Infernal took more time as the number of families increased. The other two methods were not affected by the number of families.</p>
    </sec>
    <sec id="Sec17">
      <title>Frequently activated filters represent part of mature miRNAs</title>
      <p>To interpret why the one-hot encoding method performed well, we visualized some motifs extracted by our CNN model. Employing the method used in DeepFam [<xref ref-type="bibr" rid="CR29">29</xref>], we utilized the most frequently activated filters in trained Rfam-300 model to extract motifs from the RF00247 training sequences. We compared the motifs obtained by CNN with the motifs produced by MEME on training sequences, as shown in Fig. <xref rid="Fig9" ref-type="fig">9</xref>. Because the convolution layer used filters of different sizes, this model can identify motifs with various lengths. We found that the identified motifs represented part of the mature miRNA. We tested other families and had the same observation. This is consistent to the findings by DeepFam.
<fig id="Fig9"><label>Fig. 9</label><caption><p>Visualizing and comparing the motifs extracted by MEME [<xref ref-type="bibr" rid="CR46">46</xref>] and CNN model in RF00247. (<bold>a</bold>) Motifs extracted by MEME and CNN and the corresponding convolution filter of length 8. (<bold>b</bold>) Motifs extracted by MEME and CNN and the corresponding convolution filter of length 16. (<bold>c</bold>) The secondary structure of RF00247 with highlighted mature miRNA</p></caption><graphic xlink:href="12859_2019_3279_Fig9_HTML" id="MO9"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec18" sec-type="discussion">
    <title>Discussion</title>
    <p>We evaluated and compared the classification performance using different encoding methods and CNN architectures. Based on the experimental results, simple one-hot matrix performed much better than other encoding methods that explicitly incorporate predicted secondary structures. This could be caused by similar secondary structures among different types of pre-miRNA families. As shown by Do et al. [<xref ref-type="bibr" rid="CR37">37</xref>], it is possible that encoding secondary structures will benefit distinguishing miRNAs from other ncRNAs in the binary classification problem.</p>
    <p>In practice, input data such as small RNA-Seq can contain sequences from other types of ncRNAs. Useful miRNA classification must be able to reject out-of-distribution samples. Our experiments demonstrated that using softmax output can achieve an optimal trade-off between sensitivity and precision in distinguishing targeted miRNAs from other sequences. Thus, the designed classification models are practically useful in conducting finer scale miRNA analysis. By comparing our tool with a general ncRNA classification tool Infernal and also another machine learning based miRNA classification tool, we conclude that ours can achieve high sensitivity and accuracy with significantly reduced running time.</p>
  </sec>
  <sec id="Sec19" sec-type="conclusion">
    <title>Conclusion</title>
    <p>In this work, we developed CNN-based classification models for identifying different types of miRNAs. By using the output of the softmax probability as a threshold, our model can reject other types of ncRNAs and out-of-distribution miRNAs with high precision. Comparing with two existing methods, our one-hot encoding method takes much less time and still has high accuracy.</p>
    <p>Although this work only concerns miRNAs, the trained CNNs can be extended to classify other types of ncRNAs. The method holds the promise to achieve comparable performance while achieving significant speedups compared to Infernal. It is our future work to extend and optimize our model for other types of ncRNAs.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>CNN</term>
        <def>
          <p>Convolution neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>FPR</term>
        <def>
          <p>False position rate</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p>Long short term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>miRNA</term>
        <def>
          <p>microRNA</p>
        </def>
      </def-item>
      <def-item>
        <term>MFE</term>
        <def>
          <p>Minimum free energy</p>
        </def>
      </def-item>
      <def-item>
        <term>ncRNA</term>
        <def>
          <p>non-coding RNA</p>
        </def>
      </def-item>
      <def-item>
        <term>pre-miRNA</term>
        <def>
          <p>precursor microRNA</p>
        </def>
      </def-item>
      <def-item>
        <term>pri-miRNA</term>
        <def>
          <p>primary microRNA</p>
        </def>
      </def-item>
      <def-item>
        <term>rRNA</term>
        <def>
          <p>ribosome RNA</p>
        </def>
      </def-item>
      <def-item>
        <term>ROC</term>
        <def>
          <p>Receiver Operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>tRNA</term>
        <def>
          <p>transfer RNA</p>
        </def>
      </def-item>
      <def-item>
        <term>TPR</term>
        <def>
          <p>True positive rate</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <p>Not applicable.</p>
    <sec id="d29e2517">
      <title>About this supplement</title>
      <p>This article has been published as part of BMC Bioinformatics Volume 20 Supplement 23, 2019: Proceedings of the Joint International GIW &amp; ABACBS-2019 Conference: bioinformatics. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-20-supplement-23">https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-20-supplement-23</ext-link>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>YS initiated the project. Both YS and XT designed the methods. XT conducted the experiments. Both YS and XT contributed to the writing of this manuscript. Both YS and XT read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work and the publication costs were supported by City University of Hong Kong (Hong Kong, China SAR) project 7200620. The funding did not play any role in design/conclusion.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The source code and datasets used during the current study are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/HubertTang/DeepMir">https://github.com/HubertTang/DeepMir</ext-link></p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cech</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Steitz</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>The noncoding RNA revolution—trashing old rules to forge new ones</article-title>
        <source>Cell</source>
        <year>2014</year>
        <volume>157</volume>
        <issue>1</issue>
        <fpage>77</fpage>
        <lpage>94</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2014.03.008</pub-id>
        <pub-id pub-id-type="pmid">24679528</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>VN</given-names>
          </name>
          <name>
            <surname>Nam</surname>
            <given-names>J-W</given-names>
          </name>
        </person-group>
        <article-title>Genomics of microRNA,</article-title>
        <source>Trends Genet</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>3</issue>
        <fpage>165</fpage>
        <lpage>73</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tig.2006.01.003</pub-id>
        <pub-id pub-id-type="pmid">16446010</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krol</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Loedige</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Filipowicz</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>The widespread regulation of microRNA biogenesis, function and decay,</article-title>
        <source>Nat Rev Genet</source>
        <year>2010</year>
        <volume>11</volume>
        <issue>9</issue>
        <fpage>597</fpage>
        <lpage>610</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg2843</pub-id>
        <pub-id pub-id-type="pmid">20661255</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berezikov</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Evolution of microRNA diversity and regulation in animals,</article-title>
        <source>Nat Rev Genet</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>12</issue>
        <fpage>846</fpage>
        <lpage>60</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg3079</pub-id>
        <pub-id pub-id-type="pmid">22094948</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bartel</surname>
            <given-names>DP</given-names>
          </name>
        </person-group>
        <article-title>MicroRNAs: genomics, biogenesis, mechanism, and function</article-title>
        <source>Cell</source>
        <year>2004</year>
        <volume>116</volume>
        <issue>2</issue>
        <fpage>281</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1016/S0092-8674(04)00045-5</pub-id>
        <pub-id pub-id-type="pmid">14744438</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mallanna</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Rizzino</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Emerging roles of microRNAs in the control of embryonic stem cells and the generation of induced pluripotent stem cells</article-title>
        <source>Dev Biol</source>
        <year>2010</year>
        <volume>344</volume>
        <issue>1</issue>
        <fpage>16</fpage>
        <lpage>25</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ydbio.2010.05.014</pub-id>
        <pub-id pub-id-type="pmid">20478297</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saini</surname>
            <given-names>HK</given-names>
          </name>
          <name>
            <surname>Griffiths-Jones</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Enright</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <article-title>Genomic analysis of human microRNA transcripts</article-title>
        <source>Proc Natl Acad Sci U S A</source>
        <year>2007</year>
        <volume>104</volume>
        <issue>45</issue>
        <fpage>17719</fpage>
        <lpage>24</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0703890104</pub-id>
        <pub-id pub-id-type="pmid">17965236</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ruby</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Jan</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Bartel</surname>
            <given-names>DP</given-names>
          </name>
        </person-group>
        <article-title>Intronic microRNA precursors that bypass Drosha processing</article-title>
        <source>Nature</source>
        <year>2007</year>
        <volume>448</volume>
        <issue>7149</issue>
        <fpage>83</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1038/nature05983</pub-id>
        <pub-id pub-id-type="pmid">17589500</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ahn</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yim</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Provost</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Rådmark</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The nuclear RNase III Drosha initiates microRNA processing</article-title>
        <source>Nature</source>
        <year>2003</year>
        <volume>425</volume>
        <issue>6956</issue>
        <fpage>415</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1038/nature01957</pub-id>
        <pub-id pub-id-type="pmid">14508493</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuehbacher</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Urbich</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zeiher</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Dimmeler</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Role of Dicer and Drosha for endothelial microRNA expression and angiogenesis</article-title>
        <source>Circ Res</source>
        <year>2007</year>
        <volume>101</volume>
        <issue>1</issue>
        <fpage>59</fpage>
        <lpage>68</lpage>
        <pub-id pub-id-type="doi">10.1161/CIRCRESAHA.107.153916</pub-id>
        <pub-id pub-id-type="pmid">17540974</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vilborg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>M-D</given-names>
          </name>
          <name>
            <surname>Yartseva</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Šestan</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Steitz</surname>
            <given-names>Ja</given-names>
          </name>
        </person-group>
        <article-title>Mammalian 5’-capped microRNA precursors that generate a single microRNA</article-title>
        <source>Cell</source>
        <year>2013</year>
        <volume>155</volume>
        <issue>7</issue>
        <fpage>1568</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2013.11.027</pub-id>
        <pub-id pub-id-type="pmid">24360278</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nawrocki</surname>
            <given-names>EP</given-names>
          </name>
          <name>
            <surname>Eddy</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Infernal 1.1: 100-fold faster RNA homology searches</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>22</issue>
        <fpage>2933</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt509</pub-id>
        <pub-id pub-id-type="pmid">24008419</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Artzi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kiezun</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shomron</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>miRNAminer: a tool for homologous microRNA gene search</article-title>
        <source>BMC Bioinformatics</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>39</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-9-39</pub-id>
        <pub-id pub-id-type="pmid">18215311</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <mixed-citation publication-type="other">Sippl MJ. Biological sequence analysis. Probabilistic models of proteins and nucleic acids In: Durbin R, Eddy S, Krogh A, Mitchinson G, editors. 356 pp. £55.00 ($80.00)(hardcover); £19.95 ($34.95)[J]. Protein Science.Cambridge: Cambridge University Press: 1998. 8(3);695.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zaretskaya</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Raytselis</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Merezhuk</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>McGinnis</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
        </person-group>
        <article-title>NCBI BLAST: a better web interface</article-title>
        <source>Nucleic Acids Res</source>
        <year>2008</year>
        <volume>36</volume>
        <issue>suppl_2</issue>
        <fpage>5</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkn201</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vitsios</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Kentepozidou</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Quintais</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Benito-Gutiérrez</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>van Dongen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Enright</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <article-title>Mirnovo: genome-free prediction of microRNAs from small RNA sequencing data and single-cells using decision forests</article-title>
        <source>Nucleic Acids Res</source>
        <year>2017</year>
        <volume>45</volume>
        <issue>21</issue>
        <fpage>177</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx836</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kadri</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hinman</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Benos</surname>
            <given-names>PV</given-names>
          </name>
        </person-group>
        <article-title>HHMMiR: efficient de novo prediction of microRNAs using hierarchical hidden Markov models</article-title>
        <source>BMC Bioinformatics</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>35</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-10-S1-S35</pub-id>
        <pub-id pub-id-type="pmid">19173744</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Teune</surname>
            <given-names>J-H</given-names>
          </name>
          <name>
            <surname>Steger</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>NOVOMIR: de novo prediction of microRNA-coding regions in a single plant-genome</article-title>
        <source>J Nucleic Acids</source>
        <year>2010</year>
        <volume>2010</volume>
        <fpage>10</fpage>
        <pub-id pub-id-type="doi">10.4061/2010/495904</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Gerstein</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Snyder</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>RNA-Seq: a revolutionary tool for transcriptomics</article-title>
        <source>Nat Rev Genet</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>57</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg2484</pub-id>
        <pub-id pub-id-type="pmid">19015660</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lei</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>miR-PREFeR: an accurate, fast and easy-to-use plant miRNA prediction tool using small RNA-Seq data</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>19</issue>
        <fpage>2837</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu380</pub-id>
        <pub-id pub-id-type="pmid">24930140</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>W-C</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>F-M</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>W-C</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>K-Y</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>H-D</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>N-S</given-names>
          </name>
        </person-group>
        <article-title>miRExpress: analyzing high-throughput sequencing data for profiling microRNA expression</article-title>
        <source>BMC Bioinformatics</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>328</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-10-328</pub-id>
        <pub-id pub-id-type="pmid">19821977</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>miRDeep-P: a computational tool for analyzing the microRNA transcriptome in plants</article-title>
        <source>Bioinformatics</source>
        <year>2011</year>
        <volume>27</volume>
        <issue>18</issue>
        <fpage>2614</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr430</pub-id>
        <pub-id pub-id-type="pmid">21775303</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Conesa</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Madrigal</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Tarazona</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gomez-Cabrero</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cervera</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>McPherson</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Szcześniak</surname>
            <given-names>MW</given-names>
          </name>
          <name>
            <surname>Gaffney</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Elo</surname>
            <given-names>LL</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A survey of best practices for RNA-seq data analysis</article-title>
        <source>Genome Biol</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>13</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-016-0881-8</pub-id>
        <pub-id pub-id-type="pmid">26813401</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kozomara</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Birgaoanu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Griffiths-Jones</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>miRBase: from microRNA sequences to function</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>155</fpage>
        <lpage>62</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky1141</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kalvari</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Argasinska</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Quinones-Olvera</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Nawrocki</surname>
            <given-names>EP</given-names>
          </name>
          <name>
            <surname>Rivas</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Eddy</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Bateman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Finn</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Petrov</surname>
            <given-names>AI</given-names>
          </name>
        </person-group>
        <article-title>Rfam 13.0: shifting to a genome-centric resource for non-coding RNA families</article-title>
        <source>Nucleic Acids Res</source>
        <year>2017</year>
        <volume>46</volume>
        <issue>D1</issue>
        <fpage>335</fpage>
        <lpage>42</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx1038</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alipanahi</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Delong</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Weirauch</surname>
            <given-names>MT</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>
        <source>Nat Biotechnol</source>
        <year>2015</year>
        <volume>33</volume>
        <issue>8</issue>
        <fpage>831</fpage>
        <pub-id pub-id-type="doi">10.1038/nbt.3300</pub-id>
        <pub-id pub-id-type="pmid">26213851</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zeng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gifford</surname>
            <given-names>DK</given-names>
          </name>
        </person-group>
        <article-title>Convolutional neural network architectures for predicting DNA–protein binding</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>12</issue>
        <fpage>121</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw255</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Troyanskaya</surname>
            <given-names>OG</given-names>
          </name>
        </person-group>
        <article-title>Predicting effects of noncoding variants with deep learning–based sequence model</article-title>
        <source>Nat Methods</source>
        <year>2015</year>
        <volume>12</volume>
        <issue>10</issue>
        <fpage>931</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.3547</pub-id>
        <pub-id pub-id-type="pmid">26301843</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Seo</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Oh</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>DeepFam: deep learning based alignment-free method for protein family modeling and prediction</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>13</issue>
        <fpage>254</fpage>
        <lpage>62</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty275</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Quang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>11</issue>
        <fpage>107</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw226</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de ON Lopes</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Schliep</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>de Carvalho</surname>
            <given-names>ACdL</given-names>
          </name>
        </person-group>
        <article-title>The discriminant power of RNA features for pre-miRNA recognition</article-title>
        <source>BMC Bioinformatics</source>
        <year>2014</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>124</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-15-124</pub-id>
        <pub-id pub-id-type="pmid">24884650</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Middleton</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rasko</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Ritchie</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>miREval 2.0: a web tool for simple microRNA prediction in genome sequences</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>24</issue>
        <fpage>3225</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt545</pub-id>
        <pub-id pub-id-type="pmid">24048357</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gudyś</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Szcześniak</surname>
            <given-names>MW</given-names>
          </name>
          <name>
            <surname>Sikora</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Makałowska</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>HuntMi: an efficient and taxon-specific approach in pre-miRNA identification</article-title>
        <source>BMC Bioinformatics</source>
        <year>2013</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>83</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-83</pub-id>
        <pub-id pub-id-type="pmid">23497112</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Batuwita</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Palade</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>microPred: effective classification of pre-miRNAs for human miRNA gene prediction</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>8</issue>
        <fpage>989</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp107</pub-id>
        <pub-id pub-id-type="pmid">19233894</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>miRNA-dis: microRNA precursor identification based on distance structure status pairs</article-title>
        <source>Mol BioSyst</source>
        <year>2015</year>
        <volume>11</volume>
        <issue>4</issue>
        <fpage>1194</fpage>
        <lpage>204</lpage>
        <pub-id pub-id-type="doi">10.1039/C5MB00050E</pub-id>
        <pub-id pub-id-type="pmid">25715848</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>MiPred: classification of real and pseudo microRNA precursors using random forest prediction model with combined features</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>35</volume>
        <issue>suppl_2</issue>
        <fpage>339</fpage>
        <lpage>44</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm368</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37</label>
      <mixed-citation publication-type="other">Do BT, Golkov V, Gürel GE, Cremers D. Precursor microRNA identification using deep convolutional neural networks. bioRxiv. 2018:414656.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aoki</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Sakakibara</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Convolutional neural networks for classification of alignments of non-coding rna sequences</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>13</issue>
        <fpage>237</fpage>
        <lpage>44</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty228</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stegmayer</surname>
            <given-names>Georgina</given-names>
          </name>
          <name>
            <surname>Di Persia</surname>
            <given-names>Leandro E</given-names>
          </name>
          <name>
            <surname>Rubiolo</surname>
            <given-names>Mariano</given-names>
          </name>
          <name>
            <surname>Gerard</surname>
            <given-names>Matias</given-names>
          </name>
          <name>
            <surname>Pividori</surname>
            <given-names>Milton</given-names>
          </name>
          <name>
            <surname>Yones</surname>
            <given-names>Cristian</given-names>
          </name>
          <name>
            <surname>Bugnon</surname>
            <given-names>Leandro A</given-names>
          </name>
          <name>
            <surname>Rodriguez</surname>
            <given-names>Tadeo</given-names>
          </name>
          <name>
            <surname>Raad</surname>
            <given-names>Jonathan</given-names>
          </name>
          <name>
            <surname>Milone</surname>
            <given-names>Diego H</given-names>
          </name>
        </person-group>
        <article-title>Predicting novel microRNA: a comprehensive comparison of machine learning approaches</article-title>
        <source>Briefings in Bioinformatics</source>
        <year>2018</year>
        <volume>20</volume>
        <issue>5</issue>
        <fpage>1607</fpage>
        <lpage>1620</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bby037</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40</label>
      <mixed-citation publication-type="other">Bendale A, Boult TE. Towards open set deep networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. IEEE: 2016. p. 1563–72.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lorenz</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bernhart</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Zu Siederdissen</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Tafer</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Flamm</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>PF</given-names>
          </name>
          <name>
            <surname>Hofacker</surname>
            <given-names>IL</given-names>
          </name>
        </person-group>
        <article-title>Viennarna package 2.0</article-title>
        <source>Algoritm Mol Biol</source>
        <year>2011</year>
        <volume>6</volume>
        <issue>1</issue>
        <fpage>26</fpage>
        <pub-id pub-id-type="doi">10.1186/1748-7188-6-26</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42</label>
      <mixed-citation publication-type="other">Chollet F, et al.Keras. 2015. <ext-link ext-link-type="uri" xlink:href="https://keras.io">https://keras.io</ext-link>. Accessed Oct 2018.</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43</label>
      <mixed-citation publication-type="other">Kim Y. Convolutional neural networks for sentence classification. In: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics: 2014. p. 1746–51.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44</label>
      <mixed-citation publication-type="other">Hendrycks D, Gimpel K. A baseline for detecting misclassified and out-of-distribution examples in neural networks: 2017.</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>miRClassify: an advanced web server for miRNA family classification and annotation</article-title>
        <source>Comput Biol Med</source>
        <year>2014</year>
        <volume>45</volume>
        <fpage>157</fpage>
        <lpage>60</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiomed.2013.12.007</pub-id>
        <pub-id pub-id-type="pmid">24480175</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46</label>
      <mixed-citation publication-type="other">Bailey TL, Elkan C, et al.Fitting a mixture model by expectation maximization to discover motifs in biopolymers. In: Proceedings of the Second International Conference on Intelligent Systems for Molecular Biology. AAAI Press: 1994. p. 28–36.</mixed-citation>
    </ref>
  </ref-list>
</back>
