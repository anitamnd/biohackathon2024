<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10543834</article-id>
    <article-id pub-id-type="pmid">37777712</article-id>
    <article-id pub-id-type="publisher-id">5497</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-023-05497-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DGDTA: dynamic graph attention network for predicting drug–target binding affinity</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhai</surname>
          <given-names>Haixia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hou</surname>
          <given-names>Hongli</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Luo</surname>
          <given-names>Junwei</given-names>
        </name>
        <address>
          <email>luojunwei@hpu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Xiaoyan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Zhengjiang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Junfeng</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05vr1c885</institution-id><institution-id institution-id-type="GRID">grid.412097.9</institution-id><institution-id institution-id-type="ISNI">0000 0000 8645 6375</institution-id><institution>School of Software, </institution><institution>Henan Polytechnic University, </institution></institution-wrap>Jiaozuo, 454003 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>9</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>9</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>24</volume>
    <elocation-id>367</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>23</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Obtaining accurate drug–target binding affinity (DTA) information is significant for drug discovery and drug repositioning. Although some methods have been proposed for predicting DTA, the features of proteins and drugs still need to be further analyzed. Recently, deep learning has been successfully used in many fields. Hence, designing a more effective deep learning method for predicting DTA remains attractive.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Dynamic graph DTA (DGDTA), which uses a dynamic graph attention network combined with a bidirectional long short-term memory (Bi-LSTM) network to predict DTA is proposed in this paper. DGDTA adopts drug compound as input according to its corresponding simplified molecular input line entry system (SMILES) and protein amino acid sequence. First, each drug is considered a graph of interactions between atoms and edges, and dynamic attention scores are used to consider which atoms and edges in the drug are most important for predicting DTA. Then, Bi-LSTM is used to better extract the contextual information features of protein amino acid sequences. Finally, after combining the obtained drug and protein feature vectors, the DTA is predicted by a fully connected layer. The source code is available from GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/DGDTA">https://github.com/luojunwei/DGDTA</ext-link>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">The experimental results show that DGDTA can predict DTA more accurately than some other methods.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Drug–target binding affinity</kwd>
      <kwd>Dynamic graph attention network</kwd>
      <kwd>Long short-term memory</kwd>
      <kwd>Drug discovery</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Innovative and Scientific Research Team of Henan Polytechnic University</institution>
        </funding-source>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zhai</surname>
            <given-names>Haixia</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Xiaoyan</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Zhengjiang</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Junfeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Innovation Project of New Generation Information Technology</institution>
        </funding-source>
        <award-id>2021ITA09021</award-id>
        <award-id>2021ITA09021</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zhai</surname>
            <given-names>Haixia</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61972134</award-id>
        <award-id>61972134</award-id>
        <principal-award-recipient>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Junfeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Young Elite Teachers in Henan Province</institution>
        </funding-source>
        <award-id>2020GGJS050</award-id>
        <principal-award-recipient>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Doctor Foundation of Henan Polytechnic University</institution>
        </funding-source>
        <award-id>B2018-36</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par15">Drug–target interaction (DTI) prediction is a critical task in drug discovery and drug repositioning [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Structural changes to a drug can significantly alter its binding affinity with proteins [<xref ref-type="bibr" rid="CR3">3</xref>], making it important to predict whether a drug can bind to a specific protein. However, the traditional high-throughput screening experiments used to detect this activity are expensive and time-consuming [<xref ref-type="bibr" rid="CR4">4</xref>]. Therefore, computing methods for DTI prediction have become popular and effective [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p id="Par16">DTI calculation methods focus on binary classification [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR7">7</xref>], and the main goal is to determine whether a drug and a target interact with each other [<xref ref-type="bibr" rid="CR8">8</xref>]. However, the assumed binding strength values of the given protein and the drug compound are continuous and referred to as their binding affinity. The drug–target pair prediction task is described as an affinity prediction problem [<xref ref-type="bibr" rid="CR8">8</xref>] in which, the binding affinity score is directly used, thus creating a more realistic experiment. In addition, regression-based models are more advantageous in approximating the strength of DTIs [<xref ref-type="bibr" rid="CR9">9</xref>], making them more conducive to the discovery of new drug compounds in the limited drug research space.</p>
    <p id="Par17">Recently, some methods [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>] for predicting drug–target affinity (DTA) have been developed. SimBoost [<xref ref-type="bibr" rid="CR11">11</xref>] enhances the performance of learning-based methods by extracting features from drugs, targets, and drug–target pairs and providing them to gradient-enhanced supervised learning methods. Affinity is characterized by an inhibition constant (<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{i}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq1.gif"/></alternatives></inline-formula>), dissociation constant (<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{d}$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mi>K</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq2.gif"/></alternatives></inline-formula>), changes in free energy measures (<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta G$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>G</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq3.gif"/></alternatives></inline-formula>,<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta H$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq4.gif"/></alternatives></inline-formula>), half-maximal inhibition constant (<inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I{C}_{50}$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>50</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq5.gif"/></alternatives></inline-formula>) [<xref ref-type="bibr" rid="CR12">12</xref>], half-maximal activity concentration (<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A{C}_{50}$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>50</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq6.gif"/></alternatives></inline-formula>) [<xref ref-type="bibr" rid="CR13">13</xref>], KIBA score [<xref ref-type="bibr" rid="CR14">14</xref>] and scoring. Stronger affinity readings indicate greater DTIs [<xref ref-type="bibr" rid="CR15">15</xref>]. In the KronRLS [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR16">16</xref>] model, the Kronecker products of a drug and target are constructed by drug and protein pairs to calculate the kernel K of the pairs, which is entered into a regularized least-squares regression model (RLS) to predict the binding affinity.</p>
    <p id="Par18">With the success of deep learning, various deep networks have been used for DTA prediction [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR13">13</xref>], and have achieved better performance than machine learning. Some prediction methods are summarized in Table <xref rid="Tab1" ref-type="table">1</xref>. In the DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>] model, one-dimensional sequences of drugs and proteins are fed into a convolutional neural network (CNN) to extract the features of drugs and their targets through the (simplified molecular input line entry system) SMILES string representations of the drugs, and good results have been achieved. The PADME [<xref ref-type="bibr" rid="CR13">13</xref>] model combines molecular graph convolution of compounds and protein features and uses fixed-rule descriptors to represent proteins, improving the predictive performance of the model. The model is more scalable than traditional machine learning models. WideDTA [<xref ref-type="bibr" rid="CR17">17</xref>] builds on DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>] by representing drugs and proteins as words, learning more potential characteristics of drugs and proteins. However, since the convolution window of a CNN is fixed, this network is unable to extract the features of contextual information. To represent molecules in a natural way that preserves as much molecular structure information as possible, thus allowing the model to better learn the relevance of the underlying space, an increasing number of approaches are utilizing graph neural networks to predict DTA. MT-DTI [<xref ref-type="bibr" rid="CR18">18</xref>] introduces the attention mechanism in drug representation and takes more account of the correlation between different molecules, which improves the prediction performance of DTA and greatly increases the interpretability. In DeepGS [<xref ref-type="bibr" rid="CR19">19</xref>], the topological structure information of a drug is extracted by using a graph attention network (GAT) [<xref ref-type="bibr" rid="CR20">20</xref>], while the local chemical background of the drug is captured by using a bidirectional gated recurrent unit (Bi-GRU) [<xref ref-type="bibr" rid="CR21">21</xref>] and combined with the protein sequence features extracted by a CNN for prediction. rzMLP [<xref ref-type="bibr" rid="CR22">22</xref>] uses a gMLP model to aggregate input features with constant size, and uses a ReZero layer to smooth the training process for that block. The model is able to learn more complex global features while avoiding poor predictions due to a too deep model. EnsembleDLM [<xref ref-type="bibr" rid="CR23">23</xref>] aggregates predictions from multiple deep neural networks, not only obtaining better predictions, but also exploring how much data deep learning networks need to achieve better prediction performance. GANsDTA [<xref ref-type="bibr" rid="CR24">24</xref>] employs a generative adversarial network (GAN) [<xref ref-type="bibr" rid="CR25">25</xref>] to extract features of protein sequences and compound SMILES in an unsupervised manner. Because GAN’s feature extractor does not require labeled data, the model is able to accommodate unlabeled data for training. Because GAN’s feature extractor does not require labeled data, the model is able to accommodate unlabeled data for training. The model can use more datasets to learn protein and drug features, thus achieving correspondingly better feature representation and prediction performance. GraphDTA [<xref ref-type="bibr" rid="CR26">26</xref>] modelled drugs as molecular graphs with one-dimensional drug sequences, then put the graph into several graph network models and obtained deep learning models, which were excellent at the time. GraphDTA [<xref ref-type="bibr" rid="CR26">26</xref>] demonstrated that representing drugs as graphs can further improve the prediction capabilities of deep learning models in terms of DTA.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Prediction methods
</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">Published time</th><th align="left">Model</th><th align="left">Summary</th></tr></thead><tbody><tr><td align="left">SimBoost [<xref ref-type="bibr" rid="CR11">11</xref>]</td><td align="left">2016</td><td align="left">Gradient boosting regression trees</td><td align="left">Predicting continuous values of binding affinities of compounds and proteins</td></tr><tr><td align="left">KronRLS [<xref ref-type="bibr" rid="CR16">16</xref>]</td><td align="left">2018</td><td align="left">Multiple kernel learning</td><td align="left">The first method for time- and memory-efficient learning with multiple pairwise kernels</td></tr><tr><td align="left">DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td align="left">2018</td><td align="left">CNN</td><td align="left">Processing protein sequences and compound 1D representations using convolutional neural networks</td></tr><tr><td align="left">PADME [<xref ref-type="bibr" rid="CR13">13</xref>]</td><td align="left">2018</td><td align="left">DNN</td><td align="left">The first to combine Molecular Graph Convolution for compound featurization with protein descriptors</td></tr><tr><td align="left">WideDTA [<xref ref-type="bibr" rid="CR17">17</xref>]</td><td align="left">2019</td><td align="left">CNN</td><td align="left">Combining four different textual pieces of information related to proteins and ligands</td></tr><tr><td align="left">MT-DTI [<xref ref-type="bibr" rid="CR18">18</xref>]</td><td align="left">2019</td><td align="left">Transformers + CNN</td><td align="left">Proposing a new molecule representation based on the self-attention mechanism</td></tr><tr><td align="left">GANsDTA [<xref ref-type="bibr" rid="CR24">24</xref>]</td><td align="left">2019</td><td align="left">GAN + CNN</td><td align="left">Effectively learning valuable features from labeled and unlabeled data</td></tr><tr><td align="left">DeepGS [<xref ref-type="bibr" rid="CR19">19</xref>]</td><td align="left">2020</td><td align="left">GAT + Bi-GRU</td><td align="left">Extracting the topological information of the molecular map and the local chemical context of the drug</td></tr><tr><td align="left">rzMLP [<xref ref-type="bibr" rid="CR22">22</xref>]</td><td align="left">2021</td><td align="left">gMLP + ReZero</td><td align="left">Use MHM block for multiple protein and ligand representations and rzMLP block to aggregate concatenated protein-ligand pair representations</td></tr><tr><td align="left">EnsembelDLM [<xref ref-type="bibr" rid="CR23">23</xref>]</td><td align="left">2021</td><td align="left">Multiple deep networks</td><td align="left">Aggregating predictions from multiple deep neural networks</td></tr><tr><td align="left">GraphDTA [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td align="left">2021</td><td align="left">GIN + CNN</td><td align="left">Introducing multiple models of graph neural networks</td></tr></tbody></table></table-wrap></p>
    <p id="Par19">However, two problems remain that prevent accurate DTA. (1) The GAT model used by some contemporary methods is a restricted form of static attention, and the attention coefficient function of the nodes in the drug graph is monotonic, which leads to the inability to comprehensively extract drug features. (2) When processing protein sequences, the contextual association information of amino acid sequences is not acquired, and the protein association features are thus ignored.</p>
    <p id="Par20">To solve the above problem, this paper proposes a method named dynamic graph DTA (DGDTA). In DGDTA, each drug is considered a graph of interactions between atoms and edges, and a dynamic attention score is used to consider which atoms and edges in the drug graph play more critical roles in predicting DTA. Compared with static attention, DGDTA is able to extract a more comprehensive drug signature. To better obtain the contextual features of amino acid sequences in proteins, DGDTA introduces bidirectional long short-term memory (Bi-LSTM) [<xref ref-type="bibr" rid="CR27">27</xref>] to extract more comprehensive amino acid sequence features in combination with drugs. Through validations conducted on the Davis [<xref ref-type="bibr" rid="CR28">28</xref>] and KIBA [<xref ref-type="bibr" rid="CR14">14</xref>] datasets, DGDTA achieves better performance than the competing methods in terms of results. In this paper, a dynamic graph attention network example is given to further improve the representativeness and effectiveness of drug molecule maps. The experimental results demonstrate the effectiveness of DGDTA.
</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <p id="Par21">DGDTA is a method for predicting DTA based on a deep learning network, and its architecture (shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>), is divided into three main steps. (1) Obtaining drug features. DGDTA uses the SMILES [<xref ref-type="bibr" rid="CR29">29</xref>] as the drug compound input, and transforms the drug into a drug graph consisting of atoms and edges with reference to the natural properties of the drug. According to the literature, a two-layer graph network structure has better feature extraction performance. DGDTA uses a two-layer dynamic graph attention network (GATv2) [<xref ref-type="bibr" rid="CR30">30</xref>] and a combination of GATv2 and a graph convolutional network (GCN) to obtain drug graph features, and DGDTA is divided into two versions: DGDTA-AL and DGDTA-CL. (2) Extracting protein features. DGDTA uses a combination of Bi-LSTM and multilayer convolutional networks to obtain more comprehensive protein amino acid sequence information while considering the contextual relationships among the amino acid sequences. (3) Performing DTA prediction. The observed connections among drug features and protein features during extraction used to determine DTA via a fully connected layer. The details of DGDTA are described in the following parts.<fig id="Fig1"><label>Fig. 1</label><caption><p>General architecture of DGDTA</p></caption><graphic xlink:href="12859_2023_5497_Fig1_HTML" id="d32e656"/></fig></p>
    <sec id="Sec3">
      <title>Obtaining drug features</title>
      <p id="Par22">With the development of graph neural networks for DTA, many approaches have been presented. When using a graph to represent a drug, it is difficult to accurately extract graph features due to the complexity of drug graphs. DGDTA adopts a dynamic GAT to obtain drug features. Through SMILE code, drug’s atomic composition, and the valence charge number of atoms can be inferred, which can further judge drug information such as the number of hydrogen bonds, and then used for the drug’s feature representation in affinity prediction. To better extract drug features, DGDTA uses the SMILES [<xref ref-type="bibr" rid="CR29">29</xref>] sequences of drugs as inputs, and uses RDKit to extract the atoms and interactions from the SMILES sequences. Then, DGDTA constructs a graph for each drug based on its SMILES sequence. A drug graph is denoted as <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G=(V,E)$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq7.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V$$\end{document}</tex-math><mml:math id="M16"><mml:mi>V</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq8.gif"/></alternatives></inline-formula> is a node represented by a drug atom, and <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E$$\end{document}</tex-math><mml:math id="M18"><mml:mi>E</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq9.gif"/></alternatives></inline-formula> represents the set of edges between nodes. Each node is represented by an n-dimensional vector from DeepChem [<xref ref-type="bibr" rid="CR31">31</xref>]. This n-dimensional vector includes the atomic symbols, the number of adjacent hydrogen atoms, the number of adjacent atoms, the implicit valence of the atoms (implicit valence) and whether the bonds are aromatic. One node is represented as <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{d}=\left\{{\text{f}}_{1},{\text{f}}_{2},{\text{f}}_{3}\dots ,{\text{f}}_{n}\right\}$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mtext>f</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>f</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>f</mml:mtext><mml:mn>3</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mtext>f</mml:mtext><mml:mi>n</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq10.gif"/></alternatives></inline-formula>. By representing the atoms d of each drug as the vertices of the drug graph, the features <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\left\{{\text{d}}_{1},{\text{d}}_{2},{\text{d}}_{3}\dots ,{\text{d}}_{D}\right\}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mtext>d</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>d</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>d</mml:mtext><mml:mn>3</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mtext>d</mml:mtext><mml:mi>D</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq11.gif"/></alternatives></inline-formula> of each drug are obtained. To obtain more information about the graph structure in n-dimensional space, this paper adopts a dynamic attention mechanism for the graph:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e\left({d}_{i},{d}_{j}\right)={a}^{T}LeakyReLU\left(W\left[{d}_{i}\parallel {d}_{j}\right]\right) \quad j\in {\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi><mml:mfenced close="]" open="["><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mspace width="1em"/><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e\left( {d_{i} ,d_{j} } \right)$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq12.gif"/></alternatives></inline-formula> denotes the importance of the features of neighbour node <inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M28"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq13.gif"/></alternatives></inline-formula> to node <inline-formula id="IEq14"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M30"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq14.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq15"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq15.gif"/></alternatives></inline-formula> represents the neighbours of node <inline-formula id="IEq16"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M34"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq16.gif"/></alternatives></inline-formula>, <inline-formula id="IEq17"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a\in {\mathbb{R}}^{{2d}^{{\prime }}}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq17.gif"/></alternatives></inline-formula>, <inline-formula id="IEq18"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W\in {\mathbb{R}}^{{2d}^{{\prime }}\times d}$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq18.gif"/></alternatives></inline-formula> are learned, and II denotes vector concatenation. Utilizing the <inline-formula id="IEq19"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$softmax$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mi mathvariant="italic">softmax</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq19.gif"/></alternatives></inline-formula> function to normalize all neighbours, we can obtain the following attention function:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{ij}=softmax\left(e\left({d}_{i},{d}_{j}\right)\right)=\frac{exp\left(e\left({d}_{i},{d}_{j}\right)\right)}{{\sum }_{k\in {\mathcal{N}}_{\mathcalligra{i}}}exp\left(e\left({d}_{i},{d}_{k}\right)\right)}$$\end{document}</tex-math><mml:math id="M42" display="block"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par23">Combining Eqs. (<xref rid="Equ1" ref-type="disp-formula">1</xref>) and (<xref rid="Equ2" ref-type="disp-formula">2</xref>), the coefficients of attention are expressed as:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{ij}=\frac{{a}^{T}LeakyReLU\left(W\left[{d}_{i}\parallel {d}_{j}\right]\right)}{{\sum }_{k\in {\mathcal{N}}_{\mathcalligra{i}}}exp\left({a}^{T}LeakyReLU\left(W\left[{d}_{i}\parallel {d}_{j}\right]\right)\right)}$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi><mml:mfenced close="]" open="["><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi><mml:mfenced close="]" open="["><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par24">After integrating the feature information of the neighbouring nodes, we apply the nonlinear parameter <inline-formula id="IEq20"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M46"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq20.gif"/></alternatives></inline-formula>, to obtain the output features of each node:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{i}^{{\prime }}=\sigma \left({\sum }_{j\in {\mathcal{N}}_{\mathcalligra{i}}}{a}_{ij}W{d}_{j}\right)$$\end{document}</tex-math><mml:math id="M48" display="block"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mi>W</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par25">Nodes are represented as the weighted averages of their neighbouring feature vectors. To further solidify the learning process of dynamic graph self-attention and improve the learning effect, the attention is extended to multiheaded attention.<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{i}^{{\prime }{\prime }}=\sigma \left(\frac{1}{H}\sum _{h=1}^{H}{\sum }_{j\in {\mathcal{N}}_{\mathcalligra{i}}}{{a}_{ij}}^{h}{W}^{h}{d}_{j}\right)$$\end{document}</tex-math><mml:math id="M50" display="block"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mi>H</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>H</mml:mi></mml:munderover><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>h</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msup><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq21"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H$$\end{document}</tex-math><mml:math id="M52"><mml:mi>H</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq21.gif"/></alternatives></inline-formula> independent attention mechanisms connect the semantic feature vectors of the nodes through Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>), and obtain an updated drug feature representation <inline-formula id="IEq22"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{D}}^{\left(1\right)}=\left\{{\text{d}}_{1}^{\left(1\right)},{\text{d}}_{2}^{\left(1\right)},{\text{d}}_{3}^{\left(1\right)}\dots ,{\text{d}}_{D}^{\left(1\right)}\right\}$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:msup><mml:mrow><mml:mtext>D</mml:mtext></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq22.gif"/></alternatives></inline-formula>. Based on a combination of research and experiments, a two-layer graph network structure is able to obtain more accurate prediction results. First, the graph network in the second layer uses a dynamic graph neural network and obtains the drug feature representations <inline-formula id="IEq23"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{D}}^{\left(2\right)}=\left\{{\text{d}}_{1}^{\left(2\right)},{\text{d}}_{2}^{\left(2\right)},{\text{d}}_{3}^{\left(2\right)}\dots ,{\text{d}}_{D}^{\left(2\right)}\right\}$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:msup><mml:mrow><mml:mtext>D</mml:mtext></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq23.gif"/></alternatives></inline-formula>; this version is named DGDTA-AL. After many experiments and comparisons, the graph network in the second layer is replaced with a GCN, whose propagation rules are as follows:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{(l+1)}=\sigma \left({\stackrel{\sim}{D}}^{-\frac{1}{2}}\stackrel{\sim}{A}{\stackrel{\sim}{D}}^{-\frac{1}{2}}{H}^{\left(l\right)}{W}^{\left(l\right)}\right)$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>∼</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mover><mml:mi>A</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>∼</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq24"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{\left(l\right)}$$\end{document}</tex-math><mml:math id="M60"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq24.gif"/></alternatives></inline-formula> denotes the nodal feature matrix of <inline-formula id="IEq25"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${l}^{th}$$\end{document}</tex-math><mml:math id="M62"><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">th</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq25.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq26"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\stackrel{\sim}{A}=A+I$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq26.gif"/></alternatives></inline-formula>, <inline-formula id="IEq27"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A$$\end{document}</tex-math><mml:math id="M66"><mml:mi>A</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq27.gif"/></alternatives></inline-formula> is the adjacency matrix, <inline-formula id="IEq28"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I$$\end{document}</tex-math><mml:math id="M68"><mml:mi>I</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq28.gif"/></alternatives></inline-formula> is the unit matrix, <inline-formula id="IEq29"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\stackrel{\sim}{D}=D+I$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq29.gif"/></alternatives></inline-formula>, <inline-formula id="IEq30"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M72"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq30.gif"/></alternatives></inline-formula> is the degree matrix, and <inline-formula id="IEq31"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W$$\end{document}</tex-math><mml:math id="M74"><mml:mi>W</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq31.gif"/></alternatives></inline-formula> is a trainable weight. A drug feature representation <inline-formula id="IEq32"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{D}}^{{\left(2\right)}^{{\prime }}}=\left\{{\text{d}}_{1}^{{\left(2\right)}^{{\prime }}},{\text{d}}_{2}^{{\left(2\right)}^{{\prime }}},{\text{d}}_{3}^{{\left(2\right)}^{{\prime }}}\dots ,{\text{d}}_{D}^{{\left(2\right)}^{{\prime }}}\right\}$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:msup><mml:mrow><mml:mtext>D</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq32.gif"/></alternatives></inline-formula> is obtained. The GCN is applied to the full graph via the Laplacian matrix, which captures the connectivity relationships between the graph nodes and updates the node features of the full graph. In this paper, this version is named DGDTA-CL. We use the rectified linear unit (<inline-formula id="IEq33"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ReLU$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mi mathvariant="italic">ReLU</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq33.gif"/></alternatives></inline-formula>) activation function after each layer and use global maximum pooling in the last layer to obtain the vector representation of the drug.</p>
    </sec>
    <sec id="Sec4">
      <title>Extracting protein features</title>
      <p id="Par26">A protein sequence is a string of ASCII characters represented as amino acids. In many methods, one-hot codes are used to represent drugs and proteins, as well as other biological sequences, such as DNA and RNA. We use one-hot encoding to represent the atoms of the drug and incorporate atomic properties for drug initialization. Because drug molecules are shorter and simpler in structure than proteins, we utilize one-hot encoding to expand the dimensionality of the drug’s representation. This enables model to capture specific information associated with each drug atom. For protein, in order to prevent feature singularity, we employ different approaches for the initialization. In this paper, we map each amino acid to a numerical value and represent one protein as a sequence of integers. And then an embedding layer is added to the sequence, where each character is represented by a 128-dimensional vector. For training purposes, the sequences are cut or padded to a fixed sequence with a length of 1000. If the sequence is short, it is padded with 0 values. In this paper, the embedding representation (<inline-formula id="IEq34"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{c}\in {\mathbb{R}}^{{\mathcalligra{d}}_{p}}$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mtext>c</mml:mtext><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mi mathvariant="script">d</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq34.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq35"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M82"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq35.gif"/></alternatives></inline-formula> is the dimensionality of the protein embedding) is a Bi-LSTM layer that captures the dependencies the characters in a sequence of length <inline-formula id="IEq36"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M84"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq36.gif"/></alternatives></inline-formula> (<inline-formula id="IEq37"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C=\left[{\text{c}}_{1},{c}_{2}\dots {\text{c}}_{n}\right]$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:msub><mml:mtext>c</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mtext>c</mml:mtext><mml:mi>n</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq37.gif"/></alternatives></inline-formula>). We obtain <inline-formula id="IEq38"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}\in {\mathbb{R}}^{{2\mathcalligra{d}}_{1}}$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="script">d</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq38.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq39"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{1}$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq39.gif"/></alternatives></inline-formula> denotes the number of output cells used in each LSTM cell.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow{{p}_{i}}= \overrightarrow{LSTM}({\text{c}}_{\text{i}},{p}_{i-1})$$\end{document}</tex-math><mml:math id="M92" display="block"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="italic">LSTM</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>c</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{p}_{i}}=\overleftarrow{LSTM}({c}_{i},{p}_{i+1})$$\end{document}</tex-math><mml:math id="M94" display="block"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="italic">LSTM</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{\text{i}}= \overrightarrow{{p}_{i}}\parallel \overleftarrow{{p}_{i}}$$\end{document}</tex-math><mml:math id="M96" display="block"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>i</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">‖</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par27">The vector <inline-formula id="IEq40"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P$$\end{document}</tex-math><mml:math id="M98"><mml:mi>P</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq40.gif"/></alternatives></inline-formula> is composed of the output vectors generated by the Bi-LSTM; i.e., <inline-formula id="IEq41"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=\left[{p}_{1},{p}_{2}\dots {p}_{n}\right]$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq41.gif"/></alternatives></inline-formula>. Finally, we use a one-dimensional convolutional layer to learn different levels of abstract features to obtain a vector of protein sequences representations.</p>
    </sec>
    <sec id="Sec5">
      <title>Performing DTA prediction</title>
      <p id="Par28">The prediction layer connects the learned drug vector representation with the vector representation of the protein sequence. Then, they are used as inputs and the output <inline-formula id="IEq42"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y$$\end{document}</tex-math><mml:math id="M102"><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq42.gif"/></alternatives></inline-formula> is obtained from the fully connected layer.<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y={W}_{output}\left[D,P\right]+{b}_{output}$$\end{document}</tex-math><mml:math id="M104" display="block"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="["><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula> where <inline-formula id="IEq43"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{output}$$\end{document}</tex-math><mml:math id="M106"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq43.gif"/></alternatives></inline-formula> denotes the weight matrix of the fully connected layer and <inline-formula id="IEq44"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{output}$$\end{document}</tex-math><mml:math id="M108"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq44.gif"/></alternatives></inline-formula> denotes the bias of the fully connected layer.</p>
      <p id="Par29">We choose the mean square error (MSE) loss as the loss function, which has the advantage of a function curve that is smooth, continuous and derivable everywhere, making it convenient for use in the gradient descent algorithm. As the error decreases, the gradient also decreases, which is more conducive to convergence and more stable.<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MSE=\frac{1}{n}\sum _{i=1}^{n}{({Y}_{i}-{y}_{i})}^{2}$$\end{document}</tex-math><mml:math id="M110" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula> where <inline-formula id="IEq45"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Y}_{i}\in {\mathbb{R}}^{\text{B}}$$\end{document}</tex-math><mml:math id="M112"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mtext>B</mml:mtext></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq45.gif"/></alternatives></inline-formula>, <inline-formula id="IEq46"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{i}\in {\mathbb{R}}^{\text{B}}$$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mtext>B</mml:mtext></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq46.gif"/></alternatives></inline-formula> denotes the predicted affinity value between the <inline-formula id="IEq47"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M116"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq47.gif"/></alternatives></inline-formula>th sample and the label of the affinity value in the sample, and <inline-formula id="IEq48"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{B}$$\end{document}</tex-math><mml:math id="M118"><mml:mtext>B</mml:mtext></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq48.gif"/></alternatives></inline-formula> denotes the batch size.</p>
    </sec>
    <sec id="Sec6">
      <title>Model training</title>
      <p id="Par30">DGDTA takes drug SMILES strings and protein amino acid sequences as inputs. In this paper, Python 3.9, PyTorch 1.12.1 and PyG2.1 are used to implement dynamic GAT and LSTM. In this paper, the number of layers in the graph neural network is set to 2, Bi-LSTM is applied, the number of hidden states is set to 10, and the dropout parameter is set to 0.2. Then, the proposed method is trained on the above dataset for 1000 epochs, and the adaptive moment estimation (Adam) optimizer is used with a learning rate of 0.0005. The devices that are used for the experiments are an Intel(R) Xeon(R) Platinum 8260 CPU @ 2.30 GHz and an NVIDIA GeForce RTX 3090 GPU.</p>
    </sec>
  </sec>
  <sec id="Sec7" sec-type="results">
    <title>Results</title>
    <p id="Par31">In this section, we present the dataset used, the evaluation metrics, an ablation study and the results of a comparison with state-of-the-art methods. This section also illustrates the advantage of the dynamic GAT and gives an example of a real drug–target combination.</p>
    <sec id="Sec8">
      <title>Dataset and evaluation metrics</title>
      <p id="Par32">We use the Davis [<xref ref-type="bibr" rid="CR28">28</xref>] and KIBA [<xref ref-type="bibr" rid="CR14">14</xref>] datasets to evaluate the performance of the method proposed in this paper. The numbers of drugs and targets in the dataset, and the sample sizes for training and testing during the experiments are shown in Table <xref rid="Tab2" ref-type="table">2</xref>. In this paper, the concordance index (CI; the larger the better) [<xref ref-type="bibr" rid="CR32">32</xref>] and MSE (the smaller the better) are also used as the main indicators for evaluating the performance of the tested models. In this paper, the GAT and GAT_GCN models are chosen as baseline1 and baseline2 of the ablation study, respectively.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Davis</th><th align="left">KIBA</th></tr></thead><tbody><tr><td align="left">Drugs</td><td align="left">72</td><td align="left">2116</td></tr><tr><td align="left">Targets</td><td align="left">442</td><td align="left">229</td></tr><tr><td align="left">Total samples</td><td align="left">30,056</td><td align="left">118,254</td></tr><tr><td align="left">Train samples</td><td align="left">25,046</td><td align="left">98,545</td></tr><tr><td align="left">Test samples</td><td align="left">5010</td><td align="left">19,709</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec9">
      <title>Ablation study</title>
      <p id="Par33">In the ablation study, we analyse the effectiveness of the innovative elements of our method. In this section, to be as fair as possible, we use the same training and testing sets as those employed by the baselines and the same evaluation metrics. In this paper, a dynamic graph neural network is incorporated into the drug graph, and Bi-LSTM is added to extract protein amino acid sequence features to further improve the model accuracy. The popular GRU model is added as a comparison method. GRU and LSTM are important variants of recurrent neural networks, and they have strong memory and long-distance dependence capturing ability when processing sequence data. GRU has higher computational efficiency with reduced parameter settings compared to LSTM, but this also leads to some loss of information at longer distances in some cases. In order to better capture the contextual association information of amino acid sequences and further prove the effectiveness of LSTM method, GRU is introduced as a comparison in the ablation study. And the results of the ablation study are shown in Figs. <xref rid="Fig2" ref-type="fig">2</xref> and <xref rid="Fig3" ref-type="fig">3</xref>.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Comparison between baseline1 and different models at 200 and 1000 epochs</p></caption><graphic xlink:href="12859_2023_5497_Fig2_HTML" id="d32e1999"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>Comparison between baseline2 and different models at 200 and 1000 epochs</p></caption><graphic xlink:href="12859_2023_5497_Fig3_HTML" id="d32e2006"/></fig></p>
      <p id="Par34">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows that on the Davis and KIBA datasets, the DTA prediction results obtained by Model-2 using the dynamic GAT achieve a higher CI and a smaller MSE than those of baseline 1 in the same number of epochs. Model-1 with the addition of Bi-LSTM method is also better than baseline1. Based on Model-2, Bi-LSTM is used to improve the ability to extract contextual protein amino acid sequence features. The evaluation score of Model-4 is improved further, while the prediction result is better than that of the GRU in Model-3 with the same parameters. Model-4 achieves the best results in the 200-epoch and 1000-epoch comparisons conducted on both datasets, and Model-4 is the DGDTA-AL method illustrated in 2.1. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, Model-8 obtains the highest CI and the lowest MSE in the comparison with baseline 2 over the same number of epochs; Model-8 is the DGDTA-CL method.</p>
      <p id="Par35">In this paper, the results obtained by different models in the ablation study are presented in Table <xref rid="Tab3" ref-type="table">3</xref>. On the Davis dataset, DGDTA-AL achieves the best results (in bold), reaching 0.899 and 0.225 CI and MSE values, respectively, which are improvements of 0.7% and 0.7% over those of baseline. DGDTA-CL achieves a CI of 0.902 and an MSE of 0.125 on the KIBA dataset, which are improvements of 1.1% and 1.4% over those of baseline 2, respectively. The results of the ablation study demonstrate the effectiveness of the innovative elements proposed in this paper.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Ablation study on the Davis and KIBA datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Methods</th><th align="left">GATv2</th><th align="left">GCN</th><th align="left">GRU</th><th align="left">LSTM</th><th align="left">CI</th><th align="left">MSE</th></tr></thead><tbody><tr><td align="left">Davis</td><td align="left">Baseline1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.892</td><td char="." align="char">0.232</td></tr><tr><td align="left"/><td align="left">Model-1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.893</td><td char="." align="char">0.230</td></tr><tr><td align="left"/><td align="left">Model-2</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.895</td><td char="." align="char">0.232</td></tr><tr><td align="left"/><td align="left">Model-3</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td char="." align="char">0.896</td><td char="." align="char">0.228</td></tr><tr><td align="left"/><td align="left">Model-4</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char"><bold>0.899</bold><sup><bold>*</bold></sup></td><td char="." align="char"><bold>0.225</bold></td></tr><tr><td align="left"/><td align="left">Baseline2</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.881</td><td char="." align="char">0.245</td></tr><tr><td align="left"/><td align="left">Model-5</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.886</td><td char="." align="char">0.241</td></tr><tr><td align="left"/><td align="left">Model-6</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.883</td><td char="." align="char">0.242</td></tr><tr><td align="left"/><td align="left">Model-7</td><td align="left">✓</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td char="." align="char">0.887</td><td char="." align="char">0.239</td></tr><tr><td align="left"/><td align="left">Model-8</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.889</td><td char="." align="char">0.237</td></tr><tr><td align="left">KIBA</td><td align="left">Baseline1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.866</td><td char="." align="char">0.179</td></tr><tr><td align="left"/><td align="left">Model-1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.867</td><td char="." align="char">0.172</td></tr><tr><td align="left"/><td align="left">Model-2</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.869</td><td char="." align="char">0.175</td></tr><tr><td align="left"/><td align="left">Model-3</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td align="left"/><td char="." align="char">0.871</td><td char="." align="char">0.169</td></tr><tr><td align="left"/><td align="left">Model-4</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.878</td><td char="." align="char">0.162</td></tr><tr><td align="left"/><td align="left">Baseline2</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.891</td><td char="." align="char">0.139</td></tr><tr><td align="left"/><td align="left">Model-5</td><td align="left"/><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.896</td><td char="." align="char">0.131</td></tr><tr><td align="left"/><td align="left">Model-6</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.893</td><td char="." align="char">0.135</td></tr><tr><td align="left"/><td align="left">Model-7</td><td align="left">✓</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td char="." align="char">0.898</td><td char="." align="char">0.128</td></tr><tr><td align="left"/><td align="left">Model-8</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char"><bold>0.902</bold></td><td char="." align="char"><bold>0.125</bold></td></tr></tbody></table><table-wrap-foot><p>
*Bold values represent the best result</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec10">
      <title>Comparison with the state-of-the-art methods</title>
      <p id="Par36">In this section, Table <xref rid="Tab4" ref-type="table">4</xref> shows the experimental results obtained by DGDTA and the comparison methods. To be consistent with the ablation experiment in 3.2, we use the same datasets and evaluation metrics. Based on this, we added the <inline-formula id="IEq49"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M120"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq49.gif"/></alternatives></inline-formula> evaluation metric. As shown in Table <xref rid="Tab4" ref-type="table">4</xref>, DGDTA-AL is better than the mainstream DTA methods in terms of the CI, MSE and <inline-formula id="IEq50"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M122"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq50.gif"/></alternatives></inline-formula> on the Davis dataset. Compared with DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>], which has the best results among the comparison methods, the CI and MSE of the proposed approach are improved by 0.6% and 1.1%, respectively. Additionally, the CI and MSE are improved by 0.9% and 0.4%, respectively, over those of the excellent MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>] method. And, <inline-formula id="IEq51"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M124"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq51.gif"/></alternatives></inline-formula> reaches 0.707. As shown in Table <xref rid="Tab4" ref-type="table">4</xref>, DGDTA-CL achieves a more significant improvement in its results on the KIBA dataset. Compared with the DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>] method, DGDTA-CL attains 1.2% and 1.8% performance improvements in terms of the CI and MSE metrics, and 1.3% and 2.5% CI and MSE improvements are achieved over the MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>] method, respectively. And, <inline-formula id="IEq52"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M126"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq52.gif"/></alternatives></inline-formula> reaches 0.809. Figure <xref rid="Fig4" ref-type="fig">4</xref> plots the CI scores obtained by the methods in the table for both datasets to further demonstrate the performance improvement provided by the DGDTA method. The experimental results show that DGDTA is better than the comparative methods, and the use of a dynamic graph with attention to extract drug features and effective contextual protein information is significant for predicting DTA.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparison with the state-of-the-art methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Methods</th><th align="left">CI</th><th align="left">MSE</th><th align="left"><inline-formula id="IEq53"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\textbf{r}}_{\textbf{m}}^{2}$$\end{document}</tex-math><mml:math id="M128"><mml:msubsup><mml:mi mathvariant="bold">r</mml:mi><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq53.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left">Davis</td><td align="left">DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td char="." align="char">0.878</td><td char="." align="char">0.261</td><td char="." align="char">0.631</td></tr><tr><td align="left"/><td align="left">DeepCDA [<xref ref-type="bibr" rid="CR35">35</xref>]</td><td char="." align="char">0.891</td><td char="." align="char">0.248</td><td char="." align="char">0.652</td></tr><tr><td align="left"/><td align="left">MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>]</td><td char="." align="char">0.890</td><td char="." align="char">0.229</td><td char="." align="char">0.688</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.892</td><td char="." align="char">0.232</td><td char="." align="char">0.689</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT-GCN) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.881</td><td char="." align="char">0.245</td><td char="." align="char">0.667</td></tr><tr><td align="left"/><td align="left">CPInformer [<xref ref-type="bibr" rid="CR6">6</xref>]</td><td char="." align="char">0.874</td><td char="." align="char">0.277</td><td char="." align="char">0.621</td></tr><tr><td align="left"/><td align="left">DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>]</td><td char="." align="char">0.893</td><td char="." align="char">0.236</td><td char="." align="char">0.679</td></tr><tr><td align="left"/><td align="left">DGDTA-CL (ours)</td><td char="." align="char">0.889</td><td char="." align="char">0.237</td><td char="." align="char">0.672</td></tr><tr><td align="left"/><td align="left">DGDTA-AL (ours)</td><td char="." align="char"><bold>0.899</bold><sup><bold>*</bold></sup></td><td char="." align="char"><bold>0.225</bold></td><td char="." align="char"><bold>0.707</bold></td></tr><tr><td align="left">KIBA</td><td align="left">DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td char="." align="char">0.863</td><td char="." align="char">0.194</td><td char="." align="char">0.673</td></tr><tr><td align="left"/><td align="left">DeepCDA [<xref ref-type="bibr" rid="CR35">35</xref>]</td><td char="." align="char">0.889</td><td char="." align="char">0.176</td><td char="." align="char">0.682</td></tr><tr><td align="left"/><td align="left">MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>]</td><td char="." align="char">0.889</td><td char="." align="char">0.150</td><td char="." align="char">0.762</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.866</td><td char="." align="char">0.179</td><td char="." align="char">0.738</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT-GCN) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.891</td><td char="." align="char">0.139</td><td char="." align="char">0.789</td></tr><tr><td align="left"/><td align="left">CPInformer [<xref ref-type="bibr" rid="CR6">6</xref>]</td><td char="." align="char">0.867</td><td char="." align="char">0.183</td><td char="." align="char">0.678</td></tr><tr><td align="left"/><td align="left">DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>]</td><td char="." align="char">0.890</td><td char="." align="char">0.143</td><td char="." align="char">0.789</td></tr><tr><td align="left"/><td align="left">DGDTA-AL (ours)</td><td char="." align="char">0.881</td><td char="." align="char">0.162</td><td char="." align="char">0.762</td></tr><tr><td align="left"/><td align="left">DGDTA-CL (ours)</td><td char="." align="char"><bold>0.902</bold></td><td char="." align="char"><bold>0.125</bold></td><td char="." align="char"><bold>0.809</bold></td></tr></tbody></table><table-wrap-foot><p>*Bold values represent the best result</p></table-wrap-foot></table-wrap><fig id="Fig4"><label>Fig. 4</label><caption><p>CI comparison among the experimental methods on the Davis and KIBA datasets</p></caption><graphic xlink:href="12859_2023_5497_Fig4_HTML" id="d32e2789"/></fig></p>
    </sec>
    <sec id="Sec11">
      <title>Advantages of the DGDTA model</title>
      <p id="Par37">A dynamic GAT suggests that a traditional GAT is only a computationally constrained form of “static” attention: for any query node, the attention function is monotonic with respect to the key fraction [<xref ref-type="bibr" rid="CR30">30</xref>]. As shown in the GAT heatmap presented in Fig. <xref rid="Fig5" ref-type="fig">5</xref>, the ordering of the attention coefficients is global, and all queries focus primarily on the 7th key.<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e\left({d}_{i},{d}_{j}\right)=LeakyReLU\left({a}^{T}\left[W{d}_{i}\right]\parallel \left[W{d}_{j}\right]\right) j\in {\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M130" display="block"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mfenced close="]" open="["><mml:mi>W</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:mfenced close="]" open="["><mml:mi>W</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par38">Formula (<xref rid="Equ10" ref-type="disp-formula">10</xref>) is the method for calculating the attention coefficients in the GAT, indicating the importance of the feature of node <inline-formula id="IEq54"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M132"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq54.gif"/></alternatives></inline-formula> to node <inline-formula id="IEq55"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M134"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq55.gif"/></alternatives></inline-formula>. As <inline-formula id="IEq56"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M136"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq56.gif"/></alternatives></inline-formula> is limited, there exists <inline-formula id="IEq57"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M138"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq57.gif"/></alternatives></inline-formula> node <inline-formula id="IEq58"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${j}_{max}$$\end{document}</tex-math><mml:math id="M140"><mml:msub><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq58.gif"/></alternatives></inline-formula> where the attention distribution <inline-formula id="IEq59"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M142"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq59.gif"/></alternatives></inline-formula> only calculates static attention from <inline-formula id="IEq60"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${j}_{max}$$\end{document}</tex-math><mml:math id="M144"><mml:msub><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq60.gif"/></alternatives></inline-formula> due to it being the maximum value. To overcome the monotonicity restriction of the key score, Formula (<xref rid="Equ12" ref-type="disp-formula">12</xref>) is transformed into Formula (<xref rid="Equ1" ref-type="disp-formula">1</xref>). This variant is more expressive than the GAT, as shown in the attention maps of GATv2 in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. Since static attention cannot have different correlations for different keys and different queries, if there is one key that has a higher attention score than the others, then no query can ignore the score of this key, which results in very limited static attention.<fig id="Fig5"><label>Fig. 5</label><caption><p>Attention coefficients of the GAT and GATv2</p></caption><graphic xlink:href="12859_2023_5497_Fig5_HTML" id="d32e2950"/></fig></p>
      <p id="Par39">Among the datasets, Davis contains 2457 positive samples and 27,599 negative samples, the total number of samples is small, and the label distribution in the dataset is unbalanced. KIBA has 22,729 positive samples and 95,525 negative samples, so it contains more samples than Davis, but most of the labels in KIBA are very concentrated, and the label distribution is relatively normal. These problems create barriers for the model in terms of affinity prediction. Dynamic graph attention pays different amounts of attention to different queries in the attention score, enabling it to better distinguish the similarities and differences between samples. It is more discriminative during drug graph extraction and alleviates the imbalance problem in the given dataset. Figure <xref rid="Fig6" ref-type="fig">6</xref> shows the MSE changes exhibited by the DGDTA-AL, DGDTA-CL, baseline 1 and baseline 2 models on Davis and KIBA at 200 and 500 epochs. Blue and green represent our proposed models with faster decreasing trends. The results demonstrate the more significant improvement yielded by the dynamic GAT in terms of predicting DTA.
<fig id="Fig6"><label>Fig. 6</label><caption><p>MSE trend</p></caption><graphic xlink:href="12859_2023_5497_Fig6_HTML" id="d32e2962"/></fig></p>
    </sec>
    <sec id="Sec12">
      <title>Example of a realistic drug–target combination</title>
      <p id="Par40">To further demonstrate the validity of the proposed method, this paper gives an example to show the 3D model produced for a tested sample in reality. As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>, the targeted drug (sunitinib) inhibits receptor tyrosine kinases (RTKs), where certain receptor tyrosine kinases are involved in tumour growth, pathological blood vessel formation and tumour metastasis. In biological and cytometric assays, sunitinib has been shown to inhibit tumour growth, cause tumour regression and inhibit tumour metastasis. In this paper, the bound small drug molecules are scaled up on the right side, and the drug and its binding target correspond to the drug ‘DB5329102’ and the target ‘ITK’ in the test set, respectively; this is done to verify the validity and practicality of the model proposed in this paper in practical applications through known drug–target binding examples.<fig id="Fig7"><label>Fig. 7</label><caption><p>Visualization of the binding of a drug ‘DB5329102’ and a target ‘ITK’</p></caption><graphic xlink:href="12859_2023_5497_Fig7_HTML" id="d32e2976"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec13" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par41">In this paper, DGDTA is proposed based on the dynamic graph attention model and is divided into two versions, DGDTA-AL and DGDTA-CL, to predict the affinity values between drugs and proteins. Ablation experiments are performed on the Davis and KIBA datasets, and the proposed approach is compared with the DTA models that are popular today. The experimental results show that DGDTA can achieve better prediction performance and demonstrate that the dynamic graph attention model can extract more comprehensive feature representations from molecular drug maps.</p>
  </sec>
  <sec id="Sec14" sec-type="conclusion">
    <title>Conclusions</title>
    <p id="Par42">DGDTA can effectively predict DTA via deep learning, and it can obtain high CI and MSE metrics on experimental datasets, but it still has shortcomings. First, while dynamic graph attention models attain good prediction performance, they also require increased prediction time and computational cost. Second, drugs and proteins have very complex spatial structures, and much characteristic drug and protein information is lost in one-dimensional sequences.</p>
    <p id="Par43">In the future, further consideration will be given to fusing other characteristic drug information, such as their side effects, physicochemical properties, and deep structures. This will contribute to improving the performance of drug–target binding prediction models from various aspects.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>DGDTA</term>
        <def>
          <p id="Par4">Dynamic graph DTA</p>
        </def>
      </def-item>
      <def-item>
        <term>DTA</term>
        <def>
          <p id="Par5">Drug–target binding affinity</p>
        </def>
      </def-item>
      <def-item>
        <term>GAT</term>
        <def>
          <p id="Par6">Graph attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>Bi-LSTM</term>
        <def>
          <p id="Par7">Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>SMILES</term>
        <def>
          <p id="Par8">Simplified molecular input line entry system</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par9">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>Bi-GRU</term>
        <def>
          <p id="Par10">Bidirectional gated recurrent unit</p>
        </def>
      </def-item>
      <def-item>
        <term>GAN</term>
        <def>
          <p id="Par11">Generative adversarial network</p>
        </def>
      </def-item>
      <def-item>
        <term>GATv2</term>
        <def>
          <p id="Par12">Dynamic graph attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>RTK</term>
        <def>
          <p id="Par13">Receptor tyrosine kinases</p>
        </def>
      </def-item>
      <def-item>
        <term>GCN</term>
        <def>
          <p id="Par14">Graph convolutional network</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>HZ, HH and JL participated in the design of the study and the analysis of the experimental results. HH and XL performed the implementation, prepared the tables and figures, and summarized the results of the study. ZW and JW checked the format of the manuscript. All authors have read and approved the final manuscript for publication.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The authors declare that they have no competing interests. This work has been supported in part by the National Natural Science Foundation of China under Grant No. 61972134, Young Elite Teachers in Henan Province No. 2020GGJS050, Doctor Foundation of Henan Polytechnic University under Grant No. B2018-36, Innovative and Scientific Research Team of Henan Polytechnic University under No. T2021-3, Innovation Project of New Generation Information Technology under No. 2021ITA09021.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The Davis and KIBA data can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/thinng/GraphDTA/tree/master">https://github.com/thinng/GraphDTA/tree/master</ext-link>. The software and sample result as part of this project are readily avail- able from GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/DGDTA">https://github.com/luojunwei/DGDTA</ext-link>. Project name: DGDTA. Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/DGDTA">https://github.com/luojunwei/DGDTA</ext-link>. Operating system(s): Linux or other unix-like systems. Programming language: python 3.x. License: GNU GPL v3. Any restrictions to use by non-academics: license needed.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar2">
      <title>Ethics approval and consent to participate</title>
      <p id="Par44">Not applicable.</p>
    </notes>
    <notes id="FPar3">
      <title>Consent for publication</title>
      <p id="Par45">Not applicable.</p>
    </notes>
    <notes id="FPar1" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par46">The authors declare no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Strittmatter</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <article-title>Old drugs learn new tricks</article-title>
        <source>Nat Med</source>
        <year>2014</year>
        <volume>20</volume>
        <issue>6</issue>
        <fpage>590</fpage>
        <pub-id pub-id-type="doi">10.1038/nm.3595</pub-id>
        <?supplied-pmid 24901567?>
        <pub-id pub-id-type="pmid">24901567</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>Affinity2Vec</collab>
        </person-group>
        <article-title>drug–target binding affinity prediction through representation learning, graph mining, and machine learning</article-title>
        <source>Sci Rep</source>
        <year>2022</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">34992227</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ilyin</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Homsi</surname>
            <given-names>UA</given-names>
          </name>
          <name>
            <surname>Coveney</surname>
            <given-names>PV</given-names>
          </name>
        </person-group>
        <article-title>The effect of protein mutations on drug binding suggests ensuing personalised drug selection</article-title>
        <source>Sci Rep</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>13452</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-021-92785-w</pub-id>
        <?supplied-pmid 34188094?>
        <pub-id pub-id-type="pmid">34188094</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ashburn</surname>
            <given-names>TT</given-names>
          </name>
          <name>
            <surname>Thor</surname>
            <given-names>KB</given-names>
          </name>
        </person-group>
        <article-title>Drug repositioning: identifying and developing new uses for existing drugs</article-title>
        <source>Nat Rev Drug Discov</source>
        <year>2004</year>
        <volume>3</volume>
        <issue>8</issue>
        <fpage>673</fpage>
        <lpage>683</lpage>
        <pub-id pub-id-type="doi">10.1038/nrd1468</pub-id>
        <?supplied-pmid 15286734?>
        <pub-id pub-id-type="pmid">15286734</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Boosting compound-protein interaction prediction by deep learning</article-title>
        <source>Methods Companion Methods Enzymol</source>
        <year>2016</year>
        <volume>110</volume>
        <fpage>64</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ymeth.2016.06.024</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hua</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>XJ</given-names>
          </name>
          <name>
            <surname>Kittler</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <article-title>CPInformer for efficient and robust compound–protein interaction prediction</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2022</year>
        <volume>20</volume>
        <fpage>285</fpage>
        <lpage>296</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thomas</surname>
            <given-names>KL</given-names>
          </name>
        </person-group>
        <article-title>Predicting new molecular targets for known drugs</article-title>
        <source>Nature</source>
        <year>2009</year>
        <volume>462</volume>
        <issue>7270</issue>
        <fpage>175</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1038/nature08506</pub-id>
        <?supplied-pmid 19881490?>
        <pub-id pub-id-type="pmid">19881490</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hakime</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Arzucan</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Elif</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>DeepDTA: deep drug–target binding affinity prediction</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>17</issue>
        <fpage>i821</fpage>
        <lpage>i829</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty593</pub-id>
        <pub-id pub-id-type="pmid">30423097</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krisztian</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ladislav</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Júlia</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Modified linear regression predicts drug–target interactions accurately</article-title>
        <source>PLoS ONE</source>
        <year>2020</year>
        <volume>15</volume>
        <issue>4</issue>
        <fpage>e0230726</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0230726</pub-id>
        <pub-id pub-id-type="pmid">32251481</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cichonska</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ravikumar</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Parri</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Timonen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pahikkala</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Airola</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wennerberg</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Rousu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Computational-experimental approach to drug–target interaction mapping: a case study on kinase inhibitors</article-title>
        <source>PLoS Comput Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <issue>8</issue>
        <fpage>e1005678</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005678</pub-id>
        <?supplied-pmid 28787438?>
        <pub-id pub-id-type="pmid">28787438</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>SimBoost: a read-across approach for drug–target interaction prediction using gradient boosting machines</article-title>
        <source>J. Cheminform.</source>
        <year>2016</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <lpage>14</lpage>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>YB</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>HC</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>ZH</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>A deep learning-based method for drug–target interaction prediction based on long short-term memory neural network</article-title>
        <source>BMC Med Inf Decis Mak</source>
        <year>2020</year>
        <volume>20</volume>
        <issue>Suppl 2</issue>
        <fpage>49</fpage>
        <pub-id pub-id-type="doi">10.1186/s12911-020-1052-0</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Feng Q, Dueva E, Cherkasov A, Ester M. PADME: a deep learning-based framework for drug–target interaction prediction. 2018.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Szwajda</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shakyawar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Making sense of large-scale kinase inhibitor bioactivity data sets: a comparative and integrative analysis</article-title>
        <source>J Chem Inf Model</source>
        <year>2014</year>
        <volume>54</volume>
        <issue>3</issue>
        <fpage>735</fpage>
        <lpage>743</lpage>
        <pub-id pub-id-type="doi">10.1021/ci400709d</pub-id>
        <?supplied-pmid 24521231?>
        <pub-id pub-id-type="pmid">24521231</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cer RZ</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Mudunuri U</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Stephens R</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lebeda FJ</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>IC50-to-Ki: a web-based tool for converting IC50 to Ki values for inhibitors of enzyme activity and ligand binding</article-title>
        <source>Nucleic Acids Res</source>
        <year>2009</year>
        <volume>37</volume>
        <issue>Web Server issue</issue>
        <fpage>W441</fpage>
        <lpage>445</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkp253</pub-id>
        <?supplied-pmid 19395593?>
        <pub-id pub-id-type="pmid">19395593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cichonska</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pahikkala</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Szedmak</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Julkunen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Airola</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Heinonen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Rousu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Learning with multiple pairwise kernels for drug bioactivity prediction</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>509</fpage>
        <lpage>518</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty277</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Öztürk H, Ozkirimli E, Özgür A. WideDTA: prediction of drug–target binding affinity. 2019.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Shin B, Park S, Kang K, Ho JC. Self-attention based molecule representation for predicting drug–target interaction. In: Machine learning for healthcare conference: 2019. PMLR: p. 230–248.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Lin X. DeepGS: deep representation learning of graphs and sequences for drug–target binding affinity prediction. 2020.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Velikovi P, Cucurull G, Casanova A, Romero A, Liò P, Bengio Y. Graph attention networks. 2017.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Cho K, Merrienboer BV, Gulcehre C, Bahdanau D, Bougares F, Schwenk H, Bengio Y. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1406.1078">arXiv:1406.1078</ext-link>. 2014.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Qiu Z, Jiao Q, Wang Y, Chen C, Zhu D, Cui X. rzMLP-DTA: gMLP network with ReZero for sequence-based drug–target affinity prediction. In: 2021 IEEE international conference on bioinformatics and biomedicine (BIBM): 2021. IEEE. p. 308–313.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Kao P-Y, Kao S-M, Huang N-L, Lin Y-C. Toward drug–target interaction prediction via ensemble modeling and transfer learning. In: 2021 IEEE international conference on bioinformatics and biomedicine (BIBM): 2021. IEEE. p. 2384–2391.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lingling</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Junjie</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Jun</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>GANsDTA: predicting drug–target binding affinity using GANs</article-title>
        <source>Front Genet</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>1243</fpage>
        <pub-id pub-id-type="pmid">31993067</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goodfellow</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Pouget-Abadie</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Mirza</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Warde-Farley</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ozair</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Generative adversarial networks</article-title>
        <source>Commun ACM</source>
        <year>2020</year>
        <volume>63</volume>
        <issue>11</issue>
        <fpage>139</fpage>
        <lpage>44</lpage>
        <pub-id pub-id-type="doi">10.1145/3422622</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Quinn</surname>
            <given-names>TP</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Venkatesh</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>GraphDTA: predicting drug–target binding affinity with graph neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>37</volume>
        <fpage>1140</fpage>
        <lpage>1147</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa921</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>1735</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <?supplied-pmid 9377276?>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>MI</given-names>
          </name>
          <name>
            <surname>Hunt</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Herrgard</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ciceri</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wodicka</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Pallares</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Hocker</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Treiber</surname>
            <given-names>DK</given-names>
          </name>
          <name>
            <surname>Zarrinkar</surname>
            <given-names>PP</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive analysis of kinase inhibitor selectivity</article-title>
        <source>Nat Biotechnol</source>
        <year>2011</year>
        <volume>29</volume>
        <issue>11</issue>
        <fpage>1046</fpage>
        <lpage>51</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.1990</pub-id>
        <?supplied-pmid 22037378?>
        <pub-id pub-id-type="pmid">22037378</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weininger</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules</article-title>
        <source>J Chem Inform Comput Sci</source>
        <year>1988</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>31</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1021/ci00057a005</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Brody S, Alon U, Yahav E. How attentive are graph attention networks? 2021.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Ramsundar B. Deep learning for the life sciences: applying deep learning to genomics, microscopy, drug discovery, and more. O’Reilly Media, Inc. 2019.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mithat</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Glenn</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Concordance probability and discriminatory power in proportional hazards regression</article-title>
        <source>Biometrika</source>
        <year>2005</year>
        <volume>92</volume>
        <issue>4</issue>
        <fpage>965</fpage>
        <lpage>70</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/92.4.965</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Mukherjee S, Ghosh M, Basuchowdhuri P. Deep graph convolutional network and LSTM based approach for predicting drug–target binding affinity. 2022.</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yuni</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xiangru</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yujie</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xuedong</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Dezhong</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Deep drug–target binding affinity prediction with multiple attention blocks</article-title>
        <source>Brief. Bioinform.</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>5</issue>
        <fpage>bbab117</fpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbab117</pub-id>
        <pub-id pub-id-type="pmid">33866349</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Karim</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Parvin</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Antti</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Massoud</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ghasemi</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Ali</surname>
            <given-names>MN</given-names>
          </name>
        </person-group>
        <article-title>DeepCDA: deep cross-domain compound-proteinaffinity prediction through LSTM and convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>4633</fpage>
        <lpage>4642</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa544</pub-id>
        <pub-id pub-id-type="pmid">32462178</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10543834</article-id>
    <article-id pub-id-type="pmid">37777712</article-id>
    <article-id pub-id-type="publisher-id">5497</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-023-05497-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DGDTA: dynamic graph attention network for predicting drug–target binding affinity</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhai</surname>
          <given-names>Haixia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hou</surname>
          <given-names>Hongli</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Luo</surname>
          <given-names>Junwei</given-names>
        </name>
        <address>
          <email>luojunwei@hpu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Xiaoyan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Zhengjiang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Junfeng</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05vr1c885</institution-id><institution-id institution-id-type="GRID">grid.412097.9</institution-id><institution-id institution-id-type="ISNI">0000 0000 8645 6375</institution-id><institution>School of Software, </institution><institution>Henan Polytechnic University, </institution></institution-wrap>Jiaozuo, 454003 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>9</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>30</day>
      <month>9</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>24</volume>
    <elocation-id>367</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>5</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>23</day>
        <month>9</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Obtaining accurate drug–target binding affinity (DTA) information is significant for drug discovery and drug repositioning. Although some methods have been proposed for predicting DTA, the features of proteins and drugs still need to be further analyzed. Recently, deep learning has been successfully used in many fields. Hence, designing a more effective deep learning method for predicting DTA remains attractive.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Dynamic graph DTA (DGDTA), which uses a dynamic graph attention network combined with a bidirectional long short-term memory (Bi-LSTM) network to predict DTA is proposed in this paper. DGDTA adopts drug compound as input according to its corresponding simplified molecular input line entry system (SMILES) and protein amino acid sequence. First, each drug is considered a graph of interactions between atoms and edges, and dynamic attention scores are used to consider which atoms and edges in the drug are most important for predicting DTA. Then, Bi-LSTM is used to better extract the contextual information features of protein amino acid sequences. Finally, after combining the obtained drug and protein feature vectors, the DTA is predicted by a fully connected layer. The source code is available from GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/DGDTA">https://github.com/luojunwei/DGDTA</ext-link>.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">The experimental results show that DGDTA can predict DTA more accurately than some other methods.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Drug–target binding affinity</kwd>
      <kwd>Dynamic graph attention network</kwd>
      <kwd>Long short-term memory</kwd>
      <kwd>Drug discovery</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Innovative and Scientific Research Team of Henan Polytechnic University</institution>
        </funding-source>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <award-id>T2021-3</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zhai</surname>
            <given-names>Haixia</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Xiaoyan</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Zhengjiang</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Junfeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Innovation Project of New Generation Information Technology</institution>
        </funding-source>
        <award-id>2021ITA09021</award-id>
        <award-id>2021ITA09021</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zhai</surname>
            <given-names>Haixia</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61972134</award-id>
        <award-id>61972134</award-id>
        <principal-award-recipient>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Junfeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Young Elite Teachers in Henan Province</institution>
        </funding-source>
        <award-id>2020GGJS050</award-id>
        <principal-award-recipient>
          <name>
            <surname>Luo</surname>
            <given-names>Junwei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Doctor Foundation of Henan Polytechnic University</institution>
        </funding-source>
        <award-id>B2018-36</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par15">Drug–target interaction (DTI) prediction is a critical task in drug discovery and drug repositioning [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Structural changes to a drug can significantly alter its binding affinity with proteins [<xref ref-type="bibr" rid="CR3">3</xref>], making it important to predict whether a drug can bind to a specific protein. However, the traditional high-throughput screening experiments used to detect this activity are expensive and time-consuming [<xref ref-type="bibr" rid="CR4">4</xref>]. Therefore, computing methods for DTI prediction have become popular and effective [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p id="Par16">DTI calculation methods focus on binary classification [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR7">7</xref>], and the main goal is to determine whether a drug and a target interact with each other [<xref ref-type="bibr" rid="CR8">8</xref>]. However, the assumed binding strength values of the given protein and the drug compound are continuous and referred to as their binding affinity. The drug–target pair prediction task is described as an affinity prediction problem [<xref ref-type="bibr" rid="CR8">8</xref>] in which, the binding affinity score is directly used, thus creating a more realistic experiment. In addition, regression-based models are more advantageous in approximating the strength of DTIs [<xref ref-type="bibr" rid="CR9">9</xref>], making them more conducive to the discovery of new drug compounds in the limited drug research space.</p>
    <p id="Par17">Recently, some methods [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>] for predicting drug–target affinity (DTA) have been developed. SimBoost [<xref ref-type="bibr" rid="CR11">11</xref>] enhances the performance of learning-based methods by extracting features from drugs, targets, and drug–target pairs and providing them to gradient-enhanced supervised learning methods. Affinity is characterized by an inhibition constant (<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{i}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq1.gif"/></alternatives></inline-formula>), dissociation constant (<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}_{d}$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mi>K</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq2.gif"/></alternatives></inline-formula>), changes in free energy measures (<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta G$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>G</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq3.gif"/></alternatives></inline-formula>,<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta H$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq4.gif"/></alternatives></inline-formula>), half-maximal inhibition constant (<inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I{C}_{50}$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi>I</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>50</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq5.gif"/></alternatives></inline-formula>) [<xref ref-type="bibr" rid="CR12">12</xref>], half-maximal activity concentration (<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A{C}_{50}$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>50</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq6.gif"/></alternatives></inline-formula>) [<xref ref-type="bibr" rid="CR13">13</xref>], KIBA score [<xref ref-type="bibr" rid="CR14">14</xref>] and scoring. Stronger affinity readings indicate greater DTIs [<xref ref-type="bibr" rid="CR15">15</xref>]. In the KronRLS [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR16">16</xref>] model, the Kronecker products of a drug and target are constructed by drug and protein pairs to calculate the kernel K of the pairs, which is entered into a regularized least-squares regression model (RLS) to predict the binding affinity.</p>
    <p id="Par18">With the success of deep learning, various deep networks have been used for DTA prediction [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR13">13</xref>], and have achieved better performance than machine learning. Some prediction methods are summarized in Table <xref rid="Tab1" ref-type="table">1</xref>. In the DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>] model, one-dimensional sequences of drugs and proteins are fed into a convolutional neural network (CNN) to extract the features of drugs and their targets through the (simplified molecular input line entry system) SMILES string representations of the drugs, and good results have been achieved. The PADME [<xref ref-type="bibr" rid="CR13">13</xref>] model combines molecular graph convolution of compounds and protein features and uses fixed-rule descriptors to represent proteins, improving the predictive performance of the model. The model is more scalable than traditional machine learning models. WideDTA [<xref ref-type="bibr" rid="CR17">17</xref>] builds on DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>] by representing drugs and proteins as words, learning more potential characteristics of drugs and proteins. However, since the convolution window of a CNN is fixed, this network is unable to extract the features of contextual information. To represent molecules in a natural way that preserves as much molecular structure information as possible, thus allowing the model to better learn the relevance of the underlying space, an increasing number of approaches are utilizing graph neural networks to predict DTA. MT-DTI [<xref ref-type="bibr" rid="CR18">18</xref>] introduces the attention mechanism in drug representation and takes more account of the correlation between different molecules, which improves the prediction performance of DTA and greatly increases the interpretability. In DeepGS [<xref ref-type="bibr" rid="CR19">19</xref>], the topological structure information of a drug is extracted by using a graph attention network (GAT) [<xref ref-type="bibr" rid="CR20">20</xref>], while the local chemical background of the drug is captured by using a bidirectional gated recurrent unit (Bi-GRU) [<xref ref-type="bibr" rid="CR21">21</xref>] and combined with the protein sequence features extracted by a CNN for prediction. rzMLP [<xref ref-type="bibr" rid="CR22">22</xref>] uses a gMLP model to aggregate input features with constant size, and uses a ReZero layer to smooth the training process for that block. The model is able to learn more complex global features while avoiding poor predictions due to a too deep model. EnsembleDLM [<xref ref-type="bibr" rid="CR23">23</xref>] aggregates predictions from multiple deep neural networks, not only obtaining better predictions, but also exploring how much data deep learning networks need to achieve better prediction performance. GANsDTA [<xref ref-type="bibr" rid="CR24">24</xref>] employs a generative adversarial network (GAN) [<xref ref-type="bibr" rid="CR25">25</xref>] to extract features of protein sequences and compound SMILES in an unsupervised manner. Because GAN’s feature extractor does not require labeled data, the model is able to accommodate unlabeled data for training. Because GAN’s feature extractor does not require labeled data, the model is able to accommodate unlabeled data for training. The model can use more datasets to learn protein and drug features, thus achieving correspondingly better feature representation and prediction performance. GraphDTA [<xref ref-type="bibr" rid="CR26">26</xref>] modelled drugs as molecular graphs with one-dimensional drug sequences, then put the graph into several graph network models and obtained deep learning models, which were excellent at the time. GraphDTA [<xref ref-type="bibr" rid="CR26">26</xref>] demonstrated that representing drugs as graphs can further improve the prediction capabilities of deep learning models in terms of DTA.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Prediction methods
</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">Published time</th><th align="left">Model</th><th align="left">Summary</th></tr></thead><tbody><tr><td align="left">SimBoost [<xref ref-type="bibr" rid="CR11">11</xref>]</td><td align="left">2016</td><td align="left">Gradient boosting regression trees</td><td align="left">Predicting continuous values of binding affinities of compounds and proteins</td></tr><tr><td align="left">KronRLS [<xref ref-type="bibr" rid="CR16">16</xref>]</td><td align="left">2018</td><td align="left">Multiple kernel learning</td><td align="left">The first method for time- and memory-efficient learning with multiple pairwise kernels</td></tr><tr><td align="left">DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td align="left">2018</td><td align="left">CNN</td><td align="left">Processing protein sequences and compound 1D representations using convolutional neural networks</td></tr><tr><td align="left">PADME [<xref ref-type="bibr" rid="CR13">13</xref>]</td><td align="left">2018</td><td align="left">DNN</td><td align="left">The first to combine Molecular Graph Convolution for compound featurization with protein descriptors</td></tr><tr><td align="left">WideDTA [<xref ref-type="bibr" rid="CR17">17</xref>]</td><td align="left">2019</td><td align="left">CNN</td><td align="left">Combining four different textual pieces of information related to proteins and ligands</td></tr><tr><td align="left">MT-DTI [<xref ref-type="bibr" rid="CR18">18</xref>]</td><td align="left">2019</td><td align="left">Transformers + CNN</td><td align="left">Proposing a new molecule representation based on the self-attention mechanism</td></tr><tr><td align="left">GANsDTA [<xref ref-type="bibr" rid="CR24">24</xref>]</td><td align="left">2019</td><td align="left">GAN + CNN</td><td align="left">Effectively learning valuable features from labeled and unlabeled data</td></tr><tr><td align="left">DeepGS [<xref ref-type="bibr" rid="CR19">19</xref>]</td><td align="left">2020</td><td align="left">GAT + Bi-GRU</td><td align="left">Extracting the topological information of the molecular map and the local chemical context of the drug</td></tr><tr><td align="left">rzMLP [<xref ref-type="bibr" rid="CR22">22</xref>]</td><td align="left">2021</td><td align="left">gMLP + ReZero</td><td align="left">Use MHM block for multiple protein and ligand representations and rzMLP block to aggregate concatenated protein-ligand pair representations</td></tr><tr><td align="left">EnsembelDLM [<xref ref-type="bibr" rid="CR23">23</xref>]</td><td align="left">2021</td><td align="left">Multiple deep networks</td><td align="left">Aggregating predictions from multiple deep neural networks</td></tr><tr><td align="left">GraphDTA [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td align="left">2021</td><td align="left">GIN + CNN</td><td align="left">Introducing multiple models of graph neural networks</td></tr></tbody></table></table-wrap></p>
    <p id="Par19">However, two problems remain that prevent accurate DTA. (1) The GAT model used by some contemporary methods is a restricted form of static attention, and the attention coefficient function of the nodes in the drug graph is monotonic, which leads to the inability to comprehensively extract drug features. (2) When processing protein sequences, the contextual association information of amino acid sequences is not acquired, and the protein association features are thus ignored.</p>
    <p id="Par20">To solve the above problem, this paper proposes a method named dynamic graph DTA (DGDTA). In DGDTA, each drug is considered a graph of interactions between atoms and edges, and a dynamic attention score is used to consider which atoms and edges in the drug graph play more critical roles in predicting DTA. Compared with static attention, DGDTA is able to extract a more comprehensive drug signature. To better obtain the contextual features of amino acid sequences in proteins, DGDTA introduces bidirectional long short-term memory (Bi-LSTM) [<xref ref-type="bibr" rid="CR27">27</xref>] to extract more comprehensive amino acid sequence features in combination with drugs. Through validations conducted on the Davis [<xref ref-type="bibr" rid="CR28">28</xref>] and KIBA [<xref ref-type="bibr" rid="CR14">14</xref>] datasets, DGDTA achieves better performance than the competing methods in terms of results. In this paper, a dynamic graph attention network example is given to further improve the representativeness and effectiveness of drug molecule maps. The experimental results demonstrate the effectiveness of DGDTA.
</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <p id="Par21">DGDTA is a method for predicting DTA based on a deep learning network, and its architecture (shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>), is divided into three main steps. (1) Obtaining drug features. DGDTA uses the SMILES [<xref ref-type="bibr" rid="CR29">29</xref>] as the drug compound input, and transforms the drug into a drug graph consisting of atoms and edges with reference to the natural properties of the drug. According to the literature, a two-layer graph network structure has better feature extraction performance. DGDTA uses a two-layer dynamic graph attention network (GATv2) [<xref ref-type="bibr" rid="CR30">30</xref>] and a combination of GATv2 and a graph convolutional network (GCN) to obtain drug graph features, and DGDTA is divided into two versions: DGDTA-AL and DGDTA-CL. (2) Extracting protein features. DGDTA uses a combination of Bi-LSTM and multilayer convolutional networks to obtain more comprehensive protein amino acid sequence information while considering the contextual relationships among the amino acid sequences. (3) Performing DTA prediction. The observed connections among drug features and protein features during extraction used to determine DTA via a fully connected layer. The details of DGDTA are described in the following parts.<fig id="Fig1"><label>Fig. 1</label><caption><p>General architecture of DGDTA</p></caption><graphic xlink:href="12859_2023_5497_Fig1_HTML" id="d32e656"/></fig></p>
    <sec id="Sec3">
      <title>Obtaining drug features</title>
      <p id="Par22">With the development of graph neural networks for DTA, many approaches have been presented. When using a graph to represent a drug, it is difficult to accurately extract graph features due to the complexity of drug graphs. DGDTA adopts a dynamic GAT to obtain drug features. Through SMILE code, drug’s atomic composition, and the valence charge number of atoms can be inferred, which can further judge drug information such as the number of hydrogen bonds, and then used for the drug’s feature representation in affinity prediction. To better extract drug features, DGDTA uses the SMILES [<xref ref-type="bibr" rid="CR29">29</xref>] sequences of drugs as inputs, and uses RDKit to extract the atoms and interactions from the SMILES sequences. Then, DGDTA constructs a graph for each drug based on its SMILES sequence. A drug graph is denoted as <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G=(V,E)$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq7.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V$$\end{document}</tex-math><mml:math id="M16"><mml:mi>V</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq8.gif"/></alternatives></inline-formula> is a node represented by a drug atom, and <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E$$\end{document}</tex-math><mml:math id="M18"><mml:mi>E</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq9.gif"/></alternatives></inline-formula> represents the set of edges between nodes. Each node is represented by an n-dimensional vector from DeepChem [<xref ref-type="bibr" rid="CR31">31</xref>]. This n-dimensional vector includes the atomic symbols, the number of adjacent hydrogen atoms, the number of adjacent atoms, the implicit valence of the atoms (implicit valence) and whether the bonds are aromatic. One node is represented as <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{d}=\left\{{\text{f}}_{1},{\text{f}}_{2},{\text{f}}_{3}\dots ,{\text{f}}_{n}\right\}$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mtext>f</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>f</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>f</mml:mtext><mml:mn>3</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mtext>f</mml:mtext><mml:mi>n</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq10.gif"/></alternatives></inline-formula>. By representing the atoms d of each drug as the vertices of the drug graph, the features <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\left\{{\text{d}}_{1},{\text{d}}_{2},{\text{d}}_{3}\dots ,{\text{d}}_{D}\right\}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mtext>d</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>d</mml:mtext><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>d</mml:mtext><mml:mn>3</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mtext>d</mml:mtext><mml:mi>D</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq11.gif"/></alternatives></inline-formula> of each drug are obtained. To obtain more information about the graph structure in n-dimensional space, this paper adopts a dynamic attention mechanism for the graph:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e\left({d}_{i},{d}_{j}\right)={a}^{T}LeakyReLU\left(W\left[{d}_{i}\parallel {d}_{j}\right]\right) \quad j\in {\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi><mml:mfenced close="]" open="["><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mspace width="1em"/><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e\left( {d_{i} ,d_{j} } \right)$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq12.gif"/></alternatives></inline-formula> denotes the importance of the features of neighbour node <inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M28"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq13.gif"/></alternatives></inline-formula> to node <inline-formula id="IEq14"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M30"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq14.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq15"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq15.gif"/></alternatives></inline-formula> represents the neighbours of node <inline-formula id="IEq16"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M34"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq16.gif"/></alternatives></inline-formula>, <inline-formula id="IEq17"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a\in {\mathbb{R}}^{{2d}^{{\prime }}}$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq17.gif"/></alternatives></inline-formula>, <inline-formula id="IEq18"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W\in {\mathbb{R}}^{{2d}^{{\prime }}\times d}$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq18.gif"/></alternatives></inline-formula> are learned, and II denotes vector concatenation. Utilizing the <inline-formula id="IEq19"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$softmax$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mi mathvariant="italic">softmax</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq19.gif"/></alternatives></inline-formula> function to normalize all neighbours, we can obtain the following attention function:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{ij}=softmax\left(e\left({d}_{i},{d}_{j}\right)\right)=\frac{exp\left(e\left({d}_{i},{d}_{j}\right)\right)}{{\sum }_{k\in {\mathcal{N}}_{\mathcalligra{i}}}exp\left(e\left({d}_{i},{d}_{k}\right)\right)}$$\end{document}</tex-math><mml:math id="M42" display="block"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par23">Combining Eqs. (<xref rid="Equ1" ref-type="disp-formula">1</xref>) and (<xref rid="Equ2" ref-type="disp-formula">2</xref>), the coefficients of attention are expressed as:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{ij}=\frac{{a}^{T}LeakyReLU\left(W\left[{d}_{i}\parallel {d}_{j}\right]\right)}{{\sum }_{k\in {\mathcal{N}}_{\mathcalligra{i}}}exp\left({a}^{T}LeakyReLU\left(W\left[{d}_{i}\parallel {d}_{j}\right]\right)\right)}$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi><mml:mfenced close="]" open="["><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi><mml:mfenced close="]" open="["><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par24">After integrating the feature information of the neighbouring nodes, we apply the nonlinear parameter <inline-formula id="IEq20"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M46"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq20.gif"/></alternatives></inline-formula>, to obtain the output features of each node:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{i}^{{\prime }}=\sigma \left({\sum }_{j\in {\mathcal{N}}_{\mathcalligra{i}}}{a}_{ij}W{d}_{j}\right)$$\end{document}</tex-math><mml:math id="M48" display="block"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mi>W</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par25">Nodes are represented as the weighted averages of their neighbouring feature vectors. To further solidify the learning process of dynamic graph self-attention and improve the learning effect, the attention is extended to multiheaded attention.<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{i}^{{\prime }{\prime }}=\sigma \left(\frac{1}{H}\sum _{h=1}^{H}{\sum }_{j\in {\mathcal{N}}_{\mathcalligra{i}}}{{a}_{ij}}^{h}{W}^{h}{d}_{j}\right)$$\end{document}</tex-math><mml:math id="M50" display="block"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mn>1</mml:mn><mml:mi>H</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>H</mml:mi></mml:munderover><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>h</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msup><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq21"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H$$\end{document}</tex-math><mml:math id="M52"><mml:mi>H</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq21.gif"/></alternatives></inline-formula> independent attention mechanisms connect the semantic feature vectors of the nodes through Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>), and obtain an updated drug feature representation <inline-formula id="IEq22"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{D}}^{\left(1\right)}=\left\{{\text{d}}_{1}^{\left(1\right)},{\text{d}}_{2}^{\left(1\right)},{\text{d}}_{3}^{\left(1\right)}\dots ,{\text{d}}_{D}^{\left(1\right)}\right\}$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:msup><mml:mrow><mml:mtext>D</mml:mtext></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq22.gif"/></alternatives></inline-formula>. Based on a combination of research and experiments, a two-layer graph network structure is able to obtain more accurate prediction results. First, the graph network in the second layer uses a dynamic graph neural network and obtains the drug feature representations <inline-formula id="IEq23"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{D}}^{\left(2\right)}=\left\{{\text{d}}_{1}^{\left(2\right)},{\text{d}}_{2}^{\left(2\right)},{\text{d}}_{3}^{\left(2\right)}\dots ,{\text{d}}_{D}^{\left(2\right)}\right\}$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:msup><mml:mrow><mml:mtext>D</mml:mtext></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq23.gif"/></alternatives></inline-formula>; this version is named DGDTA-AL. After many experiments and comparisons, the graph network in the second layer is replaced with a GCN, whose propagation rules are as follows:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{(l+1)}=\sigma \left({\stackrel{\sim}{D}}^{-\frac{1}{2}}\stackrel{\sim}{A}{\stackrel{\sim}{D}}^{-\frac{1}{2}}{H}^{\left(l\right)}{W}^{\left(l\right)}\right)$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>∼</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mover><mml:mi>A</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>∼</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq24"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{\left(l\right)}$$\end{document}</tex-math><mml:math id="M60"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq24.gif"/></alternatives></inline-formula> denotes the nodal feature matrix of <inline-formula id="IEq25"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${l}^{th}$$\end{document}</tex-math><mml:math id="M62"><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">th</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq25.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq26"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\stackrel{\sim}{A}=A+I$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq26.gif"/></alternatives></inline-formula>, <inline-formula id="IEq27"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A$$\end{document}</tex-math><mml:math id="M66"><mml:mi>A</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq27.gif"/></alternatives></inline-formula> is the adjacency matrix, <inline-formula id="IEq28"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I$$\end{document}</tex-math><mml:math id="M68"><mml:mi>I</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq28.gif"/></alternatives></inline-formula> is the unit matrix, <inline-formula id="IEq29"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\stackrel{\sim}{D}=D+I$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq29.gif"/></alternatives></inline-formula>, <inline-formula id="IEq30"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D$$\end{document}</tex-math><mml:math id="M72"><mml:mi>D</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq30.gif"/></alternatives></inline-formula> is the degree matrix, and <inline-formula id="IEq31"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W$$\end{document}</tex-math><mml:math id="M74"><mml:mi>W</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq31.gif"/></alternatives></inline-formula> is a trainable weight. A drug feature representation <inline-formula id="IEq32"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{D}}^{{\left(2\right)}^{{\prime }}}=\left\{{\text{d}}_{1}^{{\left(2\right)}^{{\prime }}},{\text{d}}_{2}^{{\left(2\right)}^{{\prime }}},{\text{d}}_{3}^{{\left(2\right)}^{{\prime }}}\dots ,{\text{d}}_{D}^{{\left(2\right)}^{{\prime }}}\right\}$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:msup><mml:mrow><mml:mtext>D</mml:mtext></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:msubsup></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq32.gif"/></alternatives></inline-formula> is obtained. The GCN is applied to the full graph via the Laplacian matrix, which captures the connectivity relationships between the graph nodes and updates the node features of the full graph. In this paper, this version is named DGDTA-CL. We use the rectified linear unit (<inline-formula id="IEq33"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ReLU$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mi mathvariant="italic">ReLU</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq33.gif"/></alternatives></inline-formula>) activation function after each layer and use global maximum pooling in the last layer to obtain the vector representation of the drug.</p>
    </sec>
    <sec id="Sec4">
      <title>Extracting protein features</title>
      <p id="Par26">A protein sequence is a string of ASCII characters represented as amino acids. In many methods, one-hot codes are used to represent drugs and proteins, as well as other biological sequences, such as DNA and RNA. We use one-hot encoding to represent the atoms of the drug and incorporate atomic properties for drug initialization. Because drug molecules are shorter and simpler in structure than proteins, we utilize one-hot encoding to expand the dimensionality of the drug’s representation. This enables model to capture specific information associated with each drug atom. For protein, in order to prevent feature singularity, we employ different approaches for the initialization. In this paper, we map each amino acid to a numerical value and represent one protein as a sequence of integers. And then an embedding layer is added to the sequence, where each character is represented by a 128-dimensional vector. For training purposes, the sequences are cut or padded to a fixed sequence with a length of 1000. If the sequence is short, it is padded with 0 values. In this paper, the embedding representation (<inline-formula id="IEq34"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{c}\in {\mathbb{R}}^{{\mathcalligra{d}}_{p}}$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mtext>c</mml:mtext><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mi mathvariant="script">d</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq34.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq35"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M82"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq35.gif"/></alternatives></inline-formula> is the dimensionality of the protein embedding) is a Bi-LSTM layer that captures the dependencies the characters in a sequence of length <inline-formula id="IEq36"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M84"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq36.gif"/></alternatives></inline-formula> (<inline-formula id="IEq37"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C=\left[{\text{c}}_{1},{c}_{2}\dots {\text{c}}_{n}\right]$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:msub><mml:mtext>c</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mtext>c</mml:mtext><mml:mi>n</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq37.gif"/></alternatives></inline-formula>). We obtain <inline-formula id="IEq38"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}\in {\mathbb{R}}^{{2\mathcalligra{d}}_{1}}$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="script">d</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq38.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq39"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{1}$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq39.gif"/></alternatives></inline-formula> denotes the number of output cells used in each LSTM cell.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow{{p}_{i}}= \overrightarrow{LSTM}({\text{c}}_{\text{i}},{p}_{i-1})$$\end{document}</tex-math><mml:math id="M92" display="block"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="italic">LSTM</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>c</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{p}_{i}}=\overleftarrow{LSTM}({c}_{i},{p}_{i+1})$$\end{document}</tex-math><mml:math id="M94" display="block"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="italic">LSTM</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{\text{i}}= \overrightarrow{{p}_{i}}\parallel \overleftarrow{{p}_{i}}$$\end{document}</tex-math><mml:math id="M96" display="block"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>i</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo stretchy="false">‖</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par27">The vector <inline-formula id="IEq40"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P$$\end{document}</tex-math><mml:math id="M98"><mml:mi>P</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq40.gif"/></alternatives></inline-formula> is composed of the output vectors generated by the Bi-LSTM; i.e., <inline-formula id="IEq41"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=\left[{p}_{1},{p}_{2}\dots {p}_{n}\right]$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq41.gif"/></alternatives></inline-formula>. Finally, we use a one-dimensional convolutional layer to learn different levels of abstract features to obtain a vector of protein sequences representations.</p>
    </sec>
    <sec id="Sec5">
      <title>Performing DTA prediction</title>
      <p id="Par28">The prediction layer connects the learned drug vector representation with the vector representation of the protein sequence. Then, they are used as inputs and the output <inline-formula id="IEq42"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y$$\end{document}</tex-math><mml:math id="M102"><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq42.gif"/></alternatives></inline-formula> is obtained from the fully connected layer.<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y={W}_{output}\left[D,P\right]+{b}_{output}$$\end{document}</tex-math><mml:math id="M104" display="block"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="["><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula> where <inline-formula id="IEq43"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{output}$$\end{document}</tex-math><mml:math id="M106"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq43.gif"/></alternatives></inline-formula> denotes the weight matrix of the fully connected layer and <inline-formula id="IEq44"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{output}$$\end{document}</tex-math><mml:math id="M108"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">output</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq44.gif"/></alternatives></inline-formula> denotes the bias of the fully connected layer.</p>
      <p id="Par29">We choose the mean square error (MSE) loss as the loss function, which has the advantage of a function curve that is smooth, continuous and derivable everywhere, making it convenient for use in the gradient descent algorithm. As the error decreases, the gradient also decreases, which is more conducive to convergence and more stable.<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MSE=\frac{1}{n}\sum _{i=1}^{n}{({Y}_{i}-{y}_{i})}^{2}$$\end{document}</tex-math><mml:math id="M110" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula> where <inline-formula id="IEq45"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Y}_{i}\in {\mathbb{R}}^{\text{B}}$$\end{document}</tex-math><mml:math id="M112"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mtext>B</mml:mtext></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq45.gif"/></alternatives></inline-formula>, <inline-formula id="IEq46"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{i}\in {\mathbb{R}}^{\text{B}}$$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mtext>B</mml:mtext></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq46.gif"/></alternatives></inline-formula> denotes the predicted affinity value between the <inline-formula id="IEq47"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M116"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq47.gif"/></alternatives></inline-formula>th sample and the label of the affinity value in the sample, and <inline-formula id="IEq48"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text{B}$$\end{document}</tex-math><mml:math id="M118"><mml:mtext>B</mml:mtext></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq48.gif"/></alternatives></inline-formula> denotes the batch size.</p>
    </sec>
    <sec id="Sec6">
      <title>Model training</title>
      <p id="Par30">DGDTA takes drug SMILES strings and protein amino acid sequences as inputs. In this paper, Python 3.9, PyTorch 1.12.1 and PyG2.1 are used to implement dynamic GAT and LSTM. In this paper, the number of layers in the graph neural network is set to 2, Bi-LSTM is applied, the number of hidden states is set to 10, and the dropout parameter is set to 0.2. Then, the proposed method is trained on the above dataset for 1000 epochs, and the adaptive moment estimation (Adam) optimizer is used with a learning rate of 0.0005. The devices that are used for the experiments are an Intel(R) Xeon(R) Platinum 8260 CPU @ 2.30 GHz and an NVIDIA GeForce RTX 3090 GPU.</p>
    </sec>
  </sec>
  <sec id="Sec7" sec-type="results">
    <title>Results</title>
    <p id="Par31">In this section, we present the dataset used, the evaluation metrics, an ablation study and the results of a comparison with state-of-the-art methods. This section also illustrates the advantage of the dynamic GAT and gives an example of a real drug–target combination.</p>
    <sec id="Sec8">
      <title>Dataset and evaluation metrics</title>
      <p id="Par32">We use the Davis [<xref ref-type="bibr" rid="CR28">28</xref>] and KIBA [<xref ref-type="bibr" rid="CR14">14</xref>] datasets to evaluate the performance of the method proposed in this paper. The numbers of drugs and targets in the dataset, and the sample sizes for training and testing during the experiments are shown in Table <xref rid="Tab2" ref-type="table">2</xref>. In this paper, the concordance index (CI; the larger the better) [<xref ref-type="bibr" rid="CR32">32</xref>] and MSE (the smaller the better) are also used as the main indicators for evaluating the performance of the tested models. In this paper, the GAT and GAT_GCN models are chosen as baseline1 and baseline2 of the ablation study, respectively.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Davis</th><th align="left">KIBA</th></tr></thead><tbody><tr><td align="left">Drugs</td><td align="left">72</td><td align="left">2116</td></tr><tr><td align="left">Targets</td><td align="left">442</td><td align="left">229</td></tr><tr><td align="left">Total samples</td><td align="left">30,056</td><td align="left">118,254</td></tr><tr><td align="left">Train samples</td><td align="left">25,046</td><td align="left">98,545</td></tr><tr><td align="left">Test samples</td><td align="left">5010</td><td align="left">19,709</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec9">
      <title>Ablation study</title>
      <p id="Par33">In the ablation study, we analyse the effectiveness of the innovative elements of our method. In this section, to be as fair as possible, we use the same training and testing sets as those employed by the baselines and the same evaluation metrics. In this paper, a dynamic graph neural network is incorporated into the drug graph, and Bi-LSTM is added to extract protein amino acid sequence features to further improve the model accuracy. The popular GRU model is added as a comparison method. GRU and LSTM are important variants of recurrent neural networks, and they have strong memory and long-distance dependence capturing ability when processing sequence data. GRU has higher computational efficiency with reduced parameter settings compared to LSTM, but this also leads to some loss of information at longer distances in some cases. In order to better capture the contextual association information of amino acid sequences and further prove the effectiveness of LSTM method, GRU is introduced as a comparison in the ablation study. And the results of the ablation study are shown in Figs. <xref rid="Fig2" ref-type="fig">2</xref> and <xref rid="Fig3" ref-type="fig">3</xref>.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Comparison between baseline1 and different models at 200 and 1000 epochs</p></caption><graphic xlink:href="12859_2023_5497_Fig2_HTML" id="d32e1999"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>Comparison between baseline2 and different models at 200 and 1000 epochs</p></caption><graphic xlink:href="12859_2023_5497_Fig3_HTML" id="d32e2006"/></fig></p>
      <p id="Par34">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows that on the Davis and KIBA datasets, the DTA prediction results obtained by Model-2 using the dynamic GAT achieve a higher CI and a smaller MSE than those of baseline 1 in the same number of epochs. Model-1 with the addition of Bi-LSTM method is also better than baseline1. Based on Model-2, Bi-LSTM is used to improve the ability to extract contextual protein amino acid sequence features. The evaluation score of Model-4 is improved further, while the prediction result is better than that of the GRU in Model-3 with the same parameters. Model-4 achieves the best results in the 200-epoch and 1000-epoch comparisons conducted on both datasets, and Model-4 is the DGDTA-AL method illustrated in 2.1. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, Model-8 obtains the highest CI and the lowest MSE in the comparison with baseline 2 over the same number of epochs; Model-8 is the DGDTA-CL method.</p>
      <p id="Par35">In this paper, the results obtained by different models in the ablation study are presented in Table <xref rid="Tab3" ref-type="table">3</xref>. On the Davis dataset, DGDTA-AL achieves the best results (in bold), reaching 0.899 and 0.225 CI and MSE values, respectively, which are improvements of 0.7% and 0.7% over those of baseline. DGDTA-CL achieves a CI of 0.902 and an MSE of 0.125 on the KIBA dataset, which are improvements of 1.1% and 1.4% over those of baseline 2, respectively. The results of the ablation study demonstrate the effectiveness of the innovative elements proposed in this paper.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Ablation study on the Davis and KIBA datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Methods</th><th align="left">GATv2</th><th align="left">GCN</th><th align="left">GRU</th><th align="left">LSTM</th><th align="left">CI</th><th align="left">MSE</th></tr></thead><tbody><tr><td align="left">Davis</td><td align="left">Baseline1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.892</td><td char="." align="char">0.232</td></tr><tr><td align="left"/><td align="left">Model-1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.893</td><td char="." align="char">0.230</td></tr><tr><td align="left"/><td align="left">Model-2</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.895</td><td char="." align="char">0.232</td></tr><tr><td align="left"/><td align="left">Model-3</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td char="." align="char">0.896</td><td char="." align="char">0.228</td></tr><tr><td align="left"/><td align="left">Model-4</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char"><bold>0.899</bold><sup><bold>*</bold></sup></td><td char="." align="char"><bold>0.225</bold></td></tr><tr><td align="left"/><td align="left">Baseline2</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.881</td><td char="." align="char">0.245</td></tr><tr><td align="left"/><td align="left">Model-5</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.886</td><td char="." align="char">0.241</td></tr><tr><td align="left"/><td align="left">Model-6</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.883</td><td char="." align="char">0.242</td></tr><tr><td align="left"/><td align="left">Model-7</td><td align="left">✓</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td char="." align="char">0.887</td><td char="." align="char">0.239</td></tr><tr><td align="left"/><td align="left">Model-8</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.889</td><td char="." align="char">0.237</td></tr><tr><td align="left">KIBA</td><td align="left">Baseline1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.866</td><td char="." align="char">0.179</td></tr><tr><td align="left"/><td align="left">Model-1</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.867</td><td char="." align="char">0.172</td></tr><tr><td align="left"/><td align="left">Model-2</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.869</td><td char="." align="char">0.175</td></tr><tr><td align="left"/><td align="left">Model-3</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td align="left"/><td char="." align="char">0.871</td><td char="." align="char">0.169</td></tr><tr><td align="left"/><td align="left">Model-4</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.878</td><td char="." align="char">0.162</td></tr><tr><td align="left"/><td align="left">Baseline2</td><td align="left">–</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.891</td><td char="." align="char">0.139</td></tr><tr><td align="left"/><td align="left">Model-5</td><td align="left"/><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char">0.896</td><td char="." align="char">0.131</td></tr><tr><td align="left"/><td align="left">Model-6</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">–</td><td char="." align="char">0.893</td><td char="." align="char">0.135</td></tr><tr><td align="left"/><td align="left">Model-7</td><td align="left">✓</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td char="." align="char">0.898</td><td char="." align="char">0.128</td></tr><tr><td align="left"/><td align="left">Model-8</td><td align="left">✓</td><td align="left">✓</td><td align="left">–</td><td align="left">✓</td><td char="." align="char"><bold>0.902</bold></td><td char="." align="char"><bold>0.125</bold></td></tr></tbody></table><table-wrap-foot><p>
*Bold values represent the best result</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec10">
      <title>Comparison with the state-of-the-art methods</title>
      <p id="Par36">In this section, Table <xref rid="Tab4" ref-type="table">4</xref> shows the experimental results obtained by DGDTA and the comparison methods. To be consistent with the ablation experiment in 3.2, we use the same datasets and evaluation metrics. Based on this, we added the <inline-formula id="IEq49"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M120"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq49.gif"/></alternatives></inline-formula> evaluation metric. As shown in Table <xref rid="Tab4" ref-type="table">4</xref>, DGDTA-AL is better than the mainstream DTA methods in terms of the CI, MSE and <inline-formula id="IEq50"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M122"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq50.gif"/></alternatives></inline-formula> on the Davis dataset. Compared with DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>], which has the best results among the comparison methods, the CI and MSE of the proposed approach are improved by 0.6% and 1.1%, respectively. Additionally, the CI and MSE are improved by 0.9% and 0.4%, respectively, over those of the excellent MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>] method. And, <inline-formula id="IEq51"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M124"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq51.gif"/></alternatives></inline-formula> reaches 0.707. As shown in Table <xref rid="Tab4" ref-type="table">4</xref>, DGDTA-CL achieves a more significant improvement in its results on the KIBA dataset. Compared with the DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>] method, DGDTA-CL attains 1.2% and 1.8% performance improvements in terms of the CI and MSE metrics, and 1.3% and 2.5% CI and MSE improvements are achieved over the MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>] method, respectively. And, <inline-formula id="IEq52"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${r}_{m}^{2}$$\end{document}</tex-math><mml:math id="M126"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq52.gif"/></alternatives></inline-formula> reaches 0.809. Figure <xref rid="Fig4" ref-type="fig">4</xref> plots the CI scores obtained by the methods in the table for both datasets to further demonstrate the performance improvement provided by the DGDTA method. The experimental results show that DGDTA is better than the comparative methods, and the use of a dynamic graph with attention to extract drug features and effective contextual protein information is significant for predicting DTA.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparison with the state-of-the-art methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Methods</th><th align="left">CI</th><th align="left">MSE</th><th align="left"><inline-formula id="IEq53"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\textbf{r}}_{\textbf{m}}^{2}$$\end{document}</tex-math><mml:math id="M128"><mml:msubsup><mml:mi mathvariant="bold">r</mml:mi><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq53.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left">Davis</td><td align="left">DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td char="." align="char">0.878</td><td char="." align="char">0.261</td><td char="." align="char">0.631</td></tr><tr><td align="left"/><td align="left">DeepCDA [<xref ref-type="bibr" rid="CR35">35</xref>]</td><td char="." align="char">0.891</td><td char="." align="char">0.248</td><td char="." align="char">0.652</td></tr><tr><td align="left"/><td align="left">MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>]</td><td char="." align="char">0.890</td><td char="." align="char">0.229</td><td char="." align="char">0.688</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.892</td><td char="." align="char">0.232</td><td char="." align="char">0.689</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT-GCN) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.881</td><td char="." align="char">0.245</td><td char="." align="char">0.667</td></tr><tr><td align="left"/><td align="left">CPInformer [<xref ref-type="bibr" rid="CR6">6</xref>]</td><td char="." align="char">0.874</td><td char="." align="char">0.277</td><td char="." align="char">0.621</td></tr><tr><td align="left"/><td align="left">DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>]</td><td char="." align="char">0.893</td><td char="." align="char">0.236</td><td char="." align="char">0.679</td></tr><tr><td align="left"/><td align="left">DGDTA-CL (ours)</td><td char="." align="char">0.889</td><td char="." align="char">0.237</td><td char="." align="char">0.672</td></tr><tr><td align="left"/><td align="left">DGDTA-AL (ours)</td><td char="." align="char"><bold>0.899</bold><sup><bold>*</bold></sup></td><td char="." align="char"><bold>0.225</bold></td><td char="." align="char"><bold>0.707</bold></td></tr><tr><td align="left">KIBA</td><td align="left">DeepDTA [<xref ref-type="bibr" rid="CR8">8</xref>]</td><td char="." align="char">0.863</td><td char="." align="char">0.194</td><td char="." align="char">0.673</td></tr><tr><td align="left"/><td align="left">DeepCDA [<xref ref-type="bibr" rid="CR35">35</xref>]</td><td char="." align="char">0.889</td><td char="." align="char">0.176</td><td char="." align="char">0.682</td></tr><tr><td align="left"/><td align="left">MATT-DTI [<xref ref-type="bibr" rid="CR34">34</xref>]</td><td char="." align="char">0.889</td><td char="." align="char">0.150</td><td char="." align="char">0.762</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.866</td><td char="." align="char">0.179</td><td char="." align="char">0.738</td></tr><tr><td align="left"/><td align="left">GraphDTA(GAT-GCN) [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td char="." align="char">0.891</td><td char="." align="char">0.139</td><td char="." align="char">0.789</td></tr><tr><td align="left"/><td align="left">CPInformer [<xref ref-type="bibr" rid="CR6">6</xref>]</td><td char="." align="char">0.867</td><td char="." align="char">0.183</td><td char="." align="char">0.678</td></tr><tr><td align="left"/><td align="left">DeepGLSTM [<xref ref-type="bibr" rid="CR33">33</xref>]</td><td char="." align="char">0.890</td><td char="." align="char">0.143</td><td char="." align="char">0.789</td></tr><tr><td align="left"/><td align="left">DGDTA-AL (ours)</td><td char="." align="char">0.881</td><td char="." align="char">0.162</td><td char="." align="char">0.762</td></tr><tr><td align="left"/><td align="left">DGDTA-CL (ours)</td><td char="." align="char"><bold>0.902</bold></td><td char="." align="char"><bold>0.125</bold></td><td char="." align="char"><bold>0.809</bold></td></tr></tbody></table><table-wrap-foot><p>*Bold values represent the best result</p></table-wrap-foot></table-wrap><fig id="Fig4"><label>Fig. 4</label><caption><p>CI comparison among the experimental methods on the Davis and KIBA datasets</p></caption><graphic xlink:href="12859_2023_5497_Fig4_HTML" id="d32e2789"/></fig></p>
    </sec>
    <sec id="Sec11">
      <title>Advantages of the DGDTA model</title>
      <p id="Par37">A dynamic GAT suggests that a traditional GAT is only a computationally constrained form of “static” attention: for any query node, the attention function is monotonic with respect to the key fraction [<xref ref-type="bibr" rid="CR30">30</xref>]. As shown in the GAT heatmap presented in Fig. <xref rid="Fig5" ref-type="fig">5</xref>, the ordering of the attention coefficients is global, and all queries focus primarily on the 7th key.<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e\left({d}_{i},{d}_{j}\right)=LeakyReLU\left({a}^{T}\left[W{d}_{i}\right]\parallel \left[W{d}_{j}\right]\right) j\in {\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M130" display="block"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mfenced close="]" open="["><mml:mi>W</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo stretchy="false">‖</mml:mo><mml:mfenced close="]" open="["><mml:mi>W</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:mrow></mml:math><graphic xlink:href="12859_2023_5497_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par38">Formula (<xref rid="Equ10" ref-type="disp-formula">10</xref>) is the method for calculating the attention coefficients in the GAT, indicating the importance of the feature of node <inline-formula id="IEq54"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M132"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq54.gif"/></alternatives></inline-formula> to node <inline-formula id="IEq55"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M134"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq55.gif"/></alternatives></inline-formula>. As <inline-formula id="IEq56"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{N}}_{\mathcalligra{i}}$$\end{document}</tex-math><mml:math id="M136"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mi mathvariant="script">i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq56.gif"/></alternatives></inline-formula> is limited, there exists <inline-formula id="IEq57"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M138"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq57.gif"/></alternatives></inline-formula> node <inline-formula id="IEq58"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${j}_{max}$$\end{document}</tex-math><mml:math id="M140"><mml:msub><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq58.gif"/></alternatives></inline-formula> where the attention distribution <inline-formula id="IEq59"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a$$\end{document}</tex-math><mml:math id="M142"><mml:mi>a</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq59.gif"/></alternatives></inline-formula> only calculates static attention from <inline-formula id="IEq60"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${j}_{max}$$\end{document}</tex-math><mml:math id="M144"><mml:msub><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5497_Article_IEq60.gif"/></alternatives></inline-formula> due to it being the maximum value. To overcome the monotonicity restriction of the key score, Formula (<xref rid="Equ12" ref-type="disp-formula">12</xref>) is transformed into Formula (<xref rid="Equ1" ref-type="disp-formula">1</xref>). This variant is more expressive than the GAT, as shown in the attention maps of GATv2 in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. Since static attention cannot have different correlations for different keys and different queries, if there is one key that has a higher attention score than the others, then no query can ignore the score of this key, which results in very limited static attention.<fig id="Fig5"><label>Fig. 5</label><caption><p>Attention coefficients of the GAT and GATv2</p></caption><graphic xlink:href="12859_2023_5497_Fig5_HTML" id="d32e2950"/></fig></p>
      <p id="Par39">Among the datasets, Davis contains 2457 positive samples and 27,599 negative samples, the total number of samples is small, and the label distribution in the dataset is unbalanced. KIBA has 22,729 positive samples and 95,525 negative samples, so it contains more samples than Davis, but most of the labels in KIBA are very concentrated, and the label distribution is relatively normal. These problems create barriers for the model in terms of affinity prediction. Dynamic graph attention pays different amounts of attention to different queries in the attention score, enabling it to better distinguish the similarities and differences between samples. It is more discriminative during drug graph extraction and alleviates the imbalance problem in the given dataset. Figure <xref rid="Fig6" ref-type="fig">6</xref> shows the MSE changes exhibited by the DGDTA-AL, DGDTA-CL, baseline 1 and baseline 2 models on Davis and KIBA at 200 and 500 epochs. Blue and green represent our proposed models with faster decreasing trends. The results demonstrate the more significant improvement yielded by the dynamic GAT in terms of predicting DTA.
<fig id="Fig6"><label>Fig. 6</label><caption><p>MSE trend</p></caption><graphic xlink:href="12859_2023_5497_Fig6_HTML" id="d32e2962"/></fig></p>
    </sec>
    <sec id="Sec12">
      <title>Example of a realistic drug–target combination</title>
      <p id="Par40">To further demonstrate the validity of the proposed method, this paper gives an example to show the 3D model produced for a tested sample in reality. As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>, the targeted drug (sunitinib) inhibits receptor tyrosine kinases (RTKs), where certain receptor tyrosine kinases are involved in tumour growth, pathological blood vessel formation and tumour metastasis. In biological and cytometric assays, sunitinib has been shown to inhibit tumour growth, cause tumour regression and inhibit tumour metastasis. In this paper, the bound small drug molecules are scaled up on the right side, and the drug and its binding target correspond to the drug ‘DB5329102’ and the target ‘ITK’ in the test set, respectively; this is done to verify the validity and practicality of the model proposed in this paper in practical applications through known drug–target binding examples.<fig id="Fig7"><label>Fig. 7</label><caption><p>Visualization of the binding of a drug ‘DB5329102’ and a target ‘ITK’</p></caption><graphic xlink:href="12859_2023_5497_Fig7_HTML" id="d32e2976"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec13" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par41">In this paper, DGDTA is proposed based on the dynamic graph attention model and is divided into two versions, DGDTA-AL and DGDTA-CL, to predict the affinity values between drugs and proteins. Ablation experiments are performed on the Davis and KIBA datasets, and the proposed approach is compared with the DTA models that are popular today. The experimental results show that DGDTA can achieve better prediction performance and demonstrate that the dynamic graph attention model can extract more comprehensive feature representations from molecular drug maps.</p>
  </sec>
  <sec id="Sec14" sec-type="conclusion">
    <title>Conclusions</title>
    <p id="Par42">DGDTA can effectively predict DTA via deep learning, and it can obtain high CI and MSE metrics on experimental datasets, but it still has shortcomings. First, while dynamic graph attention models attain good prediction performance, they also require increased prediction time and computational cost. Second, drugs and proteins have very complex spatial structures, and much characteristic drug and protein information is lost in one-dimensional sequences.</p>
    <p id="Par43">In the future, further consideration will be given to fusing other characteristic drug information, such as their side effects, physicochemical properties, and deep structures. This will contribute to improving the performance of drug–target binding prediction models from various aspects.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>DGDTA</term>
        <def>
          <p id="Par4">Dynamic graph DTA</p>
        </def>
      </def-item>
      <def-item>
        <term>DTA</term>
        <def>
          <p id="Par5">Drug–target binding affinity</p>
        </def>
      </def-item>
      <def-item>
        <term>GAT</term>
        <def>
          <p id="Par6">Graph attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>Bi-LSTM</term>
        <def>
          <p id="Par7">Bidirectional long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>SMILES</term>
        <def>
          <p id="Par8">Simplified molecular input line entry system</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par9">Convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>Bi-GRU</term>
        <def>
          <p id="Par10">Bidirectional gated recurrent unit</p>
        </def>
      </def-item>
      <def-item>
        <term>GAN</term>
        <def>
          <p id="Par11">Generative adversarial network</p>
        </def>
      </def-item>
      <def-item>
        <term>GATv2</term>
        <def>
          <p id="Par12">Dynamic graph attention network</p>
        </def>
      </def-item>
      <def-item>
        <term>RTK</term>
        <def>
          <p id="Par13">Receptor tyrosine kinases</p>
        </def>
      </def-item>
      <def-item>
        <term>GCN</term>
        <def>
          <p id="Par14">Graph convolutional network</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>HZ, HH and JL participated in the design of the study and the analysis of the experimental results. HH and XL performed the implementation, prepared the tables and figures, and summarized the results of the study. ZW and JW checked the format of the manuscript. All authors have read and approved the final manuscript for publication.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The authors declare that they have no competing interests. This work has been supported in part by the National Natural Science Foundation of China under Grant No. 61972134, Young Elite Teachers in Henan Province No. 2020GGJS050, Doctor Foundation of Henan Polytechnic University under Grant No. B2018-36, Innovative and Scientific Research Team of Henan Polytechnic University under No. T2021-3, Innovation Project of New Generation Information Technology under No. 2021ITA09021.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The Davis and KIBA data can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/thinng/GraphDTA/tree/master">https://github.com/thinng/GraphDTA/tree/master</ext-link>. The software and sample result as part of this project are readily avail- able from GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/DGDTA">https://github.com/luojunwei/DGDTA</ext-link>. Project name: DGDTA. Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/luojunwei/DGDTA">https://github.com/luojunwei/DGDTA</ext-link>. Operating system(s): Linux or other unix-like systems. Programming language: python 3.x. License: GNU GPL v3. Any restrictions to use by non-academics: license needed.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar2">
      <title>Ethics approval and consent to participate</title>
      <p id="Par44">Not applicable.</p>
    </notes>
    <notes id="FPar3">
      <title>Consent for publication</title>
      <p id="Par45">Not applicable.</p>
    </notes>
    <notes id="FPar1" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par46">The authors declare no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Strittmatter</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <article-title>Old drugs learn new tricks</article-title>
        <source>Nat Med</source>
        <year>2014</year>
        <volume>20</volume>
        <issue>6</issue>
        <fpage>590</fpage>
        <pub-id pub-id-type="doi">10.1038/nm.3595</pub-id>
        <?supplied-pmid 24901567?>
        <pub-id pub-id-type="pmid">24901567</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>Affinity2Vec</collab>
        </person-group>
        <article-title>drug–target binding affinity prediction through representation learning, graph mining, and machine learning</article-title>
        <source>Sci Rep</source>
        <year>2022</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">34992227</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ilyin</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Homsi</surname>
            <given-names>UA</given-names>
          </name>
          <name>
            <surname>Coveney</surname>
            <given-names>PV</given-names>
          </name>
        </person-group>
        <article-title>The effect of protein mutations on drug binding suggests ensuing personalised drug selection</article-title>
        <source>Sci Rep</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>13452</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-021-92785-w</pub-id>
        <?supplied-pmid 34188094?>
        <pub-id pub-id-type="pmid">34188094</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ashburn</surname>
            <given-names>TT</given-names>
          </name>
          <name>
            <surname>Thor</surname>
            <given-names>KB</given-names>
          </name>
        </person-group>
        <article-title>Drug repositioning: identifying and developing new uses for existing drugs</article-title>
        <source>Nat Rev Drug Discov</source>
        <year>2004</year>
        <volume>3</volume>
        <issue>8</issue>
        <fpage>673</fpage>
        <lpage>683</lpage>
        <pub-id pub-id-type="doi">10.1038/nrd1468</pub-id>
        <?supplied-pmid 15286734?>
        <pub-id pub-id-type="pmid">15286734</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Boosting compound-protein interaction prediction by deep learning</article-title>
        <source>Methods Companion Methods Enzymol</source>
        <year>2016</year>
        <volume>110</volume>
        <fpage>64</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ymeth.2016.06.024</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hua</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>XJ</given-names>
          </name>
          <name>
            <surname>Kittler</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <article-title>CPInformer for efficient and robust compound–protein interaction prediction</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2022</year>
        <volume>20</volume>
        <fpage>285</fpage>
        <lpage>296</lpage>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thomas</surname>
            <given-names>KL</given-names>
          </name>
        </person-group>
        <article-title>Predicting new molecular targets for known drugs</article-title>
        <source>Nature</source>
        <year>2009</year>
        <volume>462</volume>
        <issue>7270</issue>
        <fpage>175</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1038/nature08506</pub-id>
        <?supplied-pmid 19881490?>
        <pub-id pub-id-type="pmid">19881490</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hakime</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Arzucan</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Elif</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>DeepDTA: deep drug–target binding affinity prediction</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>17</issue>
        <fpage>i821</fpage>
        <lpage>i829</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty593</pub-id>
        <pub-id pub-id-type="pmid">30423097</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krisztian</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ladislav</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Júlia</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Modified linear regression predicts drug–target interactions accurately</article-title>
        <source>PLoS ONE</source>
        <year>2020</year>
        <volume>15</volume>
        <issue>4</issue>
        <fpage>e0230726</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0230726</pub-id>
        <pub-id pub-id-type="pmid">32251481</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cichonska</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ravikumar</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Parri</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Timonen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pahikkala</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Airola</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wennerberg</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Rousu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Computational-experimental approach to drug–target interaction mapping: a case study on kinase inhibitors</article-title>
        <source>PLoS Comput Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <issue>8</issue>
        <fpage>e1005678</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005678</pub-id>
        <?supplied-pmid 28787438?>
        <pub-id pub-id-type="pmid">28787438</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>SimBoost: a read-across approach for drug–target interaction prediction using gradient boosting machines</article-title>
        <source>J. Cheminform.</source>
        <year>2016</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <lpage>14</lpage>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>YB</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>HC</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>ZH</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>A deep learning-based method for drug–target interaction prediction based on long short-term memory neural network</article-title>
        <source>BMC Med Inf Decis Mak</source>
        <year>2020</year>
        <volume>20</volume>
        <issue>Suppl 2</issue>
        <fpage>49</fpage>
        <pub-id pub-id-type="doi">10.1186/s12911-020-1052-0</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Feng Q, Dueva E, Cherkasov A, Ester M. PADME: a deep learning-based framework for drug–target interaction prediction. 2018.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Szwajda</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shakyawar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Making sense of large-scale kinase inhibitor bioactivity data sets: a comparative and integrative analysis</article-title>
        <source>J Chem Inf Model</source>
        <year>2014</year>
        <volume>54</volume>
        <issue>3</issue>
        <fpage>735</fpage>
        <lpage>743</lpage>
        <pub-id pub-id-type="doi">10.1021/ci400709d</pub-id>
        <?supplied-pmid 24521231?>
        <pub-id pub-id-type="pmid">24521231</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cer RZ</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Mudunuri U</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Stephens R</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lebeda FJ</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>IC50-to-Ki: a web-based tool for converting IC50 to Ki values for inhibitors of enzyme activity and ligand binding</article-title>
        <source>Nucleic Acids Res</source>
        <year>2009</year>
        <volume>37</volume>
        <issue>Web Server issue</issue>
        <fpage>W441</fpage>
        <lpage>445</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkp253</pub-id>
        <?supplied-pmid 19395593?>
        <pub-id pub-id-type="pmid">19395593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cichonska</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pahikkala</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Szedmak</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Julkunen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Airola</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Heinonen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Aittokallio</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Rousu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Learning with multiple pairwise kernels for drug bioactivity prediction</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>509</fpage>
        <lpage>518</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty277</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Öztürk H, Ozkirimli E, Özgür A. WideDTA: prediction of drug–target binding affinity. 2019.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Shin B, Park S, Kang K, Ho JC. Self-attention based molecule representation for predicting drug–target interaction. In: Machine learning for healthcare conference: 2019. PMLR: p. 230–248.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Lin X. DeepGS: deep representation learning of graphs and sequences for drug–target binding affinity prediction. 2020.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Velikovi P, Cucurull G, Casanova A, Romero A, Liò P, Bengio Y. Graph attention networks. 2017.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Cho K, Merrienboer BV, Gulcehre C, Bahdanau D, Bougares F, Schwenk H, Bengio Y. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1406.1078">arXiv:1406.1078</ext-link>. 2014.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Qiu Z, Jiao Q, Wang Y, Chen C, Zhu D, Cui X. rzMLP-DTA: gMLP network with ReZero for sequence-based drug–target affinity prediction. In: 2021 IEEE international conference on bioinformatics and biomedicine (BIBM): 2021. IEEE. p. 308–313.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Kao P-Y, Kao S-M, Huang N-L, Lin Y-C. Toward drug–target interaction prediction via ensemble modeling and transfer learning. In: 2021 IEEE international conference on bioinformatics and biomedicine (BIBM): 2021. IEEE. p. 2384–2391.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lingling</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Junjie</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Jun</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>GANsDTA: predicting drug–target binding affinity using GANs</article-title>
        <source>Front Genet</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>1243</fpage>
        <pub-id pub-id-type="pmid">31993067</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goodfellow</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Pouget-Abadie</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Mirza</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Warde-Farley</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ozair</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Generative adversarial networks</article-title>
        <source>Commun ACM</source>
        <year>2020</year>
        <volume>63</volume>
        <issue>11</issue>
        <fpage>139</fpage>
        <lpage>44</lpage>
        <pub-id pub-id-type="doi">10.1145/3422622</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Quinn</surname>
            <given-names>TP</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Venkatesh</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>GraphDTA: predicting drug–target binding affinity with graph neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>37</volume>
        <fpage>1140</fpage>
        <lpage>1147</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa921</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>1735</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <?supplied-pmid 9377276?>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>MI</given-names>
          </name>
          <name>
            <surname>Hunt</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Herrgard</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ciceri</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wodicka</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Pallares</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Hocker</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Treiber</surname>
            <given-names>DK</given-names>
          </name>
          <name>
            <surname>Zarrinkar</surname>
            <given-names>PP</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive analysis of kinase inhibitor selectivity</article-title>
        <source>Nat Biotechnol</source>
        <year>2011</year>
        <volume>29</volume>
        <issue>11</issue>
        <fpage>1046</fpage>
        <lpage>51</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.1990</pub-id>
        <?supplied-pmid 22037378?>
        <pub-id pub-id-type="pmid">22037378</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weininger</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules</article-title>
        <source>J Chem Inform Comput Sci</source>
        <year>1988</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>31</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1021/ci00057a005</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Brody S, Alon U, Yahav E. How attentive are graph attention networks? 2021.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Ramsundar B. Deep learning for the life sciences: applying deep learning to genomics, microscopy, drug discovery, and more. O’Reilly Media, Inc. 2019.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mithat</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Glenn</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Concordance probability and discriminatory power in proportional hazards regression</article-title>
        <source>Biometrika</source>
        <year>2005</year>
        <volume>92</volume>
        <issue>4</issue>
        <fpage>965</fpage>
        <lpage>70</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/92.4.965</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Mukherjee S, Ghosh M, Basuchowdhuri P. Deep graph convolutional network and LSTM based approach for predicting drug–target binding affinity. 2022.</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yuni</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xiangru</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yujie</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Xuedong</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Dezhong</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Deep drug–target binding affinity prediction with multiple attention blocks</article-title>
        <source>Brief. Bioinform.</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>5</issue>
        <fpage>bbab117</fpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbab117</pub-id>
        <pub-id pub-id-type="pmid">33866349</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Karim</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Parvin</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Antti</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Massoud</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ghasemi</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Ali</surname>
            <given-names>MN</given-names>
          </name>
        </person-group>
        <article-title>DeepCDA: deep cross-domain compound-proteinaffinity prediction through LSTM and convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>4633</fpage>
        <lpage>4642</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa544</pub-id>
        <pub-id pub-id-type="pmid">32462178</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
