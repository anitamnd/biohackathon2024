<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Cell Neurosci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Cell Neurosci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Cell. Neurosci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Cellular Neuroscience</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5102</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8172593</article-id>
    <article-id pub-id-type="doi">10.3389/fncel.2021.681066</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Cellular Neuroscience</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Begonia—A Two-Photon Imaging Analysis Pipeline for Astrocytic Ca<sup>2+</sup> Signals</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Bjørnstad</surname>
          <given-names>Daniel M.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>†</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1017205/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Åbjørsbråten</surname>
          <given-names>Knut S.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>†</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1294123/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hennestad</surname>
          <given-names>Eivind</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cunen</surname>
          <given-names>Céline</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/834614/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hermansen</surname>
          <given-names>Gudmund Horn</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bojarskaite</surname>
          <given-names>Laura</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pettersen</surname>
          <given-names>Klas H.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/54279/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vervaeke</surname>
          <given-names>Koen</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Enger</surname>
          <given-names>Rune</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>GliaLab at the Letten Centre, Division of Anatomy, Department of Molecular Medicine, Institute of Basic Medical Sciences, University of Oslo</institution>, <addr-line>Oslo</addr-line>, <country>Norway</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Lab for Neural Computation, Division of Physiology, Department of Molecular Medicine, Institute of Basic Medical Sciences, University of Oslo</institution>, <addr-line>Oslo</addr-line>, <country>Norway</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Statistics and Data Science Group, Department of Mathematics, Faculty of Mathematics and Natural Sciences, University of Oslo</institution>, <addr-line>Oslo</addr-line>, <country>Norway</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Department of Neurology, Oslo University Hospital</institution>, <addr-line>Rikshospitalet, Oslo</addr-line>, <country>Norway</country></aff>
    <aff id="aff5"><sup>5</sup><institution>NORA—Norwegian Artificial Intelligence Research Consortium, Faculty of Mathematics and Natural Sciences, University of Oslo</institution>, <addr-line>Oslo</addr-line>, <country>Norway</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Yu-Wei Wu, Academia Sinica, Taiwan</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Bernd Kuhn, Okinawa Institute of Science and Technology Graduate University, Japan; Janelle M. P. Pakan, Otto von Guericke University Magdeburg, Germany</p>
      </fn>
      <corresp id="c001">*Correspondence: Rune Enger <email>rune.enger@medisin.uio.no</email></corresp>
      <fn fn-type="other" id="fn001">
        <p><sup>†</sup>These authors have contributed equally to this work and share first authorship</p>
      </fn>
      <fn fn-type="other" id="fn002">
        <p><bold>Specialty section</bold>: This article was submitted to Non-Neuronal Cells, a section of the journal Frontiers in Cellular Neuroscience</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>15</volume>
    <elocation-id>681066</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>3</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>4</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2021 Bjørnstad, Åbjørsbråten, Hennestad, Cunen, Hermansen, Bojarskaite, Pettersen, Vervaeke and Enger.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Bjørnstad, Åbjørsbråten, Hennestad, Cunen, Hermansen, Bojarskaite, Pettersen, Vervaeke and Enger</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Imaging the intact brain of awake behaving mice without the dampening effects of anesthesia, has revealed an exceedingly rich repertoire of astrocytic Ca<sup>2+</sup> signals. Analyzing and interpreting such complex signals pose many challenges. Traditional analyses of fluorescent changes typically rely on manually outlined static region-of-interests, but such analyses fail to capture the intricate spatiotemporal patterns of astrocytic Ca<sup>2+</sup> dynamics. Moreover, all astrocytic Ca<sup>2+</sup> imaging data obtained from awake behaving mice need to be interpreted in light of the complex behavioral patterns of the animal. Hence processing multimodal data, including animal behavior metrics, stimulation timings, and electrophysiological signals is needed to interpret astrocytic Ca<sup>2+</sup> signals. Managing and incorporating these data types into a coherent analysis pipeline is challenging and time-consuming, especially if research protocols change or new data types are added. Here, we introduce Begonia, a MATLAB-based data management and analysis toolbox tailored for the analyses of astrocytic Ca<sup>2+</sup> signals in conjunction with behavioral data. The analysis suite includes an automatic, event-based algorithm with few input parameters that can capture a high level of spatiotemporal complexity of astrocytic Ca<sup>2+</sup> signals. The toolbox enables the experimentalist to quantify astrocytic Ca<sup>2+</sup> signals in a precise and unbiased way and combine them with other types of time series data.</p>
    </abstract>
    <kwd-group>
      <kwd>two-photon (2P)</kwd>
      <kwd>image analysis</kwd>
      <kwd>calcium imaging</kwd>
      <kwd>ROA analysis</kwd>
      <kwd>astrocyte</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">Norges Forskningsråd<named-content content-type="fundref-id">10.13039/501100005416</named-content></funding-source>
        <award-id rid="cn001">249988, 240476, 262552</award-id>
      </award-group>
      <award-group>
        <funding-source id="cn002">Helse Sør-Øst RHF<named-content content-type="fundref-id">10.13039/501100006095</named-content></funding-source>
        <award-id rid="cn002">2016070</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="6"/>
      <table-count count="1"/>
      <equation-count count="19"/>
      <ref-count count="29"/>
      <page-count count="12"/>
      <word-count count="8788"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="introduction" id="s1">
    <title>Introduction</title>
    <p>Astrocytic Ca<sup>2+</sup> signals have been shown to play important roles in a wide range of physiological and pathophysiological brain processes (Cornell-Bell et al., <xref rid="B4" ref-type="bibr">1990</xref>; Rusakov et al., <xref rid="B16" ref-type="bibr">2011</xref>; Verkhratsky and Parpura, <xref rid="B25" ref-type="bibr">2013</xref>; Bazargani and Attwell, <xref rid="B2" ref-type="bibr">2016</xref>). Until recently, studies on astrocytic Ca<sup>2+</sup> signals were confined to <italic>in vitro</italic> experiments and <italic>in vivo</italic> experiments in anesthetized mice. With the development of genetically encoded Ca<sup>2+</sup> sensors and improvements in optical imaging, <italic>in vivo</italic> imaging without the dampening effects of anesthesia (Thrane et al., <xref rid="B24" ref-type="bibr">2012</xref>) in behaving animals has become possible (Srinivasan et al., <xref rid="B22" ref-type="bibr">2015</xref>; Enger et al., <xref rid="B9" ref-type="bibr">2017</xref>; Stobart et al., <xref rid="B23" ref-type="bibr">2018</xref>). This, in turn, has revealed an exceedingly rich palette of astrocytic Ca<sup>2+</sup> signals coupled to behavior, ranging from small, short-lived events in subcellular compartments to long-lasting, global activations affecting large swaths of the cortical mantle (Srinivasan et al., <xref rid="B22" ref-type="bibr">2015</xref>; Stobart et al., <xref rid="B23" ref-type="bibr">2018</xref>; Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>).</p>
    <p>High frame rates (e.g., ~30 Hz) are needed to appropriately capture short-lasting Ca<sup>2+</sup> signals and enable efficient movement correction of two-photon imaging data from awake mice (Pnevmatikakis and Giovannucci, <xref rid="B15" ref-type="bibr">2017</xref>; Stobart et al., <xref rid="B23" ref-type="bibr">2018</xref>). Moreover, to reliably quantify the relatively sparse astrocytic Ca<sup>2+</sup> signals in behavioral quiescence, long acquisition times are also warranted. For these reasons, two-photon microscopy data for a given project could amount to tens of terabytes of data, and an analysis pipeline for such datasets needs to be optimized for speed and performance to avoid unacceptably long processing times.</p>
    <p>Traditional analyses of astrocytic Ca<sup>2+</sup> signals typically comprise manual or semi-automatic segmentation of regions-of-interest (ROIs) overlying astrocytic somata and processes (Eilert-Olsen et al., <xref rid="B8" ref-type="bibr">2019</xref>; Semyanov et al., <xref rid="B20" ref-type="bibr">2020</xref>). Even though such analyses are appropriate and to some level sufficient to describe the relatively sparse astrocytic Ca<sup>2+</sup> activity in brain slices and the anesthetized brain, they are not adequate for capturing the true complexity of astrocytic Ca<sup>2+</sup> signals in the unanesthetized brain (Wang et al., <xref rid="B26" ref-type="bibr">2019</xref>; Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>; Semyanov et al., <xref rid="B20" ref-type="bibr">2020</xref>): first, ROI analyses do not capture the dynamic spatial extent of these signals, as astrocytic Ca<sup>2+</sup> signals can emerge from multiple point sources, merge, and spread throughout the gap junction coupled astrocyte syncytium (Semyanov, <xref rid="B19" ref-type="bibr">2019</xref>). Second, as fluorescence from an ROI is typically measured as the mean gray value of the pixels within that ROI per time unit, events affecting a small proportion of the segmented area will typically not reach the threshold for event detection. Third, a static ROI analysis fails to capture separate concurrent events occurring within a single defined area (Wang et al., <xref rid="B26" ref-type="bibr">2019</xref>; Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>). Lately, new algorithms have been proposed to appropriately address the dynamic nature of astrocytic Ca<sup>2+</sup> signaling (Srinivasan et al., <xref rid="B22" ref-type="bibr">2015</xref>; Barrett et al., <xref rid="B1" ref-type="bibr">2018</xref>; Wang et al., <xref rid="B26" ref-type="bibr">2019</xref>). One of these, the <italic>Astrocyte Quantitative Analysis</italic> (AQuA) algorithm, employs an event-based approach to detect astrocytic Ca<sup>2+</sup> signals (Wang et al., <xref rid="B26" ref-type="bibr">2019</xref>). AQuA has in our view prominently advanced the field of astroglial Ca<sup>2+</sup> signal analyses, especially by its efforts to describe how astroglial Ca<sup>2+</sup> signals dynamically change in time and space. Even so, AQuA is dependent on a wide range of tuning parameters, and the analysis pipeline is not optimized for high frame rate data (Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>).</p>
    <p>Another challenge with analyzing astrocytic Ca<sup>2+</sup> signaling data from unanesthetized awake–behaving mice is to properly align and interpret these in the context of rich animal behavior. Various time series data are acquired for studies in behaving animals that need to be integrated with astrocytic signaling. For example, locomotion and whisking activity are typically recorded. To properly collate and align such multimodal data is challenging as they are typically acquired by multiple recording devices with different sampling frequencies and data formats.</p>
    <p>Here, we present a MATLAB toolbox tailored to analyze astrocytic Ca<sup>2+</sup> signals from behaving animals in a timely manner. The toolbox comprises a data management pipeline from raw data to derived data in tables, is optimized for large datasets, and contains the following functions: (i) implementation of previously published image alignment algorithms (Pnevmatikakis and Giovannucci, <xref rid="B15" ref-type="bibr">2017</xref>); (ii) an automatic Ca<sup>2+</sup> signal analysis pipeline, the region-of-activity (ROA) method, that may be used without setting manual tuning parameters; (iii) an ROI segmentation graphical user interface that can combine hand-drawn ROIs with automatically detected Ca<sup>2+</sup> signals; (iv) easy integration with other time series data such as electrophysiological recordings or movement data; and (v) an output module that can export data as tables for statistical analyses, or as plots and figures. The toolbox is programmed in MATLAB with modularity and flexibility in mind, enabling quick creation of graphical user interfaces and workflows when new analyses need to be established.</p>
  </sec>
  <sec sec-type="materials and methods" id="s2">
    <title>Materials and Methods</title>
    <p>The Begonia toolbox comprises multiple graphical and programmatic tools placed on top of a framework for the storage of metadata and derived data from image recordings, and a set of abstract base classes that offer a common application programming interface (API) for accessing image data in a source agnostic manner.</p>
    <sec id="s2-1">
      <title>Metadata Storage With Data Locations</title>
      <p>We define metadata as all data connected to the recording and analysis of a two-photon microscopy experiment except the actual imaging data. We developed Begonia around a metadata storage strategy we call <italic>data locations</italic> which is facilitated by the DataLocation class. Data locations offer a way for the software provided by Begonia to easily store and retrieve metadata as processing and manual steps take place on imaging data.</p>
      <p>In simple terms, data locations are paths in the file directory that through the DataLocation class allow metadata variables to be associated with these paths. The system does not rely on a centralized database of any kind and does not enforce a strict schema of names and entities on the data being saved. Data locations by default store the metadata entries at the path they point to. A problem with using filesystem paths as identifiers is to keep track of the data if files and folders are moved. For this reason, data locations save a universal unique identifier (UUID) on first use so that data that are moved can be re-identified.</p>
      <p>The data location system supports several ways of storing and retrieving metadata through the use of keywords, with abstract access to these mechanisms through a generic API on the DataLocation objects. We provide two such methods, or <italic>engines</italic>: the on-path engine, and the off-path engine. The on-path engine is the default, and stores metadata in a .mat file adjacent to the imaging data. The off-path engine stores all the metadata in a separate directory chosen by the user. Using the on-path engine, data locations require no setup to attach additional data to the imaging data.</p>
    </sec>
    <sec id="s2-2">
      <title>Data Import, Management, and On-Demand Reading</title>
      <p>We offer an API for importing imaging data and metadata acquired by different microscopes into a standardized format. This is implemented through the TSeries class, which provides a gateway to use the functionality of Begonia, regardless of how the data are recorded. Begonia contains a +scantype namespace that contains classes that inherit from the TSeries class that can load multi-page TIFF files [an adaptation of the TIFFStack (Muir and Kampa, <xref rid="B12" ref-type="bibr">2014</xref>) library for faster loading and alternative matrix indexing], PrairieView (Bruker) time series, and TIFFs created in ScanImage (Vidrio Technologies). The imaging classes also inherit the DataLocation class, allowing new metadata to be associated directly with a particular recording and granting access to the data management system.</p>
      <p>We have frequently found that two-photon microscopy data from a single trial exceed the random-access memory size (RAM) on the analyst’s computer. Moreover, we often want to review specific moments without waiting to load the whole recording. To allow faster and improved loading, we convert large data to the Hierarchical Data Format 5 (HDF5) whenever possible. HDF5 allows data to be retrieved on-demand, utilizing only the memory needed for the operation in question and retrieving only a subset of the recording of interest.</p>
      <p>Analysts can use imported recordings directly in MATLAB. However, Begonia offers a data management tool, that lists recordings and displays associated metadata through the data location system (<xref ref-type="fig" rid="F1">Figure 1B</xref>). The tool offers multiple features such as filtering, processing, and plotting through simple drop-down menus and buttons. The data manager is built on a base class called Editor that allows programmers to quickly develop one-shot graphical user interfaces (GUIs) with customized visualization of data and metadata as well as buttons for project-specific processing functions. We find that GUIs and the DataLocation system enable an efficient and flexible analysis pipeline that provides non-expert programmers with easy access to a complex processing pipeline. The GUIs are particularly useful for performing manual steps of the analyses, such as marking anatomical features and reviewing the data quality of individual recordings. Manually generated metadata can be used by processing functions that subsequently can be executed directly or added to a processing queue from the data manager.</p>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Begonia workflow. <bold>(A)</bold> Acquisition of multi-modal data. Movement from a running wheel and surveillance video from an infrared-sensitive camera is typically recorded alongside two-photon imaging data. <bold>(B)</bold> Begonia provides an editor for project-specific manual tasks, data and metadata management, and manual ROI segmentation of the imaging data. <bold>(C)</bold> The region-of-activity (ROA) algorithm provides an automated or semi-automatic detection of astrocytic Ca<sup>2+</sup> signals in the field-of-view or inside manually segmented ROIs or groups of manually segmented ROIs. <bold>(D)</bold> MultiTable provides a way to collate, synchronize and segment time series traces from ROIs, ROA, and custom sources on demand.</p>
        </caption>
        <graphic xlink:href="fncel-15-681066-g0001"/>
      </fig>
    </sec>
    <sec id="s2-3">
      <title>Collation and Segmentation of Time Series Data</title>
      <p>Once data is processed, it is often necessary to combine them with other data types, like for instance recordings of locomotion and whisking. Such additional data are typically acquired on a different computer than the imaging data and are often of different acquisition rates, starting times, and data formats than the microscopy data. It is useful to plot or analyze all these multimodal data in a collated fashion. To facilitate this, Begonia implements a class called MultiTable and an associated API that can collect data from multiple sources and group them by a custom entity such as an experiment or trial identifier. In this way, all data from a single experiment are connected using a common entity.</p>
      <p>MultiTable is not a table of data, but a list of sources that provides data in a uniform tabular format on demand. It can additionally slice and resample the data based on user-given criteria. With this approach, the origin of the data can be hidden from the user and thus simplify the analysis. We provide sources for data locations out of the box, which simplifies adding data from ROI and ROA analyses. The sources must provide time information in addition to the data vectors themselves. With this requirement, analysts can resample and time-align MultiTable outputs. Additionally, all data provided to MultiTable can be added with time correction so that differences in starting time on different hardware can be compensated. The system provides a way to include any custom time series data alongside the data types provided by Begonia.</p>
      <p>We frequently need to extract time series data from various data sources around a time point or in a specified time interval. The MultiTable API allows such segmentation using MATLAB categorical arrays. For example, it may be desirable to extract fluorescence values and whisking activity around the transition from quiet wakefulness to running. In this case, the categorical array in the MultiTable (<xref ref-type="fig" rid="F1">Figure 1D</xref>) could contain the value “quiet wakefulness” in the time points where the mouse is still, and “running” when the mouse moves. MultiTable can then be asked to identify these transitions based on the categorical arrays and retrieve data from an interval relative to such a time point.</p>
    </sec>
    <sec id="s2-4">
      <title>ROI Manager</title>
      <p>In addition to metadata and data management features, Begonia provides a highly modular ROI management and time series viewer called ROI Manager. The software is designed to be extended for any type of markup a project might need, and to be a generic viewer for data loaded through Begonia.</p>
      <p>Architecturally, ROI Manager uses a central concept of <italic>Views</italic> for windows that display data, and <italic>Tools</italic> for windows that provide tools to edit the data. It is designed with a hybrid object and data-oriented design. Each piece of data loaded—primarily two-photon microscopy time series data—can have multiple views of the same imaging data simultaneously. In this way, imaging data from multiple channels may be viewed simultaneously in different windows. <italic>Views</italic> provide a data-oriented approach to communication between the modules of the ROI Manager (tools, rendering layers, and, interaction modes) by offering a set of <italic>key-value pairs</italic> (KVPs) for each <italic>View</italic> that can be read and written by any module and periodically checked. The KVPs have non-strict semantics, meaning modules can read and write any data they want to the <italic>Views</italic>. E.g., an ROI editing tool can write a table of ROIs to the key “roi_table,” and a tool for changing the colormap displayed can write these settings to a key called “channel_colormap,” while both can write to a key “channel” to set what channel in the multi-channel data is currently displayed. The modules handling the rendering of the data in the figure window similarly check if keys they are associated with are updated and then redraw the view of the data as needed.</p>
      <p>Tools and various modules can be set up to load in any combination the user wants, allowing the ROI Manager to take roles beyond managing ROIs. For instance, a project measuring vascular diameters and flow of red blood cells might warrant a Tool window for marking the vessel, in combination with visible ROIs. In its simplest form, ROI Manager is just an image sequence viewer with no Tools, and Begonia offers this as well to allow viewing any 3D MATLAB arrays.</p>
      <p>Begonia offers ROI signal extraction from ROIs in time series data through batch operations available in Data Manager. In addition, the ROIs from the ROI Manager may be used to filter the output of the ROA analysis to assign ROA activity to cells or subcellular structures.</p>
    </sec>
    <sec id="s2-5">
      <title>ROA Algorithm</title>
      <p>The ROA algorithm is a method that detects fluorescence signal events in a pixel-by-pixel fashion in two-photon microscopy time series data (<xref ref-type="fig" rid="F2">Figure 2</xref>). The raw fluorescence time series (<italic>F</italic>) of each pixel is transformed into a binary time series where the ones indicate events. These events correspond to fluorescence values which exceed a certain pixel-specific threshold <italic>τ<sub>i</sub></italic>. The threshold is a function of the baseline gray values and standard deviation of the noise. The algorithm is tailor-made for noisy, high frame rate (~30 Hz) recordings.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>The ROA algorithm. <bold>(A)</bold> The raw data (<italic>F</italic>) are spatiotemporally smoothed and transformed (<italic>F</italic><sub>smooth</sub>) until an acceptable SNR is attained. <bold>(B)</bold> In each pixel, the baseline value (μ) and the standard deviation (σ) of the root gray values are then estimated from <italic>F</italic><sub>smooth</sub> (temporal smoothing applied by merging frames). <bold>(C)</bold>
<italic>F</italic><sub>smooth</sub> is then binarized by applying a threshold defined as the baseline value (μ) plus <italic>κ</italic> times the standard deviation of the noise (σ; temporal smoothing applied with a moving average).</p>
        </caption>
        <graphic xlink:href="fncel-15-681066-g0002"/>
      </fig>
    </sec>
    <sec id="s2-6">
      <title>Finding Activity</title>
      <p>We denote the raw fluorescence time series as <italic>F</italic><sub>i</sub>(<italic>t</italic>), i.e., the gray value of pixel <italic>i</italic> at time <italic>t</italic>. Let <inline-formula><mml:math id="M1"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> denote a moving average smoothed version of <italic>F</italic><sub>i</sub>(<italic>t</italic>); (see below for details on smoothing), and consider <inline-formula><mml:math id="M2"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> the square root transformed version of <inline-formula><mml:math id="M3"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. We determine events in our time series data, by binarizing <inline-formula><mml:math id="M4"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> per pixel using a threshold ( <italic>τ<sub>i</sub></italic>) defined as:</p>
      <disp-formula>
        <mml:math id="UM0001">
          <mml:mrow>
            <mml:msub>
              <mml:mi>τ</mml:mi>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:msub>
              <mml:mover>
                <mml:mi>μ</mml:mi>
                <mml:mo>^</mml:mo>
              </mml:mover>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>+</mml:mo>
            <mml:mi>κ</mml:mi>
            <mml:mo>⋅</mml:mo>
            <mml:mover>
              <mml:mi>σ</mml:mi>
              <mml:mo>^</mml:mo>
            </mml:mover>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where <italic>κ</italic> is a user-defined number (default <italic>κ</italic> = 4) which determines the height of the threshold, <inline-formula><mml:math id="M5"><mml:mrow><mml:msub><mml:mover><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the estimated baseline value for each pixel, and <inline-formula><mml:math id="M6"><mml:mover><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> is the estimated standard deviation of the noise as defined in the following sections.</p>
    </sec>
    <sec id="s2-7">
      <title>Modeling Fluorescence Time Series</title>
      <p>To accurately estimate the level of noise, one needs to model the underlying distribution of the fluorescence data. When the number of photons recorded per pixel is sufficiently high, fluorescence data from two-photon Ca<sup>2+</sup> imaging may be considered approximately normally distributed with a particular relationship between the expected value and the variance; <italic>Var<sub>i</sub></italic>(<italic>t</italic>) = <italic>aE<sub>i</sub></italic>(<italic>t</italic>) + <italic>b</italic>, with unknown parameters <italic>a</italic> and <italic>b</italic>, due to the effect of the amplification of the signal by the photomultiplier tubes (Danielyan et al., <xref rid="B5" ref-type="bibr">2014</xref>). Here <italic>E<sub>i</sub></italic>(<italic>t</italic>) denotes the expected fluorescence value at time <italic>t</italic> and in a particular pixel <italic>i</italic> and <italic>Var<sub>i</sub></italic>(<italic>t</italic>) the variance of the fluorescence. Our raw, high frame rate data (<italic>F<sub>i</sub></italic>(<italic>t</italic>)) have a highly non-normal distribution, with a high probability of observing values equal to zero and a heavy right tail. After smoothing (mainly in time), we observe that the distribution comes closer to normality. This is natural, since smoothing has a similar effect on the distribution of the pixel gray values as increasing the pixel integration time. At this level of the analysis, we perform spatiotemporal smoothing by averaging a specific number of frames and neighboring pixels and we denote this time series by <italic>Z<sub>i</sub></italic>(<italic>t</italic>). The particular dependency between the expected value and variance in the model of Danielyan et al. (<xref rid="B5" ref-type="bibr">2014</xref>) may be essentially eliminated using the following transformation <inline-formula><mml:math id="M7"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>. The transformed variable <italic>X<sub>i</sub></italic>(<italic>t</italic>) will have a time-varying expected value <inline-formula><mml:math id="M8"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>≈</mml:mo><mml:msqrt><mml:mrow><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> and an (essentially) time-independent variance <inline-formula><mml:math id="M9"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. In the following, <italic>E</italic> denotes the expected value and <italic>σ<sub>i</sub></italic> represents the standard deviation of the noise. The transformation above is occasionally referred to as a variance stabilization in the literature (Bartlett, <xref rid="B1900" ref-type="bibr">1947</xref>; Wang et al., <xref rid="B26" ref-type="bibr">2019</xref>). Note that the variance after transformation will, in fact, be approximately equal to the following expression</p>
      <disp-formula>
        <mml:math id="UM0002">
          <mml:mrow>
            <mml:mi>V</mml:mi>
            <mml:mi>a</mml:mi>
            <mml:mi>r</mml:mi>
            <mml:mo>(</mml:mo>
            <mml:msub>
              <mml:mi>X</mml:mi>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>(</mml:mo>
            <mml:mi>t</mml:mi>
            <mml:mo>)</mml:mo>
            <mml:mo>)</mml:mo>
            <mml:mo>≈</mml:mo>
            <mml:mi>a</mml:mi>
            <mml:mo>/</mml:mo>
            <mml:mn>4</mml:mn>
            <mml:mo>+</mml:mo>
            <mml:mi>b</mml:mi>
            <mml:mo>/</mml:mo>
            <mml:mo>[</mml:mo>
            <mml:mn>4</mml:mn>
            <mml:mi>E</mml:mi>
            <mml:mo>(</mml:mo>
            <mml:msub>
              <mml:mi>Z</mml:mi>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>(</mml:mo>
            <mml:mi>t</mml:mi>
            <mml:mo>)</mml:mo>
            <mml:mo>)</mml:mo>
            <mml:mo>]</mml:mo>
            <mml:mo>.</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>This expression can be derived using the delta method, see for instance Casella and Berger (<xref rid="B1500" ref-type="bibr">2002</xref>). Clearly, the dependency between the variance and the expected value will be negligible if the expected value, <italic>E</italic>(<italic>Z<sub>i</sub></italic>(<italic>t</italic>)), is sufficiently large, and after the square root transformation, we observe that there is virtually no dependency between μ<sub>i</sub>(<italic>t</italic>) and <italic>Var</italic>(<italic>X<sub>i</sub></italic>(<italic>t</italic>)), which suggests that <italic>b</italic> is an order of magnitude smaller than <italic>E</italic>(<italic>Z<sub>i</sub></italic>(<italic>t</italic>)). We therefore ignore <italic>b</italic> in the following.</p>
    </sec>
    <sec id="s2-8">
      <title>Estimating Pixel-Specific Parameters</title>
      <p>Estimating the time-varying expectation μ<sub>i</sub>(<italic>t</italic>) requires additional assumptions and can be challenging. Furthermore we are primarily interested in estimating the baseline of <italic>X<sub>i</sub></italic>(<italic>t</italic>), which we refer to as μ<sub>i</sub>. We estimate this quantity by finding the mode of the observations in pixel <italic>i</italic>,</p>
      <disp-formula>
        <mml:math id="UM0003">
          <mml:mrow>
            <mml:msub>
              <mml:mover>
                <mml:mi>μ</mml:mi>
                <mml:mo>^</mml:mo>
              </mml:mover>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>=</mml:mo>
            <mml:mi>M</mml:mi>
            <mml:mi>o</mml:mi>
            <mml:mi>d</mml:mi>
            <mml:mi>e</mml:mi>
            <mml:mo>(</mml:mo>
            <mml:msub>
              <mml:mi>X</mml:mi>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>)</mml:mo>
            <mml:mo>.</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>Intuitively, since the fluorescence signal in each pixel primarily takes values close to the baseline for most of the recording, it is natural to estimate the baseline by the most frequent value in the time series for pixel <italic>i</italic>. In our investigations, this estimate appears to work adequately.</p>
      <p>Since we do not estimate the time-varying expected value μ<sub>i</sub>(<italic>t</italic>), we cannot use the conventional sample variance formula. Instead, we use the following estimator for the variance of the noise,</p>
      <disp-formula>
        <mml:math id="UM0004">
          <mml:mrow>
            <mml:msubsup>
              <mml:mover>
                <mml:mi>σ</mml:mi>
                <mml:mo>^</mml:mo>
              </mml:mover>
              <mml:mi>i</mml:mi>
              <mml:mn>2</mml:mn>
            </mml:msubsup>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mn>1</mml:mn>
              <mml:mi>c</mml:mi>
            </mml:mfrac>
            <mml:mi>M</mml:mi>
            <mml:mi>e</mml:mi>
            <mml:mi>d</mml:mi>
            <mml:mi>i</mml:mi>
            <mml:mi>a</mml:mi>
            <mml:mi>n</mml:mi>
            <mml:mtext> </mml:mtext>
            <mml:mo>(</mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mo>[</mml:mo>
                <mml:msub>
                  <mml:mi>X</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo>(</mml:mo>
                <mml:mi>t</mml:mi>
                <mml:mo>+</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>)</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:msub>
                  <mml:mi>X</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo>(</mml:mo>
                <mml:mi>t</mml:mi>
                <mml:mo>)</mml:mo>
                <mml:mo>]</mml:mo>
              </mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:msup>
            <mml:mo>)</mml:mo>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>for all pairs of successive observations. The number <italic>c</italic> is a constant which ensures that this is a consistent estimator for <inline-formula><mml:math id="M10"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> under the assumption of normality. The value of <italic>c</italic> may be found by simulations or calculated theoretically, by</p>
      <disp-formula>
        <mml:math id="UM0005">
          <mml:mrow>
            <mml:mi>c</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mn>2</mml:mn>
            <mml:msub>
              <mml:mi>m</mml:mi>
              <mml:mn>1</mml:mn>
            </mml:msub>
            <mml:mo>≈</mml:mo>
            <mml:mn>0.9099</mml:mn>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where <italic>m</italic><sub>1</sub> is the median of the chi-squared distribution with 1 degree of freedom. This formula for c is an approximation that holds when the number of time points is sufficiently large. This estimator was employed by Wang et al. (<xref rid="B26" ref-type="bibr">2019</xref>). Its theoretical properties have not been derived as far as we know, but its form and motivation is close to the mean squared successive difference (MSSD) estimator suggested by Neumann et al. (<xref rid="B13" ref-type="bibr">1941</xref>) and with a relatively widespread use (Ebner-Priemer et al., <xref rid="B7" ref-type="bibr">2007</xref>, <xref rid="B6" ref-type="bibr">2009</xref>; Garrett et al., <xref rid="B10" ref-type="bibr">2013</xref>; Nomi et al., <xref rid="B14" ref-type="bibr">2017</xref>).</p>
    </sec>
    <sec id="s2-9">
      <title>Smoothing</title>
      <p>The number of events detected with the ROA algorithm is dependent on the imaging quality, which can be assessed by the signal-to-noise ratio (SNR), which we define as</p>
      <disp-formula>
        <mml:math id="UM0006">
          <mml:mrow>
            <mml:mi>S</mml:mi>
            <mml:mi>N</mml:mi>
            <mml:mi>R</mml:mi>
            <mml:mo>=</mml:mo>
            <mml:mover>
              <mml:mi>μ</mml:mi>
              <mml:mo>^</mml:mo>
            </mml:mover>
            <mml:mo>/</mml:mo>
            <mml:mover>
              <mml:mi>σ</mml:mi>
              <mml:mo>^</mml:mo>
            </mml:mover>
            <mml:mo>,</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>where <inline-formula><mml:math id="M11"><mml:mover><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="M12"><mml:mover><mml:mi>σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> are estimates of the common baseline and standard deviation for all pixels in an image time series. We use the median of the pixel-specific estimates in order to be robust against extreme values,</p>
      <disp-formula>
        <mml:math id="UM0007">
          <mml:mrow>
            <mml:mover>
              <mml:mi>μ</mml:mi>
              <mml:mo>^</mml:mo>
            </mml:mover>
            <mml:mo>=</mml:mo>
            <mml:mi>M</mml:mi>
            <mml:mi>e</mml:mi>
            <mml:mi>d</mml:mi>
            <mml:mi>i</mml:mi>
            <mml:mi>a</mml:mi>
            <mml:mi>n</mml:mi>
            <mml:mo>(</mml:mo>
            <mml:msub>
              <mml:mover>
                <mml:mi>μ</mml:mi>
                <mml:mo>^</mml:mo>
              </mml:mover>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>)</mml:mo>
            <mml:mtext> </mml:mtext>
            <mml:mi>a</mml:mi>
            <mml:mi>n</mml:mi>
            <mml:mi>d</mml:mi>
            <mml:mtext> </mml:mtext>
            <mml:mover>
              <mml:mi>σ</mml:mi>
              <mml:mo>^</mml:mo>
            </mml:mover>
            <mml:mo>=</mml:mo>
            <mml:mi>M</mml:mi>
            <mml:mi>e</mml:mi>
            <mml:mi>d</mml:mi>
            <mml:mi>i</mml:mi>
            <mml:mi>a</mml:mi>
            <mml:mi>n</mml:mi>
            <mml:mo>(</mml:mo>
            <mml:msub>
              <mml:mover>
                <mml:mi>σ</mml:mi>
                <mml:mo>^</mml:mo>
              </mml:mover>
              <mml:mi>i</mml:mi>
            </mml:msub>
            <mml:mo>)</mml:mo>
            <mml:mo>.</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
      <p>We observed that for low SNRs there was a positive correlation between SNR and the number of events detected with the ROA algorithm. If a typical dataset was smoothed to attain at least an SNR of 9, this correlation disappeared. In order to attain this desired level of SNR of at least 9, we perform a parameter search of varying levels of spatiotemporal smoothing and apply spatial Gaussian smoothing and temporal boxcar smoothing. Although we cannot guarantee that an SNR of at least 9 is the optimal target for datasets acquired by different labs and hardware, an SNR of at least 9 worked well for the external datasets we tested. For the time series <italic>X<sub>i</sub></italic>(<italic>t</italic>), the temporal smoothing is applied by binning frames and not as a moving average. The parameter search may be performed on all imaging trials independently or on a selected trial serving as a template for the rest of the analyses. For spatial smoothing, we perform a parameter search where the sigma of the Gaussian filter is increased from 0 to 2 pixels. If the desired SNR is not reached by spatial filtering alone, we keep the maximum spatial smoothing and do a parameter search for the number of averaged frames between one and 30 frames. If the target SNR is still not reached, the configurations are set to 2 pixels for the spatial smoothing and 30 frames for the temporal smoothing. We perform the parameters search for the number of frames to average by using the interval halving method. To limit the computation time in large time series data only the last 1,000 merged frames are used to compute the SNR in the parameter search. The spatial and temporal smoothing parameters can also be set manually. The parameters are estimated and stored for interactive threshold adjustment and filtering when the pre-process button in the GUI is pressed.</p>
    </sec>
    <sec id="s2-10">
      <title>Optional Threshold Adjustment and Filtering Results</title>
      <p>As the size and duration of two-photon microscopy of astrocytic Ca<sup>2+</sup> events follow a power law distribution and the optical resolution of two-photon microscopy is an order of magnitude poorer than the smallest astrocytic processes, there is a continuum between signal and noise. Moreover, we do not have access to the ground truth of real-life data. Consequently, the threshold applied will be somewhat heuristic (we have chosen four times the standard deviation of the noise as default: <italic>κ</italic> = 4) and the events detected will be strongly dependent on the threshold applied. In addition, no matter the threshold applied, a large proportion of the true Ca<sup>2+</sup> event will go undetected due to the limitations of (non-super-resolution) optical microscopy. For these reasons it is desirable to be somewhat conservative when deciding what is signal and what should be considered noise, and a tool is provided for interactively changing the threshold by adjusting <italic>κ</italic> and filtering out ROAs below a minimum size and duration.</p>
    </sec>
    <sec id="s2-11">
      <title>Performance</title>
      <p>The main outputs from Begonia can be found in <xref rid="T1" ref-type="table">Table 1</xref>. The ROA method and surrounding pipeline have been created to support the analysis of large datasets on moderate performance computers like a personal laptop. Two-photon recordings at high frame rates typically store data in integer formats at rates of ~1 GB per minute. However, for many calculations, data need to be transformed to floating-point formats. These can be two to eight times more memory intensive and consequently exhaust the working memory of the computer even for shorter (5–10 min) recordings. For these reasons, in the pipeline where the sheer size of the file may exceed the capacity of a normally configured computer, data are chunked and analyzed in smaller segments. Moreover, data retrieval is implemented with lazy (on-demand) reading. On a personal laptop, with 16 GB RAM, it took 15, 31, 51, 143, and 267 s, to analyze 100, 500, 1,000, 2,500, and 5,000 frames of 512 × 512 pixels, respectively.</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>The primary outputs from Begonia and where to find them.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="center" rowspan="1" colspan="1">Output</th>
              <th align="center" rowspan="1" colspan="1">Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">ROA event table</td>
              <td align="left" rowspan="1" colspan="1">Each row represents one event. The table contains the center position, start frame, end frame, duration, size and duration. Saved with the key-value pair “roa_table” after processing.</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ROA traces</td>
              <td align="left" rowspan="1" colspan="1">Time series of roa frequency (new events per frame) and ROA density (active x−y−t voxels) key-value pair “roa_traces” after processing.</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ROA mask</td>
              <td align="left" rowspan="1" colspan="1">A binary 3D matrix representing the imaging time series, where 1’s represent detected events. Saved with the key-value pair “roa_mask_chx” (<italic>x</italic> denoting the channel where ROAs have been detected).</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ROA 3D plot</td>
              <td align="left" rowspan="1" colspan="1">A GUI is provided to produce 3D ROA plots as in <xref ref-type="fig" rid="F5">Figure 5B</xref>.</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ROI table</td>
              <td align="left" rowspan="1" colspan="1">A table containing the manually segmented ROIs. Each row represents one ROI and contains the size, location, channel, name and a unique identifier of the ROI. Saved with the key-value pair “roi_table.”</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ROI traces</td>
              <td align="left" rowspan="1" colspan="1">Raw and Δ<italic>F/F</italic><sub>0</sub> normalized signals from ROIs. Saved with the key-value pair “roi_signals_raw” and “roi_signals_dff.”</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ROI active pixels</td>
              <td align="left" rowspan="1" colspan="1">Fraction of ROI that has a ROA per time unit. Saved with the key-value pair “roi_signals_raw” and “roi_signal_rpa.”</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3-1">
      <title>Workflow</title>
      <p>We built Begonia with the flow of data in mind, and a high priority during development was to create responsive GUIs and speed up functions that have high computational demands. Furthermore, time-consuming steps can be queued and processed in batch operations. The workflow is outlined in <xref ref-type="fig" rid="F1">Figure 1</xref>. The intended workflow is a step-by-step procedure where small chunks of the data are processed at a time and the results and intermediate data are stored with data locations associated with the imaging time series object. The chunking ensures that the software can be applied to (infinitely) large datasets whereas saving intermediate data adds flexibility. For example, if there is a failure during one or more processing steps, the fault can be troubleshot and the procedure can be started from the point where it stopped. Also, intermediate steps can easily be reprocessed using different parameters.</p>
      <p>The first step of the workflow in Begonia is to identify imaging time series data and instantiate classes to interact with them. Begonia includes methods that search directories for supported two-photon imaging formats and returns a list of imaging objects. The objects are used to access the imaging time series data and microscope metadata in a standardized way, even if the recordings are stored using heterogeneous file formats. Instructions on how to make new imaging classes for unsupported formats are provided in the documentation.</p>
      <p>Begonia provides a general method to save data together with the imaging data in folders in the directory tree. The data in these folders can then be directly accessed via the imaging objects and are known in this toolbox as data locations. Data stored through the data locations system may be retrieved via the imaging time series objects using keywords.</p>
      <p>We have provided a workflow GUI (<xref ref-type="fig" rid="F1">Figures 1B</xref>, <xref ref-type="fig" rid="F3">3A</xref>) that lists groups of data locations and associated metadata in a table and allows the user to select items and run procedures. It includes basic steps typically performed in the analysis of two-photon imaging data, and can easily be expanded or modified to allow for other types of analyses on the data. The user can select and pass single or multiple data objects to functions, other GUIs or to the batch processing queue (<xref ref-type="fig" rid="F3">Figure 3B</xref>). Standard procedures that are currently implemented in the toolbox are image alignment using the NoRMCorre software package (Pnevmatikakis and Giovannucci, <xref rid="B15" ref-type="bibr">2017</xref>), manual segmentation of ROIs in a GUI, and running the ROA algorithm.</p>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Begonia includes a data management GUI with <bold>(A)</bold> a main window where rows represent data entities (typically imaging data) and columns contain corresponding metadata. Actions in the main window can be run immediately or be added as tasks to a processing queue <bold>(B)</bold> that can be loaded for time-consuming batch processing.</p>
        </caption>
        <graphic xlink:href="fncel-15-681066-g0003"/>
      </fig>
      <p>The last step of the processing workflow is to combine imaging data with other types of data (e.g., behavioral data) and to export data. Begonia provides a way to easily combine the results from the analysis of the imaging data with other types of data (for instance electrophysiology or behavioral metrics) in a data class called MultiTable. The MultiTable enables you to resample, align and slice your dataset to export a desired subset of data for plotting or statistical analyses (<xref ref-type="fig" rid="F1">Figure 1D</xref> and see “Materials and Methods” section). The main outputs from Begonia is listed in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
    </sec>
    <sec id="s3-2">
      <title>Data Management and Processing</title>
      <p>Begonia is built around the concept of data locations to save metadata and derived data throughout the analyses (see “Materials and Methods” section). Begonia further provides a template GUI for working with these abstract representations of the data and metadata (<xref ref-type="fig" rid="F3">Figure 3</xref>). Here, DataLocation objects, e.g., a two-photon microscopy time series with corresponding metadata, appear as an entity in a list. The GUI enables the user to selectively see metadata coupled to the data location objects in the same list, and gives quick access to pass these objects to the MATLAB workspace or functions represented by buttons and menu options. You may add new buttons and menus with associated functions to the GUI by passing anonymous functions as input arguments during the initialization of the GUI. The GUI also provides a processing queue (<xref ref-type="fig" rid="F3">Figure 3B</xref>), where actions on the data location objects can be visualized before being executed in a batch-wise process.</p>
    </sec>
    <sec id="s3-3">
      <title>Marking ROIs</title>
      <p>The toolbox provides a multi-purpose GUI for visualization of imaging data, ROAs, and manual segmentation of ROIs (<xref ref-type="fig" rid="F4">Figure 4</xref>). The GUI components may also be assembled for other types of analyses. Imaging data may be visualized as raw data, running average data, or projections of the whole time series. ROIs are manually drawn with a paintbrush tool and saved in a list where the type of ROI and relationships between ROIs may be defined.</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>The ROI manager provided in Begonia comprises the following features: <bold>(A)</bold> a view controller that determines what and how imaging data should be displayed, <bold>(B)</bold> a contextual guide window that informs the user of useful shortcuts and keyboard commands for the current mode. <bold>(C)</bold> The main image window, where raw imaging data or running averages or various projections of the imaging data can be displayed. Manually segmented ROIs are drawn into the overlay. <bold>(D)</bold> An ROI editor that organizes the ROIs and enables the user to classify, rename, delete or modify ROIs.</p>
        </caption>
        <graphic xlink:href="fncel-15-681066-g0004"/>
      </fig>
    </sec>
    <sec id="s3-4">
      <title>Region of Activity (ROA) Analysis</title>
      <p>The ROA algorithm is an event-based method to quantify astrocytic Ca<sup>2+</sup> signals. An earlier iteration of the ROA algorithm was applied to two-photon microscopy data in Bojarskaite et al. (<xref rid="B3" ref-type="bibr">2020</xref>). In the current version, the noise estimation strategy has been adapted from Wang et al. (<xref rid="B26" ref-type="bibr">2019</xref>). The analysis comprises first a spatial and temporal filtering of two-dimensional time series data to attain an acceptable SNR, followed by a pixel-by-pixel quantification of noise over time, to define a threshold for signal detection. The steps of the method are shown in <xref ref-type="fig" rid="F2">Figure 2</xref>. The appropriate level of smoothing is automatically found as the first step of the algorithm (see “Materials and Methods” section). This part of the algorithm enables the ROA method to be run with few input parameters and still give reproducible results.</p>
      <p>The ROA analysis can be executed by running a few functions in series and the results can be viewed in a similar fashion. The ROA analysis is simplified by using the data management GUI which guides the analyst through the following steps: (1) loading imaging data into the GUI by searching specified directories for supported imaging formats; (2) setting the two smoothing parameters by either clicking “Auto config” or “Manual config”; (3) running the pre-processing by clicking the “Pre-process” button; (4) previewing detected events and adjusting the detection threshold in the ROA GUI (<xref ref-type="fig" rid="F5">Figure 5</xref>) by clicking the “Threshold” button. The GUI also enables filtering small and short events as well as ignoring regions around the edge of the FOV or other user-defined areas; and (5) converting the detected, filtered events to time series traces of (a) the density of Ca<sup>2+</sup> signal events per time unit and (b) the number of new events per frame. Metrics about the events, such as size, duration, and timing, are saved in a table where each row represents one event.</p>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p>ROA thresholding and output. <bold>(A)</bold> The thresholding step of the ROA algorithm is supported by a GUI that displays an overlay of the ROAs on top of the imaging data, and allows for interactive adjustment of the Ca<sup>2+</sup> event detection threshold, adjusting the minimum size and duration of events, and defining regions that should be ignored. <bold>(B)</bold> An <italic>x-y-t</italic> volume rendering of a time series of astrocytic Ca<sup>2+</sup> signals and corresponding traces of ROA density (% active voxels) and ROA frequency events per minute per μm<sup>2</sup>.</p>
        </caption>
        <graphic xlink:href="fncel-15-681066-g0005"/>
      </fig>
      <p>This list of output of the ROA algorithm is less extensive than that of the AQuA algorithm (Wang et al., <xref rid="B26" ref-type="bibr">2019</xref>). Most importantly, AQuA provides information about the spatial dynamics of every single Ca<sup>2+</sup> event and applies a set of rules to separate Ca<sup>2+</sup> events that may be splitting into several events, or merging into larger events. The overall performance of the ROA algorithm was compared to the AQuA algorithm using a downsampled dataset detecting the same trends in Ca<sup>2+</sup> signaling across different sleep stages in Bojarskaite et al. (<xref rid="B3" ref-type="bibr">2020</xref>).</p>
    </sec>
    <sec id="s3-5">
      <title>ROA Activity in ROIs Analysis</title>
      <p>As there is substantial evidence that the astroglial subcompartments behave differently, separate analyses of anatomical subcompartments are warranted (Bazargani and Attwell, <xref rid="B2" ref-type="bibr">2016</xref>). The ROA analysis output does not disclose the underlying anatomical structure of the tissue. Therefore the output of the ROA algorithm can be filtered based on manually defined ROIs providing the percentage of an ROI or subcompartment active at a given time.</p>
    </sec>
    <sec id="s3-6">
      <title>Accessibility</title>
      <p>The Begonia toolbox may be downloaded at <ext-link ext-link-type="uri" xlink:href="https://github.com/GliaLab/Begonia">https://github.com/GliaLab/Begonia</ext-link>. A detailed user manual and links to third party software packages and links to instructional videos are provided there as well as a user community discussion group.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>Deciphering astroglial Ca<sup>2+</sup> signals remains one of the biggest challenges for the field of glioscience (Semyanov et al., <xref rid="B20" ref-type="bibr">2020</xref>). Even though a plethora of functions are thought to be supported by astroglial Ca<sup>2+</sup> signals, the interpretation and importance of these signals are still somewhat controversial (Bazargani and Attwell, <xref rid="B2" ref-type="bibr">2016</xref>; Shigetomi et al., <xref rid="B21" ref-type="bibr">2016</xref>). When studying unanesthetized awake-behaving mice, a range of Ca<sup>2+</sup> signals can be detected, from small events close to the level of noise to global increases in astrocytic Ca<sup>2+</sup> signaling across the cortex in relation to neuromodulatory activity (Srinivasan et al., <xref rid="B22" ref-type="bibr">2015</xref>; Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>). To better characterize this wide range of event types is a key first step in identifying their role in the circuitry, and may contribute to solving some of the controversies in this field. Here, we present a toolbox tailor-made for the analyses of two-photon microscopy data of astrocytic Ca<sup>2+</sup> signals in conjunction with rich behavioral data, from raw data to aggregated results in tables.</p>
    <p>A large proportion of astroglial Ca<sup>2+</sup> signals are likely stochastic events (Semyanov et al., <xref rid="B20" ref-type="bibr">2020</xref>), and under certain conditions, they are quite infrequent (Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>). In these cases, long acquisition times are warranted (e.g., time series of 10 min or more) to accurately quantify event rates and dynamics. Furthermore, when imaging awake mice, a high frame rate is warranted to be able to effectively remove movement artifacts (Pnevmatikakis and Giovannucci, <xref rid="B15" ref-type="bibr">2017</xref>). For these reasons, astroglial Ca<sup>2+</sup> imaging time series from awake mice are often large files up to tens of gigabytes. We have therefore gone to great lengths to optimize Begonia’s processing to run quickly on large files even on moderate performance computers. The workflow has been organized in such a way that the time-consuming steps of the analyses can be performed unsupervised. Moreover, an important goal with the toolbox is responsive behavior and a short waiting time when manually interacting with the data. Therefore all large data in the pipeline are loaded lazily, i.e., on request. Even so, some of the analyses provided in Begonia will be slow to execute with large recordings due to the sheer number of calculations performed. Incorporating hardware-accelerated analyses could hold great potential for some of these time-consuming steps in the future.</p>
    <p>The first hurdle in the analyses of two-photon microscopy data is to import the imaging data in an efficient fashion to the analysis platform. Two-photon microscopy data are typically stored as TIFF files (either single-frame files or multi-page TIFFs). Even so the TIFF format allows for many variations and data from different channels, trials and most importantly metadata are saved in different ways by different setups. Consequently, there are no standardized ways to read two-photon microscopy data across platforms. ImageJ and FIJI offer a low threshold plug-and-play software that can handle many different TIFF implementations but has the drawback of confining the analyses to the ImageJ framework (Schindelin et al., <xref rid="B17" ref-type="bibr">2012</xref>; Schneider et al., <xref rid="B18" ref-type="bibr">2012</xref>). Begonia offers direct support for imaging data from ScanImage and PrarieView software as well as TIFF files read by the TIFFStack (Muir and Kampa, <xref rid="B12" ref-type="bibr">2014</xref>) library, but just as important provides an API for easy adaptation of other imaging data formats to our pipeline.</p>
    <p>In this article, we present an event-based Ca<sup>2+</sup> signal detection tool for the unbiased quantification of astrocytic Ca<sup>2+</sup> signals with a high level of detail. The algorithm separates Ca<sup>2+</sup> signals from the noise for each individual pixel over time, before connecting the active <italic>x-y-t</italic> voxels to Ca<sup>2+</sup> signal events. The ROA algorithm performs considerably better than static ROI analyses in terms of sensitivity and accuracy (see <xref ref-type="fig" rid="F6">Figure 6</xref> and Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>). An earlier iteration of this algorithm was used for the analyses of Ca<sup>2+</sup> signaling data in Bojarskaite et al. (<xref rid="B3" ref-type="bibr">2020</xref>). The present algorithm calculates the threshold for signal detection slightly differently, similar to that of the AQuA algorithm (Wang et al., <xref rid="B26" ref-type="bibr">2019</xref>). The event definition of the ROA algorithm and the first part of the AQuA algorithm share many similarities, but there are also noteworthy differences. In our hands, the AQuA method had some limitations that made it impractical or even impossible to use for our large files of high frame rate imaging data (Bojarskaite et al., <xref rid="B3" ref-type="bibr">2020</xref>). The first issue was processing time. For our long (e.g., 18,000 frames), 30 Hz two-photon microscopy data, processing with the AQuA algorithm failed even on a high-performance computer (128 Gb RAM, 18 cores) due to running out of RAM. When run on a moderate performance computer, a moderately sized dataset of 5,000 frames recording that ran in 267 s with the ROA algorithm took ~2 full days to analyze with the ROA algorithm. Moreover, the AQuA algorithm did not perform well in terms of separation of signal from the noise in our data, that had a poor SNR due to our high acquisition rates, resulting in high levels of artifactual events detected. The ROA algorithm is considerably less extensive than the AQuA algorithm as it does not analyze the spatiotemporal dynamics of each signaling event separately. Rather it only reports on the frequency of starting events and density of events per time unit in the full FOV or per manually segmented compartments, as well as descriptive measures of maximum spatial extent and duration of individual ROAs. This in part explains the large difference in processing times between the two algorithms—i.e., the ROA algorithm is a substantially more lightweight algorithm.</p>
    <fig id="F6" position="float">
      <label>Figure 6</label>
      <caption>
        <p>ROA algorithm vs. ROI analyses. <bold>(A)</bold> The complex spatiotemporal distribution of astroglial Ca<sup>2+</sup> signals presented as an <italic>x-y-t</italic> volume rendering. The outline of an astrocyte (ROI) is presented in green. <bold>(B)</bold> The ROA algorithm is considerably more sensitive than a standard ROI-based analysis, as evident when comparing the percentage of active pixels detected with the ROA algorithm within the ROI defined in <bold>(A)</bold>, compared to the extracted mean fluorescence from the ROI defined in <bold>(A)</bold> where no signals would be detected with a standard peak detection algorithm.</p>
      </caption>
      <graphic xlink:href="fncel-15-681066-g0006"/>
    </fig>
    <p>The size and duration of astrocytic Ca<sup>2+</sup> events are known to follow a power law distribution (Jung et al., <xref rid="B11" ref-type="bibr">1998</xref>; Wu et al., <xref rid="B27" ref-type="bibr">2014</xref>; Semyanov et al., <xref rid="B20" ref-type="bibr">2020</xref>), and Ca<sup>2+</sup> signals in the smallest processes and leaflets are of considerably smaller spatial extent than the resolution limit of optical (non-super resolution) microscopy allows. Therefore, even minute changes in the settings and consequently the thresholds and filtering applied will profoundly change the distribution of Ca<sup>2+</sup> signal events detected. These reasons call for being conservative when determining the threshold for separating signal and noise and is also an argument for not considering the smallest detected events in a given recording. An interactive tool is provided that enables easy adjustment of the threshold applied and the minimum sizes and durations allowed for a Ca<sup>2+</sup> event.</p>
    <p>One goal with the ROA method was to provide an algorithm that could be used without too many input parameters to enable a more direct comparison between datasets recorded with different hardware or settings. We have therefore provided a pre-processing method that evaluates the imaging data and determines what filtering is appropriate to: (a) ensure an accurate identification of events with few artifacts; and (b) to enable more direct comparisons between data from different datasets. The pre-processing will find suitable parameters for spatial and temporal smoothing until an empirically chosen level of SNR of at least nine is attained. We have tested the algorithm on datasets acquired in three different laboratories with different types of hardware and acquisition parameters. Even so we cannot be certain that the target SNR of nine is optimal for two-photon image recordings of all types, as photon statistics and data quality vary significantly across acquisition hardware, fluorophores, and experimental protocols.</p>
    <p>In principle, other types of fluorescent data than astrocytic Ca<sup>2+</sup> signals could be possible to analyze with Begonia. The pipeline already supports signal extraction and neuropil subtraction from neuronal ROIs (accessible through the API). Moreover, the ROA algorithm could prove useful in the future for quantifying both neuronal Ca<sup>2+</sup> signals or other types of dynamic fluorescent sensors but has not been validated for this purpose yet.</p>
    <p>To the best of our knowledge, no algorithm exists for automatically segmenting images of astroglial cells into their respective subcellular compartments of somata, processes, and endfeet. This is also true for our ROA method. Therefore, we provide the option of integrating manually segmented ROIs with the automatic ROA algorithm, such that subcompartment specific ROA signals can be described separately. Ideally ROIs should have been detected and correctly classified without manual intervention. Potentially, machine learning algorithms, using manually segmented ROIs as a training dataset could provide such functionality in the future.</p>
    <p>Our toolbox requires imaging data to be adapted to standardized classes and be funneled through our data management pipeline. We believe this is a major strength for this toolbox as it allows for more efficient and flexible approaches to data management. This may, however, also be perceived as a potential drawback—the tools in our toolbox are not standalone pieces of software that take general image formats and directly outputs results—rather, the tools are embedded in a workflow pipeline that must be executed in a certain fashion. Consequently, the threshold to start using the toolbox could be somewhat higher. To mitigate these problems, we have made instructional videos and live script example cases to be run with example datasets to quickly familiarize potential users with the API. GUIs are also provided for users that are not comfortable scripting their analyses. The Begonia software published here is the first version of this package, built to be easily extendable, and we hope that the project will evolve both locally and in collaboration with potential external users through the GitHub repository and associated user community discussion group.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>Publicly available datasets were analyzed in this study. Links to the example datasets can be found here: <ext-link ext-link-type="uri" xlink:href="http://github.com/GliaLab/Begonia">http://github.com/GliaLab/Begonia</ext-link>.</p>
  </sec>
  <sec id="s6">
    <title>Ethics Statement</title>
    <p>The animal study was reviewed and approved by the Norwegian Food Safety Authority.</p>
  </sec>
  <sec id="s7">
    <title>Author Contributions</title>
    <p>KV and RE: conceptualization and funding acquisition. DB, KÅ, EH, KP, CC, GH, and RE: methodology. RE: resources. DB, KÅ, LB, CC, GH, and RE: writing—original draft. LB and EH: acquiring microscopy data and testing. DB, KÅ, EH, KP, KV, LB, CC, GH, and RE: writing—review and editing. KP, KV, and RE: supervision. All authors contributed to the article and approved the submitted version.</p>
  </sec>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> We acknowledge the support by UNINETT Sigma2 AS for making data storage available through NIRD, project NS9021K. This work was supported by the Research Council of Norway (Norges Forskningsråd; grants #249988, #240476, and #262552), the South-Eastern Norway Regional Health Authority (Helse Sør-Øst RHF; grant #2016070), the European Union’s Seventh Framework Program for research, technological development, and demonstration under grant agreement no. 601055, The National Association of Public Health, The Olav Thon Foundation, and the Letten Foundation.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>M. J. P.</given-names></name><name><surname>Ferrari</surname><given-names>K. D.</given-names></name><name><surname>Stobart</surname><given-names>J. L.</given-names></name><name><surname>Holub</surname><given-names>M.</given-names></name><name><surname>Weber</surname><given-names>B.</given-names></name></person-group> (<year>2018</year>). <article-title>CHIPS: an extensible toolbox for cellular and hemodynamic two-photon image analysis</article-title>. <source>Neuroinformatics</source>
<volume>16</volume>, <fpage>145</fpage>–<lpage>147</lpage>. <pub-id pub-id-type="doi">10.1007/s12021-017-9344-y</pub-id><?supplied-pmid 28980186?><pub-id pub-id-type="pmid">28980186</pub-id></mixed-citation>
    </ref>
    <ref id="B1900">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartlett</surname><given-names>M. S.</given-names></name></person-group> (<year>1947</year>). <article-title>The use of transformations</article-title>. <source>Biometrics</source>
<volume>3</volume>, <fpage>39</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.2307/3001536</pub-id><?supplied-pmid 30579813?><pub-id pub-id-type="pmid">20240416</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bazargani</surname><given-names>N.</given-names></name><name><surname>Attwell</surname><given-names>D.</given-names></name></person-group> (<year>2016</year>). <article-title>Astrocyte calcium signaling: the third wave</article-title>. <source>Nat. Neurosci.</source>
<volume>19</volume>, <fpage>182</fpage>–<lpage>189</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4201</pub-id><?supplied-pmid 26814587?><pub-id pub-id-type="pmid">26814587</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bojarskaite</surname><given-names>L.</given-names></name><name><surname>Bjørnstad</surname><given-names>D. M.</given-names></name><name><surname>Pettersen</surname><given-names>K. H.</given-names></name><name><surname>Cunen</surname><given-names>C.</given-names></name><name><surname>Hermansen</surname><given-names>G. H.</given-names></name><name><surname>Åbjørsbråten</surname><given-names>K. S.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Astrocytic Ca signaling is reduced during sleep and is involved in the regulation of slow wave sleep</article-title>. <source>Nat. Commun.</source><volume>11</volume>:<fpage>3240</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-020-17062-2</pub-id><?supplied-pmid 32632168?><pub-id pub-id-type="pmid">32632168</pub-id></mixed-citation>
    </ref>
    <ref id="B1500">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Casella</surname><given-names>G.</given-names></name><name><surname>Berger</surname><given-names>R. L.</given-names></name></person-group> (<year>2002</year>). <source>Statistical Inference.</source>
<publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Cengage Learning</publisher-name>. </mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornell-Bell</surname><given-names>A. H.</given-names></name><name><surname>Finkbeiner</surname><given-names>S. M.</given-names></name><name><surname>Cooper</surname><given-names>M. S.</given-names></name><name><surname>Smith</surname><given-names>S. J.</given-names></name></person-group> (<year>1990</year>). <article-title>Glutamate induces calcium waves in cultured astrocytes: long-range glial signaling</article-title>. <source>Science</source>
<volume>247</volume>, <fpage>470</fpage>–<lpage>473</lpage>. <pub-id pub-id-type="doi">10.1126/science.1967852</pub-id><?supplied-pmid 1967852?><pub-id pub-id-type="pmid">1967852</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danielyan</surname><given-names>A.</given-names></name><name><surname>Wu</surname><given-names>Y.-W.</given-names></name><name><surname>Shih</surname><given-names>P.-Y.</given-names></name><name><surname>Dembitskaya</surname><given-names>Y.</given-names></name><name><surname>Semyanov</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>Denoising of two-photon fluorescence images with block-matching 3D filtering</article-title>. <source>Methods</source>
<volume>68</volume>, <fpage>308</fpage>–<lpage>316</lpage>. <pub-id pub-id-type="doi">10.1016/j.ymeth.2014.03.010</pub-id><?supplied-pmid 24657185?><pub-id pub-id-type="pmid">24657185</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebner-Priemer</surname><given-names>U. W.</given-names></name><name><surname>Eid</surname><given-names>M.</given-names></name><name><surname>Kleindienst</surname><given-names>N.</given-names></name><name><surname>Stabenow</surname><given-names>S.</given-names></name><name><surname>Trull</surname><given-names>T. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Analytic strategies for understanding affective (in)stability and other dynamic processes in psychopathology</article-title>. <source>J. Abnorm. Psychol.</source>
<volume>118</volume>, <fpage>195</fpage>–<lpage>202</lpage>. <pub-id pub-id-type="doi">10.1037/a0014868</pub-id><?supplied-pmid 19222325?><pub-id pub-id-type="pmid">19222325</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebner-Priemer</surname><given-names>U. W.</given-names></name><name><surname>Kuo</surname><given-names>J.</given-names></name><name><surname>Kleindienst</surname><given-names>N.</given-names></name><name><surname>Welch</surname><given-names>S. S.</given-names></name><name><surname>Reisch</surname><given-names>T.</given-names></name><name><surname>Reinhard</surname><given-names>I.</given-names></name><etal/></person-group>. (<year>2007</year>). <article-title>State affective instability in borderline personality disorder assessed by ambulatory monitoring</article-title>. <source>Psychol. Med.</source><volume>37</volume>, <fpage>961</fpage>–<lpage>970</lpage>. <pub-id pub-id-type="doi">10.1017/S0033291706009706</pub-id><?supplied-pmid 17202005?><pub-id pub-id-type="pmid">17202005</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eilert-Olsen</surname><given-names>M.</given-names></name><name><surname>Hjukse</surname><given-names>J. B.</given-names></name><name><surname>Thoren</surname><given-names>A. E.</given-names></name><name><surname>Tang</surname><given-names>W.</given-names></name><name><surname>Enger</surname><given-names>R.</given-names></name><name><surname>Jensen</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Astroglial endfeet exhibit distinct Ca signals during hypoosmotic conditions</article-title>. <source>Glia</source><volume>67</volume>, <fpage>2399</fpage>–<lpage>2409</lpage>. <pub-id pub-id-type="doi">10.1002/glia.23692</pub-id><?supplied-pmid 31350866?><pub-id pub-id-type="pmid">31350866</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enger</surname><given-names>R.</given-names></name><name><surname>Dukefoss</surname><given-names>D. B.</given-names></name><name><surname>Tang</surname><given-names>W.</given-names></name><name><surname>Pettersen</surname><given-names>K. H.</given-names></name><name><surname>Bjørnstad</surname><given-names>D. M.</given-names></name><name><surname>Helm</surname><given-names>P. J.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Deletion of aquaporin-4 curtails extracellular glutamate elevation in cortical spreading depression in awake mice</article-title>. <source>Cereb. Cortex</source><volume>27</volume>, <fpage>24</fpage>–<lpage>33</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhw359</pub-id><?supplied-pmid 28365776?><pub-id pub-id-type="pmid">28365776</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname><given-names>D. D.</given-names></name><name><surname>Samanez-Larkin</surname><given-names>G. R.</given-names></name><name><surname>MacDonald</surname><given-names>S. W. S.</given-names></name><name><surname>Lindenberger</surname><given-names>U.</given-names></name><name><surname>McIntosh</surname><given-names>A. R.</given-names></name><name><surname>Grady</surname><given-names>C. L.</given-names></name></person-group> (<year>2013</year>). <article-title>Moment-to-moment brain signal variability: a next frontier in human brain mapping?</article-title>
<source>Neurosci. Biobehav. Rev.</source>
<volume>37</volume>, <fpage>610</fpage>–<lpage>624</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2013.02.015</pub-id><?supplied-pmid 23458776?><pub-id pub-id-type="pmid">23458776</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>P.</given-names></name><name><surname>Cornell-Bell</surname><given-names>A.</given-names></name><name><surname>Madden</surname><given-names>K. S.</given-names></name><name><surname>Moss</surname><given-names>F.</given-names></name></person-group> (<year>1998</year>). <article-title>Noise-induced spiral waves in astrocyte syncytia show evidence of self-organized criticality</article-title>. <source>J. Neurophysiol.</source>
<volume>79</volume>, <fpage>1098</fpage>–<lpage>1101</lpage>. <pub-id pub-id-type="doi">10.1152/jn.1998.79.2.1098</pub-id><?supplied-pmid 9463465?><pub-id pub-id-type="pmid">9463465</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muir</surname><given-names>D. R.</given-names></name><name><surname>Kampa</surname><given-names>B. M.</given-names></name></person-group> (<year>2014</year>). <article-title>FocusStack and StimServer: a new open source MATLAB toolchain for visual stimulation and analysis of two-photon calcium neuronal imaging data</article-title>. <source>Front. Neuroinform.</source>
<volume>8</volume>:<fpage>85</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2014.00085</pub-id><?supplied-pmid 25653614?><pub-id pub-id-type="pmid">25653614</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neumann</surname><given-names>J.</given-names></name><name><surname>von Neumann</surname><given-names>J.</given-names></name><name><surname>Kent</surname><given-names>R. H.</given-names></name><name><surname>Bellinson</surname><given-names>H. R.</given-names></name><name><surname>Hart</surname><given-names>B. I.</given-names></name></person-group> (<year>1941</year>). <article-title>The mean square successive difference</article-title>. <source>Ann. Math. Stat.</source>
<volume>12</volume>, <fpage>153</fpage>–<lpage>162</lpage>. <pub-id pub-id-type="doi">10.1214/aoms/1177731746</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nomi</surname><given-names>J. S.</given-names></name><name><surname>Bolt</surname><given-names>T. S.</given-names></name><name><surname>Ezie</surname><given-names>C. E. C.</given-names></name><name><surname>Uddin</surname><given-names>L. Q.</given-names></name><name><surname>Heller</surname><given-names>A. S.</given-names></name></person-group> (<year>2017</year>). <article-title>Moment-to-moment BOLD signal variability reflects regional changes in neural flexibility across the lifespan</article-title>. <source>J. Neurosci.</source>
<volume>37</volume>, <fpage>5539</fpage>–<lpage>5548</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3408-16.2017</pub-id><?supplied-pmid 28473644?><pub-id pub-id-type="pmid">28473644</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pnevmatikakis</surname><given-names>E. A.</given-names></name><name><surname>Giovannucci</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>NoRMCorre: an online algorithm for piecewise rigid motion correction of calcium imaging data</article-title>. <source>J. Neurosci. Methods</source>
<volume>291</volume>, <fpage>83</fpage>–<lpage>94</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.07.031</pub-id><?supplied-pmid 28782629?><pub-id pub-id-type="pmid">28782629</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rusakov</surname><given-names>D. A.</given-names></name><name><surname>Zheng</surname><given-names>K.</given-names></name><name><surname>Henneberger</surname><given-names>C.</given-names></name></person-group> (<year>2011</year>). <article-title>Astrocytes as regulators of synaptic function: a quest for the Ca<sup>2+</sup> master key</article-title>. <source>Neuroscientist</source>
<volume>17</volume>, <fpage>513</fpage>–<lpage>523</lpage>. <pub-id pub-id-type="doi">10.1177/1073858410387304</pub-id><?supplied-pmid 21536839?><pub-id pub-id-type="pmid">21536839</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schindelin</surname><given-names>J.</given-names></name><name><surname>Arganda-Carreras</surname><given-names>I.</given-names></name><name><surname>Frise</surname><given-names>E.</given-names></name><name><surname>Kaynig</surname><given-names>V.</given-names></name><name><surname>Longair</surname><given-names>M.</given-names></name><name><surname>Pietzsch</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nat. Methods</source><volume>9</volume>, <fpage>676</fpage>–<lpage>682</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id><?supplied-pmid 22743772?><pub-id pub-id-type="pmid">22743772</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>C. A.</given-names></name><name><surname>Rasband</surname><given-names>W. S.</given-names></name><name><surname>Eliceiri</surname><given-names>K. W.</given-names></name></person-group> (<year>2012</year>). <article-title>NIH image to imagej: 25 years of image analysis</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>671</fpage>–<lpage>675</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.2089</pub-id><?supplied-pmid 22930834?><pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semyanov</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Spatiotemporal pattern of calcium activity in astrocytic network</article-title>. <source>Cell Calcium</source>
<volume>78</volume>, <fpage>15</fpage>–<lpage>25</lpage>. <pub-id pub-id-type="doi">10.1016/j.ceca.2018.12.007</pub-id><?supplied-pmid 30579813?><pub-id pub-id-type="pmid">30579813</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semyanov</surname><given-names>A.</given-names></name><name><surname>Henneberger</surname><given-names>C.</given-names></name><name><surname>Agarwal</surname><given-names>A.</given-names></name></person-group> (<year>2020</year>). <article-title>Making sense of astrocytic calcium signals—from acquisition to interpretation</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>21</volume>, <fpage>551</fpage>–<lpage>564</lpage>. <pub-id pub-id-type="doi">10.1038/s41583-020-0361-8</pub-id><?supplied-pmid 32873937?><pub-id pub-id-type="pmid">32873937</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shigetomi</surname><given-names>E.</given-names></name><name><surname>Patel</surname><given-names>S.</given-names></name><name><surname>Khakh</surname><given-names>B. S.</given-names></name></person-group> (<year>2016</year>). <article-title>Probing the complexities of astrocyte calcium signaling</article-title>. <source>Trends Cell Biol.</source>
<volume>26</volume>, <fpage>300</fpage>–<lpage>312</lpage>. <pub-id pub-id-type="doi">10.1016/j.tcb.2016.01.003</pub-id><?supplied-pmid 26896246?><pub-id pub-id-type="pmid">26896246</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>R.</given-names></name><name><surname>Huang</surname><given-names>B. S.</given-names></name><name><surname>Venugopal</surname><given-names>S.</given-names></name><name><surname>Johnston</surname><given-names>A. D.</given-names></name><name><surname>Chai</surname><given-names>H.</given-names></name><name><surname>Zeng</surname><given-names>H.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>Ca<sup>2+</sup> signaling in astrocytes from Ip3r2(−/−) mice in brain slices and during startle responses in vivo</article-title>. <source>Nat. Neurosci.</source><volume>18</volume>, <fpage>708</fpage>–<lpage>717</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4001</pub-id><?supplied-pmid 25894291?><pub-id pub-id-type="pmid">25894291</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stobart</surname><given-names>J. L.</given-names></name><name><surname>Ferrari</surname><given-names>K. D.</given-names></name><name><surname>Barrett</surname><given-names>M. J. P.</given-names></name><name><surname>Glück</surname><given-names>C.</given-names></name><name><surname>Stobart</surname><given-names>M. J.</given-names></name><name><surname>Zuend</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Cortical circuit activity evokes rapid astrocyte calcium signals on a similar timescale to neurons</article-title>. <source>Neuron</source><volume>98</volume>, <fpage>726</fpage>–<lpage>735</lpage>.e4.<pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.050</pub-id><?supplied-pmid 29706581?><pub-id pub-id-type="pmid">29706581</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thrane</surname><given-names>A. S.</given-names></name><name><surname>Rangroo Thrane</surname><given-names>V.</given-names></name><name><surname>Zeppenfeld</surname><given-names>D.</given-names></name><name><surname>Lou</surname><given-names>N.</given-names></name><name><surname>Xu</surname><given-names>Q.</given-names></name><name><surname>Nagelhus</surname><given-names>E. A.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>General anesthesia selectively disrupts astrocyte calcium signaling in the awake mouse cortex</article-title>. <source>Proc. Natl. Acad. Sci. U S A</source><volume>109</volume>, <fpage>18974</fpage>–<lpage>18979</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1209448109</pub-id><?supplied-pmid 23112168?><pub-id pub-id-type="pmid">23112168</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verkhratsky</surname><given-names>A.</given-names></name><name><surname>Parpura</surname><given-names>V.</given-names></name></person-group> (<year>2013</year>). “<article-title>Astroglial calcium signaling and calcium waves</article-title>,” in <source>Gap Junctions in the Brain</source>, ed E. Dere (Elsevier, Inc.), <fpage>51</fpage>–<lpage>68</lpage>. <pub-id pub-id-type="doi">10.1016/b978-0-12-415901-3.00004-9</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>DelRosso</surname><given-names>N. V.</given-names></name><name><surname>Vaidyanathan</surname><given-names>T. V.</given-names></name><name><surname>Cahill</surname><given-names>M. K.</given-names></name><name><surname>Reitman</surname><given-names>M. E.</given-names></name><name><surname>Pittolo</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Accurate quantification of astrocyte and neurotransmitter fluorescence dynamics for single-cell and population-level physiology</article-title>. <source>Nat. Neurosci.</source><volume>22</volume>, <fpage>1936</fpage>–<lpage>1944</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-019-0492-2</pub-id><?supplied-pmid 31570865?><pub-id pub-id-type="pmid">31570865</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y.-W.</given-names></name><name><surname>Tang</surname><given-names>X.</given-names></name><name><surname>Arizono</surname><given-names>M.</given-names></name><name><surname>Bannai</surname><given-names>H.</given-names></name><name><surname>Shih</surname><given-names>P.-Y.</given-names></name><name><surname>Dembitskaya</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Spatiotemporal calcium dynamics in single astrocytes and its modulation by neuronal activity</article-title>. <source>Cell Calcium</source><volume>55</volume>, <fpage>119</fpage>–<lpage>129</lpage>. <pub-id pub-id-type="doi">10.1016/j.ceca.2013.12.006</pub-id><?supplied-pmid 24484772?><pub-id pub-id-type="pmid">24484772</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
