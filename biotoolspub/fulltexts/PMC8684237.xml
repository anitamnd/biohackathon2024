<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Med Inform Decis Mak</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Med Inform Decis Mak</journal-id>
    <journal-title-group>
      <journal-title>BMC Medical Informatics and Decision Making</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1472-6947</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8684237</article-id>
    <article-id pub-id-type="publisher-id">1706</article-id>
    <article-id pub-id-type="doi">10.1186/s12911-021-01706-4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MedTAG: a portable and customizable annotation tool for biomedical documents</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Giachelle</surname>
          <given-names>Fabio</given-names>
        </name>
        <address>
          <email>fabio.giachelle@unipd.it</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Irrera</surname>
          <given-names>Ornella</given-names>
        </name>
        <address>
          <email>ornella.irrera@unipd.it</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4970-4554</contrib-id>
        <name>
          <surname>Silvello</surname>
          <given-names>Gianmaria</given-names>
        </name>
        <address>
          <email>gianmaria.silvello@unipd.it</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.5608.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1757 3470</institution-id><institution>Department of Information Engineering, </institution><institution>University of Padua, </institution></institution-wrap>Padua, Italy </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>21</volume>
    <elocation-id>352</elocation-id>
    <history>
      <date date-type="received">
        <day>27</day>
        <month>5</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>1</day>
        <month>12</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Semantic annotators and <italic>Natural Language Processing (NLP)</italic> methods for <italic>Named Entity Recognition and Linking (NER+L)</italic> require plenty of training and test data, especially in the biomedical domain. Despite the abundance of unstructured biomedical data, the lack of richly annotated biomedical datasets poses hindrances to the further development of NER+L algorithms for any effective secondary use. In addition, manual annotation of biomedical documents performed by physicians and experts is a costly and time-consuming task. To support, organize and speed up the annotation process, we introduce MedTAG, a collaborative biomedical annotation tool that is open-source, platform-independent, and free to use/distribute.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We present the main features of MedTAG and how it has been employed in the histopathology domain by physicians and experts to annotate more than seven thousand clinical reports manually. We compare MedTAG with a set of well-established biomedical annotation tools, including BioQRator, ezTag, MyMiner, and tagtog, comparing their pros and cons with those of MedTag. We highlight that MedTAG is one of the very few open-source tools provided with an open license and a straightforward installation procedure supporting cross-platform use.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">MedTAG has been designed according to five requirements (i.e. available, distributable, installable, workable and schematic) defined in a recent extensive review of manual annotation tools. Moreover, MedTAG satisfies 20 over 22 criteria specified in the same study.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Biomedical annotation tools</kwd>
      <kwd>Entity extraction</kwd>
      <kwd>eHealth</kwd>
      <kwd>Digital health</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010662</institution-id>
            <institution>H2020 Excellent Science</institution>
          </institution-wrap>
        </funding-source>
        <award-id>825292</award-id>
        <principal-award-recipient>
          <name>
            <surname>Silvello</surname>
            <given-names>Gianmaria</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par17">In the last decades, exascale volumes of biomedical data have been produced, where the vast majority is available as unstructured text [<xref ref-type="bibr" rid="CR1">1</xref>]. Health-care professionals traditionally rely on free-text reporting for communicating patient information such as diagnosis and treatments. For instance, narrative clinical reports are usually conceived as free-text reports, which are human-readable but not machine-readable. This brings interoperability issues and limitations to effective secondary reuse of data, essential for medical decision making and support. In order to process the vast amount of unstructured biomedical data from clinical reports and <italic>Electronic Health Records (EHRs)</italic>, <italic>Information Extraction (IE)</italic> algorithms and NLP techniques have been developed and are currently exploited.</p>
    <p id="Par18">To this aim, significant efforts have been dedicated to applying <italic>Named Entity Recognition and Linking</italic> (NER+L) methods for entity extraction and semantic annotation [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR6">6</xref>]. Semantic annotation is the NLP task of identifying the type of an entity and uniquely linking it to a corresponding knowledge base entry [<xref ref-type="bibr" rid="CR7">7</xref>]; it leverages both text-processing and <italic>Machine Learning (ML)</italic> techniques to tackle biomedical information extraction challenges such as terms and abbreviations disambiguation. Furthermore, semantic annotation tasks based on ML methods are often carried out in a supervised context where large-scale training and test annotated corpora are required. Moreover, even in an unsupervised context, NER+L models require annotated datasets for evaluation purposes. However, the lack of manually annotated biomedical datasets poses hindrances to the further development of NER+L systems. In addition, most of the training data available for the biomedical domain covers mainly common entity types (e.g., drugs, genes, and diseases) [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR11">11</xref>], thus the coverage of some biomedical sub-domains is limited. For these reasons, several attempts to create large annotated biomedical corpora have been conducted [<xref ref-type="bibr" rid="CR12">12</xref>–<xref ref-type="bibr" rid="CR19">19</xref>].</p>
    <p id="Par19">To achieve the high-quality standards required for the biomedical domain, the annotation process demands human-expert supervision. Nevertheless, manual annotation of large datasets is an expensive and time-consuming task requiring plenty of expert annotators with extensive experience in biomedical contents. To support, organize and speed up the annotation process, several annotation tools have been developed [<xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR33">33</xref>]. However the biomedical domain is particularly challenging, since biomedical texts contain mentions that are burdensome for semantic annotation, such as the abbreviations of genes and proteins. Moreover, the specificity of some biomedical sub-domains, such as histopathology, requires fine-grained annotation systems designed to be customizable according to physicians’ and experts’ needs.<fig id="Fig1"><label>Fig. 1</label><caption><p>Overview of annotation tools and their functionalities. The annotation tools considered come from a recent extensive review of tools for manual annotation of documents [<xref ref-type="bibr" rid="CR34">34</xref>]. In addition, we consider also TeamTat [<xref ref-type="bibr" rid="CR35">35</xref>] and INCEpTION [<xref ref-type="bibr" rid="CR36">36</xref>] and report our judgements. The annotation tools are assessed with 22 criteria, defined in the latter review study, among three categories: <italic>Data</italic> (D), <italic>Functional</italic> (F) and <italic>Technical</italic> (T). The fulfillment of each criterion is indicated with a color in a three levels scale: white (feature absent or not met), light blue (feature partially satisfied), blue (feature satisfied)</p></caption><graphic xlink:href="12911_2021_1706_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par20">In recent years, several biomedical annotation tools have been released [<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR37">37</xref>]. Motivation for the wide variety of biomedical annotation tools available could be the necessity of domain-specific functionalities that might be only partially supported or not by other well-established tools. Hence, some tools could be handier than others for a specific task of interest.</p>
    <p id="Par21">A recent extensive review of both general-purpose and biomedical annotation tools provides a detailed comparison of state-of-the-art annotation tools [<xref ref-type="bibr" rid="CR34">34</xref>]. Some of the common limitations of the available tools are, for instance, the non-availability of the source code or the raised exceptions and failures during the installation process. In addition, even the most popular annotation tools present drawbacks such as a burdensome installation procedure or the lack of documentation. As an example, WebAnno [<xref ref-type="bibr" rid="CR38">38</xref>] and brat [<xref ref-type="bibr" rid="CR39">39</xref>] are popular general-purpose annotation tools with a comprehensive set of functionalities, but their installation process is rather complex for the not technology-savvy users. INCEpTION [<xref ref-type="bibr" rid="CR36">36</xref>, <xref ref-type="bibr" rid="CR40">40</xref>] is a more recent general-purpose annotation tool from the authors of WebAnno [<xref ref-type="bibr" rid="CR38">38</xref>], that mitigates this issue with a web service enabling the users to work online. Moreover, general-purpose annotation tools often do not fulfill the needs of biomedical experts; thus, domain-specific solutions are preferable for this field. Even though brat [<xref ref-type="bibr" rid="CR39">39</xref>] has been used in several biomedical projects [<xref ref-type="bibr" rid="CR41">41</xref>–<xref ref-type="bibr" rid="CR45">45</xref>], it is designed for general-purpose annotation, thus it provides additional features that are not suited for physicians and experts of the biomedical domain. Since the annotation process is a time-consuming task, biomedical annotation tools should be designed to offer an intuitive streamlined interface that minimizes redundant features, fulfill domain-specific requirements and reduce the annotators workload.</p>
    <p id="Par22">For the in-depth analysis, we focus on the tools specifically designed for biomedical annotations: BioQRator [<xref ref-type="bibr" rid="CR25">25</xref>], ezTag [<xref ref-type="bibr" rid="CR26">26</xref>], TeamTat [<xref ref-type="bibr" rid="CR35">35</xref>], MyMiner [<xref ref-type="bibr" rid="CR27">27</xref>] and tagtog [<xref ref-type="bibr" rid="CR28">28</xref>]. Additionally, we also consider two general-purpose annotation tools that are used by the biomedical community as well - i.e., brat [<xref ref-type="bibr" rid="CR39">39</xref>] and INCEpTION [<xref ref-type="bibr" rid="CR36">36</xref>].</p>
    <p id="Par23">In Fig. <xref rid="Fig1" ref-type="fig">1</xref>, we can see a heat-map reporting on the functionalities of the current text annotation tools as analyzed by a very recent extensive survey [<xref ref-type="bibr" rid="CR34">34</xref>]. The provided heat-map is to be used as a visual summary of the features provided by each annotation tool.<xref ref-type="fn" rid="Fn1">1</xref> In particular, the heat-map considers a list of 15 annotation tools selected according to five major requirements: (i) <bold>Available</bold>: the executable and project source code should be available; (ii) <bold>Web-based</bold>: the tool should be provided as an online web application or as an installable application running in a web browser container; (iii) <bold>Installable</bold>: the installation process should last two hours at most; (iv) <bold>Workable</bold>: it should work for hands-on experiments; (v) <bold>Schematic</bold>: users should be able to configure the annotation schema at will. Hence, several biomedical annotation tools such as Argo [<xref ref-type="bibr" rid="CR29">29</xref>], Egas [<xref ref-type="bibr" rid="CR24">24</xref>], Marky [<xref ref-type="bibr" rid="CR30">30</xref>], ODIN [<xref ref-type="bibr" rid="CR31">31</xref>], Pubtator [<xref ref-type="bibr" rid="CR32">32</xref>] and Textpresso [<xref ref-type="bibr" rid="CR33">33</xref>] are not considered since they do not satisfy one or more of the previous five requirements.</p>
    <p id="Par24">Moreover, the selected annotation tools are compared according to a set of 22 criteria chosen among the original 26 criteria of the same study [<xref ref-type="bibr" rid="CR34">34</xref>]. In particular, the criteria are grouped in four categories: (i) <italic>Data</italic>, (ii) <italic>Functional</italic>, (iii) <italic>Publication</italic> and (iv) <italic>Technical</italic>. We excluded the publication criteria (i.e., the four missing criteria) since we are interested in comparing the facilities and functionalities provided by the different tools and not on their coverage in scientific publications.</p>
    <p id="Par25">The <italic>data</italic> criteria are: (D1) format of the schema – whether it is configurable or uses standard formats (e.g. JSON, XML); (D2) input format for documents – whether the input documents are based on standard formats (e.g. JSON, XML) and (D3) output format for annotations – whether the annotations are based on standard formats (e.g. JSON, XML).</p>
    <p id="Par26">The <italic>functionality</italic> criteria are: (F1) support for overlapping mentions/annotations; (F2) support for document-level annotations – users can specify the labels that apply to the whole document (not just for a textual portion); (F3) support for relationship annotations; (F4) support for ontologies and terminologies (i.e. a procedure to import terminology resources is provided); (F5) Support for built-in predictions and active learning from pre-annotated documents; (F6) Integration with PubMed – users can annotate PubMed abstracts just providing a list of PubMed ids; (F7) Suitability for full texts (i.e., tool capable of displaying long text correctly, without compromising readability); (F8) Allowance for saving documents partially (i.e., holding annotations partially to later continue the annotation process); (F9) Ability to highlight parts of the text; (F10) Support for users and teams; (F11) Support for <italic>Inter-Annotator Agreement (IAA)</italic>; (F12) Data privacy (i.e., can be used for private data); (F13) multilingual support (i.e., annotating multilingual documents, that might contain special characters).</p>
    <p id="Par27">The <italic>technical</italic> criteria are (T1) Date of the last version – whether the last version (or commit) has been released within the past five years; (T2) availability of the source code – whether the source code is available in version control platforms; (T3) online availability for use; (T4) easiness of installation – i.e., available online (no installation required) or easy and fast to install (up to half-hour time); (T6) license allowing modification and redistribution; (T7) free of charge. We excluded T5 (quality of documentation) from the technical criteria since we are interested in objective and assessable criteria.</p>
    <p id="Par28">Figure <xref rid="Fig1" ref-type="fig">1</xref> shows that several tools lack one of the following functionalities: (i) document-level annotation; (ii) ontology and terminology resources support; (iii) support for multi-label annotation; and (iv) support for collaborative annotations with users and teams. Moreover, seven over the seventeen selected tools are provided through a license that limits modifications and redistribution.</p>
    <p id="Par29">To mitigate this, we introduce MedTAG, a customizable, collaborative, web-based annotation tool provided as a docker container to enable cross-platform support and quick and easy installation. MedTag provides a step-by-step schema configuration, by which the project/team leader can specify in detail which document parts or document fields can be annotated. We designed MedTAG according to the five primary annotation tools’ requirements previously discussed. Besides, we determined the feature coverage provided by MedTAG concerning the former criteria. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows that MedTAG satisfies most of the criteria, having a feature coverage of 20 criteria over 22. The rest of the criteria currently not covered by MedTAG, such as the relationship annotations and active learning capabilities, are planned as future work.</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <p id="Par30">MedTAG has been designed to be flexible and customizable, so that users can easily install it and configure the annotation schema at will. Hence, MedTAG is not limited to a specific (sub-)domain (e.g., histopathology), but it can be seamlessly used in different biomedical sub-domains. The key MedTAG functionalities are: (i) a web-based collaborative annotation platform with support for users and roles; (ii) a user-friendly interface with support for click-away mention annotation, mentions highlighting in different colors and automatic saving every time an action is performed; (iii) sorting of documents based on the lexicographic order or the “unannotated-first” policy; (iv) support for mobile devices; (v) download of annotations in several formats (i.e., BioC/JSON, BioC/XML, CSV, JSON); (vi) support for multi-label annotation; (vii) support for document-level annotations; (viii) multilingual support; (ix) support for ontologies/concepts to use for the annotation process; (x) support for IAA; (xi) integration with PubMed; (xii) support for automatic built-in predictions; (xiii) support for schema configuration, so that users can easily import data (i.e., documents, labels and concepts), as CSV files, and choose which document fields to annotate. In order to achieve automatic annotations and built-in predictions, we integrated the <italic>Semantic Knowledge Extractor Tool (SKET)</italic><xref ref-type="fn" rid="Fn2">2</xref> in MedTAG. Note that the support for built-in predictions is currently limited to three cancer use-cases (i.e., cervix, colon, and lung cancer). Nevertheless, we plan to extend the support for automatic built-in predictions also for other use-cases. General-purpose automatic annotation methods are of limited efficacy for the biomedical domain; nevertheless, the integration of SKET paves the road for the integration of other third-party libraries users may want to employ.</p>
    <p id="Par31">To exploit the concept linking functionality, MedTAG requires the admin user to specify, during the configuration phase, the CSV file containing all the concepts used for annotating the clinical reports. During the first configuration, the admin user is not defined yet, thus the configuration is handled by the <italic>Test</italic> user in <italic>Test mode</italic>, as described in the <italic>Installation and customization</italic> section. Figure <xref rid="Fig5" ref-type="fig">5</xref>.2 shows the configuration interface that allows the users to specify the CSV file for the concepts. Moreover, the users can choose whether to use the concepts of the ExaMode ontology<xref ref-type="fn" rid="Fn3">3</xref> (necessary for the automatic annotation module using SKET) or a set of concepts from a different ontology. Then, the concepts provided in the CSV file populates the MedTAG database and are integrated in the drop-down menu available to the user to select the concepts. Every concept defined in the provided CSV is uniquely identified with a concept IRI. Thus, users could use concepts defined in different ontologies at the same time. Since the CSV file with the concepts for the annotation process is provided by the admin user, the coherence of the data (e.g., the same concept mapping to more than one IRI from different ontologies) should be checked and enforced by the admin herself. Nevertheless, in the case of the same entity mapping to different ontologies, MedTAG differentiates the concepts in the user interface based on the IRIs and other concept information such as use-cases and semantic areas. Thus, users have the means to disambiguate between potentially similar concepts.</p>
    <p id="Par32">MedTAG source code and the documentation are publicly available at this URL: <ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core">https://github.com/MedTAG/medtag-core</ext-link>.</p>
    <sec id="Sec3">
      <title>Architecture</title>
      <p id="Par33">Figure <xref rid="Fig2" ref-type="fig">2</xref> illustrates the MedTAG architecture, which consists of three logic layers (i.e., <italic>Data</italic>, <italic>Business</italic> and <italic>Presentation</italic> layer). The data layer concerns information and data management; it consists of two main relational databases realized with PostgreSQL, namely, the <italic>MedTAG data</italic> and the <italic>Log data</italic> databases. The former contains documents, entity concepts/labels, and the relations among them. The latter takes care of logging data such as user-provided information about issues with the documents to be annotated. The business layer controls the whole information flow as the information is displayed in the web interface and stored in the MedTAG database. It consists of two business units, the business logic, and the REST APIs end-point. The first one consists of Python routines and a controller that invokes the proper routine based on the received request. The second one is the back-end entry-point of MedTAG; it handles all the user requests from the web interface, invoking the business logic controller and returning its result to the front-end. The presentation layer provides the MedTAG front-end; it consists of a web interface to navigate the documents, annotate them and download the annotations in different formats (i.e., BioC/JSON, BioC/XML, CSV, and JSON).</p>
      <p id="Par34">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the technologies adopted for each logic layer: (i) the front-end interface built with React.js,<xref ref-type="fn" rid="Fn4">4</xref> HTML5 and CSS3; (ii) the back-end for web API and services built with the Python web framework Django<xref ref-type="fn" rid="Fn5">5</xref>; (iii) the <italic>MedTAG data</italic> relational database implemented using PostgreSQL.</p>
      <p id="Par35">Due to the multitude of architecture components, manually installing and configuring each one would be cumbersome and error-prone. To mitigate this, we provide a fast and reliable installation by distributing MedTAG as a docker container.<fig id="Fig2"><label>Fig. 2</label><caption><p>MedTAG Architecture. The data layer comprises two relational databases, namely, <italic>MedTAG data</italic> and <italic>Log data</italic> to store all the information concerning the annotation process (e.g., concepts, labels, reports, users and their annotations) and logging data such as notifications of malformatted clinical reports. The business layer comprises two business units: <italic>Business logic</italic> and <italic>REST API</italic> which jointly control the whole information flow from the front-end to the database and vice-versa. The presentation layer provides the MedTAG front-end, a web interface allowing users to annotate medical reports and download their ground truths</p></caption><graphic xlink:href="12911_2021_1706_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Installation and customization</title>
      <p id="Par36">Since MedTAG is provided as a Docker container, both <italic>docker</italic><xref ref-type="fn" rid="Fn6">6</xref> and <italic>docker-compose</italic><xref ref-type="fn" rid="Fn7">7</xref> are required. The detailed installation procedure is described at <ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core/tree/main#installation">https://github.com/MedTAG/medtag-core/tree/main#installation</ext-link>. We can summarize the MedTAG installation in three steps: <list list-type="order"><list-item><p id="Par37">Check the Docker daemon - i.e., dockerd - is up and running.</p></list-item><list-item><p id="Par38">Download the MedTAG_Dockerized<xref ref-type="fn" rid="Fn8">8</xref> folder from the medtag-core<xref ref-type="fn" rid="Fn9">9</xref> repository, or clone it.</p></list-item><list-item><p id="Par39">Open the MedTAG_Dockerized project folder and, on a new terminal session, type docker-compose up.</p></list-item></list>Once the installation process has been completed, MedTAG is available on your browser at <ext-link ext-link-type="uri" xlink:href="http://0.0.0.0:8000">http://0.0.0.0:8000</ext-link>. At this stage, users can access MedTAG only in <italic>Test mode</italic> – i.e., by using the pre-loaded documents. The pre-loaded documents for the test mode are taken from the histopathology domain because we chose this domain as a use case for introducing and testing MedTAG functionalities.</p>
      <p id="Par40">Users can log into MedTAG and test it with the preloaded medical reports using <italic>Test</italic> as username and password.</p>
      <p id="Par41">To customize MedTAG, the users need to follow three steps: (i) open the menu and click on <italic>Configure</italic>, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>; (ii) follow the instructions of the guided procedure – i.e., users are asked to provide both the admin user credentials and three CSV files: concepts_file, labels_file and reports_file, as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. The users are provided with CSV templates and with examples containing real data to speed-up the data preparation procedure; (iii) choose which document fields to display and annotate as shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>; the <italic>Check</italic> button activates the file compliance procedures that will produce some state messages in different colors to inform the user about whether the CSV files provided are well formatted or not. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the configuration interface that allows the users to specify whether to use the ExaMode concepts (indicated with number two) and labels (indicated with number three) or to upload a new set of concepts from different ontologies. The latter are necessary in case users want to take advantage of automatic annotation features. In addition, users can choose whether to annotate custom documents or PubMed abstracts and titles. In the first case, users are required to provide all the reports to annotate as a CSV file, that is, reports_file. Then, users can choose the report fields to annotate at will. In the second case, users have to specify a list of PubMed identifiers as a CSV file. Then, users can annotate both abstract and title of each PubMed article specified.</p>
      <p id="Par42">The detailed customization procedure is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core#customize-medtag">https://github.com/MedTAG/medtag-core#customize-medtag</ext-link>.<fig id="Fig3"><label>Fig. 3</label><caption><p>MedTAG sidebar provides the <italic>Configure</italic> option, indicated by the orange arrow, to set up a new custom configuration</p></caption><graphic xlink:href="12911_2021_1706_Fig3_HTML" id="MO3"/></fig><fig id="Fig4"><label>Fig. 4</label><caption><p>MedTAG new configuration interface allows the user to save the current data before creating a new configuration. To guide the user in providing the new configuration files needed (i.e. reports/documents, labels and concepts), MedTAG provides both example and template files. In particular, users can use the example files to test MedTAG without providing their own data. Instead, users can use the template files as a reference to structure their own configuration files</p></caption><graphic xlink:href="12911_2021_1706_Fig4_HTML" id="MO4"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>MedTAG main interface for data configuration. Users can provide their own CSV files for the reports/documents to annotate and the concepts and labels to use for the annotation process. Moreover, MedTAG detects automatically the document fields and allows users to specify which of them to annotate and/or display in the interface, as shown in the orange box (1)</p></caption><graphic xlink:href="12911_2021_1706_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>User interface and interaction</title>
      <p id="Par43">The MedTAG web interface has been developed based on the positive feedback received from physicians and experts in the digital pathology domain where an instance of MedTAG - i.e., ExaTAG - has been released. Figure <xref rid="Fig6" ref-type="fig">6</xref> shows the main MedTag web-interface for the annotation of medical documents or reports. On the top of the web page, there is the header section with the current MedTAG configuration: (i) the clinical case (e.g., Colon cancer); (ii) the report language (e.g., English); (iii) the hospital/institute which provided the report’s dataset (e.g., “default_hospital” identifies the institute which provided the datasets of reports pre-loaded in MedTAG in test mode) and (iv) the annotation mode (i.e., manual or automatic) used for the annotation process. In addition, the menu button (left-side) and the user section (right-side) are included in the header as well. It is worth noting that when the automatic annotation mode is active the users visualize the automatic annotations generated by the built-in annotation module. Any user edit concerning the automatic annotations is also replicated in the user profile, available for further edits in manual annotation mode. The user section shows the current username along with the <italic>Logout</italic> button. Below the header, the interface body is divided into two sections: the diagnostic report and the annotation section. The first one (left-side) shows the information regarding the textual document, that in the case of a medical report may contain the diagnosis and the patient’s information. Users can navigate between documents using either the keyboard arrows or the <italic>next</italic> and <italic>previous</italic> buttons. The annotation section (right side) shows the information concerning annotation labels, ontological concepts and the mentions identified in the selected document.<fig id="Fig6"><label>Fig. 6</label><caption><p>MedTAG main interface in test mode with default configuration: clinical case set to “Colon cancer”, reports’ language set to English, reports’ institute/hospital set to “default_hospital” (the real name has been anonymized) and the annotation mode set to manual. The annotation type active is the <italic>Labels</italic> one. Three labels have been checked: (i) <italic>Cancer</italic>; (ii) <italic>Adenomatous polyp - low grade dysplasia</italic> and (iii) <italic>Hyperplastic polyp</italic></p></caption><graphic xlink:href="12911_2021_1706_Fig6_HTML" id="MO6"/></fig><fig id="Fig7"><label>Fig. 7</label><caption><p>MedTAG main interface in test mode with default configuration: clinical case set to “Colon cancer”, reports’ language set to English, reports’ institute/hospital set to “default_hospital” (the real name has been anonymized) and the annotation mode set to manual. The annotation type active is the <italic>Linking</italic> one. Three mentions have been identified and linked to the corresponding concepts: (i) <italic>hyperplastic adenomatous polyp</italic> is linked to <italic>Colon Hyperplastic Polyp</italic>; (ii) <italic>mild dysplasia</italic> is linked to <italic>Mild Colon Dysplasia</italic>; and (iii) <italic>tubular adenoma</italic> is linked to <italic>Colon Tubular Adenoma</italic></p></caption><graphic xlink:href="12911_2021_1706_Fig7_HTML" id="MO7"/></fig></p>
      <p id="Par44">MedTag allows the users to use four different annotation types that can be activated alternatively by clicking on the corresponding buttons: (i) <italic>Labels</italic> is a form of document-level annotation where the reports are classified into predefined categories, (ii) <italic>Mentions</italic> where the user selects words in the text of the reports, (iii) <italic>Linking</italic> where the identified mentions are linked to ontological concepts, and (iv) <italic>Concepts</italic>, another form of document-level annotation, where the reports are annotated with ontological concepts not strictly tied to specific mentions.</p>
      <p id="Par45">In Fig. <xref rid="Fig6" ref-type="fig">6</xref> the <italic>Labels</italic> action is activated. We can notice three selected labels: “Cancer”, “Adenomatous polyp - low grade dysplasia” and “Hyperplastic polyp”. The labels describe properties or attributes that apply to the whole document, such as the presence or the absence of cancer in the diagnosis of a clinical report. The set of labels used for the document-level annotation process, are provided by the user during the configuration phase, as previously discussed.</p>
      <p id="Par46">In Fig. <xref rid="Fig7" ref-type="fig">7</xref> the <italic>Linking</italic> action is activated. We can see three selected multi-word mentions in the text: “tubular adenoma”, “hyperplastic adenomatous polyp’ and “mild dysplasia”. These mentions are linked to concepts taken from an histopathological ontology: (i) <italic>hyperplastic adenomatous polyp</italic> is linked to <italic>Colon Hyperplastic Polyp</italic>; (ii) <italic>mild dysplasia</italic> is linked to <italic>Mild Colon Dysplasia</italic>; and (iii) <italic>tubular adenoma</italic> is linked to <italic>Colon Tubular Adenoma</italic>.</p>
      <p id="Par47">The ontological concepts linked to the mentions can be selected via a drop-down menu (that, in turn, can be divided into semantic areas) or manually typed in a text field; in the latter case, the user is aided by auto-completion facilities.</p>
      <p id="Par48">To add a new mention, a user can click on any text token. After clicking on a text token, it gets highlighted with a new color, and the neighbor tokens turn highlighted as well, meaning that they could be selected as part of the current mention. All the mentions are highlighted with a different color in the document text and in the list of mentions for fast detection. The users can add, edit and delete the associations at will. Moreover, every time an action is performed, all the concerning information is asynchronously saved in the database; there is also manual saving via the <italic>Save</italic> button. Users can delete (after confirmation) all the annotations related to the current action button selected by clicking on the <italic>Clear</italic> button.</p>
      <p id="Par49">MedTAG enables the team members to collaborate during the annotation process. In particular, users can see anytime the annotations done by other team members for each clinical report by clicking on the button (3) of Fig. <xref rid="Fig6" ref-type="fig">6</xref>. This feature is handy in case of annotation uncertainty (e.g., which concepts to associate to an identified mention). To attain high-quality annotations, users can take advantage of the expertise and work other team members have previously done. In addition, users can visualize the automatic annotations made by the robot user - i.e., the automatic annotation module SKET - by clicking on button (2) of Fig. <xref rid="Fig6" ref-type="fig">6</xref>. Moreover, the users can consult and edit the automatic annotations so that new edits are automatically copied in the user profiles for further modifications in manual annotation mode. Hence, users can take advantage of automated annotation facilities to reduce the annotation workload. Moreover, the admin can oversee the overall annotation process from the <italic>Team members’ statistics</italic> section of the control panel. This section provides the admin user an overview of the annotation work carried out by each team member, providing information such as the number and the percentage of annotated reports for each use-case and annotation type. Hence, the admin can make decisions to coordinate the work of team members and keep track of the advancements in the annotation process.</p>
      <p id="Par50">Finally, users can download their annotations in different formats (i.e., BioC/JSON, BioC/XML, CSV and JSON), by clicking on the <italic>Download</italic> button.</p>
      <p id="Par51">Overall, a detailed graphical tutorial is always available to the users to learn how to use MedTAG; the <italic>Tutorial</italic> link is provided in the sidebar, as shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>.<fig id="Fig8"><label>Fig. 8</label><caption><p>MedTAG tutorial interface. To reach the tutorial section, users can click on the <italic>Tutorial</italic> link in the sidebar, indicated by the orange arrow</p></caption><graphic xlink:href="12911_2021_1706_Fig8_HTML" id="MO8"/></fig><fig id="Fig9"><label>Fig. 9</label><caption><p>MedTAG control panel concerning the reports’ statistics. The reports are organized in an interactive table enabling the admin user to: (i) access report data; (ii) delete one or more reports; (iii) download report data including manual and automatic annotations and (iv) access the information concerning IAA and manage the majority vote procedure</p></caption><graphic xlink:href="12911_2021_1706_Fig9_HTML" id="MO9"/></fig><fig id="Fig10"><label>Fig. 10</label><caption><p>MedTAG control panel concerning the team members’ statistics. The ring charts report the annotation work carried out by each team member, so that the admin can keep track of the advancements regarding the whole annotation process</p></caption><graphic xlink:href="12911_2021_1706_Fig10_HTML" id="MO10"/></fig><fig id="Fig11"><label>Fig. 11</label><caption><p>MedTAG <italic>My Statistics</italic> panel, providing information about the user annotation work in terms of documents annotated for each use-case</p></caption><graphic xlink:href="12911_2021_1706_Fig11_HTML" id="MO11"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>MedTAG control panel for statistics and Inter-Annotator Agreement (IAA)</title>
      <p id="Par52">MedTAG provides a unified interface that allows the admin user to access the annotation statistics (e.g., the number of users that annotated each report) and access the information concerning IAA for each report. It is worth noting that only the admin user can consult the statistics concerning the overall annotation process. Instead, other members can only access their statistics in the dedicated menu section <italic>My statistics</italic>. Figure <xref rid="Fig9" ref-type="fig">9</xref> shows the control panel information organized in a dynamic table, where the admin can search, access, and filter the reports according to a selection of columns filters. Moreover, the admin can choose anytime which columns to show by clicking on the <italic>Columns</italic> button. The last column provides the following action buttons:<list list-type="bullet"><list-item><p id="Par53"><italic>Delete</italic>: enables the admin user to remove the corresponding reports.</p></list-item><list-item><p id="Par54"><italic>Download</italic>: allows the admin user to download either the original annotations or the ones resulting from the majority vote procedure. Moreover, the admin user can also download the automatic annotations generated by the built-in prediction system. Several download options are provided, including the output file format, the annotation mode (i.e., manual or automatic) and type (i.e., <italic>Labels</italic>, <italic>Concepts</italic>, <italic>Mentions</italic> and <italic>Linking</italic>).</p></list-item><list-item><p id="Par55"><italic>Inspect statistics</italic>: allows the admin user to consult the report information as well as the statistics concerning the annotations of the selected report. The annotation statistics regards all the annotation types provided in MedTAG (i.e., <italic>Labels</italic>, <italic>Concepts</italic>, <italic>Mentions</italic> and <italic>Linking</italic>) and include the number of users that identified each label, mention or concept in the report. In addition to user annotations, the interface shows the automatic annotations highlighted in blue produced by the built-in prediction system.</p></list-item><list-item><p id="Par56"><italic>IAA and majority vote</italic>: allows the admin user to access the information concerning IAA for each report. Figure <xref rid="Fig12" ref-type="fig">12</xref> shows the pop-up modal by which the admin can specify the options for the majority vote procedure. The admin can choose from a drop-down menu which team members (annotators) to consider, as well as the annotation mode and type. The procedure returns only the annotations that achieved more than fifty percent of agreement among the annotators considered. Then, the admin can download the annotations resulting from the majority vote procedure, as shown in Fig. <xref rid="Fig13" ref-type="fig">13</xref>.</p></list-item></list>Figure <xref rid="Fig10" ref-type="fig">10</xref> shows the <italic>Team members’ statistics</italic> section of the control panel, which provides the information about the advancements in the annotation work for each team member. Access to this section is restricted to the admin user. The admin can overview the annotation work carried out for each use-case and annotation type using ring charts providing information about the number of annotated reports and the corresponding percentage out of the total. Moreover, Fig. <xref rid="Fig11" ref-type="fig">11</xref> shows that team members can keep track of their work by consulting the section <italic>My statistics</italic>, where other ring charts visually summarize the personal annotation statistics.<fig id="Fig12"><label>Fig. 12</label><caption><p>MedTAG majority vote interface. The admin can overview the selected report and choose the options of interest for the majority vote procedure, including: (i) the annotation mode; (ii) the annotation type and (iii) the team members (annotators) to consider</p></caption><graphic xlink:href="12911_2021_1706_Fig12_HTML" id="MO12"/></fig><fig id="Fig13"><label>Fig. 13</label><caption><p>MedTAG majority vote output for the <italic>Labels</italic> annotation type. The admin can visualize the annotations resulting from the majority vote procedure, together with the corresponding authors. In addition, the admin can download the annotations or change the current majority vote configuration</p></caption><graphic xlink:href="12911_2021_1706_Fig13_HTML" id="MO13"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec7">
    <title>Results and Discussion</title>
    <p id="Par57">MedTAG has been used to annotate diagnostic reports to produce both training and test annotated data. In particular, a specific instance of MedTAG (ExaTAG) has been used to generate more than seven thousand annotated reports and more than eight thousand annotations overall. ExaTAG<xref ref-type="fn" rid="Fn10">10</xref> is an instance of MedTAG tailored for the histopathology domain. By connecting to ExaTAG, users can try MedTAG functionalities with real (anonymized) clinical reports from the digital pathology domain without downloading and installing it. ExaTAG has been customized to meet the needs of the physicians and experts concerning three cancer use-cases (i.e., cervix, colon, and lung cancer) within the ExaMode H2020 EU project.<xref ref-type="fn" rid="Fn11">11</xref> Physicians and experts have used ExaTAG to annotate the diagnostic reports from two healthcare institutions, namely, the <italic>Azienda Ospedaliera Cannizzaro, Catania (Italy)</italic> and the <italic>Radboud University Medical Center, Nijmegen, (The Netherlands)</italic>. For the time being, ten annotators between physicians and experts have annotated thousands of medical reports in three languages (Dutch, English, and Italian). Table <xref rid="Tab1" ref-type="table">1</xref> reports some statistics about the manual annotation process conducted so far. Instead, Table <xref rid="Tab2" ref-type="table">2</xref> shows the number of automatic annotations done by SKET (i.e. the automatic annotation module) for each annotation type and use-case.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Number of diagnostic reports annotated per language and use-case</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Language</th><th align="left" colspan="4">Use-case</th></tr><tr><th align="left">Cervix cancer</th><th align="left">Colon cancer</th><th align="left">Lung cancer</th><th align="left">Total</th></tr></thead><tbody><tr><td align="left">Dutch</td><td align="left">–</td><td align="left">889</td><td align="left">–</td><td align="left">889</td></tr><tr><td align="left">English</td><td align="left">2361</td><td align="left">–</td><td align="left">–</td><td align="left">2361</td></tr><tr><td align="left">Italian</td><td align="left">1828</td><td align="left">239</td><td align="left">2005</td><td align="left">4072</td></tr><tr><td align="left">Total</td><td align="left">4189</td><td align="left">1128</td><td align="left">2005</td><td align="left">7322</td></tr></tbody></table></table-wrap><table-wrap id="Tab2"><label>Table 2</label><caption><p>Number of labels, concepts, mentions and links (mention - concept) automatically annotated per use-case</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Annotation type</th><th align="left" colspan="4">Use-case</th></tr><tr><th align="left">Cervix cancer</th><th align="left">Colon cancer</th><th align="left">Lung cancer</th><th align="left">Total</th></tr></thead><tbody><tr><td align="left">Labels</td><td align="left">16,033</td><td align="left">9309</td><td align="left">2066</td><td align="left">27,408</td></tr><tr><td align="left">Concepts</td><td align="left">12,936</td><td align="left">11,932</td><td align="left">2336</td><td align="left">27,204</td></tr><tr><td align="left">Mentions</td><td align="left">12,070</td><td align="left">10,926</td><td align="left">2336</td><td align="left">25,332</td></tr><tr><td align="left">Linking</td><td align="left">12,936</td><td align="left">11,932</td><td align="left">2336</td><td align="left">27,204</td></tr><tr><td align="left">Total</td><td align="left">53,975</td><td align="left">44,099</td><td align="left">9074</td><td align="left">107,148</td></tr></tbody></table></table-wrap></p>
    <sec id="Sec8">
      <title>Biomedical annotation tools comparison</title>
      <p id="Par58">The biomedical annotation tools selected for the comparison, according to the five requirements presented above, are BioQRator [<xref ref-type="bibr" rid="CR25">25</xref>], ezTag [<xref ref-type="bibr" rid="CR26">26</xref>], MyMiner [<xref ref-type="bibr" rid="CR27">27</xref>], tagtog [<xref ref-type="bibr" rid="CR28">28</xref>] and TeamTat [<xref ref-type="bibr" rid="CR35">35</xref>]. Moreover, we also consider brat [<xref ref-type="bibr" rid="CR39">39</xref>] and INCEpTION [<xref ref-type="bibr" rid="CR36">36</xref>] because they are used by the biomedical community in some settings. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows that several of the considered tools lack T6 (license allowance to modify and redistribute the tool) and F1 (support for overlapping mentions). Almost half of the tools (three out of seven) lacks T2 (availability of the source code), F2 (support for document-level annotation), F11 (support for IAA), F12 (data privacy) and F13 (multilingual support). In contrast, MedTAG satisfies: (T6) MedTAG is provided through the MIT license, permitting the use, modification and distribution of the tool free of charge; (T2) the source code of MedTAG is publicly available<xref ref-type="fn" rid="Fn12">12</xref>; (F12) MedTAG enables the utilization of data on a local system without any sharing with external servers, thus ensuring data privacy; (F2) MedTAG supports two types of document-level annotations, namely, label and concept annotations. The label annotation feature allows the user to tag a document according to a customizable set of labels.</p>
      <p id="Par59">The concept annotation feature allows the users to mark a document as pertinent for one or more ontological concepts. Users can leverage the auto-complete feature to search for the relevant concepts to assign. Note that, as analyzed in [<xref ref-type="bibr" rid="CR34">34</xref>], only a tiny minority of annotation tools on the market fully support document-level annotation. For instance, MyMiner supports document annotation, but due to limits in the customization process, the annotators must re-define the labels every time new documents are added to the system. Moreover, most of the other annotation tools allow the users to provide document-level annotations only using some workaround such as zero-width annotations and annotations of pre-defined placeholders placed at the beginning or at the end of the document to annotate. However, this practice is additional overhead that further complicates and slows down the annotation process; (F10) MedTAG supports users and roles.</p>
      <p id="Par60">MedTAG is distributed as a Docker container, thus it can seamlessly be deployed in a local environment or a remote cloud solution. Therefore, the administrator can choose whether to grant MedTAG access to annotators only within a local network or “worldwide”; (F13) MedTAG provides multilingual support. It allows the users to annotate the same document (same document identifier) in different languages.</p>
      <p id="Par61">When dealing with thousands of biomedical documents to annotate, time is crucial. Hence, web-based annotation tools provided with the modality of <italic>Software as a service</italic> (SaaS) are not necessarily the best solution in this context due to possible network delays. For instance, network delays might be experienced when uploading high volumes of data. A local installation can avoid network delays and operate better in the case of large corpora to be annotated. However, several annotation tools present difficulties about the installation process, such as lack of documentation or dependency issues, as stated in [<xref ref-type="bibr" rid="CR34">34</xref>]. For instance, tagtog can be installed locally only in its commercial version, whereas ezTAG and TeamTat can be installed free of charge. Still, the procedure could be quite complex for the not technology-savvy; ezTag and TeamTat require the user to install and configure some frameworks and software packages manually (e.g., Ruby, Rails, and MySQL) as prerequisites. In contrast, MedTAG provides an easy installation procedure; it requires the user only to execute the docker-compose up command (provided that Docker is installed). The MedTAG installation procedure is available and thoroughly described online.<xref ref-type="fn" rid="Fn13">13</xref></p>
      <p id="Par62">Note that TeamTat provides high-level inter-annotator agreement statistics since the project manager can calculate the agreement among annotators. In contrast, MedTAG provides fine-grained statistics by allowing the users to access the information concerning IAA for each report and to download the annotations resulting from the majority vote procedure. For this reason, we consider the criterion (F11) partially satisfied by TeamTat (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). TeamTat supports the annotation of documents compliant with the Unicode Standard, meaning that documents with special characters are visualized and annotated correctly. However, TeamTat does not provide additional facilities to manage, organize and search documents according to their languages (unless using a specific workaround such as creating language-specific document collections). In contrast, MedTAG allows the users to organize and filter documents according to their languages out-of-the-box; no additional configuration or effort is required. For this reason, we consider (F13) partially satisfied by TeamTat and entirely by MedTAG.</p>
      <p id="Par63">Several biomedical tools let the users upload biomedical documents by using tool-specific procedures and formats. For instance, BioQRator and ezTag only accept medical documents in BioC format. Despite BioC being a well-established file format in the biomedical domain, adopting it as the only valid format poses hindrances to annotating biomedical documents in other formats. For instance, narrative clinical reports are usually available in an unstructured format, such as plain text. Thus, to use them in BioQRator and ezTag, they need to be converted in BioC format in advance. In contrast, MedTAG allows the users to provide the medical documents as customizable CSV files, letting the user decide and set up which fields to display and annotate. This feature turns out to be helpful, especially when dealing with high volumes of long biomedical documents, where changing data format is not always a feasible or reasonable operation for annotators.</p>
      <p id="Par64">For what concerns the general-purpose annotation tools - i.e., brat and INCEpTION - they are substantially different from MedTAG. For instance, brat [<xref ref-type="bibr" rid="CR39">39</xref>] is a well-established web-based annotation tool specifically suited for entity and relationship annotations. It has been extensively used for the annotation of biomedical projects [<xref ref-type="bibr" rid="CR41">41</xref>–<xref ref-type="bibr" rid="CR45">45</xref>]. Brat is not available for online use; it requires to be installed locally in a UNIX-like environment. Hence, the procedure could be complex for not technology-savvy users, as stated in [<xref ref-type="bibr" rid="CR34">34</xref>]. In contrast, MedTAG is provided as a portable and easy-to-run Docker container. Users can configure brat via plain-text schema configuration. Moreover, users can import raw documents and export the annotations in plain-text format. Conversely, MedTAG provides support for several file formats such as BioC/JSON and BioC/XML, which are standard formats for the annotations in the biomedical domain. In addition, MedTAG also provides several other features that brat currently does not support, as (T3) online availability; (F2) support for document-level annotation; and, (F6) integration with PubMed.</p>
      <p id="Par65">INCEpTION is another general-purpose tool used also by the biomedical community [<xref ref-type="bibr" rid="CR46">46</xref>–<xref ref-type="bibr" rid="CR49">49</xref>]. It is an open-source web-based annotation tool both available online and for local installation. For the local use, it requires Java, as described in the online documentation.<xref ref-type="fn" rid="Fn14">14</xref> Figure <xref rid="Fig1" ref-type="fig">1</xref> shows that INCEpTION covers most of the considered criteria (21 over 22). For instance, it provides active learning facilities to improve suggestions over time in a human-in-the-loop environment and a comprehensive set of features to adapt to different annotation scenarios. However, the INCEpTION interface provides several functionalities not specifically designed for the biomedical domain, which can be perceived as redundant by the biomedical community. Moreover, to achieve annotation flexibility, INCEpTION introduces additional levels of abstraction that increase the complexity of the annotation task, thus resulting potentially not within reach of not technologically-savvy users. For instance, document-level annotation is, at the time of writing, an experimental feature that needs to be explicitly enabled by manually editing a settings file. Moreover, to enable document-level annotations, the user must define a “Document metadata” annotation layer in the project settings. For such a reason, we judge the criterion (F2) as partially satisfied by INCEpTION (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). In contrast, MedTAG provides document-level annotation facilities off-the-shelf since no additional configuration is required. In addition, MedTAG provides native PubMed integration facilities - i.e., users can annotate PubMed titles and abstracts – whereas INCEpTION employs a third-party tool (i.e., PubAnnotation [<xref ref-type="bibr" rid="CR50">50</xref>]) to retrieve the documents to annotate from PubMed Central, as stated in [<xref ref-type="bibr" rid="CR51">51</xref>].</p>
    </sec>
    <sec id="Sec9">
      <title>Quantitative comparison of biomedical annotation tools</title>
      <p id="Par66">To quantitatively assess MedTAG performance, we conducted several experiments designed to evaluate MedTAG concerning two annotation tasks: document-level annotation and mention identification. The first one concerns annotations that refer to the whole document, such as labels describing the overall document content (e.g., the “cancer” label may indicate whether a clinical report suggests a cancer condition). Instead, mention identification regards entity mentions identified in the textual content of a document. The annotation tools are compared regarding the number of actions and elapsed time required to complete the overall annotation process. To the best of our knowledge, this is the first available quantitative evaluation of biomedical annotation tools. The analysis we conducted considers a set of web-based biomedical annotation tools - i.e., ezTag, MedTAG, MyMiner, tagtog and TeamTat - evaluated on a sample of one hundred documents, randomly chosen from a real dataset concerning the digital pathology domain (i.e., clinical reports related to colon cancer). For the comparison, we consider only web-based publicly available tools since many biomedical annotation tools are not available for local installation or are not easy to install for not technologically savvy end-users. It is worth noting that our analysis does not focus on usability and <italic>Human-Computer Interaction</italic> (HCI) aspects (e.g., <italic>User Experience</italic>(UX) and interface look and feel) that may vary subjectively. Nevertheless, the latter are essential points that should be treated with specific user studies. In contrast, we focused on the annotation work regarding the number of actions (e.g., mouse clicks and keys pressed) and elapsed time to achieve the same annotations in different tools. To perform a fair comparison, we used automatic agents (web robots) designed to annotate using the same annotation speed - i.e., exact time to simulate a mouse click or a key pressed for each annotation tool. The automatic agents have been implemented using the Python Web automation library Selenium.<xref ref-type="fn" rid="Fn15">15</xref> The source code of the automated agents used for the experiments is publicly available.<xref ref-type="fn" rid="Fn16">16</xref> Since the automatic agents are generally way faster than any human annotator, we introduced a short delay (about two hundred milliseconds) between two consecutive actions, which is also necessary to avoid overloading the server with too many requests.</p>
      <p id="Par67">Tables <xref rid="Tab3" ref-type="table">3</xref> and <xref rid="Tab4" ref-type="table">4</xref> show the experimental results in terms of the number of actions and elapsed time for annotating one hundred documents. The elapsed time for each tool was recorded forty times; the resulting mean value and standard deviation are reported in the tables. Table <xref rid="Tab3" ref-type="table">3</xref> shows the performance analysis concerning the document-level annotation task. For the latter task, we considered three tools - i.e., MedTAG, MyMiner, and tagtog - since ezTag does not support document-level annotation, whereas TeamTat provides different document-level annotation facilities. In particular, TeamTat allows us to annotate entities in different documents and then to create relationships between them; this is different from the functional criterion (F2), indicating whether the users can specify labels at the document-level. For this reason, we consider the latter criterion only partially satisfied. The experiments concerning document-level annotation consist of assigning one label for each document to annotate. The labels, mentions, and documents used for testing are publicly available<xref ref-type="fn" rid="Fn17">17</xref> for reproducibility purposes. Table <xref rid="Tab3" ref-type="table">3</xref> shows that MyMiner requires fewer actions than other tools to achieve the same annotations, whereas MedTAG turns out to be the fastest tool in terms of elapsed time. Nevertheless, the time difference between MyMiner and MedTAG is about ten seconds, which is negligible considering different server response times. According to Table <xref rid="Tab3" ref-type="table">3</xref>, tagtog requires more actions and time than other tools to complete the annotation process. However, these results are motivated considering that tagtog is one of the most flexible annotation tools and allows to specify whether a document label is <italic>true</italic>, <italic>false</italic> or <italic>unknown</italic>. To this aim, tagtog allows users to choose the correct value from a drop-down menu for a document label. Thus, the users have to click on the drop-down menu two times: the first one to open the pop-up menu and the second for the value selection. In contrast, MyMiner and MedTAG require just one click on a checkbox, based on the assumption that a label may apply for a document or not (the <italic>unknown</italic> state is not allowed). Moreover, MyMiner requires fewer actions than MedTAG to complete the annotation process since it automatically moves on to the following document to annotate after the user selection. However, MyMiner does not allow to specify more labels for a document. In contrast, MedTAG goes beyond this limitation and allows to specify of several labels at the same time for each document. Thus, users can decide on their own when to move on to the next document to annotate.</p>
      <p id="Par68">Table <xref rid="Tab4" ref-type="table">4</xref> shows the performance analysis concerning the mention identification task. The experiments concerning mention identification consist of identifying entity mentions within the documents’ textual content. To this aim, we used a set of pre-identified mentions for each of the documents considered. According to Table <xref rid="Tab4" ref-type="table">4</xref>, the tools with the lowest number of actions required are ezTag and TeamTat, whereas MyMiner and MedTAG are the fastest tools in terms of elapsed time. TeamTat and ezTag achieved comparable performance since they are similar in terms of functionalities provided. The experimental results show that MyMiner is the fastest tool in terms of elapsed time. MyMiner provides a neat interface that requires low network resources and bandwidth to work, thus reducing loading time and making the annotation process faster. However, it lacks several functionalities such as (i) support for users and teams, (ii) availability for local installation, and (iii) data privacy (upload of the documents to annotate is required) that could be relevant for the needs of the biomedical community. In contrast, MedTAG is designed to be portable (i.e., local installation is available) and flexible; it provides annotation facilities, such as schema configuration, that allow users to customize the annotation experience. Moreover, MedTAG is faster than other tools, even if it requires more actions. A possible explanation could be the different mention annotation functionality. Indeed, most of the annotation tools allow identifying entity mentions within the text using drag-and-drop facilities. In contrast, MedTAG enables users to annotate mentions with a single click on each text token. The latter facility turns out to be convenient in short mentions, whereas drag-and-drop is more suitable in the case of long ones.</p>
      <p id="Par69">To summarize, we quantitatively compared a set of web-based biomedical annotation tools on two tasks: document-level annotation (one label per document) and mention identification. We conducted several experiments to assess each annotation tool regarding the number of actions and elapsed time required to complete the overall annotation process. From the experimental results emerge that, depending on the task, some tools perform better than others. Despite the higher number of actions required to complete the annotation process, MedTAG turns out to be faster than other tools, especially for the document-level annotation task.</p>
      <p id="Par70">Finally, it is worth noting that the present study focuses on evaluating a set of biomedical annotation tools only on physical aspects such as the number of actions and elapsed time required to annotate all the documents considered. Hence, we do not consider several critical human-centric factors (e.g., UX and HCI) that should be investigated in dedicated usability studies.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Document-level annotation performance analysis in terms of number of actions (e.g. mouse clicks and keys pressed) and elapsed time required to complete the whole annotation process</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Tool</th><th align="left">Number of actions</th><th align="left">Elapsed time in seconds (mean)</th><th align="left">Standard deviation in seconds</th></tr></thead><tbody><tr><td align="left">MedTAG</td><td align="left">200</td><td align="left">46.840</td><td align="left">0.803</td></tr><tr><td align="left">MyMiner</td><td align="left">100</td><td align="left">56.677</td><td align="left">0.416</td></tr><tr><td align="left">tagtog</td><td align="left">400</td><td align="left">205.740</td><td align="left">5.471</td></tr></tbody></table></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Mention-level annotation performance analysis in terms of number of actions (e.g. mouse clicks and keys pressed) and elapsed time required to complete the whole annotation process</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Tool</th><th align="left">Number of actions</th><th align="left">Elapsed time in seconds (mean)</th><th align="left">Standard deviation in seconds</th></tr></thead><tbody><tr><td align="left">MedTAG</td><td align="left">519</td><td align="left">159.337</td><td align="left">0.479</td></tr><tr><td align="left">ezTag</td><td align="left">307</td><td align="left">260.340</td><td align="left">0.576</td></tr><tr><td align="left">MyMiner</td><td align="left">414</td><td align="left">114.390</td><td align="left">1.507</td></tr><tr><td align="left">tagtog</td><td align="left">404</td><td align="left">304.692</td><td align="left">10.067</td></tr><tr><td align="left">TeamTat</td><td align="left">307</td><td align="left">271.577</td><td align="left">1.542</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Conclusions</title>
    <p id="Par71">We presented MedTAG, a customizable, portable, collaborative, web-based biomedical annotation tool. We described an instance of MedTAG adopted in the histopathology domain, where MedTAG has been used by physicians to annotate more than seven thousand clinical reports in three languages (Dutch, English and Italian), from two health-care institutions. MedTAG is provided as a docker container to make it distributable, platform-independent and easy to install/deploy. We designed MedTAG according to the five requirements (i.e. available, distributable, installable, workable and schematic) defined in a recent extensive review of manual annotation tool [<xref ref-type="bibr" rid="CR34">34</xref>]. Moreover, MedTAG satisfies 20 over 22 criteria defined in the same study.</p>
    <p id="Par72">The key points of strength of MedTAG are: (i) fast and easy installation because only one command is necessary to install it in less than 10 min on a current notebook; (ii) cross-platform support since MedTAG can be installed in every platform supporting docker; (iii) a collaborative web-based platform supporting users and roles; (iv) broad data formats support including BioC/JSON, BioC/XML, CSV, and JSON; (v) support for schema configuration where the users provide the documents to annotate by using custom CSV files and can decide which fields to display and annotate.</p>
    <sec id="Sec11">
      <title>Limitations and future work</title>
      <p id="Par73">MedTAG, as the name suggests, is a customizable annotation tool for the biomedical domain; Thus, it is not intended for general-purpose annotations since the users could not exploit domain-specific features such as automatic annotation. It is worth noting that the automatic annotation is currently provided for three cancer use-cases (i.e., cervix, colon, and lung cancer). Nevertheless, we plan to extend the automatic annotation support for other use-cases according to the needs of the biomedical community. The integration of SKET as an automated annotation tool shows the flexibility of MedTAG and how annotation automation may work with MedTAG. Another limitation concerns the file format of the input documents since MedTAG currently supports only plain-text documents. We believe that PDF annotation would be particularly useful, especially when dealing with scientific paper annotation. Hence, we plan to include this feature in the future version of MedTAG. For the time being, MedTAG does not support both overlapping mentions (also known as multi-label annotations) and relationship annotations that are left as future work. Indeed, even if MedTAG allows assigning multiple concept labels to the same mention, it is currently impossible to annotate any sub-mention. Finally, it is worth noting that even if MedTAG is designed for the biomedical domain, it could also be used for general-purpose annotation as long as a suitable schema configuration is provided. As future work, we plan to enrich MedTAG by adding (i) the support for overlapping mentions; (ii) the support for relationship annotations; (iii) the support for active learning capabilities; (iv) the support for PDF annotation; (v) the automatic annotation support for other use-cases relevant for the biomedical community. Thereby, we aim to improve MedTAG according to the biomedical community’s needs and foster further developments in this field.</p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Availability and requirements</title>
    <p id="Par74">
      <list list-type="bullet">
        <list-item>
          <p id="Par75">Project name: MedTAG</p>
        </list-item>
        <list-item>
          <p id="Par76">Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core">https://github.com/MedTAG/medtag-core</ext-link></p>
        </list-item>
        <list-item>
          <p id="Par77">Operating system(s): Platform independent.</p>
        </list-item>
        <list-item>
          <p id="Par78">Other requirements: Docker and docker-compose</p>
        </list-item>
        <list-item>
          <p id="Par79">License: MIT License</p>
        </list-item>
        <list-item>
          <p id="Par80">Any restrictions to use by non-academics: No</p>
        </list-item>
      </list>
    </p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>EHRs</term>
        <def>
          <p id="Par4">Electronic health records</p>
        </def>
      </def-item>
      <def-item>
        <term>HCI</term>
        <def>
          <p id="Par5">Human-computer interaction</p>
        </def>
      </def-item>
      <def-item>
        <term>IAA</term>
        <def>
          <p id="Par6">Inter-annotator agreement</p>
        </def>
      </def-item>
      <def-item>
        <term>IE</term>
        <def>
          <p id="Par7">Information extraction</p>
        </def>
      </def-item>
      <def-item>
        <term>ML</term>
        <def>
          <p id="Par8">Machine learning</p>
        </def>
      </def-item>
      <def-item>
        <term>NCIT</term>
        <def>
          <p id="Par9">National cancer institute thesaurus</p>
        </def>
      </def-item>
      <def-item>
        <term>NER+L</term>
        <def>
          <p id="Par10">Named entity recognition and linking</p>
        </def>
      </def-item>
      <def-item>
        <term>NLP</term>
        <def>
          <p id="Par11">Natural language processing</p>
        </def>
      </def-item>
      <def-item>
        <term>PMC</term>
        <def>
          <p id="Par12">PubMed central</p>
        </def>
      </def-item>
      <def-item>
        <term>SaaS</term>
        <def>
          <p id="Par13">Software as a service</p>
        </def>
      </def-item>
      <def-item>
        <term>SKET</term>
        <def>
          <p id="Par14">Semantic knowledge extractor tool</p>
        </def>
      </def-item>
      <def-item>
        <term>UI</term>
        <def>
          <p id="Par15">User interface</p>
        </def>
      </def-item>
      <def-item>
        <term>UX</term>
        <def>
          <p id="Par16">User experience</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn id="Fn1">
      <label>1</label>
      <p id="Par82">We report details about the main features considered in [<xref ref-type="bibr" rid="CR34">34</xref>] to ease the comprehension of our analysis.</p>
    </fn>
    <fn id="Fn2">
      <label>2</label>
      <p id="Par83"><ext-link ext-link-type="uri" xlink:href="https://github.com/ExaNLP/sket/">https://github.com/ExaNLP/sket/</ext-link>.</p>
    </fn>
    <fn id="Fn3">
      <label>3</label>
      <p id="Par84"><ext-link ext-link-type="uri" xlink:href="http://examode.dei.unipd.it/ontology/">http://examode.dei.unipd.it/ontology/</ext-link>.</p>
    </fn>
    <fn id="Fn4">
      <label>4</label>
      <p id="Par85"><ext-link ext-link-type="uri" xlink:href="https://reactjs.org/">https://reactjs.org/</ext-link>.</p>
    </fn>
    <fn id="Fn5">
      <label>5</label>
      <p id="Par86"><ext-link ext-link-type="uri" xlink:href="https://www.djangoproject.com/">https://www.djangoproject.com/</ext-link>.</p>
    </fn>
    <fn id="Fn6">
      <label>6</label>
      <p id="Par87"><ext-link ext-link-type="uri" xlink:href="https://docs.docker.com/engine/reference/commandline/docker/">https://docs.docker.com/engine/reference/commandline/docker/</ext-link>.</p>
    </fn>
    <fn id="Fn7">
      <label>7</label>
      <p id="Par88"><ext-link ext-link-type="uri" xlink:href="https://docs.docker.com/compose/">https://docs.docker.com/compose/</ext-link>.</p>
    </fn>
    <fn id="Fn8">
      <label>8</label>
      <p id="Par89"><ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core/tree/main/MedTAG_Dockerized">https://github.com/MedTAG/medtag-core/tree/main/MedTAG_Dockerized</ext-link>.</p>
    </fn>
    <fn id="Fn9">
      <label>9</label>
      <p id="Par90"><ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core">https://github.com/MedTAG/medtag-core</ext-link>.</p>
    </fn>
    <fn id="Fn10">
      <label>10</label>
      <p id="Par91"><ext-link ext-link-type="uri" xlink:href="http://w3id.org/exatag/">http://w3id.org/exatag/</ext-link> access granted with username and password <italic>Test</italic> for reviewing purposes.</p>
    </fn>
    <fn id="Fn11">
      <label>11</label>
      <p id="Par92"><ext-link ext-link-type="uri" xlink:href="https://www.examode.eu/">https://www.examode.eu/</ext-link>.</p>
    </fn>
    <fn id="Fn12">
      <label>12</label>
      <p id="Par93"><ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core/">https://github.com/MedTAG/medtag-core/</ext-link>.</p>
    </fn>
    <fn id="Fn13">
      <label>13</label>
      <p id="Par94"><ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core/tree/main#installation">https://github.com/MedTAG/medtag-core/tree/main#installation</ext-link>.</p>
    </fn>
    <fn id="Fn14">
      <label>14</label>
      <p id="Par95"><ext-link ext-link-type="uri" xlink:href="https://inception-project.github.io/documentation/">https://inception-project.github.io/documentation/</ext-link>.</p>
    </fn>
    <fn id="Fn15">
      <label>15</label>
      <p id="Par96"><ext-link ext-link-type="uri" xlink:href="https://www.selenium.dev/">https://www.selenium.dev/</ext-link>.</p>
    </fn>
    <fn id="Fn16">
      <label>16</label>
      <p id="Par97"><ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core/tree/main/benchmark">https://github.com/MedTAG/medtag-core/tree/main/benchmark</ext-link>.</p>
    </fn>
    <fn id="Fn17">
      <label>17</label>
      <p id="Par98"><ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core/tree/main/benchmark/datasets">https://github.com/MedTAG/medtag-core/tree/main/benchmark/datasets</ext-link>.</p>
    </fn>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors wish to thank Stefano Marchesin for the work on SKET which has been integrated in this work.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>All the authors participated to the design of MedTAG. OI and FG co-developed MedTAG tool and wrote the documentation revised by GS. OI implemented the docker version of MedTAG. GS oversaw the implementation of the MedTAG tool. FG, OI and GS co-authored the first draft of the manuscript. All the authors discussed the manuscript at all stages. All the authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the ExaMode Project, as a part of the European Union Horizon 2020 Program under Grant 825292. There was no additional external funding received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The full source code of MedTAG is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/MedTAG/medtag-core">https://github.com/MedTAG/medtag-core</ext-link>. An instance of MedTAG (i.e. ExaTAG) is publicly available for testing it, using the following credentials: username and password <italic>Test</italic>.</p>
  </notes>
  <notes>
    <title>Decalrations</title>
    <notes id="FPar2" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par81">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Murdoch</surname>
            <given-names>TB</given-names>
          </name>
          <name>
            <surname>Detsky</surname>
            <given-names>AS</given-names>
          </name>
        </person-group>
        <article-title>The inevitable application of big data to health care</article-title>
        <source>JAMA</source>
        <year>2013</year>
        <volume>309</volume>
        <issue>13</issue>
        <fpage>1351</fpage>
        <lpage>1352</lpage>
        <pub-id pub-id-type="doi">10.1001/jama.2013.393</pub-id>
        <pub-id pub-id-type="pmid">23549579</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aronson</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Lang</surname>
            <given-names>FM</given-names>
          </name>
        </person-group>
        <article-title>An overview of MetaMap: historical perspective and recent advances</article-title>
        <source>J Am Med Inform Assoc</source>
        <year>2010</year>
        <volume>17</volume>
        <issue>3</issue>
        <fpage>229</fpage>
        <lpage>236</lpage>
        <pub-id pub-id-type="doi">10.1136/jamia.2009.002733</pub-id>
        <pub-id pub-id-type="pmid">20442139</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">Gorrell G, Song X, Roberts A. Bio-yodie: A named entity linking system for biomedical text. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/181104860">arXiv:181104860</ext-link>. 2018;.</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Toti</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Morley</surname>
            <given-names>KI</given-names>
          </name>
          <name>
            <surname>Ibrahim</surname>
            <given-names>ZM</given-names>
          </name>
          <name>
            <surname>Folarin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jackson</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SemEHR: A general-purpose semantic search system to surface semantic data from clinical notes for tailored care, trial recruitment, and clinical research</article-title>
        <source>J Am Med Inform Assoc</source>
        <year>2018</year>
        <volume>25</volume>
        <issue>5</issue>
        <fpage>530</fpage>
        <lpage>537</lpage>
        <pub-id pub-id-type="doi">10.1093/jamia/ocx160</pub-id>
        <pub-id pub-id-type="pmid">29361077</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Savova</surname>
            <given-names>GK</given-names>
          </name>
          <name>
            <surname>Masanz</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Ogren</surname>
            <given-names>PV</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sohn</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kipper-Schuler</surname>
            <given-names>KC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mayo clinical text analysis and knowledge extraction system (cTAKES): architecture, component evaluation and applications</article-title>
        <source>J Am Med Inform Assoc</source>
        <year>2010</year>
        <volume>17</volume>
        <issue>5</issue>
        <fpage>507</fpage>
        <lpage>513</lpage>
        <pub-id pub-id-type="doi">10.1136/jamia.2009.001560</pub-id>
        <pub-id pub-id-type="pmid">20819853</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Kraljevic Z, Bean D, Mascio A, Roguski L, Folarin A, Roberts A, et al. MedCAT–Medical Concept Annotation Tool. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/191210166">arXiv:191210166</ext-link>. 2019;.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jovanović</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bagheri</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Semantic annotation in biomedicine: the current landscape</article-title>
        <source>J Biomed Semant</source>
        <year>2017</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="doi">10.1186/s13326-017-0153-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morgan</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Fluck</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ruch</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Overview of BioCreative II gene normalization</article-title>
        <source>Genome Biol</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>2</issue>
        <fpage>1</fpage>
        <lpage>19</lpage>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Li J, Sun Y, Johnson RJ, Sciaky D, Wei CH, Leaman R, et al. BioCreative V CDR task corpus: a resource for chemical disease relation extraction. Database. 2016;2016.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Doğan</surname>
            <given-names>RI</given-names>
          </name>
          <name>
            <surname>Leaman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>NCBI disease corpus: a resource for disease name recognition and concept normalization</article-title>
        <source>J Biomed Inform</source>
        <year>2014</year>
        <volume>47</volume>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2013.12.006</pub-id>
        <pub-id pub-id-type="pmid">24393765</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krallinger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rabal</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Leitner</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Vazquez</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Salgado</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The CHEMDNER corpus of chemicals and drugs and its annotation principles</article-title>
        <source>J Cheminform</source>
        <year>2015</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1186/1758-2946-7-S1-S1</pub-id>
        <pub-id pub-id-type="pmid">25705261</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Mohan S, Li D. Medmentions: a large biomedical corpus annotated with UMLS concepts. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/190209476">arXiv:190209476</ext-link>. 2019;.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Nye B, Li JJ, Patel R, Yang Y, Marshall IJ, Nenkova A, et al. A corpus with multi-level annotations of patients, interventions and outcomes to support language processing for medical literature. In: Proceedings of the conference. Association for Computational Linguistics. Meeting. vol. 2018. NIH Public Access; 2018. p. 197.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roberts</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Gaizauskas</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Hepple</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Demetriou</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Roberts</surname>
            <given-names>I</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Building a semantically annotated corpus of clinical texts</article-title>
        <source>J Biomed Inform</source>
        <year>2009</year>
        <volume>42</volume>
        <issue>5</issue>
        <fpage>950</fpage>
        <lpage>966</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2008.12.013</pub-id>
        <pub-id pub-id-type="pmid">19535011</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Campillos</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Deléger</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Grouin</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hamon</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ligozat</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Névéol</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A French clinical corpus with comprehensive semantic annotations: development of the Medical Entity and Relation LIMSI annOtated Text corpus (MERLOT)</article-title>
        <source>Lang Resour Eval</source>
        <year>2018</year>
        <volume>52</volume>
        <issue>2</issue>
        <fpage>571</fpage>
        <lpage>601</lpage>
        <pub-id pub-id-type="doi">10.1007/s10579-017-9382-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Ohta T, Pyysalo S, Tsujii J, Ananiadou S. Open-domain anatomical entity mention detection. In: Proceedings of the workshop on detecting structure in scholarly discourse; 2012. p. 27–36.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Kafkas S, Lewin I, Milward D, van Mulligen EM, Kors JA, Hahn U, et al. CALBC: Releasing the Final Corpora. In: LREC; 2012. p. 2923–2926.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Van Auken K, Schaeffer ML, McQuilton P, Laulederkind SJ, Li D, Wang SJ, et al. BC4GO: a full-text corpus for the BioCreative IV GO task. Database. 2014;2014.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>AE</given-names>
          </name>
          <name>
            <surname>Pollard</surname>
            <given-names>TJ</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li-Wei</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ghassemi</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MIMIC-III, a freely accessible critical care database</article-title>
        <source>Sci Data</source>
        <year>2016</year>
        <volume>3</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1038/sdata.2016.35</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Dobbie S, Strafford H, Pickrell WO, Fonferko-Shadrach B, Jones C, Akbari A, et al. Markup: a web-based annotation tool powered by active learning. Frontiers Digit Health. 2021;3:598916. <pub-id pub-id-type="doi">10.3389/fdgth.2021.598916</pub-id>.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Searle T, Kraljevic Z, Bendayan R, Bean D, Dobson R. MedCATTrainer: A biomedical free text annotation interface with active learning and research use case specific customisation. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/190707322">arXiv:190707322</ext-link>. 2019;.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zvára</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tomecková</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Peleška</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Svátek</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Zvárová</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Tool-supported interactive correction and semantic annotation of narrative clinical reports</article-title>
        <source>Methods Inf Med</source>
        <year>2017</year>
        <volume>56</volume>
        <issue>03</issue>
        <fpage>217</fpage>
        <lpage>229</lpage>
        <pub-id pub-id-type="doi">10.3414/ME16-01-0083</pub-id>
        <pub-id pub-id-type="pmid">28451691</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bontcheva</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Cunningham</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Roberts</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Roberts</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tablan</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Aswani</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>GATE Teamware: a web-based, collaborative text annotation framework</article-title>
        <source>Lang Resour Eval</source>
        <year>2013</year>
        <volume>47</volume>
        <issue>4</issue>
        <fpage>1007</fpage>
        <lpage>1029</lpage>
        <pub-id pub-id-type="doi">10.1007/s10579-013-9215-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Campos D, Lourenço J, Matos S, Oliveira JL. Egas: a collaborative and interactive document curation platform. Database. 2014;2014.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Kwon D, Kim S, Shin SY, Wilbur WJ. BioQRator: a web-based interactive biomedical literature curating system. In: Proceedings of the Fourth BioCreative Challenge Evaluation Workshop. vol. 1; 2013. pp. 241–246.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kwon</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Leaman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>ezTag: tagging biomedical concepts via interactive learning</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>46</volume>
        <issue>W1</issue>
        <fpage>W523</fpage>
        <lpage>W529</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky428</pub-id>
        <pub-id pub-id-type="pmid">29788413</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Salgado</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Krallinger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Depaule</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Drula</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Tendulkar</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Leitner</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MyMiner: a web application for computer-assisted biocuration and text annotation</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>17</issue>
        <fpage>2285</fpage>
        <lpage>2287</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts435</pub-id>
        <pub-id pub-id-type="pmid">22789588</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Cejuela JM, McQuilton P, Ponting L, Marygold SJ, Stefancsik R, Millburn GH, et al. tagtog: interactive and text-mining-assisted annotation of gene mentions in PLOS full-text articles. Database. 2014;2014.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Rak R, Rowley A, Black W, Ananiadou S. Argo: an integrative, interactive, text mining-based workbench supporting curation. Database. 2012;2012.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pérez-Pérez</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Glez-Peña</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Fdez-Riverola</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Lourenço</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Marky: a tool supporting annotation consistency in multi-user and iterative document annotation projects</article-title>
        <source>Comput Methods Programs Biomed</source>
        <year>2015</year>
        <volume>118</volume>
        <issue>2</issue>
        <fpage>242</fpage>
        <lpage>251</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cmpb.2014.11.005</pub-id>
        <pub-id pub-id-type="pmid">25480679</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Rinaldi F, Clematide S, Schneider G, Romacker M, Vachon T. ODIN: an advanced interface for the curation of biomedical literature. Nat Precedings. 2010;p. 1–1.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wei</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Allot</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Leaman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>PubTator central: automated concept annotation for biomedical full text articles</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>W1</issue>
        <fpage>W587</fpage>
        <lpage>W593</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkz389</pub-id>
        <pub-id pub-id-type="pmid">31114887</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Müller</surname>
            <given-names>HM</given-names>
          </name>
          <name>
            <surname>Van Auken</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sternberg</surname>
            <given-names>PW</given-names>
          </name>
        </person-group>
        <article-title>Textpresso Central: a customizable platform for searching, text mining, viewing, and curating biomedical literature</article-title>
        <source>BMC Bioinformatics</source>
        <year>2018</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
        <pub-id pub-id-type="doi">10.1186/s12859-017-2006-0</pub-id>
        <pub-id pub-id-type="pmid">29291722</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Neves</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ševa</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>An extensive review of tools for manual annotation of documents</article-title>
        <source>Brief Bioinform</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>146</fpage>
        <lpage>163</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbz130</pub-id>
        <pub-id pub-id-type="pmid">31838514</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Islamaj R, Kwon D, Kim S, Lu Z. TeamTat: a collaborative text annotation tool. Nucleic Acids Res. 2020 05;48(W1):W5–W11.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Klie JC, Bugert M, Boullosa B, de Castilho RE, Gurevych I. The INCEpTION Platform: machine-assisted and knowledge-oriented interactive annotation. In: Proceedings of the 27th international conference on computational linguistics: system demonstrations. Association for Computational Linguistics; 2018. p. 5–9. <ext-link ext-link-type="uri" xlink:href="http://tubiblio.ulb.tu-darmstadt.de/106270/">http://tubiblio.ulb.tu-darmstadt.de/106270/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Neves</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Leser</surname>
            <given-names>U</given-names>
          </name>
        </person-group>
        <article-title>A survey on annotation tools for the biomedical literature</article-title>
        <source>Brief Bioinform</source>
        <year>2014</year>
        <volume>15</volume>
        <issue>2</issue>
        <fpage>327</fpage>
        <lpage>340</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbs084</pub-id>
        <pub-id pub-id-type="pmid">23255168</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Yimam SM, Gurevych I, de Castilho RE, Biemann C. Webanno: A flexible, web-based and visually supported system for distributed annotations. In: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations; 2013. p. 1–6.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Stenetorp P, Pyysalo S, Topić G, Ohta T, Ananiadou S, Tsujii J. BRAT: a web-based tool for NLP-assisted text annotation. In: Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics; 2012. p. 102–107.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Klie J. INCEpTION: Interactive machine-assisted annotation. In: Proceedings of the First Biennial Conference on Design of Experimental Search &amp; Information Retrieval Systems (DESIRES 2018). vol. 2167 of CEUR Workshop Proceedings. CEUR-WS.org; 2018. p. 105. <ext-link ext-link-type="uri" xlink:href="http://ceur-ws.org/Vol-2167/short8.pdf">http://ceur-ws.org/Vol-2167/short8.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mihăilă</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ohta</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Pyysalo</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ananiadou</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>BioCause: annotating and analysing causality in the biomedical domain</article-title>
        <source>BMC Bioinform</source>
        <year>2013</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-2</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zerva</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Batista-Navarro</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Day</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ananiadou</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Using uncertainty to link and rank evidence from biomedical literature for model curation</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>23</issue>
        <fpage>3784</fpage>
        <lpage>3792</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx466</pub-id>
        <pub-id pub-id-type="pmid">29036627</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kors</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Clematide</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Akhondi</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Van Mulligen</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Rebholz-Schuhmann</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>A multilingual gold-standard corpus for biomedical concept recognition: the Mantra GSC</article-title>
        <source>J Am Med Inform Assoc</source>
        <year>2015</year>
        <volume>22</volume>
        <issue>5</issue>
        <fpage>948</fpage>
        <lpage>956</lpage>
        <pub-id pub-id-type="doi">10.1093/jamia/ocv037</pub-id>
        <pub-id pub-id-type="pmid">25948699</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Campos</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Matos</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Oliveira</surname>
            <given-names>JL</given-names>
          </name>
        </person-group>
        <article-title>A modular framework for biomedical concept recognition</article-title>
        <source>BMC Bioinform</source>
        <year>2013</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Verspoor K, Jimeno Yepes A, Cavedon L, McIntosh T, Herten-Crabb A, Thomas Z, et al. Annotating the biomedical literature for the human variome. Database. 2013;2013.</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Tutubalina E, Alimova I, Miftahutdinov Z, Sakhovskiy A, Malykh V, Nikolenko SI. The Russian Drug Reaction Corpus and neural models for drug reactions and effectiveness detection in user reviews. Bioinform. 2021;37(2):243–249. <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa675</pub-id>.</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <mixed-citation publication-type="other">Canales L, Menke S, Marchesseau S, D’Agostino A, del Rio-Bermudez C, Taberna M, et al. Assessing the Performance of Clinical Natural Language Processing Systems: Development of an Evaluation Methodology. JMIR Med Inform. 2021;9(7):e20492. <ext-link ext-link-type="uri" xlink:href="https://medinform.jmir.org/2021/7/e20492">https://medinform.jmir.org/2021/7/e20492</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Yi Y, Shen Z, Bompelli A, Yu F, Wang Y, Zhang R. Natural language processing methods to extract lifestyle exposures for Alzheimer’s disease from clinical notes. In: 2020 IEEE International Conference on Healthcare Informatics (ICHI); 2020. p. 1–2.</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">Schulz C, Meyer CM, Kiesewetter J, Sailer M, Bauer E, Fischer MR, et al. Analysis of automatic annotation suggestions for hard discourse-level tasks in expert domains. In: ACL; 2019. .</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">Kim J, Wang Y. PubAnnotation - a persistent and sharable corpus and annotation repository. In: Cohen KB, Demner-Fushman D, Ananiadou S, Webber BL, Tsujii J, Pestian J, editors. Proceedings of the 2012 Workshop on Biomedical Natural Language Processing, BioNLP@HLT-NAACL Montrèal, Canada, June 8, 2012. Association for Computational Linguistics; 2012. p. 202–205. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/W12-2425/">https://aclanthology.org/W12-2425/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">de Castilho RE, Ide N, Kim JD, Klie JC, Suderman K. Towards cross-platform interoperability for machine-assisted text annotation. Genom Inform. 2019;17.</mixed-citation>
    </ref>
  </ref-list>
</back>
