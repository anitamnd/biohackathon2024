<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10789309</article-id>
    <article-id pub-id-type="pmid">38180876</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae004</article-id>
    <article-id pub-id-type="publisher-id">btae004</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CircSI-SSL: circRNA-binding site identification based on self-supervised learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6730-9422</contrib-id>
        <name>
          <surname>Cao</surname>
          <given-names>Chao</given-names>
        </name>
        <aff><institution>Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China</institution>, Quzhou, Zhejiang 324003, <country country="CN">China</country></aff>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, Sichuan 611731, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2965-9920</contrib-id>
        <name>
          <surname>Wang</surname>
          <given-names>Chunyu</given-names>
        </name>
        <aff><institution>Faculty of Computing, Harbin Institute of Technology</institution>, Harbin, Heilongjiang 150001, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Shuhong</given-names>
        </name>
        <aff><institution>Faculty of Mathematics and Computer Science, Guangdong Ocean University</institution>, Zhanjiang, Guangdong 524088, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6406-1142</contrib-id>
        <name>
          <surname>Zou</surname>
          <given-names>Quan</given-names>
        </name>
        <aff><institution>Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China</institution>, Quzhou, Zhejiang 324003, <country country="CN">China</country></aff>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, Sichuan 611731, <country country="CN">China</country></aff>
        <xref rid="btae004-cor1" ref-type="corresp"/>
        <!--zouquan@nclab.net-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Valencia</surname>
          <given-names>Alfonso</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae004-cor1">Corresponding author. Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China, Quzhou, Zhejiang 324003, China. E-mail: <email>zouquan@nclab.net</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-01-05">
      <day>05</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>1</issue>
    <elocation-id>btae004</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>13</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>28</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>15</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae004.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>In recent years, circular RNAs (circRNAs), the particular form of RNA with a closed-loop structure, have attracted widespread attention due to their physiological significance (they can directly bind proteins), leading to the development of numerous protein site identification algorithms. Unfortunately, these studies are supervised and require the vast majority of labeled samples in training to produce superior performance. But the acquisition of sample labels requires a large number of biological experiments and is difficult to obtain.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To resolve this matter that a great deal of tags need to be trained in the circRNA-binding site prediction task, a self-supervised learning binding site identification algorithm named CircSI-SSL is proposed in this article. According to the survey, this is unprecedented in the research field. Specifically, CircSI-SSL initially combines multiple feature coding schemes and employs RNA_Transformer for cross-view sequence prediction (self-supervised task) to learn mutual information from the multi-view data, and then fine-tuning with only a few sample labels. Comprehensive experiments on six widely used circRNA datasets indicate that our CircSI-SSL algorithm achieves excellent performance in comparison to previous algorithms, even in the extreme case where the ratio of training data to test data is 1:9. In addition, the transplantation experiment of six linRNA datasets without network modification and hyperparameter adjustment shows that CircSI-SSL has good scalability. In summary, the prediction algorithm based on self-supervised learning proposed in this article is expected to replace previous supervised algorithms and has more extensive application value.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code and data are available at <ext-link xlink:href="https://github.com/cc646201081/CircSI-SSL" ext-link-type="uri">https://github.com/cc646201081/CircSI-SSL</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62231013</award-id>
        <award-id>62250028</award-id>
        <award-id>62271329</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Sichuan Provincial Science Fund for Distinguished Young Scholars</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2021JDJQ0025</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Shenzhen Polytechnic</institution>
            <institution-id institution-id-type="DOI">10.13039/100012840</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>6022310036K</award-id>
        <award-id>6023310037K</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Municipal Government of Quzhou</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2022D040</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Circular RNA (circRNA) is the peculiar class of RNAs produced by pre-mRNA. Unlike common RNAs with the two ends of 5â² and 3â², circRNA has a unique ring structure formed by the reverse splicing mechanism (<xref rid="btae004-B2" ref-type="bibr">Bogard <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae004-B12" ref-type="bibr">Hao <italic toggle="yes">et al.</italic> 2019</xref>), widely present in human, hippocampus, mouse, and other cells and tissues (<xref rid="btae004-B7" ref-type="bibr">Dori <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae004-B22" ref-type="bibr">Li and Han 2019</xref>). This special structure can enhance the stability of circRNA and usually has a stage-specific expression pattern (<xref rid="btae004-B34" ref-type="bibr">Rybak-Wolf <italic toggle="yes">et al.</italic> 2015</xref>). More and more evidence has proved that circRNA can participate in the processes of gene expression regulation through combining the corresponding RNA-binding protein (RBP) (<xref rid="btae004-B4" ref-type="bibr">Chen 2016</xref>, <xref rid="btae004-B43" ref-type="bibr">Zang <italic toggle="yes">et al.</italic> 2020</xref>). Like other non-coding RNAs (<xref rid="btae004-B16" ref-type="bibr">Huang <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B17" ref-type="bibr">b</xref>), It can also play a crucial part in the screening and therapy of many diseases (<xref rid="btae004-B19" ref-type="bibr">Jiao <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btae004-B37" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2021</xref>), especially cancer (<xref rid="btae004-B44" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae004-B35" ref-type="bibr">Su <italic toggle="yes">et al.</italic> 2022</xref>). Therefore, the understanding of the action mechanism between circRNA and RBP is crucial to reveal the circRNA formation and its biological function (<xref rid="btae004-B6" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btae004-B26" ref-type="bibr">Niu <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B27" ref-type="bibr">b</xref>,<xref rid="btae004-B28" ref-type="bibr">c</xref>).</p>
    <p>With the emergence of some biological technologies about sequencing, such as high-throughput sequencing with crosslinking immunoprecipitation (HITS-CLIP), many RBP targets in mature circRNAs have been found in eukaryotes (<xref rid="btae004-B8" ref-type="bibr">Dudekula <italic toggle="yes">et al.</italic> 2016</xref>, <xref rid="btae004-B33" ref-type="bibr">Ruan <italic toggle="yes">et al.</italic> 2019</xref>). However, due to the high cost of detecting each pair of interaction sites, many computational methods for identifying circRNAâRBP sites have been developed. Thanks to the advancements in deep learning, the identification performance of RBP-binding sites has been continuously improved. For example, CSCRSites (<xref rid="btae004-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2019a</xref>,<xref rid="btae004-B39" ref-type="bibr">b</xref>) is a deep learning algorithm that identifies RBP-binding sites about cancer-specific only using nucleotide sequences information. CircSLNN (<xref rid="btae004-B20" ref-type="bibr">Ju <italic toggle="yes">et al.</italic> 2019</xref>) is a novel approach that transforms the RNA-binding site prediction problem into a sequence labeling problem, which adopts a word-embedded based coding scheme to capture the context and semantic information of sequences. CRIP (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>) proposes a stacked codon encoding deep learning algorithm based on convolutional neural networks and recurrent neural networks, which respectively learn abstract features and sequence dependences to complete the RBP-binding site recognition task. However, these methods are single-view algorithms, and the useful features obtained from the sequence are quite limited, and often constrained by the size of the data, and cannot achieve good performance. Subsequently, researchers have introduced some multi-view algorithms. PASSION (<xref rid="btae004-B18" ref-type="bibr">Jia <italic toggle="yes">et al.</italic> 2020</xref>) is a multi-view integrated neural network algorithm, and the optimal feature subset is selected and input into the network through incremental features selection and XGBoost algorithm. iCircRBP-DHN (<xref rid="btae004-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>) proposes to use two new encoding schemes: K-tuple nucleotide frequency patterns and CircRNA2Vec word embedding encoding as inputs. Deep multi-scale residual network, bidirectional gate recurrent unit (BiGRU), and self-attention mechanism are used as algorithms for deep network architecture. CRBPDL (<xref rid="btae004-B26" ref-type="bibr">Niu <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B27" ref-type="bibr">b</xref>,<xref rid="btae004-B28" ref-type="bibr">c</xref>) proposes an Adaboost integrated deep network architecture, which includes deep multi-scale residual networks and BiGRU. The performance of the algorithm is further improved. HCRNET (<xref rid="btae004-B41" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2022</xref>) incorporates a fine-tuned DNABERT model and a deep temporal convolutional network to capture global context-dependent semantic and syntactic information for circRNA sequences.</p>
    <p>As for the networks based on CNN, RNN or their deformation used in the above research as deep feature extraction networks, there are problems, such as poor network parallel capability, difficulty to capture features long-time series dependence, and insufficient algorithm stability. CircSSNN (<xref rid="btae004-B3" ref-type="bibr">Cao <italic toggle="yes">et al.</italic> 2023</xref>) proposes an algorithm that fully uses the self-attention mechanism to extract deep features and achieves better performance. Although these algorithms are constantly updating the performance of the recognition task, they are based on supervised learning, in other words, the algorithm requires a great number of sample labels in network training. Usually, the ratio of training samples to test samples is as high as 80%:20%. Although the algorithm achieves good performance, it greatly limits the exploration of the unknown circRNAâRBP interaction mechanism. As a consequence, it has immense practical significance to develop an algorithm based on supervised weakly, self-supervised, and even unsupervised in this task.</p>
    <p>Self-supervised learning (SSL) (<xref rid="btae004-B24" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2021</xref>) is a special kind of unsupervised learning. It learns required features without the need for real labels through pre-designed agent tasks, and subsequent tasks often require only a few labels (or even none) to significantly enhance performance according to specific tasks. Contrast learning performs particularly well in computer vision because it can learn invariant representations from enhanced data without label information (<xref rid="btae004-B15" ref-type="bibr">Hjelm <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae004-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae004-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic> 2020</xref>), demonstrating significant self-supervised capabilities. The specific operation process is as follows: first, data augmentation is used to get a number of different perspectives (usually two) from the original image that are slightly different. Then, different views of the same sample are taken as positive sample pairs and the others as negative samples. By maximizing the similarity between positive sample pairs and minimizing the similarity between positive sample and negative sample, a âlabelâ is artificially constructed to guide the learning of network features. However, while contrast learning can be useful in the field of images, it is difficult to apply to time-series data for several reasons: above all, there exists a challenge of capturing temporal dependencies in the data, which is very critical. Secondly, image-based augmentation techniques, such as random cropping, do not work with time-series datasets. Thus far, there have been few studies on contrast learning for time-series data, and it has not been applied to the prediction of circRNA-binding sites.</p>
    <p>For the sake of reducing the dependence of the algorithm on the sample label as much as possible, thereby enhancing its applicability across a wider range of scenarios. This article carried out in-depth research and innovatively proposed an algorithm named circRNA-binding site identification based on self-supervised learning (CircSI-SSL). The algorithm uses only KNFP, CircRNA2Vec, and electronâion interaction pseudo-potential (EIIP) shallow statistical feature descriptors, which reduces the computational resource requirements. After encoding, our Transformer model RNA_Transformer, which is improved for CircRNA recognition task, is used to: (i) perform cross-view sequence prediction tasks to train the network, capture temporal dependencies in sequence multi-view data, and learn the overall representation of the sequence; (ii) apply a very small number of sample tags (10%) to fine-tune network parameters for a specific task, thereby completing the RBP-binding site prediction task. Through a comprehensive experiment conducted on 12 widely used datasets, it is shown that the algorithm obtains a significant improvement over the supervised learning algorithms. In summary, the primary contributions of this article can be outlined as follows.</p>
    <p>A novelSSL method is applied in the domain of circRNA-binding protein recognition, which changes the situation that most of the label information is needed to obtain good performance. Using only a small amount of supervised information can lead to a substantial enhancement in the algorithmâs performance, which has a wide range of application value.</p>
    <p>We propose a novel proxy task that captures sequence temporal dependencies using an improved RNA_Transformer as a benchmark model and completes cross-view sequence prediction based on multiple feature descriptors instead of using sequence augmentation techniques.</p>
    <p>Comprehensive experiments conducted on six widely used circRNA datasets and six linRNA datasets demonstrate that the proposed algorithm exhibits comprehensive advantages over previous supervised learning approaches. Even when utilizing only 10% of the labeled data for training, the proposed algorithm demonstrates stable and outstanding performance, along with robust scalability.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>In order to assess the validity of our approach, we selected six widely used circRNA datasets, WTAP, FXR1, C17ORF85, QKI, TAF15, and AUF1. These circRNA sequences derive from circRNA interaction set of database (<ext-link xlink:href="https://circinteractome.nia.nih.gov/" ext-link-type="uri">https://circinteractome.nia.nih.gov/</ext-link>), which extracted data includes circRNAâRBP interaction information, also includes RBPs that bind to mature circRNA upstream and downstream flanker sequences (<xref rid="btae004-B42" ref-type="bibr">Yee <italic toggle="yes">et al.</italic> 2019</xref>). We then use the identical data processing steps as previous research (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>). Resulting 101 nucleotides sequence fragments in length are obtained as positive samples, and randomly selecting other sequences to acquire negative samples with same numbers. These similar sequences are removed using CD-HIT technique, with the threshold of 0.8 (<xref rid="btae004-B23" ref-type="bibr">Li and Godzik 2006</xref>). After the removal of sequence redundancy, a total of 15Â 570 samples were obtained, and all samples used in the experiments were randomly shuffled.</p>
      <p>In addition, we transplant the circSI-SSL algorithm to linear RNA datasets and compare the performance of several existing supervised algorithms in identifying RBP interactions. The same linear RNA datasets are downloaded from iDeepS (<xref rid="btae004-B32" ref-type="bibr">Pan <italic toggle="yes">et al.</italic> 2018</xref>) and DeepBind (<xref rid="btae004-B1" ref-type="bibr">Alipanahi <italic toggle="yes">et al.</italic> 2015</xref>), including six datasets after HITS-CLIP processing: hnRNPC-2, U2AF65, hnRNPC-1, QKI, ELVAL1-2, and Y2AF65.</p>
    </sec>
    <sec>
      <title>2.2 Feature muti-descriptors</title>
      <p>To enrich the originally single sequence, we employ three quantitative feature methods to extract the preliminary statistical features of the sequence: (i) KNFP, which is used to capture local semantic features at disparate positions. (ii) CircRNA2Vec, which is employed to capture remote dependencies. (iii) The EIIP, which is utilized to characterize the free electron energy on the circRNA sequence.</p>
      <sec>
        <title>2.2.1 KNFP</title>
        <p>In this section, we introduce KNFP schema in detail. Different from the traditional One-hot representation (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>), KNFP schema can extract various short-range sequence-dependent information (<xref rid="btae004-B31" ref-type="bibr">Orenstein <italic toggle="yes">et al.</italic> 2016</xref>) and local semantic features, which greatly makes up for the deficiency of One-hot information and retains the original sequence schema.</p>
        <p>Taking a specific circRNA sequence of length <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>L</mml:mi></mml:math></inline-formula> as an example, KNFP slidingly selects <italic toggle="yes">k</italic> consecutive nucleotides on the circRNA sequence, and counts the frequencies of the corresponding combinations in the form of <italic toggle="yes">k</italic> tuples (different combinations of <italic toggle="yes">k</italic> nucleotides), as the final encoding. In detail, for a <italic toggle="yes">k</italic>-tuple, which has <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> different combinations, the frequency <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>p</mml:mi></mml:math></inline-formula> of the corresponding <italic toggle="yes">K</italic>-tuple pattern is statistically calculated according to the specific circRNA sequence.
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi mathvariant="normal">Â </mml:mi></mml:math></inline-formula>represents the frequency of the <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>-th <italic toggle="yes">k</italic>-tuple pattern. Upon processing a single circRNA sequence, the resulting feature dimension becomes <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:math></inline-formula>. We concatenate the encoded features obtained by <italic toggle="yes">k</italic>â=â1, 2, and 3, respectively, and complete them with 0 at the end.</p>
      </sec>
      <sec>
        <title>2.2.2 CircRNA2Vec</title>
        <p>CircRNA2Vect (<xref rid="btae004-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>) is a feature descriptor that employs the Doc2Vec algorithm to learn global contextual features of circRNA. Doc2Vec (<xref rid="btae004-B21" ref-type="bibr">Le and Mikolov 2014</xref>) is an extension of Word2Vec, capable of learning fixed-length feature representations from variable-length texts. Unlike Word2Vec, Doc2Vec introduces an additional paragraph vector <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> at the input layer, which captures the contextual information of paragraphs. This enables the linkage of word vectors with paragraph vectors, addressing the limitation of Word2Vec that focuses solely on training word vectors while overlooking the grasp of paragraph-level context.</p>
        <p>We collect as many circRNA splicing sequences as possible from circBase (<xref rid="btae004-B11" ref-type="bibr">GlaÅ¾ar <italic toggle="yes">et al.</italic> 2014</xref>) to serve as the corpus. Utilizing a sliding window of size 10, extract subsequences from each circRNA sequence, resulting in multiple sequences. This allows the algorithm to capture semantic information within these subsequences for modeling purposes. Given a text sequence of length <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="normal">T</mml:mi></mml:math></inline-formula>, where the word at time step <italic toggle="yes">t</italic> is denoted as <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For context window size <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, the likelihood function of the model is the probability of generating a specific word <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which express as term <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. The goal of the model is to maximize the average logarithmic probability as follow:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>â</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.2.3 EIIP</title>
        <p>EIIP, as introduced by <xref rid="btae004-B25" ref-type="bibr">Nair and Sreenadhan (2006)</xref>, is a novel feature encoding scheme that describes the energy of delocalized electrons in amino acids and nucleotides present in circRNA sequences. Four binary indicator sequences are used to encode the sequence. It has been widely utilized in the Resonance Recognition Model. The EIIP values for the nucleotide âG,â âC,â âT,â and âAâ are â0.0806,â â0.1340,â â0.1335,â and â0.1260,â respectively. To enrich the feature representation, we incorporate a PSTNPss encoding scheme. It is position-specific feature encoding based on single-strand of DNA. See <xref rid="btae004-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic> (2018)</xref> for more details.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 CircSI-SSL algorithm architecture</title>
      <p>In this section, we introduce the CircSI-SSL self-supervised algorithm framework for learning high-quality representations of sequences, using only a small number of samples to fine-tune the CircSI-SSL algorithm for specific tasks to achieve excellent results. The overall framework is shown in <xref rid="btae004-F1" ref-type="fig">Fig.Â 1</xref>. For a more intuitive understanding, we provide the pseudo-code as follow. The model consists of two components: cross-view prediction and fine-tuning. (i) Multiple feature encoders are employed to encode initial features obtained from various descriptors extracted from the raw sequence data. A cross-view sequence prediction is conducted using RNA_Transformer. (ii) The trained encoded features are then fused, followed by employing RNA_Transformer to extract structured features from the fused multi-view features based on a small number of labels, facilitating the classification task.</p>
      <fig position="float" id="btae004-F1">
        <label>Figure 1.</label>
        <caption>
          <p>CircSI-SSL framework.</p>
        </caption>
        <graphic xlink:href="btae004f1" position="float"/>
      </fig>
      <boxed-text id="btae004-BOX1" position="float">
        <label>Algorithm 1</label>
        <caption>
          <p>CircSI-SSL</p>
        </caption>
        <p><bold>Input:</bold> CircRNA sequence x, label y, Maximum iterations MaxIter</p>
        <p><bold>Output:</bold> Neural network parameters W, Prediction label y'</p>
        <p>1.ââfor iter in range(MaxIter): # Self-supervised stage</p>
        <p>2.ââenc1â=âKNFP(x)</p>
        <p>3.ââenc2â=âCircRNA2Vec(x)</p>
        <p>4.ââenc3â=âEIIP(x)</p>
        <p>5.ââc1â=âRNA_Transformer(enc1) # Context c1 of enc1 is extracted by RNA_Transformer</p>
        <p>6.ââc2â=âRNA_Transformer(enc2)</p>
        <p>7.ââc3â=âRNA_Transformer(enc3)</p>
        <p>8.ââCalculate cross-view contrast loss according to Formula 6 and 7</p>
        <p>9.ââUpdate W according to Adam optimizer</p>
        <p>10.ââfor iter in range(MaxIter): # Fine-tuning stage</p>
        <p>11.ââenc = concatenate([enc1, enc2, enc3]) # Obtaining the enc1, enc2, enc3 follows the same steps as above</p>
        <p>12.ââc = RNA_Transformer(enc)</p>
        <p>13.ââyâ = softmax(c)</p>
        <p>14.ââCalculate cross-entropy loss of y and y' according to Formula 9</p>
        <p>15.ââFine-tune W according to Adam optimizer</p>
      </boxed-text>
      <sec>
        <title>2.3.1 Cross-view prediction</title>
        <p>The initial research on SSL started with the application of agent tasks on image datasets, which aims to learn high-quality representations. For example, some previous work predicts image rotation (<xref rid="btae004-B10" ref-type="bibr">Gidaris <italic toggle="yes">et al.</italic> 2018</xref>), images colorization (<xref rid="btae004-B46" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2016</xref>), and puzzle solving (<xref rid="btae004-B29" ref-type="bibr">Noroozi and Favaro 2016</xref>). By using image augmentation technology to construct positive and negative samples, the application range of contrast learning is broadened: case discrimination fields, such as SimCLR (<xref rid="btae004-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2020</xref>) and MoCo (<xref rid="btae004-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic> 2020</xref>); time-series analysis, such as CPC (<xref rid="btae004-B30" ref-type="bibr">Oord <italic toggle="yes">et al.</italic> 2018</xref>) and TS-TC (<xref rid="btae004-B9" ref-type="bibr">Eldele <italic toggle="yes">et al.</italic> 2021</xref>). Unfortunately, these algorithmsâ performance depends heavily on the augmentation techniques used, especially for time-series data, and it is difficult to find a set of effective and widely used augmentation techniques for operations, such as random cropping and image graying. This greatly restricts the application of contrast learning to time-series data. Building upon this, this article studies a new contrast task, which extracts features from multiple real views for mutual prediction without the help of augmentation techniques.</p>
        <p>We take the improved Transformer (<xref rid="btae004-B36" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic> 2017</xref>) and TS-TC (<xref rid="btae004-B9" ref-type="bibr">Eldele <italic toggle="yes">et al.</italic> 2021</xref>) as feature extraction networks, as revealed in <xref rid="btae004-F2" ref-type="fig">Fig.Â 2</xref>. It principal consists of Multi-head Attention and Feed Forward Neural Network (FFN), Layer Normalization (LN) blocks. The FFN block consists of a fully connected layer, a non-linear ReLU function and dropout. The model uses a pre-norm residual connection (<xref rid="btae004-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2019a</xref>,<xref rid="btae004-B39" ref-type="bibr">b</xref>) and LN prior to passing through a multi-head self-attention network, resulting in more stable gradients:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>LN</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>Î³</mml:mo><mml:mo>,</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>â</mml:mo><mml:mo>Î¼</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>Ï</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mo>Ïµ</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>â</mml:mo><mml:mo>Î³</mml:mo><mml:mo>+</mml:mo><mml:mo>Î²</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtext>MHA</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>softmax</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>V</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <fig position="float" id="btae004-F2">
          <label>Figure 2.</label>
          <caption>
            <p>RNA_Transformer structure.</p>
          </caption>
          <graphic xlink:href="btae004f2" position="float"/>
        </fig>
        <p>Where <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mo>Î¼</mml:mo></mml:math></inline-formula> and <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mo>Ï</mml:mo></mml:math></inline-formula> are the mean and variance of <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>z</mml:mi></mml:math></inline-formula>, respectively, <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Î³</mml:mi></mml:math></inline-formula> and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Î²</mml:mi></mml:math></inline-formula> represent the parameter vectors of scaling and translation, respectively. Query information, key information, and value information related to a specific task are represented as <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mi>q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula>, respectively. The number of operation heads is represented as<inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>h</mml:mi></mml:math></inline-formula>, and the aggregated <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi>q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> after multiple heads are denoted as <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mi>Q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mi>K</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>V</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> respectively. Here, <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> signifies the dimensions of the input vector. Then, LayerNorm regularization is carried out, and the features extracted by multiple heads are aggregated through FFN blocks to finally obtain the context feature <italic toggle="yes">C</italic> that represents the whole sequence.</p>
        <p>The entire process can be summarized as follows: given a circRNA sequence with a batch size of <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula>, the preliminary features <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are extracted by CircRNA2Vec and EIIP descriptors, respectively. It is then encoded by an encoder (using a 1D convolutional neural network) as <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>and <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where the feature sequence length is <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula>. Then, context variables <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are extracted by improved transformer respectively, and cross-view mutual prediction is carried out. The loss functions are:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">self</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">diag</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">diag</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.3.2 Fine-tuning</title>
        <p>After mutual prediction across the sequence of views, we get the trained RNA_Transformer. This allows him to learn the expression of the context of the overview from the sequence features. We then fine-tune the network for specific tasks to meet the needs of circRNAâprotein binding site prediction. Specifically, we combine the features <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">all</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> encoded by the above three feature descriptors and input them into RNA_Transformer. Context information <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">all</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of fusion features is extracted, processed by projection_head and normalized by softmax to obtain prediction label <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>. Finally, using cross-entropy loss and training with only a very small number of real labels, excellent results can be obtained:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Ï</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">all</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo>â</mml:mo><mml:mi>m</mml:mi></mml:munder></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Ï</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">all</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>As far as we know, this is the first time to apply the SSL algorithm to address the RNAâprotein binding site prediction problem. Different from HCRNet and CircSSNN, the three feature descriptors we selected are relatively shallow algorithms and do not use DNABertâs large language model, which requires lower hardware resources and is easy to be widely used. Compared with previous supervised learning algorithms, it reduces the excessive dependence on actual labels. After representing sequences in agent task learning without using real tags, superior performance can be achieved with only a small number of tags depending on the final task.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Experimental setup</title>
      <p>In our experiment, the networks are trained by the Adam optimizer, where <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:math></inline-formula>, <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:math></inline-formula>, and weight_decay is set to 3e-4 and batchSize to 64. The optimizerâs learning rate is automatically controlled by the scheduling that comes with pytorch, where initial value is 3e-3. We employ a layer of RNA_Transformer and set dim to 400, heads to 8, and mlp_dim to 200.</p>
    </sec>
    <sec>
      <title>3.2 Existing supervised algorithm performance</title>
      <p>We demonstrate the AUC performance achieved by eight existing supervised recognition algorithms on six circRNAâRBP datasets, as shown in <xref rid="btae004-F3" ref-type="fig">Fig.Â 3</xref>. These include CircSSNN, HCRNet, iCircRBP-DHN, PASSION, CRIP, CircRB, CSCRSites, and CircSLNN. The dataset ratio is set to 8:2, based on the number of training and test samples as claimed in their respective papers. It can be seen from the picture that the latest algorithm CircSSNN has achieved nearly perfect performance, and HCRNet and iCircRBP-DHN are not much different from it. Since <xref rid="btae004-F3" ref-type="fig">Fig.Â 3</xref> cannot be well distinguished, we independently draw the results of these three algorithms on these datasets to draw box plots (<xref rid="btae004-F4" ref-type="fig">Fig.Â 4</xref>). However, it should be noted that these algorithms require up to 80% of the training samples, i.e. 80% of the labeling labels obtained through biological experiments need to be invested in the algorithm for auxiliary learning, so as to guide the network to learn useful and easily distinguishable features. We know that the biological experiment analysis cost is high, the cycle is long, the efficiency is low, consumes a lot of human, material, and financial resources, which greatly limits the universality of the algorithm. Therefore, the algorithmâs dependence on labels should be reduced as much as possible to reduce the cost.</p>
      <fig position="float" id="btae004-F3">
        <label>Figure 3.</label>
        <caption>
          <p>AUC discrimination performance obtained by eight existing supervised algorithms.</p>
        </caption>
        <graphic xlink:href="btae004f3" position="float"/>
      </fig>
      <fig position="float" id="btae004-F4">
        <label>Figure 4.</label>
        <caption>
          <p>AUC performance obtained by the latest three supervised learning algorithms on six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Our CircSI-SSL performance</title>
      <p>To validate the low dependency for labels and recognition effectiveness of our CircSI-SSL algorithm, we selected three algorithms with the best supervised performance, CircSSNN, HCRNet, and iCircRBP-DHN, and compared them with our algorithm under the premise of train:testâ=â1:9. The results are shown in <xref rid="btae004-F5" ref-type="fig">Fig.Â 5</xref>. It can be seen that our algorithm has achieved remarkable performance on most datasets and indicators, but we also see that our algorithm is slightly lower than HCRNet in Recall index. The reason may be that when very little supervision information is involved in training, supervised algorithms tend to pay too much attention to individual indicators and failure to achieve overall performance. For example, HCRNet focuses on recall index, while ACC and Precision fail to achieve good results. In contrast, our CircSI-SSL achieves a balanced and excellent performance across all metrics. It can also be seen from the comprehensive index AUC that the algorithm in this article has the best comprehensive ability and has a wide application prospect. For the convenience of comparison, we visualized the average AUC of the algorithm on six datasets as <xref rid="btae004-F6" ref-type="fig">Fig.Â 6</xref>. It can be intuitively seen that the algorithm in this article achieved the highest performance compared with other datasets, which was 3.3% higher on average and more than 5% higher on some datasets.</p>
      <fig position="float" id="btae004-F5">
        <label>Figure 5.</label>
        <caption>
          <p>Performance comparison between CircSI-SSL and the latest three supervised algorithms in four indicators.</p>
        </caption>
        <graphic xlink:href="btae004f5" position="float"/>
      </fig>
      <fig position="float" id="btae004-F6">
        <label>Figure 6.</label>
        <caption>
          <p>Average AUC performance comparison between CircSI-SSL and the latest three supervised algorithms on six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f6" position="float"/>
      </fig>
      <p>To further explore the relationship between the performance of the proposed algorithm and the amount of supervised information introduced, it is proved that the proposed algorithm can achieve stable performance under the condition of very few training samples. We conducted a step test according to the training samples from 1 to 9. Ratio was used to represent the ratio between the training set and the test set. The AUC performance obtained was shown in <xref rid="btae004-T1" ref-type="table">TableÂ 1</xref>. We can see that in general, the algorithm has learned easily distinguishable features under the sample ratio of 1:9, and achieved excellent classification performance. With the continuous increase of training samples, the performance of the algorithm can maintain a certain increase, but the difference is not much compared with the initial. This fully indicates that the cross-view prediction task based on SSL has trained the RNA_Transformer feature extractor and learned enough contextual features to represent the entire sequence. Only a very small number of samples are required to fine-tune for subsequent recognition tasks.</p>
      <table-wrap position="float" id="btae004-T1">
        <label>Table 1.</label>
        <caption>
          <p>AUC performance of CircSI-SSL algorithm under different training sample proportions.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Ratio</th>
              <th rowspan="1" colspan="1">WTAP</th>
              <th rowspan="1" colspan="1">FXR1</th>
              <th rowspan="1" colspan="1">C17ORF85</th>
              <th rowspan="1" colspan="1">QKI</th>
              <th rowspan="1" colspan="1">TAF15</th>
              <th rowspan="1" colspan="1">AUF1</th>
              <th rowspan="1" colspan="1">AVG</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1:9</td>
              <td rowspan="1" colspan="1">0.887</td>
              <td rowspan="1" colspan="1">0.981</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.961</td>
              <td rowspan="1" colspan="1">0.986</td>
              <td rowspan="1" colspan="1">0.971</td>
              <td rowspan="1" colspan="1">0.958</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2:8</td>
              <td rowspan="1" colspan="1">0.914</td>
              <td rowspan="1" colspan="1">0.980</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.986</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">0.963</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3:7</td>
              <td rowspan="1" colspan="1">0.913</td>
              <td rowspan="1" colspan="1">0.984</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.967</td>
              <td rowspan="1" colspan="1">0.987</td>
              <td rowspan="1" colspan="1">0.973</td>
              <td rowspan="1" colspan="1">0.964</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4:6</td>
              <td rowspan="1" colspan="1">0.926</td>
              <td rowspan="1" colspan="1">0.987</td>
              <td rowspan="1" colspan="1">0.963</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.972</td>
              <td rowspan="1" colspan="1">0.967</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5:5</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.983</td>
              <td rowspan="1" colspan="1">0.961</td>
              <td rowspan="1" colspan="1">0.968</td>
              <td rowspan="1" colspan="1">0.988</td>
              <td rowspan="1" colspan="1">0.973</td>
              <td rowspan="1" colspan="1">0.968</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">6:4</td>
              <td rowspan="1" colspan="1">0.943</td>
              <td rowspan="1" colspan="1">0.985</td>
              <td rowspan="1" colspan="1">0.960</td>
              <td rowspan="1" colspan="1">0.969</td>
              <td rowspan="1" colspan="1">0.991</td>
              <td rowspan="1" colspan="1">0.977</td>
              <td rowspan="1" colspan="1">0.971</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">7:3</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.983</td>
              <td rowspan="1" colspan="1">0.959</td>
              <td rowspan="1" colspan="1">0.971</td>
              <td rowspan="1" colspan="1">0.990</td>
              <td rowspan="1" colspan="1">0.975</td>
              <td rowspan="1" colspan="1">0.969</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">8:2</td>
              <td rowspan="1" colspan="1">0.978</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.956</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.979</td>
              <td rowspan="1" colspan="1">0.977</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.4 Ablation analysis</title>
      <p>In this section, we conduct an ablation analysis to demonstrate that the improved performance of our algorithm is a direct result of the SSL task we designed. The AUC performance obtained by the CircSI-SSL algorithm on these datasets is presented in <xref rid="btae004-T2" ref-type="table">TableÂ 2</xref>, where fine-tuning based on real labels is performed directly without cross-view sequence prediction task. It is evident that when no proxy task is performed, the algorithm performance drops off a cliff, with an average decline of about 10%, as shown in <xref rid="btae004-F7" ref-type="fig">Fig.Â 7</xref>. In particular, there is also an extreme AUC performance of 0.5. This is sufficient to show that it is necessary to conduct self-supervised tasks, to learn the overall expression of the sequence from the data (without labels), and thus to significantly improve subsequent classification tasks with only a few labels.</p>
      <fig position="float" id="btae004-F7">
        <label>Figure 7.</label>
        <caption>
          <p>Average AUC performance with and without SSL across six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f7" position="float"/>
      </fig>
      <table-wrap position="float" id="btae004-T2">
        <label>Table 2.</label>
        <caption>
          <p>AUC performance of CircSI-SSL algorithm (without self-supervision task) under different training sample proportions.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Ratio</th>
              <th rowspan="1" colspan="1">WTAP</th>
              <th rowspan="1" colspan="1">FXR1</th>
              <th rowspan="1" colspan="1">C17ORF85</th>
              <th rowspan="1" colspan="1">QKI</th>
              <th rowspan="1" colspan="1">TAF15</th>
              <th rowspan="1" colspan="1">AUF1</th>
              <th rowspan="1" colspan="1">AVG</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1:9</td>
              <td rowspan="1" colspan="1">0.881</td>
              <td rowspan="1" colspan="1">0.883</td>
              <td rowspan="1" colspan="1">0.941</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.888</td>
              <td rowspan="1" colspan="1">0.653</td>
              <td rowspan="1" colspan="1">0.852</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2:8</td>
              <td rowspan="1" colspan="1">0.876</td>
              <td rowspan="1" colspan="1">0.895</td>
              <td rowspan="1" colspan="1">0.944</td>
              <td rowspan="1" colspan="1">0.838</td>
              <td rowspan="1" colspan="1">0.931</td>
              <td rowspan="1" colspan="1">0.848</td>
              <td rowspan="1" colspan="1">0.889</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3:7</td>
              <td rowspan="1" colspan="1">0.878</td>
              <td rowspan="1" colspan="1">0.923</td>
              <td rowspan="1" colspan="1">0.941</td>
              <td rowspan="1" colspan="1">0.923</td>
              <td rowspan="1" colspan="1">0.913</td>
              <td rowspan="1" colspan="1">0.711</td>
              <td rowspan="1" colspan="1">0.881</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4:6</td>
              <td rowspan="1" colspan="1">0.885</td>
              <td rowspan="1" colspan="1">0.904</td>
              <td rowspan="1" colspan="1">0.936</td>
              <td rowspan="1" colspan="1">0.926</td>
              <td rowspan="1" colspan="1">0.831</td>
              <td rowspan="1" colspan="1">0.744</td>
              <td rowspan="1" colspan="1">0.871</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5:5</td>
              <td rowspan="1" colspan="1">0.918</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.733</td>
              <td rowspan="1" colspan="1">0.673</td>
              <td rowspan="1" colspan="1">0.915</td>
              <td rowspan="1" colspan="1">0.673</td>
              <td rowspan="1" colspan="1">0.809</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">6:4</td>
              <td rowspan="1" colspan="1">0.907</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.945</td>
              <td rowspan="1" colspan="1">0.703</td>
              <td rowspan="1" colspan="1">0.909</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.744</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">7:3</td>
              <td rowspan="1" colspan="1">0.902</td>
              <td rowspan="1" colspan="1">0.898</td>
              <td rowspan="1" colspan="1">0.940</td>
              <td rowspan="1" colspan="1">0.934</td>
              <td rowspan="1" colspan="1">0.853</td>
              <td rowspan="1" colspan="1">0.775</td>
              <td rowspan="1" colspan="1">0.884</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">8:2</td>
              <td rowspan="1" colspan="1">0.930</td>
              <td rowspan="1" colspan="1">0.886</td>
              <td rowspan="1" colspan="1">0.946</td>
              <td rowspan="1" colspan="1">0.873</td>
              <td rowspan="1" colspan="1">0.836</td>
              <td rowspan="1" colspan="1">0.922</td>
              <td rowspan="1" colspan="1">0.899</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.5 Transplant analysis</title>
      <p>To further demonstrate the advantages of the proposed algorithm in more aspects, we transplanted the circSI-SSL algorithm originally designed for circRNA into the binding protein prediction task of linRNA without any network modification and with consistent hyperparameters. In the performance comparison between the six widely used linRNAs and several supervised algorithms as shown in <xref rid="btae004-F8" ref-type="fig">Fig.Â 8</xref> below, the ratio of training set to test set is still 1:9. Remarkably, the proposed algorithm achieves the best overall performance without any task-oriented tuning. In <xref rid="btae004-F8" ref-type="fig">Fig.Â 8</xref>, we can see that although iCircRBP-DHN also obtained a good average AUC value, it can also clearly see huge fluctuations in ACC, Precison, and Recall, which are separate indicators. HCRNet algorithm is relatively stable, but its performance on Recall index is poor. In the case of a very small number of training datasets put into training, the performance of the above two in each indicator is not balanced, and the overall good performance is not achieved. Therefore, supervised learning algorithm is not a good choice when there are only a few labeled samples. In contrast, the algorithm in this article achieves the overall optimal performance, even in such a harsh environment.</p>
      <fig position="float" id="btae004-F8">
        <label>Figure 8.</label>
        <caption>
          <p>Comparison of transplant performance on linRNA datasets.</p>
        </caption>
        <graphic xlink:href="btae004f8" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this article, we propose the novel CircSI-SSL framework for circRNAâRBP site recognition tasks based on SSL. By designing a cross-view sequence prediction task, the algorithm can learn the overall representation of the sequence in an unsupervised manner, and significantly enhance subsequent RBP identification performance with only a small amount of supervised information. Based on the improved Transformer network RNA_Transformer in this article, the framework extracts sequence context features from multiple views to characterize the sequence. By designing reasonable and effective proxy tasks, along with a stable and efficient network architecture, significant improvements were achieved with only a small amount of supervised information on the widely used six circRNA datasets and six linRNA datasets compared to supervised learning algorithms.</p>
    <p>In short, the CircSI-SSL algorithm based on SSL has good identification performance, expansion performance, and wide application range, only a small amount of label information can significantly improve the recognition performance. It is a very competitive tool for circRNAâRBP binding site identification.</p>
  </sec>
</body>
<back>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>The work was supported by the National Natural Science Foundation of China [62231013, 62250028, 62271329]; the Sichuan Provincial Science Fund for Distinguished Young Scholars [2021JDJQ0025]; the fund of Shenzhen Polytechnic [6022310036K, 6023310037K]; and the Municipal Government of Quzhou [No. 2022D040].</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae004-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alipanahi</surname><given-names>B</given-names></string-name>, <string-name><surname>Delong</surname><given-names>A</given-names></string-name>, <string-name><surname>Weirauch</surname><given-names>MT</given-names></string-name></person-group><etal>et al</etal><article-title>Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</article-title>. <source>Nat Biotechnol</source><year>2015</year>;<volume>33</volume>:<fpage>831</fpage>â<lpage>8</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bogard</surname><given-names>B</given-names></string-name>, <string-name><surname>Francastel</surname><given-names>C</given-names></string-name>, <string-name><surname>HubÃ©</surname><given-names>F.</given-names></string-name></person-group><article-title>A new method for the identification of thousands of circular RNAs</article-title>. <source>Non-Coding RNA Investig</source><year>2018</year>;<volume>2</volume>:<fpage>5</fpage>.</mixed-citation>
    </ref>
    <ref id="btae004-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>C</given-names></string-name>, <string-name><surname>Yang</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>CircSSNN: circRNA-binding site prediction via sequence self-attention neural networks with pre-normalization</article-title>. <source>BMC Bioinformatics</source><year>2023</year>;<volume>24</volume>:<fpage>220</fpage>.<pub-id pub-id-type="pmid">37254080</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>L-L.</given-names></string-name></person-group><article-title>The biogenesis and emerging roles of circular RNAs</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2016</year>;<volume>17</volume>:<fpage>205</fpage>â<lpage>11</lpage>.<pub-id pub-id-type="pmid">26908011</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>T</given-names></string-name>, <string-name><surname>Kornblith</surname><given-names>S</given-names></string-name>, <string-name><surname>Norouzi</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal> A simple framework for contrastive learning of visual representations. In: <italic toggle="yes">International Conference on Machine Learning</italic>. Vienna, Austria, 13 July, 2020. <fpage>1597</fpage>â1<lpage>607</lpage>. PMLR, 2020.</mixed-citation>
    </ref>
    <ref id="btae004-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning models for disease-associated circRNA prediction: a review</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac364</fpage>.<pub-id pub-id-type="pmid">36130259</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dori</surname><given-names>M</given-names></string-name>, <string-name><surname>Haj Abdullah Alieh</surname><given-names>L</given-names></string-name>, <string-name><surname>Cavalli</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Sequence and expression levels of circular RNAs in progenitor cell types during mouse corticogenesis</article-title>. <source>Life Sci Alliance</source><year>2019</year>;<volume>2</volume>:<fpage>e201900354</fpage>.<pub-id pub-id-type="pmid">30926618</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dudekula</surname><given-names>DB</given-names></string-name>, <string-name><surname>Panda</surname><given-names>AC</given-names></string-name>, <string-name><surname>Grammatikakis</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>CircInteractome: a web tool for exploring circular RNAs and their interacting proteins and microRNAs</article-title>. <source>RNA Biol</source><year>2016</year>;<volume>13</volume>:<fpage>34</fpage>â<lpage>42</lpage>.<pub-id pub-id-type="pmid">26669964</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Eldele</surname><given-names>E</given-names></string-name>, <string-name><surname>Ragab</surname><given-names>M</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal> Time-series representation learning via temporal and contextual contrasting. In <source>Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence.</source> Montreal, Canada, August 19-27, 2021, IJCAI, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="btae004-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gidaris</surname><given-names>S</given-names></string-name>, <string-name><surname>Singh</surname><given-names>P</given-names></string-name>, <string-name><surname>Komodakis</surname><given-names>N.</given-names></string-name></person-group> Unsupervised representation learning by predicting image rotations. In <italic toggle="yes">ICLR 2018</italic>, <italic toggle="yes">Vancouver Convention Center, Vancouver, BC, Canada, April 30 - May 3</italic>, <year>2018</year>, OpenReview.net.</mixed-citation>
    </ref>
    <ref id="btae004-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>GlaÅ¾ar</surname><given-names>P</given-names></string-name>, <string-name><surname>Papavasileiou</surname><given-names>P</given-names></string-name>, <string-name><surname>Rajewsky</surname><given-names>N.</given-names></string-name></person-group><article-title>circBase: a database for circular RNAs</article-title>. <source>RNA</source><year>2014</year>;<volume>20</volume>:<fpage>1666</fpage>â<lpage>70</lpage>.<pub-id pub-id-type="pmid">25234927</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hao</surname><given-names>S</given-names></string-name>, <string-name><surname>Lv</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Q</given-names></string-name></person-group><etal>et al</etal><article-title>Identification of key genes and circular RNAs in human gastric cancer</article-title>. <source>Med Sci Monit</source><year>2019</year>;<volume>25</volume>:<fpage>2488</fpage>â<lpage>504</lpage>.<pub-id pub-id-type="pmid">30948703</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K</given-names></string-name>, <string-name><surname>Fan</surname><given-names>H</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal> Momentum contrast for unsupervised visual representation learning. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>. <fpage>9729</fpage>â<lpage>38</lpage>. <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btae004-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>W</given-names></string-name>, <string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Duan</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>70ProPred: a predictor for discovering sigma70 promoters based on combining multiple features</article-title>. <source>BMC Syst Biol</source><year>2018</year>;<volume>12</volume>:<fpage>44</fpage>.<pub-id pub-id-type="pmid">29745856</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hjelm</surname><given-names>RD</given-names></string-name>, <string-name><surname>Fedorov</surname><given-names>A</given-names></string-name>, <string-name><surname>Lavoie-Marchildon</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal> Learning deep representations by mutual information estimation and maximization. In <italic toggle="yes">International Conference on Learning Representations</italic>. New Orleans, LA, USA, May 6-9, 2019. <year>2019</year>, OpenReview.net.</mixed-citation>
    </ref>
    <ref id="btae004-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X.</given-names></string-name></person-group><article-title>Updated review of advances in microRNAs and complex diseases: taxonomy, trends and challenges of computational models</article-title>. <source>Brief Bioinform</source><year>2022a</year>;<volume>23</volume>:<fpage>bbac358</fpage>.<pub-id pub-id-type="pmid">36056743</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X.</given-names></string-name></person-group><article-title>Updated review of advances in microRNAs and complex diseases: towards systematic evaluation of computational models</article-title>. <source>Brief Bioinform</source><year>2022b</year>;<volume>23</volume>:<fpage>bbac407</fpage>.<pub-id pub-id-type="pmid">36151749</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Bi</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>PASSION: an ensemble neural network approach for identifying the binding sites of RBPs on circRNAs</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>4276</fpage>â<lpage>82</lpage>.<pub-id pub-id-type="pmid">32426818</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiao</surname><given-names>S</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Huang</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Advances in the identification of circular RNAs and research into circRNAs in human diseases</article-title>. <source>Front Genet</source><year>2021</year>;<volume>12</volume>:<fpage>665233</fpage>.<pub-id pub-id-type="pmid">33815488</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ju</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>L</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>CircSLNN: identifying RBP-binding sites on circRNAs via sequence labeling neural networks</article-title>. <source>Front Genet</source><year>2019</year>;<volume>10</volume>:<fpage>1184</fpage>.<pub-id pub-id-type="pmid">31824574</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>Q</given-names></string-name>, <string-name><surname>Mikolov</surname><given-names>T.</given-names></string-name></person-group> Distributed representations of sentences and documents. In: <italic toggle="yes">International Conference on Machine Learning</italic>, <italic toggle="yes">Beijing, China, on June 21âJune 26, 2014</italic>. <fpage>1188</fpage>â<lpage>96</lpage>. <publisher-name>PMLR, 2014.</publisher-name></mixed-citation>
    </ref>
    <ref id="btae004-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>S</given-names></string-name>, <string-name><surname>Han</surname><given-names>L.</given-names></string-name></person-group><article-title>Circular RNAs as promising biomarkers in cancer: detection, function, and beyond</article-title>. <source>Genome Med</source><year>2019</year>;<volume>11</volume>:<fpage>15</fpage>.<pub-id pub-id-type="pmid">30894216</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>W</given-names></string-name>, <string-name><surname>Godzik</surname><given-names>A.</given-names></string-name></person-group><article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source><year>2006</year>;<volume>22</volume>:<fpage>1658</fpage>â<lpage>9</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal><article-title>Self-supervised learning: generative or contrastive</article-title>. <source>IEEE Trans Knowl Data Eng</source><year>2021</year>;<volume>35</volume>:<fpage>1</fpage>â<lpage>876</lpage>.<pub-id pub-id-type="pmid">36506788</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>AS</given-names></string-name>, <string-name><surname>Sreenadhan</surname><given-names>SP.</given-names></string-name></person-group><article-title>A coding measure scheme employing electron-ion interaction pseudopotential (EIIP)</article-title>. <source>Bioinformation</source><year>2006</year>;<volume>1</volume>:<fpage>197</fpage>â<lpage>202</lpage>.<pub-id pub-id-type="pmid">17597888</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Ju</surname><given-names>Y</given-names></string-name>, <string-name><surname>Lin</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Characterizing viral circRNAs and their application in identifying circRNAs in viruses</article-title>. <source>Brief Bioinform</source><year>2022a</year>;<volume>23</volume>:<fpage>bbab404</fpage>.<pub-id pub-id-type="pmid">34585234</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Lin</surname><given-names>C.</given-names></string-name></person-group><article-title>CRBPDL: identification of circRNA-RBP interaction sites using an ensemble neural network approach</article-title>. <source>PLoS Comput Biol</source><year>2022b</year>;<volume>18</volume>:<fpage>e1009798</fpage>.<pub-id pub-id-type="pmid">35051187</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C.</given-names></string-name></person-group><article-title>GMNN2CD: identification of circRNAâdisease associations based on variational inference and graph Markov neural networks</article-title>. <source>Bioinformatics</source><year>2022c</year>;<volume>38</volume>:<fpage>2246</fpage>â<lpage>53</lpage>.<pub-id pub-id-type="pmid">35157027</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B29">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Noroozi</surname><given-names>M</given-names></string-name>, <string-name><surname>Favaro</surname><given-names>P.</given-names></string-name></person-group> Unsupervised learning of visual representations by solving jigsaw puzzles. In: <italic toggle="yes">European Conference on Computer Vision</italic>, <italic toggle="yes">Amsterdam, Netherlands, October 10-16, 2016</italic>. <fpage>69</fpage>â<lpage>84</lpage>. Springer, 2016.</mixed-citation>
    </ref>
    <ref id="btae004-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Oord</surname><given-names>A</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Vinyals</surname><given-names>O.</given-names></string-name></person-group> Representation learning with contrastive predictive coding. arXiv, arXiv:1807.03748, <year>2018</year>. <pub-id pub-id-type="doi">10.48550/arXiv.1807.03748</pub-id>.</mixed-citation>
    </ref>
    <ref id="btae004-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orenstein</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Berger</surname><given-names>B.</given-names></string-name></person-group><article-title>RCK: accurate and efficient inference of sequence-and structure-based proteinâRNA binding models from RNAcompete data</article-title>. <source>Bioinformatics</source><year>2016</year>;<volume>32</volume>:<fpage>i351</fpage>â<lpage>9</lpage>.<pub-id pub-id-type="pmid">27307637</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pan</surname><given-names>X</given-names></string-name>, <string-name><surname>Rijnbeek</surname><given-names>P</given-names></string-name>, <string-name><surname>Yan</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks</article-title>. <source>BMC Genomics</source><year>2018</year>;<volume>19</volume>:<fpage>511</fpage>.<pub-id pub-id-type="pmid">29970003</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ruan</surname><given-names>H</given-names></string-name>, <string-name><surname>Xiang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ko</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Comprehensive characterization of circular RNAs inâ¼ 1000 human cancer cell lines</article-title>. <source>Genome Med</source><year>2019</year>;<volume>11</volume>:<fpage>55</fpage>.<pub-id pub-id-type="pmid">31446897</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rybak-Wolf</surname><given-names>A</given-names></string-name>, <string-name><surname>Stottmeister</surname><given-names>C</given-names></string-name>, <string-name><surname>GlaÅ¾ar</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>Circular RNAs in the mammalian brain are highly abundant, conserved, and dynamically expressed</article-title>. <source>Mol Cell</source><year>2015</year>;<volume>58</volume>:<fpage>870</fpage>â<lpage>85</lpage>.<pub-id pub-id-type="pmid">25921068</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Su</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>J</given-names></string-name>, <string-name><surname>Su</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>CircRNAs in lung adenocarcinoma: diagnosis and therapy</article-title>. <source>Curr Gene Ther</source><year>2022</year>;<volume>22</volume>:<fpage>15</fpage>â<lpage>22</lpage>.<pub-id pub-id-type="pmid">34856899</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A</given-names></string-name>, <string-name><surname>Shazeer</surname><given-names>N</given-names></string-name>, <string-name><surname>Parmar</surname><given-names>N</given-names></string-name></person-group> et al. Attention is all you need. In: Advances in Neural Information Processing Systems, <italic toggle="yes">Long Beach, USA, December 4-9, 2017</italic>. Vol. 30. MIT Press, 2017.</mixed-citation>
    </ref>
    <ref id="btae004-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>CC</given-names></string-name>, <string-name><surname>Han</surname><given-names>CD</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>Q</given-names></string-name></person-group><etal>et al</etal><article-title>Circular RNAs and complex diseases: from experimental results to computational models</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbab286</fpage>.<pub-id pub-id-type="pmid">34329377</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Li</surname><given-names>B</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>T</given-names></string-name></person-group><etal>et al</etal> Learning deep transformer models for machine translation. In <italic toggle="yes">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</italic>. Florence, Italy, July, <year>2019a</year>, Association for Computational Linguistics.</mixed-citation>
    </ref>
    <ref id="btae004-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Lei</surname><given-names>X</given-names></string-name>, <string-name><surname>Wu</surname><given-names>F-X.</given-names></string-name></person-group><article-title>Identifying cancer-specific circRNAâRBP binding sites based on deep learning</article-title>. <source>Molecules</source><year>2019b</year>;<volume>24</volume>:<fpage>4035</fpage>.<pub-id pub-id-type="pmid">31703384</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal><article-title>iCircRBP-DHN: identification of circRNA-RBP interaction sites using deep hierarchical network</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbaa274</fpage>.<pub-id pub-id-type="pmid">33126261</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>HCRNet: high-throughput circRNA-binding event identification from CLIP-seq data using deep temporal convolutional network</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac027</fpage>.<pub-id pub-id-type="pmid">35189638</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yee</surname><given-names>BA</given-names></string-name>, <string-name><surname>Pratt</surname><given-names>GA</given-names></string-name>, <string-name><surname>Graveley</surname><given-names>BR</given-names></string-name></person-group><etal>et al</etal><article-title>RBP-Maps enables robust generation of splicing regulatory maps</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>193</fpage>â<lpage>204</lpage>.<pub-id pub-id-type="pmid">30413564</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zang</surname><given-names>J</given-names></string-name>, <string-name><surname>Lu</surname><given-names>D</given-names></string-name>, <string-name><surname>Xu</surname><given-names>A.</given-names></string-name></person-group><article-title>The interaction of circRNAs and RNA binding proteins: an important part of circRNA maintenance and function</article-title>. <source>J Neurosci Res</source><year>2020</year>;<volume>98</volume>:<fpage>87</fpage>â<lpage>97</lpage>.<pub-id pub-id-type="pmid">30575990</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H-D</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>L-H</given-names></string-name>, <string-name><surname>Sun</surname><given-names>D-W</given-names></string-name></person-group><etal>et al</etal><article-title>CircRNA: a novel type of biomarker for cancer</article-title>. <source>Breast Cancer</source><year>2018</year>;<volume>25</volume>:<fpage>1</fpage>â<lpage>7</lpage>.<pub-id pub-id-type="pmid">28721656</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>K</given-names></string-name>, <string-name><surname>Pan</surname><given-names>X</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>CRIP: predicting circRNAâRBP-binding sites using a codon-based encoding and hybrid deep neural networks</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>1604</fpage>â<lpage>15</lpage>.<pub-id pub-id-type="pmid">31537716</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B46">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>R</given-names></string-name>, <string-name><surname>Isola</surname><given-names>P</given-names></string-name>, <string-name><surname>Efros</surname><given-names>AA.</given-names></string-name></person-group> Colorful image colorization. In: <italic toggle="yes">Computer VisionâECCV 2016: 14th European Conference, Amsterdam, Netherlands, October 11-14, 2016, Proceedings, Part III 14.</italic><fpage>649</fpage>â<lpage>66</lpage>. Springer, <year>2016</year>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10789309</article-id>
    <article-id pub-id-type="pmid">38180876</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae004</article-id>
    <article-id pub-id-type="publisher-id">btae004</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CircSI-SSL: circRNA-binding site identification based on self-supervised learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6730-9422</contrib-id>
        <name>
          <surname>Cao</surname>
          <given-names>Chao</given-names>
        </name>
        <aff><institution>Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China</institution>, Quzhou, Zhejiang 324003, <country country="CN">China</country></aff>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, Sichuan 611731, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2965-9920</contrib-id>
        <name>
          <surname>Wang</surname>
          <given-names>Chunyu</given-names>
        </name>
        <aff><institution>Faculty of Computing, Harbin Institute of Technology</institution>, Harbin, Heilongjiang 150001, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Shuhong</given-names>
        </name>
        <aff><institution>Faculty of Mathematics and Computer Science, Guangdong Ocean University</institution>, Zhanjiang, Guangdong 524088, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6406-1142</contrib-id>
        <name>
          <surname>Zou</surname>
          <given-names>Quan</given-names>
        </name>
        <aff><institution>Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China</institution>, Quzhou, Zhejiang 324003, <country country="CN">China</country></aff>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, Sichuan 611731, <country country="CN">China</country></aff>
        <xref rid="btae004-cor1" ref-type="corresp"/>
        <!--zouquan@nclab.net-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Valencia</surname>
          <given-names>Alfonso</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae004-cor1">Corresponding author. Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China, Quzhou, Zhejiang 324003, China. E-mail: <email>zouquan@nclab.net</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-01-05">
      <day>05</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>1</issue>
    <elocation-id>btae004</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>13</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>28</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>15</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae004.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>In recent years, circular RNAs (circRNAs), the particular form of RNA with a closed-loop structure, have attracted widespread attention due to their physiological significance (they can directly bind proteins), leading to the development of numerous protein site identification algorithms. Unfortunately, these studies are supervised and require the vast majority of labeled samples in training to produce superior performance. But the acquisition of sample labels requires a large number of biological experiments and is difficult to obtain.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To resolve this matter that a great deal of tags need to be trained in the circRNA-binding site prediction task, a self-supervised learning binding site identification algorithm named CircSI-SSL is proposed in this article. According to the survey, this is unprecedented in the research field. Specifically, CircSI-SSL initially combines multiple feature coding schemes and employs RNA_Transformer for cross-view sequence prediction (self-supervised task) to learn mutual information from the multi-view data, and then fine-tuning with only a few sample labels. Comprehensive experiments on six widely used circRNA datasets indicate that our CircSI-SSL algorithm achieves excellent performance in comparison to previous algorithms, even in the extreme case where the ratio of training data to test data is 1:9. In addition, the transplantation experiment of six linRNA datasets without network modification and hyperparameter adjustment shows that CircSI-SSL has good scalability. In summary, the prediction algorithm based on self-supervised learning proposed in this article is expected to replace previous supervised algorithms and has more extensive application value.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code and data are available at <ext-link xlink:href="https://github.com/cc646201081/CircSI-SSL" ext-link-type="uri">https://github.com/cc646201081/CircSI-SSL</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62231013</award-id>
        <award-id>62250028</award-id>
        <award-id>62271329</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Sichuan Provincial Science Fund for Distinguished Young Scholars</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2021JDJQ0025</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Shenzhen Polytechnic</institution>
            <institution-id institution-id-type="DOI">10.13039/100012840</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>6022310036K</award-id>
        <award-id>6023310037K</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Municipal Government of Quzhou</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2022D040</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Circular RNA (circRNA) is the peculiar class of RNAs produced by pre-mRNA. Unlike common RNAs with the two ends of 5â² and 3â², circRNA has a unique ring structure formed by the reverse splicing mechanism (<xref rid="btae004-B2" ref-type="bibr">Bogard <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae004-B12" ref-type="bibr">Hao <italic toggle="yes">et al.</italic> 2019</xref>), widely present in human, hippocampus, mouse, and other cells and tissues (<xref rid="btae004-B7" ref-type="bibr">Dori <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae004-B22" ref-type="bibr">Li and Han 2019</xref>). This special structure can enhance the stability of circRNA and usually has a stage-specific expression pattern (<xref rid="btae004-B34" ref-type="bibr">Rybak-Wolf <italic toggle="yes">et al.</italic> 2015</xref>). More and more evidence has proved that circRNA can participate in the processes of gene expression regulation through combining the corresponding RNA-binding protein (RBP) (<xref rid="btae004-B4" ref-type="bibr">Chen 2016</xref>, <xref rid="btae004-B43" ref-type="bibr">Zang <italic toggle="yes">et al.</italic> 2020</xref>). Like other non-coding RNAs (<xref rid="btae004-B16" ref-type="bibr">Huang <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B17" ref-type="bibr">b</xref>), It can also play a crucial part in the screening and therapy of many diseases (<xref rid="btae004-B19" ref-type="bibr">Jiao <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btae004-B37" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2021</xref>), especially cancer (<xref rid="btae004-B44" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae004-B35" ref-type="bibr">Su <italic toggle="yes">et al.</italic> 2022</xref>). Therefore, the understanding of the action mechanism between circRNA and RBP is crucial to reveal the circRNA formation and its biological function (<xref rid="btae004-B6" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btae004-B26" ref-type="bibr">Niu <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B27" ref-type="bibr">b</xref>,<xref rid="btae004-B28" ref-type="bibr">c</xref>).</p>
    <p>With the emergence of some biological technologies about sequencing, such as high-throughput sequencing with crosslinking immunoprecipitation (HITS-CLIP), many RBP targets in mature circRNAs have been found in eukaryotes (<xref rid="btae004-B8" ref-type="bibr">Dudekula <italic toggle="yes">et al.</italic> 2016</xref>, <xref rid="btae004-B33" ref-type="bibr">Ruan <italic toggle="yes">et al.</italic> 2019</xref>). However, due to the high cost of detecting each pair of interaction sites, many computational methods for identifying circRNAâRBP sites have been developed. Thanks to the advancements in deep learning, the identification performance of RBP-binding sites has been continuously improved. For example, CSCRSites (<xref rid="btae004-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2019a</xref>,<xref rid="btae004-B39" ref-type="bibr">b</xref>) is a deep learning algorithm that identifies RBP-binding sites about cancer-specific only using nucleotide sequences information. CircSLNN (<xref rid="btae004-B20" ref-type="bibr">Ju <italic toggle="yes">et al.</italic> 2019</xref>) is a novel approach that transforms the RNA-binding site prediction problem into a sequence labeling problem, which adopts a word-embedded based coding scheme to capture the context and semantic information of sequences. CRIP (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>) proposes a stacked codon encoding deep learning algorithm based on convolutional neural networks and recurrent neural networks, which respectively learn abstract features and sequence dependences to complete the RBP-binding site recognition task. However, these methods are single-view algorithms, and the useful features obtained from the sequence are quite limited, and often constrained by the size of the data, and cannot achieve good performance. Subsequently, researchers have introduced some multi-view algorithms. PASSION (<xref rid="btae004-B18" ref-type="bibr">Jia <italic toggle="yes">et al.</italic> 2020</xref>) is a multi-view integrated neural network algorithm, and the optimal feature subset is selected and input into the network through incremental features selection and XGBoost algorithm. iCircRBP-DHN (<xref rid="btae004-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>) proposes to use two new encoding schemes: K-tuple nucleotide frequency patterns and CircRNA2Vec word embedding encoding as inputs. Deep multi-scale residual network, bidirectional gate recurrent unit (BiGRU), and self-attention mechanism are used as algorithms for deep network architecture. CRBPDL (<xref rid="btae004-B26" ref-type="bibr">Niu <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B27" ref-type="bibr">b</xref>,<xref rid="btae004-B28" ref-type="bibr">c</xref>) proposes an Adaboost integrated deep network architecture, which includes deep multi-scale residual networks and BiGRU. The performance of the algorithm is further improved. HCRNET (<xref rid="btae004-B41" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2022</xref>) incorporates a fine-tuned DNABERT model and a deep temporal convolutional network to capture global context-dependent semantic and syntactic information for circRNA sequences.</p>
    <p>As for the networks based on CNN, RNN or their deformation used in the above research as deep feature extraction networks, there are problems, such as poor network parallel capability, difficulty to capture features long-time series dependence, and insufficient algorithm stability. CircSSNN (<xref rid="btae004-B3" ref-type="bibr">Cao <italic toggle="yes">et al.</italic> 2023</xref>) proposes an algorithm that fully uses the self-attention mechanism to extract deep features and achieves better performance. Although these algorithms are constantly updating the performance of the recognition task, they are based on supervised learning, in other words, the algorithm requires a great number of sample labels in network training. Usually, the ratio of training samples to test samples is as high as 80%:20%. Although the algorithm achieves good performance, it greatly limits the exploration of the unknown circRNAâRBP interaction mechanism. As a consequence, it has immense practical significance to develop an algorithm based on supervised weakly, self-supervised, and even unsupervised in this task.</p>
    <p>Self-supervised learning (SSL) (<xref rid="btae004-B24" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2021</xref>) is a special kind of unsupervised learning. It learns required features without the need for real labels through pre-designed agent tasks, and subsequent tasks often require only a few labels (or even none) to significantly enhance performance according to specific tasks. Contrast learning performs particularly well in computer vision because it can learn invariant representations from enhanced data without label information (<xref rid="btae004-B15" ref-type="bibr">Hjelm <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae004-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae004-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic> 2020</xref>), demonstrating significant self-supervised capabilities. The specific operation process is as follows: first, data augmentation is used to get a number of different perspectives (usually two) from the original image that are slightly different. Then, different views of the same sample are taken as positive sample pairs and the others as negative samples. By maximizing the similarity between positive sample pairs and minimizing the similarity between positive sample and negative sample, a âlabelâ is artificially constructed to guide the learning of network features. However, while contrast learning can be useful in the field of images, it is difficult to apply to time-series data for several reasons: above all, there exists a challenge of capturing temporal dependencies in the data, which is very critical. Secondly, image-based augmentation techniques, such as random cropping, do not work with time-series datasets. Thus far, there have been few studies on contrast learning for time-series data, and it has not been applied to the prediction of circRNA-binding sites.</p>
    <p>For the sake of reducing the dependence of the algorithm on the sample label as much as possible, thereby enhancing its applicability across a wider range of scenarios. This article carried out in-depth research and innovatively proposed an algorithm named circRNA-binding site identification based on self-supervised learning (CircSI-SSL). The algorithm uses only KNFP, CircRNA2Vec, and electronâion interaction pseudo-potential (EIIP) shallow statistical feature descriptors, which reduces the computational resource requirements. After encoding, our Transformer model RNA_Transformer, which is improved for CircRNA recognition task, is used to: (i) perform cross-view sequence prediction tasks to train the network, capture temporal dependencies in sequence multi-view data, and learn the overall representation of the sequence; (ii) apply a very small number of sample tags (10%) to fine-tune network parameters for a specific task, thereby completing the RBP-binding site prediction task. Through a comprehensive experiment conducted on 12 widely used datasets, it is shown that the algorithm obtains a significant improvement over the supervised learning algorithms. In summary, the primary contributions of this article can be outlined as follows.</p>
    <p>A novelSSL method is applied in the domain of circRNA-binding protein recognition, which changes the situation that most of the label information is needed to obtain good performance. Using only a small amount of supervised information can lead to a substantial enhancement in the algorithmâs performance, which has a wide range of application value.</p>
    <p>We propose a novel proxy task that captures sequence temporal dependencies using an improved RNA_Transformer as a benchmark model and completes cross-view sequence prediction based on multiple feature descriptors instead of using sequence augmentation techniques.</p>
    <p>Comprehensive experiments conducted on six widely used circRNA datasets and six linRNA datasets demonstrate that the proposed algorithm exhibits comprehensive advantages over previous supervised learning approaches. Even when utilizing only 10% of the labeled data for training, the proposed algorithm demonstrates stable and outstanding performance, along with robust scalability.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>In order to assess the validity of our approach, we selected six widely used circRNA datasets, WTAP, FXR1, C17ORF85, QKI, TAF15, and AUF1. These circRNA sequences derive from circRNA interaction set of database (<ext-link xlink:href="https://circinteractome.nia.nih.gov/" ext-link-type="uri">https://circinteractome.nia.nih.gov/</ext-link>), which extracted data includes circRNAâRBP interaction information, also includes RBPs that bind to mature circRNA upstream and downstream flanker sequences (<xref rid="btae004-B42" ref-type="bibr">Yee <italic toggle="yes">et al.</italic> 2019</xref>). We then use the identical data processing steps as previous research (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>). Resulting 101 nucleotides sequence fragments in length are obtained as positive samples, and randomly selecting other sequences to acquire negative samples with same numbers. These similar sequences are removed using CD-HIT technique, with the threshold of 0.8 (<xref rid="btae004-B23" ref-type="bibr">Li and Godzik 2006</xref>). After the removal of sequence redundancy, a total of 15Â 570 samples were obtained, and all samples used in the experiments were randomly shuffled.</p>
      <p>In addition, we transplant the circSI-SSL algorithm to linear RNA datasets and compare the performance of several existing supervised algorithms in identifying RBP interactions. The same linear RNA datasets are downloaded from iDeepS (<xref rid="btae004-B32" ref-type="bibr">Pan <italic toggle="yes">et al.</italic> 2018</xref>) and DeepBind (<xref rid="btae004-B1" ref-type="bibr">Alipanahi <italic toggle="yes">et al.</italic> 2015</xref>), including six datasets after HITS-CLIP processing: hnRNPC-2, U2AF65, hnRNPC-1, QKI, ELVAL1-2, and Y2AF65.</p>
    </sec>
    <sec>
      <title>2.2 Feature muti-descriptors</title>
      <p>To enrich the originally single sequence, we employ three quantitative feature methods to extract the preliminary statistical features of the sequence: (i) KNFP, which is used to capture local semantic features at disparate positions. (ii) CircRNA2Vec, which is employed to capture remote dependencies. (iii) The EIIP, which is utilized to characterize the free electron energy on the circRNA sequence.</p>
      <sec>
        <title>2.2.1 KNFP</title>
        <p>In this section, we introduce KNFP schema in detail. Different from the traditional One-hot representation (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>), KNFP schema can extract various short-range sequence-dependent information (<xref rid="btae004-B31" ref-type="bibr">Orenstein <italic toggle="yes">et al.</italic> 2016</xref>) and local semantic features, which greatly makes up for the deficiency of One-hot information and retains the original sequence schema.</p>
        <p>Taking a specific circRNA sequence of length <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>L</mml:mi></mml:math></inline-formula> as an example, KNFP slidingly selects <italic toggle="yes">k</italic> consecutive nucleotides on the circRNA sequence, and counts the frequencies of the corresponding combinations in the form of <italic toggle="yes">k</italic> tuples (different combinations of <italic toggle="yes">k</italic> nucleotides), as the final encoding. In detail, for a <italic toggle="yes">k</italic>-tuple, which has <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> different combinations, the frequency <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>p</mml:mi></mml:math></inline-formula> of the corresponding <italic toggle="yes">K</italic>-tuple pattern is statistically calculated according to the specific circRNA sequence.
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi mathvariant="normal">Â </mml:mi></mml:math></inline-formula>represents the frequency of the <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>-th <italic toggle="yes">k</italic>-tuple pattern. Upon processing a single circRNA sequence, the resulting feature dimension becomes <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:math></inline-formula>. We concatenate the encoded features obtained by <italic toggle="yes">k</italic>â=â1, 2, and 3, respectively, and complete them with 0 at the end.</p>
      </sec>
      <sec>
        <title>2.2.2 CircRNA2Vec</title>
        <p>CircRNA2Vect (<xref rid="btae004-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>) is a feature descriptor that employs the Doc2Vec algorithm to learn global contextual features of circRNA. Doc2Vec (<xref rid="btae004-B21" ref-type="bibr">Le and Mikolov 2014</xref>) is an extension of Word2Vec, capable of learning fixed-length feature representations from variable-length texts. Unlike Word2Vec, Doc2Vec introduces an additional paragraph vector <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> at the input layer, which captures the contextual information of paragraphs. This enables the linkage of word vectors with paragraph vectors, addressing the limitation of Word2Vec that focuses solely on training word vectors while overlooking the grasp of paragraph-level context.</p>
        <p>We collect as many circRNA splicing sequences as possible from circBase (<xref rid="btae004-B11" ref-type="bibr">GlaÅ¾ar <italic toggle="yes">et al.</italic> 2014</xref>) to serve as the corpus. Utilizing a sliding window of size 10, extract subsequences from each circRNA sequence, resulting in multiple sequences. This allows the algorithm to capture semantic information within these subsequences for modeling purposes. Given a text sequence of length <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="normal">T</mml:mi></mml:math></inline-formula>, where the word at time step <italic toggle="yes">t</italic> is denoted as <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For context window size <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, the likelihood function of the model is the probability of generating a specific word <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which express as term <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. The goal of the model is to maximize the average logarithmic probability as follow:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>â</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.2.3 EIIP</title>
        <p>EIIP, as introduced by <xref rid="btae004-B25" ref-type="bibr">Nair and Sreenadhan (2006)</xref>, is a novel feature encoding scheme that describes the energy of delocalized electrons in amino acids and nucleotides present in circRNA sequences. Four binary indicator sequences are used to encode the sequence. It has been widely utilized in the Resonance Recognition Model. The EIIP values for the nucleotide âG,â âC,â âT,â and âAâ are â0.0806,â â0.1340,â â0.1335,â and â0.1260,â respectively. To enrich the feature representation, we incorporate a PSTNPss encoding scheme. It is position-specific feature encoding based on single-strand of DNA. See <xref rid="btae004-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic> (2018)</xref> for more details.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 CircSI-SSL algorithm architecture</title>
      <p>In this section, we introduce the CircSI-SSL self-supervised algorithm framework for learning high-quality representations of sequences, using only a small number of samples to fine-tune the CircSI-SSL algorithm for specific tasks to achieve excellent results. The overall framework is shown in <xref rid="btae004-F1" ref-type="fig">Fig.Â 1</xref>. For a more intuitive understanding, we provide the pseudo-code as follow. The model consists of two components: cross-view prediction and fine-tuning. (i) Multiple feature encoders are employed to encode initial features obtained from various descriptors extracted from the raw sequence data. A cross-view sequence prediction is conducted using RNA_Transformer. (ii) The trained encoded features are then fused, followed by employing RNA_Transformer to extract structured features from the fused multi-view features based on a small number of labels, facilitating the classification task.</p>
      <fig position="float" id="btae004-F1">
        <label>Figure 1.</label>
        <caption>
          <p>CircSI-SSL framework.</p>
        </caption>
        <graphic xlink:href="btae004f1" position="float"/>
      </fig>
      <boxed-text id="btae004-BOX1" position="float">
        <label>Algorithm 1</label>
        <caption>
          <p>CircSI-SSL</p>
        </caption>
        <p><bold>Input:</bold> CircRNA sequence x, label y, Maximum iterations MaxIter</p>
        <p><bold>Output:</bold> Neural network parameters W, Prediction label y'</p>
        <p>1.ââfor iter in range(MaxIter): # Self-supervised stage</p>
        <p>2.ââenc1â=âKNFP(x)</p>
        <p>3.ââenc2â=âCircRNA2Vec(x)</p>
        <p>4.ââenc3â=âEIIP(x)</p>
        <p>5.ââc1â=âRNA_Transformer(enc1) # Context c1 of enc1 is extracted by RNA_Transformer</p>
        <p>6.ââc2â=âRNA_Transformer(enc2)</p>
        <p>7.ââc3â=âRNA_Transformer(enc3)</p>
        <p>8.ââCalculate cross-view contrast loss according to Formula 6 and 7</p>
        <p>9.ââUpdate W according to Adam optimizer</p>
        <p>10.ââfor iter in range(MaxIter): # Fine-tuning stage</p>
        <p>11.ââenc = concatenate([enc1, enc2, enc3]) # Obtaining the enc1, enc2, enc3 follows the same steps as above</p>
        <p>12.ââc = RNA_Transformer(enc)</p>
        <p>13.ââyâ = softmax(c)</p>
        <p>14.ââCalculate cross-entropy loss of y and y' according to Formula 9</p>
        <p>15.ââFine-tune W according to Adam optimizer</p>
      </boxed-text>
      <sec>
        <title>2.3.1 Cross-view prediction</title>
        <p>The initial research on SSL started with the application of agent tasks on image datasets, which aims to learn high-quality representations. For example, some previous work predicts image rotation (<xref rid="btae004-B10" ref-type="bibr">Gidaris <italic toggle="yes">et al.</italic> 2018</xref>), images colorization (<xref rid="btae004-B46" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2016</xref>), and puzzle solving (<xref rid="btae004-B29" ref-type="bibr">Noroozi and Favaro 2016</xref>). By using image augmentation technology to construct positive and negative samples, the application range of contrast learning is broadened: case discrimination fields, such as SimCLR (<xref rid="btae004-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2020</xref>) and MoCo (<xref rid="btae004-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic> 2020</xref>); time-series analysis, such as CPC (<xref rid="btae004-B30" ref-type="bibr">Oord <italic toggle="yes">et al.</italic> 2018</xref>) and TS-TC (<xref rid="btae004-B9" ref-type="bibr">Eldele <italic toggle="yes">et al.</italic> 2021</xref>). Unfortunately, these algorithmsâ performance depends heavily on the augmentation techniques used, especially for time-series data, and it is difficult to find a set of effective and widely used augmentation techniques for operations, such as random cropping and image graying. This greatly restricts the application of contrast learning to time-series data. Building upon this, this article studies a new contrast task, which extracts features from multiple real views for mutual prediction without the help of augmentation techniques.</p>
        <p>We take the improved Transformer (<xref rid="btae004-B36" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic> 2017</xref>) and TS-TC (<xref rid="btae004-B9" ref-type="bibr">Eldele <italic toggle="yes">et al.</italic> 2021</xref>) as feature extraction networks, as revealed in <xref rid="btae004-F2" ref-type="fig">Fig.Â 2</xref>. It principal consists of Multi-head Attention and Feed Forward Neural Network (FFN), Layer Normalization (LN) blocks. The FFN block consists of a fully connected layer, a non-linear ReLU function and dropout. The model uses a pre-norm residual connection (<xref rid="btae004-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2019a</xref>,<xref rid="btae004-B39" ref-type="bibr">b</xref>) and LN prior to passing through a multi-head self-attention network, resulting in more stable gradients:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>LN</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>Î³</mml:mo><mml:mo>,</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>â</mml:mo><mml:mo>Î¼</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>Ï</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mo>Ïµ</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>â</mml:mo><mml:mo>Î³</mml:mo><mml:mo>+</mml:mo><mml:mo>Î²</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtext>MHA</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>softmax</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>V</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <fig position="float" id="btae004-F2">
          <label>Figure 2.</label>
          <caption>
            <p>RNA_Transformer structure.</p>
          </caption>
          <graphic xlink:href="btae004f2" position="float"/>
        </fig>
        <p>Where <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mo>Î¼</mml:mo></mml:math></inline-formula> and <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mo>Ï</mml:mo></mml:math></inline-formula> are the mean and variance of <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>z</mml:mi></mml:math></inline-formula>, respectively, <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Î³</mml:mi></mml:math></inline-formula> and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Î²</mml:mi></mml:math></inline-formula> represent the parameter vectors of scaling and translation, respectively. Query information, key information, and value information related to a specific task are represented as <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mi>q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula>, respectively. The number of operation heads is represented as<inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>h</mml:mi></mml:math></inline-formula>, and the aggregated <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi>q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> after multiple heads are denoted as <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mi>Q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mi>K</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>V</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> respectively. Here, <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> signifies the dimensions of the input vector. Then, LayerNorm regularization is carried out, and the features extracted by multiple heads are aggregated through FFN blocks to finally obtain the context feature <italic toggle="yes">C</italic> that represents the whole sequence.</p>
        <p>The entire process can be summarized as follows: given a circRNA sequence with a batch size of <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula>, the preliminary features <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are extracted by CircRNA2Vec and EIIP descriptors, respectively. It is then encoded by an encoder (using a 1D convolutional neural network) as <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>and <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where the feature sequence length is <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula>. Then, context variables <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are extracted by improved transformer respectively, and cross-view mutual prediction is carried out. The loss functions are:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">self</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">diag</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">diag</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.3.2 Fine-tuning</title>
        <p>After mutual prediction across the sequence of views, we get the trained RNA_Transformer. This allows him to learn the expression of the context of the overview from the sequence features. We then fine-tune the network for specific tasks to meet the needs of circRNAâprotein binding site prediction. Specifically, we combine the features <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">all</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> encoded by the above three feature descriptors and input them into RNA_Transformer. Context information <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">all</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of fusion features is extracted, processed by projection_head and normalized by softmax to obtain prediction label <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>. Finally, using cross-entropy loss and training with only a very small number of real labels, excellent results can be obtained:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Ï</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">all</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo>â</mml:mo><mml:mi>m</mml:mi></mml:munder></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Ï</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">all</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>As far as we know, this is the first time to apply the SSL algorithm to address the RNAâprotein binding site prediction problem. Different from HCRNet and CircSSNN, the three feature descriptors we selected are relatively shallow algorithms and do not use DNABertâs large language model, which requires lower hardware resources and is easy to be widely used. Compared with previous supervised learning algorithms, it reduces the excessive dependence on actual labels. After representing sequences in agent task learning without using real tags, superior performance can be achieved with only a small number of tags depending on the final task.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Experimental setup</title>
      <p>In our experiment, the networks are trained by the Adam optimizer, where <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:math></inline-formula>, <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:math></inline-formula>, and weight_decay is set to 3e-4 and batchSize to 64. The optimizerâs learning rate is automatically controlled by the scheduling that comes with pytorch, where initial value is 3e-3. We employ a layer of RNA_Transformer and set dim to 400, heads to 8, and mlp_dim to 200.</p>
    </sec>
    <sec>
      <title>3.2 Existing supervised algorithm performance</title>
      <p>We demonstrate the AUC performance achieved by eight existing supervised recognition algorithms on six circRNAâRBP datasets, as shown in <xref rid="btae004-F3" ref-type="fig">Fig.Â 3</xref>. These include CircSSNN, HCRNet, iCircRBP-DHN, PASSION, CRIP, CircRB, CSCRSites, and CircSLNN. The dataset ratio is set to 8:2, based on the number of training and test samples as claimed in their respective papers. It can be seen from the picture that the latest algorithm CircSSNN has achieved nearly perfect performance, and HCRNet and iCircRBP-DHN are not much different from it. Since <xref rid="btae004-F3" ref-type="fig">Fig.Â 3</xref> cannot be well distinguished, we independently draw the results of these three algorithms on these datasets to draw box plots (<xref rid="btae004-F4" ref-type="fig">Fig.Â 4</xref>). However, it should be noted that these algorithms require up to 80% of the training samples, i.e. 80% of the labeling labels obtained through biological experiments need to be invested in the algorithm for auxiliary learning, so as to guide the network to learn useful and easily distinguishable features. We know that the biological experiment analysis cost is high, the cycle is long, the efficiency is low, consumes a lot of human, material, and financial resources, which greatly limits the universality of the algorithm. Therefore, the algorithmâs dependence on labels should be reduced as much as possible to reduce the cost.</p>
      <fig position="float" id="btae004-F3">
        <label>Figure 3.</label>
        <caption>
          <p>AUC discrimination performance obtained by eight existing supervised algorithms.</p>
        </caption>
        <graphic xlink:href="btae004f3" position="float"/>
      </fig>
      <fig position="float" id="btae004-F4">
        <label>Figure 4.</label>
        <caption>
          <p>AUC performance obtained by the latest three supervised learning algorithms on six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Our CircSI-SSL performance</title>
      <p>To validate the low dependency for labels and recognition effectiveness of our CircSI-SSL algorithm, we selected three algorithms with the best supervised performance, CircSSNN, HCRNet, and iCircRBP-DHN, and compared them with our algorithm under the premise of train:testâ=â1:9. The results are shown in <xref rid="btae004-F5" ref-type="fig">Fig.Â 5</xref>. It can be seen that our algorithm has achieved remarkable performance on most datasets and indicators, but we also see that our algorithm is slightly lower than HCRNet in Recall index. The reason may be that when very little supervision information is involved in training, supervised algorithms tend to pay too much attention to individual indicators and failure to achieve overall performance. For example, HCRNet focuses on recall index, while ACC and Precision fail to achieve good results. In contrast, our CircSI-SSL achieves a balanced and excellent performance across all metrics. It can also be seen from the comprehensive index AUC that the algorithm in this article has the best comprehensive ability and has a wide application prospect. For the convenience of comparison, we visualized the average AUC of the algorithm on six datasets as <xref rid="btae004-F6" ref-type="fig">Fig.Â 6</xref>. It can be intuitively seen that the algorithm in this article achieved the highest performance compared with other datasets, which was 3.3% higher on average and more than 5% higher on some datasets.</p>
      <fig position="float" id="btae004-F5">
        <label>Figure 5.</label>
        <caption>
          <p>Performance comparison between CircSI-SSL and the latest three supervised algorithms in four indicators.</p>
        </caption>
        <graphic xlink:href="btae004f5" position="float"/>
      </fig>
      <fig position="float" id="btae004-F6">
        <label>Figure 6.</label>
        <caption>
          <p>Average AUC performance comparison between CircSI-SSL and the latest three supervised algorithms on six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f6" position="float"/>
      </fig>
      <p>To further explore the relationship between the performance of the proposed algorithm and the amount of supervised information introduced, it is proved that the proposed algorithm can achieve stable performance under the condition of very few training samples. We conducted a step test according to the training samples from 1 to 9. Ratio was used to represent the ratio between the training set and the test set. The AUC performance obtained was shown in <xref rid="btae004-T1" ref-type="table">TableÂ 1</xref>. We can see that in general, the algorithm has learned easily distinguishable features under the sample ratio of 1:9, and achieved excellent classification performance. With the continuous increase of training samples, the performance of the algorithm can maintain a certain increase, but the difference is not much compared with the initial. This fully indicates that the cross-view prediction task based on SSL has trained the RNA_Transformer feature extractor and learned enough contextual features to represent the entire sequence. Only a very small number of samples are required to fine-tune for subsequent recognition tasks.</p>
      <table-wrap position="float" id="btae004-T1">
        <label>Table 1.</label>
        <caption>
          <p>AUC performance of CircSI-SSL algorithm under different training sample proportions.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Ratio</th>
              <th rowspan="1" colspan="1">WTAP</th>
              <th rowspan="1" colspan="1">FXR1</th>
              <th rowspan="1" colspan="1">C17ORF85</th>
              <th rowspan="1" colspan="1">QKI</th>
              <th rowspan="1" colspan="1">TAF15</th>
              <th rowspan="1" colspan="1">AUF1</th>
              <th rowspan="1" colspan="1">AVG</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1:9</td>
              <td rowspan="1" colspan="1">0.887</td>
              <td rowspan="1" colspan="1">0.981</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.961</td>
              <td rowspan="1" colspan="1">0.986</td>
              <td rowspan="1" colspan="1">0.971</td>
              <td rowspan="1" colspan="1">0.958</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2:8</td>
              <td rowspan="1" colspan="1">0.914</td>
              <td rowspan="1" colspan="1">0.980</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.986</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">0.963</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3:7</td>
              <td rowspan="1" colspan="1">0.913</td>
              <td rowspan="1" colspan="1">0.984</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.967</td>
              <td rowspan="1" colspan="1">0.987</td>
              <td rowspan="1" colspan="1">0.973</td>
              <td rowspan="1" colspan="1">0.964</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4:6</td>
              <td rowspan="1" colspan="1">0.926</td>
              <td rowspan="1" colspan="1">0.987</td>
              <td rowspan="1" colspan="1">0.963</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.972</td>
              <td rowspan="1" colspan="1">0.967</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5:5</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.983</td>
              <td rowspan="1" colspan="1">0.961</td>
              <td rowspan="1" colspan="1">0.968</td>
              <td rowspan="1" colspan="1">0.988</td>
              <td rowspan="1" colspan="1">0.973</td>
              <td rowspan="1" colspan="1">0.968</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">6:4</td>
              <td rowspan="1" colspan="1">0.943</td>
              <td rowspan="1" colspan="1">0.985</td>
              <td rowspan="1" colspan="1">0.960</td>
              <td rowspan="1" colspan="1">0.969</td>
              <td rowspan="1" colspan="1">0.991</td>
              <td rowspan="1" colspan="1">0.977</td>
              <td rowspan="1" colspan="1">0.971</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">7:3</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.983</td>
              <td rowspan="1" colspan="1">0.959</td>
              <td rowspan="1" colspan="1">0.971</td>
              <td rowspan="1" colspan="1">0.990</td>
              <td rowspan="1" colspan="1">0.975</td>
              <td rowspan="1" colspan="1">0.969</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">8:2</td>
              <td rowspan="1" colspan="1">0.978</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.956</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.979</td>
              <td rowspan="1" colspan="1">0.977</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.4 Ablation analysis</title>
      <p>In this section, we conduct an ablation analysis to demonstrate that the improved performance of our algorithm is a direct result of the SSL task we designed. The AUC performance obtained by the CircSI-SSL algorithm on these datasets is presented in <xref rid="btae004-T2" ref-type="table">TableÂ 2</xref>, where fine-tuning based on real labels is performed directly without cross-view sequence prediction task. It is evident that when no proxy task is performed, the algorithm performance drops off a cliff, with an average decline of about 10%, as shown in <xref rid="btae004-F7" ref-type="fig">Fig.Â 7</xref>. In particular, there is also an extreme AUC performance of 0.5. This is sufficient to show that it is necessary to conduct self-supervised tasks, to learn the overall expression of the sequence from the data (without labels), and thus to significantly improve subsequent classification tasks with only a few labels.</p>
      <fig position="float" id="btae004-F7">
        <label>Figure 7.</label>
        <caption>
          <p>Average AUC performance with and without SSL across six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f7" position="float"/>
      </fig>
      <table-wrap position="float" id="btae004-T2">
        <label>Table 2.</label>
        <caption>
          <p>AUC performance of CircSI-SSL algorithm (without self-supervision task) under different training sample proportions.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Ratio</th>
              <th rowspan="1" colspan="1">WTAP</th>
              <th rowspan="1" colspan="1">FXR1</th>
              <th rowspan="1" colspan="1">C17ORF85</th>
              <th rowspan="1" colspan="1">QKI</th>
              <th rowspan="1" colspan="1">TAF15</th>
              <th rowspan="1" colspan="1">AUF1</th>
              <th rowspan="1" colspan="1">AVG</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1:9</td>
              <td rowspan="1" colspan="1">0.881</td>
              <td rowspan="1" colspan="1">0.883</td>
              <td rowspan="1" colspan="1">0.941</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.888</td>
              <td rowspan="1" colspan="1">0.653</td>
              <td rowspan="1" colspan="1">0.852</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2:8</td>
              <td rowspan="1" colspan="1">0.876</td>
              <td rowspan="1" colspan="1">0.895</td>
              <td rowspan="1" colspan="1">0.944</td>
              <td rowspan="1" colspan="1">0.838</td>
              <td rowspan="1" colspan="1">0.931</td>
              <td rowspan="1" colspan="1">0.848</td>
              <td rowspan="1" colspan="1">0.889</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3:7</td>
              <td rowspan="1" colspan="1">0.878</td>
              <td rowspan="1" colspan="1">0.923</td>
              <td rowspan="1" colspan="1">0.941</td>
              <td rowspan="1" colspan="1">0.923</td>
              <td rowspan="1" colspan="1">0.913</td>
              <td rowspan="1" colspan="1">0.711</td>
              <td rowspan="1" colspan="1">0.881</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4:6</td>
              <td rowspan="1" colspan="1">0.885</td>
              <td rowspan="1" colspan="1">0.904</td>
              <td rowspan="1" colspan="1">0.936</td>
              <td rowspan="1" colspan="1">0.926</td>
              <td rowspan="1" colspan="1">0.831</td>
              <td rowspan="1" colspan="1">0.744</td>
              <td rowspan="1" colspan="1">0.871</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5:5</td>
              <td rowspan="1" colspan="1">0.918</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.733</td>
              <td rowspan="1" colspan="1">0.673</td>
              <td rowspan="1" colspan="1">0.915</td>
              <td rowspan="1" colspan="1">0.673</td>
              <td rowspan="1" colspan="1">0.809</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">6:4</td>
              <td rowspan="1" colspan="1">0.907</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.945</td>
              <td rowspan="1" colspan="1">0.703</td>
              <td rowspan="1" colspan="1">0.909</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.744</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">7:3</td>
              <td rowspan="1" colspan="1">0.902</td>
              <td rowspan="1" colspan="1">0.898</td>
              <td rowspan="1" colspan="1">0.940</td>
              <td rowspan="1" colspan="1">0.934</td>
              <td rowspan="1" colspan="1">0.853</td>
              <td rowspan="1" colspan="1">0.775</td>
              <td rowspan="1" colspan="1">0.884</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">8:2</td>
              <td rowspan="1" colspan="1">0.930</td>
              <td rowspan="1" colspan="1">0.886</td>
              <td rowspan="1" colspan="1">0.946</td>
              <td rowspan="1" colspan="1">0.873</td>
              <td rowspan="1" colspan="1">0.836</td>
              <td rowspan="1" colspan="1">0.922</td>
              <td rowspan="1" colspan="1">0.899</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.5 Transplant analysis</title>
      <p>To further demonstrate the advantages of the proposed algorithm in more aspects, we transplanted the circSI-SSL algorithm originally designed for circRNA into the binding protein prediction task of linRNA without any network modification and with consistent hyperparameters. In the performance comparison between the six widely used linRNAs and several supervised algorithms as shown in <xref rid="btae004-F8" ref-type="fig">Fig.Â 8</xref> below, the ratio of training set to test set is still 1:9. Remarkably, the proposed algorithm achieves the best overall performance without any task-oriented tuning. In <xref rid="btae004-F8" ref-type="fig">Fig.Â 8</xref>, we can see that although iCircRBP-DHN also obtained a good average AUC value, it can also clearly see huge fluctuations in ACC, Precison, and Recall, which are separate indicators. HCRNet algorithm is relatively stable, but its performance on Recall index is poor. In the case of a very small number of training datasets put into training, the performance of the above two in each indicator is not balanced, and the overall good performance is not achieved. Therefore, supervised learning algorithm is not a good choice when there are only a few labeled samples. In contrast, the algorithm in this article achieves the overall optimal performance, even in such a harsh environment.</p>
      <fig position="float" id="btae004-F8">
        <label>Figure 8.</label>
        <caption>
          <p>Comparison of transplant performance on linRNA datasets.</p>
        </caption>
        <graphic xlink:href="btae004f8" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this article, we propose the novel CircSI-SSL framework for circRNAâRBP site recognition tasks based on SSL. By designing a cross-view sequence prediction task, the algorithm can learn the overall representation of the sequence in an unsupervised manner, and significantly enhance subsequent RBP identification performance with only a small amount of supervised information. Based on the improved Transformer network RNA_Transformer in this article, the framework extracts sequence context features from multiple views to characterize the sequence. By designing reasonable and effective proxy tasks, along with a stable and efficient network architecture, significant improvements were achieved with only a small amount of supervised information on the widely used six circRNA datasets and six linRNA datasets compared to supervised learning algorithms.</p>
    <p>In short, the CircSI-SSL algorithm based on SSL has good identification performance, expansion performance, and wide application range, only a small amount of label information can significantly improve the recognition performance. It is a very competitive tool for circRNAâRBP binding site identification.</p>
  </sec>
</body>
<back>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>The work was supported by the National Natural Science Foundation of China [62231013, 62250028, 62271329]; the Sichuan Provincial Science Fund for Distinguished Young Scholars [2021JDJQ0025]; the fund of Shenzhen Polytechnic [6022310036K, 6023310037K]; and the Municipal Government of Quzhou [No. 2022D040].</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae004-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alipanahi</surname><given-names>B</given-names></string-name>, <string-name><surname>Delong</surname><given-names>A</given-names></string-name>, <string-name><surname>Weirauch</surname><given-names>MT</given-names></string-name></person-group><etal>et al</etal><article-title>Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</article-title>. <source>Nat Biotechnol</source><year>2015</year>;<volume>33</volume>:<fpage>831</fpage>â<lpage>8</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bogard</surname><given-names>B</given-names></string-name>, <string-name><surname>Francastel</surname><given-names>C</given-names></string-name>, <string-name><surname>HubÃ©</surname><given-names>F.</given-names></string-name></person-group><article-title>A new method for the identification of thousands of circular RNAs</article-title>. <source>Non-Coding RNA Investig</source><year>2018</year>;<volume>2</volume>:<fpage>5</fpage>.</mixed-citation>
    </ref>
    <ref id="btae004-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>C</given-names></string-name>, <string-name><surname>Yang</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>CircSSNN: circRNA-binding site prediction via sequence self-attention neural networks with pre-normalization</article-title>. <source>BMC Bioinformatics</source><year>2023</year>;<volume>24</volume>:<fpage>220</fpage>.<pub-id pub-id-type="pmid">37254080</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>L-L.</given-names></string-name></person-group><article-title>The biogenesis and emerging roles of circular RNAs</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2016</year>;<volume>17</volume>:<fpage>205</fpage>â<lpage>11</lpage>.<pub-id pub-id-type="pmid">26908011</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>T</given-names></string-name>, <string-name><surname>Kornblith</surname><given-names>S</given-names></string-name>, <string-name><surname>Norouzi</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal> A simple framework for contrastive learning of visual representations. In: <italic toggle="yes">International Conference on Machine Learning</italic>. Vienna, Austria, 13 July, 2020. <fpage>1597</fpage>â1<lpage>607</lpage>. PMLR, 2020.</mixed-citation>
    </ref>
    <ref id="btae004-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning models for disease-associated circRNA prediction: a review</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac364</fpage>.<pub-id pub-id-type="pmid">36130259</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dori</surname><given-names>M</given-names></string-name>, <string-name><surname>Haj Abdullah Alieh</surname><given-names>L</given-names></string-name>, <string-name><surname>Cavalli</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Sequence and expression levels of circular RNAs in progenitor cell types during mouse corticogenesis</article-title>. <source>Life Sci Alliance</source><year>2019</year>;<volume>2</volume>:<fpage>e201900354</fpage>.<pub-id pub-id-type="pmid">30926618</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dudekula</surname><given-names>DB</given-names></string-name>, <string-name><surname>Panda</surname><given-names>AC</given-names></string-name>, <string-name><surname>Grammatikakis</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>CircInteractome: a web tool for exploring circular RNAs and their interacting proteins and microRNAs</article-title>. <source>RNA Biol</source><year>2016</year>;<volume>13</volume>:<fpage>34</fpage>â<lpage>42</lpage>.<pub-id pub-id-type="pmid">26669964</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Eldele</surname><given-names>E</given-names></string-name>, <string-name><surname>Ragab</surname><given-names>M</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal> Time-series representation learning via temporal and contextual contrasting. In <source>Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence.</source> Montreal, Canada, August 19-27, 2021, IJCAI, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="btae004-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gidaris</surname><given-names>S</given-names></string-name>, <string-name><surname>Singh</surname><given-names>P</given-names></string-name>, <string-name><surname>Komodakis</surname><given-names>N.</given-names></string-name></person-group> Unsupervised representation learning by predicting image rotations. In <italic toggle="yes">ICLR 2018</italic>, <italic toggle="yes">Vancouver Convention Center, Vancouver, BC, Canada, April 30 - May 3</italic>, <year>2018</year>, OpenReview.net.</mixed-citation>
    </ref>
    <ref id="btae004-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>GlaÅ¾ar</surname><given-names>P</given-names></string-name>, <string-name><surname>Papavasileiou</surname><given-names>P</given-names></string-name>, <string-name><surname>Rajewsky</surname><given-names>N.</given-names></string-name></person-group><article-title>circBase: a database for circular RNAs</article-title>. <source>RNA</source><year>2014</year>;<volume>20</volume>:<fpage>1666</fpage>â<lpage>70</lpage>.<pub-id pub-id-type="pmid">25234927</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hao</surname><given-names>S</given-names></string-name>, <string-name><surname>Lv</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Q</given-names></string-name></person-group><etal>et al</etal><article-title>Identification of key genes and circular RNAs in human gastric cancer</article-title>. <source>Med Sci Monit</source><year>2019</year>;<volume>25</volume>:<fpage>2488</fpage>â<lpage>504</lpage>.<pub-id pub-id-type="pmid">30948703</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K</given-names></string-name>, <string-name><surname>Fan</surname><given-names>H</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal> Momentum contrast for unsupervised visual representation learning. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>. <fpage>9729</fpage>â<lpage>38</lpage>. <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btae004-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>W</given-names></string-name>, <string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Duan</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>70ProPred: a predictor for discovering sigma70 promoters based on combining multiple features</article-title>. <source>BMC Syst Biol</source><year>2018</year>;<volume>12</volume>:<fpage>44</fpage>.<pub-id pub-id-type="pmid">29745856</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hjelm</surname><given-names>RD</given-names></string-name>, <string-name><surname>Fedorov</surname><given-names>A</given-names></string-name>, <string-name><surname>Lavoie-Marchildon</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal> Learning deep representations by mutual information estimation and maximization. In <italic toggle="yes">International Conference on Learning Representations</italic>. New Orleans, LA, USA, May 6-9, 2019. <year>2019</year>, OpenReview.net.</mixed-citation>
    </ref>
    <ref id="btae004-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X.</given-names></string-name></person-group><article-title>Updated review of advances in microRNAs and complex diseases: taxonomy, trends and challenges of computational models</article-title>. <source>Brief Bioinform</source><year>2022a</year>;<volume>23</volume>:<fpage>bbac358</fpage>.<pub-id pub-id-type="pmid">36056743</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X.</given-names></string-name></person-group><article-title>Updated review of advances in microRNAs and complex diseases: towards systematic evaluation of computational models</article-title>. <source>Brief Bioinform</source><year>2022b</year>;<volume>23</volume>:<fpage>bbac407</fpage>.<pub-id pub-id-type="pmid">36151749</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Bi</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>PASSION: an ensemble neural network approach for identifying the binding sites of RBPs on circRNAs</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>4276</fpage>â<lpage>82</lpage>.<pub-id pub-id-type="pmid">32426818</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiao</surname><given-names>S</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Huang</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Advances in the identification of circular RNAs and research into circRNAs in human diseases</article-title>. <source>Front Genet</source><year>2021</year>;<volume>12</volume>:<fpage>665233</fpage>.<pub-id pub-id-type="pmid">33815488</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ju</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>L</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>CircSLNN: identifying RBP-binding sites on circRNAs via sequence labeling neural networks</article-title>. <source>Front Genet</source><year>2019</year>;<volume>10</volume>:<fpage>1184</fpage>.<pub-id pub-id-type="pmid">31824574</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>Q</given-names></string-name>, <string-name><surname>Mikolov</surname><given-names>T.</given-names></string-name></person-group> Distributed representations of sentences and documents. In: <italic toggle="yes">International Conference on Machine Learning</italic>, <italic toggle="yes">Beijing, China, on June 21âJune 26, 2014</italic>. <fpage>1188</fpage>â<lpage>96</lpage>. <publisher-name>PMLR, 2014.</publisher-name></mixed-citation>
    </ref>
    <ref id="btae004-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>S</given-names></string-name>, <string-name><surname>Han</surname><given-names>L.</given-names></string-name></person-group><article-title>Circular RNAs as promising biomarkers in cancer: detection, function, and beyond</article-title>. <source>Genome Med</source><year>2019</year>;<volume>11</volume>:<fpage>15</fpage>.<pub-id pub-id-type="pmid">30894216</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>W</given-names></string-name>, <string-name><surname>Godzik</surname><given-names>A.</given-names></string-name></person-group><article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source><year>2006</year>;<volume>22</volume>:<fpage>1658</fpage>â<lpage>9</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal><article-title>Self-supervised learning: generative or contrastive</article-title>. <source>IEEE Trans Knowl Data Eng</source><year>2021</year>;<volume>35</volume>:<fpage>1</fpage>â<lpage>876</lpage>.<pub-id pub-id-type="pmid">36506788</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>AS</given-names></string-name>, <string-name><surname>Sreenadhan</surname><given-names>SP.</given-names></string-name></person-group><article-title>A coding measure scheme employing electron-ion interaction pseudopotential (EIIP)</article-title>. <source>Bioinformation</source><year>2006</year>;<volume>1</volume>:<fpage>197</fpage>â<lpage>202</lpage>.<pub-id pub-id-type="pmid">17597888</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Ju</surname><given-names>Y</given-names></string-name>, <string-name><surname>Lin</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Characterizing viral circRNAs and their application in identifying circRNAs in viruses</article-title>. <source>Brief Bioinform</source><year>2022a</year>;<volume>23</volume>:<fpage>bbab404</fpage>.<pub-id pub-id-type="pmid">34585234</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Lin</surname><given-names>C.</given-names></string-name></person-group><article-title>CRBPDL: identification of circRNA-RBP interaction sites using an ensemble neural network approach</article-title>. <source>PLoS Comput Biol</source><year>2022b</year>;<volume>18</volume>:<fpage>e1009798</fpage>.<pub-id pub-id-type="pmid">35051187</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C.</given-names></string-name></person-group><article-title>GMNN2CD: identification of circRNAâdisease associations based on variational inference and graph Markov neural networks</article-title>. <source>Bioinformatics</source><year>2022c</year>;<volume>38</volume>:<fpage>2246</fpage>â<lpage>53</lpage>.<pub-id pub-id-type="pmid">35157027</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B29">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Noroozi</surname><given-names>M</given-names></string-name>, <string-name><surname>Favaro</surname><given-names>P.</given-names></string-name></person-group> Unsupervised learning of visual representations by solving jigsaw puzzles. In: <italic toggle="yes">European Conference on Computer Vision</italic>, <italic toggle="yes">Amsterdam, Netherlands, October 10-16, 2016</italic>. <fpage>69</fpage>â<lpage>84</lpage>. Springer, 2016.</mixed-citation>
    </ref>
    <ref id="btae004-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Oord</surname><given-names>A</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Vinyals</surname><given-names>O.</given-names></string-name></person-group> Representation learning with contrastive predictive coding. arXiv, arXiv:1807.03748, <year>2018</year>. <pub-id pub-id-type="doi">10.48550/arXiv.1807.03748</pub-id>.</mixed-citation>
    </ref>
    <ref id="btae004-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orenstein</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Berger</surname><given-names>B.</given-names></string-name></person-group><article-title>RCK: accurate and efficient inference of sequence-and structure-based proteinâRNA binding models from RNAcompete data</article-title>. <source>Bioinformatics</source><year>2016</year>;<volume>32</volume>:<fpage>i351</fpage>â<lpage>9</lpage>.<pub-id pub-id-type="pmid">27307637</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pan</surname><given-names>X</given-names></string-name>, <string-name><surname>Rijnbeek</surname><given-names>P</given-names></string-name>, <string-name><surname>Yan</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks</article-title>. <source>BMC Genomics</source><year>2018</year>;<volume>19</volume>:<fpage>511</fpage>.<pub-id pub-id-type="pmid">29970003</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ruan</surname><given-names>H</given-names></string-name>, <string-name><surname>Xiang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ko</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Comprehensive characterization of circular RNAs inâ¼ 1000 human cancer cell lines</article-title>. <source>Genome Med</source><year>2019</year>;<volume>11</volume>:<fpage>55</fpage>.<pub-id pub-id-type="pmid">31446897</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rybak-Wolf</surname><given-names>A</given-names></string-name>, <string-name><surname>Stottmeister</surname><given-names>C</given-names></string-name>, <string-name><surname>GlaÅ¾ar</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>Circular RNAs in the mammalian brain are highly abundant, conserved, and dynamically expressed</article-title>. <source>Mol Cell</source><year>2015</year>;<volume>58</volume>:<fpage>870</fpage>â<lpage>85</lpage>.<pub-id pub-id-type="pmid">25921068</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Su</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>J</given-names></string-name>, <string-name><surname>Su</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>CircRNAs in lung adenocarcinoma: diagnosis and therapy</article-title>. <source>Curr Gene Ther</source><year>2022</year>;<volume>22</volume>:<fpage>15</fpage>â<lpage>22</lpage>.<pub-id pub-id-type="pmid">34856899</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A</given-names></string-name>, <string-name><surname>Shazeer</surname><given-names>N</given-names></string-name>, <string-name><surname>Parmar</surname><given-names>N</given-names></string-name></person-group> et al. Attention is all you need. In: Advances in Neural Information Processing Systems, <italic toggle="yes">Long Beach, USA, December 4-9, 2017</italic>. Vol. 30. MIT Press, 2017.</mixed-citation>
    </ref>
    <ref id="btae004-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>CC</given-names></string-name>, <string-name><surname>Han</surname><given-names>CD</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>Q</given-names></string-name></person-group><etal>et al</etal><article-title>Circular RNAs and complex diseases: from experimental results to computational models</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbab286</fpage>.<pub-id pub-id-type="pmid">34329377</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Li</surname><given-names>B</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>T</given-names></string-name></person-group><etal>et al</etal> Learning deep transformer models for machine translation. In <italic toggle="yes">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</italic>. Florence, Italy, July, <year>2019a</year>, Association for Computational Linguistics.</mixed-citation>
    </ref>
    <ref id="btae004-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Lei</surname><given-names>X</given-names></string-name>, <string-name><surname>Wu</surname><given-names>F-X.</given-names></string-name></person-group><article-title>Identifying cancer-specific circRNAâRBP binding sites based on deep learning</article-title>. <source>Molecules</source><year>2019b</year>;<volume>24</volume>:<fpage>4035</fpage>.<pub-id pub-id-type="pmid">31703384</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal><article-title>iCircRBP-DHN: identification of circRNA-RBP interaction sites using deep hierarchical network</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbaa274</fpage>.<pub-id pub-id-type="pmid">33126261</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>HCRNet: high-throughput circRNA-binding event identification from CLIP-seq data using deep temporal convolutional network</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac027</fpage>.<pub-id pub-id-type="pmid">35189638</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yee</surname><given-names>BA</given-names></string-name>, <string-name><surname>Pratt</surname><given-names>GA</given-names></string-name>, <string-name><surname>Graveley</surname><given-names>BR</given-names></string-name></person-group><etal>et al</etal><article-title>RBP-Maps enables robust generation of splicing regulatory maps</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>193</fpage>â<lpage>204</lpage>.<pub-id pub-id-type="pmid">30413564</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zang</surname><given-names>J</given-names></string-name>, <string-name><surname>Lu</surname><given-names>D</given-names></string-name>, <string-name><surname>Xu</surname><given-names>A.</given-names></string-name></person-group><article-title>The interaction of circRNAs and RNA binding proteins: an important part of circRNA maintenance and function</article-title>. <source>J Neurosci Res</source><year>2020</year>;<volume>98</volume>:<fpage>87</fpage>â<lpage>97</lpage>.<pub-id pub-id-type="pmid">30575990</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H-D</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>L-H</given-names></string-name>, <string-name><surname>Sun</surname><given-names>D-W</given-names></string-name></person-group><etal>et al</etal><article-title>CircRNA: a novel type of biomarker for cancer</article-title>. <source>Breast Cancer</source><year>2018</year>;<volume>25</volume>:<fpage>1</fpage>â<lpage>7</lpage>.<pub-id pub-id-type="pmid">28721656</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>K</given-names></string-name>, <string-name><surname>Pan</surname><given-names>X</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>CRIP: predicting circRNAâRBP-binding sites using a codon-based encoding and hybrid deep neural networks</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>1604</fpage>â<lpage>15</lpage>.<pub-id pub-id-type="pmid">31537716</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B46">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>R</given-names></string-name>, <string-name><surname>Isola</surname><given-names>P</given-names></string-name>, <string-name><surname>Efros</surname><given-names>AA.</given-names></string-name></person-group> Colorful image colorization. In: <italic toggle="yes">Computer VisionâECCV 2016: 14th European Conference, Amsterdam, Netherlands, October 11-14, 2016, Proceedings, Part III 14.</italic><fpage>649</fpage>â<lpage>66</lpage>. Springer, <year>2016</year>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10789309</article-id>
    <article-id pub-id-type="pmid">38180876</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae004</article-id>
    <article-id pub-id-type="publisher-id">btae004</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CircSI-SSL: circRNA-binding site identification based on self-supervised learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6730-9422</contrib-id>
        <name>
          <surname>Cao</surname>
          <given-names>Chao</given-names>
        </name>
        <aff><institution>Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China</institution>, Quzhou, Zhejiang 324003, <country country="CN">China</country></aff>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, Sichuan 611731, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2965-9920</contrib-id>
        <name>
          <surname>Wang</surname>
          <given-names>Chunyu</given-names>
        </name>
        <aff><institution>Faculty of Computing, Harbin Institute of Technology</institution>, Harbin, Heilongjiang 150001, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Shuhong</given-names>
        </name>
        <aff><institution>Faculty of Mathematics and Computer Science, Guangdong Ocean University</institution>, Zhanjiang, Guangdong 524088, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6406-1142</contrib-id>
        <name>
          <surname>Zou</surname>
          <given-names>Quan</given-names>
        </name>
        <aff><institution>Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China</institution>, Quzhou, Zhejiang 324003, <country country="CN">China</country></aff>
        <aff><institution>Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China</institution>, Chengdu, Sichuan 611731, <country country="CN">China</country></aff>
        <xref rid="btae004-cor1" ref-type="corresp"/>
        <!--zouquan@nclab.net-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Valencia</surname>
          <given-names>Alfonso</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae004-cor1">Corresponding author. Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China, Quzhou, Zhejiang 324003, China. E-mail: <email>zouquan@nclab.net</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-01-05">
      <day>05</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>1</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>1</issue>
    <elocation-id>btae004</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>8</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>13</day>
        <month>11</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>28</day>
        <month>12</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>15</day>
        <month>1</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae004.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>In recent years, circular RNAs (circRNAs), the particular form of RNA with a closed-loop structure, have attracted widespread attention due to their physiological significance (they can directly bind proteins), leading to the development of numerous protein site identification algorithms. Unfortunately, these studies are supervised and require the vast majority of labeled samples in training to produce superior performance. But the acquisition of sample labels requires a large number of biological experiments and is difficult to obtain.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To resolve this matter that a great deal of tags need to be trained in the circRNA-binding site prediction task, a self-supervised learning binding site identification algorithm named CircSI-SSL is proposed in this article. According to the survey, this is unprecedented in the research field. Specifically, CircSI-SSL initially combines multiple feature coding schemes and employs RNA_Transformer for cross-view sequence prediction (self-supervised task) to learn mutual information from the multi-view data, and then fine-tuning with only a few sample labels. Comprehensive experiments on six widely used circRNA datasets indicate that our CircSI-SSL algorithm achieves excellent performance in comparison to previous algorithms, even in the extreme case where the ratio of training data to test data is 1:9. In addition, the transplantation experiment of six linRNA datasets without network modification and hyperparameter adjustment shows that CircSI-SSL has good scalability. In summary, the prediction algorithm based on self-supervised learning proposed in this article is expected to replace previous supervised algorithms and has more extensive application value.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code and data are available at <ext-link xlink:href="https://github.com/cc646201081/CircSI-SSL" ext-link-type="uri">https://github.com/cc646201081/CircSI-SSL</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62231013</award-id>
        <award-id>62250028</award-id>
        <award-id>62271329</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Sichuan Provincial Science Fund for Distinguished Young Scholars</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2021JDJQ0025</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Shenzhen Polytechnic</institution>
            <institution-id institution-id-type="DOI">10.13039/100012840</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>6022310036K</award-id>
        <award-id>6023310037K</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Municipal Government of Quzhou</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2022D040</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Circular RNA (circRNA) is the peculiar class of RNAs produced by pre-mRNA. Unlike common RNAs with the two ends of 5â² and 3â², circRNA has a unique ring structure formed by the reverse splicing mechanism (<xref rid="btae004-B2" ref-type="bibr">Bogard <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae004-B12" ref-type="bibr">Hao <italic toggle="yes">et al.</italic> 2019</xref>), widely present in human, hippocampus, mouse, and other cells and tissues (<xref rid="btae004-B7" ref-type="bibr">Dori <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae004-B22" ref-type="bibr">Li and Han 2019</xref>). This special structure can enhance the stability of circRNA and usually has a stage-specific expression pattern (<xref rid="btae004-B34" ref-type="bibr">Rybak-Wolf <italic toggle="yes">et al.</italic> 2015</xref>). More and more evidence has proved that circRNA can participate in the processes of gene expression regulation through combining the corresponding RNA-binding protein (RBP) (<xref rid="btae004-B4" ref-type="bibr">Chen 2016</xref>, <xref rid="btae004-B43" ref-type="bibr">Zang <italic toggle="yes">et al.</italic> 2020</xref>). Like other non-coding RNAs (<xref rid="btae004-B16" ref-type="bibr">Huang <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B17" ref-type="bibr">b</xref>), It can also play a crucial part in the screening and therapy of many diseases (<xref rid="btae004-B19" ref-type="bibr">Jiao <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btae004-B37" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2021</xref>), especially cancer (<xref rid="btae004-B44" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae004-B35" ref-type="bibr">Su <italic toggle="yes">et al.</italic> 2022</xref>). Therefore, the understanding of the action mechanism between circRNA and RBP is crucial to reveal the circRNA formation and its biological function (<xref rid="btae004-B6" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btae004-B26" ref-type="bibr">Niu <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B27" ref-type="bibr">b</xref>,<xref rid="btae004-B28" ref-type="bibr">c</xref>).</p>
    <p>With the emergence of some biological technologies about sequencing, such as high-throughput sequencing with crosslinking immunoprecipitation (HITS-CLIP), many RBP targets in mature circRNAs have been found in eukaryotes (<xref rid="btae004-B8" ref-type="bibr">Dudekula <italic toggle="yes">et al.</italic> 2016</xref>, <xref rid="btae004-B33" ref-type="bibr">Ruan <italic toggle="yes">et al.</italic> 2019</xref>). However, due to the high cost of detecting each pair of interaction sites, many computational methods for identifying circRNAâRBP sites have been developed. Thanks to the advancements in deep learning, the identification performance of RBP-binding sites has been continuously improved. For example, CSCRSites (<xref rid="btae004-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2019a</xref>,<xref rid="btae004-B39" ref-type="bibr">b</xref>) is a deep learning algorithm that identifies RBP-binding sites about cancer-specific only using nucleotide sequences information. CircSLNN (<xref rid="btae004-B20" ref-type="bibr">Ju <italic toggle="yes">et al.</italic> 2019</xref>) is a novel approach that transforms the RNA-binding site prediction problem into a sequence labeling problem, which adopts a word-embedded based coding scheme to capture the context and semantic information of sequences. CRIP (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>) proposes a stacked codon encoding deep learning algorithm based on convolutional neural networks and recurrent neural networks, which respectively learn abstract features and sequence dependences to complete the RBP-binding site recognition task. However, these methods are single-view algorithms, and the useful features obtained from the sequence are quite limited, and often constrained by the size of the data, and cannot achieve good performance. Subsequently, researchers have introduced some multi-view algorithms. PASSION (<xref rid="btae004-B18" ref-type="bibr">Jia <italic toggle="yes">et al.</italic> 2020</xref>) is a multi-view integrated neural network algorithm, and the optimal feature subset is selected and input into the network through incremental features selection and XGBoost algorithm. iCircRBP-DHN (<xref rid="btae004-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>) proposes to use two new encoding schemes: K-tuple nucleotide frequency patterns and CircRNA2Vec word embedding encoding as inputs. Deep multi-scale residual network, bidirectional gate recurrent unit (BiGRU), and self-attention mechanism are used as algorithms for deep network architecture. CRBPDL (<xref rid="btae004-B26" ref-type="bibr">Niu <italic toggle="yes">et al.</italic> 2022a</xref>,<xref rid="btae004-B27" ref-type="bibr">b</xref>,<xref rid="btae004-B28" ref-type="bibr">c</xref>) proposes an Adaboost integrated deep network architecture, which includes deep multi-scale residual networks and BiGRU. The performance of the algorithm is further improved. HCRNET (<xref rid="btae004-B41" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2022</xref>) incorporates a fine-tuned DNABERT model and a deep temporal convolutional network to capture global context-dependent semantic and syntactic information for circRNA sequences.</p>
    <p>As for the networks based on CNN, RNN or their deformation used in the above research as deep feature extraction networks, there are problems, such as poor network parallel capability, difficulty to capture features long-time series dependence, and insufficient algorithm stability. CircSSNN (<xref rid="btae004-B3" ref-type="bibr">Cao <italic toggle="yes">et al.</italic> 2023</xref>) proposes an algorithm that fully uses the self-attention mechanism to extract deep features and achieves better performance. Although these algorithms are constantly updating the performance of the recognition task, they are based on supervised learning, in other words, the algorithm requires a great number of sample labels in network training. Usually, the ratio of training samples to test samples is as high as 80%:20%. Although the algorithm achieves good performance, it greatly limits the exploration of the unknown circRNAâRBP interaction mechanism. As a consequence, it has immense practical significance to develop an algorithm based on supervised weakly, self-supervised, and even unsupervised in this task.</p>
    <p>Self-supervised learning (SSL) (<xref rid="btae004-B24" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2021</xref>) is a special kind of unsupervised learning. It learns required features without the need for real labels through pre-designed agent tasks, and subsequent tasks often require only a few labels (or even none) to significantly enhance performance according to specific tasks. Contrast learning performs particularly well in computer vision because it can learn invariant representations from enhanced data without label information (<xref rid="btae004-B15" ref-type="bibr">Hjelm <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae004-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae004-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic> 2020</xref>), demonstrating significant self-supervised capabilities. The specific operation process is as follows: first, data augmentation is used to get a number of different perspectives (usually two) from the original image that are slightly different. Then, different views of the same sample are taken as positive sample pairs and the others as negative samples. By maximizing the similarity between positive sample pairs and minimizing the similarity between positive sample and negative sample, a âlabelâ is artificially constructed to guide the learning of network features. However, while contrast learning can be useful in the field of images, it is difficult to apply to time-series data for several reasons: above all, there exists a challenge of capturing temporal dependencies in the data, which is very critical. Secondly, image-based augmentation techniques, such as random cropping, do not work with time-series datasets. Thus far, there have been few studies on contrast learning for time-series data, and it has not been applied to the prediction of circRNA-binding sites.</p>
    <p>For the sake of reducing the dependence of the algorithm on the sample label as much as possible, thereby enhancing its applicability across a wider range of scenarios. This article carried out in-depth research and innovatively proposed an algorithm named circRNA-binding site identification based on self-supervised learning (CircSI-SSL). The algorithm uses only KNFP, CircRNA2Vec, and electronâion interaction pseudo-potential (EIIP) shallow statistical feature descriptors, which reduces the computational resource requirements. After encoding, our Transformer model RNA_Transformer, which is improved for CircRNA recognition task, is used to: (i) perform cross-view sequence prediction tasks to train the network, capture temporal dependencies in sequence multi-view data, and learn the overall representation of the sequence; (ii) apply a very small number of sample tags (10%) to fine-tune network parameters for a specific task, thereby completing the RBP-binding site prediction task. Through a comprehensive experiment conducted on 12 widely used datasets, it is shown that the algorithm obtains a significant improvement over the supervised learning algorithms. In summary, the primary contributions of this article can be outlined as follows.</p>
    <p>A novelSSL method is applied in the domain of circRNA-binding protein recognition, which changes the situation that most of the label information is needed to obtain good performance. Using only a small amount of supervised information can lead to a substantial enhancement in the algorithmâs performance, which has a wide range of application value.</p>
    <p>We propose a novel proxy task that captures sequence temporal dependencies using an improved RNA_Transformer as a benchmark model and completes cross-view sequence prediction based on multiple feature descriptors instead of using sequence augmentation techniques.</p>
    <p>Comprehensive experiments conducted on six widely used circRNA datasets and six linRNA datasets demonstrate that the proposed algorithm exhibits comprehensive advantages over previous supervised learning approaches. Even when utilizing only 10% of the labeled data for training, the proposed algorithm demonstrates stable and outstanding performance, along with robust scalability.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>In order to assess the validity of our approach, we selected six widely used circRNA datasets, WTAP, FXR1, C17ORF85, QKI, TAF15, and AUF1. These circRNA sequences derive from circRNA interaction set of database (<ext-link xlink:href="https://circinteractome.nia.nih.gov/" ext-link-type="uri">https://circinteractome.nia.nih.gov/</ext-link>), which extracted data includes circRNAâRBP interaction information, also includes RBPs that bind to mature circRNA upstream and downstream flanker sequences (<xref rid="btae004-B42" ref-type="bibr">Yee <italic toggle="yes">et al.</italic> 2019</xref>). We then use the identical data processing steps as previous research (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>). Resulting 101 nucleotides sequence fragments in length are obtained as positive samples, and randomly selecting other sequences to acquire negative samples with same numbers. These similar sequences are removed using CD-HIT technique, with the threshold of 0.8 (<xref rid="btae004-B23" ref-type="bibr">Li and Godzik 2006</xref>). After the removal of sequence redundancy, a total of 15Â 570 samples were obtained, and all samples used in the experiments were randomly shuffled.</p>
      <p>In addition, we transplant the circSI-SSL algorithm to linear RNA datasets and compare the performance of several existing supervised algorithms in identifying RBP interactions. The same linear RNA datasets are downloaded from iDeepS (<xref rid="btae004-B32" ref-type="bibr">Pan <italic toggle="yes">et al.</italic> 2018</xref>) and DeepBind (<xref rid="btae004-B1" ref-type="bibr">Alipanahi <italic toggle="yes">et al.</italic> 2015</xref>), including six datasets after HITS-CLIP processing: hnRNPC-2, U2AF65, hnRNPC-1, QKI, ELVAL1-2, and Y2AF65.</p>
    </sec>
    <sec>
      <title>2.2 Feature muti-descriptors</title>
      <p>To enrich the originally single sequence, we employ three quantitative feature methods to extract the preliminary statistical features of the sequence: (i) KNFP, which is used to capture local semantic features at disparate positions. (ii) CircRNA2Vec, which is employed to capture remote dependencies. (iii) The EIIP, which is utilized to characterize the free electron energy on the circRNA sequence.</p>
      <sec>
        <title>2.2.1 KNFP</title>
        <p>In this section, we introduce KNFP schema in detail. Different from the traditional One-hot representation (<xref rid="btae004-B45" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2019</xref>), KNFP schema can extract various short-range sequence-dependent information (<xref rid="btae004-B31" ref-type="bibr">Orenstein <italic toggle="yes">et al.</italic> 2016</xref>) and local semantic features, which greatly makes up for the deficiency of One-hot information and retains the original sequence schema.</p>
        <p>Taking a specific circRNA sequence of length <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>L</mml:mi></mml:math></inline-formula> as an example, KNFP slidingly selects <italic toggle="yes">k</italic> consecutive nucleotides on the circRNA sequence, and counts the frequencies of the corresponding combinations in the form of <italic toggle="yes">k</italic> tuples (different combinations of <italic toggle="yes">k</italic> nucleotides), as the final encoding. In detail, for a <italic toggle="yes">k</italic>-tuple, which has <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> different combinations, the frequency <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>p</mml:mi></mml:math></inline-formula> of the corresponding <italic toggle="yes">K</italic>-tuple pattern is statistically calculated according to the specific circRNA sequence.
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Here, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi mathvariant="normal">Â </mml:mi></mml:math></inline-formula>represents the frequency of the <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>-th <italic toggle="yes">k</italic>-tuple pattern. Upon processing a single circRNA sequence, the resulting feature dimension becomes <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:math></inline-formula>. We concatenate the encoded features obtained by <italic toggle="yes">k</italic>â=â1, 2, and 3, respectively, and complete them with 0 at the end.</p>
      </sec>
      <sec>
        <title>2.2.2 CircRNA2Vec</title>
        <p>CircRNA2Vect (<xref rid="btae004-B40" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>) is a feature descriptor that employs the Doc2Vec algorithm to learn global contextual features of circRNA. Doc2Vec (<xref rid="btae004-B21" ref-type="bibr">Le and Mikolov 2014</xref>) is an extension of Word2Vec, capable of learning fixed-length feature representations from variable-length texts. Unlike Word2Vec, Doc2Vec introduces an additional paragraph vector <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> at the input layer, which captures the contextual information of paragraphs. This enables the linkage of word vectors with paragraph vectors, addressing the limitation of Word2Vec that focuses solely on training word vectors while overlooking the grasp of paragraph-level context.</p>
        <p>We collect as many circRNA splicing sequences as possible from circBase (<xref rid="btae004-B11" ref-type="bibr">GlaÅ¾ar <italic toggle="yes">et al.</italic> 2014</xref>) to serve as the corpus. Utilizing a sliding window of size 10, extract subsequences from each circRNA sequence, resulting in multiple sequences. This allows the algorithm to capture semantic information within these subsequences for modeling purposes. Given a text sequence of length <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="normal">T</mml:mi></mml:math></inline-formula>, where the word at time step <italic toggle="yes">t</italic> is denoted as <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For context window size <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, the likelihood function of the model is the probability of generating a specific word <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which express as term <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. The goal of the model is to maximize the average logarithmic probability as follow:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>â</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.2.3 EIIP</title>
        <p>EIIP, as introduced by <xref rid="btae004-B25" ref-type="bibr">Nair and Sreenadhan (2006)</xref>, is a novel feature encoding scheme that describes the energy of delocalized electrons in amino acids and nucleotides present in circRNA sequences. Four binary indicator sequences are used to encode the sequence. It has been widely utilized in the Resonance Recognition Model. The EIIP values for the nucleotide âG,â âC,â âT,â and âAâ are â0.0806,â â0.1340,â â0.1335,â and â0.1260,â respectively. To enrich the feature representation, we incorporate a PSTNPss encoding scheme. It is position-specific feature encoding based on single-strand of DNA. See <xref rid="btae004-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic> (2018)</xref> for more details.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 CircSI-SSL algorithm architecture</title>
      <p>In this section, we introduce the CircSI-SSL self-supervised algorithm framework for learning high-quality representations of sequences, using only a small number of samples to fine-tune the CircSI-SSL algorithm for specific tasks to achieve excellent results. The overall framework is shown in <xref rid="btae004-F1" ref-type="fig">Fig.Â 1</xref>. For a more intuitive understanding, we provide the pseudo-code as follow. The model consists of two components: cross-view prediction and fine-tuning. (i) Multiple feature encoders are employed to encode initial features obtained from various descriptors extracted from the raw sequence data. A cross-view sequence prediction is conducted using RNA_Transformer. (ii) The trained encoded features are then fused, followed by employing RNA_Transformer to extract structured features from the fused multi-view features based on a small number of labels, facilitating the classification task.</p>
      <fig position="float" id="btae004-F1">
        <label>Figure 1.</label>
        <caption>
          <p>CircSI-SSL framework.</p>
        </caption>
        <graphic xlink:href="btae004f1" position="float"/>
      </fig>
      <boxed-text id="btae004-BOX1" position="float">
        <label>Algorithm 1</label>
        <caption>
          <p>CircSI-SSL</p>
        </caption>
        <p><bold>Input:</bold> CircRNA sequence x, label y, Maximum iterations MaxIter</p>
        <p><bold>Output:</bold> Neural network parameters W, Prediction label y'</p>
        <p>1.ââfor iter in range(MaxIter): # Self-supervised stage</p>
        <p>2.ââenc1â=âKNFP(x)</p>
        <p>3.ââenc2â=âCircRNA2Vec(x)</p>
        <p>4.ââenc3â=âEIIP(x)</p>
        <p>5.ââc1â=âRNA_Transformer(enc1) # Context c1 of enc1 is extracted by RNA_Transformer</p>
        <p>6.ââc2â=âRNA_Transformer(enc2)</p>
        <p>7.ââc3â=âRNA_Transformer(enc3)</p>
        <p>8.ââCalculate cross-view contrast loss according to Formula 6 and 7</p>
        <p>9.ââUpdate W according to Adam optimizer</p>
        <p>10.ââfor iter in range(MaxIter): # Fine-tuning stage</p>
        <p>11.ââenc = concatenate([enc1, enc2, enc3]) # Obtaining the enc1, enc2, enc3 follows the same steps as above</p>
        <p>12.ââc = RNA_Transformer(enc)</p>
        <p>13.ââyâ = softmax(c)</p>
        <p>14.ââCalculate cross-entropy loss of y and y' according to Formula 9</p>
        <p>15.ââFine-tune W according to Adam optimizer</p>
      </boxed-text>
      <sec>
        <title>2.3.1 Cross-view prediction</title>
        <p>The initial research on SSL started with the application of agent tasks on image datasets, which aims to learn high-quality representations. For example, some previous work predicts image rotation (<xref rid="btae004-B10" ref-type="bibr">Gidaris <italic toggle="yes">et al.</italic> 2018</xref>), images colorization (<xref rid="btae004-B46" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2016</xref>), and puzzle solving (<xref rid="btae004-B29" ref-type="bibr">Noroozi and Favaro 2016</xref>). By using image augmentation technology to construct positive and negative samples, the application range of contrast learning is broadened: case discrimination fields, such as SimCLR (<xref rid="btae004-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2020</xref>) and MoCo (<xref rid="btae004-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic> 2020</xref>); time-series analysis, such as CPC (<xref rid="btae004-B30" ref-type="bibr">Oord <italic toggle="yes">et al.</italic> 2018</xref>) and TS-TC (<xref rid="btae004-B9" ref-type="bibr">Eldele <italic toggle="yes">et al.</italic> 2021</xref>). Unfortunately, these algorithmsâ performance depends heavily on the augmentation techniques used, especially for time-series data, and it is difficult to find a set of effective and widely used augmentation techniques for operations, such as random cropping and image graying. This greatly restricts the application of contrast learning to time-series data. Building upon this, this article studies a new contrast task, which extracts features from multiple real views for mutual prediction without the help of augmentation techniques.</p>
        <p>We take the improved Transformer (<xref rid="btae004-B36" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic> 2017</xref>) and TS-TC (<xref rid="btae004-B9" ref-type="bibr">Eldele <italic toggle="yes">et al.</italic> 2021</xref>) as feature extraction networks, as revealed in <xref rid="btae004-F2" ref-type="fig">Fig.Â 2</xref>. It principal consists of Multi-head Attention and Feed Forward Neural Network (FFN), Layer Normalization (LN) blocks. The FFN block consists of a fully connected layer, a non-linear ReLU function and dropout. The model uses a pre-norm residual connection (<xref rid="btae004-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2019a</xref>,<xref rid="btae004-B39" ref-type="bibr">b</xref>) and LN prior to passing through a multi-head self-attention network, resulting in more stable gradients:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>LN</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>Î³</mml:mo><mml:mo>,</mml:mo><mml:mo>Î²</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>â</mml:mo><mml:mo>Î¼</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>Ï</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mo>Ïµ</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>â</mml:mo><mml:mo>Î³</mml:mo><mml:mo>+</mml:mo><mml:mo>Î²</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mtext>MHA</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>softmax</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>V</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <fig position="float" id="btae004-F2">
          <label>Figure 2.</label>
          <caption>
            <p>RNA_Transformer structure.</p>
          </caption>
          <graphic xlink:href="btae004f2" position="float"/>
        </fig>
        <p>Where <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mo>Î¼</mml:mo></mml:math></inline-formula> and <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mo>Ï</mml:mo></mml:math></inline-formula> are the mean and variance of <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>z</mml:mi></mml:math></inline-formula>, respectively, <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Î³</mml:mi></mml:math></inline-formula> and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Î²</mml:mi></mml:math></inline-formula> represent the parameter vectors of scaling and translation, respectively. Query information, key information, and value information related to a specific task are represented as <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mi>q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula>, respectively. The number of operation heads is represented as<inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>h</mml:mi></mml:math></inline-formula>, and the aggregated <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi>q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> after multiple heads are denoted as <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mi>Q</mml:mi></mml:math></inline-formula>, <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mi>K</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>V</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> respectively. Here, <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> signifies the dimensions of the input vector. Then, LayerNorm regularization is carried out, and the features extracted by multiple heads are aggregated through FFN blocks to finally obtain the context feature <italic toggle="yes">C</italic> that represents the whole sequence.</p>
        <p>The entire process can be summarized as follows: given a circRNA sequence with a batch size of <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula>, the preliminary features <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are extracted by CircRNA2Vec and EIIP descriptors, respectively. It is then encoded by an encoder (using a 1D convolutional neural network) as <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>and <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where the feature sequence length is <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula>. Then, context variables <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are extracted by improved transformer respectively, and cross-view mutual prediction is carried out. The loss functions are:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">self</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">diag</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">diag</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec>
        <title>2.3.2 Fine-tuning</title>
        <p>After mutual prediction across the sequence of views, we get the trained RNA_Transformer. This allows him to learn the expression of the context of the overview from the sequence features. We then fine-tune the network for specific tasks to meet the needs of circRNAâprotein binding site prediction. Specifically, we combine the features <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">all</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> encoded by the above three feature descriptors and input them into RNA_Transformer. Context information <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">all</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of fusion features is extracted, processed by projection_head and normalized by softmax to obtain prediction label <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>. Finally, using cross-entropy loss and training with only a very small number of real labels, excellent results can be obtained:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Ï</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">all</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo>â</mml:mo><mml:mi>m</mml:mi></mml:munder></mml:mrow><mml:mrow><mml:mo>â</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>â</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>Ï</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">W</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">all</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mtext>log</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>y</mml:mtext><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>As far as we know, this is the first time to apply the SSL algorithm to address the RNAâprotein binding site prediction problem. Different from HCRNet and CircSSNN, the three feature descriptors we selected are relatively shallow algorithms and do not use DNABertâs large language model, which requires lower hardware resources and is easy to be widely used. Compared with previous supervised learning algorithms, it reduces the excessive dependence on actual labels. After representing sequences in agent task learning without using real tags, superior performance can be achieved with only a small number of tags depending on the final task.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Experimental setup</title>
      <p>In our experiment, the networks are trained by the Adam optimizer, where <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:math></inline-formula>, <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:math></inline-formula>, and weight_decay is set to 3e-4 and batchSize to 64. The optimizerâs learning rate is automatically controlled by the scheduling that comes with pytorch, where initial value is 3e-3. We employ a layer of RNA_Transformer and set dim to 400, heads to 8, and mlp_dim to 200.</p>
    </sec>
    <sec>
      <title>3.2 Existing supervised algorithm performance</title>
      <p>We demonstrate the AUC performance achieved by eight existing supervised recognition algorithms on six circRNAâRBP datasets, as shown in <xref rid="btae004-F3" ref-type="fig">Fig.Â 3</xref>. These include CircSSNN, HCRNet, iCircRBP-DHN, PASSION, CRIP, CircRB, CSCRSites, and CircSLNN. The dataset ratio is set to 8:2, based on the number of training and test samples as claimed in their respective papers. It can be seen from the picture that the latest algorithm CircSSNN has achieved nearly perfect performance, and HCRNet and iCircRBP-DHN are not much different from it. Since <xref rid="btae004-F3" ref-type="fig">Fig.Â 3</xref> cannot be well distinguished, we independently draw the results of these three algorithms on these datasets to draw box plots (<xref rid="btae004-F4" ref-type="fig">Fig.Â 4</xref>). However, it should be noted that these algorithms require up to 80% of the training samples, i.e. 80% of the labeling labels obtained through biological experiments need to be invested in the algorithm for auxiliary learning, so as to guide the network to learn useful and easily distinguishable features. We know that the biological experiment analysis cost is high, the cycle is long, the efficiency is low, consumes a lot of human, material, and financial resources, which greatly limits the universality of the algorithm. Therefore, the algorithmâs dependence on labels should be reduced as much as possible to reduce the cost.</p>
      <fig position="float" id="btae004-F3">
        <label>Figure 3.</label>
        <caption>
          <p>AUC discrimination performance obtained by eight existing supervised algorithms.</p>
        </caption>
        <graphic xlink:href="btae004f3" position="float"/>
      </fig>
      <fig position="float" id="btae004-F4">
        <label>Figure 4.</label>
        <caption>
          <p>AUC performance obtained by the latest three supervised learning algorithms on six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Our CircSI-SSL performance</title>
      <p>To validate the low dependency for labels and recognition effectiveness of our CircSI-SSL algorithm, we selected three algorithms with the best supervised performance, CircSSNN, HCRNet, and iCircRBP-DHN, and compared them with our algorithm under the premise of train:testâ=â1:9. The results are shown in <xref rid="btae004-F5" ref-type="fig">Fig.Â 5</xref>. It can be seen that our algorithm has achieved remarkable performance on most datasets and indicators, but we also see that our algorithm is slightly lower than HCRNet in Recall index. The reason may be that when very little supervision information is involved in training, supervised algorithms tend to pay too much attention to individual indicators and failure to achieve overall performance. For example, HCRNet focuses on recall index, while ACC and Precision fail to achieve good results. In contrast, our CircSI-SSL achieves a balanced and excellent performance across all metrics. It can also be seen from the comprehensive index AUC that the algorithm in this article has the best comprehensive ability and has a wide application prospect. For the convenience of comparison, we visualized the average AUC of the algorithm on six datasets as <xref rid="btae004-F6" ref-type="fig">Fig.Â 6</xref>. It can be intuitively seen that the algorithm in this article achieved the highest performance compared with other datasets, which was 3.3% higher on average and more than 5% higher on some datasets.</p>
      <fig position="float" id="btae004-F5">
        <label>Figure 5.</label>
        <caption>
          <p>Performance comparison between CircSI-SSL and the latest three supervised algorithms in four indicators.</p>
        </caption>
        <graphic xlink:href="btae004f5" position="float"/>
      </fig>
      <fig position="float" id="btae004-F6">
        <label>Figure 6.</label>
        <caption>
          <p>Average AUC performance comparison between CircSI-SSL and the latest three supervised algorithms on six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f6" position="float"/>
      </fig>
      <p>To further explore the relationship between the performance of the proposed algorithm and the amount of supervised information introduced, it is proved that the proposed algorithm can achieve stable performance under the condition of very few training samples. We conducted a step test according to the training samples from 1 to 9. Ratio was used to represent the ratio between the training set and the test set. The AUC performance obtained was shown in <xref rid="btae004-T1" ref-type="table">TableÂ 1</xref>. We can see that in general, the algorithm has learned easily distinguishable features under the sample ratio of 1:9, and achieved excellent classification performance. With the continuous increase of training samples, the performance of the algorithm can maintain a certain increase, but the difference is not much compared with the initial. This fully indicates that the cross-view prediction task based on SSL has trained the RNA_Transformer feature extractor and learned enough contextual features to represent the entire sequence. Only a very small number of samples are required to fine-tune for subsequent recognition tasks.</p>
      <table-wrap position="float" id="btae004-T1">
        <label>Table 1.</label>
        <caption>
          <p>AUC performance of CircSI-SSL algorithm under different training sample proportions.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Ratio</th>
              <th rowspan="1" colspan="1">WTAP</th>
              <th rowspan="1" colspan="1">FXR1</th>
              <th rowspan="1" colspan="1">C17ORF85</th>
              <th rowspan="1" colspan="1">QKI</th>
              <th rowspan="1" colspan="1">TAF15</th>
              <th rowspan="1" colspan="1">AUF1</th>
              <th rowspan="1" colspan="1">AVG</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1:9</td>
              <td rowspan="1" colspan="1">0.887</td>
              <td rowspan="1" colspan="1">0.981</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.961</td>
              <td rowspan="1" colspan="1">0.986</td>
              <td rowspan="1" colspan="1">0.971</td>
              <td rowspan="1" colspan="1">0.958</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2:8</td>
              <td rowspan="1" colspan="1">0.914</td>
              <td rowspan="1" colspan="1">0.980</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.986</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">0.963</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3:7</td>
              <td rowspan="1" colspan="1">0.913</td>
              <td rowspan="1" colspan="1">0.984</td>
              <td rowspan="1" colspan="1">0.962</td>
              <td rowspan="1" colspan="1">0.967</td>
              <td rowspan="1" colspan="1">0.987</td>
              <td rowspan="1" colspan="1">0.973</td>
              <td rowspan="1" colspan="1">0.964</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4:6</td>
              <td rowspan="1" colspan="1">0.926</td>
              <td rowspan="1" colspan="1">0.987</td>
              <td rowspan="1" colspan="1">0.963</td>
              <td rowspan="1" colspan="1">0.964</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.972</td>
              <td rowspan="1" colspan="1">0.967</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5:5</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.983</td>
              <td rowspan="1" colspan="1">0.961</td>
              <td rowspan="1" colspan="1">0.968</td>
              <td rowspan="1" colspan="1">0.988</td>
              <td rowspan="1" colspan="1">0.973</td>
              <td rowspan="1" colspan="1">0.968</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">6:4</td>
              <td rowspan="1" colspan="1">0.943</td>
              <td rowspan="1" colspan="1">0.985</td>
              <td rowspan="1" colspan="1">0.960</td>
              <td rowspan="1" colspan="1">0.969</td>
              <td rowspan="1" colspan="1">0.991</td>
              <td rowspan="1" colspan="1">0.977</td>
              <td rowspan="1" colspan="1">0.971</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">7:3</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.983</td>
              <td rowspan="1" colspan="1">0.959</td>
              <td rowspan="1" colspan="1">0.971</td>
              <td rowspan="1" colspan="1">0.990</td>
              <td rowspan="1" colspan="1">0.975</td>
              <td rowspan="1" colspan="1">0.969</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">8:2</td>
              <td rowspan="1" colspan="1">0.978</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.956</td>
              <td rowspan="1" colspan="1">0.970</td>
              <td rowspan="1" colspan="1">0.989</td>
              <td rowspan="1" colspan="1">0.979</td>
              <td rowspan="1" colspan="1">0.977</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.4 Ablation analysis</title>
      <p>In this section, we conduct an ablation analysis to demonstrate that the improved performance of our algorithm is a direct result of the SSL task we designed. The AUC performance obtained by the CircSI-SSL algorithm on these datasets is presented in <xref rid="btae004-T2" ref-type="table">TableÂ 2</xref>, where fine-tuning based on real labels is performed directly without cross-view sequence prediction task. It is evident that when no proxy task is performed, the algorithm performance drops off a cliff, with an average decline of about 10%, as shown in <xref rid="btae004-F7" ref-type="fig">Fig.Â 7</xref>. In particular, there is also an extreme AUC performance of 0.5. This is sufficient to show that it is necessary to conduct self-supervised tasks, to learn the overall expression of the sequence from the data (without labels), and thus to significantly improve subsequent classification tasks with only a few labels.</p>
      <fig position="float" id="btae004-F7">
        <label>Figure 7.</label>
        <caption>
          <p>Average AUC performance with and without SSL across six datasets.</p>
        </caption>
        <graphic xlink:href="btae004f7" position="float"/>
      </fig>
      <table-wrap position="float" id="btae004-T2">
        <label>Table 2.</label>
        <caption>
          <p>AUC performance of CircSI-SSL algorithm (without self-supervision task) under different training sample proportions.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Ratio</th>
              <th rowspan="1" colspan="1">WTAP</th>
              <th rowspan="1" colspan="1">FXR1</th>
              <th rowspan="1" colspan="1">C17ORF85</th>
              <th rowspan="1" colspan="1">QKI</th>
              <th rowspan="1" colspan="1">TAF15</th>
              <th rowspan="1" colspan="1">AUF1</th>
              <th rowspan="1" colspan="1">AVG</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1:9</td>
              <td rowspan="1" colspan="1">0.881</td>
              <td rowspan="1" colspan="1">0.883</td>
              <td rowspan="1" colspan="1">0.941</td>
              <td rowspan="1" colspan="1">0.866</td>
              <td rowspan="1" colspan="1">0.888</td>
              <td rowspan="1" colspan="1">0.653</td>
              <td rowspan="1" colspan="1">0.852</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2:8</td>
              <td rowspan="1" colspan="1">0.876</td>
              <td rowspan="1" colspan="1">0.895</td>
              <td rowspan="1" colspan="1">0.944</td>
              <td rowspan="1" colspan="1">0.838</td>
              <td rowspan="1" colspan="1">0.931</td>
              <td rowspan="1" colspan="1">0.848</td>
              <td rowspan="1" colspan="1">0.889</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3:7</td>
              <td rowspan="1" colspan="1">0.878</td>
              <td rowspan="1" colspan="1">0.923</td>
              <td rowspan="1" colspan="1">0.941</td>
              <td rowspan="1" colspan="1">0.923</td>
              <td rowspan="1" colspan="1">0.913</td>
              <td rowspan="1" colspan="1">0.711</td>
              <td rowspan="1" colspan="1">0.881</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4:6</td>
              <td rowspan="1" colspan="1">0.885</td>
              <td rowspan="1" colspan="1">0.904</td>
              <td rowspan="1" colspan="1">0.936</td>
              <td rowspan="1" colspan="1">0.926</td>
              <td rowspan="1" colspan="1">0.831</td>
              <td rowspan="1" colspan="1">0.744</td>
              <td rowspan="1" colspan="1">0.871</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5:5</td>
              <td rowspan="1" colspan="1">0.918</td>
              <td rowspan="1" colspan="1">0.938</td>
              <td rowspan="1" colspan="1">0.733</td>
              <td rowspan="1" colspan="1">0.673</td>
              <td rowspan="1" colspan="1">0.915</td>
              <td rowspan="1" colspan="1">0.673</td>
              <td rowspan="1" colspan="1">0.809</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">6:4</td>
              <td rowspan="1" colspan="1">0.907</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.945</td>
              <td rowspan="1" colspan="1">0.703</td>
              <td rowspan="1" colspan="1">0.909</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.744</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">7:3</td>
              <td rowspan="1" colspan="1">0.902</td>
              <td rowspan="1" colspan="1">0.898</td>
              <td rowspan="1" colspan="1">0.940</td>
              <td rowspan="1" colspan="1">0.934</td>
              <td rowspan="1" colspan="1">0.853</td>
              <td rowspan="1" colspan="1">0.775</td>
              <td rowspan="1" colspan="1">0.884</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">8:2</td>
              <td rowspan="1" colspan="1">0.930</td>
              <td rowspan="1" colspan="1">0.886</td>
              <td rowspan="1" colspan="1">0.946</td>
              <td rowspan="1" colspan="1">0.873</td>
              <td rowspan="1" colspan="1">0.836</td>
              <td rowspan="1" colspan="1">0.922</td>
              <td rowspan="1" colspan="1">0.899</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>3.5 Transplant analysis</title>
      <p>To further demonstrate the advantages of the proposed algorithm in more aspects, we transplanted the circSI-SSL algorithm originally designed for circRNA into the binding protein prediction task of linRNA without any network modification and with consistent hyperparameters. In the performance comparison between the six widely used linRNAs and several supervised algorithms as shown in <xref rid="btae004-F8" ref-type="fig">Fig.Â 8</xref> below, the ratio of training set to test set is still 1:9. Remarkably, the proposed algorithm achieves the best overall performance without any task-oriented tuning. In <xref rid="btae004-F8" ref-type="fig">Fig.Â 8</xref>, we can see that although iCircRBP-DHN also obtained a good average AUC value, it can also clearly see huge fluctuations in ACC, Precison, and Recall, which are separate indicators. HCRNet algorithm is relatively stable, but its performance on Recall index is poor. In the case of a very small number of training datasets put into training, the performance of the above two in each indicator is not balanced, and the overall good performance is not achieved. Therefore, supervised learning algorithm is not a good choice when there are only a few labeled samples. In contrast, the algorithm in this article achieves the overall optimal performance, even in such a harsh environment.</p>
      <fig position="float" id="btae004-F8">
        <label>Figure 8.</label>
        <caption>
          <p>Comparison of transplant performance on linRNA datasets.</p>
        </caption>
        <graphic xlink:href="btae004f8" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this article, we propose the novel CircSI-SSL framework for circRNAâRBP site recognition tasks based on SSL. By designing a cross-view sequence prediction task, the algorithm can learn the overall representation of the sequence in an unsupervised manner, and significantly enhance subsequent RBP identification performance with only a small amount of supervised information. Based on the improved Transformer network RNA_Transformer in this article, the framework extracts sequence context features from multiple views to characterize the sequence. By designing reasonable and effective proxy tasks, along with a stable and efficient network architecture, significant improvements were achieved with only a small amount of supervised information on the widely used six circRNA datasets and six linRNA datasets compared to supervised learning algorithms.</p>
    <p>In short, the CircSI-SSL algorithm based on SSL has good identification performance, expansion performance, and wide application range, only a small amount of label information can significantly improve the recognition performance. It is a very competitive tool for circRNAâRBP binding site identification.</p>
  </sec>
</body>
<back>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>The work was supported by the National Natural Science Foundation of China [62231013, 62250028, 62271329]; the Sichuan Provincial Science Fund for Distinguished Young Scholars [2021JDJQ0025]; the fund of Shenzhen Polytechnic [6022310036K, 6023310037K]; and the Municipal Government of Quzhou [No. 2022D040].</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae004-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alipanahi</surname><given-names>B</given-names></string-name>, <string-name><surname>Delong</surname><given-names>A</given-names></string-name>, <string-name><surname>Weirauch</surname><given-names>MT</given-names></string-name></person-group><etal>et al</etal><article-title>Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</article-title>. <source>Nat Biotechnol</source><year>2015</year>;<volume>33</volume>:<fpage>831</fpage>â<lpage>8</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bogard</surname><given-names>B</given-names></string-name>, <string-name><surname>Francastel</surname><given-names>C</given-names></string-name>, <string-name><surname>HubÃ©</surname><given-names>F.</given-names></string-name></person-group><article-title>A new method for the identification of thousands of circular RNAs</article-title>. <source>Non-Coding RNA Investig</source><year>2018</year>;<volume>2</volume>:<fpage>5</fpage>.</mixed-citation>
    </ref>
    <ref id="btae004-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>C</given-names></string-name>, <string-name><surname>Yang</surname><given-names>S</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>CircSSNN: circRNA-binding site prediction via sequence self-attention neural networks with pre-normalization</article-title>. <source>BMC Bioinformatics</source><year>2023</year>;<volume>24</volume>:<fpage>220</fpage>.<pub-id pub-id-type="pmid">37254080</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>L-L.</given-names></string-name></person-group><article-title>The biogenesis and emerging roles of circular RNAs</article-title>. <source>Nat Rev Mol Cell Biol</source><year>2016</year>;<volume>17</volume>:<fpage>205</fpage>â<lpage>11</lpage>.<pub-id pub-id-type="pmid">26908011</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>T</given-names></string-name>, <string-name><surname>Kornblith</surname><given-names>S</given-names></string-name>, <string-name><surname>Norouzi</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal> A simple framework for contrastive learning of visual representations. In: <italic toggle="yes">International Conference on Machine Learning</italic>. Vienna, Austria, 13 July, 2020. <fpage>1597</fpage>â1<lpage>607</lpage>. PMLR, 2020.</mixed-citation>
    </ref>
    <ref id="btae004-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning models for disease-associated circRNA prediction: a review</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac364</fpage>.<pub-id pub-id-type="pmid">36130259</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dori</surname><given-names>M</given-names></string-name>, <string-name><surname>Haj Abdullah Alieh</surname><given-names>L</given-names></string-name>, <string-name><surname>Cavalli</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Sequence and expression levels of circular RNAs in progenitor cell types during mouse corticogenesis</article-title>. <source>Life Sci Alliance</source><year>2019</year>;<volume>2</volume>:<fpage>e201900354</fpage>.<pub-id pub-id-type="pmid">30926618</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dudekula</surname><given-names>DB</given-names></string-name>, <string-name><surname>Panda</surname><given-names>AC</given-names></string-name>, <string-name><surname>Grammatikakis</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>CircInteractome: a web tool for exploring circular RNAs and their interacting proteins and microRNAs</article-title>. <source>RNA Biol</source><year>2016</year>;<volume>13</volume>:<fpage>34</fpage>â<lpage>42</lpage>.<pub-id pub-id-type="pmid">26669964</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Eldele</surname><given-names>E</given-names></string-name>, <string-name><surname>Ragab</surname><given-names>M</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal> Time-series representation learning via temporal and contextual contrasting. In <source>Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence.</source> Montreal, Canada, August 19-27, 2021, IJCAI, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="btae004-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gidaris</surname><given-names>S</given-names></string-name>, <string-name><surname>Singh</surname><given-names>P</given-names></string-name>, <string-name><surname>Komodakis</surname><given-names>N.</given-names></string-name></person-group> Unsupervised representation learning by predicting image rotations. In <italic toggle="yes">ICLR 2018</italic>, <italic toggle="yes">Vancouver Convention Center, Vancouver, BC, Canada, April 30 - May 3</italic>, <year>2018</year>, OpenReview.net.</mixed-citation>
    </ref>
    <ref id="btae004-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>GlaÅ¾ar</surname><given-names>P</given-names></string-name>, <string-name><surname>Papavasileiou</surname><given-names>P</given-names></string-name>, <string-name><surname>Rajewsky</surname><given-names>N.</given-names></string-name></person-group><article-title>circBase: a database for circular RNAs</article-title>. <source>RNA</source><year>2014</year>;<volume>20</volume>:<fpage>1666</fpage>â<lpage>70</lpage>.<pub-id pub-id-type="pmid">25234927</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hao</surname><given-names>S</given-names></string-name>, <string-name><surname>Lv</surname><given-names>J</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Q</given-names></string-name></person-group><etal>et al</etal><article-title>Identification of key genes and circular RNAs in human gastric cancer</article-title>. <source>Med Sci Monit</source><year>2019</year>;<volume>25</volume>:<fpage>2488</fpage>â<lpage>504</lpage>.<pub-id pub-id-type="pmid">30948703</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K</given-names></string-name>, <string-name><surname>Fan</surname><given-names>H</given-names></string-name>, <string-name><surname>Wu</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal> Momentum contrast for unsupervised visual representation learning. In: <italic toggle="yes">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</italic>. <fpage>9729</fpage>â<lpage>38</lpage>. <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="btae004-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>W</given-names></string-name>, <string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Duan</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>70ProPred: a predictor for discovering sigma70 promoters based on combining multiple features</article-title>. <source>BMC Syst Biol</source><year>2018</year>;<volume>12</volume>:<fpage>44</fpage>.<pub-id pub-id-type="pmid">29745856</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Hjelm</surname><given-names>RD</given-names></string-name>, <string-name><surname>Fedorov</surname><given-names>A</given-names></string-name>, <string-name><surname>Lavoie-Marchildon</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal> Learning deep representations by mutual information estimation and maximization. In <italic toggle="yes">International Conference on Learning Representations</italic>. New Orleans, LA, USA, May 6-9, 2019. <year>2019</year>, OpenReview.net.</mixed-citation>
    </ref>
    <ref id="btae004-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X.</given-names></string-name></person-group><article-title>Updated review of advances in microRNAs and complex diseases: taxonomy, trends and challenges of computational models</article-title>. <source>Brief Bioinform</source><year>2022a</year>;<volume>23</volume>:<fpage>bbac358</fpage>.<pub-id pub-id-type="pmid">36056743</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>L</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X.</given-names></string-name></person-group><article-title>Updated review of advances in microRNAs and complex diseases: towards systematic evaluation of computational models</article-title>. <source>Brief Bioinform</source><year>2022b</year>;<volume>23</volume>:<fpage>bbac407</fpage>.<pub-id pub-id-type="pmid">36151749</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jia</surname><given-names>C</given-names></string-name>, <string-name><surname>Bi</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>PASSION: an ensemble neural network approach for identifying the binding sites of RBPs on circRNAs</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>4276</fpage>â<lpage>82</lpage>.<pub-id pub-id-type="pmid">32426818</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiao</surname><given-names>S</given-names></string-name>, <string-name><surname>Wu</surname><given-names>S</given-names></string-name>, <string-name><surname>Huang</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Advances in the identification of circular RNAs and research into circRNAs in human diseases</article-title>. <source>Front Genet</source><year>2021</year>;<volume>12</volume>:<fpage>665233</fpage>.<pub-id pub-id-type="pmid">33815488</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ju</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yuan</surname><given-names>L</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>CircSLNN: identifying RBP-binding sites on circRNAs via sequence labeling neural networks</article-title>. <source>Front Genet</source><year>2019</year>;<volume>10</volume>:<fpage>1184</fpage>.<pub-id pub-id-type="pmid">31824574</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>Q</given-names></string-name>, <string-name><surname>Mikolov</surname><given-names>T.</given-names></string-name></person-group> Distributed representations of sentences and documents. In: <italic toggle="yes">International Conference on Machine Learning</italic>, <italic toggle="yes">Beijing, China, on June 21âJune 26, 2014</italic>. <fpage>1188</fpage>â<lpage>96</lpage>. <publisher-name>PMLR, 2014.</publisher-name></mixed-citation>
    </ref>
    <ref id="btae004-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>S</given-names></string-name>, <string-name><surname>Han</surname><given-names>L.</given-names></string-name></person-group><article-title>Circular RNAs as promising biomarkers in cancer: detection, function, and beyond</article-title>. <source>Genome Med</source><year>2019</year>;<volume>11</volume>:<fpage>15</fpage>.<pub-id pub-id-type="pmid">30894216</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>W</given-names></string-name>, <string-name><surname>Godzik</surname><given-names>A.</given-names></string-name></person-group><article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source><year>2006</year>;<volume>22</volume>:<fpage>1658</fpage>â<lpage>9</lpage>.<pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal><article-title>Self-supervised learning: generative or contrastive</article-title>. <source>IEEE Trans Knowl Data Eng</source><year>2021</year>;<volume>35</volume>:<fpage>1</fpage>â<lpage>876</lpage>.<pub-id pub-id-type="pmid">36506788</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>AS</given-names></string-name>, <string-name><surname>Sreenadhan</surname><given-names>SP.</given-names></string-name></person-group><article-title>A coding measure scheme employing electron-ion interaction pseudopotential (EIIP)</article-title>. <source>Bioinformation</source><year>2006</year>;<volume>1</volume>:<fpage>197</fpage>â<lpage>202</lpage>.<pub-id pub-id-type="pmid">17597888</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Ju</surname><given-names>Y</given-names></string-name>, <string-name><surname>Lin</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Characterizing viral circRNAs and their application in identifying circRNAs in viruses</article-title>. <source>Brief Bioinform</source><year>2022a</year>;<volume>23</volume>:<fpage>bbab404</fpage>.<pub-id pub-id-type="pmid">34585234</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Lin</surname><given-names>C.</given-names></string-name></person-group><article-title>CRBPDL: identification of circRNA-RBP interaction sites using an ensemble neural network approach</article-title>. <source>PLoS Comput Biol</source><year>2022b</year>;<volume>18</volume>:<fpage>e1009798</fpage>.<pub-id pub-id-type="pmid">35051187</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname><given-names>M</given-names></string-name>, <string-name><surname>Zou</surname><given-names>Q</given-names></string-name>, <string-name><surname>Wang</surname><given-names>C.</given-names></string-name></person-group><article-title>GMNN2CD: identification of circRNAâdisease associations based on variational inference and graph Markov neural networks</article-title>. <source>Bioinformatics</source><year>2022c</year>;<volume>38</volume>:<fpage>2246</fpage>â<lpage>53</lpage>.<pub-id pub-id-type="pmid">35157027</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B29">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Noroozi</surname><given-names>M</given-names></string-name>, <string-name><surname>Favaro</surname><given-names>P.</given-names></string-name></person-group> Unsupervised learning of visual representations by solving jigsaw puzzles. In: <italic toggle="yes">European Conference on Computer Vision</italic>, <italic toggle="yes">Amsterdam, Netherlands, October 10-16, 2016</italic>. <fpage>69</fpage>â<lpage>84</lpage>. Springer, 2016.</mixed-citation>
    </ref>
    <ref id="btae004-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Oord</surname><given-names>A</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Vinyals</surname><given-names>O.</given-names></string-name></person-group> Representation learning with contrastive predictive coding. arXiv, arXiv:1807.03748, <year>2018</year>. <pub-id pub-id-type="doi">10.48550/arXiv.1807.03748</pub-id>.</mixed-citation>
    </ref>
    <ref id="btae004-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orenstein</surname><given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Berger</surname><given-names>B.</given-names></string-name></person-group><article-title>RCK: accurate and efficient inference of sequence-and structure-based proteinâRNA binding models from RNAcompete data</article-title>. <source>Bioinformatics</source><year>2016</year>;<volume>32</volume>:<fpage>i351</fpage>â<lpage>9</lpage>.<pub-id pub-id-type="pmid">27307637</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pan</surname><given-names>X</given-names></string-name>, <string-name><surname>Rijnbeek</surname><given-names>P</given-names></string-name>, <string-name><surname>Yan</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks</article-title>. <source>BMC Genomics</source><year>2018</year>;<volume>19</volume>:<fpage>511</fpage>.<pub-id pub-id-type="pmid">29970003</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ruan</surname><given-names>H</given-names></string-name>, <string-name><surname>Xiang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Ko</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Comprehensive characterization of circular RNAs inâ¼ 1000 human cancer cell lines</article-title>. <source>Genome Med</source><year>2019</year>;<volume>11</volume>:<fpage>55</fpage>.<pub-id pub-id-type="pmid">31446897</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rybak-Wolf</surname><given-names>A</given-names></string-name>, <string-name><surname>Stottmeister</surname><given-names>C</given-names></string-name>, <string-name><surname>GlaÅ¾ar</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>Circular RNAs in the mammalian brain are highly abundant, conserved, and dynamically expressed</article-title>. <source>Mol Cell</source><year>2015</year>;<volume>58</volume>:<fpage>870</fpage>â<lpage>85</lpage>.<pub-id pub-id-type="pmid">25921068</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Su</surname><given-names>L</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>J</given-names></string-name>, <string-name><surname>Su</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>CircRNAs in lung adenocarcinoma: diagnosis and therapy</article-title>. <source>Curr Gene Ther</source><year>2022</year>;<volume>22</volume>:<fpage>15</fpage>â<lpage>22</lpage>.<pub-id pub-id-type="pmid">34856899</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B36">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A</given-names></string-name>, <string-name><surname>Shazeer</surname><given-names>N</given-names></string-name>, <string-name><surname>Parmar</surname><given-names>N</given-names></string-name></person-group> et al. Attention is all you need. In: Advances in Neural Information Processing Systems, <italic toggle="yes">Long Beach, USA, December 4-9, 2017</italic>. Vol. 30. MIT Press, 2017.</mixed-citation>
    </ref>
    <ref id="btae004-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>CC</given-names></string-name>, <string-name><surname>Han</surname><given-names>CD</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>Q</given-names></string-name></person-group><etal>et al</etal><article-title>Circular RNAs and complex diseases: from experimental results to computational models</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbab286</fpage>.<pub-id pub-id-type="pmid">34329377</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Li</surname><given-names>B</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>T</given-names></string-name></person-group><etal>et al</etal> Learning deep transformer models for machine translation. In <italic toggle="yes">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</italic>. Florence, Italy, July, <year>2019a</year>, Association for Computational Linguistics.</mixed-citation>
    </ref>
    <ref id="btae004-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Lei</surname><given-names>X</given-names></string-name>, <string-name><surname>Wu</surname><given-names>F-X.</given-names></string-name></person-group><article-title>Identifying cancer-specific circRNAâRBP binding sites based on deep learning</article-title>. <source>Molecules</source><year>2019b</year>;<volume>24</volume>:<fpage>4035</fpage>.<pub-id pub-id-type="pmid">31703384</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Ma</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal><article-title>iCircRBP-DHN: identification of circRNA-RBP interaction sites using deep hierarchical network</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>bbaa274</fpage>.<pub-id pub-id-type="pmid">33126261</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Hou</surname><given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>HCRNet: high-throughput circRNA-binding event identification from CLIP-seq data using deep temporal convolutional network</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac027</fpage>.<pub-id pub-id-type="pmid">35189638</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yee</surname><given-names>BA</given-names></string-name>, <string-name><surname>Pratt</surname><given-names>GA</given-names></string-name>, <string-name><surname>Graveley</surname><given-names>BR</given-names></string-name></person-group><etal>et al</etal><article-title>RBP-Maps enables robust generation of splicing regulatory maps</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>193</fpage>â<lpage>204</lpage>.<pub-id pub-id-type="pmid">30413564</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zang</surname><given-names>J</given-names></string-name>, <string-name><surname>Lu</surname><given-names>D</given-names></string-name>, <string-name><surname>Xu</surname><given-names>A.</given-names></string-name></person-group><article-title>The interaction of circRNAs and RNA binding proteins: an important part of circRNA maintenance and function</article-title>. <source>J Neurosci Res</source><year>2020</year>;<volume>98</volume>:<fpage>87</fpage>â<lpage>97</lpage>.<pub-id pub-id-type="pmid">30575990</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>H-D</given-names></string-name>, <string-name><surname>Jiang</surname><given-names>L-H</given-names></string-name>, <string-name><surname>Sun</surname><given-names>D-W</given-names></string-name></person-group><etal>et al</etal><article-title>CircRNA: a novel type of biomarker for cancer</article-title>. <source>Breast Cancer</source><year>2018</year>;<volume>25</volume>:<fpage>1</fpage>â<lpage>7</lpage>.<pub-id pub-id-type="pmid">28721656</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>K</given-names></string-name>, <string-name><surname>Pan</surname><given-names>X</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name></person-group><etal>et al</etal><article-title>CRIP: predicting circRNAâRBP-binding sites using a codon-based encoding and hybrid deep neural networks</article-title>. <source>RNA</source><year>2019</year>;<volume>25</volume>:<fpage>1604</fpage>â<lpage>15</lpage>.<pub-id pub-id-type="pmid">31537716</pub-id></mixed-citation>
    </ref>
    <ref id="btae004-B46">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>R</given-names></string-name>, <string-name><surname>Isola</surname><given-names>P</given-names></string-name>, <string-name><surname>Efros</surname><given-names>AA.</given-names></string-name></person-group> Colorful image colorization. In: <italic toggle="yes">Computer VisionâECCV 2016: 14th European Conference, Amsterdam, Netherlands, October 11-14, 2016, Proceedings, Part III 14.</italic><fpage>649</fpage>â<lpage>66</lpage>. Springer, <year>2016</year>.</mixed-citation>
    </ref>
  </ref-list>
</back>
