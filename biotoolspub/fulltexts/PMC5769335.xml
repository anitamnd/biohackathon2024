<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5769335</article-id>
    <article-id pub-id-type="publisher-id">1996</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-017-1996-y</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>diceR: an R package for class discovery using an ensemble driven approach</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chiu</surname>
          <given-names>Derek S.</given-names>
        </name>
        <address>
          <email>dchiu@bccrc.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7760-410X</contrib-id>
        <name>
          <surname>Talhouk</surname>
          <given-names>Aline</given-names>
        </name>
        <address>
          <email>atalhouk@bccrc.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0702 3000</institution-id><institution-id institution-id-type="GRID">grid.248762.d</institution-id><institution>Department of Molecular Oncology, </institution><institution>BC Cancer Agency, </institution></institution-wrap>Vancouver, BC Canada </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2288 9830</institution-id><institution-id institution-id-type="GRID">grid.17091.3e</institution-id><institution>Department of Pathology and Laboratory Medicine, </institution><institution>University of British Columbia, </institution></institution-wrap>Vancouver, BC Canada </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>1</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>1</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <volume>19</volume>
    <elocation-id>11</elocation-id>
    <history>
      <date date-type="received">
        <day>8</day>
        <month>8</month>
        <year>2017</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>12</month>
        <year>2017</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s). 2018</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Given a set of features, researchers are often interested in partitioning objects into homogeneous clusters. In health research, cancer research in particular, high-throughput data is collected with the aim of segmenting patients into sub-populations to aid in disease diagnosis, prognosis or response to therapy. Cluster analysis, a class of unsupervised learning techniques, is often used for class discovery. Cluster analysis suffers from some limitations, including the need to select up-front the algorithm to be used as well as the number of clusters to generate, in addition, there may exist several groupings consistent with the data, making it very difficult to validate a final solution. Ensemble clustering is a technique used to mitigate these limitations and facilitate the generalization and reproducibility of findings in new cohorts of patients.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We introduce <italic>diceR (diverse cluster ensemble in R)</italic>, a software package available on CRAN: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=diceR">https://CRAN.R-project.org/package=diceR</ext-link></p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3"><italic>diceR</italic> is designed to provide a set of tools to guide researchers through a general cluster analysis process that relies on minimizing subjective decision-making. Although developed in a biological context, the tools in <italic>diceR</italic> are data-agnostic and thus can be applied in different contexts.</p>
      </sec>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (doi: 10.1186/s12859-017-1996-y) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Data mining</kwd>
      <kwd>Cluster analysis</kwd>
      <kwd>Ensemble</kwd>
      <kwd>Consensus</kwd>
      <kwd>Cancer</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2018</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par9">Cluster analysis has been used in cancer research to discover new classifications of disease and improve the understanding of underlying biological mechanisms. This technique belongs to a set of unsupervised statistical learning methods used to partition objects and/or features into homogeneous groups or clusters [<xref ref-type="bibr" rid="CR1">1</xref>]. It provides insight, for example, to how co-regulated genes associate with groupings of similar patients based on features of their disease, such as prognostic risk or propensity to respond to therapy. Many clustering algorithms are available, though none stand out as universally better than the others. Different algorithms may be better suited for specific types of data, and in high dimensions it is difficult to evaluate whether algorithm assumptions are met. Furthermore, researchers must set the number of clusters a priori for most algorithms. Additionally, several clustering solutions consistent with the data are possible, making the ascertainment of a final result without considerable reliance on additional extrinsic information difficult [<xref ref-type="bibr" rid="CR2">2</xref>]. Many internal clustering criteria have been proposed to evaluate the output of cluster analysis. These generally consist of measures of compactness (how similar are objects within the same cluster), separation (how distinct are objects from different clusters), and robustness (how reproducible are the clusters in other datasets) [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR4">4</xref>]. External evaluation can also be used to assess how resulting clusters and groupings corroborate known biological features. Researchers may choose to use internal clustering criteria only for performance evaluation [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>] to keep the analysis congruent with an unsupervised approach.</p>
    <p id="Par10">Ensemble methods are a popular class of algorithms that have been used in both the supervised [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>] and unsupervised learning setting. In the unsupervised setting, cluster ensembles have been proposed as a class of algorithms that can help mitigate many of the limitations of traditional cluster analysis by combining clustering results from multiple “experts” [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR9">9</xref>]. Ensembles are achieved by generating different clusterings, using different subsets of the data, different algorithms, or different number of clusters, and combining the results into a single consensus solution. Ensemble methods have been shown to result in a more robust clustering that converges to a true solution (if a unique one exists) as the number of experts is increased [<xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR11">11</xref>]. The agnostic approach of ensemble learning makes the technique useful in many health applications, and non-health applications such as clustering communities in social network analysis (Maglaras et al., 2016) and classifying credit scores (Koutanaei et al., 2015).</p>
  </sec>
  <sec id="Sec2">
    <title>Implementation</title>
    <p id="Par11">In this paper, we introduce diverse cluster ensemble in R <italic>(diceR</italic>), a software package built in the R statistical language (version 3.2.0+) that provides a suite of functions and tools to implement a systematic framework for cluster discovery using ensemble clustering. This framework guides the user through the steps of generating diverse clusterings, ensemble formation, and algorithm selection to the arrival at a final consensus solution, most consistent with the data. We developed a visual and analytical validation framework, thereby integrating the assessment of the final result into the process. Problems with scalability to large datasets were solved by rewriting some of the functions to run parallel on a computing cluster. <italic>diceR</italic> is available on CRAN.</p>
  </sec>
  <sec id="Sec3">
    <title>Results and discussion</title>
    <p id="Par12">The steps performed in the <italic>diceR</italic> framework are summarized below and in Fig. <xref rid="Fig1" ref-type="fig">1</xref>; a more detailed example can be found in the Additional file <xref rid="MOESM1" ref-type="media">1</xref> and at <ext-link ext-link-type="uri" xlink:href="https://alinetalhouk.github.io/diceR">https://alinetalhouk.github.io/diceR</ext-link><fig id="Fig1"><label>Fig. 1</label><caption><p>Ensemble clustering pipeline implemented in diceR. The analytical process is carried out by the main function of the package: dice</p></caption><graphic xlink:href="12859_2017_1996_Fig1_HTML" id="MO1"/></fig></p>
    <sec id="Sec4">
      <title>Diverse cluster generation</title>
      <p id="Par13">The full process is incorporated into a single function dice that wraps the different components described herein. The input data consists of a data frame with rows as samples and columns as features. Cluster generation is obtained by applying a variety of clustering algorithms (e.g. k-means, spectral clustering, etc.), distance metrics (e.g. Euclidean, Manhattan, etc.), and cluster sizes to the input data (please consult the supplementary methods for the list of algorithms and clustering distances currently implemented). In addition to algorithms and distances implemented within <italic>diceR</italic>, a simple framework is available for the user to input the algorithm or distance of their choosing. Every algorithm is applied to several subsets of the data, each consisting of 80% of the original observations. As a result of subsampling, not every sample is included in each clustering; the data is “completed” using k-nearest neighbor and majority voting.<graphic position="anchor" xlink:href="12859_2017_1996_Figa_HTML" id="MO2"/></p>
      <p id="Par14">The output of the cluster generation step is an array of clustering assignments computed across cluster sizes, algorithms, and subsamples of the data (See “Clustering Array” and “Completed Clustering Array” in Fig. <xref rid="Fig1" ref-type="fig">1</xref>). This technique extends the consensus clustering method proposed by Monti et al. [<xref ref-type="bibr" rid="CR12">12</xref>] to include a consensus across algorithms.</p>
    </sec>
    <sec id="Sec5">
      <title>Consensus ensemble</title>
      <p id="Par15">A cluster ensemble is generated by combining results from the cluster generation step. <italic>diceR</italic> implements four methods for consensus formation: Majority Voting [<xref ref-type="bibr" rid="CR13">13</xref>], K-modes [<xref ref-type="bibr" rid="CR14">14</xref>], Link-Based Cluster Ensembles (LCE) [<xref ref-type="bibr" rid="CR10">10</xref>], and Cluster-based Similarity Partitioning Algorithm (CSPA) [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR15">15</xref>] (See Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Thus, the final ensemble is a consensus across samples <italic>and</italic> algorithms.</p>
      <p id="Par16">
        <inline-graphic xlink:href="12859_2017_1996_Figb_HTML.gif" id="d29e420"/>
      </p>
      <p id="Par17">There is also an option to choose a consensus cluster size using the proportion of ambiguous clustering (PAC) metric [<xref ref-type="bibr" rid="CR4">4</xref>]. The cluster size corresponding to the smallest PAC value is selected, since low values of PAC indicate greater clustering stability. Additionally, the user can allocate different weights to the algorithms in the ensemble, proportional to their internal evaluation index scores.</p>
    </sec>
    <sec id="Sec6">
      <title>Visualization and evaluation</title>
      <p id="Par18">For each clustering algorithm used, we calculate internal and external validity indices [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>]. <italic>diceR</italic> has visualization plots to compare clustering results between different cluster sizes. The user can monitor the consensus cumulative distribution functions (CDFs), relative change in area under the curve for CDFs, heatmaps, and track how cluster assignments change in relation to the requested cluster size.<graphic position="anchor" xlink:href="12859_2017_1996_Figc_HTML" id="MO3"/></p>
      <p id="Par19">A hypothesis testing mechanism based on the SigClust method is also implemented in <italic>diceR</italic> to assess whether clustering results are statistically significant [<xref ref-type="bibr" rid="CR16">16</xref>]. This allows quantification of the confidence in the partitions. For example, we can test whether the number of statistically distinct clusters is equal to two or three, as opposed to just one (i.e. unimodal distribution no clusters). In Fig. <xref rid="Fig2" ref-type="fig">2</xref> we present a visualization of the results of a comparative analysis.<fig id="Fig2"><label>Fig. 2</label><caption><p>A comparative evaluation using diceR applied to three datasets. Using 10 clustering algorithms, we repeated the clustering of each data set, each time using only 80% of the data. Four ensemble approaches were considered. The ensembles were constructed using all the individual clusterings and were repeated by omitting the least performing algorithms (the trim version in the figure). Thirteen internal validity indices were used to rank order these algorithms based on performance from top to bottom. Indices were standardized so their performance is relative to each other. The green/red annotation tracks at the top indicate which indices should be maximized or minimized respectively. Ensemble methods were highlighted using a bold font</p></caption><graphic xlink:href="12859_2017_1996_Fig2_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec7">
      <title>Algorithm selection</title>
      <p id="Par20">Poor-performing algorithms can affect a cluster ensemble’s performance, so one way to limit that is to include only the top N performing algorithms in the ensemble [<xref ref-type="bibr" rid="CR17">17</xref>]. To this end, the internal validity indices for all algorithms are computed (see Additional file <xref rid="MOESM1" ref-type="media">1</xref> for full list of indices). Then, rank aggregation is used to select a subset of algorithms that perform well across all indices [<xref ref-type="bibr" rid="CR18">18</xref>]. The resulting subset of algorithms is selected for inclusion in the cluster ensemble. Our “diverse” strategy is not to impose diversity onto the ensemble, but to <italic>consider</italic> a diverse set of algorithms and ultimately allow the data to select which best performing algorithms to retain. This step of the analysis continues to be an active area of research and is subject to revision and improvements.</p>
    </sec>
  </sec>
  <sec id="Sec8">
    <title>Conclusions</title>
    <p id="Par21">The software we have developed provides an easy-to-use interface for researchers of all fields to use for their cluster analysis needs. More clustering algorithms will be added to <italic>diceR</italic> as they become available.</p>
  </sec>
</body>
<back>
  <app-group>
    <app id="App1">
      <sec id="Sec9">
        <title>Additional file</title>
        <p id="Par27">
          <media position="anchor" xlink:href="12859_2017_1996_MOESM1_ESM.pdf" id="MOESM1">
            <label>Additional file 1:</label>
            <caption>
              <p>A detailed tutorial and example of Cluster Analysis using diceR. (PDF 326 kb)</p>
            </caption>
          </media>
        </p>
      </sec>
    </app>
  </app-group>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>CDF</term>
        <def>
          <p id="Par4">Cumulative distribution function</p>
        </def>
      </def-item>
      <def-item>
        <term>CSPA</term>
        <def>
          <p id="Par5">Cluster-Based Partitioning Algorithm</p>
        </def>
      </def-item>
      <def-item>
        <term>diceR</term>
        <def>
          <p id="Par6">Diverse cluster ensemble in R</p>
        </def>
      </def-item>
      <def-item>
        <term>LCE</term>
        <def>
          <p id="Par7">Linkage-Based Cluster Ensembles</p>
        </def>
      </def-item>
      <def-item>
        <term>PAC</term>
        <def>
          <p id="Par8">Proportion of ambiguous clustering</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Electronic supplementary material</bold>
      </p>
      <p>The online version of this article (doi: 10.1186/s12859-017-1996-y) contains supplementary material, which is available to authorized users.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to acknowledge the contributions of Johnson Liu in package development and Dr. Michael Anglesio and Jennifer Ji for providing helpful feedback.</p>
    <sec id="FPar1">
      <title>Funding</title>
      <p id="Par22">This research was supported by donor funds to OVCARE (<ext-link ext-link-type="uri" xlink:href="http://www.ovcare.ca">www.ovcare.ca</ext-link>) from the Vancouver General Hospital and University of British Columbia Hospital Foundation and the BC Cancer Foundation.</p>
    </sec>
    <sec id="FPar2">
      <title>Availability of data and materials</title>
      <p id="Par23"><italic>diceR</italic> is available on CRAN: <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=diceR">https://CRAN.R-project.org/package=diceR</ext-link>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>DSC and AT wrote and analysed the functions in the software package. Both authors wrote, read, and approved the final manuscript.</p>
  </notes>
  <notes notes-type="COI-statement">
    <sec id="FPar3">
      <title>Ethics approval and consent to participate</title>
      <p id="Par24">Not applicable.</p>
    </sec>
    <sec id="FPar4">
      <title>Consent for publication</title>
      <p id="Par25">Not applicable.</p>
    </sec>
    <sec id="FPar5">
      <title>Competing interests</title>
      <p id="Par26">The authors declare that they have no competing interests.</p>
    </sec>
    <sec id="FPar6">
      <title>Publisher’s Note</title>
      <p id="Par38">Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </sec>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Hennig C, Meila M, Murtagh F, Rocci R. Handbook of cluster analysis: CRC Press Book; 2015.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>Q</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Cancer classification in the genomic era: five contemporary problems</article-title>
        <source>Hum Genomics</source>
        <year>2015</year>
        <volume>9</volume>
        <fpage>27</fpage>
        <pub-id pub-id-type="doi">10.1186/s40246-015-0049-8</pub-id>
        <?supplied-pmid 26481255?>
        <pub-id pub-id-type="pmid">26481255</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Understanding and enhancement of internal clustering validation measures</article-title>
        <source>IEEE Trans Cybern</source>
        <year>2013</year>
        <volume>43</volume>
        <fpage>982</fpage>
        <lpage>994</lpage>
        <pub-id pub-id-type="doi">10.1109/TSMCB.2012.2220543</pub-id>
        <?supplied-pmid 23193245?>
        <pub-id pub-id-type="pmid">23193245</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Șenbabaoğlu</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Critical limitations of consensus clustering in class discovery</article-title>
        <source>Sci Rep</source>
        <year>2014</year>
        <volume>4</volume>
        <fpage>6207</fpage>
        <?supplied-pmid 25158761?>
        <pub-id pub-id-type="pmid">25158761</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Arbelaitz</surname>
            <given-names>O</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An extensive comparative study of cluster validity indices</article-title>
        <source>Pattern Recogn</source>
        <year>2013</year>
        <volume>46</volume>
        <fpage>243</fpage>
        <lpage>256</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2012.07.021</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Handl</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Computational cluster validation in post-genomic data analysis</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>3201</fpage>
        <lpage>3212</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti517</pub-id>
        <?supplied-pmid 15914541?>
        <pub-id pub-id-type="pmid">15914541</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>Mach Learn</source>
        <year>2001</year>
        <volume>45</volume>
        <fpage>5</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Neumann</surname>
            <given-names>U</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>EFS: an ensemble feature selection tool implemented as R-package and web-application</article-title>
        <source>BioData Min.</source>
        <year>2017</year>
        <volume>10</volume>
        <fpage>21</fpage>
        <pub-id pub-id-type="doi">10.1186/s13040-017-0142-8</pub-id>
        <?supplied-pmid 28674556?>
        <pub-id pub-id-type="pmid">28674556</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Strehl</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ghosh</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Cluster ensembles – a knowledge reuse framework for combining multiple partitions</article-title>
        <source>J Mach Learn Res</source>
        <year>2002</year>
        <volume>3</volume>
        <fpage>583</fpage>
        <lpage>617</lpage>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Iam-On</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>LCE: a link-based cluster ensemble method for improved gene expression data analysis</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <fpage>1513</fpage>
        <lpage>1519</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq226</pub-id>
        <?supplied-pmid 20444838?>
        <pub-id pub-id-type="pmid">20444838</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Topchy, A.P. <italic>et al.</italic> A mixture model for clustering ensembles. In, <italic>SDM</italic>., 2004. pp. 379–390.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monti</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Consensus clustering: a resampling based method for class discovery and visualization of gene expression microarray data</article-title>
        <source>Mach Learn</source>
        <year>2003</year>
        <volume>52</volume>
        <fpage>91</fpage>
        <lpage>118</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1023949509487</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ayad</surname>
            <given-names>HG</given-names>
          </name>
          <name>
            <surname>Kamel</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>On voting-based consensus of cluster ensembles</article-title>
        <source>Pattern Recogn</source>
        <year>2010</year>
        <volume>43</volume>
        <fpage>1943</fpage>
        <lpage>1953</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2009.11.012</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Huang Z. A fast clustering algorithm to cluster very large categorical data sets in data mining. Res Issues Data Min Knowl Discov. 1997:1–8.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ghosh</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Acharya</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Cluster ensembles</article-title>
        <source>Wiley Interdiscip Rev Data Min Knowl Discov</source>
        <year>2011</year>
        <volume>1</volume>
        <fpage>305</fpage>
        <lpage>315</lpage>
        <pub-id pub-id-type="doi">10.1002/widm.32</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Statistical significance of clustering using soft Thresholding</article-title>
        <source>J Comput Graph Stat</source>
        <year>2015</year>
        <volume>24</volume>
        <fpage>975</fpage>
        <lpage>993</lpage>
        <pub-id pub-id-type="doi">10.1080/10618600.2014.948179</pub-id>
        <?supplied-pmid 26755893?>
        <pub-id pub-id-type="pmid">26755893</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Naldi</surname>
            <given-names>MC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Cluster ensemble selection based on relative validity indexes</article-title>
        <source>Data Min Knowl Discov</source>
        <year>2013</year>
        <volume>27</volume>
        <fpage>259</fpage>
        <lpage>289</lpage>
        <pub-id pub-id-type="doi">10.1007/s10618-012-0290-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pihur</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>RankAggreg, an R package for weighted rank aggregation</article-title>
        <source>BMC Bioinformatics</source>
        <year>2009</year>
        <volume>10</volume>
        <fpage>62</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-10-62</pub-id>
        <?supplied-pmid 19228411?>
        <pub-id pub-id-type="pmid">19228411</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
