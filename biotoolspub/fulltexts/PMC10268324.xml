<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archivearticle1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Proc Natl Acad Sci U S A</journal-id>
    <journal-id journal-id-type="iso-abbrev">Proc Natl Acad Sci U S A</journal-id>
    <journal-id journal-id-type="publisher-id">PNAS</journal-id>
    <journal-title-group>
      <journal-title>Proceedings of the National Academy of Sciences of the United States of America</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0027-8424</issn>
    <issn pub-type="epub">1091-6490</issn>
    <publisher>
      <publisher-name>National Academy of Sciences</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10268324</article-id>
    <article-id pub-id-type="pmid">37289807</article-id>
    <article-id pub-id-type="publisher-id">202220778</article-id>
    <article-id pub-id-type="doi">10.1073/pnas.2220778120</article-id>
    <article-categories>
      <subj-group subj-group-type="type">
        <compound-subject>
          <compound-subject-part content-type="code">research-article</compound-subject-part>
          <compound-subject-part content-type="label">Research Article</compound-subject-part>
        </compound-subject>
      </subj-group>
      <subj-group subj-group-type="topic">
        <compound-subject>
          <compound-subject-part content-type="code">biophys-bio</compound-subject-part>
          <compound-subject-part content-type="label">Biophysics and Computational Biology</compound-subject-part>
        </compound-subject>
      </subj-group>
      <subj-group subj-group-type="hwp-journal-coll">
        <subject>408</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Biological Sciences</subject>
        <subj-group>
          <subject>Biophysics and Computational Biology</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Contrastive learning in protein language space predicts interactions between drugs and protein targets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Singh</surname>
          <given-names>Rohit</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>a</sup>
        </xref>
        <xref rid="fn2" ref-type="author-notes">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sledzieski</surname>
          <given-names>Samuel</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>a</sup>
        </xref>
        <xref rid="fn2" ref-type="author-notes">
          <sup>1</sup>
        </xref>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0170-3029</contrib-id>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bryson</surname>
          <given-names>Bryan</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>b</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>c</sup>
        </xref>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1716-6712</contrib-id>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Cowen</surname>
          <given-names>Lenore</given-names>
        </name>
        <email>cowen@cs.tufts.edu</email>
        <xref rid="aff4" ref-type="aff">
          <sup>d</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp">
          <sup>2</sup>
        </xref>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6698-6413</contrib-id>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Berger</surname>
          <given-names>Bonnie</given-names>
        </name>
        <email>bab@mit.edu</email>
        <xref rid="aff1" ref-type="aff">
          <sup>a</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>e</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp">
          <sup>2</sup>
        </xref>
      </contrib>
      <aff id="aff1"><sup>a</sup><institution>Computer Science and Artificial Intelligence Laboratory</institution>, <institution>Massachusetts Institute of Technology</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
      <aff id="aff2"><sup>b</sup><institution>Ragon Institute of MGH</institution>, <institution>MIT and Harvard</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
      <aff id="aff3"><sup>c</sup><institution>Department of Biological Engineering</institution>, <institution>Massachusetts Institute of Technology</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
      <aff id="aff4"><sup>d</sup><institution>Department of Computer Science</institution>, <institution>Tufts University</institution>, <city>Medford</city>, <state>MA</state><postal-code>02155</postal-code></aff>
      <aff id="aff5"><sup>e</sup><institution>Department of Mathematics</institution>, <institution>Massachusetts Institute of Technology</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><sup>2</sup>To whom correspondence may be addressed. Email: <email>cowen@cs.tufts.edu</email> or <email>bab@mit.edu</email>.</corresp>
      <fn fn-type="edited-by" id="fn1">
        <p>Edited by Barry Honig, Columbia University, New York, NY; received December 6, 2022; accepted April 10, 2023</p>
      </fn>
      <fn fn-type="equal" id="fn2">
        <p><sup>1</sup>R.S. and S.S. contributed equally to this work.</p>
      </fn>
    </author-notes>
    <pub-date publication-format="electronic" date-type="pub">
      <day>8</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date publication-format="print" date-type="pub">
      <day>13</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>8</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <!--PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.-->
    <volume>120</volume>
    <issue>24</issue>
    <elocation-id>e2220778120</elocation-id>
    <history>
      <date date-type="received">
        <day>06</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 the Author(s). Published by PNAS.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This open access article is distributed under <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND)</ext-link>.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pnas.202220778.pdf"/>
    <abstract abstract-type="executive-summary">
      <title>Significance</title>
      <p>In time and money, one of the most expensive steps of the drug discovery pipeline is the experimental screening of small molecules to determine binding to a protein target of interest. Therefore, accurate high-throughput computational prediction of drug-target interactions would unlock significant value, guiding and prioritizing promising candidates for experimental screening. We introduce ConPLex, a machine learning method for predicting drug-target binding which achieves state-of-the-art accuracy on many types of targets by using a pretrained protein language model. The approach co-locates the proteins and potential drug molecules in a shared feature space while learning to contrast true drugs from similar nonbinding “decoy” molecules. ConPLex is extremely fast, which allows it to rapidly shortlist candidates for deeper investigation.</p>
    </abstract>
    <abstract>
      <p>Sequence-based prediction of drug–target interactions has the potential to accelerate drug discovery by complementing experimental screens. Such computational prediction needs to be generalizable and scalable while remaining sensitive to subtle variations in the inputs. However, current computational techniques fail to simultaneously meet these goals, often sacrificing performance of one to achieve the others. We develop a deep learning model, ConPLex, successfully leveraging the advances in pretrained protein language models (“PLex”) and employing a protein-anchored contrastive coembedding (“Con”) to outperform state-of-the-art approaches. ConPLex achieves high accuracy, broad adaptivity to unseen data, and specificity against decoy compounds. It makes predictions of binding based on the distance between learned representations, enabling predictions at the scale of massive compound libraries and the human proteome. Experimental testing of 19 kinase-drug interaction predictions validated 12 interactions, including four with subnanomolar affinity, plus a strongly binding EPHB1 inhibitor (<italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> = 1.3 nM). Furthermore, ConPLex embeddings are interpretable, which enables us to visualize the drug–target embedding space and use embeddings to characterize the function of human cell-surface proteins. We anticipate that ConPLex will facilitate efficient drug discovery by making highly sensitive in silico drug screening feasible at the genome scale. ConPLex is available open source at <ext-link xlink:href="https://ConPLex.csail.mit.edu" ext-link-type="uri">https://ConPLex.csail.mit.edu</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>drug discovery</kwd>
      <kwd>protein language models</kwd>
      <kwd>contrastive learning</kwd>
      <kwd>drug–target interaction</kwd>
    </kwd-group>
    <funding-group specific-use="FundRef">
      <award-group award-type="grant">
        <funding-source id="sp1">
          <institution-wrap>
            <institution>HHS | National Institutes of Health (NIH)</institution>
            <institution-id institution-id-type="FundRef">100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id rid="sp1">R35GM141861</award-id>
        <principal-award-recipient>Rohit Singh</principal-award-recipient>
        <principal-award-recipient>Bonnie Berger</principal-award-recipient>
      </award-group>
      <award-group award-type="grant">
        <funding-source id="sp2">
          <institution-wrap>
            <institution>National Science Foundation (NSF)</institution>
            <institution-id institution-id-type="FundRef">100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id rid="sp2">CCF-19345533</award-id>
        <principal-award-recipient>Samuel Sledzieski</principal-award-recipient>
        <principal-award-recipient>Lenore J Cowen</principal-award-recipient>
      </award-group>
      <award-group award-type="grant">
        <funding-source id="sp3">
          <institution-wrap>
            <institution>National Science Foundation (NSF)</institution>
            <institution-id institution-id-type="FundRef">100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id rid="sp3">2141064</award-id>
        <principal-award-recipient>Samuel Sledzieski</principal-award-recipient>
        <principal-award-recipient>Lenore J Cowen</principal-award-recipient>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="11"/>
      <word-count count="8461"/>
    </counts>
  </article-meta>
</front>
<body>
  <p content-type="flushleft">In the drug discovery pipeline, a key rate-limiting step is the experimental screening of potential drug molecules against a protein target of interest. Thus, fast and accurate computational prediction of drug–target interactions (DTIs) could be extremely valuable, accelerating the drug discovery process. One important class of computational DTI methods, molecular docking, uses 3D structural representations of both the drug and target. While the recent availability of high-throughput accurate 3D protein structure prediction models (<xref rid="r1" ref-type="bibr">1</xref><xref rid="r2" ref-type="bibr"/>–<xref rid="r3" ref-type="bibr">3</xref>) means that these methods can be employed starting only from a protein’s amino acid sequence, the computational expense of docking (<xref rid="r4" ref-type="bibr">4</xref>) and other structure-based approaches [e.g., rational design (<xref rid="r5" ref-type="bibr">5</xref>), active site modeling (<xref rid="r6" ref-type="bibr">6</xref>), template modeling (<xref rid="r7" ref-type="bibr">7</xref>, <xref rid="r8" ref-type="bibr">8</xref>)] unfortunately remains prohibitive for large-scale DTI screening. An alternative class of DTI prediction methods use 3D structure only implicitly, making rapid DTI predictions when the inputs consist only of a molecular description of the drug [such as the SMILES string (<xref rid="r9" ref-type="bibr">9</xref>)] and the amino acid sequence of the protein target. This class of sequence-based DTI approaches enables scalable DTI prediction, but there have been barriers to matching the levels of accuracy obtained by structure-based approaches.</p>
  <p>In this paper, we introduce ConPLex, a rapid purely sequence-based DTI prediction method that leverages rich featurizations from pretrained protein language models (PLMs) and show that it can produce state-of-the-art performance on the DTI prediction task at scale. The advance provided by ConPLex comes from two main ideas that together overcome some of the limitations of previous approaches: informative PLM-based representations and contrastive learning. While many methods have been proposed for the sequence-based setting of the DTI problem (<xref rid="r10" ref-type="bibr">10</xref>) [e.g., using secure multiparty computation (<xref rid="r11" ref-type="bibr">11</xref>), convolutional neural networks (<xref rid="r12" ref-type="bibr">12</xref>), or transformers (<xref rid="r13" ref-type="bibr">13</xref>)], their protein and drug representations are constructed solely from DTI ground truth data. The high level of diversity among the DTI inputs, combined with the limited availability of DTI training data, limits the accuracy of these methods and their generalizability beyond their training domain. Furthermore, the methods that do generalize often do so by sacrificing fine-grained specificity, i.e., are unable to distinguish true-positive binding compounds from false positives with similar physicochemical properties (“decoys”).</p>
  <p>In contrast, the “PLex” (Pretrained Lexicographic) part of ConPLex helps alleviate the problem of limited DTI training data. As we showed in our preliminary work (<xref rid="r14" ref-type="bibr">14</xref>), one way to get around the limited size of DTI datasets that has hampered the quality of the representations learned by previous methods is to transfer learned proteins representations from pretrained PLMs to the DTI prediction task. PLMs learn the distributional characteristics of amino acid sequences over millions of proteins in an unsupervised fashion, generating sequence-based representations that encode deep structural insights. A design paradigm in machine learning is that an informative featurization of the input can enhance the power of even simple models. For DTI, where task-specific data are limited, using PLM-generated representations as the input features allows us to borrow strength from the much larger corpus of single protein sequences (<xref rid="r14" ref-type="bibr">14</xref>). Starting with the PLMs, our second insight directly addresses the fine-grained specificity problem in our architecture by using the “Con” (Contrastive learning) part: a protein-anchored contrastive coembedding that colocates the proteins and the drugs into a shared latent space. We show that this coembedding enforces separation between true interacting partners and decoys to achieve both broad generalization and high specificity (<xref rid="fig02" ref-type="fig">Fig. 2</xref>).</p>
  <p>Putting these two ideas together gives us ConPLex, a representation learning approach that enables both broad generalization and high specificity. We show that ConPLex enables more accurate prediction of DTIs than competing methods while avoiding many of the pitfalls suffered by currently available approaches. Thus, our work constitutes a concrete demonstration of the power of a well-designed transfer learning approach that adapts foundation models for a specific task (<xref rid="r15" ref-type="bibr">15</xref>, <xref rid="r16" ref-type="bibr">16</xref>). In particular, we found that the performance of existing sequence-based DTI prediction methods could be sensitive to variation in drug-vs-protein coverage in the dataset, whereas ConPLex performs well in multiple coverage regimes. Indeed, ConPLex performs especially well relative to other methods in the zero-shot prediction setting where no information is available about a given protein or drug at training time. Experimental validation of ConPLex yielded a 63% hit rate (12/19), including four hits with subnanomolar binding affinity, demonstrating the value of ConPLex as an accurate, highly scalable, in silico screening tool.</p>
  <p>ConPLex can also be adapted beyond the binary case to make predictions about binding affinity. Furthermore, the shared representation also offers advantages beyond prediction accuracy. The coembedding of both proteins and drugs in the same space offers intepretability, and we show that distances in this space meaningfully reflect protein domain structure and binding function: We leverage ConPLex representations to functionally characterize cell-surface proteins from the Surfaceome database (<xref rid="r17" ref-type="bibr">17</xref>), a set of 2,886 proteins localized to the external plasma membrane that participate in signaling and are likely able to be easily targeted by ligands.</p>
  <p>ConPLex is extremely fast: As a proof of concept, we make predictions for the human proteome against all drugs in ChEMBL (<xref rid="r18" ref-type="bibr">18</xref>) (≊2 ×10<sup>10</sup> pairs) in just under 24 h using a single NVIDIA A100 GPU. Thus, ConPLex has the potential to be applied for tasks which would require prohibitive amounts of computation for purely structure-based approaches or less efficient sequence-based methods, such as genome-scale side-effect screens, identifying drug repurposing candidates via massive compound libraries searches or in silico deep mutational scans to predict variant effects on binding with currently approved or potential new therapeutics. We note that most DTI methods require significant computation on each drug–target pair (i.e., have quadratic time complexity). Because ConPLex predictions rely only on the distance in the shared space, predictions can be made highly efficiently once embeddings (which have linear time complexity) are computed.</p>
  <sec id="s1">
    <title>Distinguishing between Low- and High-Coverage DTI Prediction.</title>
    <p content-type="flushleft">We benchmark performance of ConPLex and competing methods in two different regimes, which we term low-coverage and high-coverage DTI prediction (<xref rid="fig01" ref-type="fig">Fig. 1<italic toggle="yes">C</italic></xref>). We show that ConPLex outperforms its competitors in both settings, but note that separating the two regimes helps clarify an often-seen issue in the field: methods whose performance varies substantially across different proposed DTI benchmarks. Several prior attempts have been made to standardize DTI benchmarking and develop a consistent framework for model evaluation (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r20" ref-type="bibr">20</xref>). However, much of this work has overlooked a key aspect of benchmarking that we find to significantly affect model performance—differing per-biomolecule data coverage. We define coverage as the average proportion of drugs or targets for which a data point exists in that dataset, whether that is a positive or negative interaction (<italic toggle="yes">Methods</italic>). Depending on the per-biomolecule data coverage of the benchmark dataset, we claim that these benchmarks are looking at very different problems. In particular, low-coverage datasets (<xref rid="fig01" ref-type="fig">Fig. 1<italic toggle="yes">A</italic></xref>) tend to measure the broad strokes of the DTI landscape, containing a highly diverse set of drugs and targets. Such datasets can present a modeling challenge due to the diverse nature of targets covered but allow for a broad assessment of compatibility between classes of compounds and proteins. High-coverage datasets (<xref rid="fig01" ref-type="fig">Fig. 1<italic toggle="yes">B</italic></xref>) represent the opposite trade-off: They contain limited diversity in drug or target type but report a dense set of potential pairwise interactions. Thus, they capture the fine-grained details of a specific subclass of drug–target binding and enable distinguishing between similar biomolecules in a particular context.</p>
    <fig position="float" id="fig01" fig-type="featured">
      <label>Fig. 1.</label>
      <caption>
        <p>Drug-target interaction benchmarks display highly variable levels of coverage. Coverage is defined as the proportion of drugs or targets for which a data point (positive or negative) exists in that dataset. High- vs. low-coverage benchmarks tend to reward different types of model performance. (<italic toggle="yes">A</italic>) In this cartoon of an example low coverage dataset, drug candidates cover the full diversity of the space, and no two drugs are highly similar. A successful model can learn a coarse estimate of the fitness landscape, but must accurately model a large part of drug space to generalize to all candidates. (<italic toggle="yes">B</italic>) For high-coverage datasets, drugs tend to be targeted to a specific protein family. Thus, a successful model does not need to generalize nearly as widely but must be able to capture more minor variations in drug fitness to achieve high specificity and differentiate between similar drugs. (<italic toggle="yes">C</italic>) In a review of existing popular DTI benchmark datasets, we find widely varying coverage, from datasets with nearly zero coverage (each drug/target is represented only a few times) to nearly full coverage (all drug-by-target pairs are known in the data).</p>
      </caption>
      <graphic xlink:href="pnas.2220778120fig01" position="float"/>
    </fig>
    <fig position="float" id="fig02" fig-type="figure">
      <label>Fig. 2.</label>
      <caption>
        <p>Outline of the ConPLex model architecture and training framework. ConPLex is trained in two phases, to optimize both generalizability and specificity. (<italic toggle="yes">A</italic>) Protein features are generated using a pretrained PLM [here ProtBert (<xref rid="r27" ref-type="bibr">27</xref>)], and drug features are generated using the Morgan fingerprint (<xref rid="r26" ref-type="bibr">26</xref>). These features are transformed into a shared latent space by a learned nonlinear projection. The prediction of interaction is based on the cosine distance in this space, and the parameters of the transformation are updated using the binary cross-entropy on a low-coverage dataset. (<italic toggle="yes">B</italic>) In the contrastive phase, triplets of a target, drug, and decoy are transformed in the same way into the shared space. Here, the transformation is treated as a metric learning problem. Parameters are updated using the triplet distance loss on a high-coverage dataset (<xref rid="r36" ref-type="bibr">36</xref>) to minimize the target-drug distance while maximizing the target-decoy distance. No additional penalty is applied if the target-decoy distance is greater than the target-drug distance plus some margin. (<italic toggle="yes">C</italic>) ConPLex is trained in alternating epochs of the binary and contrastive phase to simultaneously optimize both objectives. After each round, learning rates and the contrastive margin are updated according to an annealing scheme.</p>
      </caption>
      <graphic xlink:href="pnas.2220778120fig02" position="float"/>
    </fig>
    <p>The two coverage regimes correspond to different usage cases. The low-coverage regime is relevant when applying DTI models for large-scale scans to predict interactions for a potential target against a large compound library [e.g., for drug repurposing as in Dönertaş et al. (<xref rid="r21" ref-type="bibr">21</xref>) and Morselli et al. (<xref rid="r22" ref-type="bibr">22</xref>)] or for scanning a candidate drug against an entire proteome to identify potential adverse and off-target effects [as in Huang et al. (<xref rid="r23" ref-type="bibr">23</xref>, <xref rid="r24" ref-type="bibr">24</xref>)]. Data at this scale are often low coverage, with only a small number of known interactions for each unique biomolecule. Thus, it is important that DTI models used for these tasks are broadly applicable and can accurately generalize to many different families of proteins and drugs. However, this generalization often comes at the cost of specificity, resulting in models that are unable to distinguish between highly similar drugs or proteins.</p>
    <p>The high-coverage regime is relevant when optimizing a particular interaction. Here, models can be trained to be highly specific to a protein family or class of drugs, so much so that a per-drug or per-target model is trained to capture the precise binding dynamics of that biomolecule (<xref rid="r25" ref-type="bibr">25</xref>). While such models can be effective for lead optimization, they require high coverage on the biomolecule of interest to make accurate predictions; this may not always be available. Additionally, such models lack the capacity to generalize beyond the training domain and thus cannot be used for genome- or drug bank-scale prediction.</p>
    <p>The PLM approach of ConPLex enables strong performance in both regimes. In the low coverage regime, the strength is coming mostly from the “PLex” part, where it can leverage the effective generalization of language models to achieve state-of-the-art performance. On high-coverage datasets, the “Con” part also becomes important, since it becomes feasible to train drug- or target-specific models with high accuracy, and such models often outperform more generic models. We find that while single-task models do perform well given available data, ConPLex is able to achieve extremely high specificity in low-diversity, high-coverage scenarios, while remaining broadly applicable to protein targets with limited data. Thus, ConPLex is applicable for both large-scale compound or target screens and fine-grained, highly specific binding prediction. We discuss the issue of matching the right model to the problem domain with respect to coverage further in the <italic toggle="yes">Discussion</italic>.</p>
  </sec>
  <sec sec-type="results" id="s2">
    <title>Results</title>
    <sec id="s3">
      <title>Model Overview.</title>
      <p>To achieve both generalizability and specificity, ConPLex leverages advances in both protein language modeling and metric learning. We start with pretrained representations and learn a nonlinear projection of these representations to a shared space (ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">h</italic></sub></sup>). We guide the learning by alternating between two objectives over multiple iterations: a coarse-grained objective of accurately classifying DTIs and a fine-grained objective of distinguishing decoys from drugs. The coarse-grained objective is evaluated over a low-coverage dataset, which trains the model to distinguish between broad classes of drug and target and makes initial predictions in the right “neighborhood” of the DTI space. The fine-grained objective is evaluated over a high-coverage dataset, which fine-tunes the model to distinguish between true and false positive interactions in the same “neighborhood” and achieve high specificity within a class.</p>
      <p>To featurize the inputs, here, we use the Morgan fingerprint (<xref rid="r26" ref-type="bibr">26</xref>) for small molecules and embeddings from a pretrained ProtBert model (<xref rid="r27" ref-type="bibr">27</xref>) for proteins. We investigate other choices for features, including several other foundation PLMs in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>. We note that our framework is flexible to different methods of featurization and make recommendations on the selection of informative representations in the <italic toggle="yes">Discussion</italic>.</p>
    </sec>
    <sec id="s4">
      <title>ConPLex Achieves State-of-the-Art Performance on Low- Coverage and Zero-Shot Interactions.</title>
      <p>A key advance of ConPLex is the use of pretrained PLMs for protein representation. As foreshadowed by Scaiewicz and Levitt (<xref rid="r28" ref-type="bibr">28</xref>), PLMs have repeatedly been shown to encode evolutionary and structural information (<xref rid="r29" ref-type="bibr">29</xref><xref rid="r30" ref-type="bibr"/>–<xref rid="r31" ref-type="bibr">31</xref>) and to enable broad generalization in low-coverage scenarios (<xref rid="r32" ref-type="bibr">32</xref>, <xref rid="r33" ref-type="bibr">33</xref>). Here, we show that ConPLex achieves state-of-the-art performance on three low-coverage benchmark datasets—<bold>BIOSNAP</bold>, <bold>BindingDB</bold>, and <bold>DAVIS</bold>—where it is important to learn the broad strokes of the DTI landscape. In <xref rid="t01" ref-type="table">Table 1</xref>, we show the average area under the precision–recall curve (AUPR) over five random initializations of each model evaluated on a held-out test set (<italic toggle="yes">Methods</italic>). Here, we compare with several methods which use non-PLM protein features: MolTrans (<xref rid="r13" ref-type="bibr">13</xref>), GNN-CPI (<xref rid="r34" ref-type="bibr">34</xref>), and DeepConv-DTI (<xref rid="r12" ref-type="bibr">12</xref>). In addition, we compare to the EnzPred-CPI model from Goldman et al. (<xref rid="r25" ref-type="bibr">25</xref>) (developed simultaneously and independently), which uses a PLM for protein featurization but does not perform a coembedding or utilize a contrastive training step. Finally, we compare with the single-task Ridge regression model described in ref. <xref rid="r25" ref-type="bibr">25</xref>, which trains a different model per drug rather than a single model for the entire benchmark.</p>
      <table-wrap position="float" id="t01">
        <label>Table 1.</label>
        <caption>
          <p>ConPLex is highly accurate and generalizes broadly in low coverage settings</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Dataset</th>
              <th align="center" rowspan="1" colspan="1">ConPLex</th>
              <th align="center" rowspan="1" colspan="1">EnzPred-CPI</th>
              <th align="center" rowspan="1" colspan="1">MolTrans</th>
              <th align="center" rowspan="1" colspan="1">GNN-CPI†</th>
              <th align="center" rowspan="1" colspan="1">DeepConv-DTI†</th>
              <th align="center" rowspan="1" colspan="1">Ridge</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">BIOSNAP</td>
              <td align="center" rowspan="1" colspan="1">0.897 ± 0.001</td>
              <td align="center" rowspan="1" colspan="1">0.866 ± 0.003</td>
              <td align="center" rowspan="1" colspan="1">0.885 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">0.890 ± 0.004</td>
              <td align="center" rowspan="1" colspan="1">0.889 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">0.641 ± 0.000</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BindingDB</td>
              <td align="center" rowspan="1" colspan="1">0.628 ± 0.012</td>
              <td align="center" rowspan="1" colspan="1">0.602 ± 0.006</td>
              <td align="center" rowspan="1" colspan="1">0.598 ± 0.013</td>
              <td align="center" rowspan="1" colspan="1">0.578 ± 0.015</td>
              <td align="center" rowspan="1" colspan="1">0.611 ± 0.015</td>
              <td align="center" rowspan="1" colspan="1">0.516 ± 0.000</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DAVIS</td>
              <td align="center" rowspan="1" colspan="1">0.458 ± 0.016</td>
              <td align="center" rowspan="1" colspan="1">0.277 ± 0.009</td>
              <td align="center" rowspan="1" colspan="1">0.335 ± 0.017</td>
              <td align="center" rowspan="1" colspan="1">0.269 ± 0.020</td>
              <td align="center" rowspan="1" colspan="1">0.299 ± 0.039</td>
              <td align="center" rowspan="1" colspan="1">0.320 ± 0.000</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Unseen Drugs</td>
              <td align="center" rowspan="1" colspan="1">0.874 ± 0.002</td>
              <td align="center" rowspan="1" colspan="1">0.844 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">0.863 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.847 ± 0.009</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Unseen Targets</td>
              <td align="center" rowspan="1" colspan="1">0.842 ± 0.006</td>
              <td align="center" rowspan="1" colspan="1">0.795 ± 0.004</td>
              <td align="center" rowspan="1" colspan="1">0.668 ± 0.045</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.766 ± 0.022</td>
              <td align="center" rowspan="1" colspan="1">0.617 ± 0.000</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>ConPLex outperforms several state-of-the-art methods, including EnzPred-CPI (<xref rid="r25" ref-type="bibr">25</xref>), MolTrans (<xref rid="r13" ref-type="bibr">13</xref>), GNN-CPI (<xref rid="r34" ref-type="bibr">34</xref>), and DeepConv-DTI (<xref rid="r12" ref-type="bibr">12</xref>), as well as a simple single-target Ridge regression model, on several low- and zero- coverage benchmark datasets. We report the average and SD of the area under the precision–recall curve (AUPR) for 5 random initializations of each model. Metrics for models with † are taken from ref. <xref rid="r13" ref-type="bibr">13</xref>. Ridge regression cannot be applied for the <bold>Unseen Drugs</bold> dataset since a separate model is trained for each drug in the training set.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Observing the strength of ConPLex to generalize on low-coverage data, we sought to evaluate its performance on fully zero-shot prediction. <bold>Unseen drugs</bold> and <bold>Unseen targets</bold> are variants of the BIOSNAP dataset where drugs/targets in the test set do not appear in any interactions in the training set (<italic toggle="yes">Methods</italic>). Note that for the unseen drugs setting, the Ridge model cannot be applied since a different model must be trained for each drug that appears in the training set. We show that ConPLex achieves the best zero-shot prediction performance (<xref rid="t01" ref-type="table">Table 1</xref>), further demonstrating the applicability of the model to large-scale, very low-coverage prediction tasks.</p>
    </sec>
    <sec id="s5">
      <title>Contrastive Learning Enables High-Specificity DTI Mapping.</title>
      <p>Another key advance of our method is the use of contrastive learning to fine-tune model predictions on high-coverage data to achieve high specificity. Recently, Heinzinger et al. (<xref rid="r35" ref-type="bibr">35</xref>) demonstrated the use of semisupervised contrastive learning for effective protein embedding-based annotation transfer. Here, we adapt contrastive learning to a fully supervised setting and demonstrate that the contrastive training is essential to achieving specificity using DTI pairs from the Database of Useful Decoys (<bold>DUD-E</bold>) (<xref rid="r36" ref-type="bibr">36</xref>). The DUD-E dataset contains 57 protein targets and drugs which are known to interact with each target. However, it also contains 50 negative “decoy” small molecules for each drug, which have similar physicochemical properties to the truly interacting small molecule but are known to not bind the target. Thus, accurate prediction on DUD-E requires a model to achieve high specificity and to accurately differentiate between highly similar compounds. Additionally, DUD-E contains four different classes of targets—G-protein-coupled receptors (GPCRs), kinases, proteases, and nucleases—so models must generalize across target classes (note that single task models do not have this generalization requirement since a different model is trained per target).</p>
      <p>We derive evaluation sets from DUD-E by holding out 50% of proteins in each target class for testing and using the remaining targets for training (full splits are specified in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S1</ext-link>). Here, we evaluate a ConPLex model trained on BIOSNAP, both with and without contrastive training on DUD-E, and show that contrastive training is essential to achieving specificity on decoys.</p>
      <p>For each target in the DUD-E test set, we use t-SNE to visualize the target alongside all drugs and decoys using embeddings learned by both versions of the model. <xref rid="fig03" ref-type="fig">Fig. 3 <italic toggle="yes">A</italic> and <italic toggle="yes">B</italic></xref> shows one such example, the tyrosine kinase <italic toggle="yes">VGFR2</italic>. We also show the distribution of distances in the latent space between the target embedding and the embeddings of the drugs and decoys for each model (<xref rid="fig03" ref-type="fig">Fig. 3 <italic toggle="yes">C</italic> and <italic toggle="yes">D</italic></xref>) (<italic toggle="yes">P</italic>-values from the one-sided <italic toggle="yes">t</italic> test). Without contrastive training, drugs are interspersed with decoys and are far away in space from the target, while ConPLex clusters most true drugs very close to both each other and the <italic toggle="yes">VGFR2</italic> embedding.</p>
      <fig position="float" id="fig03" fig-type="figure">
        <label>Fig. 3.</label>
        <caption>
          <p>Contrastive training enables high specificity in discriminating drugs from decoys. We demonstrate that contrastive learning is essential for ConPLex to achieve high specificity using the DUD-E (<xref rid="r36" ref-type="bibr">36</xref>) dataset of drugs and decoys (nonbinding small molecules with similar physicochemical properties to the true drugs). (<italic toggle="yes">A</italic> and <italic toggle="yes">B</italic>) Using t-SNE, we show the learned ConPLex latent space for <italic toggle="yes">VGFR2</italic> (green) and known drugs (blue) and decoys (gray). Without contrastive training, drug and decoy representations do not separate, and true drugs are far from their target. With contrastive training, VGFR2 and drugs cluster very tightly compared to decoys. (<italic toggle="yes">C</italic> and <italic toggle="yes">D</italic>) ConPLex predictions significantly differentiate between drugs and decoys after contrastive training (<italic toggle="yes">P</italic> = 0.000 paired <italic toggle="yes">t</italic> test) but do not differ at all without such training (<italic toggle="yes">P</italic> = 0.999). (<italic toggle="yes">E</italic>) We compute the effect size between drug and decoy predictions using Cohen’s <italic toggle="yes">d</italic> for all 31 targets in the test set. Targets are classified as proteases (green), GPCRs (orange), kinases (blue), and nuclear proteins (red). This effect is computed for ConPLex both with and without contrastive training. Contrastive training increases the effect size for every target (median 0.730 vs. 4.716). For each class, we report the median <italic toggle="yes">P</italic>-value for ConPLex drug vs. decoy predictions. ConPLex performs particularly well for kinases and nuclear proteins and more poorly for GPCRs.</p>
        </caption>
        <graphic xlink:href="pnas.2220778120fig03" position="float"/>
      </fig>
      <p>In <xref rid="fig03" ref-type="fig">Fig. 3<italic toggle="yes">E</italic></xref>, we show a quantitative analysis of all 31 test-set targets. We compute the effect size (Cohen’s <italic toggle="yes">d</italic>) of the difference between predicted drug and decoy scores. We plot these effect sizes for ConPLex trained with and without contrastive training. An increase in the effect size indicates that the coembedding distances learned by the model better represent binding specificity. The effect size increases for every target, and the median effect size between predicted true and decoy compound scores was 0.730 prior to contrastive training compared to 4.716 after. For each class of targets, we also report the median <italic toggle="yes">P</italic>-value (one-sided <italic toggle="yes">t</italic> test) between drug and decoy scores predicted by ConPLex. While contrastive training has an extremely large impact on specificity in high-coverage domains, we also show that this additional training does not significantly decrease the model performance on low-coverage benchmarks via an ablation study in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S3</ext-link>.</p>
      <p>In addition to evaluation on DUD-E, we also evaluate ConPLex on five benchmark datasets derived from family-specific enzyme–substrate screens (<italic toggle="yes">Methods</italic>). These datasets are extremely high coverage, generally including data points for all possible pairs of drugs and targets. We find that in this regime, ConPLex and other PLM-based models like EnzPred-CPI have strong but highly variable performance and are still generally outperformed by a Ridge regression model (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S5</ext-link>) as shown previously in ref. <xref rid="r25" ref-type="bibr">25</xref>. However, a fine-scale single-task model is limited in its generalizability beyond the enzyme family on which it was trained (<italic toggle="yes">Discussion</italic>).</p>
    </sec>
    <sec id="s6">
      <title>ConPLex Discovers DTIs with Subnanomolar Binding Affinity.</title>
      <p>Since ConPLex exhibited strong performance on several benchmark datasets, we next sought to experimentally validate predictions using an in vitro biochemical binding assay. We selected 51 kinases from the Surfaceome database (<xref rid="r17" ref-type="bibr">17</xref>) with commercially available assays from the DiscoveryX company and used ConPLex to scan against a set of 4715 compounds from the ZINC database (<xref rid="r37" ref-type="bibr">37</xref>) purchasable from the Cayman Chemical Company (<italic toggle="yes">Methods</italic>) (<xref rid="r38" ref-type="bibr">38</xref>). We selected 19 interactions spanning 5 kinases and 14 compounds in an unbiased manner. (These pairs were chosen based solely on top scoring ConPLex predictions, without any use of prior knowledge from experimental results or in the literature.) We determined <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values for each of the 19 interactions (<xref rid="t02" ref-type="table">Table 2</xref>), finding that 12/19 pairs tested had <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values less than 100 nM. Of these, four bound with subnanomolar affinity, all of which recapitulate known interactions in the literature. Weglicki et al. identified AG-1478 as an <italic toggle="yes">EGFR</italic> inhibitor but noted that its therapeutic use may be limited due to triggering hypomagnesemia and cardiac dysfunction (<xref rid="r39" ref-type="bibr">39</xref>). Sordella et al. (<xref rid="r40" ref-type="bibr">40</xref>) described the downstream impact in lung cancer when Gefitinib inhibits <italic toggle="yes">EGFR</italic>. In a review of Nintedanib discovery, Roth et al. (<xref rid="r41" ref-type="bibr">41</xref>) noted it as an <italic toggle="yes">FLT3</italic> inhibitor, and Wang et al. (<xref rid="r42" ref-type="bibr">42</xref>) described Linifanib inhibition of <italic toggle="yes">FLT3</italic>.</p>
      <table-wrap position="float" id="t02">
        <label>Table 2.</label>
        <caption>
          <p>We selected and tested 19 potential binding interactions, where the selection of tests was done based solely on ConPLex-predicted interaction and without consulting previous experiments or literature</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">EGFR</th>
              <th align="center" rowspan="1" colspan="1">EPHB1</th>
              <th align="center" rowspan="1" colspan="1">FLT3</th>
              <th align="center" rowspan="1" colspan="1">KIT</th>
              <th align="center" rowspan="1" colspan="1">TGFBR2</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">AG-1478</td>
              <td align="center" rowspan="1" colspan="1">0.33<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Gefitinib</td>
              <td align="center" rowspan="1" colspan="1">0.60<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Janex 1</td>
              <td align="center" rowspan="1" colspan="1">26.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SB-431542</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AG-1296</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">62.00</td>
              <td align="center" rowspan="1" colspan="1">27.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ZM 447439</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">PD-166326</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>1.30</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Nintedanib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.17<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Linifanib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.72<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">1.70</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Sorafenib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">7.20</td>
              <td align="center" rowspan="1" colspan="1">36.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Imatinib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">6.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Wortmannin</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Pluripotin</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Monorden</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>We determined the <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values for each interaction via an in vitro biochemical assay (<italic toggle="yes">Methods</italic>), and we show here the <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> in nM units. Twelve exhibited binding affinity in the nanomolar range, including four (denoted with <bold>*</bold>) binding with subnanomolar affinity. The only target for which we incorrectly predicted there would be hits was <italic toggle="yes">TGFBR2</italic>, which has no known inhibitors in PKIDB (<xref rid="r47" ref-type="bibr">47</xref>), suggesting that it may be difficult to target. We recapitulate several known interactions (<italic toggle="yes">Results</italic>) and find a tightly binding interaction between <italic toggle="yes">EPHB1</italic> and <italic toggle="yes">PD 166326</italic> (<bold>bold</bold>), which to our knowledge has not been previously characterized.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We also identify an interaction between <italic toggle="yes">EPHB1</italic> and PD-166326 with nearly subnanomolar affinity (<italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> = 1.30). Wolff et al. (<xref rid="r43" ref-type="bibr">43</xref>) previously identified PD-166326 as a tyrosine-kinase inhibitor but did not report any binding to <italic toggle="yes">EPHB1</italic>, and DrugBank (<xref rid="r44" ref-type="bibr">44</xref>) lists only <italic toggle="yes">ABL1</italic> as a known target (DrugBank ID: DB08339). <italic toggle="yes">EPHB1</italic> has been implicated in chronic pain (<xref rid="r45" ref-type="bibr">45</xref>, <xref rid="r46" ref-type="bibr">46</xref>); at the time of publication, there are no known inhibitors of <italic toggle="yes">EPHB1</italic> listed in the Protein Kinase Inhibitor Database (PKIDB) (<xref rid="r47" ref-type="bibr">47</xref>), and our findings indicate that PD-166326 may act as a binder to <italic toggle="yes">EPHB1</italic>. Future work could involve further characterization of this interaction, its impact on <italic toggle="yes">EPHB1</italic> function, and possible therapeutic outcomes. In <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">B</italic></xref>, we show that PD-166326 is the only compound from our screen close to <italic toggle="yes">EPHB1</italic> in coembedding space.</p>
      <fig position="float" id="fig04" fig-type="figure">
        <label>Fig. 4.</label>
        <caption>
          <p>The shared representation space learned by ConPLex captures DTI and protein function. (<italic toggle="yes">A</italic>) We show that 51 kinases from the Surfaceome (<xref rid="r17" ref-type="bibr">17</xref>) database cluster together in ConPLex embedding space but occupy just a small section of the entire space when coembedded with the compounds from the ZINC (<xref rid="r37" ref-type="bibr">37</xref>) Cayman-purchasable library. (<italic toggle="yes">B</italic> and <italic toggle="yes">C</italic>) Zooming in on the full embedding space highlights drug–target pairs chose for experimental validation. <italic toggle="yes">EPHB1</italic> has only a single compound nearby in embedding space, PD-166326, which was confirmed to bind with single-digit nanomolar affinity. <italic toggle="yes">FLT3</italic> and <italic toggle="yes">KIT</italic> are neighbors in embedding space and tightly bind many of the same compounds; both bind to Linifanib with &lt; 2<italic toggle="yes">n</italic><italic toggle="yes">M</italic> affinity. <italic toggle="yes">EGFR</italic> was not found to bind to any of the compounds also tested with <italic toggle="yes">FLT3</italic> and <italic toggle="yes">KIT</italic> but binds three other drugs nearby in the embedding space, two of which bind with subnanomolar affinity. On the other hand, none of the three compounds we tested nearby <italic toggle="yes">TGFBR2</italic> (Wortmannin, Pluripotin, and Monorden) were found to bind. (<italic toggle="yes">D</italic>) ConPLex representations of all cell surface proteins from the Surfaceome (<xref rid="r17" ref-type="bibr">17</xref>) cluster by functional class as assigned in Almén et al. (<xref rid="r49" ref-type="bibr">49</xref>). (<italic toggle="yes">E</italic>) These representations also cluster by several functional Pfam domains (<xref rid="r50" ref-type="bibr">50</xref>), such as the PKinase domain (PF00069) shown in blue. (<italic toggle="yes">F</italic>) We evaluated the coherence of representations for each domain by training a logistic regression classifier and report the model’s average confidence for proteins containing that domain as <inline-formula><mml:math id="i2" display="inline" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. ConPLex separates all 126 domains better than the untransformed ProtBert embeddings (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S6</ext-link>, <italic toggle="yes">P</italic> = 4.85 × 10<sup>−54</sup>, paired <italic toggle="yes">t</italic> test), discriminating kinase domains (blue) especially well. We have also highlighted other classes of domains, including cadherins (green), 7-transmembrane proteins (orange), and immunoglobulins (red).</p>
        </caption>
        <graphic xlink:href="pnas.2220778120fig04" position="float"/>
      </fig>
      <p>Notably, all three of the compounds that we predicted to interact with <italic toggle="yes">TGFBR2</italic> were false positives (Wortmannin, Pluripotin, and Monorden). Despite its significance in cancer signaling (<xref rid="r48" ref-type="bibr">48</xref>), there are no known inhibitors of <italic toggle="yes">TGFBR2</italic> in PKIDB, suggesting that it may be difficult to target via small-molecule drugs.</p>
      <p>Additionally, we found that ConPLex predictions were well calibrated. Using varying thresholds, we can compute a precision–recall curve (over 19 data points, AUPR = 0.91). For high-precision screening, we recommend using a ConPLex-predicted threshold of 0.923 (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S7</ext-link>).</p>
    </sec>
    <sec id="s7">
      <title>Incorporating Drug Binding Information Improves Protein Representations.</title>
      <p>One of the advantages of the coembedding approach that our model takes is the ability to visualize and investigate the shared embedding space. For instance, we show in <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">A</italic></xref>–<italic toggle="yes">C</italic> that kinases and their inhibitors tend to colocalize within the space. Seeking to expand our analysis, we subsequently mapped all 2,716 predicted surface proteins from the Surfaceome database into ConPLex embedding space and investigated their representations. In <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">D</italic></xref>, we show the projections all Surfaceome proteins, colored by their classification into one of five functional categories [from Almén et al. (<xref rid="r49" ref-type="bibr">49</xref>)]—transporters, receptors, enzymes, miscellaneous, and those that are unclassified. ConPLex projections of surface proteins cluster in embedding space by functional type, with transporters and receptors especially separating from other classes.</p>
      <p>However, the Almén functional classification is quite broad and may group proteins with vastly different functions and binding properties. We further demonstrate the link between ConPLex projections and protein function, by evaluating how the learned DTI embedding space separates proteins by domains contained therein. We identified Pfam domains (<xref rid="r50" ref-type="bibr">50</xref>) for each protein in the Surfaceome database using HMMscan (<xref rid="r51" ref-type="bibr">51</xref>) and compared the projections of proteins that share the same domains. We identified 780 unique domains across all proteins, of which 126 domains were represented in at least 10 proteins. To quantitatively evaluate the coherence of ConPLex embeddings, we trained separate logistic regression classifiers for each domain to separate proteins with that domain from others and used the model’s confidence (<inline-formula><mml:math id="i1" display="inline" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>) for in-sample proteins as a measure of separation for the domain. We find that for all 126 domains, the model more confidently discriminated domains when trained on ConPLex representations than the baseline ProtBert embeddings.</p>
      <p><xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">F</italic></xref> shows the change in confidence scores for all 126 domains, where the dotted line represents equal confidence using either ConPLex or ProtBert. We find that prediction of all domains was improved using ConPlex. However, proteins with kinase domains (PF14575, PF01404, PF00069, and PF07714) separated especially well, whereas 7-transmembrane (7TM) domains characteristic of GPCRs (PF00001, PF00002, PF00003, and PF13853) showed more modest improvement (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S6</ext-link>). In <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">E</italic></xref>, we show the same visualization of projections as in <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">D</italic></xref> but colored by another top-differentiated domain, PKinase (PF00069). As discussed previously, ConPLex was trained contrastively with several kinase targets and excels at kinase prediction on DUD-E (<xref rid="fig03" ref-type="fig">Fig. 3<italic toggle="yes">E</italic></xref>), so it is unsurprising that proteins with these domains separate well. In fact, one of the top differentiated domains is the Ephrin ligand binding domain (PF01404), which is responsible for binding to the ephrin ligand (<xref rid="r52" ref-type="bibr">52</xref>). While the model was also trained contrastively with 7TM GPCR targets, many fewer training data samples were available. In addition to the dearth of training examples, GPCRs are less soluble than kinases and tend to exhibit more dynamic behavior—all of which contribute to difficulty predicting ligand binding. Future work in this area might adjust distances in this landscape to account for the low metric entropy of biological sequences, as demonstrated by Berger et al. (<xref rid="r53" ref-type="bibr">53</xref>).</p>
    </sec>
    <sec id="s8">
      <title>Adapting ConPLex for Affinity Prediction.</title>
      <p>While we have to this point been using the model to predict probabilities of interaction and perform binary classification, we show that ConPLex can be easily adapted to perform binding affinity prediction and that this model too achieves state-of-the-art performance. The final step of our binary interaction predictor is converting the cosine distance between the projections in the DTI space to a probability using a sigmoid activation (<italic toggle="yes">Methods</italic>). However, it is completely natural to replace this activation with a dot product between the two projections, which enables the model to make real-valued predictions, which can then be interpreted as a binding affinity. We evaluated ConPLex trained for affinity prediction on the Therapeautics Data Commons (TDC) DTI Domain Generalization (<bold>TDC-DG</bold>) benchmark. The TDC-DG benchmark contains binding affinity (<italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>) data from interactions patented between 2013 and 2018, with the test set drawn from interactions patented in 2019 and 2021 (<italic toggle="yes">Methods</italic>). Thus, these data require out-of-domain generalization and correspond to the real-life scenario of training on interactions up to a known point and predicting interactions which are yet to be documented. We trained ConPLex to predict binding affinity with five random train/validation splits and achieve an average Pearson correlation (PCC) coefficient between the true and predicted affinity of 0.538(±0.008) on the held-out test set. At submission, ConPLex is the top-performing method on the TDC-DG benchmark on TDC (<xref rid="t03" ref-type="table">Table 3</xref>).</p>
      <table-wrap position="float" id="t03">
        <label>Table 3.</label>
        <caption>
          <p>ConPLex can be adapted for state-of-the-art affinity prediction</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Model</th>
              <th align="center" rowspan="1" colspan="1">PCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">ConPLex</td>
              <td align="center" rowspan="1" colspan="1">0.538 ± 0.008</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">MMD</td>
              <td align="center" rowspan="1" colspan="1">0.433 ± 0.010</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">CORAL</td>
              <td align="center" rowspan="1" colspan="1">0.432 ± 0.010</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ERM</td>
              <td align="center" rowspan="1" colspan="1">0.427 ± 0.012</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">MTL</td>
              <td align="center" rowspan="1" colspan="1">0.425 ± 0.010</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GroupDRO</td>
              <td align="center" rowspan="1" colspan="1">0.384 ± 0.006</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AndMASK</td>
              <td align="center" rowspan="1" colspan="1">0.288 ± 0.019</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">IRM</td>
              <td align="center" rowspan="1" colspan="1">0.284 ± 0.021</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>By replacing the cosine distance in the final step of ConPLex with a dot product between the projections, ConPLex can be used for affinity prediction rather than binary classification. The TDC-DG dataset contains <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub> values for patented drug–target pairs, where training/testing data are split from before/after 2018. We report the average and SD of the PCC coefficient between true and predicted values across five train/validation splits. Metrics for all methods other than ConPLex come from the TDC leaderboard (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r58" ref-type="bibr">58</xref>), where at the time of submission, ConPLex is the best-performing method.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To investigate the strengths and limitations of ConPLex for affinity prediction, we evaluated performance by target type. Targets were annotated with Pfam domains (<xref rid="r50" ref-type="bibr">50</xref>) using HMMscan (<xref rid="r51" ref-type="bibr">51</xref>), and the PCC between predicted and true <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub> was computed over targets in each family (full details <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S8</ext-link>). We observed especially strong performance on 12 immunoglobulin targets (Pfam domains PF13927, PF13895, PF07679, PF00047), where we observed a PCC of 0.803. In keeping with our previous finding of ConPLex’s relative strength on kinases over GPCRs (<xref rid="fig03" ref-type="fig">Fig. 3<italic toggle="yes">E</italic></xref>), we observed a correlation of 0.578 on 94 protein targets with PKinase domains (PF07714, PF00069), including targets with SH3 domains (PF00018, PF07653; 13 targets; PCC = 0.705) and PI3K domains (PF00613, PF00792; 6 targets; PCC = 0.633). However, we observed substantially weaker performance on 7TM domains (PF00001; 14 targets; PCC = 0.254) and GPCR domains (PF10320; 8 targets; PCC = 0.176). To assess ConPLex’s variability in its accuracy, we computed a 95% prediction interval based on a linear regression between the true and predicted <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub> (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S8</ext-link>). While the correlations were strong, we found substantial variability around the true <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>, with the width of the prediction interval around the true <italic toggle="yes">l</italic><italic toggle="yes">n</italic>(<italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>) being ±4.89 <italic toggle="yes">l</italic><italic toggle="yes">n</italic>(<italic toggle="yes">n</italic><italic toggle="yes">M</italic>). Altogether, the variability in ConPLex’s performance across domains makes it important to understand the target of interest when using ConPLex to predict binding affinity.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s9">
    <title>Discussion</title>
    <p content-type="flushleft">Much previous work has recognized the value of meaningful drug representations (<xref rid="r54" ref-type="bibr">54</xref>, <xref rid="r55" ref-type="bibr">55</xref>) for DTI prediction, yet relatively little work has focused on the target protein representation. As a method to use pretrained PLMs for DTI prediction, ConPLex is yet another example of the power of transferring learned representations for biology (<xref rid="r13" ref-type="bibr">13</xref>, <xref rid="r31" ref-type="bibr">31</xref>, <xref rid="r32" ref-type="bibr">32</xref>, <xref rid="r56" ref-type="bibr">56</xref>, <xref rid="r57" ref-type="bibr">57</xref>). This approach enables broad generalization to unseen proteins as well as extremely fast model inference (&gt; 10× speed-up even over other sequence-based approaches <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S4</ext-link>). This speed is particularly valuable for drug repurposing and iterative screening, where large compound libraries are evaluated against hitherto-uncharacterized proteins implicated in a disease of interest. The coembedding approach which enables this speedup could also be effective for integrative multistructure models [e.g., the IMP framework (<xref rid="r59" ref-type="bibr">59</xref>)] where efficient scanning of possible combinations is important. Recent methods have also demonstrated the power of PLMs for transferring knowledge between species (<xref rid="r32" ref-type="bibr">32</xref>), and our framework may enable more accurate transfer of DTI from the model organisms on which drugs are initially tested, to their eventual use in human patients. Skolnick and Zhou (<xref rid="r60" ref-type="bibr">60</xref>) have reported the importance of considering small molecule binding pockets for protein–protein interaction prediction; thus, our DTI-informed protein representations may also be useful in that context. While structural similarity is often implicitly learned by PLMs, future work could explicitly incorporate structure where such data are available, perhaps by incorporating a more advanced projection architecture like the Geoformer (<xref rid="r3" ref-type="bibr">3</xref>).</p>
    <p>It has been shown in previous work that the performance of different PLMs varies on different tasks and that there is not one clearly “best” language model (<xref rid="r14" ref-type="bibr">14</xref>, <xref rid="r61" ref-type="bibr">61</xref>, <xref rid="r62" ref-type="bibr">62</xref>). While we have chosen to use ProtBert here, it is likely that other existing or newly developed language models may yield better performance for certain types of drugs or targets. Likewise, advancements in drug representation may improve performance—the ConPLex framework is flexible to different input features, and it remains important to experiment with different feature choices for the task at hand (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>).</p>
    <p>ConPLex approaches the DTI decoy problem from the perspective of adversarial machine learning, where the model must act as a discriminator for adversarial examples from the decoy database. This approach is directly enabled by the coembedding architecture—to compute the triplet distance loss, the protein and drugs must be coembedded, and the distance between them must be meaningful and simply computed. Such an approach would not be feasible using a model which concatenates features up front, nor for a model which has significant computation defining the probability of interaction after the coembedding. Thus, the shared lexicographic space in which we embed the proteins, targets, and decoys is key. Future work could explore adapting molecular generation methods such as JT-VAE or HierG2G (<xref rid="r63" ref-type="bibr">63</xref>, <xref rid="r64" ref-type="bibr">64</xref>) to directly act as a generator for decoys. High-specificity DTI prediction is valuable beyond decoy detection—greater specificity of inference can help improve personalized medicine or the modeling of drug effects against rare variants from underrepresented populations.</p>
    <p>It is also important to consider the coverage of the problem to select an appropriate method. While we recommend the use of PLM-based features in all cases, if enough data are available, for specific enzyme-family prediction tasks, we still recommend the use of single-task models (<xref rid="r25" ref-type="bibr">25</xref>). To verify individual interactions, energy-based molecular docking will likely be more accurate, although at the cost of being substantially slower (<xref rid="r4" ref-type="bibr">4</xref>). Different classes of computational tools for DTI prediction each have varying strengths, and the highest quality predictions can be achieved by leveraging all of these methods together where each is most fit.</p>
    <p>Drug discovery is a fundamental task for human health yet remains both extremely expensive and time consuming, with the median drug requiring over 1 billion dollars (<xref rid="r65" ref-type="bibr">65</xref>) and 10 y (<xref rid="r66" ref-type="bibr">66</xref>) from development to approval and distribution. While experimental results will remain the gold standard for validating drug functionality, in silico prediction of drug–target binding remains much faster and cheaper and so will continue to play an important role in early screening of therapeutic candidates (<xref rid="r67" ref-type="bibr">67</xref>). To address this step in the drug design pipeline, we have introduced ConPLex. DTI prediction methods should be able to generalize to unseen types of drugs and targets, while also discriminating between highly similar molecules with different binding properties. ConPLex tackles both of these challenges through its dual use of PLMs and contrastive learning. We hope that its broad applicability, specificity on decoys, and ability to scale to massive data will allow ConPLex to be a critical step in this pipeline and contribute to the efficient discovery of effective therapeutics.</p>
  </sec>
  <sec sec-type="materials|methods" id="s10">
    <title>Materials and Methods</title>
    <sec id="s11">
      <title>Computing Dataset Coverage.</title>
      <p>Let 1<sub>(<italic toggle="yes">i</italic>, <italic toggle="yes">j</italic>)</sub> be the indicator variable, meaning there exists an observation of drug <italic toggle="yes">i</italic> and target <italic toggle="yes">j</italic>. For a dataset with <italic toggle="yes">m</italic> unique drugs and <italic toggle="yes">n</italic> unique targets, we can define the coverage for drug <italic toggle="yes">d</italic> as <inline-formula><mml:math id="i3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mspace width="3.33333pt"/><mml:mo>=</mml:mo><mml:mspace width="3.33333pt"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and for a target <italic toggle="yes">t</italic> as <inline-formula><mml:math id="i4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Then, for a given dataset, we can evaluate the median drug and target coverage. A dataset with maximum coverage would have a single data point for each drug–target pair and, thus, a median coverage of 1 for both drugs and targets. Conversely, each drug and target would be represented only a single time in a minimum coverage dataset, resulting in drug and target coverages of <inline-formula><mml:math id="i5" display="inline" overflow="scroll"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="i6" display="inline" overflow="scroll"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:math></inline-formula>, respectively. We report the median drug and target coverage for each benchmark dataset in <xref rid="t04" ref-type="table">Table 4</xref>. Since the DUD-E dataset is separated out by targets, we instead report the median number of drugs against each target.</p>
      <table-wrap position="float" id="t04">
        <label>Table 4.</label>
        <caption>
          <p>Full specification of benchmark datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Dataset</th>
              <th align="center" rowspan="1" colspan="1">Drugs</th>
              <th align="center" rowspan="1" colspan="1">Targets</th>
              <th align="center" rowspan="1" colspan="1">Median Coverage</th>
              <th align="center" rowspan="1" colspan="1"># Training</th>
              <th align="center" rowspan="1" colspan="1"># Validation</th>
              <th align="center" rowspan="1" colspan="1"># Test</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">BIOSNAP</td>
              <td align="center" rowspan="1" colspan="1">4,510</td>
              <td align="center" rowspan="1" colspan="1">2,181</td>
              <td align="center" rowspan="1" colspan="1">0.0023/0.0020</td>
              <td align="center" rowspan="1" colspan="1">9,670/9,568</td>
              <td align="center" rowspan="1" colspan="1">1,396/1,352</td>
              <td align="center" rowspan="1" colspan="1">2,770/2,727</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Unseen Drugs</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">9,535/9,616</td>
              <td align="center" rowspan="1" colspan="1">1,383/1,353</td>
              <td align="center" rowspan="1" colspan="1">2,918/2,675</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Unseen Targets</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">9,876/9,499</td>
              <td align="center" rowspan="1" colspan="1">1,382/1,386</td>
              <td align="center" rowspan="1" colspan="1">2,578/2,762</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BindingDB</td>
              <td align="center" rowspan="1" colspan="1">7,165</td>
              <td align="center" rowspan="1" colspan="1">1,254</td>
              <td align="center" rowspan="1" colspan="1">0.0008/0.0010</td>
              <td align="center" rowspan="1" colspan="1">6,334/6,334</td>
              <td align="center" rowspan="1" colspan="1">927/5,717</td>
              <td align="center" rowspan="1" colspan="1">1,905/11,384</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DAVIS</td>
              <td align="center" rowspan="1" colspan="1">68</td>
              <td align="center" rowspan="1" colspan="1">379</td>
              <td align="center" rowspan="1" colspan="1">0.3707/0.3676</td>
              <td align="center" rowspan="1" colspan="1">1,043/1,043</td>
              <td align="center" rowspan="1" colspan="1">160/2,846</td>
              <td align="center" rowspan="1" colspan="1">303/5,708</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">TDC-DG</td>
              <td align="center" rowspan="1" colspan="1">140,746</td>
              <td align="center" rowspan="1" colspan="1">477</td>
              <td align="center" rowspan="1" colspan="1">0.0021/0.0005</td>
              <td align="center" rowspan="1" colspan="1">146,891</td>
              <td align="center" rowspan="1" colspan="1">36,539</td>
              <td align="center" rowspan="1" colspan="1">49,028</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Phosphatase</td>
              <td align="center" rowspan="1" colspan="1">165</td>
              <td align="center" rowspan="1" colspan="1">218</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">5,054/27,286</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">370/3,260</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Esterase</td>
              <td align="center" rowspan="1" colspan="1">96</td>
              <td align="center" rowspan="1" colspan="1">146</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">2,150/10,426</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">926/514</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Glycosyltransferase</td>
              <td align="center" rowspan="1" colspan="1">89</td>
              <td align="center" rowspan="1" colspan="1">54</td>
              <td align="center" rowspan="1" colspan="1">0.9259/0.9778</td>
              <td align="center" rowspan="1" colspan="1">725/3,042</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">113/417</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Halogenase</td>
              <td align="center" rowspan="1" colspan="1">62</td>
              <td align="center" rowspan="1" colspan="1">42</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">303/1,991</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">20/290</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BKACE</td>
              <td align="center" rowspan="1" colspan="1">17</td>
              <td align="center" rowspan="1" colspan="1">161</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">255/2,193</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">19/270</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DUD-E <sup>†</sup></td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">8,996/406,208</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">11,430/521,132</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> GPCR</td>
              <td align="center" rowspan="1" colspan="1">99,671</td>
              <td align="center" rowspan="1" colspan="1">5</td>
              <td align="center" rowspan="1" colspan="1">18,563</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Kinase</td>
              <td align="center" rowspan="1" colspan="1">315,399</td>
              <td align="center" rowspan="1" colspan="1">26</td>
              <td align="center" rowspan="1" colspan="1">15,409</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Protease</td>
              <td align="center" rowspan="1" colspan="1">286,089</td>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">9,271</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Nuclear</td>
              <td align="center" rowspan="1" colspan="1">151,133</td>
              <td align="center" rowspan="1" colspan="1">11</td>
              <td align="center" rowspan="1" colspan="1">16,257</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>We report the number of unique drugs and targets, the median (drug/target) coverage, and the number of training, validation, and test samples in each dataset. The numbers of pairs are shown as (positive/negative), except for TDC-DG (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r58" ref-type="bibr">58</xref>), which is a regression task; thus, the total number of pairs is shown. We consider BIOSNAP (<xref rid="r70" ref-type="bibr">70</xref>), BindingDB (<xref rid="r69" ref-type="bibr">69</xref>), DAVIS (<xref rid="r68" ref-type="bibr">68</xref>), and TDC-DG as low-coverage, while Phosphatase (<xref rid="r71" ref-type="bibr">71</xref>), Esterase (<xref rid="r72" ref-type="bibr">72</xref>), Glycosyltransferase (<xref rid="r73" ref-type="bibr">73</xref>), Halogenase (<xref rid="r74" ref-type="bibr">74</xref>), BKACE (<xref rid="r75" ref-type="bibr">75</xref>), and DUD-E (<xref rid="r36" ref-type="bibr">36</xref>) are considered high-coverage. † Because DUD-E is a decoy dataset, we report as coverage the median number of true drugs or decoys for each target.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="s12">
      <title>Benchmarks Overview.</title>
      <sec id="s13">
        <title>Low coverage benchmarks.</title>
        <p>We evaluate our framework on three broad-scale, low-coverage benchmark datasets. Two datasets, <bold>DAVIS</bold> (<xref rid="r68" ref-type="bibr">68</xref>) and <bold>BindingDB</bold> (<xref rid="r69" ref-type="bibr">69</xref>), consist of pairs of drugs and targets with experimentally determined dissociation constants (<italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub>). Following ref. <xref rid="r13" ref-type="bibr">13</xref>, we treat pairs with <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> &lt; 30 as positive DTIs, while larger <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values are negative. The third dataset, ChG-Miner from <bold>BIOSNAP</bold> (<xref rid="r70" ref-type="bibr">70</xref>), consists of only positive DTIs. We create negative DTIs by randomly sampling an equal number of protein–drug pairs, making the assumption that a random pair is unlikely to be positively interacting. The DAVIS dataset represents a few-shot learning setting: It contains only 2,086 training interactions, compared to 12,668 for BindingDB and 19,238 for BIOSNAP. The rest of the data preparation follows (<xref rid="r13" ref-type="bibr">13</xref>). The datasets are split into 70% for training, 10% for validation, and the remaining 20% for testing. Training data are artificially subsampled to have an equal number of positive and negative interactions, while validation and test data are left at the ratio originally in the dataset.</p>
      </sec>
      <sec id="s14">
        <title>Zero-shot benchmarks.</title>
        <p>We evaluate our framework on two zero-shot prediction modifications of BIOSNAP. Following ref. <xref rid="r13" ref-type="bibr">13</xref>, the <bold>Unseen proteins</bold> set was created by selecting 20% of proteins from the full set and selecting any interactions including these proteins for the test set. Thus, there are no proteins which appear in both the training and test set. The corresponding process was used to create the <bold>Unseen drugs</bold> dataset. The training set was then further split using 7/8 of the interactions for training and 1/8 of the interactions for testing. As above, data are subsampled so that training is balanced.</p>
      </sec>
      <sec id="s15">
        <title>Continuous benchmarks.</title>
        <p>Continuous affinity prediction data come from the TDC-DG (<xref rid="r19" ref-type="bibr">19</xref>). The TDC-DG consists of 140,746 unique drugs and 477 unique targets derived from BindingDB (<xref rid="r69" ref-type="bibr">69</xref>) interactions that have patent information. Each interaction is labeled with an experimentally determined dissociation constant (<italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>). Interactions are temporally split, so that training pairs are from patents filed between 2013 and 2018, and test pairs are from between 2019 and 2021. In addition, 20% of the training pairs are randomly set aside as a validation set. We train five different models with the train/validation splits determined by the TDC benchmarking framework and report the average PCC coefficient of predictions on the test set.</p>
      </sec>
      <sec id="s16">
        <title>High coverage benchmarks.</title>
        <p>The Database of Useful Decoys: Enhanced (<bold>DUD-E</bold>) (<xref rid="r36" ref-type="bibr">36</xref>) consists of 102 protein targets and known binding partners (average 224 molecules per target). For each binding partner, there are 50 “decoys,” or physiochemically similar compounds that are known not to bind with the target. Of note, 57 of the targets are classified as either GPCRs, kinases, nuclear proteins, or proteases. We generate train–test splits by splitting targets within classes, so that there are representative members of each class in both the training and test sets, but no target appears in both the training and test set (26 train and 31 test). These data are by definition high coverage since there are several true and decoy compounds available for each target. We provide the full target splits in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S1</ext-link>.</p>
        <p>We also evaluate several protein-family-specific datasets from various different sources compiled by Goldman et al. (<xref rid="r25" ref-type="bibr">25</xref>). These include DTI data on <italic toggle="yes">β</italic>-ketoacid cleavage (<bold>BKACE</bold>) (<xref rid="r75" ref-type="bibr">75</xref>), <bold>Esterase</bold> (<xref rid="r72" ref-type="bibr">72</xref>), <bold>Glycosyltransferases</bold> (<xref rid="r73" ref-type="bibr">73</xref>), <bold>Halogenase</bold> (<xref rid="r74" ref-type="bibr">74</xref>), and <bold>Phosphatase</bold> (<xref rid="r71" ref-type="bibr">71</xref>) enzymes. These data are uniformly very high coverage, with a known data point for nearly every drug–target pair. Following ref. (<xref rid="r25" ref-type="bibr">25</xref>), we performed a 10-fold cross-validation where the data were split into train–test sets by target, so that all drugs appear in both the training and test set, but no target does.</p>
      </sec>
    </sec>
    <sec id="s17">
      <title>ConPLex Model.</title>
      <sec id="s18">
        <title>Target featurization.</title>
        <p>We generate protein target features using pretrained PLMs: These models generate a protein embedding <italic toggle="yes">E</italic><sub><italic toggle="yes">f</italic><italic toggle="yes">u</italic><italic toggle="yes">l</italic><italic toggle="yes">l</italic></sub> ∈ ℝ<sup><italic toggle="yes">n</italic> × <italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup> for a protein of length <italic toggle="yes">n</italic>, which is then mean-pooled along the length of the protein resulting in a vector <italic toggle="yes">E</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup>. Specifically, we investigate the pretrained models Prose (<xref rid="r30" ref-type="bibr">30</xref>), ESM (<xref rid="r76" ref-type="bibr">76</xref>), and ProtBert (<xref rid="r27" ref-type="bibr">27</xref>), with default dimensions <italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub> = 6165, 1280, <italic toggle="yes">a</italic><italic toggle="yes">n</italic><italic toggle="yes">d</italic>1024, respectively (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>). Elnaggar et al. recommend the use of ProtT5XLUniref50, but we found that it did not perform as well as ProtBert for the DTI prediction task. We emphasize that the language and projection models are used exclusively to generate input features—their weights are kept unchanged and are not updated during DTI training.</p>
      </sec>
      <sec id="s19">
        <title>Drug featurization.</title>
        <p>We featurize the drug molecule by its Morgan fingerprint (<xref rid="r26" ref-type="bibr">26</xref>), an encoding of the SMILES string of the molecular graph as a fixed-dimension embedding <italic toggle="yes">M</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub></sup> (we chose <italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub>= 2,048) by considering the local neighborhood around each atom. The utility of the Morgan fingerprint for small molecule representation has been demonstrated in refs. <xref rid="r25" ref-type="bibr">25</xref> and <xref rid="r77" ref-type="bibr">77</xref>. We additionally investigated the use of molecule embeddings from Mol2Vec (<xref rid="r78" ref-type="bibr">78</xref>) and MolR (<xref rid="r79" ref-type="bibr">79</xref>) and found that they failed to perform as well as the Morgan fingerprint (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>).</p>
      </sec>
      <sec id="s20">
        <title>Transformation into a shared latent space and prediction.</title>
        <p>Given a target embedding <italic toggle="yes">T</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup> and small molecule embedding <italic toggle="yes">M</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub></sup>, we transform them separately into <italic toggle="yes">T</italic><sup>*</sup>, <italic toggle="yes">M</italic><sup>*</sup> ∈ ℝ<sup><italic toggle="yes">h</italic></sup> using a single fully connected layer with a ReLU activation. These layers are parameterized with weight matrices <italic toggle="yes">W</italic><sub><italic toggle="yes">t</italic></sub> ∈ ℝ<sup><italic toggle="yes">h</italic> × <italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup>, <italic toggle="yes">W</italic><sub><italic toggle="yes">m</italic></sub> ∈ ℝ<sup><italic toggle="yes">h</italic> × <italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub></sup>, and bias vectors <inline-formula><mml:math id="i7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.
<disp-formula id="eqn1"><label>[1]</label><mml:math id="me1" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="eqn2"><label>[2]</label><mml:math id="me2" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>Given the latent embeddings <italic toggle="yes">T</italic><sup>*</sup>, <italic toggle="yes">M</italic><sup>*</sup>, we compute the probability of a DTI <inline-formula><mml:math id="i8" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as the cosine similarity between the embedding vectors, followed by a sigmoid activation. Thus, we compute the predicted probability as:
<disp-formula id="eqn3"><label>[3]</label><mml:math id="me3" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>·</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>When predicting compound binding affinity <inline-formula><mml:math id="i9" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we substitute the sigmoid and cosine similarity (Eq. <xref rid="eqn3" ref-type="disp-formula"><bold>3</bold></xref>) with a dot product followed by a ReLU activation, which gives a nonnegative distance in the embedding space (Eq. <xref rid="eqn4" ref-type="disp-formula"><bold>4</bold></xref>).
<disp-formula id="eqn4"><label>[4]</label><mml:math id="me4" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec id="s21">
        <title>Training.</title>
        <p>The model is trained both for broad and fine predictions, with the loss computed depending on the training dataset. Broad-scale training data use the binary cross-entropy loss (<italic toggle="yes">L</italic><sub><italic toggle="yes">B</italic><italic toggle="yes">C</italic><italic toggle="yes">E</italic></sub>) between the true labels <italic toggle="yes">y</italic> and the predicted interaction probabilities <inline-formula><mml:math id="i10" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. When the model is trained to predict binding affinity, we substitute the binary cross-entropy loss with the mean squared error loss (<italic toggle="yes">L</italic><sub><italic toggle="yes">M</italic><italic toggle="yes">S</italic><italic toggle="yes">E</italic></sub>) during supervision.</p>
        <p>Training on fine-scale data (DUD-E) was performed using contrastive learning. Contrastive learning uses triplets of training points rather than pairs, denoted the <bold>anchor</bold>, <bold>positive</bold>, and <bold>negative</bold>, and aims to minimize the distance between the anchor and positive examples while maximizing the distance between the anchor and the negative examples. In the DTI setting, the natural choice for a triplet is the protein target as the anchor, the true drug as the positive, and decoy as the negative example, respectively. We derive a training set of triplets in the following manner: For each known interacting drug–target pair (<italic toggle="yes">T</italic>, <italic toggle="yes">M</italic><sup>+</sup>), we randomly sample <italic toggle="yes">k</italic> = 50 noninteracting pairs (<italic toggle="yes">T</italic>, <italic toggle="yes">M</italic><sup>−</sup>) and generate the triplets (<italic toggle="yes">T</italic>, <italic toggle="yes">M</italic><sup>+</sup>, <italic toggle="yes">M</italic><sup>−</sup>), where <italic toggle="yes">M</italic><sup>−</sup> is drawn from the set of all decoys against <italic toggle="yes">T</italic>. We map these to latent space embeddings as described above. Since all the entities are now comparable to each other, we can compute the triplet margin-distance loss (<italic toggle="yes">L</italic><sub><italic toggle="yes">T</italic><italic toggle="yes">R</italic><italic toggle="yes">M</italic></sub>).
<disp-formula id="eqn5"><label>[5]</label><mml:math id="me5" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">TRM</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>where
<disp-formula id="eqn6"><label>[6]</label><mml:math id="me6" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>The margin <italic toggle="yes">m</italic> sets the maximum required delta between distances, above which the loss is zero.</p>
      </sec>
      <sec id="s22">
        <title>Margin annealing.</title>
        <p>The margin <italic toggle="yes">m</italic> sets the maximum required delta between distances, above which the loss is zero. Initially, a large margin requires the decoy to be much further from the target than the drug to avoid a penalty, resulting in larger weight updates. As training progresses, lower margins relax this constraint, requiring only that the drug be closer than the decoy as <italic toggle="yes">m</italic> → 0. Here, the margin is initialized at <italic toggle="yes">M</italic><sub><italic toggle="yes">m</italic><italic toggle="yes">a</italic><italic toggle="yes">x</italic></sub> = 0.25 according to a tanh decay with restarts schedule. Every <italic toggle="yes">E</italic><sub><italic toggle="yes">m</italic><italic toggle="yes">a</italic><italic toggle="yes">x</italic></sub> = 10 contrastive epochs, the margin is reset to the initial <italic toggle="yes">M</italic><sub><italic toggle="yes">m</italic><italic toggle="yes">a</italic><italic toggle="yes">x</italic></sub>, for a total of 50 epochs. At epoch <italic toggle="yes">i</italic>, the margin is set to
<disp-formula id="eqn7"><label>[7]</label><mml:math id="me7" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>tanh</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mspace width="3.33333pt"/><mml:mspace width="0.333333em"/><mml:mtext>mod</mml:mtext><mml:mspace width="3.33333pt"/><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec id="s23">
        <title>Implementation.</title>
        <p>Model weights were initialized using the Xavier method from a normal distribution (<xref rid="r80" ref-type="bibr">80</xref>). Weights were updated with error backpropagation using the AdamW optimizer (<xref rid="r81" ref-type="bibr">81</xref>) for a total of 50 epochs. For the binary classification task, the learning rate was initially set to 10<sup>−4</sup> and adjusted according to a cosine annealing schedule with warm restarts (<xref rid="r82" ref-type="bibr">82</xref>) every 10 epochs. For the contrastive task, the learning rate was initially set to 10<sup>−5</sup>, and the same annealing schedule was followed. The margin for the contrastive loss was initially set to 0.25 and decreased to a minimum of 0 over 50 epochs according to a tanh decay schedule with restarts every 10 epochs. We used a latent dimension <italic toggle="yes">d</italic>= 1,024 (results were robust to even with lower dimensions, and much higher dimensions may overfit or be subject to topological restrictions) and a batch size of 32. The model was implemented in PyTorch version 1.11. Model training, and inference was performed on a machine with a 112-core Intel Xeon Gold 6258R CPU and using a single NVIDIA A100 GPU. We compare training and inference run times in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S4</ext-link>.</p>
      </sec>
    </sec>
    <sec id="s24">
      <title>Surfaceome Analysis.</title>
      <p>We evaluate the functional use of ConPLex embeddings using data from the Surfaceome database (<xref rid="r17" ref-type="bibr">17</xref>), which contains 2,886 cell-surface proteins. We identified Pfam domains using HMMscan from HMMER3 (<xref rid="r51" ref-type="bibr">51</xref>) with default settings. We analyzed domains hit in &gt; 10 proteins. For each domain, we trained a logistic regression classifier from sklearn with balanced class weights. We also evaluated domain coherence using spectral clustering with <italic toggle="yes">k</italic> = 10 clusters and evaluated the adjusted mutual information (AMI) between true clusters (protein has/does not have domain) and predicted clusters (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S6</ext-link>).</p>
    </sec>
    <sec id="s25">
      <title>Experimental Determination of Kinase Binding Affinity.</title>
      <p>From the Surfaceome (<xref rid="r17" ref-type="bibr">17</xref>) database, we selected 51 kinases which were available by the KdELECT assay from DiscoveryX. From the ZINC database (<xref rid="r37" ref-type="bibr">37</xref>), we selected 4715 compounds purchasable from the Cayman Chemical Company. Using a ConPLex model trained on BindingDB and fine-tuned on DUD-E, we predicted all pairwise interactions between kinases and small molecule drugs. Without previously consulting the literature on kinases or drugs, we selected 5 kinases which were highly represented in the top predictions (<italic toggle="yes">EGFR</italic>, <italic toggle="yes">EPHB1</italic>, <italic toggle="yes">FLT3</italic>, <italic toggle="yes">KIT</italic>, and <italic toggle="yes">TGFBR2</italic>). We then selected 19 binding pairs to test, covering 14 drugs with high ConPLex-predicted interactions. The full list of ConPLex predictions can be found in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, Data S1</ext-link>.</p>
      <p>We performed <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> determination using the KdELECT assay from the DiscoveryX company, following the procedure from Hie et al. (<xref rid="r83" ref-type="bibr">83</xref>). KdELECT measures competition between test compounds and an immobilized, active site-directed ligand. Ligands are tagged with DNA oligomers, and competition is measured by qPCR of this barcode. BL21-derived <italic toggle="yes">E. coli</italic> were infected with T7 phase strains tagged with each kinase target and incubated with shaking at 32°C. Streptavidin-coated magnetic beads were treated with a biotinylated ligand at room temperature for 30 min, following which the beads were blocked with excess biotin and washed with blocking buffer [SeaBlock (Pierce), 1% bovine serum albumin (BSA), 0.05% Tween 20, and 1 mM dithiothreitol (DTT)] to remove unbound ligand. Test compounds were prepared as 111X stocks in 100% DMSO. An 11-point, threefold compound dilution series was created, with a top test compound concentration of 10,000 nM. Three DMSO control points were also used. Test compounds are distributed by acoustic transfer (noncontact dispensing) in 100% DMSO and then diluted into the assays for a final DMSO concentration of 0.9%.</p>
      <p>Kinases, ligand-bound affinity beads, and test compounds were combined in 1X binding buffer [20% SeaBlock, 0.17X phosphate-buffered saline (PBS), 0.05% Tween 20, and 6 mM DTT] in a 384-well plate, with a final volume of 0.02 mL for each reaction. Plates were incubated for 1 h at room temperature with shaking. Affinity beads were washed with wash buffer (1x PBS, 0.05% Tween 20), resuspended in elution buffer (1x PBS, 0.05% Tween 20, 0.5 mM nonbiotinylated affinity ligand), and incubated for 30 min at room temperature with shaking. The concentration of kinases was measured using qPCR. To compute <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> of the binding, a standard dose–response curve was fit to the Hill equation curves using the Levenberg–Marquardt algorithm (Hill slope = −1).</p>
    </sec>
    <sec id="s26">
      <title>Genome-wide ChEMBL Scan.</title>
      <p>We trained a ConPLex model using BindingDB and DUD-E and used it to make predictions for all pairs of human proteins against all drugs in ChEMBL. Human protein sequences were taken from the STRING database and processed following ref. (<xref rid="r32" ref-type="bibr">32</xref>), resulting in 15,816 proteins between 50 and 800 amino acids long. Small molecule structures were downloaded from ChEMBL 30 (<xref rid="r18" ref-type="bibr">18</xref>), resulting in 1,533,652 compounds. Prediction took just under a day, accounting for embedding time.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material position="float" content-type="local-data">
      <caption>
        <p>Appendix 01 (PDF)</p>
      </caption>
      <media xlink:href="pnas.2220778120.sapp.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>R.S. and B. Berger were supported by the NIH grant R35GM141861. S.S. was supported by the NSF Graduate Research Fellowship under Grant No. 2141064. B. Bryson was supported by the Terry and Susan Ragon Foundation. L.C. was supported by NSF grant CCF-1934553. We thank Kapil Devkota, Mert Erden, Tristan Bepler, and Tim Truong for helpful discussions.</p>
    <sec id="s28">
      <title>Author contributions</title>
      <p>R.S., S.S., L.C., and B. Berger designed research; R.S., S.S., B. Bryson, L.C., and B. Berger performed research; R.S., S.S., B. Bryson, L.C., and B. Berger contributed new reagents/analytic tools; R.S., S.S., L.C., and B. Berger analyzed data; and R.S., S.S., B. Bryson, L.C., and B. Berger wrote the paper.</p>
    </sec>
    <sec sec-type="COI-statement" id="s29">
      <title>Competing interests</title>
      <p>The authors declare no competing interest.</p>
    </sec>
  </ack>
  <fn-group>
    <fn fn-type="other" id="fn3">
      <p>This article is a PNAS Direct Submission.</p>
    </fn>
  </fn-group>
  <sec sec-type="data-availability" id="s27">
    <title>Data, Materials, and Software Availability</title>
    <p>Dataset data have been deposited in Github (<ext-link xlink:href="https://github.com/samsledje/ConPLex_dev" ext-link-type="uri">https://github.com/samsledje/ConPLex_dev</ext-link>) (<xref rid="r38" ref-type="bibr">38</xref>). Previously published data were used for this work (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r36" ref-type="bibr">36</xref>, <xref rid="r68" ref-type="bibr">68</xref><xref rid="r69" ref-type="bibr"/><xref rid="r70" ref-type="bibr"/><xref rid="r71" ref-type="bibr"/><xref rid="r72" ref-type="bibr"/><xref rid="r73" ref-type="bibr"/><xref rid="r74" ref-type="bibr"/>–<xref rid="r75" ref-type="bibr">75</xref>).</p>
  </sec>
  <ref-list>
    <ref id="r1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Jumper</surname></string-name><etal/></person-group>, <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source><volume><bold>596</bold></volume>, <fpage>583</fpage>–<lpage>589</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="r2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Baek</surname></string-name><etal/></person-group>, <article-title>Accurate prediction of protein structures and interactions using a three-track neural network</article-title>. <source>Science</source><volume><bold>373</bold></volume>, <fpage>871</fpage>–<lpage>876</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34282049</pub-id></mixed-citation>
    </ref>
    <ref id="r3">
      <label>3</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Wu</surname></string-name><etal/></person-group>, High-resolution de novo structure prediction from primary sequence. bioRxiv [Preprint] (2022). <pub-id pub-id-type="doi">10.1101/2022.07.21.500999</pub-id> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.</given-names><surname>Pinzi</surname></string-name>, <string-name><given-names>G.</given-names><surname>Rastelli</surname></string-name></person-group>, <article-title>Molecular docking: Shifting paradigms in drug discovery</article-title>. <source>Int. J. Mol. Sci.</source><volume><bold>20</bold></volume>, <fpage>4331</fpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31487867</pub-id></mixed-citation>
    </ref>
    <ref id="r5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. M.</given-names><surname>Bonk</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Tarasova</surname></string-name>, <string-name><given-names>M. A.</given-names><surname>Hicks</surname></string-name>, <string-name><given-names>B.</given-names><surname>Tidor</surname></string-name>, <string-name><given-names>K. L.</given-names><surname>Prather</surname></string-name></person-group>, <article-title>Rational design of thiolase substrate specificity for metabolic engineering applications</article-title>. <source>Biotechnol. Bioeng.</source><volume><bold>115</bold></volume>, <fpage>2167</fpage>–<lpage>2182</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29877597</pub-id></mixed-citation>
    </ref>
    <ref id="r6">
      <label>6</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. C.</given-names><surname>de Melo-Minardi</surname></string-name>, <string-name><given-names>K.</given-names><surname>Bastard</surname></string-name>, <string-name><given-names>F.</given-names><surname>Artiguenave</surname></string-name></person-group>, <article-title>Identification of subfamily-specific sites based on active sites modeling and clustering</article-title>. <source>Bioinformatics</source><volume><bold>26</bold></volume>, <fpage>3075</fpage>–<lpage>3082</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20980272</pub-id></mixed-citation>
    </ref>
    <ref id="r7">
      <label>7</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>S. J.</given-names><surname>Trudeau</surname></string-name><etal/></person-group>, PrePCI: A structure- and chemical similarity-informed database of predicted protein compound interactions. bioRxiv [Preprint] (2022). <pub-id pub-id-type="doi">10.1101/2022.09.17.508184</pub-id> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>D.</given-names><surname>Park</surname></string-name>, <string-name><given-names>J.</given-names><surname>Xu</surname></string-name>, <string-name><given-names>R.</given-names><surname>Hosur</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Struct2Net: A web service to predict protein–protein interactions using a structure-based approach</article-title>. <source>Nucleic Acids Res.</source><volume><bold>38</bold></volume>, <fpage>W508</fpage>–<lpage>W515</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20513650</pub-id></mixed-citation>
    </ref>
    <ref id="r9">
      <label>9</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>E.</given-names><surname>Anderson</surname></string-name>, <string-name><given-names>G. D.</given-names><surname>Veith</surname></string-name>, <string-name><given-names>D.</given-names><surname>Weininger</surname></string-name></person-group>, <source>SMILES, A Line Notation and Computerized Interpreter for Chemical Structures</source> (<publisher-name>Environmental Research Laboratory, US Environmental Protection Agency</publisher-name>, <year>1987</year>).</mixed-citation>
    </ref>
    <ref id="r10">
      <label>10</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Bagherian</surname></string-name><etal/></person-group>, <article-title>Machine learning approaches and databases for prediction of drug–target interaction: A survey paper</article-title>. <source>Brief. Bioinf.</source><volume><bold>22</bold></volume>, <fpage>247</fpage>–<lpage>269</lpage> (<year>2021</year>).</mixed-citation>
    </ref>
    <ref id="r11">
      <label>11</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>H.</given-names><surname>Cho</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Realizing private and practical pharmacological collaboration</article-title>. <source>Science</source><volume><bold>362</bold></volume>, <fpage>347</fpage>–<lpage>350</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30337410</pub-id></mixed-citation>
    </ref>
    <ref id="r12">
      <label>12</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Lee</surname></string-name>, <string-name><given-names>J.</given-names><surname>Keum</surname></string-name>, <string-name><given-names>H.</given-names><surname>Nam</surname></string-name></person-group>, <article-title>DeepConv-DTI: Prediction of drug–target interactions via deep learning with convolution on protein sequences</article-title>. <source>PLoS Comput. Biol.</source><volume><bold>15</bold></volume>, <fpage>e1007129</fpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31199797</pub-id></mixed-citation>
    </ref>
    <ref id="r13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name>, <string-name><given-names>C.</given-names><surname>Xiao</surname></string-name>, <string-name><given-names>L. M.</given-names><surname>Glass</surname></string-name>, <string-name><given-names>J.</given-names><surname>Sun</surname></string-name></person-group>, <article-title>MolTrans: Molecular interaction transformer for drug–target interaction prediction</article-title>. <source>Bioinformatics</source><volume><bold>37</bold></volume>, <fpage>830</fpage>–<lpage>836</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33070179</pub-id></mixed-citation>
    </ref>
    <ref id="r14">
      <label>14</label>
      <mixed-citation publication-type="other">S. Sledzieski, R. Singh, L. Cowen, B. Berger. “Adapting protein language models for rapid DTI prediction in <italic toggle="yes">Machine Learning for Structural Biology Workshop (MLSB) at NeurIPS</italic> (2021).</mixed-citation>
    </ref>
    <ref id="r15">
      <label>15</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Bommasani</surname></string-name><etal/></person-group>, On the opportunities and risks of foundation models. arXiv [Preprint] (2021). <ext-link xlink:href="http://arxiv.org/abs/2108.07258" ext-link-type="uri">http://arxiv.org/abs/2108.07258</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r16">
      <label>16</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Gururangan</surname></string-name><etal/></person-group>, Don’t stop pretraining: Adapt language models to domains and tasks. arXiv [Preprint] (2020). <ext-link xlink:href="http://arxiv.org/abs/2004.10964" ext-link-type="uri">http://arxiv.org/abs/2004.10964</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r17">
      <label>17</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Bausch-Fluck</surname></string-name><etal/></person-group>, <article-title>The in silico human surfaceome</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>115</bold></volume>, <fpage>E10988</fpage>–<lpage>E10997</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30373828</pub-id></mixed-citation>
    </ref>
    <ref id="r18">
      <label>18</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Mendez</surname></string-name><etal/></person-group>, <article-title>ChEMBL: Towards direct deposition of bioassay data</article-title>. <source>Nucleic Acids Res.</source><volume><bold>47</bold></volume>, <fpage>D930</fpage>–<lpage>D940</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">30398643</pub-id></mixed-citation>
    </ref>
    <ref id="r19">
      <label>19</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name><etal/></person-group>, Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development. arXiv [Preprint] (2021). <ext-link xlink:href="http://arxiv.org/abs/2102.09548" ext-link-type="uri">http://arxiv.org/abs/2102.09548</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names><surname>Zong</surname></string-name><etal/></person-group>, <article-title>Beta: A comprehensive benchmark for computational drug–target prediction</article-title>. <source>Brief. Bioinf.</source><volume><bold>23</bold></volume>, <fpage>bbac199</fpage> (<year>2022</year>).</mixed-citation>
    </ref>
    <ref id="r21">
      <label>21</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. M.</given-names><surname>Dönertaş</surname></string-name>, <string-name><given-names>M.</given-names><surname>Fuentealba Valenzuela</surname></string-name>, <string-name><given-names>L.</given-names><surname>Partridge</surname></string-name>, <string-name><given-names>J. M.</given-names><surname>Thornton</surname></string-name></person-group>, <article-title>Gene expression-based drug repurposing to target aging</article-title>. <source>Aging Cell</source><volume><bold>17</bold></volume>, <fpage>e12819</fpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29959820</pub-id></mixed-citation>
    </ref>
    <ref id="r22">
      <label>22</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Morselli Gysi</surname></string-name><etal/></person-group>, <article-title>Network medicine framework for identifying drug-repurposing opportunities for Covid-19</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>118</bold></volume>, <fpage>e2025581118</fpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33906951</pub-id></mixed-citation>
    </ref>
    <ref id="r23">
      <label>23</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>DeepPurpose: A deep learning library for drug–target interaction prediction</article-title>. <source>Bioinformatics</source><volume><bold>36</bold></volume>, <fpage>5545</fpage>–<lpage>5547</lpage> (<year>2020</year>).</mixed-citation>
    </ref>
    <ref id="r24">
      <label>24</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>A framework for identification of on- and off-target transcriptional responses to drug treatment</article-title>. <source>Sci. Rep.</source><volume><bold>9</bold></volume>, <fpage>1</fpage>–<lpage>9</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">30626917</pub-id></mixed-citation>
    </ref>
    <ref id="r25">
      <label>25</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Goldman</surname></string-name>, <string-name><given-names>R.</given-names><surname>Das</surname></string-name>, <string-name><given-names>K. K.</given-names><surname>Yang</surname></string-name>, <string-name><given-names>C. W.</given-names><surname>Coley</surname></string-name></person-group>, <article-title>Machine learning modeling of family wide enzyme-substrate specificity screens</article-title>. <source>PLoS Comput. Biol.</source><volume><bold>18</bold></volume>, <fpage>e1009853</fpage> (<year>2022</year>).<pub-id pub-id-type="pmid">35143485</pub-id></mixed-citation>
    </ref>
    <ref id="r26">
      <label>26</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. L.</given-names><surname>Morgan</surname></string-name></person-group>, <article-title>The generation of a unique machine description for chemical structures—A technique developed at chemical abstracts service</article-title>. <source>J. Chem. Doc.</source><volume><bold>5</bold></volume>, <fpage>107</fpage>–<lpage>113</lpage> (<year>1965</year>).</mixed-citation>
    </ref>
    <ref id="r27">
      <label>27</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Elnaggar</surname></string-name><etal/></person-group>, ProtTrans: Towards cracking the language of life’s code through self-supervised deep learning and high performance computing. arXiv [Preprint] (2020). <ext-link xlink:href="http://arxiv.org/abs/2007.06225" ext-link-type="uri">http://arxiv.org/abs/2007.06225</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Scaiewicz</surname></string-name>, <string-name><given-names>M.</given-names><surname>Levitt</surname></string-name></person-group>, <article-title>The language of the protein universe</article-title>. <source>Curr. Opin. Genet. Dev.</source><volume><bold>35</bold></volume>, <fpage>50</fpage>–<lpage>56</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26451980</pub-id></mixed-citation>
    </ref>
    <ref id="r29">
      <label>29</label>
      <mixed-citation publication-type="other">T. Bepler, B. Berger, “Learning protein sequence embeddings using information from structure” in <italic toggle="yes">7th International Conference on Learning Representations, ICLR 2019</italic> (2019).</mixed-citation>
    </ref>
    <ref id="r30">
      <label>30</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names><surname>Bepler</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Learning the protein language: Evolution, structure, and function</article-title>. <source>Cell Syst.</source><volume><bold>12</bold></volume>, <fpage>654</fpage>–<lpage>669.e3</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34139171</pub-id></mixed-citation>
    </ref>
    <ref id="r31">
      <label>31</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Heinzinger</surname></string-name><etal/></person-group>, <article-title>Modeling aspects of the language of life through transfer–learning protein sequences</article-title>. <source>BMC Bioinf.</source><volume><bold>20</bold></volume>, <fpage>1</fpage>–<lpage>17</lpage> (<year>2019</year>).</mixed-citation>
    </ref>
    <ref id="r32">
      <label>32</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Sledzieski</surname></string-name>, <string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>L.</given-names><surname>Cowen</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>D-SCRIPT translates genome to phenome with sequence-based, structure-aware, genome-scale predictions of protein–protein interactions</article-title>. <source>Cell Syst.</source><volume><bold>12</bold></volume>, <fpage>1</fpage>–<lpage>14</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33476552</pub-id></mixed-citation>
    </ref>
    <ref id="r33">
      <label>33</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>K.</given-names><surname>Devkota</surname></string-name>, <string-name><given-names>S.</given-names><surname>Sledzieski</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name>, <string-name><given-names>L.</given-names><surname>Cowen</surname></string-name></person-group>, <article-title>Topsy-Turvy: Integrating a global view into sequence-based PPI prediction</article-title>. <source>Bioinformatics</source><volume><bold>38</bold></volume>, <fpage>i264</fpage>–<lpage>i272</lpage> (<year>2022</year>).<pub-id pub-id-type="pmid">35758793</pub-id></mixed-citation>
    </ref>
    <ref id="r34">
      <label>34</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Tsubaki</surname></string-name>, <string-name><given-names>K.</given-names><surname>Tomii</surname></string-name>, <string-name><given-names>J.</given-names><surname>Sese</surname></string-name></person-group>, <article-title>Compound–protein interaction prediction with end-to-end learning of neural networks for graphs and sequences</article-title>. <source>Bioinformatics</source><volume><bold>35</bold></volume>, <fpage>309</fpage>–<lpage>318</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">29982330</pub-id></mixed-citation>
    </ref>
    <ref id="r35">
      <label>35</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Heinzinger</surname></string-name><etal/></person-group>, <article-title>Contrastive learning on protein embeddings enlightens midnight zone</article-title>. <source>NAR Genom. Bioinf.</source><volume><bold>4</bold></volume>, <fpage>lqac043</fpage> (<year>2022</year>).</mixed-citation>
    </ref>
    <ref id="r36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. M.</given-names><surname>Mysinger</surname></string-name>, <string-name><given-names>M.</given-names><surname>Carchia</surname></string-name>, <string-name><given-names>J. J.</given-names><surname>Irwin</surname></string-name>, <string-name><given-names>B. K.</given-names><surname>Shoichet</surname></string-name></person-group>, <article-title>Directory of useful decoys, enhanced (DUD-E): Better ligands and decoys for better benchmarking</article-title>. <source>J. Med. Chem.</source><volume><bold>55</bold></volume>, <fpage>6582</fpage>–<lpage>6594</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22716043</pub-id></mixed-citation>
    </ref>
    <ref id="r37">
      <label>37</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. J.</given-names><surname>Irwin</surname></string-name>, <string-name><given-names>B. K.</given-names><surname>Shoichet</surname></string-name></person-group>, <article-title>Zinc—A free database of commercially available compounds for virtual screening</article-title>. <source>J. Chem. Inf. Model.</source><volume><bold>45</bold></volume>, <fpage>177</fpage>–<lpage>182</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15667143</pub-id></mixed-citation>
    </ref>
    <ref id="r38">
      <label>38</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>S.</given-names><surname>Sledzieski</surname></string-name>, <string-name><given-names>B.</given-names><surname>Bryson</surname></string-name>, <string-name><given-names>L.</given-names><surname>Cowen</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, surfaceome\_cayman\_validation\_scan.csv. Github. <ext-link xlink:href="https://github.com/samsledje/ConPLex_dev/blob/main/dataset/surfaceome_cayman_validation_scan.csv" ext-link-type="uri">https://github.com/samsledje/ConPLex_dev/blob/main/dataset/surfaceome_cayman_validation_scan.csv</ext-link>. Deposited 20 March 2023.</mixed-citation>
    </ref>
    <ref id="r39">
      <label>39</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W. B.</given-names><surname>Weglicki</surname></string-name>, <string-name><given-names>J. H.</given-names><surname>Kramer</surname></string-name>, <string-name><given-names>C. F.</given-names><surname>Spurney</surname></string-name>, <string-name><given-names>J. J.</given-names><surname>Chmielinska</surname></string-name>, <string-name><given-names>I. T.</given-names><surname>Mak</surname></string-name></person-group>, <article-title>The EGFR tyrosine kinase inhibitor tyrphostin AG-1478 causes hypomagnesemia and cardiac dysfunction</article-title>. <source>Can. J. Physiol. Pharmacol.</source><volume><bold>90</bold></volume>, <fpage>1145</fpage>–<lpage>1149</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22646904</pub-id></mixed-citation>
    </ref>
    <ref id="r40">
      <label>40</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Sordella</surname></string-name>, <string-name><given-names>D. W.</given-names><surname>Bell</surname></string-name>, <string-name><given-names>D. A.</given-names><surname>Haber</surname></string-name>, <string-name><given-names>J.</given-names><surname>Settleman</surname></string-name></person-group>, <article-title>Gefitinib-sensitizing EGFR mutations in lung cancer activate anti-apoptotic pathways</article-title>. <source>Science</source><volume><bold>305</bold></volume>, <fpage>1163</fpage>–<lpage>1167</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15284455</pub-id></mixed-citation>
    </ref>
    <ref id="r41">
      <label>41</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. J.</given-names><surname>Roth</surname></string-name><etal/></person-group>, <article-title>Nintedanib: From discovery to the clinic</article-title>. <source>J. Med. Chem.</source><volume><bold>58</bold></volume>, <fpage>1053</fpage>–<lpage>1063</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25474320</pub-id></mixed-citation>
    </ref>
    <ref id="r42">
      <label>42</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. S.</given-names><surname>Wang</surname></string-name><etal/></person-group>, <article-title>Phase 1 trial of linifanib (ABT-869) in patients with refractory or relapsed acute myeloid leukemia</article-title>. <source>Leuk. Lymphoma</source><volume><bold>53</bold></volume>, <fpage>1543</fpage>–<lpage>1551</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22280537</pub-id></mixed-citation>
    </ref>
    <ref id="r43">
      <label>43</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N. C.</given-names><surname>Wolff</surname></string-name><etal/></person-group>, <article-title>PD166326, a novel tyrosine kinase inhibitor, has greater antileukemic activity than imatinib mesylate in a murine model of chronic myeloid leukemia</article-title>. <source>Blood</source><volume><bold>105</bold></volume>, <fpage>3995</fpage>–<lpage>4003</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15657179</pub-id></mixed-citation>
    </ref>
    <ref id="r44">
      <label>44</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. S.</given-names><surname>Wishart</surname></string-name><etal/></person-group>, <article-title>DrugBank 5.0: A major update to the DrugBank database for 2018</article-title>. <source>Nucleic Acids Res.</source><volume><bold>46</bold></volume>, <fpage>D1074</fpage>–<lpage>D1082</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29126136</pub-id></mixed-citation>
    </ref>
    <ref id="r45">
      <label>45</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V.</given-names><surname>Cibert-Goton</surname></string-name><etal/></person-group>, <article-title>Involvement of EphB1 receptors signalling in models of inflammatory and neuropathic pain</article-title>. <source>PLoS ONE</source><volume><bold>8</bold></volume>, <fpage>e53673</fpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23341972</pub-id></mixed-citation>
    </ref>
    <ref id="r46">
      <label>46</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Liu</surname></string-name><etal/></person-group>, <article-title>Blocking EphB1 receptor forward signaling in spinal cord relieves bone cancer pain and rescues analgesic effect of morphine treatment in rodents EphB1 receptor is critical to bone cancer pain</article-title>. <source>Cancer Res.</source><volume><bold>71</bold></volume>, <fpage>4392</fpage>–<lpage>4402</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21555368</pub-id></mixed-citation>
    </ref>
    <ref id="r47">
      <label>47</label>
      <mixed-citation publication-type="journal">
F. Carles, S. Bourg, C. Meyer, P. Bonnet, PKIDB: A curated, annotated and updated database of
protein kinase inhibitors in clinical trials. Molecules 23, 908 (2018).</mixed-citation>
    </ref>
    <ref id="r48">
      <label>48</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>Drabsch</surname></string-name>, <string-name><given-names>P.</given-names><surname>Ten Dijke</surname></string-name></person-group>, <article-title>TGF-<inline-formula><mml:math id="ueqn1001" display="inline" overflow="scroll"><mml:mi>β</mml:mi></mml:math></inline-formula> signalling and its role in cancer progression and metastasis</article-title>. <source>Cancer Metastasis Rev.</source><volume><bold>31</bold></volume>, <fpage>553</fpage>–<lpage>568</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22714591</pub-id></mixed-citation>
    </ref>
    <ref id="r49">
      <label>49</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. S.</given-names><surname>Almén</surname></string-name>, <string-name><given-names>K. J.</given-names><surname>Nordström</surname></string-name>, <string-name><given-names>R.</given-names><surname>Fredriksson</surname></string-name>, <string-name><given-names>H. B.</given-names><surname>Schiöth</surname></string-name></person-group>, <article-title>Mapping the human membrane proteome: A majority of the human membrane proteins can be classified according to function and evolutionary origin</article-title>. <source>BMC Biol.</source><volume><bold>7</bold></volume>, <fpage>1</fpage>–<lpage>14</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19144100</pub-id></mixed-citation>
    </ref>
    <ref id="r50">
      <label>50</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>El-Gebali</surname></string-name><etal/></person-group>, <article-title>The Pfam protein families database in 2019</article-title>. <source>Nucleic Acids Res.</source><volume><bold>47</bold></volume>, <fpage>D427</fpage>–<lpage>D432</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">30357350</pub-id></mixed-citation>
    </ref>
    <ref id="r51">
      <label>51</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. R.</given-names><surname>Eddy</surname></string-name></person-group>, <article-title>Accelerated profile HMM searches</article-title>. <source>PLoS Comput. Biol.</source><volume><bold>7</bold></volume>, <fpage>e1002195</fpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22039361</pub-id></mixed-citation>
    </ref>
    <ref id="r52">
      <label>52</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. P.</given-names><surname>Himanen</surname></string-name>, <string-name><given-names>M.</given-names><surname>Henkemeyer</surname></string-name>, <string-name><given-names>D. B.</given-names><surname>Nikolov</surname></string-name></person-group>, <article-title>Crystal structure of the ligand-binding domain of the receptor tyrosine kinase EphB2</article-title>. <source>Nature</source><volume><bold>396</bold></volume>, <fpage>486</fpage>–<lpage>491</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9853759</pub-id></mixed-citation>
    </ref>
    <ref id="r53">
      <label>53</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Berger</surname></string-name>, <string-name><given-names>M. S.</given-names><surname>Waterman</surname></string-name>, <string-name><given-names>Y. W.</given-names><surname>Yu</surname></string-name></person-group>, <article-title>Levenshtein distance, sequence comparison and biological database search</article-title>. <source>IEEE Trans. Inf. Theory.</source><volume><bold>67</bold></volume>, <fpage>3287</fpage>–<lpage>3294</lpage> (<year>2020</year>).<pub-id pub-id-type="pmid">34257466</pub-id></mixed-citation>
    </ref>
    <ref id="r54">
      <label>54</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>DeepPurpose: A deep learning library for drug–target interaction prediction</article-title>. <source>Bioinformatics</source><volume><bold>36</bold></volume>, <fpage>5545</fpage>–<lpage>5547</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33275143</pub-id></mixed-citation>
    </ref>
    <ref id="r55">
      <label>55</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Ramsundar</surname></string-name></person-group>, “Molecular machine learning with DeepChem,” PhD thesis (Stanford University, 2018).</mixed-citation>
    </ref>
    <ref id="r56">
      <label>56</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>E. D.</given-names><surname>Zhong</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name>, <string-name><given-names>B.</given-names><surname>Bryson</surname></string-name></person-group>, <article-title>Learning the language of viral evolution and escape</article-title>. <source>Science</source><volume><bold>371</bold></volume>, <fpage>284</fpage>–<lpage>288</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33446556</pub-id></mixed-citation>
    </ref>
    <ref id="r57">
      <label>57</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Littmann</surname></string-name>, <string-name><given-names>M.</given-names><surname>Heinzinger</surname></string-name>, <string-name><given-names>C.</given-names><surname>Dallago</surname></string-name>, <string-name><given-names>K.</given-names><surname>Weissenow</surname></string-name>, <string-name><given-names>B.</given-names><surname>Rost</surname></string-name></person-group>, <article-title>Protein embeddings and deep learning predict binding residues for various ligand classes</article-title>. <source>Sci. Rep.</source><volume><bold>11</bold></volume>, <fpage>1</fpage>–<lpage>15</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="r58">
      <label>58</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Gulrajani</surname></string-name>, <string-name><given-names>D.</given-names><surname>Lopez-Paz</surname></string-name></person-group>, In search of lost domain generalization. arXiv [Preprint] (2020). <ext-link xlink:href="http://arxiv.org/abs/2007.01434" ext-link-type="uri">http://arxiv.org/abs/2007.01434</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r59">
      <label>59</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Russel</surname></string-name><etal/></person-group>, <article-title>Putting the pieces together: Integrative modeling platform software for structure determination of macromolecular assemblies</article-title>. <source>PLoS Biol.</source><volume><bold>10</bold></volume>, <fpage>e1001244</fpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22272186</pub-id></mixed-citation>
    </ref>
    <ref id="r60">
      <label>60</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Skolnick</surname></string-name>, <string-name><given-names>H.</given-names><surname>Zhou</surname></string-name></person-group>, <article-title>Implications of the essential role of small molecule ligand binding pockets in protein–protein interactions</article-title>. <source>J. Phys. Chem. B</source><volume><bold>126</bold></volume>, <fpage>6853</fpage>–<lpage>6867</lpage> (<year>2022</year>).<pub-id pub-id-type="pmid">36044742</pub-id></mixed-citation>
    </ref>
    <ref id="r61">
      <label>61</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>B. L.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>K. K.</given-names><surname>Yang</surname></string-name>, <string-name><given-names>P. S.</given-names><surname>Kim</surname></string-name></person-group>, Evolutionary velocity with protein language models. bioRxiv [Preprint] (2021). <pub-id pub-id-type="doi">10.1101/2021.06.07.447389</pub-id> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r62">
      <label>62</label>
      <mixed-citation publication-type="other">C. Hsu, H. Nisonoff, C. Fannjiang, J. Listgarten, Combining evolutionary and assay-labelled data for protein fitness prediction. bioRxiv [Preprint] (2021). <pub-id pub-id-type="doi">10.1101/2021.03.28.437402</pub-id>.</mixed-citation>
    </ref>
    <ref id="r63">
      <label>63</label>
      <mixed-citation publication-type="other">W. Jin, R. Barzilay, T. Jaakkola, “Junction tree variational autoencoder for molecular graph generation” in <italic toggle="yes">International Conference on Machine Learning</italic> (PMLR, 2018), pp. 2323–2332.</mixed-citation>
    </ref>
    <ref id="r64">
      <label>64</label>
      <mixed-citation publication-type="other">W. Jin, R. Barzilay, T. Jaakkola, “Hierarchical generation of molecular graphs using structural motifs” in <italic toggle="yes">International Conference on Machine Learning</italic> (PMLR, 2020), pp. 4839–4848.</mixed-citation>
    </ref>
    <ref id="r65">
      <label>65</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>O. J.</given-names><surname>Wouters</surname></string-name>, <string-name><given-names>M.</given-names><surname>McKee</surname></string-name>, <string-name><given-names>J.</given-names><surname>Luyten</surname></string-name></person-group>, <article-title>Estimated research and development investment needed to bring a new medicine to market, 2009–2018</article-title>. <source>J. Am. Med. Assoc.</source><volume><bold>323</bold></volume>, <fpage>844</fpage>–<lpage>853</lpage> (<year>2020</year>).</mixed-citation>
    </ref>
    <ref id="r66">
      <label>66</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. A.</given-names><surname>Van Norman</surname></string-name></person-group>, <article-title>Drugs, devices, and the FDA. Part 1: An overview of approval processes for drugs</article-title>. <source>JACC: Basic Transl. Sci.</source><volume><bold>1</bold></volume>, <fpage>170</fpage>–<lpage>179</lpage> (<year>2016</year>).<pub-id pub-id-type="pmid">30167510</pub-id></mixed-citation>
    </ref>
    <ref id="r67">
      <label>67</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. T.</given-names><surname>Sabe</surname></string-name><etal/></person-group>, <article-title>Current trends in computer aided drug design and a highlight of drugs discovered via computational techniques: A review</article-title>. <source>Eur. J. Med. Chem.</source><volume><bold>224</bold></volume>, <fpage>113705</fpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34303871</pub-id></mixed-citation>
    </ref>
    <ref id="r68">
      <label>68</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. I.</given-names><surname>Davis</surname></string-name><etal/></person-group>, <article-title>Comprehensive analysis of kinase inhibitor selectivity</article-title>. <source>Nat. Biotechnol.</source><volume><bold>29</bold></volume>, <fpage>1046</fpage>–<lpage>1051</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22037378</pub-id></mixed-citation>
    </ref>
    <ref id="r69">
      <label>69</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names><surname>Liu</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Lin</surname></string-name>, <string-name><given-names>X.</given-names><surname>Wen</surname></string-name>, <string-name><given-names>R. N.</given-names><surname>Jorissen</surname></string-name>, <string-name><given-names>M. K.</given-names><surname>Gilson</surname></string-name></person-group>, <article-title>BindingDB: A web-accessible database of experimentally determined protein–ligand binding affinities</article-title>. <source>Nucleic Acids Res.</source><volume><bold>35</bold></volume>, <fpage>D198</fpage>–<lpage>D201</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17145705</pub-id></mixed-citation>
    </ref>
    <ref id="r70">
      <label>70</label>
      <mixed-citation publication-type="other">M. Zitnik, R. Sosič, S. Maheshwari, J. Leskovec, BioSNAP Datasets: Stanford biomedical network dataset collection (2018). <ext-link xlink:href="http://snap.stanford.edu/biodata" ext-link-type="uri">http://snap.stanford.edu/biodata</ext-link>.</mixed-citation>
    </ref>
    <ref id="r71">
      <label>71</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>Panoramic view of a superfamily of phosphatases through substrate profiling</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>112</bold></volume>, <fpage>E1974</fpage>–<lpage>E1983</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25848029</pub-id></mixed-citation>
    </ref>
    <ref id="r72">
      <label>72</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Martínez-Martínez</surname></string-name><etal/></person-group>, <article-title>Determinants and prediction of esterase substrate promiscuity patterns</article-title>. <source>ACS Chem. Biol.</source><volume><bold>13</bold></volume>, <fpage>225</fpage>–<lpage>234</lpage> (<year>2017</year>).<pub-id pub-id-type="pmid">29182315</pub-id></mixed-citation>
    </ref>
    <ref id="r73">
      <label>73</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Yang</surname></string-name><etal/></person-group>, <article-title>Functional and informatics analysis enables glycosyltransferase activity prediction</article-title>. <source>Nat. Chem. Biol.</source><volume><bold>14</bold></volume>, <fpage>1109</fpage>–<lpage>1117</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30420693</pub-id></mixed-citation>
    </ref>
    <ref id="r74">
      <label>74</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. F.</given-names><surname>Fisher</surname></string-name>, <string-name><given-names>H. M.</given-names><surname>Snodgrass</surname></string-name>, <string-name><given-names>K. A.</given-names><surname>Jones</surname></string-name>, <string-name><given-names>M. C.</given-names><surname>Andorfer</surname></string-name>, <string-name><given-names>J. C.</given-names><surname>Lewis</surname></string-name></person-group>, <article-title>Site-selective C–H halogenation using flavin-dependent halogenases identified via family-wide activity profiling</article-title>. <source>ACS Cent. Sci.</source><volume><bold>5</bold></volume>, <fpage>1844</fpage>–<lpage>1856</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31807686</pub-id></mixed-citation>
    </ref>
    <ref id="r75">
      <label>75</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Bastard</surname></string-name><etal/></person-group>, <article-title>Revealing the hidden functional diversity of an enzyme family</article-title>. <source>Nat. Chem. Biol.</source><volume><bold>10</bold></volume>, <fpage>42</fpage>–<lpage>49</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24240508</pub-id></mixed-citation>
    </ref>
    <ref id="r76">
      <label>76</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Rives</surname></string-name><etal/></person-group>, <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>118</bold></volume>, <fpage>e2016239118</fpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33876751</pub-id></mixed-citation>
    </ref>
    <ref id="r77">
      <label>77</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Rogers</surname></string-name>, <string-name><given-names>M.</given-names><surname>Hahn</surname></string-name></person-group>, <article-title>Extended-connectivity fingerprints</article-title>. <source>J. Chem. Inf. Model.</source><volume><bold>50</bold></volume>, <fpage>742</fpage>–<lpage>754</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20426451</pub-id></mixed-citation>
    </ref>
    <ref id="r78">
      <label>78</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Jaeger</surname></string-name>, <string-name><given-names>S.</given-names><surname>Fulle</surname></string-name>, <string-name><given-names>S.</given-names><surname>Turk</surname></string-name></person-group>, <article-title>Mol2vec: Unsupervised machine learning approach with chemical intuition</article-title>. <source>J. Chem. Inf. Model.</source><volume><bold>58</bold></volume>, <fpage>27</fpage>–<lpage>35</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29268609</pub-id></mixed-citation>
    </ref>
    <ref id="r79">
      <label>79</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>H.</given-names><surname>Wang</surname></string-name><etal/></person-group>, Chemical-reaction-aware molecule representation learning. arXiv [Preprint] (2021). <ext-link xlink:href="http://arxiv.org/abs/2109.09888" ext-link-type="uri">http://arxiv.org/abs/2109.09888</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r80">
      <label>80</label>
      <mixed-citation publication-type="other">X. Glorot, Y. Bengio, “Understanding the difficulty of training deep feedforward neural networks” in <italic toggle="yes">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</italic> (JMLR Workshop and Conference Proceedings, 2010), pp. 249–256.</mixed-citation>
    </ref>
    <ref id="r81">
      <label>81</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Loshchilov</surname></string-name>, <string-name><given-names>F.</given-names><surname>Hutter</surname></string-name></person-group>, Decoupled weight decay regularization. arXiv [Preprint] (2017). <ext-link xlink:href="http://arxiv.org/abs/1711.05101" ext-link-type="uri">http://arxiv.org/abs/1711.05101</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r82">
      <label>82</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Loshchilov</surname></string-name>, <string-name><given-names>F.</given-names><surname>Hutter</surname></string-name></person-group>, SGDR: Stochastic gradient descent with warm restarts. arXiv [Preprint] (2019). <ext-link xlink:href="http://arxiv.org/abs/1608.03983" ext-link-type="uri">http://arxiv.org/abs/1608.03983</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r83">
      <label>83</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>B. D.</given-names><surname>Bryson</surname></string-name>, <string-name><given-names>B. A.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Leveraging uncertainty in machine learning accelerates biological discovery and design</article-title>. <source>Cell Syst.</source><volume><bold>11</bold></volume>, <fpage>461</fpage>–<lpage>477.e9</lpage> (<year>2020</year>).<pub-id pub-id-type="pmid">33065027</pub-id></mixed-citation>
    </ref>
  </ref-list>
  <sec sec-type="supplementary-material" id="s30">
    <title>Supporting Information</title>
  </sec>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archivearticle1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Proc Natl Acad Sci U S A</journal-id>
    <journal-id journal-id-type="iso-abbrev">Proc Natl Acad Sci U S A</journal-id>
    <journal-id journal-id-type="publisher-id">PNAS</journal-id>
    <journal-title-group>
      <journal-title>Proceedings of the National Academy of Sciences of the United States of America</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0027-8424</issn>
    <issn pub-type="epub">1091-6490</issn>
    <publisher>
      <publisher-name>National Academy of Sciences</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10268324</article-id>
    <article-id pub-id-type="pmid">37289807</article-id>
    <article-id pub-id-type="publisher-id">202220778</article-id>
    <article-id pub-id-type="doi">10.1073/pnas.2220778120</article-id>
    <article-categories>
      <subj-group subj-group-type="type">
        <compound-subject>
          <compound-subject-part content-type="code">research-article</compound-subject-part>
          <compound-subject-part content-type="label">Research Article</compound-subject-part>
        </compound-subject>
      </subj-group>
      <subj-group subj-group-type="topic">
        <compound-subject>
          <compound-subject-part content-type="code">biophys-bio</compound-subject-part>
          <compound-subject-part content-type="label">Biophysics and Computational Biology</compound-subject-part>
        </compound-subject>
      </subj-group>
      <subj-group subj-group-type="hwp-journal-coll">
        <subject>408</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Biological Sciences</subject>
        <subj-group>
          <subject>Biophysics and Computational Biology</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Contrastive learning in protein language space predicts interactions between drugs and protein targets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Singh</surname>
          <given-names>Rohit</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>a</sup>
        </xref>
        <xref rid="fn2" ref-type="author-notes">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sledzieski</surname>
          <given-names>Samuel</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>a</sup>
        </xref>
        <xref rid="fn2" ref-type="author-notes">
          <sup>1</sup>
        </xref>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0170-3029</contrib-id>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bryson</surname>
          <given-names>Bryan</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>b</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>c</sup>
        </xref>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1716-6712</contrib-id>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Cowen</surname>
          <given-names>Lenore</given-names>
        </name>
        <email>cowen@cs.tufts.edu</email>
        <xref rid="aff4" ref-type="aff">
          <sup>d</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp">
          <sup>2</sup>
        </xref>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6698-6413</contrib-id>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Berger</surname>
          <given-names>Bonnie</given-names>
        </name>
        <email>bab@mit.edu</email>
        <xref rid="aff1" ref-type="aff">
          <sup>a</sup>
        </xref>
        <xref rid="aff5" ref-type="aff">
          <sup>e</sup>
        </xref>
        <xref rid="cor1" ref-type="corresp">
          <sup>2</sup>
        </xref>
      </contrib>
      <aff id="aff1"><sup>a</sup><institution>Computer Science and Artificial Intelligence Laboratory</institution>, <institution>Massachusetts Institute of Technology</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
      <aff id="aff2"><sup>b</sup><institution>Ragon Institute of MGH</institution>, <institution>MIT and Harvard</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
      <aff id="aff3"><sup>c</sup><institution>Department of Biological Engineering</institution>, <institution>Massachusetts Institute of Technology</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
      <aff id="aff4"><sup>d</sup><institution>Department of Computer Science</institution>, <institution>Tufts University</institution>, <city>Medford</city>, <state>MA</state><postal-code>02155</postal-code></aff>
      <aff id="aff5"><sup>e</sup><institution>Department of Mathematics</institution>, <institution>Massachusetts Institute of Technology</institution>, <city>Cambridge</city>, <state>MA</state><postal-code>02139</postal-code></aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><sup>2</sup>To whom correspondence may be addressed. Email: <email>cowen@cs.tufts.edu</email> or <email>bab@mit.edu</email>.</corresp>
      <fn fn-type="edited-by" id="fn1">
        <p>Edited by Barry Honig, Columbia University, New York, NY; received December 6, 2022; accepted April 10, 2023</p>
      </fn>
      <fn fn-type="equal" id="fn2">
        <p><sup>1</sup>R.S. and S.S. contributed equally to this work.</p>
      </fn>
    </author-notes>
    <pub-date publication-format="electronic" date-type="pub">
      <day>8</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date publication-format="print" date-type="pub">
      <day>13</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>8</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <!--PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.-->
    <volume>120</volume>
    <issue>24</issue>
    <elocation-id>e2220778120</elocation-id>
    <history>
      <date date-type="received">
        <day>06</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 the Author(s). Published by PNAS.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This open access article is distributed under <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND)</ext-link>.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pnas.202220778.pdf"/>
    <abstract abstract-type="executive-summary">
      <title>Significance</title>
      <p>In time and money, one of the most expensive steps of the drug discovery pipeline is the experimental screening of small molecules to determine binding to a protein target of interest. Therefore, accurate high-throughput computational prediction of drug-target interactions would unlock significant value, guiding and prioritizing promising candidates for experimental screening. We introduce ConPLex, a machine learning method for predicting drug-target binding which achieves state-of-the-art accuracy on many types of targets by using a pretrained protein language model. The approach co-locates the proteins and potential drug molecules in a shared feature space while learning to contrast true drugs from similar nonbinding “decoy” molecules. ConPLex is extremely fast, which allows it to rapidly shortlist candidates for deeper investigation.</p>
    </abstract>
    <abstract>
      <p>Sequence-based prediction of drug–target interactions has the potential to accelerate drug discovery by complementing experimental screens. Such computational prediction needs to be generalizable and scalable while remaining sensitive to subtle variations in the inputs. However, current computational techniques fail to simultaneously meet these goals, often sacrificing performance of one to achieve the others. We develop a deep learning model, ConPLex, successfully leveraging the advances in pretrained protein language models (“PLex”) and employing a protein-anchored contrastive coembedding (“Con”) to outperform state-of-the-art approaches. ConPLex achieves high accuracy, broad adaptivity to unseen data, and specificity against decoy compounds. It makes predictions of binding based on the distance between learned representations, enabling predictions at the scale of massive compound libraries and the human proteome. Experimental testing of 19 kinase-drug interaction predictions validated 12 interactions, including four with subnanomolar affinity, plus a strongly binding EPHB1 inhibitor (<italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> = 1.3 nM). Furthermore, ConPLex embeddings are interpretable, which enables us to visualize the drug–target embedding space and use embeddings to characterize the function of human cell-surface proteins. We anticipate that ConPLex will facilitate efficient drug discovery by making highly sensitive in silico drug screening feasible at the genome scale. ConPLex is available open source at <ext-link xlink:href="https://ConPLex.csail.mit.edu" ext-link-type="uri">https://ConPLex.csail.mit.edu</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>drug discovery</kwd>
      <kwd>protein language models</kwd>
      <kwd>contrastive learning</kwd>
      <kwd>drug–target interaction</kwd>
    </kwd-group>
    <funding-group specific-use="FundRef">
      <award-group award-type="grant">
        <funding-source id="sp1">
          <institution-wrap>
            <institution>HHS | National Institutes of Health (NIH)</institution>
            <institution-id institution-id-type="FundRef">100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id rid="sp1">R35GM141861</award-id>
        <principal-award-recipient>Rohit Singh</principal-award-recipient>
        <principal-award-recipient>Bonnie Berger</principal-award-recipient>
      </award-group>
      <award-group award-type="grant">
        <funding-source id="sp2">
          <institution-wrap>
            <institution>National Science Foundation (NSF)</institution>
            <institution-id institution-id-type="FundRef">100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id rid="sp2">CCF-19345533</award-id>
        <principal-award-recipient>Samuel Sledzieski</principal-award-recipient>
        <principal-award-recipient>Lenore J Cowen</principal-award-recipient>
      </award-group>
      <award-group award-type="grant">
        <funding-source id="sp3">
          <institution-wrap>
            <institution>National Science Foundation (NSF)</institution>
            <institution-id institution-id-type="FundRef">100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id rid="sp3">2141064</award-id>
        <principal-award-recipient>Samuel Sledzieski</principal-award-recipient>
        <principal-award-recipient>Lenore J Cowen</principal-award-recipient>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="11"/>
      <word-count count="8461"/>
    </counts>
  </article-meta>
</front>
<body>
  <p content-type="flushleft">In the drug discovery pipeline, a key rate-limiting step is the experimental screening of potential drug molecules against a protein target of interest. Thus, fast and accurate computational prediction of drug–target interactions (DTIs) could be extremely valuable, accelerating the drug discovery process. One important class of computational DTI methods, molecular docking, uses 3D structural representations of both the drug and target. While the recent availability of high-throughput accurate 3D protein structure prediction models (<xref rid="r1" ref-type="bibr">1</xref><xref rid="r2" ref-type="bibr"/>–<xref rid="r3" ref-type="bibr">3</xref>) means that these methods can be employed starting only from a protein’s amino acid sequence, the computational expense of docking (<xref rid="r4" ref-type="bibr">4</xref>) and other structure-based approaches [e.g., rational design (<xref rid="r5" ref-type="bibr">5</xref>), active site modeling (<xref rid="r6" ref-type="bibr">6</xref>), template modeling (<xref rid="r7" ref-type="bibr">7</xref>, <xref rid="r8" ref-type="bibr">8</xref>)] unfortunately remains prohibitive for large-scale DTI screening. An alternative class of DTI prediction methods use 3D structure only implicitly, making rapid DTI predictions when the inputs consist only of a molecular description of the drug [such as the SMILES string (<xref rid="r9" ref-type="bibr">9</xref>)] and the amino acid sequence of the protein target. This class of sequence-based DTI approaches enables scalable DTI prediction, but there have been barriers to matching the levels of accuracy obtained by structure-based approaches.</p>
  <p>In this paper, we introduce ConPLex, a rapid purely sequence-based DTI prediction method that leverages rich featurizations from pretrained protein language models (PLMs) and show that it can produce state-of-the-art performance on the DTI prediction task at scale. The advance provided by ConPLex comes from two main ideas that together overcome some of the limitations of previous approaches: informative PLM-based representations and contrastive learning. While many methods have been proposed for the sequence-based setting of the DTI problem (<xref rid="r10" ref-type="bibr">10</xref>) [e.g., using secure multiparty computation (<xref rid="r11" ref-type="bibr">11</xref>), convolutional neural networks (<xref rid="r12" ref-type="bibr">12</xref>), or transformers (<xref rid="r13" ref-type="bibr">13</xref>)], their protein and drug representations are constructed solely from DTI ground truth data. The high level of diversity among the DTI inputs, combined with the limited availability of DTI training data, limits the accuracy of these methods and their generalizability beyond their training domain. Furthermore, the methods that do generalize often do so by sacrificing fine-grained specificity, i.e., are unable to distinguish true-positive binding compounds from false positives with similar physicochemical properties (“decoys”).</p>
  <p>In contrast, the “PLex” (Pretrained Lexicographic) part of ConPLex helps alleviate the problem of limited DTI training data. As we showed in our preliminary work (<xref rid="r14" ref-type="bibr">14</xref>), one way to get around the limited size of DTI datasets that has hampered the quality of the representations learned by previous methods is to transfer learned proteins representations from pretrained PLMs to the DTI prediction task. PLMs learn the distributional characteristics of amino acid sequences over millions of proteins in an unsupervised fashion, generating sequence-based representations that encode deep structural insights. A design paradigm in machine learning is that an informative featurization of the input can enhance the power of even simple models. For DTI, where task-specific data are limited, using PLM-generated representations as the input features allows us to borrow strength from the much larger corpus of single protein sequences (<xref rid="r14" ref-type="bibr">14</xref>). Starting with the PLMs, our second insight directly addresses the fine-grained specificity problem in our architecture by using the “Con” (Contrastive learning) part: a protein-anchored contrastive coembedding that colocates the proteins and the drugs into a shared latent space. We show that this coembedding enforces separation between true interacting partners and decoys to achieve both broad generalization and high specificity (<xref rid="fig02" ref-type="fig">Fig. 2</xref>).</p>
  <p>Putting these two ideas together gives us ConPLex, a representation learning approach that enables both broad generalization and high specificity. We show that ConPLex enables more accurate prediction of DTIs than competing methods while avoiding many of the pitfalls suffered by currently available approaches. Thus, our work constitutes a concrete demonstration of the power of a well-designed transfer learning approach that adapts foundation models for a specific task (<xref rid="r15" ref-type="bibr">15</xref>, <xref rid="r16" ref-type="bibr">16</xref>). In particular, we found that the performance of existing sequence-based DTI prediction methods could be sensitive to variation in drug-vs-protein coverage in the dataset, whereas ConPLex performs well in multiple coverage regimes. Indeed, ConPLex performs especially well relative to other methods in the zero-shot prediction setting where no information is available about a given protein or drug at training time. Experimental validation of ConPLex yielded a 63% hit rate (12/19), including four hits with subnanomolar binding affinity, demonstrating the value of ConPLex as an accurate, highly scalable, in silico screening tool.</p>
  <p>ConPLex can also be adapted beyond the binary case to make predictions about binding affinity. Furthermore, the shared representation also offers advantages beyond prediction accuracy. The coembedding of both proteins and drugs in the same space offers intepretability, and we show that distances in this space meaningfully reflect protein domain structure and binding function: We leverage ConPLex representations to functionally characterize cell-surface proteins from the Surfaceome database (<xref rid="r17" ref-type="bibr">17</xref>), a set of 2,886 proteins localized to the external plasma membrane that participate in signaling and are likely able to be easily targeted by ligands.</p>
  <p>ConPLex is extremely fast: As a proof of concept, we make predictions for the human proteome against all drugs in ChEMBL (<xref rid="r18" ref-type="bibr">18</xref>) (≊2 ×10<sup>10</sup> pairs) in just under 24 h using a single NVIDIA A100 GPU. Thus, ConPLex has the potential to be applied for tasks which would require prohibitive amounts of computation for purely structure-based approaches or less efficient sequence-based methods, such as genome-scale side-effect screens, identifying drug repurposing candidates via massive compound libraries searches or in silico deep mutational scans to predict variant effects on binding with currently approved or potential new therapeutics. We note that most DTI methods require significant computation on each drug–target pair (i.e., have quadratic time complexity). Because ConPLex predictions rely only on the distance in the shared space, predictions can be made highly efficiently once embeddings (which have linear time complexity) are computed.</p>
  <sec id="s1">
    <title>Distinguishing between Low- and High-Coverage DTI Prediction.</title>
    <p content-type="flushleft">We benchmark performance of ConPLex and competing methods in two different regimes, which we term low-coverage and high-coverage DTI prediction (<xref rid="fig01" ref-type="fig">Fig. 1<italic toggle="yes">C</italic></xref>). We show that ConPLex outperforms its competitors in both settings, but note that separating the two regimes helps clarify an often-seen issue in the field: methods whose performance varies substantially across different proposed DTI benchmarks. Several prior attempts have been made to standardize DTI benchmarking and develop a consistent framework for model evaluation (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r20" ref-type="bibr">20</xref>). However, much of this work has overlooked a key aspect of benchmarking that we find to significantly affect model performance—differing per-biomolecule data coverage. We define coverage as the average proportion of drugs or targets for which a data point exists in that dataset, whether that is a positive or negative interaction (<italic toggle="yes">Methods</italic>). Depending on the per-biomolecule data coverage of the benchmark dataset, we claim that these benchmarks are looking at very different problems. In particular, low-coverage datasets (<xref rid="fig01" ref-type="fig">Fig. 1<italic toggle="yes">A</italic></xref>) tend to measure the broad strokes of the DTI landscape, containing a highly diverse set of drugs and targets. Such datasets can present a modeling challenge due to the diverse nature of targets covered but allow for a broad assessment of compatibility between classes of compounds and proteins. High-coverage datasets (<xref rid="fig01" ref-type="fig">Fig. 1<italic toggle="yes">B</italic></xref>) represent the opposite trade-off: They contain limited diversity in drug or target type but report a dense set of potential pairwise interactions. Thus, they capture the fine-grained details of a specific subclass of drug–target binding and enable distinguishing between similar biomolecules in a particular context.</p>
    <fig position="float" id="fig01" fig-type="featured">
      <label>Fig. 1.</label>
      <caption>
        <p>Drug-target interaction benchmarks display highly variable levels of coverage. Coverage is defined as the proportion of drugs or targets for which a data point (positive or negative) exists in that dataset. High- vs. low-coverage benchmarks tend to reward different types of model performance. (<italic toggle="yes">A</italic>) In this cartoon of an example low coverage dataset, drug candidates cover the full diversity of the space, and no two drugs are highly similar. A successful model can learn a coarse estimate of the fitness landscape, but must accurately model a large part of drug space to generalize to all candidates. (<italic toggle="yes">B</italic>) For high-coverage datasets, drugs tend to be targeted to a specific protein family. Thus, a successful model does not need to generalize nearly as widely but must be able to capture more minor variations in drug fitness to achieve high specificity and differentiate between similar drugs. (<italic toggle="yes">C</italic>) In a review of existing popular DTI benchmark datasets, we find widely varying coverage, from datasets with nearly zero coverage (each drug/target is represented only a few times) to nearly full coverage (all drug-by-target pairs are known in the data).</p>
      </caption>
      <graphic xlink:href="pnas.2220778120fig01" position="float"/>
    </fig>
    <fig position="float" id="fig02" fig-type="figure">
      <label>Fig. 2.</label>
      <caption>
        <p>Outline of the ConPLex model architecture and training framework. ConPLex is trained in two phases, to optimize both generalizability and specificity. (<italic toggle="yes">A</italic>) Protein features are generated using a pretrained PLM [here ProtBert (<xref rid="r27" ref-type="bibr">27</xref>)], and drug features are generated using the Morgan fingerprint (<xref rid="r26" ref-type="bibr">26</xref>). These features are transformed into a shared latent space by a learned nonlinear projection. The prediction of interaction is based on the cosine distance in this space, and the parameters of the transformation are updated using the binary cross-entropy on a low-coverage dataset. (<italic toggle="yes">B</italic>) In the contrastive phase, triplets of a target, drug, and decoy are transformed in the same way into the shared space. Here, the transformation is treated as a metric learning problem. Parameters are updated using the triplet distance loss on a high-coverage dataset (<xref rid="r36" ref-type="bibr">36</xref>) to minimize the target-drug distance while maximizing the target-decoy distance. No additional penalty is applied if the target-decoy distance is greater than the target-drug distance plus some margin. (<italic toggle="yes">C</italic>) ConPLex is trained in alternating epochs of the binary and contrastive phase to simultaneously optimize both objectives. After each round, learning rates and the contrastive margin are updated according to an annealing scheme.</p>
      </caption>
      <graphic xlink:href="pnas.2220778120fig02" position="float"/>
    </fig>
    <p>The two coverage regimes correspond to different usage cases. The low-coverage regime is relevant when applying DTI models for large-scale scans to predict interactions for a potential target against a large compound library [e.g., for drug repurposing as in Dönertaş et al. (<xref rid="r21" ref-type="bibr">21</xref>) and Morselli et al. (<xref rid="r22" ref-type="bibr">22</xref>)] or for scanning a candidate drug against an entire proteome to identify potential adverse and off-target effects [as in Huang et al. (<xref rid="r23" ref-type="bibr">23</xref>, <xref rid="r24" ref-type="bibr">24</xref>)]. Data at this scale are often low coverage, with only a small number of known interactions for each unique biomolecule. Thus, it is important that DTI models used for these tasks are broadly applicable and can accurately generalize to many different families of proteins and drugs. However, this generalization often comes at the cost of specificity, resulting in models that are unable to distinguish between highly similar drugs or proteins.</p>
    <p>The high-coverage regime is relevant when optimizing a particular interaction. Here, models can be trained to be highly specific to a protein family or class of drugs, so much so that a per-drug or per-target model is trained to capture the precise binding dynamics of that biomolecule (<xref rid="r25" ref-type="bibr">25</xref>). While such models can be effective for lead optimization, they require high coverage on the biomolecule of interest to make accurate predictions; this may not always be available. Additionally, such models lack the capacity to generalize beyond the training domain and thus cannot be used for genome- or drug bank-scale prediction.</p>
    <p>The PLM approach of ConPLex enables strong performance in both regimes. In the low coverage regime, the strength is coming mostly from the “PLex” part, where it can leverage the effective generalization of language models to achieve state-of-the-art performance. On high-coverage datasets, the “Con” part also becomes important, since it becomes feasible to train drug- or target-specific models with high accuracy, and such models often outperform more generic models. We find that while single-task models do perform well given available data, ConPLex is able to achieve extremely high specificity in low-diversity, high-coverage scenarios, while remaining broadly applicable to protein targets with limited data. Thus, ConPLex is applicable for both large-scale compound or target screens and fine-grained, highly specific binding prediction. We discuss the issue of matching the right model to the problem domain with respect to coverage further in the <italic toggle="yes">Discussion</italic>.</p>
  </sec>
  <sec sec-type="results" id="s2">
    <title>Results</title>
    <sec id="s3">
      <title>Model Overview.</title>
      <p>To achieve both generalizability and specificity, ConPLex leverages advances in both protein language modeling and metric learning. We start with pretrained representations and learn a nonlinear projection of these representations to a shared space (ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">h</italic></sub></sup>). We guide the learning by alternating between two objectives over multiple iterations: a coarse-grained objective of accurately classifying DTIs and a fine-grained objective of distinguishing decoys from drugs. The coarse-grained objective is evaluated over a low-coverage dataset, which trains the model to distinguish between broad classes of drug and target and makes initial predictions in the right “neighborhood” of the DTI space. The fine-grained objective is evaluated over a high-coverage dataset, which fine-tunes the model to distinguish between true and false positive interactions in the same “neighborhood” and achieve high specificity within a class.</p>
      <p>To featurize the inputs, here, we use the Morgan fingerprint (<xref rid="r26" ref-type="bibr">26</xref>) for small molecules and embeddings from a pretrained ProtBert model (<xref rid="r27" ref-type="bibr">27</xref>) for proteins. We investigate other choices for features, including several other foundation PLMs in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>. We note that our framework is flexible to different methods of featurization and make recommendations on the selection of informative representations in the <italic toggle="yes">Discussion</italic>.</p>
    </sec>
    <sec id="s4">
      <title>ConPLex Achieves State-of-the-Art Performance on Low- Coverage and Zero-Shot Interactions.</title>
      <p>A key advance of ConPLex is the use of pretrained PLMs for protein representation. As foreshadowed by Scaiewicz and Levitt (<xref rid="r28" ref-type="bibr">28</xref>), PLMs have repeatedly been shown to encode evolutionary and structural information (<xref rid="r29" ref-type="bibr">29</xref><xref rid="r30" ref-type="bibr"/>–<xref rid="r31" ref-type="bibr">31</xref>) and to enable broad generalization in low-coverage scenarios (<xref rid="r32" ref-type="bibr">32</xref>, <xref rid="r33" ref-type="bibr">33</xref>). Here, we show that ConPLex achieves state-of-the-art performance on three low-coverage benchmark datasets—<bold>BIOSNAP</bold>, <bold>BindingDB</bold>, and <bold>DAVIS</bold>—where it is important to learn the broad strokes of the DTI landscape. In <xref rid="t01" ref-type="table">Table 1</xref>, we show the average area under the precision–recall curve (AUPR) over five random initializations of each model evaluated on a held-out test set (<italic toggle="yes">Methods</italic>). Here, we compare with several methods which use non-PLM protein features: MolTrans (<xref rid="r13" ref-type="bibr">13</xref>), GNN-CPI (<xref rid="r34" ref-type="bibr">34</xref>), and DeepConv-DTI (<xref rid="r12" ref-type="bibr">12</xref>). In addition, we compare to the EnzPred-CPI model from Goldman et al. (<xref rid="r25" ref-type="bibr">25</xref>) (developed simultaneously and independently), which uses a PLM for protein featurization but does not perform a coembedding or utilize a contrastive training step. Finally, we compare with the single-task Ridge regression model described in ref. <xref rid="r25" ref-type="bibr">25</xref>, which trains a different model per drug rather than a single model for the entire benchmark.</p>
      <table-wrap position="float" id="t01">
        <label>Table 1.</label>
        <caption>
          <p>ConPLex is highly accurate and generalizes broadly in low coverage settings</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Dataset</th>
              <th align="center" rowspan="1" colspan="1">ConPLex</th>
              <th align="center" rowspan="1" colspan="1">EnzPred-CPI</th>
              <th align="center" rowspan="1" colspan="1">MolTrans</th>
              <th align="center" rowspan="1" colspan="1">GNN-CPI†</th>
              <th align="center" rowspan="1" colspan="1">DeepConv-DTI†</th>
              <th align="center" rowspan="1" colspan="1">Ridge</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">BIOSNAP</td>
              <td align="center" rowspan="1" colspan="1">0.897 ± 0.001</td>
              <td align="center" rowspan="1" colspan="1">0.866 ± 0.003</td>
              <td align="center" rowspan="1" colspan="1">0.885 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">0.890 ± 0.004</td>
              <td align="center" rowspan="1" colspan="1">0.889 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">0.641 ± 0.000</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BindingDB</td>
              <td align="center" rowspan="1" colspan="1">0.628 ± 0.012</td>
              <td align="center" rowspan="1" colspan="1">0.602 ± 0.006</td>
              <td align="center" rowspan="1" colspan="1">0.598 ± 0.013</td>
              <td align="center" rowspan="1" colspan="1">0.578 ± 0.015</td>
              <td align="center" rowspan="1" colspan="1">0.611 ± 0.015</td>
              <td align="center" rowspan="1" colspan="1">0.516 ± 0.000</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DAVIS</td>
              <td align="center" rowspan="1" colspan="1">0.458 ± 0.016</td>
              <td align="center" rowspan="1" colspan="1">0.277 ± 0.009</td>
              <td align="center" rowspan="1" colspan="1">0.335 ± 0.017</td>
              <td align="center" rowspan="1" colspan="1">0.269 ± 0.020</td>
              <td align="center" rowspan="1" colspan="1">0.299 ± 0.039</td>
              <td align="center" rowspan="1" colspan="1">0.320 ± 0.000</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Unseen Drugs</td>
              <td align="center" rowspan="1" colspan="1">0.874 ± 0.002</td>
              <td align="center" rowspan="1" colspan="1">0.844 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">0.863 ± 0.005</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.847 ± 0.009</td>
              <td align="center" rowspan="1" colspan="1">N/A</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Unseen Targets</td>
              <td align="center" rowspan="1" colspan="1">0.842 ± 0.006</td>
              <td align="center" rowspan="1" colspan="1">0.795 ± 0.004</td>
              <td align="center" rowspan="1" colspan="1">0.668 ± 0.045</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.766 ± 0.022</td>
              <td align="center" rowspan="1" colspan="1">0.617 ± 0.000</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>ConPLex outperforms several state-of-the-art methods, including EnzPred-CPI (<xref rid="r25" ref-type="bibr">25</xref>), MolTrans (<xref rid="r13" ref-type="bibr">13</xref>), GNN-CPI (<xref rid="r34" ref-type="bibr">34</xref>), and DeepConv-DTI (<xref rid="r12" ref-type="bibr">12</xref>), as well as a simple single-target Ridge regression model, on several low- and zero- coverage benchmark datasets. We report the average and SD of the area under the precision–recall curve (AUPR) for 5 random initializations of each model. Metrics for models with † are taken from ref. <xref rid="r13" ref-type="bibr">13</xref>. Ridge regression cannot be applied for the <bold>Unseen Drugs</bold> dataset since a separate model is trained for each drug in the training set.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Observing the strength of ConPLex to generalize on low-coverage data, we sought to evaluate its performance on fully zero-shot prediction. <bold>Unseen drugs</bold> and <bold>Unseen targets</bold> are variants of the BIOSNAP dataset where drugs/targets in the test set do not appear in any interactions in the training set (<italic toggle="yes">Methods</italic>). Note that for the unseen drugs setting, the Ridge model cannot be applied since a different model must be trained for each drug that appears in the training set. We show that ConPLex achieves the best zero-shot prediction performance (<xref rid="t01" ref-type="table">Table 1</xref>), further demonstrating the applicability of the model to large-scale, very low-coverage prediction tasks.</p>
    </sec>
    <sec id="s5">
      <title>Contrastive Learning Enables High-Specificity DTI Mapping.</title>
      <p>Another key advance of our method is the use of contrastive learning to fine-tune model predictions on high-coverage data to achieve high specificity. Recently, Heinzinger et al. (<xref rid="r35" ref-type="bibr">35</xref>) demonstrated the use of semisupervised contrastive learning for effective protein embedding-based annotation transfer. Here, we adapt contrastive learning to a fully supervised setting and demonstrate that the contrastive training is essential to achieving specificity using DTI pairs from the Database of Useful Decoys (<bold>DUD-E</bold>) (<xref rid="r36" ref-type="bibr">36</xref>). The DUD-E dataset contains 57 protein targets and drugs which are known to interact with each target. However, it also contains 50 negative “decoy” small molecules for each drug, which have similar physicochemical properties to the truly interacting small molecule but are known to not bind the target. Thus, accurate prediction on DUD-E requires a model to achieve high specificity and to accurately differentiate between highly similar compounds. Additionally, DUD-E contains four different classes of targets—G-protein-coupled receptors (GPCRs), kinases, proteases, and nucleases—so models must generalize across target classes (note that single task models do not have this generalization requirement since a different model is trained per target).</p>
      <p>We derive evaluation sets from DUD-E by holding out 50% of proteins in each target class for testing and using the remaining targets for training (full splits are specified in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S1</ext-link>). Here, we evaluate a ConPLex model trained on BIOSNAP, both with and without contrastive training on DUD-E, and show that contrastive training is essential to achieving specificity on decoys.</p>
      <p>For each target in the DUD-E test set, we use t-SNE to visualize the target alongside all drugs and decoys using embeddings learned by both versions of the model. <xref rid="fig03" ref-type="fig">Fig. 3 <italic toggle="yes">A</italic> and <italic toggle="yes">B</italic></xref> shows one such example, the tyrosine kinase <italic toggle="yes">VGFR2</italic>. We also show the distribution of distances in the latent space between the target embedding and the embeddings of the drugs and decoys for each model (<xref rid="fig03" ref-type="fig">Fig. 3 <italic toggle="yes">C</italic> and <italic toggle="yes">D</italic></xref>) (<italic toggle="yes">P</italic>-values from the one-sided <italic toggle="yes">t</italic> test). Without contrastive training, drugs are interspersed with decoys and are far away in space from the target, while ConPLex clusters most true drugs very close to both each other and the <italic toggle="yes">VGFR2</italic> embedding.</p>
      <fig position="float" id="fig03" fig-type="figure">
        <label>Fig. 3.</label>
        <caption>
          <p>Contrastive training enables high specificity in discriminating drugs from decoys. We demonstrate that contrastive learning is essential for ConPLex to achieve high specificity using the DUD-E (<xref rid="r36" ref-type="bibr">36</xref>) dataset of drugs and decoys (nonbinding small molecules with similar physicochemical properties to the true drugs). (<italic toggle="yes">A</italic> and <italic toggle="yes">B</italic>) Using t-SNE, we show the learned ConPLex latent space for <italic toggle="yes">VGFR2</italic> (green) and known drugs (blue) and decoys (gray). Without contrastive training, drug and decoy representations do not separate, and true drugs are far from their target. With contrastive training, VGFR2 and drugs cluster very tightly compared to decoys. (<italic toggle="yes">C</italic> and <italic toggle="yes">D</italic>) ConPLex predictions significantly differentiate between drugs and decoys after contrastive training (<italic toggle="yes">P</italic> = 0.000 paired <italic toggle="yes">t</italic> test) but do not differ at all without such training (<italic toggle="yes">P</italic> = 0.999). (<italic toggle="yes">E</italic>) We compute the effect size between drug and decoy predictions using Cohen’s <italic toggle="yes">d</italic> for all 31 targets in the test set. Targets are classified as proteases (green), GPCRs (orange), kinases (blue), and nuclear proteins (red). This effect is computed for ConPLex both with and without contrastive training. Contrastive training increases the effect size for every target (median 0.730 vs. 4.716). For each class, we report the median <italic toggle="yes">P</italic>-value for ConPLex drug vs. decoy predictions. ConPLex performs particularly well for kinases and nuclear proteins and more poorly for GPCRs.</p>
        </caption>
        <graphic xlink:href="pnas.2220778120fig03" position="float"/>
      </fig>
      <p>In <xref rid="fig03" ref-type="fig">Fig. 3<italic toggle="yes">E</italic></xref>, we show a quantitative analysis of all 31 test-set targets. We compute the effect size (Cohen’s <italic toggle="yes">d</italic>) of the difference between predicted drug and decoy scores. We plot these effect sizes for ConPLex trained with and without contrastive training. An increase in the effect size indicates that the coembedding distances learned by the model better represent binding specificity. The effect size increases for every target, and the median effect size between predicted true and decoy compound scores was 0.730 prior to contrastive training compared to 4.716 after. For each class of targets, we also report the median <italic toggle="yes">P</italic>-value (one-sided <italic toggle="yes">t</italic> test) between drug and decoy scores predicted by ConPLex. While contrastive training has an extremely large impact on specificity in high-coverage domains, we also show that this additional training does not significantly decrease the model performance on low-coverage benchmarks via an ablation study in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S3</ext-link>.</p>
      <p>In addition to evaluation on DUD-E, we also evaluate ConPLex on five benchmark datasets derived from family-specific enzyme–substrate screens (<italic toggle="yes">Methods</italic>). These datasets are extremely high coverage, generally including data points for all possible pairs of drugs and targets. We find that in this regime, ConPLex and other PLM-based models like EnzPred-CPI have strong but highly variable performance and are still generally outperformed by a Ridge regression model (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S5</ext-link>) as shown previously in ref. <xref rid="r25" ref-type="bibr">25</xref>. However, a fine-scale single-task model is limited in its generalizability beyond the enzyme family on which it was trained (<italic toggle="yes">Discussion</italic>).</p>
    </sec>
    <sec id="s6">
      <title>ConPLex Discovers DTIs with Subnanomolar Binding Affinity.</title>
      <p>Since ConPLex exhibited strong performance on several benchmark datasets, we next sought to experimentally validate predictions using an in vitro biochemical binding assay. We selected 51 kinases from the Surfaceome database (<xref rid="r17" ref-type="bibr">17</xref>) with commercially available assays from the DiscoveryX company and used ConPLex to scan against a set of 4715 compounds from the ZINC database (<xref rid="r37" ref-type="bibr">37</xref>) purchasable from the Cayman Chemical Company (<italic toggle="yes">Methods</italic>) (<xref rid="r38" ref-type="bibr">38</xref>). We selected 19 interactions spanning 5 kinases and 14 compounds in an unbiased manner. (These pairs were chosen based solely on top scoring ConPLex predictions, without any use of prior knowledge from experimental results or in the literature.) We determined <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values for each of the 19 interactions (<xref rid="t02" ref-type="table">Table 2</xref>), finding that 12/19 pairs tested had <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values less than 100 nM. Of these, four bound with subnanomolar affinity, all of which recapitulate known interactions in the literature. Weglicki et al. identified AG-1478 as an <italic toggle="yes">EGFR</italic> inhibitor but noted that its therapeutic use may be limited due to triggering hypomagnesemia and cardiac dysfunction (<xref rid="r39" ref-type="bibr">39</xref>). Sordella et al. (<xref rid="r40" ref-type="bibr">40</xref>) described the downstream impact in lung cancer when Gefitinib inhibits <italic toggle="yes">EGFR</italic>. In a review of Nintedanib discovery, Roth et al. (<xref rid="r41" ref-type="bibr">41</xref>) noted it as an <italic toggle="yes">FLT3</italic> inhibitor, and Wang et al. (<xref rid="r42" ref-type="bibr">42</xref>) described Linifanib inhibition of <italic toggle="yes">FLT3</italic>.</p>
      <table-wrap position="float" id="t02">
        <label>Table 2.</label>
        <caption>
          <p>We selected and tested 19 potential binding interactions, where the selection of tests was done based solely on ConPLex-predicted interaction and without consulting previous experiments or literature</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">EGFR</th>
              <th align="center" rowspan="1" colspan="1">EPHB1</th>
              <th align="center" rowspan="1" colspan="1">FLT3</th>
              <th align="center" rowspan="1" colspan="1">KIT</th>
              <th align="center" rowspan="1" colspan="1">TGFBR2</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">AG-1478</td>
              <td align="center" rowspan="1" colspan="1">0.33<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Gefitinib</td>
              <td align="center" rowspan="1" colspan="1">0.60<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Janex 1</td>
              <td align="center" rowspan="1" colspan="1">26.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SB-431542</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AG-1296</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">62.00</td>
              <td align="center" rowspan="1" colspan="1">27.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ZM 447439</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">PD-166326</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">
                <bold>1.30</bold>
              </td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Nintedanib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.17<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Linifanib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">0.72<sup>*</sup></td>
              <td align="center" rowspan="1" colspan="1">1.70</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Sorafenib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">7.20</td>
              <td align="center" rowspan="1" colspan="1">36.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Imatinib</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">6.00</td>
              <td align="center" rowspan="1" colspan="1">–</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Wortmannin</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Pluripotin</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Monorden</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">–</td>
              <td align="center" rowspan="1" colspan="1">&gt;1e4</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>We determined the <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values for each interaction via an in vitro biochemical assay (<italic toggle="yes">Methods</italic>), and we show here the <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> in nM units. Twelve exhibited binding affinity in the nanomolar range, including four (denoted with <bold>*</bold>) binding with subnanomolar affinity. The only target for which we incorrectly predicted there would be hits was <italic toggle="yes">TGFBR2</italic>, which has no known inhibitors in PKIDB (<xref rid="r47" ref-type="bibr">47</xref>), suggesting that it may be difficult to target. We recapitulate several known interactions (<italic toggle="yes">Results</italic>) and find a tightly binding interaction between <italic toggle="yes">EPHB1</italic> and <italic toggle="yes">PD 166326</italic> (<bold>bold</bold>), which to our knowledge has not been previously characterized.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We also identify an interaction between <italic toggle="yes">EPHB1</italic> and PD-166326 with nearly subnanomolar affinity (<italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> = 1.30). Wolff et al. (<xref rid="r43" ref-type="bibr">43</xref>) previously identified PD-166326 as a tyrosine-kinase inhibitor but did not report any binding to <italic toggle="yes">EPHB1</italic>, and DrugBank (<xref rid="r44" ref-type="bibr">44</xref>) lists only <italic toggle="yes">ABL1</italic> as a known target (DrugBank ID: DB08339). <italic toggle="yes">EPHB1</italic> has been implicated in chronic pain (<xref rid="r45" ref-type="bibr">45</xref>, <xref rid="r46" ref-type="bibr">46</xref>); at the time of publication, there are no known inhibitors of <italic toggle="yes">EPHB1</italic> listed in the Protein Kinase Inhibitor Database (PKIDB) (<xref rid="r47" ref-type="bibr">47</xref>), and our findings indicate that PD-166326 may act as a binder to <italic toggle="yes">EPHB1</italic>. Future work could involve further characterization of this interaction, its impact on <italic toggle="yes">EPHB1</italic> function, and possible therapeutic outcomes. In <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">B</italic></xref>, we show that PD-166326 is the only compound from our screen close to <italic toggle="yes">EPHB1</italic> in coembedding space.</p>
      <fig position="float" id="fig04" fig-type="figure">
        <label>Fig. 4.</label>
        <caption>
          <p>The shared representation space learned by ConPLex captures DTI and protein function. (<italic toggle="yes">A</italic>) We show that 51 kinases from the Surfaceome (<xref rid="r17" ref-type="bibr">17</xref>) database cluster together in ConPLex embedding space but occupy just a small section of the entire space when coembedded with the compounds from the ZINC (<xref rid="r37" ref-type="bibr">37</xref>) Cayman-purchasable library. (<italic toggle="yes">B</italic> and <italic toggle="yes">C</italic>) Zooming in on the full embedding space highlights drug–target pairs chose for experimental validation. <italic toggle="yes">EPHB1</italic> has only a single compound nearby in embedding space, PD-166326, which was confirmed to bind with single-digit nanomolar affinity. <italic toggle="yes">FLT3</italic> and <italic toggle="yes">KIT</italic> are neighbors in embedding space and tightly bind many of the same compounds; both bind to Linifanib with &lt; 2<italic toggle="yes">n</italic><italic toggle="yes">M</italic> affinity. <italic toggle="yes">EGFR</italic> was not found to bind to any of the compounds also tested with <italic toggle="yes">FLT3</italic> and <italic toggle="yes">KIT</italic> but binds three other drugs nearby in the embedding space, two of which bind with subnanomolar affinity. On the other hand, none of the three compounds we tested nearby <italic toggle="yes">TGFBR2</italic> (Wortmannin, Pluripotin, and Monorden) were found to bind. (<italic toggle="yes">D</italic>) ConPLex representations of all cell surface proteins from the Surfaceome (<xref rid="r17" ref-type="bibr">17</xref>) cluster by functional class as assigned in Almén et al. (<xref rid="r49" ref-type="bibr">49</xref>). (<italic toggle="yes">E</italic>) These representations also cluster by several functional Pfam domains (<xref rid="r50" ref-type="bibr">50</xref>), such as the PKinase domain (PF00069) shown in blue. (<italic toggle="yes">F</italic>) We evaluated the coherence of representations for each domain by training a logistic regression classifier and report the model’s average confidence for proteins containing that domain as <inline-formula><mml:math id="i2" display="inline" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. ConPLex separates all 126 domains better than the untransformed ProtBert embeddings (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S6</ext-link>, <italic toggle="yes">P</italic> = 4.85 × 10<sup>−54</sup>, paired <italic toggle="yes">t</italic> test), discriminating kinase domains (blue) especially well. We have also highlighted other classes of domains, including cadherins (green), 7-transmembrane proteins (orange), and immunoglobulins (red).</p>
        </caption>
        <graphic xlink:href="pnas.2220778120fig04" position="float"/>
      </fig>
      <p>Notably, all three of the compounds that we predicted to interact with <italic toggle="yes">TGFBR2</italic> were false positives (Wortmannin, Pluripotin, and Monorden). Despite its significance in cancer signaling (<xref rid="r48" ref-type="bibr">48</xref>), there are no known inhibitors of <italic toggle="yes">TGFBR2</italic> in PKIDB, suggesting that it may be difficult to target via small-molecule drugs.</p>
      <p>Additionally, we found that ConPLex predictions were well calibrated. Using varying thresholds, we can compute a precision–recall curve (over 19 data points, AUPR = 0.91). For high-precision screening, we recommend using a ConPLex-predicted threshold of 0.923 (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S7</ext-link>).</p>
    </sec>
    <sec id="s7">
      <title>Incorporating Drug Binding Information Improves Protein Representations.</title>
      <p>One of the advantages of the coembedding approach that our model takes is the ability to visualize and investigate the shared embedding space. For instance, we show in <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">A</italic></xref>–<italic toggle="yes">C</italic> that kinases and their inhibitors tend to colocalize within the space. Seeking to expand our analysis, we subsequently mapped all 2,716 predicted surface proteins from the Surfaceome database into ConPLex embedding space and investigated their representations. In <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">D</italic></xref>, we show the projections all Surfaceome proteins, colored by their classification into one of five functional categories [from Almén et al. (<xref rid="r49" ref-type="bibr">49</xref>)]—transporters, receptors, enzymes, miscellaneous, and those that are unclassified. ConPLex projections of surface proteins cluster in embedding space by functional type, with transporters and receptors especially separating from other classes.</p>
      <p>However, the Almén functional classification is quite broad and may group proteins with vastly different functions and binding properties. We further demonstrate the link between ConPLex projections and protein function, by evaluating how the learned DTI embedding space separates proteins by domains contained therein. We identified Pfam domains (<xref rid="r50" ref-type="bibr">50</xref>) for each protein in the Surfaceome database using HMMscan (<xref rid="r51" ref-type="bibr">51</xref>) and compared the projections of proteins that share the same domains. We identified 780 unique domains across all proteins, of which 126 domains were represented in at least 10 proteins. To quantitatively evaluate the coherence of ConPLex embeddings, we trained separate logistic regression classifiers for each domain to separate proteins with that domain from others and used the model’s confidence (<inline-formula><mml:math id="i1" display="inline" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>) for in-sample proteins as a measure of separation for the domain. We find that for all 126 domains, the model more confidently discriminated domains when trained on ConPLex representations than the baseline ProtBert embeddings.</p>
      <p><xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">F</italic></xref> shows the change in confidence scores for all 126 domains, where the dotted line represents equal confidence using either ConPLex or ProtBert. We find that prediction of all domains was improved using ConPlex. However, proteins with kinase domains (PF14575, PF01404, PF00069, and PF07714) separated especially well, whereas 7-transmembrane (7TM) domains characteristic of GPCRs (PF00001, PF00002, PF00003, and PF13853) showed more modest improvement (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S6</ext-link>). In <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">E</italic></xref>, we show the same visualization of projections as in <xref rid="fig04" ref-type="fig">Fig. 4<italic toggle="yes">D</italic></xref> but colored by another top-differentiated domain, PKinase (PF00069). As discussed previously, ConPLex was trained contrastively with several kinase targets and excels at kinase prediction on DUD-E (<xref rid="fig03" ref-type="fig">Fig. 3<italic toggle="yes">E</italic></xref>), so it is unsurprising that proteins with these domains separate well. In fact, one of the top differentiated domains is the Ephrin ligand binding domain (PF01404), which is responsible for binding to the ephrin ligand (<xref rid="r52" ref-type="bibr">52</xref>). While the model was also trained contrastively with 7TM GPCR targets, many fewer training data samples were available. In addition to the dearth of training examples, GPCRs are less soluble than kinases and tend to exhibit more dynamic behavior—all of which contribute to difficulty predicting ligand binding. Future work in this area might adjust distances in this landscape to account for the low metric entropy of biological sequences, as demonstrated by Berger et al. (<xref rid="r53" ref-type="bibr">53</xref>).</p>
    </sec>
    <sec id="s8">
      <title>Adapting ConPLex for Affinity Prediction.</title>
      <p>While we have to this point been using the model to predict probabilities of interaction and perform binary classification, we show that ConPLex can be easily adapted to perform binding affinity prediction and that this model too achieves state-of-the-art performance. The final step of our binary interaction predictor is converting the cosine distance between the projections in the DTI space to a probability using a sigmoid activation (<italic toggle="yes">Methods</italic>). However, it is completely natural to replace this activation with a dot product between the two projections, which enables the model to make real-valued predictions, which can then be interpreted as a binding affinity. We evaluated ConPLex trained for affinity prediction on the Therapeautics Data Commons (TDC) DTI Domain Generalization (<bold>TDC-DG</bold>) benchmark. The TDC-DG benchmark contains binding affinity (<italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>) data from interactions patented between 2013 and 2018, with the test set drawn from interactions patented in 2019 and 2021 (<italic toggle="yes">Methods</italic>). Thus, these data require out-of-domain generalization and correspond to the real-life scenario of training on interactions up to a known point and predicting interactions which are yet to be documented. We trained ConPLex to predict binding affinity with five random train/validation splits and achieve an average Pearson correlation (PCC) coefficient between the true and predicted affinity of 0.538(±0.008) on the held-out test set. At submission, ConPLex is the top-performing method on the TDC-DG benchmark on TDC (<xref rid="t03" ref-type="table">Table 3</xref>).</p>
      <table-wrap position="float" id="t03">
        <label>Table 3.</label>
        <caption>
          <p>ConPLex can be adapted for state-of-the-art affinity prediction</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Model</th>
              <th align="center" rowspan="1" colspan="1">PCC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">ConPLex</td>
              <td align="center" rowspan="1" colspan="1">0.538 ± 0.008</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">MMD</td>
              <td align="center" rowspan="1" colspan="1">0.433 ± 0.010</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">CORAL</td>
              <td align="center" rowspan="1" colspan="1">0.432 ± 0.010</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ERM</td>
              <td align="center" rowspan="1" colspan="1">0.427 ± 0.012</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">MTL</td>
              <td align="center" rowspan="1" colspan="1">0.425 ± 0.010</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GroupDRO</td>
              <td align="center" rowspan="1" colspan="1">0.384 ± 0.006</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AndMASK</td>
              <td align="center" rowspan="1" colspan="1">0.288 ± 0.019</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">IRM</td>
              <td align="center" rowspan="1" colspan="1">0.284 ± 0.021</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>By replacing the cosine distance in the final step of ConPLex with a dot product between the projections, ConPLex can be used for affinity prediction rather than binary classification. The TDC-DG dataset contains <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub> values for patented drug–target pairs, where training/testing data are split from before/after 2018. We report the average and SD of the PCC coefficient between true and predicted values across five train/validation splits. Metrics for all methods other than ConPLex come from the TDC leaderboard (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r58" ref-type="bibr">58</xref>), where at the time of submission, ConPLex is the best-performing method.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To investigate the strengths and limitations of ConPLex for affinity prediction, we evaluated performance by target type. Targets were annotated with Pfam domains (<xref rid="r50" ref-type="bibr">50</xref>) using HMMscan (<xref rid="r51" ref-type="bibr">51</xref>), and the PCC between predicted and true <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub> was computed over targets in each family (full details <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S8</ext-link>). We observed especially strong performance on 12 immunoglobulin targets (Pfam domains PF13927, PF13895, PF07679, PF00047), where we observed a PCC of 0.803. In keeping with our previous finding of ConPLex’s relative strength on kinases over GPCRs (<xref rid="fig03" ref-type="fig">Fig. 3<italic toggle="yes">E</italic></xref>), we observed a correlation of 0.578 on 94 protein targets with PKinase domains (PF07714, PF00069), including targets with SH3 domains (PF00018, PF07653; 13 targets; PCC = 0.705) and PI3K domains (PF00613, PF00792; 6 targets; PCC = 0.633). However, we observed substantially weaker performance on 7TM domains (PF00001; 14 targets; PCC = 0.254) and GPCR domains (PF10320; 8 targets; PCC = 0.176). To assess ConPLex’s variability in its accuracy, we computed a 95% prediction interval based on a linear regression between the true and predicted <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub> (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S8</ext-link>). While the correlations were strong, we found substantial variability around the true <italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>, with the width of the prediction interval around the true <italic toggle="yes">l</italic><italic toggle="yes">n</italic>(<italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>) being ±4.89 <italic toggle="yes">l</italic><italic toggle="yes">n</italic>(<italic toggle="yes">n</italic><italic toggle="yes">M</italic>). Altogether, the variability in ConPLex’s performance across domains makes it important to understand the target of interest when using ConPLex to predict binding affinity.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s9">
    <title>Discussion</title>
    <p content-type="flushleft">Much previous work has recognized the value of meaningful drug representations (<xref rid="r54" ref-type="bibr">54</xref>, <xref rid="r55" ref-type="bibr">55</xref>) for DTI prediction, yet relatively little work has focused on the target protein representation. As a method to use pretrained PLMs for DTI prediction, ConPLex is yet another example of the power of transferring learned representations for biology (<xref rid="r13" ref-type="bibr">13</xref>, <xref rid="r31" ref-type="bibr">31</xref>, <xref rid="r32" ref-type="bibr">32</xref>, <xref rid="r56" ref-type="bibr">56</xref>, <xref rid="r57" ref-type="bibr">57</xref>). This approach enables broad generalization to unseen proteins as well as extremely fast model inference (&gt; 10× speed-up even over other sequence-based approaches <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S4</ext-link>). This speed is particularly valuable for drug repurposing and iterative screening, where large compound libraries are evaluated against hitherto-uncharacterized proteins implicated in a disease of interest. The coembedding approach which enables this speedup could also be effective for integrative multistructure models [e.g., the IMP framework (<xref rid="r59" ref-type="bibr">59</xref>)] where efficient scanning of possible combinations is important. Recent methods have also demonstrated the power of PLMs for transferring knowledge between species (<xref rid="r32" ref-type="bibr">32</xref>), and our framework may enable more accurate transfer of DTI from the model organisms on which drugs are initially tested, to their eventual use in human patients. Skolnick and Zhou (<xref rid="r60" ref-type="bibr">60</xref>) have reported the importance of considering small molecule binding pockets for protein–protein interaction prediction; thus, our DTI-informed protein representations may also be useful in that context. While structural similarity is often implicitly learned by PLMs, future work could explicitly incorporate structure where such data are available, perhaps by incorporating a more advanced projection architecture like the Geoformer (<xref rid="r3" ref-type="bibr">3</xref>).</p>
    <p>It has been shown in previous work that the performance of different PLMs varies on different tasks and that there is not one clearly “best” language model (<xref rid="r14" ref-type="bibr">14</xref>, <xref rid="r61" ref-type="bibr">61</xref>, <xref rid="r62" ref-type="bibr">62</xref>). While we have chosen to use ProtBert here, it is likely that other existing or newly developed language models may yield better performance for certain types of drugs or targets. Likewise, advancements in drug representation may improve performance—the ConPLex framework is flexible to different input features, and it remains important to experiment with different feature choices for the task at hand (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>).</p>
    <p>ConPLex approaches the DTI decoy problem from the perspective of adversarial machine learning, where the model must act as a discriminator for adversarial examples from the decoy database. This approach is directly enabled by the coembedding architecture—to compute the triplet distance loss, the protein and drugs must be coembedded, and the distance between them must be meaningful and simply computed. Such an approach would not be feasible using a model which concatenates features up front, nor for a model which has significant computation defining the probability of interaction after the coembedding. Thus, the shared lexicographic space in which we embed the proteins, targets, and decoys is key. Future work could explore adapting molecular generation methods such as JT-VAE or HierG2G (<xref rid="r63" ref-type="bibr">63</xref>, <xref rid="r64" ref-type="bibr">64</xref>) to directly act as a generator for decoys. High-specificity DTI prediction is valuable beyond decoy detection—greater specificity of inference can help improve personalized medicine or the modeling of drug effects against rare variants from underrepresented populations.</p>
    <p>It is also important to consider the coverage of the problem to select an appropriate method. While we recommend the use of PLM-based features in all cases, if enough data are available, for specific enzyme-family prediction tasks, we still recommend the use of single-task models (<xref rid="r25" ref-type="bibr">25</xref>). To verify individual interactions, energy-based molecular docking will likely be more accurate, although at the cost of being substantially slower (<xref rid="r4" ref-type="bibr">4</xref>). Different classes of computational tools for DTI prediction each have varying strengths, and the highest quality predictions can be achieved by leveraging all of these methods together where each is most fit.</p>
    <p>Drug discovery is a fundamental task for human health yet remains both extremely expensive and time consuming, with the median drug requiring over 1 billion dollars (<xref rid="r65" ref-type="bibr">65</xref>) and 10 y (<xref rid="r66" ref-type="bibr">66</xref>) from development to approval and distribution. While experimental results will remain the gold standard for validating drug functionality, in silico prediction of drug–target binding remains much faster and cheaper and so will continue to play an important role in early screening of therapeutic candidates (<xref rid="r67" ref-type="bibr">67</xref>). To address this step in the drug design pipeline, we have introduced ConPLex. DTI prediction methods should be able to generalize to unseen types of drugs and targets, while also discriminating between highly similar molecules with different binding properties. ConPLex tackles both of these challenges through its dual use of PLMs and contrastive learning. We hope that its broad applicability, specificity on decoys, and ability to scale to massive data will allow ConPLex to be a critical step in this pipeline and contribute to the efficient discovery of effective therapeutics.</p>
  </sec>
  <sec sec-type="materials|methods" id="s10">
    <title>Materials and Methods</title>
    <sec id="s11">
      <title>Computing Dataset Coverage.</title>
      <p>Let 1<sub>(<italic toggle="yes">i</italic>, <italic toggle="yes">j</italic>)</sub> be the indicator variable, meaning there exists an observation of drug <italic toggle="yes">i</italic> and target <italic toggle="yes">j</italic>. For a dataset with <italic toggle="yes">m</italic> unique drugs and <italic toggle="yes">n</italic> unique targets, we can define the coverage for drug <italic toggle="yes">d</italic> as <inline-formula><mml:math id="i3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mspace width="3.33333pt"/><mml:mo>=</mml:mo><mml:mspace width="3.33333pt"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and for a target <italic toggle="yes">t</italic> as <inline-formula><mml:math id="i4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Then, for a given dataset, we can evaluate the median drug and target coverage. A dataset with maximum coverage would have a single data point for each drug–target pair and, thus, a median coverage of 1 for both drugs and targets. Conversely, each drug and target would be represented only a single time in a minimum coverage dataset, resulting in drug and target coverages of <inline-formula><mml:math id="i5" display="inline" overflow="scroll"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="i6" display="inline" overflow="scroll"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:math></inline-formula>, respectively. We report the median drug and target coverage for each benchmark dataset in <xref rid="t04" ref-type="table">Table 4</xref>. Since the DUD-E dataset is separated out by targets, we instead report the median number of drugs against each target.</p>
      <table-wrap position="float" id="t04">
        <label>Table 4.</label>
        <caption>
          <p>Full specification of benchmark datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Dataset</th>
              <th align="center" rowspan="1" colspan="1">Drugs</th>
              <th align="center" rowspan="1" colspan="1">Targets</th>
              <th align="center" rowspan="1" colspan="1">Median Coverage</th>
              <th align="center" rowspan="1" colspan="1"># Training</th>
              <th align="center" rowspan="1" colspan="1"># Validation</th>
              <th align="center" rowspan="1" colspan="1"># Test</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">BIOSNAP</td>
              <td align="center" rowspan="1" colspan="1">4,510</td>
              <td align="center" rowspan="1" colspan="1">2,181</td>
              <td align="center" rowspan="1" colspan="1">0.0023/0.0020</td>
              <td align="center" rowspan="1" colspan="1">9,670/9,568</td>
              <td align="center" rowspan="1" colspan="1">1,396/1,352</td>
              <td align="center" rowspan="1" colspan="1">2,770/2,727</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Unseen Drugs</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">9,535/9,616</td>
              <td align="center" rowspan="1" colspan="1">1,383/1,353</td>
              <td align="center" rowspan="1" colspan="1">2,918/2,675</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Unseen Targets</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">9,876/9,499</td>
              <td align="center" rowspan="1" colspan="1">1,382/1,386</td>
              <td align="center" rowspan="1" colspan="1">2,578/2,762</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BindingDB</td>
              <td align="center" rowspan="1" colspan="1">7,165</td>
              <td align="center" rowspan="1" colspan="1">1,254</td>
              <td align="center" rowspan="1" colspan="1">0.0008/0.0010</td>
              <td align="center" rowspan="1" colspan="1">6,334/6,334</td>
              <td align="center" rowspan="1" colspan="1">927/5,717</td>
              <td align="center" rowspan="1" colspan="1">1,905/11,384</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DAVIS</td>
              <td align="center" rowspan="1" colspan="1">68</td>
              <td align="center" rowspan="1" colspan="1">379</td>
              <td align="center" rowspan="1" colspan="1">0.3707/0.3676</td>
              <td align="center" rowspan="1" colspan="1">1,043/1,043</td>
              <td align="center" rowspan="1" colspan="1">160/2,846</td>
              <td align="center" rowspan="1" colspan="1">303/5,708</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">TDC-DG</td>
              <td align="center" rowspan="1" colspan="1">140,746</td>
              <td align="center" rowspan="1" colspan="1">477</td>
              <td align="center" rowspan="1" colspan="1">0.0021/0.0005</td>
              <td align="center" rowspan="1" colspan="1">146,891</td>
              <td align="center" rowspan="1" colspan="1">36,539</td>
              <td align="center" rowspan="1" colspan="1">49,028</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Phosphatase</td>
              <td align="center" rowspan="1" colspan="1">165</td>
              <td align="center" rowspan="1" colspan="1">218</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">5,054/27,286</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">370/3,260</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Esterase</td>
              <td align="center" rowspan="1" colspan="1">96</td>
              <td align="center" rowspan="1" colspan="1">146</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">2,150/10,426</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">926/514</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Glycosyltransferase</td>
              <td align="center" rowspan="1" colspan="1">89</td>
              <td align="center" rowspan="1" colspan="1">54</td>
              <td align="center" rowspan="1" colspan="1">0.9259/0.9778</td>
              <td align="center" rowspan="1" colspan="1">725/3,042</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">113/417</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Halogenase</td>
              <td align="center" rowspan="1" colspan="1">62</td>
              <td align="center" rowspan="1" colspan="1">42</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">303/1,991</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">20/290</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BKACE</td>
              <td align="center" rowspan="1" colspan="1">17</td>
              <td align="center" rowspan="1" colspan="1">161</td>
              <td align="center" rowspan="1" colspan="1">1.0/1.0</td>
              <td align="center" rowspan="1" colspan="1">255/2,193</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">19/270</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DUD-E <sup>†</sup></td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">8,996/406,208</td>
              <td align="center" rowspan="1" colspan="1">—</td>
              <td align="center" rowspan="1" colspan="1">11,430/521,132</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> GPCR</td>
              <td align="center" rowspan="1" colspan="1">99,671</td>
              <td align="center" rowspan="1" colspan="1">5</td>
              <td align="center" rowspan="1" colspan="1">18,563</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Kinase</td>
              <td align="center" rowspan="1" colspan="1">315,399</td>
              <td align="center" rowspan="1" colspan="1">26</td>
              <td align="center" rowspan="1" colspan="1">15,409</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Protease</td>
              <td align="center" rowspan="1" colspan="1">286,089</td>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">9,271</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Nuclear</td>
              <td align="center" rowspan="1" colspan="1">151,133</td>
              <td align="center" rowspan="1" colspan="1">11</td>
              <td align="center" rowspan="1" colspan="1">16,257</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1"/>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>We report the number of unique drugs and targets, the median (drug/target) coverage, and the number of training, validation, and test samples in each dataset. The numbers of pairs are shown as (positive/negative), except for TDC-DG (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r58" ref-type="bibr">58</xref>), which is a regression task; thus, the total number of pairs is shown. We consider BIOSNAP (<xref rid="r70" ref-type="bibr">70</xref>), BindingDB (<xref rid="r69" ref-type="bibr">69</xref>), DAVIS (<xref rid="r68" ref-type="bibr">68</xref>), and TDC-DG as low-coverage, while Phosphatase (<xref rid="r71" ref-type="bibr">71</xref>), Esterase (<xref rid="r72" ref-type="bibr">72</xref>), Glycosyltransferase (<xref rid="r73" ref-type="bibr">73</xref>), Halogenase (<xref rid="r74" ref-type="bibr">74</xref>), BKACE (<xref rid="r75" ref-type="bibr">75</xref>), and DUD-E (<xref rid="r36" ref-type="bibr">36</xref>) are considered high-coverage. † Because DUD-E is a decoy dataset, we report as coverage the median number of true drugs or decoys for each target.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="s12">
      <title>Benchmarks Overview.</title>
      <sec id="s13">
        <title>Low coverage benchmarks.</title>
        <p>We evaluate our framework on three broad-scale, low-coverage benchmark datasets. Two datasets, <bold>DAVIS</bold> (<xref rid="r68" ref-type="bibr">68</xref>) and <bold>BindingDB</bold> (<xref rid="r69" ref-type="bibr">69</xref>), consist of pairs of drugs and targets with experimentally determined dissociation constants (<italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub>). Following ref. <xref rid="r13" ref-type="bibr">13</xref>, we treat pairs with <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> &lt; 30 as positive DTIs, while larger <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> values are negative. The third dataset, ChG-Miner from <bold>BIOSNAP</bold> (<xref rid="r70" ref-type="bibr">70</xref>), consists of only positive DTIs. We create negative DTIs by randomly sampling an equal number of protein–drug pairs, making the assumption that a random pair is unlikely to be positively interacting. The DAVIS dataset represents a few-shot learning setting: It contains only 2,086 training interactions, compared to 12,668 for BindingDB and 19,238 for BIOSNAP. The rest of the data preparation follows (<xref rid="r13" ref-type="bibr">13</xref>). The datasets are split into 70% for training, 10% for validation, and the remaining 20% for testing. Training data are artificially subsampled to have an equal number of positive and negative interactions, while validation and test data are left at the ratio originally in the dataset.</p>
      </sec>
      <sec id="s14">
        <title>Zero-shot benchmarks.</title>
        <p>We evaluate our framework on two zero-shot prediction modifications of BIOSNAP. Following ref. <xref rid="r13" ref-type="bibr">13</xref>, the <bold>Unseen proteins</bold> set was created by selecting 20% of proteins from the full set and selecting any interactions including these proteins for the test set. Thus, there are no proteins which appear in both the training and test set. The corresponding process was used to create the <bold>Unseen drugs</bold> dataset. The training set was then further split using 7/8 of the interactions for training and 1/8 of the interactions for testing. As above, data are subsampled so that training is balanced.</p>
      </sec>
      <sec id="s15">
        <title>Continuous benchmarks.</title>
        <p>Continuous affinity prediction data come from the TDC-DG (<xref rid="r19" ref-type="bibr">19</xref>). The TDC-DG consists of 140,746 unique drugs and 477 unique targets derived from BindingDB (<xref rid="r69" ref-type="bibr">69</xref>) interactions that have patent information. Each interaction is labeled with an experimentally determined dissociation constant (<italic toggle="yes">I</italic><italic toggle="yes">C</italic><sub>50</sub>). Interactions are temporally split, so that training pairs are from patents filed between 2013 and 2018, and test pairs are from between 2019 and 2021. In addition, 20% of the training pairs are randomly set aside as a validation set. We train five different models with the train/validation splits determined by the TDC benchmarking framework and report the average PCC coefficient of predictions on the test set.</p>
      </sec>
      <sec id="s16">
        <title>High coverage benchmarks.</title>
        <p>The Database of Useful Decoys: Enhanced (<bold>DUD-E</bold>) (<xref rid="r36" ref-type="bibr">36</xref>) consists of 102 protein targets and known binding partners (average 224 molecules per target). For each binding partner, there are 50 “decoys,” or physiochemically similar compounds that are known not to bind with the target. Of note, 57 of the targets are classified as either GPCRs, kinases, nuclear proteins, or proteases. We generate train–test splits by splitting targets within classes, so that there are representative members of each class in both the training and test sets, but no target appears in both the training and test set (26 train and 31 test). These data are by definition high coverage since there are several true and decoy compounds available for each target. We provide the full target splits in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S1</ext-link>.</p>
        <p>We also evaluate several protein-family-specific datasets from various different sources compiled by Goldman et al. (<xref rid="r25" ref-type="bibr">25</xref>). These include DTI data on <italic toggle="yes">β</italic>-ketoacid cleavage (<bold>BKACE</bold>) (<xref rid="r75" ref-type="bibr">75</xref>), <bold>Esterase</bold> (<xref rid="r72" ref-type="bibr">72</xref>), <bold>Glycosyltransferases</bold> (<xref rid="r73" ref-type="bibr">73</xref>), <bold>Halogenase</bold> (<xref rid="r74" ref-type="bibr">74</xref>), and <bold>Phosphatase</bold> (<xref rid="r71" ref-type="bibr">71</xref>) enzymes. These data are uniformly very high coverage, with a known data point for nearly every drug–target pair. Following ref. (<xref rid="r25" ref-type="bibr">25</xref>), we performed a 10-fold cross-validation where the data were split into train–test sets by target, so that all drugs appear in both the training and test set, but no target does.</p>
      </sec>
    </sec>
    <sec id="s17">
      <title>ConPLex Model.</title>
      <sec id="s18">
        <title>Target featurization.</title>
        <p>We generate protein target features using pretrained PLMs: These models generate a protein embedding <italic toggle="yes">E</italic><sub><italic toggle="yes">f</italic><italic toggle="yes">u</italic><italic toggle="yes">l</italic><italic toggle="yes">l</italic></sub> ∈ ℝ<sup><italic toggle="yes">n</italic> × <italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup> for a protein of length <italic toggle="yes">n</italic>, which is then mean-pooled along the length of the protein resulting in a vector <italic toggle="yes">E</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup>. Specifically, we investigate the pretrained models Prose (<xref rid="r30" ref-type="bibr">30</xref>), ESM (<xref rid="r76" ref-type="bibr">76</xref>), and ProtBert (<xref rid="r27" ref-type="bibr">27</xref>), with default dimensions <italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub> = 6165, 1280, <italic toggle="yes">a</italic><italic toggle="yes">n</italic><italic toggle="yes">d</italic>1024, respectively (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>). Elnaggar et al. recommend the use of ProtT5XLUniref50, but we found that it did not perform as well as ProtBert for the DTI prediction task. We emphasize that the language and projection models are used exclusively to generate input features—their weights are kept unchanged and are not updated during DTI training.</p>
      </sec>
      <sec id="s19">
        <title>Drug featurization.</title>
        <p>We featurize the drug molecule by its Morgan fingerprint (<xref rid="r26" ref-type="bibr">26</xref>), an encoding of the SMILES string of the molecular graph as a fixed-dimension embedding <italic toggle="yes">M</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub></sup> (we chose <italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub>= 2,048) by considering the local neighborhood around each atom. The utility of the Morgan fingerprint for small molecule representation has been demonstrated in refs. <xref rid="r25" ref-type="bibr">25</xref> and <xref rid="r77" ref-type="bibr">77</xref>. We additionally investigated the use of molecule embeddings from Mol2Vec (<xref rid="r78" ref-type="bibr">78</xref>) and MolR (<xref rid="r79" ref-type="bibr">79</xref>) and found that they failed to perform as well as the Morgan fingerprint (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S2</ext-link>).</p>
      </sec>
      <sec id="s20">
        <title>Transformation into a shared latent space and prediction.</title>
        <p>Given a target embedding <italic toggle="yes">T</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup> and small molecule embedding <italic toggle="yes">M</italic> ∈ ℝ<sup><italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub></sup>, we transform them separately into <italic toggle="yes">T</italic><sup>*</sup>, <italic toggle="yes">M</italic><sup>*</sup> ∈ ℝ<sup><italic toggle="yes">h</italic></sup> using a single fully connected layer with a ReLU activation. These layers are parameterized with weight matrices <italic toggle="yes">W</italic><sub><italic toggle="yes">t</italic></sub> ∈ ℝ<sup><italic toggle="yes">h</italic> × <italic toggle="yes">d</italic><sub><italic toggle="yes">t</italic></sub></sup>, <italic toggle="yes">W</italic><sub><italic toggle="yes">m</italic></sub> ∈ ℝ<sup><italic toggle="yes">h</italic> × <italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub></sup>, and bias vectors <inline-formula><mml:math id="i7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.
<disp-formula id="eqn1"><label>[1]</label><mml:math id="me1" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="eqn2"><label>[2]</label><mml:math id="me2" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>Given the latent embeddings <italic toggle="yes">T</italic><sup>*</sup>, <italic toggle="yes">M</italic><sup>*</sup>, we compute the probability of a DTI <inline-formula><mml:math id="i8" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as the cosine similarity between the embedding vectors, followed by a sigmoid activation. Thus, we compute the predicted probability as:
<disp-formula id="eqn3"><label>[3]</label><mml:math id="me3" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>·</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>When predicting compound binding affinity <inline-formula><mml:math id="i9" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we substitute the sigmoid and cosine similarity (Eq. <xref rid="eqn3" ref-type="disp-formula"><bold>3</bold></xref>) with a dot product followed by a ReLU activation, which gives a nonnegative distance in the embedding space (Eq. <xref rid="eqn4" ref-type="disp-formula"><bold>4</bold></xref>).
<disp-formula id="eqn4"><label>[4]</label><mml:math id="me4" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>·</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec id="s21">
        <title>Training.</title>
        <p>The model is trained both for broad and fine predictions, with the loss computed depending on the training dataset. Broad-scale training data use the binary cross-entropy loss (<italic toggle="yes">L</italic><sub><italic toggle="yes">B</italic><italic toggle="yes">C</italic><italic toggle="yes">E</italic></sub>) between the true labels <italic toggle="yes">y</italic> and the predicted interaction probabilities <inline-formula><mml:math id="i10" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. When the model is trained to predict binding affinity, we substitute the binary cross-entropy loss with the mean squared error loss (<italic toggle="yes">L</italic><sub><italic toggle="yes">M</italic><italic toggle="yes">S</italic><italic toggle="yes">E</italic></sub>) during supervision.</p>
        <p>Training on fine-scale data (DUD-E) was performed using contrastive learning. Contrastive learning uses triplets of training points rather than pairs, denoted the <bold>anchor</bold>, <bold>positive</bold>, and <bold>negative</bold>, and aims to minimize the distance between the anchor and positive examples while maximizing the distance between the anchor and the negative examples. In the DTI setting, the natural choice for a triplet is the protein target as the anchor, the true drug as the positive, and decoy as the negative example, respectively. We derive a training set of triplets in the following manner: For each known interacting drug–target pair (<italic toggle="yes">T</italic>, <italic toggle="yes">M</italic><sup>+</sup>), we randomly sample <italic toggle="yes">k</italic> = 50 noninteracting pairs (<italic toggle="yes">T</italic>, <italic toggle="yes">M</italic><sup>−</sup>) and generate the triplets (<italic toggle="yes">T</italic>, <italic toggle="yes">M</italic><sup>+</sup>, <italic toggle="yes">M</italic><sup>−</sup>), where <italic toggle="yes">M</italic><sup>−</sup> is drawn from the set of all decoys against <italic toggle="yes">T</italic>. We map these to latent space embeddings as described above. Since all the entities are now comparable to each other, we can compute the triplet margin-distance loss (<italic toggle="yes">L</italic><sub><italic toggle="yes">T</italic><italic toggle="yes">R</italic><italic toggle="yes">M</italic></sub>).
<disp-formula id="eqn5"><label>[5]</label><mml:math id="me5" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">TRM</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>where
<disp-formula id="eqn6"><label>[6]</label><mml:math id="me6" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
        <p>The margin <italic toggle="yes">m</italic> sets the maximum required delta between distances, above which the loss is zero.</p>
      </sec>
      <sec id="s22">
        <title>Margin annealing.</title>
        <p>The margin <italic toggle="yes">m</italic> sets the maximum required delta between distances, above which the loss is zero. Initially, a large margin requires the decoy to be much further from the target than the drug to avoid a penalty, resulting in larger weight updates. As training progresses, lower margins relax this constraint, requiring only that the drug be closer than the decoy as <italic toggle="yes">m</italic> → 0. Here, the margin is initialized at <italic toggle="yes">M</italic><sub><italic toggle="yes">m</italic><italic toggle="yes">a</italic><italic toggle="yes">x</italic></sub> = 0.25 according to a tanh decay with restarts schedule. Every <italic toggle="yes">E</italic><sub><italic toggle="yes">m</italic><italic toggle="yes">a</italic><italic toggle="yes">x</italic></sub> = 10 contrastive epochs, the margin is reset to the initial <italic toggle="yes">M</italic><sub><italic toggle="yes">m</italic><italic toggle="yes">a</italic><italic toggle="yes">x</italic></sub>, for a total of 50 epochs. At epoch <italic toggle="yes">i</italic>, the margin is set to
<disp-formula id="eqn7"><label>[7]</label><mml:math id="me7" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>m</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>tanh</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mspace width="3.33333pt"/><mml:mspace width="0.333333em"/><mml:mtext>mod</mml:mtext><mml:mspace width="3.33333pt"/><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      </sec>
      <sec id="s23">
        <title>Implementation.</title>
        <p>Model weights were initialized using the Xavier method from a normal distribution (<xref rid="r80" ref-type="bibr">80</xref>). Weights were updated with error backpropagation using the AdamW optimizer (<xref rid="r81" ref-type="bibr">81</xref>) for a total of 50 epochs. For the binary classification task, the learning rate was initially set to 10<sup>−4</sup> and adjusted according to a cosine annealing schedule with warm restarts (<xref rid="r82" ref-type="bibr">82</xref>) every 10 epochs. For the contrastive task, the learning rate was initially set to 10<sup>−5</sup>, and the same annealing schedule was followed. The margin for the contrastive loss was initially set to 0.25 and decreased to a minimum of 0 over 50 epochs according to a tanh decay schedule with restarts every 10 epochs. We used a latent dimension <italic toggle="yes">d</italic>= 1,024 (results were robust to even with lower dimensions, and much higher dimensions may overfit or be subject to topological restrictions) and a batch size of 32. The model was implemented in PyTorch version 1.11. Model training, and inference was performed on a machine with a 112-core Intel Xeon Gold 6258R CPU and using a single NVIDIA A100 GPU. We compare training and inference run times in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S4</ext-link>.</p>
      </sec>
    </sec>
    <sec id="s24">
      <title>Surfaceome Analysis.</title>
      <p>We evaluate the functional use of ConPLex embeddings using data from the Surfaceome database (<xref rid="r17" ref-type="bibr">17</xref>), which contains 2,886 cell-surface proteins. We identified Pfam domains using HMMscan from HMMER3 (<xref rid="r51" ref-type="bibr">51</xref>) with default settings. We analyzed domains hit in &gt; 10 proteins. For each domain, we trained a logistic regression classifier from sklearn with balanced class weights. We also evaluated domain coherence using spectral clustering with <italic toggle="yes">k</italic> = 10 clusters and evaluated the adjusted mutual information (AMI) between true clusters (protein has/does not have domain) and predicted clusters (<ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, S6</ext-link>).</p>
    </sec>
    <sec id="s25">
      <title>Experimental Determination of Kinase Binding Affinity.</title>
      <p>From the Surfaceome (<xref rid="r17" ref-type="bibr">17</xref>) database, we selected 51 kinases which were available by the KdELECT assay from DiscoveryX. From the ZINC database (<xref rid="r37" ref-type="bibr">37</xref>), we selected 4715 compounds purchasable from the Cayman Chemical Company. Using a ConPLex model trained on BindingDB and fine-tuned on DUD-E, we predicted all pairwise interactions between kinases and small molecule drugs. Without previously consulting the literature on kinases or drugs, we selected 5 kinases which were highly represented in the top predictions (<italic toggle="yes">EGFR</italic>, <italic toggle="yes">EPHB1</italic>, <italic toggle="yes">FLT3</italic>, <italic toggle="yes">KIT</italic>, and <italic toggle="yes">TGFBR2</italic>). We then selected 19 binding pairs to test, covering 14 drugs with high ConPLex-predicted interactions. The full list of ConPLex predictions can be found in <ext-link xlink:href="https://www.pnas.org/lookup/doi/10.1073/pnas.2220778120#supplementary-materials" ext-link-type="uri" xlink:show="new"><italic toggle="yes">SI Appendix</italic>, Data S1</ext-link>.</p>
      <p>We performed <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> determination using the KdELECT assay from the DiscoveryX company, following the procedure from Hie et al. (<xref rid="r83" ref-type="bibr">83</xref>). KdELECT measures competition between test compounds and an immobilized, active site-directed ligand. Ligands are tagged with DNA oligomers, and competition is measured by qPCR of this barcode. BL21-derived <italic toggle="yes">E. coli</italic> were infected with T7 phase strains tagged with each kinase target and incubated with shaking at 32°C. Streptavidin-coated magnetic beads were treated with a biotinylated ligand at room temperature for 30 min, following which the beads were blocked with excess biotin and washed with blocking buffer [SeaBlock (Pierce), 1% bovine serum albumin (BSA), 0.05% Tween 20, and 1 mM dithiothreitol (DTT)] to remove unbound ligand. Test compounds were prepared as 111X stocks in 100% DMSO. An 11-point, threefold compound dilution series was created, with a top test compound concentration of 10,000 nM. Three DMSO control points were also used. Test compounds are distributed by acoustic transfer (noncontact dispensing) in 100% DMSO and then diluted into the assays for a final DMSO concentration of 0.9%.</p>
      <p>Kinases, ligand-bound affinity beads, and test compounds were combined in 1X binding buffer [20% SeaBlock, 0.17X phosphate-buffered saline (PBS), 0.05% Tween 20, and 6 mM DTT] in a 384-well plate, with a final volume of 0.02 mL for each reaction. Plates were incubated for 1 h at room temperature with shaking. Affinity beads were washed with wash buffer (1x PBS, 0.05% Tween 20), resuspended in elution buffer (1x PBS, 0.05% Tween 20, 0.5 mM nonbiotinylated affinity ligand), and incubated for 30 min at room temperature with shaking. The concentration of kinases was measured using qPCR. To compute <italic toggle="yes">K</italic><sub><italic toggle="yes">D</italic></sub> of the binding, a standard dose–response curve was fit to the Hill equation curves using the Levenberg–Marquardt algorithm (Hill slope = −1).</p>
    </sec>
    <sec id="s26">
      <title>Genome-wide ChEMBL Scan.</title>
      <p>We trained a ConPLex model using BindingDB and DUD-E and used it to make predictions for all pairs of human proteins against all drugs in ChEMBL. Human protein sequences were taken from the STRING database and processed following ref. (<xref rid="r32" ref-type="bibr">32</xref>), resulting in 15,816 proteins between 50 and 800 amino acids long. Small molecule structures were downloaded from ChEMBL 30 (<xref rid="r18" ref-type="bibr">18</xref>), resulting in 1,533,652 compounds. Prediction took just under a day, accounting for embedding time.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material position="float" content-type="local-data">
      <caption>
        <p>Appendix 01 (PDF)</p>
      </caption>
      <media xlink:href="pnas.2220778120.sapp.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>R.S. and B. Berger were supported by the NIH grant R35GM141861. S.S. was supported by the NSF Graduate Research Fellowship under Grant No. 2141064. B. Bryson was supported by the Terry and Susan Ragon Foundation. L.C. was supported by NSF grant CCF-1934553. We thank Kapil Devkota, Mert Erden, Tristan Bepler, and Tim Truong for helpful discussions.</p>
    <sec id="s28">
      <title>Author contributions</title>
      <p>R.S., S.S., L.C., and B. Berger designed research; R.S., S.S., B. Bryson, L.C., and B. Berger performed research; R.S., S.S., B. Bryson, L.C., and B. Berger contributed new reagents/analytic tools; R.S., S.S., L.C., and B. Berger analyzed data; and R.S., S.S., B. Bryson, L.C., and B. Berger wrote the paper.</p>
    </sec>
    <sec sec-type="COI-statement" id="s29">
      <title>Competing interests</title>
      <p>The authors declare no competing interest.</p>
    </sec>
  </ack>
  <fn-group>
    <fn fn-type="other" id="fn3">
      <p>This article is a PNAS Direct Submission.</p>
    </fn>
  </fn-group>
  <sec sec-type="data-availability" id="s27">
    <title>Data, Materials, and Software Availability</title>
    <p>Dataset data have been deposited in Github (<ext-link xlink:href="https://github.com/samsledje/ConPLex_dev" ext-link-type="uri">https://github.com/samsledje/ConPLex_dev</ext-link>) (<xref rid="r38" ref-type="bibr">38</xref>). Previously published data were used for this work (<xref rid="r19" ref-type="bibr">19</xref>, <xref rid="r36" ref-type="bibr">36</xref>, <xref rid="r68" ref-type="bibr">68</xref><xref rid="r69" ref-type="bibr"/><xref rid="r70" ref-type="bibr"/><xref rid="r71" ref-type="bibr"/><xref rid="r72" ref-type="bibr"/><xref rid="r73" ref-type="bibr"/><xref rid="r74" ref-type="bibr"/>–<xref rid="r75" ref-type="bibr">75</xref>).</p>
  </sec>
  <ref-list>
    <ref id="r1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Jumper</surname></string-name><etal/></person-group>, <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source><volume><bold>596</bold></volume>, <fpage>583</fpage>–<lpage>589</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="r2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Baek</surname></string-name><etal/></person-group>, <article-title>Accurate prediction of protein structures and interactions using a three-track neural network</article-title>. <source>Science</source><volume><bold>373</bold></volume>, <fpage>871</fpage>–<lpage>876</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34282049</pub-id></mixed-citation>
    </ref>
    <ref id="r3">
      <label>3</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Wu</surname></string-name><etal/></person-group>, High-resolution de novo structure prediction from primary sequence. bioRxiv [Preprint] (2022). <pub-id pub-id-type="doi">10.1101/2022.07.21.500999</pub-id> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.</given-names><surname>Pinzi</surname></string-name>, <string-name><given-names>G.</given-names><surname>Rastelli</surname></string-name></person-group>, <article-title>Molecular docking: Shifting paradigms in drug discovery</article-title>. <source>Int. J. Mol. Sci.</source><volume><bold>20</bold></volume>, <fpage>4331</fpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31487867</pub-id></mixed-citation>
    </ref>
    <ref id="r5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. M.</given-names><surname>Bonk</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Tarasova</surname></string-name>, <string-name><given-names>M. A.</given-names><surname>Hicks</surname></string-name>, <string-name><given-names>B.</given-names><surname>Tidor</surname></string-name>, <string-name><given-names>K. L.</given-names><surname>Prather</surname></string-name></person-group>, <article-title>Rational design of thiolase substrate specificity for metabolic engineering applications</article-title>. <source>Biotechnol. Bioeng.</source><volume><bold>115</bold></volume>, <fpage>2167</fpage>–<lpage>2182</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29877597</pub-id></mixed-citation>
    </ref>
    <ref id="r6">
      <label>6</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. C.</given-names><surname>de Melo-Minardi</surname></string-name>, <string-name><given-names>K.</given-names><surname>Bastard</surname></string-name>, <string-name><given-names>F.</given-names><surname>Artiguenave</surname></string-name></person-group>, <article-title>Identification of subfamily-specific sites based on active sites modeling and clustering</article-title>. <source>Bioinformatics</source><volume><bold>26</bold></volume>, <fpage>3075</fpage>–<lpage>3082</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20980272</pub-id></mixed-citation>
    </ref>
    <ref id="r7">
      <label>7</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>S. J.</given-names><surname>Trudeau</surname></string-name><etal/></person-group>, PrePCI: A structure- and chemical similarity-informed database of predicted protein compound interactions. bioRxiv [Preprint] (2022). <pub-id pub-id-type="doi">10.1101/2022.09.17.508184</pub-id> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>D.</given-names><surname>Park</surname></string-name>, <string-name><given-names>J.</given-names><surname>Xu</surname></string-name>, <string-name><given-names>R.</given-names><surname>Hosur</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Struct2Net: A web service to predict protein–protein interactions using a structure-based approach</article-title>. <source>Nucleic Acids Res.</source><volume><bold>38</bold></volume>, <fpage>W508</fpage>–<lpage>W515</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20513650</pub-id></mixed-citation>
    </ref>
    <ref id="r9">
      <label>9</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>E.</given-names><surname>Anderson</surname></string-name>, <string-name><given-names>G. D.</given-names><surname>Veith</surname></string-name>, <string-name><given-names>D.</given-names><surname>Weininger</surname></string-name></person-group>, <source>SMILES, A Line Notation and Computerized Interpreter for Chemical Structures</source> (<publisher-name>Environmental Research Laboratory, US Environmental Protection Agency</publisher-name>, <year>1987</year>).</mixed-citation>
    </ref>
    <ref id="r10">
      <label>10</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Bagherian</surname></string-name><etal/></person-group>, <article-title>Machine learning approaches and databases for prediction of drug–target interaction: A survey paper</article-title>. <source>Brief. Bioinf.</source><volume><bold>22</bold></volume>, <fpage>247</fpage>–<lpage>269</lpage> (<year>2021</year>).</mixed-citation>
    </ref>
    <ref id="r11">
      <label>11</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>H.</given-names><surname>Cho</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Realizing private and practical pharmacological collaboration</article-title>. <source>Science</source><volume><bold>362</bold></volume>, <fpage>347</fpage>–<lpage>350</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30337410</pub-id></mixed-citation>
    </ref>
    <ref id="r12">
      <label>12</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Lee</surname></string-name>, <string-name><given-names>J.</given-names><surname>Keum</surname></string-name>, <string-name><given-names>H.</given-names><surname>Nam</surname></string-name></person-group>, <article-title>DeepConv-DTI: Prediction of drug–target interactions via deep learning with convolution on protein sequences</article-title>. <source>PLoS Comput. Biol.</source><volume><bold>15</bold></volume>, <fpage>e1007129</fpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31199797</pub-id></mixed-citation>
    </ref>
    <ref id="r13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name>, <string-name><given-names>C.</given-names><surname>Xiao</surname></string-name>, <string-name><given-names>L. M.</given-names><surname>Glass</surname></string-name>, <string-name><given-names>J.</given-names><surname>Sun</surname></string-name></person-group>, <article-title>MolTrans: Molecular interaction transformer for drug–target interaction prediction</article-title>. <source>Bioinformatics</source><volume><bold>37</bold></volume>, <fpage>830</fpage>–<lpage>836</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33070179</pub-id></mixed-citation>
    </ref>
    <ref id="r14">
      <label>14</label>
      <mixed-citation publication-type="other">S. Sledzieski, R. Singh, L. Cowen, B. Berger. “Adapting protein language models for rapid DTI prediction in <italic toggle="yes">Machine Learning for Structural Biology Workshop (MLSB) at NeurIPS</italic> (2021).</mixed-citation>
    </ref>
    <ref id="r15">
      <label>15</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Bommasani</surname></string-name><etal/></person-group>, On the opportunities and risks of foundation models. arXiv [Preprint] (2021). <ext-link xlink:href="http://arxiv.org/abs/2108.07258" ext-link-type="uri">http://arxiv.org/abs/2108.07258</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r16">
      <label>16</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Gururangan</surname></string-name><etal/></person-group>, Don’t stop pretraining: Adapt language models to domains and tasks. arXiv [Preprint] (2020). <ext-link xlink:href="http://arxiv.org/abs/2004.10964" ext-link-type="uri">http://arxiv.org/abs/2004.10964</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r17">
      <label>17</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Bausch-Fluck</surname></string-name><etal/></person-group>, <article-title>The in silico human surfaceome</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>115</bold></volume>, <fpage>E10988</fpage>–<lpage>E10997</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30373828</pub-id></mixed-citation>
    </ref>
    <ref id="r18">
      <label>18</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Mendez</surname></string-name><etal/></person-group>, <article-title>ChEMBL: Towards direct deposition of bioassay data</article-title>. <source>Nucleic Acids Res.</source><volume><bold>47</bold></volume>, <fpage>D930</fpage>–<lpage>D940</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">30398643</pub-id></mixed-citation>
    </ref>
    <ref id="r19">
      <label>19</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name><etal/></person-group>, Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development. arXiv [Preprint] (2021). <ext-link xlink:href="http://arxiv.org/abs/2102.09548" ext-link-type="uri">http://arxiv.org/abs/2102.09548</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names><surname>Zong</surname></string-name><etal/></person-group>, <article-title>Beta: A comprehensive benchmark for computational drug–target prediction</article-title>. <source>Brief. Bioinf.</source><volume><bold>23</bold></volume>, <fpage>bbac199</fpage> (<year>2022</year>).</mixed-citation>
    </ref>
    <ref id="r21">
      <label>21</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. M.</given-names><surname>Dönertaş</surname></string-name>, <string-name><given-names>M.</given-names><surname>Fuentealba Valenzuela</surname></string-name>, <string-name><given-names>L.</given-names><surname>Partridge</surname></string-name>, <string-name><given-names>J. M.</given-names><surname>Thornton</surname></string-name></person-group>, <article-title>Gene expression-based drug repurposing to target aging</article-title>. <source>Aging Cell</source><volume><bold>17</bold></volume>, <fpage>e12819</fpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29959820</pub-id></mixed-citation>
    </ref>
    <ref id="r22">
      <label>22</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Morselli Gysi</surname></string-name><etal/></person-group>, <article-title>Network medicine framework for identifying drug-repurposing opportunities for Covid-19</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>118</bold></volume>, <fpage>e2025581118</fpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33906951</pub-id></mixed-citation>
    </ref>
    <ref id="r23">
      <label>23</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>DeepPurpose: A deep learning library for drug–target interaction prediction</article-title>. <source>Bioinformatics</source><volume><bold>36</bold></volume>, <fpage>5545</fpage>–<lpage>5547</lpage> (<year>2020</year>).</mixed-citation>
    </ref>
    <ref id="r24">
      <label>24</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>A framework for identification of on- and off-target transcriptional responses to drug treatment</article-title>. <source>Sci. Rep.</source><volume><bold>9</bold></volume>, <fpage>1</fpage>–<lpage>9</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">30626917</pub-id></mixed-citation>
    </ref>
    <ref id="r25">
      <label>25</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Goldman</surname></string-name>, <string-name><given-names>R.</given-names><surname>Das</surname></string-name>, <string-name><given-names>K. K.</given-names><surname>Yang</surname></string-name>, <string-name><given-names>C. W.</given-names><surname>Coley</surname></string-name></person-group>, <article-title>Machine learning modeling of family wide enzyme-substrate specificity screens</article-title>. <source>PLoS Comput. Biol.</source><volume><bold>18</bold></volume>, <fpage>e1009853</fpage> (<year>2022</year>).<pub-id pub-id-type="pmid">35143485</pub-id></mixed-citation>
    </ref>
    <ref id="r26">
      <label>26</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. L.</given-names><surname>Morgan</surname></string-name></person-group>, <article-title>The generation of a unique machine description for chemical structures—A technique developed at chemical abstracts service</article-title>. <source>J. Chem. Doc.</source><volume><bold>5</bold></volume>, <fpage>107</fpage>–<lpage>113</lpage> (<year>1965</year>).</mixed-citation>
    </ref>
    <ref id="r27">
      <label>27</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Elnaggar</surname></string-name><etal/></person-group>, ProtTrans: Towards cracking the language of life’s code through self-supervised deep learning and high performance computing. arXiv [Preprint] (2020). <ext-link xlink:href="http://arxiv.org/abs/2007.06225" ext-link-type="uri">http://arxiv.org/abs/2007.06225</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Scaiewicz</surname></string-name>, <string-name><given-names>M.</given-names><surname>Levitt</surname></string-name></person-group>, <article-title>The language of the protein universe</article-title>. <source>Curr. Opin. Genet. Dev.</source><volume><bold>35</bold></volume>, <fpage>50</fpage>–<lpage>56</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26451980</pub-id></mixed-citation>
    </ref>
    <ref id="r29">
      <label>29</label>
      <mixed-citation publication-type="other">T. Bepler, B. Berger, “Learning protein sequence embeddings using information from structure” in <italic toggle="yes">7th International Conference on Learning Representations, ICLR 2019</italic> (2019).</mixed-citation>
    </ref>
    <ref id="r30">
      <label>30</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names><surname>Bepler</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Learning the protein language: Evolution, structure, and function</article-title>. <source>Cell Syst.</source><volume><bold>12</bold></volume>, <fpage>654</fpage>–<lpage>669.e3</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34139171</pub-id></mixed-citation>
    </ref>
    <ref id="r31">
      <label>31</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Heinzinger</surname></string-name><etal/></person-group>, <article-title>Modeling aspects of the language of life through transfer–learning protein sequences</article-title>. <source>BMC Bioinf.</source><volume><bold>20</bold></volume>, <fpage>1</fpage>–<lpage>17</lpage> (<year>2019</year>).</mixed-citation>
    </ref>
    <ref id="r32">
      <label>32</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Sledzieski</surname></string-name>, <string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>L.</given-names><surname>Cowen</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>D-SCRIPT translates genome to phenome with sequence-based, structure-aware, genome-scale predictions of protein–protein interactions</article-title>. <source>Cell Syst.</source><volume><bold>12</bold></volume>, <fpage>1</fpage>–<lpage>14</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33476552</pub-id></mixed-citation>
    </ref>
    <ref id="r33">
      <label>33</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>K.</given-names><surname>Devkota</surname></string-name>, <string-name><given-names>S.</given-names><surname>Sledzieski</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name>, <string-name><given-names>L.</given-names><surname>Cowen</surname></string-name></person-group>, <article-title>Topsy-Turvy: Integrating a global view into sequence-based PPI prediction</article-title>. <source>Bioinformatics</source><volume><bold>38</bold></volume>, <fpage>i264</fpage>–<lpage>i272</lpage> (<year>2022</year>).<pub-id pub-id-type="pmid">35758793</pub-id></mixed-citation>
    </ref>
    <ref id="r34">
      <label>34</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Tsubaki</surname></string-name>, <string-name><given-names>K.</given-names><surname>Tomii</surname></string-name>, <string-name><given-names>J.</given-names><surname>Sese</surname></string-name></person-group>, <article-title>Compound–protein interaction prediction with end-to-end learning of neural networks for graphs and sequences</article-title>. <source>Bioinformatics</source><volume><bold>35</bold></volume>, <fpage>309</fpage>–<lpage>318</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">29982330</pub-id></mixed-citation>
    </ref>
    <ref id="r35">
      <label>35</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Heinzinger</surname></string-name><etal/></person-group>, <article-title>Contrastive learning on protein embeddings enlightens midnight zone</article-title>. <source>NAR Genom. Bioinf.</source><volume><bold>4</bold></volume>, <fpage>lqac043</fpage> (<year>2022</year>).</mixed-citation>
    </ref>
    <ref id="r36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. M.</given-names><surname>Mysinger</surname></string-name>, <string-name><given-names>M.</given-names><surname>Carchia</surname></string-name>, <string-name><given-names>J. J.</given-names><surname>Irwin</surname></string-name>, <string-name><given-names>B. K.</given-names><surname>Shoichet</surname></string-name></person-group>, <article-title>Directory of useful decoys, enhanced (DUD-E): Better ligands and decoys for better benchmarking</article-title>. <source>J. Med. Chem.</source><volume><bold>55</bold></volume>, <fpage>6582</fpage>–<lpage>6594</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22716043</pub-id></mixed-citation>
    </ref>
    <ref id="r37">
      <label>37</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. J.</given-names><surname>Irwin</surname></string-name>, <string-name><given-names>B. K.</given-names><surname>Shoichet</surname></string-name></person-group>, <article-title>Zinc—A free database of commercially available compounds for virtual screening</article-title>. <source>J. Chem. Inf. Model.</source><volume><bold>45</bold></volume>, <fpage>177</fpage>–<lpage>182</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15667143</pub-id></mixed-citation>
    </ref>
    <ref id="r38">
      <label>38</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Singh</surname></string-name>, <string-name><given-names>S.</given-names><surname>Sledzieski</surname></string-name>, <string-name><given-names>B.</given-names><surname>Bryson</surname></string-name>, <string-name><given-names>L.</given-names><surname>Cowen</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name></person-group>, surfaceome\_cayman\_validation\_scan.csv. Github. <ext-link xlink:href="https://github.com/samsledje/ConPLex_dev/blob/main/dataset/surfaceome_cayman_validation_scan.csv" ext-link-type="uri">https://github.com/samsledje/ConPLex_dev/blob/main/dataset/surfaceome_cayman_validation_scan.csv</ext-link>. Deposited 20 March 2023.</mixed-citation>
    </ref>
    <ref id="r39">
      <label>39</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W. B.</given-names><surname>Weglicki</surname></string-name>, <string-name><given-names>J. H.</given-names><surname>Kramer</surname></string-name>, <string-name><given-names>C. F.</given-names><surname>Spurney</surname></string-name>, <string-name><given-names>J. J.</given-names><surname>Chmielinska</surname></string-name>, <string-name><given-names>I. T.</given-names><surname>Mak</surname></string-name></person-group>, <article-title>The EGFR tyrosine kinase inhibitor tyrphostin AG-1478 causes hypomagnesemia and cardiac dysfunction</article-title>. <source>Can. J. Physiol. Pharmacol.</source><volume><bold>90</bold></volume>, <fpage>1145</fpage>–<lpage>1149</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22646904</pub-id></mixed-citation>
    </ref>
    <ref id="r40">
      <label>40</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names><surname>Sordella</surname></string-name>, <string-name><given-names>D. W.</given-names><surname>Bell</surname></string-name>, <string-name><given-names>D. A.</given-names><surname>Haber</surname></string-name>, <string-name><given-names>J.</given-names><surname>Settleman</surname></string-name></person-group>, <article-title>Gefitinib-sensitizing EGFR mutations in lung cancer activate anti-apoptotic pathways</article-title>. <source>Science</source><volume><bold>305</bold></volume>, <fpage>1163</fpage>–<lpage>1167</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15284455</pub-id></mixed-citation>
    </ref>
    <ref id="r41">
      <label>41</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. J.</given-names><surname>Roth</surname></string-name><etal/></person-group>, <article-title>Nintedanib: From discovery to the clinic</article-title>. <source>J. Med. Chem.</source><volume><bold>58</bold></volume>, <fpage>1053</fpage>–<lpage>1063</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25474320</pub-id></mixed-citation>
    </ref>
    <ref id="r42">
      <label>42</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. S.</given-names><surname>Wang</surname></string-name><etal/></person-group>, <article-title>Phase 1 trial of linifanib (ABT-869) in patients with refractory or relapsed acute myeloid leukemia</article-title>. <source>Leuk. Lymphoma</source><volume><bold>53</bold></volume>, <fpage>1543</fpage>–<lpage>1551</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22280537</pub-id></mixed-citation>
    </ref>
    <ref id="r43">
      <label>43</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N. C.</given-names><surname>Wolff</surname></string-name><etal/></person-group>, <article-title>PD166326, a novel tyrosine kinase inhibitor, has greater antileukemic activity than imatinib mesylate in a murine model of chronic myeloid leukemia</article-title>. <source>Blood</source><volume><bold>105</bold></volume>, <fpage>3995</fpage>–<lpage>4003</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15657179</pub-id></mixed-citation>
    </ref>
    <ref id="r44">
      <label>44</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. S.</given-names><surname>Wishart</surname></string-name><etal/></person-group>, <article-title>DrugBank 5.0: A major update to the DrugBank database for 2018</article-title>. <source>Nucleic Acids Res.</source><volume><bold>46</bold></volume>, <fpage>D1074</fpage>–<lpage>D1082</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29126136</pub-id></mixed-citation>
    </ref>
    <ref id="r45">
      <label>45</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V.</given-names><surname>Cibert-Goton</surname></string-name><etal/></person-group>, <article-title>Involvement of EphB1 receptors signalling in models of inflammatory and neuropathic pain</article-title>. <source>PLoS ONE</source><volume><bold>8</bold></volume>, <fpage>e53673</fpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23341972</pub-id></mixed-citation>
    </ref>
    <ref id="r46">
      <label>46</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Liu</surname></string-name><etal/></person-group>, <article-title>Blocking EphB1 receptor forward signaling in spinal cord relieves bone cancer pain and rescues analgesic effect of morphine treatment in rodents EphB1 receptor is critical to bone cancer pain</article-title>. <source>Cancer Res.</source><volume><bold>71</bold></volume>, <fpage>4392</fpage>–<lpage>4402</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21555368</pub-id></mixed-citation>
    </ref>
    <ref id="r47">
      <label>47</label>
      <mixed-citation publication-type="journal">
F. Carles, S. Bourg, C. Meyer, P. Bonnet, PKIDB: A curated, annotated and updated database of
protein kinase inhibitors in clinical trials. Molecules 23, 908 (2018).</mixed-citation>
    </ref>
    <ref id="r48">
      <label>48</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>Drabsch</surname></string-name>, <string-name><given-names>P.</given-names><surname>Ten Dijke</surname></string-name></person-group>, <article-title>TGF-<inline-formula><mml:math id="ueqn1001" display="inline" overflow="scroll"><mml:mi>β</mml:mi></mml:math></inline-formula> signalling and its role in cancer progression and metastasis</article-title>. <source>Cancer Metastasis Rev.</source><volume><bold>31</bold></volume>, <fpage>553</fpage>–<lpage>568</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22714591</pub-id></mixed-citation>
    </ref>
    <ref id="r49">
      <label>49</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. S.</given-names><surname>Almén</surname></string-name>, <string-name><given-names>K. J.</given-names><surname>Nordström</surname></string-name>, <string-name><given-names>R.</given-names><surname>Fredriksson</surname></string-name>, <string-name><given-names>H. B.</given-names><surname>Schiöth</surname></string-name></person-group>, <article-title>Mapping the human membrane proteome: A majority of the human membrane proteins can be classified according to function and evolutionary origin</article-title>. <source>BMC Biol.</source><volume><bold>7</bold></volume>, <fpage>1</fpage>–<lpage>14</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19144100</pub-id></mixed-citation>
    </ref>
    <ref id="r50">
      <label>50</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>El-Gebali</surname></string-name><etal/></person-group>, <article-title>The Pfam protein families database in 2019</article-title>. <source>Nucleic Acids Res.</source><volume><bold>47</bold></volume>, <fpage>D427</fpage>–<lpage>D432</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">30357350</pub-id></mixed-citation>
    </ref>
    <ref id="r51">
      <label>51</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. R.</given-names><surname>Eddy</surname></string-name></person-group>, <article-title>Accelerated profile HMM searches</article-title>. <source>PLoS Comput. Biol.</source><volume><bold>7</bold></volume>, <fpage>e1002195</fpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22039361</pub-id></mixed-citation>
    </ref>
    <ref id="r52">
      <label>52</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. P.</given-names><surname>Himanen</surname></string-name>, <string-name><given-names>M.</given-names><surname>Henkemeyer</surname></string-name>, <string-name><given-names>D. B.</given-names><surname>Nikolov</surname></string-name></person-group>, <article-title>Crystal structure of the ligand-binding domain of the receptor tyrosine kinase EphB2</article-title>. <source>Nature</source><volume><bold>396</bold></volume>, <fpage>486</fpage>–<lpage>491</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9853759</pub-id></mixed-citation>
    </ref>
    <ref id="r53">
      <label>53</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Berger</surname></string-name>, <string-name><given-names>M. S.</given-names><surname>Waterman</surname></string-name>, <string-name><given-names>Y. W.</given-names><surname>Yu</surname></string-name></person-group>, <article-title>Levenshtein distance, sequence comparison and biological database search</article-title>. <source>IEEE Trans. Inf. Theory.</source><volume><bold>67</bold></volume>, <fpage>3287</fpage>–<lpage>3294</lpage> (<year>2020</year>).<pub-id pub-id-type="pmid">34257466</pub-id></mixed-citation>
    </ref>
    <ref id="r54">
      <label>54</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>DeepPurpose: A deep learning library for drug–target interaction prediction</article-title>. <source>Bioinformatics</source><volume><bold>36</bold></volume>, <fpage>5545</fpage>–<lpage>5547</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33275143</pub-id></mixed-citation>
    </ref>
    <ref id="r55">
      <label>55</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Ramsundar</surname></string-name></person-group>, “Molecular machine learning with DeepChem,” PhD thesis (Stanford University, 2018).</mixed-citation>
    </ref>
    <ref id="r56">
      <label>56</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>E. D.</given-names><surname>Zhong</surname></string-name>, <string-name><given-names>B.</given-names><surname>Berger</surname></string-name>, <string-name><given-names>B.</given-names><surname>Bryson</surname></string-name></person-group>, <article-title>Learning the language of viral evolution and escape</article-title>. <source>Science</source><volume><bold>371</bold></volume>, <fpage>284</fpage>–<lpage>288</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33446556</pub-id></mixed-citation>
    </ref>
    <ref id="r57">
      <label>57</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Littmann</surname></string-name>, <string-name><given-names>M.</given-names><surname>Heinzinger</surname></string-name>, <string-name><given-names>C.</given-names><surname>Dallago</surname></string-name>, <string-name><given-names>K.</given-names><surname>Weissenow</surname></string-name>, <string-name><given-names>B.</given-names><surname>Rost</surname></string-name></person-group>, <article-title>Protein embeddings and deep learning predict binding residues for various ligand classes</article-title>. <source>Sci. Rep.</source><volume><bold>11</bold></volume>, <fpage>1</fpage>–<lpage>15</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="r58">
      <label>58</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Gulrajani</surname></string-name>, <string-name><given-names>D.</given-names><surname>Lopez-Paz</surname></string-name></person-group>, In search of lost domain generalization. arXiv [Preprint] (2020). <ext-link xlink:href="http://arxiv.org/abs/2007.01434" ext-link-type="uri">http://arxiv.org/abs/2007.01434</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r59">
      <label>59</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Russel</surname></string-name><etal/></person-group>, <article-title>Putting the pieces together: Integrative modeling platform software for structure determination of macromolecular assemblies</article-title>. <source>PLoS Biol.</source><volume><bold>10</bold></volume>, <fpage>e1001244</fpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22272186</pub-id></mixed-citation>
    </ref>
    <ref id="r60">
      <label>60</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Skolnick</surname></string-name>, <string-name><given-names>H.</given-names><surname>Zhou</surname></string-name></person-group>, <article-title>Implications of the essential role of small molecule ligand binding pockets in protein–protein interactions</article-title>. <source>J. Phys. Chem. B</source><volume><bold>126</bold></volume>, <fpage>6853</fpage>–<lpage>6867</lpage> (<year>2022</year>).<pub-id pub-id-type="pmid">36044742</pub-id></mixed-citation>
    </ref>
    <ref id="r61">
      <label>61</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>B. L.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>K. K.</given-names><surname>Yang</surname></string-name>, <string-name><given-names>P. S.</given-names><surname>Kim</surname></string-name></person-group>, Evolutionary velocity with protein language models. bioRxiv [Preprint] (2021). <pub-id pub-id-type="doi">10.1101/2021.06.07.447389</pub-id> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r62">
      <label>62</label>
      <mixed-citation publication-type="other">C. Hsu, H. Nisonoff, C. Fannjiang, J. Listgarten, Combining evolutionary and assay-labelled data for protein fitness prediction. bioRxiv [Preprint] (2021). <pub-id pub-id-type="doi">10.1101/2021.03.28.437402</pub-id>.</mixed-citation>
    </ref>
    <ref id="r63">
      <label>63</label>
      <mixed-citation publication-type="other">W. Jin, R. Barzilay, T. Jaakkola, “Junction tree variational autoencoder for molecular graph generation” in <italic toggle="yes">International Conference on Machine Learning</italic> (PMLR, 2018), pp. 2323–2332.</mixed-citation>
    </ref>
    <ref id="r64">
      <label>64</label>
      <mixed-citation publication-type="other">W. Jin, R. Barzilay, T. Jaakkola, “Hierarchical generation of molecular graphs using structural motifs” in <italic toggle="yes">International Conference on Machine Learning</italic> (PMLR, 2020), pp. 4839–4848.</mixed-citation>
    </ref>
    <ref id="r65">
      <label>65</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>O. J.</given-names><surname>Wouters</surname></string-name>, <string-name><given-names>M.</given-names><surname>McKee</surname></string-name>, <string-name><given-names>J.</given-names><surname>Luyten</surname></string-name></person-group>, <article-title>Estimated research and development investment needed to bring a new medicine to market, 2009–2018</article-title>. <source>J. Am. Med. Assoc.</source><volume><bold>323</bold></volume>, <fpage>844</fpage>–<lpage>853</lpage> (<year>2020</year>).</mixed-citation>
    </ref>
    <ref id="r66">
      <label>66</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. A.</given-names><surname>Van Norman</surname></string-name></person-group>, <article-title>Drugs, devices, and the FDA. Part 1: An overview of approval processes for drugs</article-title>. <source>JACC: Basic Transl. Sci.</source><volume><bold>1</bold></volume>, <fpage>170</fpage>–<lpage>179</lpage> (<year>2016</year>).<pub-id pub-id-type="pmid">30167510</pub-id></mixed-citation>
    </ref>
    <ref id="r67">
      <label>67</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. T.</given-names><surname>Sabe</surname></string-name><etal/></person-group>, <article-title>Current trends in computer aided drug design and a highlight of drugs discovered via computational techniques: A review</article-title>. <source>Eur. J. Med. Chem.</source><volume><bold>224</bold></volume>, <fpage>113705</fpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34303871</pub-id></mixed-citation>
    </ref>
    <ref id="r68">
      <label>68</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. I.</given-names><surname>Davis</surname></string-name><etal/></person-group>, <article-title>Comprehensive analysis of kinase inhibitor selectivity</article-title>. <source>Nat. Biotechnol.</source><volume><bold>29</bold></volume>, <fpage>1046</fpage>–<lpage>1051</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22037378</pub-id></mixed-citation>
    </ref>
    <ref id="r69">
      <label>69</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names><surname>Liu</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Lin</surname></string-name>, <string-name><given-names>X.</given-names><surname>Wen</surname></string-name>, <string-name><given-names>R. N.</given-names><surname>Jorissen</surname></string-name>, <string-name><given-names>M. K.</given-names><surname>Gilson</surname></string-name></person-group>, <article-title>BindingDB: A web-accessible database of experimentally determined protein–ligand binding affinities</article-title>. <source>Nucleic Acids Res.</source><volume><bold>35</bold></volume>, <fpage>D198</fpage>–<lpage>D201</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17145705</pub-id></mixed-citation>
    </ref>
    <ref id="r70">
      <label>70</label>
      <mixed-citation publication-type="other">M. Zitnik, R. Sosič, S. Maheshwari, J. Leskovec, BioSNAP Datasets: Stanford biomedical network dataset collection (2018). <ext-link xlink:href="http://snap.stanford.edu/biodata" ext-link-type="uri">http://snap.stanford.edu/biodata</ext-link>.</mixed-citation>
    </ref>
    <ref id="r71">
      <label>71</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names><surname>Huang</surname></string-name><etal/></person-group>, <article-title>Panoramic view of a superfamily of phosphatases through substrate profiling</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>112</bold></volume>, <fpage>E1974</fpage>–<lpage>E1983</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25848029</pub-id></mixed-citation>
    </ref>
    <ref id="r72">
      <label>72</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Martínez-Martínez</surname></string-name><etal/></person-group>, <article-title>Determinants and prediction of esterase substrate promiscuity patterns</article-title>. <source>ACS Chem. Biol.</source><volume><bold>13</bold></volume>, <fpage>225</fpage>–<lpage>234</lpage> (<year>2017</year>).<pub-id pub-id-type="pmid">29182315</pub-id></mixed-citation>
    </ref>
    <ref id="r73">
      <label>73</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names><surname>Yang</surname></string-name><etal/></person-group>, <article-title>Functional and informatics analysis enables glycosyltransferase activity prediction</article-title>. <source>Nat. Chem. Biol.</source><volume><bold>14</bold></volume>, <fpage>1109</fpage>–<lpage>1117</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30420693</pub-id></mixed-citation>
    </ref>
    <ref id="r74">
      <label>74</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. F.</given-names><surname>Fisher</surname></string-name>, <string-name><given-names>H. M.</given-names><surname>Snodgrass</surname></string-name>, <string-name><given-names>K. A.</given-names><surname>Jones</surname></string-name>, <string-name><given-names>M. C.</given-names><surname>Andorfer</surname></string-name>, <string-name><given-names>J. C.</given-names><surname>Lewis</surname></string-name></person-group>, <article-title>Site-selective C–H halogenation using flavin-dependent halogenases identified via family-wide activity profiling</article-title>. <source>ACS Cent. Sci.</source><volume><bold>5</bold></volume>, <fpage>1844</fpage>–<lpage>1856</lpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31807686</pub-id></mixed-citation>
    </ref>
    <ref id="r75">
      <label>75</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Bastard</surname></string-name><etal/></person-group>, <article-title>Revealing the hidden functional diversity of an enzyme family</article-title>. <source>Nat. Chem. Biol.</source><volume><bold>10</bold></volume>, <fpage>42</fpage>–<lpage>49</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24240508</pub-id></mixed-citation>
    </ref>
    <ref id="r76">
      <label>76</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names><surname>Rives</surname></string-name><etal/></person-group>, <article-title>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume><bold>118</bold></volume>, <fpage>e2016239118</fpage> (<year>2021</year>).<pub-id pub-id-type="pmid">33876751</pub-id></mixed-citation>
    </ref>
    <ref id="r77">
      <label>77</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Rogers</surname></string-name>, <string-name><given-names>M.</given-names><surname>Hahn</surname></string-name></person-group>, <article-title>Extended-connectivity fingerprints</article-title>. <source>J. Chem. Inf. Model.</source><volume><bold>50</bold></volume>, <fpage>742</fpage>–<lpage>754</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20426451</pub-id></mixed-citation>
    </ref>
    <ref id="r78">
      <label>78</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Jaeger</surname></string-name>, <string-name><given-names>S.</given-names><surname>Fulle</surname></string-name>, <string-name><given-names>S.</given-names><surname>Turk</surname></string-name></person-group>, <article-title>Mol2vec: Unsupervised machine learning approach with chemical intuition</article-title>. <source>J. Chem. Inf. Model.</source><volume><bold>58</bold></volume>, <fpage>27</fpage>–<lpage>35</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29268609</pub-id></mixed-citation>
    </ref>
    <ref id="r79">
      <label>79</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>H.</given-names><surname>Wang</surname></string-name><etal/></person-group>, Chemical-reaction-aware molecule representation learning. arXiv [Preprint] (2021). <ext-link xlink:href="http://arxiv.org/abs/2109.09888" ext-link-type="uri">http://arxiv.org/abs/2109.09888</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r80">
      <label>80</label>
      <mixed-citation publication-type="other">X. Glorot, Y. Bengio, “Understanding the difficulty of training deep feedforward neural networks” in <italic toggle="yes">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</italic> (JMLR Workshop and Conference Proceedings, 2010), pp. 249–256.</mixed-citation>
    </ref>
    <ref id="r81">
      <label>81</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Loshchilov</surname></string-name>, <string-name><given-names>F.</given-names><surname>Hutter</surname></string-name></person-group>, Decoupled weight decay regularization. arXiv [Preprint] (2017). <ext-link xlink:href="http://arxiv.org/abs/1711.05101" ext-link-type="uri">http://arxiv.org/abs/1711.05101</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r82">
      <label>82</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>I.</given-names><surname>Loshchilov</surname></string-name>, <string-name><given-names>F.</given-names><surname>Hutter</surname></string-name></person-group>, SGDR: Stochastic gradient descent with warm restarts. arXiv [Preprint] (2019). <ext-link xlink:href="http://arxiv.org/abs/1608.03983" ext-link-type="uri">http://arxiv.org/abs/1608.03983</ext-link> (Accessed 7 December 2022).</mixed-citation>
    </ref>
    <ref id="r83">
      <label>83</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names><surname>Hie</surname></string-name>, <string-name><given-names>B. D.</given-names><surname>Bryson</surname></string-name>, <string-name><given-names>B. A.</given-names><surname>Berger</surname></string-name></person-group>, <article-title>Leveraging uncertainty in machine learning accelerates biological discovery and design</article-title>. <source>Cell Syst.</source><volume><bold>11</bold></volume>, <fpage>461</fpage>–<lpage>477.e9</lpage> (<year>2020</year>).<pub-id pub-id-type="pmid">33065027</pub-id></mixed-citation>
    </ref>
  </ref-list>
  <sec sec-type="supplementary-material" id="s30">
    <title>Supporting Information</title>
  </sec>
</back>
