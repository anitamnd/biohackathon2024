<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9930278</article-id>
    <article-id pub-id-type="publisher-id">5168</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-023-05168-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>petiteFinder: an automated computer vision tool to compute Petite colony frequencies in baker’s yeast</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Nunn</surname>
          <given-names>Christopher J.</given-names>
        </name>
        <address>
          <email>chris.nunn@utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Klyshko</surname>
          <given-names>Eugene</given-names>
        </name>
        <address>
          <email>e.klyshko@mail.utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Goyal</surname>
          <given-names>Sidhartha</given-names>
        </name>
        <address>
          <email>goyal@physics.utoronto.ca</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Physics, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON M5S 2W9 Canada </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Chemical and Physical Sciences, </institution><institution>University of Toronto Mississauga, </institution></institution-wrap>Mississauga, ON L5L 1C6 Canada </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>IBBME, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON M5S 3G9 Canada </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>24</volume>
    <elocation-id>50</elocation-id>
    <history>
      <date date-type="received">
        <day>9</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>1</day>
        <month>2</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Mitochondrial respiration is central to cellular and organismal health in eukaryotes. In baker’s yeast, however, respiration is dispensable under fermentation conditions. Because yeast are tolerant of this mitochondrial dysfunction, yeast are widely used by biologists as a model organism to ask a variety of questions about the integrity of mitochondrial respiration. Fortunately, baker’s yeast also display a visually identifiable Petite colony phenotype that indicates when cells are incapable of respiration. Petite colonies are smaller than their Grande (wild-type) counterparts, and their frequency can be used to infer the integrity of mitochondrial respiration in populations of cells. Unfortunately, the computation of Petite colony frequencies currently relies on laborious manual colony counting methods which limit both experimental throughput and reproducibility.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">To address these problems, we introduce a deep learning enabled tool, <italic>petiteFinder</italic>, that increases the throughput of the Petite frequency assay. This automated computer vision tool detects Grande and Petite colonies and computes Petite colony frequencies from scanned images of Petri dishes. It achieves accuracy comparable to human annotation but at up to 100 times the speed and outperforms semi-supervised Grande/Petite colony classification approaches. Combined with the detailed experimental protocols we provide, we believe this study can serve as a foundation to standardize this assay. Finally, we comment on how Petite colony detection as a computer vision problem highlights ongoing difficulties with small object detection in existing object detection architectures.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">Colony detection with <italic>petiteFinder</italic> results in high accuracy Petite and Grande detection in images in a completely automated fashion. It addresses issues in scalability and reproducibility of the Petite colony assay which currently relies on manual colony counting. By constructing this tool and providing details of experimental conditions, we hope this study will enable larger-scale experiments that rely on Petite colony frequencies to infer mitochondrial function in yeast.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-023-05168-5.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Computer vision</kwd>
      <kwd>Object detection</kwd>
      <kwd>Mitochondrial respiration</kwd>
      <kwd>Baker’s yeast</kwd>
      <kwd>Colony morphology</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>NSERC</institution>
        </funding-source>
        <award-id>RGPIN-2015-0</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id>
            <institution>Simons Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>326844</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Canadian Foundation for Innovation (CFI)</institution>
        </funding-source>
        <award-id>32708</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par4">Eukaryotic cells have numerous mitochondria containing multiple copies of their genome, mitochondrial DNA (mtDNA). In most eukaryotes, mtDNA encodes a subset of proteins involved in oxidative phosphorylation, while the remainder is encoded in nuclear DNA (nDNA). <italic>Saccharomyces cerevisiae</italic>, or baker’s yeast, is a widely used model organism to study the interdependence of mtDNA and nDNA. This is largely due to the dispensability of respiration in yeast under fermentable conditions, which allows cells to propagate without mitochondrial/nuclear-encoded genes involved in respiration. In particular, tolerance to mutations in mtDNA, which would otherwise be fatal to cells in other model systems, enables the study of mtDNA dynamics in yeast, including interesting questions regarding mtDNA maintenance, selection, and mutation.</p>
    <p id="Par5">Since the discovery of the Petite colony phenotype in yeast, this phenotype has played a central role in studying the interplay of nDNA and mtDNA [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. As the name suggests, the Petite phenotype is characterized by small, more translucent colonies compared to Grande (wild-type) colonies under fermentable conditions. These colonies are smaller and have lower cell density due to the inability to switch to respiration once fermentable carbon sources have been consumed as the colony spreads on an agar surface. The ease of distinguishing Petite from Grande colonies visually, with nothing but a Petri dish and its agar surface, is part of what has made the Petite phenotype popular as an indicator of mitochondrial function.</p>
    <p id="Par6">Measurements of Petite colony frequencies have found various uses in the literature. By transplanting mtDNA into yeast strains with various genetic backgrounds, changes in Petite frequencies resulting from this transplantation have been used to understand what effect variants in nuclear genes and mtDNA structures have on mtDNA stability [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]. Petite frequencies have also been shown to be useful as a screen to determine what nuclear genes are responsible for mtDNA recombination that affect mtDNA integrity [<xref ref-type="bibr" rid="CR5">5</xref>–<xref ref-type="bibr" rid="CR8">8</xref>], and chemicals that induce mitochondrial maintenance, or mitophagy [<xref ref-type="bibr" rid="CR9">9</xref>]. Petite frequency measurements have been integrated into a powerful approach that discovered numerous genes involved in mitochondrial biogenesis [<xref ref-type="bibr" rid="CR10">10</xref>]. Furthermore, mating cells with wild-type and mutated mtDNAs and measuring the fraction of progeny that themselves are Petite provides access to the selection and dynamics of competing mtDNAs [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>].</p>
    <p id="Par7">While the Petite frequency assay is both accessible and versatile, current methods of Petite colony identification are laborious. These methods often involve manual annotation of Petri dishes under growth conditions where Petite/Grande colony differences are perceptible or replica plating onto non-fermentable media (see for example the methods in [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>]). Annotation under different growth conditions across laboratories, which can influence Petite versus Grande colony characteristics, also hinders reproducibility.</p>
    <p id="Par8">Although no automation tool designed specifically for the Petite frequency assay exists to our knowledge, machine learning algorithms have been widely used to detect and count colonies in images to improve the scalability of other colony morphology assays [<xref ref-type="bibr" rid="CR13">13</xref>–<xref ref-type="bibr" rid="CR18">18</xref>]. Unsupervised/semi-supervised versions of these methods, such as the popular AutoCellSeg [<xref ref-type="bibr" rid="CR15">15</xref>], OpenCFU [<xref ref-type="bibr" rid="CR13">13</xref>], and CellProfiler [<xref ref-type="bibr" rid="CR14">14</xref>], primarily perform colony segmentation (separating colonies from background). While these tools do perform admirably under ideal conditions (uniform background, lack of imaging artifacts), they can struggle to segment colonies under some experimental conditions. The consequence is that many of these unsupervised/semi-supervised approaches require user input to help characterize colonies (e.g. max/min size, eccentricity, and plate location in [<xref ref-type="bibr" rid="CR13">13</xref>–<xref ref-type="bibr" rid="CR15">15</xref>]). The same user input requirements exist in supervised approaches, where the preprocessing of colonies based on size/eccentricity is common [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Unfortunately, as experimental conditions change, user defined parameters often need to be tuned between images which reduces pipeline throughput. Furthermore, in all of the aforementioned approaches except [<xref ref-type="bibr" rid="CR17">17</xref>], colony classification is left entirely to the users; they must engineer and select features before applying their own supervised classifier to distinguish between different classes of segmented colonies.</p>
    <p id="Par9">In the present study, we develop an automated computer vision tool that addresses the limited scalability and reproducibility of the Petite frequency assay. Our tool, <italic>petiteFinder</italic>, detects Petite/Grande colonies and computes Petite frequencies from scanned images of Petri dishes. Unlike existing colony detection approaches, <italic>petiteFinder</italic> requires no mandatory user input and performs both segmentation and the classification of colonies in one step. <italic>petiteFinder</italic> is built on the open-source object detection toolbox MMDetection [<xref ref-type="bibr" rid="CR19">19</xref>] and a computer vision library SAHI [<xref ref-type="bibr" rid="CR20">20</xref>], which improves small object detection via image slicing. It uses a Faster RCNN [<xref ref-type="bibr" rid="CR21">21</xref>] object detection architecture built on top of a ResNet-50 backbone [<xref ref-type="bibr" rid="CR22">22</xref>] coupled with a feature pyramid network (FPN) [<xref ref-type="bibr" rid="CR23">23</xref>]. Besides colony detection, <italic>petiteFinder</italic> also enables users to amend colony classification predictions with a user-friendly interface.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Acquisition of the Grande/Petite colony dataset</title>
      <p id="Par10">To generate a dataset for this tool, we performed plating experiments where yeast colonies were grown on an agar surface in Petri dishes. We conducted these experiments with fermentable media (both synthetic and complete) that can be constructed to support baker’s yeast strains with any auxotrophies (see details in "<xref rid="Sec10" ref-type="sec">Media and growth conditions</xref>" section). The only constraint on the media was a carbon composition of 3% glycerol and 0.1% glucose that allows for robust visual identification of Grande/Petite colonies after 3–5 days of growth on agar at <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$30\,^{\circ }$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mn>30</mml:mn><mml:msup><mml:mspace width="0.166667em"/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq1.gif"/></alternatives></inline-formula>C [<xref ref-type="bibr" rid="CR4">4</xref>]. With this carbon composition, Petite colonies appear smaller and more translucent than their Grande counterparts on an agar surface. On synthetic media (SC-ura-trp), we mated a Grande strain and a variety of Petite strains. We plated this mixture to identify whether or not the progeny of mated parents were Petite or Grande. On complete media (YPADG), we plated cells from a single haploid strain to identify spontaneous transitions from Grande to Petite cells. These experiments yielded Petri dishes with Petite colony frequencies ranging from ~0 to 0.9.</p>
      <p id="Par11">Following these experiments, Petri dishes were scanned with an image scanner, six at a time (see Petri dish imaging, Fig. <xref rid="Fig1" ref-type="fig">1</xref>a). Images were then cropped to contain an individual petri dish with the aid of a 3D printed scanner insert that fixed their positions and reduced refraction due to adjacent plates. These images were manually annotated using the LabelMe package [<xref ref-type="bibr" rid="CR24">24</xref>], where bounding boxes were drawn around Grande and Petite colonies and assigned to their corresponding labels by an expert in Petite/Grande colony identification. The resulting labeled dataset is a collection of 83 petri dish images, 59 in synthetic media and 24 in complete media. There are 5799 bounding box annotations encompassing colonies, with 2716 Petite and 3083 Grande labels in total. Variation in agar concentrations within synthetic media poured into plates in this dataset produced 20 images we consider “non-ideal” due to the diffuseness of colonies, and 39 images we consider “ideal” (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b). Images of complete media were largely consistent and did not exhibit this variability. All types of images were used as training data. This experimental variation, both at the level of media and the types of experiments that generated these plates, is further augmented during training to produce a robust computer vision model. Images were split into 60% training, 20% validation, and 20% test sets.<fig id="Fig1"><label>Fig. 1</label><caption><p>An overview of the labeled dataset. <bold>a</bold> A composite image showing Petri dishes containing synthetic (top 4 Petri dishes) and complete media (bottom 2 Petri dishes) with yeast colonies on their surface. Six petri dishes at a time were placed in a 3D printed insert (black structure bordering petri dish images) and scanned on a computer scanner bottom-up. The synthetic media was SC-ura-trp and the complete media was YPADG (both 0.1% glucose and 3% glycerol carbon source). <bold>b</bold> Individual plate images were cropped out of the large image, and 83 of these images were annotated using the LabelMe annotation tool [<xref ref-type="bibr" rid="CR24">24</xref>]. Grande and Petite colonies are indicated by blue and orange bounding boxes, respectively. Experimental variation in media preparation/pouring of plates produces diffuse low-quality scans (non-ideal) and sharper plate images (ideal) as shown by example plate crops (i) and (ii) for synthetic media. Plate crop (iii) is complete media that has uniform agar opacity across all images</p></caption><graphic xlink:href="12859_2023_5168_Fig1_HTML" id="MO1"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Model architecture</title>
      <p id="Par12">The detection and classification of colonies is an object detection problem that is commonly solved in computer vision through convolutional neural networks (CNN) [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]. Object detection frameworks built on region-based convolutional neural networks (RCNNs) remain among top performers in object detection competitions [<xref ref-type="bibr" rid="CR27">27</xref>]. However, small object detection is challenging for most RCNN approaches, where lower-level features (in early layers of the network) of small objects are lost through coarse-graining via convolutions and pooling. The Faster-RCNN architecture [<xref ref-type="bibr" rid="CR21">21</xref>] coupled with a feature pyramid network (FPN) has been shown to improve performance in small object detection [<xref ref-type="bibr" rid="CR23">23</xref>]. Specifically, the FPN achieves high accuracy detection of small objects by propagating high-level features down to lower layers in the network and sharing feature maps of multiple scales with the region proposal component of the detector.</p>
      <p id="Par13">Despite adopting the architectural advantages of FPN for small object detection, a Faster-RCNN ResNet-50 FPN pipeline performed poorly in Petite colony detection on whole images of Petri dishes. Petite colonies were largely undetected in test images, although Grande colonies were appropriately localized. We attributed this to the initial downsampling of images (<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1024\times 1024$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mn>1024</mml:mn><mml:mo>×</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq2.gif"/></alternatives></inline-formula>) we performed to fit models on consumer GPUs. This downsampling can eliminate Petite colonies in images due to their small size. To address this poor performance, we employed SAHI [<xref ref-type="bibr" rid="CR20">20</xref>], a computer vision package that performs model inference through image slicing. Instead of whole images, small slices of images are passed through the Faster-RCNN ResNet-50 FPN architecture, which increases the relative size of colonies to the background in the network. Following object detection on all image slices from sliding windows over the entire image, slice predictions are merged in a greedy non-maximal merging algorithm (NMM). This algorithm operates like non-maximal suppression (NMS), but instead of eliminating bounding boxes, it simply merges them above a particular intersection over smaller area (IOS) threshold. The final output of the model operating on an image is a collection of predicted colony bounding boxes with Grande/Petite classification probability (Fig. <xref rid="Fig2" ref-type="fig">2</xref>).<fig id="Fig2"><label>Fig. 2</label><caption><p>The architecture of the object detection pipeline. The entire plate image is first sliced into cropped images (red boxes) using a sliding window with the SAHI package. The image slice is scaled to (<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1024\times 1024$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mn>1024</mml:mn><mml:mo>×</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq3.gif"/></alternatives></inline-formula>) regardless of its size and is passed into a ResNet-50-FPN convolutional neural network backbone. Here, Sx represents the convolutional stage of the ResNet-50 network. Solid blue indicates stages that were frozen during training. Convolution block outputs are rescaled (dotted arrow), undergo element-wise addition (intersection of solid and dotted arrows), and in one case, undergo max pooling (red arrow). This is the feature pyramid underlying the FPN (feature pyramid network) nomenclature. The output of this step is a collection of feature maps of various scales (resolutions) and semantic values. All feature maps are passed into the Faster R-CNN object detection architecture. In this architecture, the region proposal network (RPN), which is fully convolutional, generates region proposals that are likely to contain objects. These proposals are then passed to a final regressor and classifier which outputs a predicted bounding box and probability score for the class of the predicted object. Bounding boxes per image slice are filtered through non-maximal suppression (NMS). Finally, bounding box predictions on all image slices are merged into the final image using a non-maximum merging algorithm (NMM). The final output is a set of predicted bounding boxes on the entire image with associated Grande/Petite class probabilities (lower left image and zoomed portion)</p></caption><graphic xlink:href="12859_2023_5168_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>Model training</title>
      <p id="Par14">Network weights were initialized with a network pre-trained on the Microsoft Common Objects in Context (COCO) dataset [<xref ref-type="bibr" rid="CR28">28</xref>] with 80 classification categories. Network weights were frozen from stage 1 to the beginning of the ResNet-50 backbone (indicated by solid blue blocks in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). The rest of the network was trained for 17 epochs with a batch size of 50 through stochastic gradient descent with a learning rate of 0.001, momentum 0.9, and weight decay of 0.0001. We used a learning rate scheduler with step-based decay, a linear warmup of 500 iterations, a warmup ratio of 0.001, and decay steps of factor 10 at 8 and 11 epochs. Images fed to the network during training were (<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$512\times 512$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mn>512</mml:mn><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq4.gif"/></alternatives></inline-formula>) image crops of Petri dishes upsampled to (<inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1024\times 1024$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mn>1024</mml:mn><mml:mo>×</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq5.gif"/></alternatives></inline-formula>) through bilinear interpolation. The crop size was selected so that objects in cropped images were of comparable size to objects from the COCO dataset. This step was important as frozen network weights were trained on objects of much larger relative size and correspond to these scale-specific features. Extensive data augmentation was also applied to training images, including random flips, 0.8 to 1.0 scale crops, and photometric distortions. These distortions included: random changes of brightness, contrast, saturation and hue, colour conversions between BGR and HSV, and randomly swapping colour channels (see details in MMDetection documentation: [<xref ref-type="bibr" rid="CR19">19</xref>]).</p>
      <p id="Par15">The training parameters (including learning policies and optimizers) were selected following an extensive hyperparameter grid search on the validation image set. Once optimal hyperparameters had been selected for the network, we performed a hyperparameter grid search for SAHI. Bounding boxes were merged through NMM if they had a confidence score above 0.6 and had matching class predictions with an IOS of greater than 0.5.</p>
    </sec>
    <sec id="Sec6">
      <title>Model evaluation</title>
      <p id="Par16">During model finetuning, model performance was evaluated through the mean average precision metric with a bounding box intersection over union threshold (IOU) of 0.5 (mAP@0.5) on the validation set. Mean average precision is the area under the precision-recall curve across all bounding box confidence scores. Precision <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$= \frac{TP}{TP + FP}$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq6.gif"/></alternatives></inline-formula> and recall <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$= \frac{TP}{TP+FN}$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq7.gif"/></alternatives></inline-formula> with TP, FP, and FN, being true positives, false positives, and false negatives, respectively. For SAHI fine-tuning, we optimized parameters on the absolute error between predicted and ground truth Petite frequencies on images. However, this yielded similar parameters and performance to optimizing SAHI on mAP@0.5. For model performance on the test set, we report the mean average precision over IOUs ranging from 0.5 to 0.95 in 0.05 increments (mAP@0.5:0.95), alongside mAP@0.5, and mAP@0.75, which are commonly used in object detection competitions. We also show the Grande and Petite precision and recall. Finally, we compared predicted and ground truth Petite frequencies in the test set to evaluate real-world performance.</p>
    </sec>
    <sec id="Sec7">
      <title>Pipeline implementation</title>
      <p id="Par17"><italic>petiteFinder</italic> is implemented in Python 3.7.11 and uses the MMDetection package [<xref ref-type="bibr" rid="CR19">19</xref>] to build, train, and test the model. Training/testing was performed on an Nvidia GTX 1070 and GTX 1080 GPU with CUDA toolkit 11.3.1. It also uses SAHI [<xref ref-type="bibr" rid="CR20">20</xref>] which relies on MMDetection to perform sliced predictions. Before images are passed through the pipeline, slice heights and widths are determined by the image resolution equation, <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_W = S_H = \sqrt{I_w I_H S_A}$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq8.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_W$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq9.gif"/></alternatives></inline-formula>, <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_H$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mi>S</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq10.gif"/></alternatives></inline-formula>, <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_w$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mi>I</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq11.gif"/></alternatives></inline-formula>, <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$I_H$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mi>I</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq12.gif"/></alternatives></inline-formula> are slice and image widths and heights, respectively. <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_A$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mi>S</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq13.gif"/></alternatives></inline-formula> is the relative area of the image slices to the area of the training images, which for our training set was <inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_A = \frac{512\times 512}{2376\times 2288}$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>512</mml:mn><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow><mml:mrow><mml:mn>2376</mml:mn><mml:mo>×</mml:mo><mml:mn>2288</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq14.gif"/></alternatives></inline-formula>. Assuming a user provides images of Petri dishes that fill the frame, this equation computes image slices with colony sizes relative to the background that are comparable to the training images. Under circumstances where colonies differ significantly in size from the training data, an alternative equation, <inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_W = S_H = \frac{GD_I}{GD_t}\times 512$$\end{document}</tex-math><mml:math id="M30"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>G</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>512</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq15.gif"/></alternatives></inline-formula> can be optionally used to compute image slices. In this equation, <inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$GD_I$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:mi>G</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq16.gif"/></alternatives></inline-formula> represents the typical diameter of a Grande colony provided by a user, <inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$GD_t$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mi>G</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq17.gif"/></alternatives></inline-formula> the typical Grande diameter from the training data, and 512 is the size in pixels of the training image slices. This equation serves to enforce the same Grande size to slice size ratio as the training data, but is only necessary under extreme circumstances where adherence to our experimental conditions are grossly violated (See Additional File <xref rid="MOESM1" ref-type="media">1</xref>: Appendix C).</p>
      <p id="Par18">Users of <italic>petiteFinder</italic> have the option to output a CSV of Petite frequencies, visually annotated images with bounding boxes and scores, and a COCO formatted JSON file of annotations. There is also an option to amend <italic>petiteFinder</italic> annotations with a GUI that enables users to explore predictions and add/remove bounding boxes around colonies (see Fig. <xref rid="Fig3" ref-type="fig">3</xref>).<fig id="Fig3"><label>Fig. 3</label><caption><p>An example of the interface in the amend function within <italic>petiteFinder</italic>. <bold>a</bold> The default view upon opening the GUI. Orange and blue boxes are Petites and Grandes, respectively. Arrow buttons in the top left can be used to move through images that have predictions. Hovering over colonies with a cursor reveals their class and probability score in the upper right. <bold>b</bold> An example where a user is zooming into an image to add a new Grande bounding box that is being drawn in white in the center of the frame. Upon finishing the drawing movement with the mouse, the bounding box switches to the appropriate colour (blue) in this case. Functions also exist to remove bounding boxes after being selected with the cursor</p></caption><graphic xlink:href="12859_2023_5168_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Experimental details and best practices</title>
      <sec id="Sec9">
        <title>Petri dish imaging</title>
        <p id="Par19">Six 100 mm Petri dishes were scanned at a time, bottom-up, on an Epson V370 photo scanner at 600 DPI. The scanner was equipped with a custom 3D printed insert that dishes were placed into on the scanner surface and a black felt backing above the imaging surface. The 3D printed insert fixes Petri dish location for ease in cropping and reduces refraction from neighbouring Petri dishes which cause imaging artifacts. The black felt backing produced a dark background in scans which increased contrast between colonies and media in the images. Individual Petri dishes were cropped from the initial scan to fill the frame, resulting in (<inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2376\times 2288$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mn>2376</mml:mn><mml:mo>×</mml:mo><mml:mn>2288</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq18.gif"/></alternatives></inline-formula>) resolution images per petri dish. For best performance, images should be cropped so that Petri dishes fill the frame, as calculations of slice size are performed in the pipeline under this assumption. It is also recommended to have a resolution of at least (<inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1000\times 1000$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mn>1000</mml:mn><mml:mo>×</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq19.gif"/></alternatives></inline-formula>) per Petri dish image to obtain comparable results to those reported in this study for similar sized colonies.</p>
      </sec>
      <sec id="Sec10">
        <title>Media and growth conditions</title>
        <p id="Par20">Yeast colonies were grown on both complex and synthetic media to capture potential imaging variability in the most widely used growth media. The complex media was YPADG (1% yeast extract, 2% bacto-peptone, 0.1% glucose, 3% glycerol, 0.072% adenine hemisulfate). Synthetic media was SC-ura-trp (0.67% bacto yeast nitrogen base w/o amino acids, 0.1% glucose, 3% glycerol, 0.2% dropout powder lacking uracil and tryptophan). The shared characteristic across both media types that enables Petite identification is the carbon composition with reduced glucose which causes Petites to appear smaller and more translucent after 3–5 days of growth at <inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$30\,^\circ$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mn>30</mml:mn><mml:msup><mml:mspace width="0.166667em"/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq20.gif"/></alternatives></inline-formula>C [<xref ref-type="bibr" rid="CR4">4</xref>]. Before plating, liquid cultures were grown at <inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$30\,^\circ$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:mn>30</mml:mn><mml:msup><mml:mspace width="0.166667em"/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq21.gif"/></alternatives></inline-formula>C in a linear shaking water bath, while solid media growth took place in a forced air incubator at <inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$30\,^\circ$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:mn>30</mml:mn><mml:msup><mml:mspace width="0.166667em"/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq22.gif"/></alternatives></inline-formula>C. Across the labeled dataset, images were taken in a range from 3 to 5 days after growth, resulting in varying relative sizes of Petite/Grande colonies. However, Petites were discernible by eye after this timeframe in all images.</p>
      </sec>
      <sec id="Sec11">
        <title>Yeast strains</title>
        <p id="Par21">All strains used in Petite frequency experiments were in the W303 background. Yeast cultured on SC-ura-trp (0.1% glucose, 3% glycerol carbon source) were matings between W303 <italic>MATa</italic>
<italic>leu</italic>2-3,112 <italic>can</italic>1-100 <italic>ura</italic>3-1 <italic>ade</italic>2-1 <italic>his</italic>3-11,15 and W303 <italic>MAT</italic><inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M46"><mml:mi>α</mml:mi></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq23.gif"/></alternatives></inline-formula>
<italic>leu</italic>2-3,112 <italic>can</italic>1-100 <italic>ade</italic>2-1 <italic>his</italic>3-11,15 <italic>trp</italic>1-1. Yeast cultured on YPADG was a haploid strain W303 <italic>MATa</italic>
<italic>leu</italic>2-3,112 <italic>can</italic>1-100 <italic>ura</italic>3-1 <italic>ade</italic>2-1 <italic>his</italic>3-11,15.</p>
      </sec>
    </sec>
    <sec id="Sec12">
      <title>Predictions with published semi-supervised methods</title>
      <sec id="Sec13">
        <title>OpenCFU</title>
        <p id="Par22">Predictions on the test image set were performed with OpenCFU 3.9.1. Automatic bilateral thresholding was used alongside the auto outlier filter (default threshold of 30) and auto ROI masking. Minimum and maximum colony radii were 4 and 44 px, respectively. These radii correspond most closely to the minimum and maximum colony areas of 40 px<inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M48"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq24.gif"/></alternatives></inline-formula> and 6000 px<inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M50"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq25.gif"/></alternatives></inline-formula> used in our finely tuned semi-supervised pipeline (detailed in Additional File <xref rid="MOESM1" ref-type="media">1</xref>: Appendix A) to ensure a fair comparison.</p>
      </sec>
      <sec id="Sec14">
        <title>CellProfiler</title>
        <p id="Par23">Predictions on the test image set were performed with CellProfiler 4.2.4. As a pipeline, we used a suggested yeast colony classification protocol [<xref ref-type="bibr" rid="CR14">14</xref>] as a base, and modified it to provide a fair comparison with the other semi-supervised methods. Illumination correction with default parameters was applied to each color channel, and results were then combined, followed by alignment and masking. A binary mask of the plate (excluding its boundaries) was obtained through the resizing of a provided template image to fit the plate shape in our test set. During segmentation, a minimum and maximum area of 40 px<inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M52"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq26.gif"/></alternatives></inline-formula> and 6000 px<inline-formula id="IEq27"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M54"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq27.gif"/></alternatives></inline-formula> were used to filter yeast colonies, similar to the other semi-supervised methods. Initially we applied the same eccentricity filtering (<inline-formula id="IEq28"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt; 0.9$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq28.gif"/></alternatives></inline-formula>) as in our semi-supervised method. However, the results demonstrated a very low segmentation precision. Results were dramatically improved by using a lower eccentricity threshold of <inline-formula id="IEq29"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt; 0.6$$\end{document}</tex-math><mml:math id="M58"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq29.gif"/></alternatives></inline-formula>. The classification of the colonies within CellProfiler was based on a colony size threshold of 1000 px<inline-formula id="IEq30"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M60"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq30.gif"/></alternatives></inline-formula> between Petite and Grande bins.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec15">
    <title>Results</title>
    <sec id="Sec16">
      <title>Pipeline performance</title>
      <p id="Par24">To evaluate the performance of the pipeline, <italic>petiteFinder</italic> was applied to the images in the test set and compared against ground truth annotations. The test set consists of 17 petri dish images (4 YPADG, 4 SC-ura-trp nonideal, 9 SC-ura-trp ideal) with 1327 ground truth colonies. Of these 1327 colonies, 602 are Grande and 725 are Petite. On the test set, <italic>petiteFinder</italic> achieved a mean average precision at IOU = 0.5 of 0.96. Grande colonies had a precision and recall of 0.96 and 0.99, and Petite colonies a precision and recall of 0.96 and 0.98 (Table <xref rid="Tab1" ref-type="table">1</xref>). These results are without any post-processing or user input. To improve accuracy even further, users can cull model predictions below a particular quality score.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Summary of ground truth versus predicted annotations from <italic>petiteFinder</italic>. Ground truth annotations of 1327 colonies were compared to predicted annotations from <italic>petiteFinder</italic> across 17 images in the test set</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">mAP(0.5:0.95): 0.64</th><th align="left">mAP@0.5: 0.96</th><th align="left">mAP@0.75: 0.62</th></tr><tr><th align="left">Category</th><th align="left">Precision</th><th align="left">Recall</th></tr></thead><tbody><tr><td align="left">Grande</td><td align="left">0.96</td><td align="left">0.99</td></tr><tr><td align="left">Petite</td><td align="left">0.96</td><td align="left">0.98</td></tr></tbody></table><table-wrap-foot><p>The top row includes mean average precision computations (mAP) across IOU thresholds from 0.5 to 0.95 in 0.05 increments, at 0.5 IOU, and 0.75 IOU. Below this, precision <inline-formula id="IEq31"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{TP}{TP + FP}$$\end{document}</tex-math><mml:math id="M62"><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq31.gif"/></alternatives></inline-formula> and recall <inline-formula id="IEq32"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{TP}{TP+FN}$$\end{document}</tex-math><mml:math id="M64"><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq32.gif"/></alternatives></inline-formula> at 0.5 IOU have been computed for each colony class</p></table-wrap-foot></table-wrap></p>
      <p id="Par25">To test what these accuracy metrics mean for computations based on colony detections, we compared Petite frequencies determined by <italic>petiteFinder</italic> and manual counting for each petri dish (Fig. <xref rid="Fig4" ref-type="fig">4</xref>a). The red points are predictions, and the black points are manual counting (ground truth) Petite frequencies. Across all test images, the average absolute difference in predicted versus ground truth Petite percentages (prediction error) is 1.7%, with a standard deviation of 1.2%. To understand the potential impact of this error on biological insights gained from <italic>petiteFinder</italic> predictions, we compare the prediction error to expected variation in Petite frequencies from experimental sampling. Assuming that the generation of Petite colonies is a Bernoulli process, the standard deviation in Petite frequency expected from sampling numerous Petri dishes with the same underlying Petite probability is <inline-formula id="IEq33"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sqrt{\frac{P(1-P)}{k}}$$\end{document}</tex-math><mml:math id="M66"><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:mfrac></mml:msqrt></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq33.gif"/></alternatives></inline-formula>. Here <italic>P</italic> represents the probability of Petite colony production and <italic>k</italic> is the number of colonies per Petri dish. Taking <italic>P</italic> to be the ground truth Petite frequency, and <inline-formula id="IEq34"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=78$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>78</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq34.gif"/></alternatives></inline-formula>, which is the average number of colonies per plate in the test set, we plot this binomial sampling error as a gray envelope around the ground truth measurements with ± the binomial standard deviation (gray envelope in Fig. <xref rid="Fig4" ref-type="fig">4</xref>a). Above Petite frequencies of 0.1, Fig. <xref rid="Fig4" ref-type="fig">4</xref>a demonstrates that <italic>petiteFinder</italic> predictions are within this sampling error envelope, suggesting that prediction errors are less impactful than sampling error itself. Below 0.1 petite frequency, where sampling error is negligible, predictions exist outside this envelope but still yield small absolute error compared to ground truth measurements (<inline-formula id="IEq35"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt;5$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq35.gif"/></alternatives></inline-formula>% error in Petite percentage).</p>
      <p id="Par26">While we applied extensive data augmentation during training that would encompass a variety of imaging conditions, one parameter that remained fixed in both training and testing was the image resolution. Therefore, to understand how robust <italic>petiteFinder</italic> is to image resolution, we plotted model accuracy metrics while varying the image resolution of the test set in Fig. <xref rid="Fig4" ref-type="fig">4</xref>b. The x-axis in this plot should be interpreted as the fractional size in x and y dimensions of the test image relative to the training image resolution (<inline-formula id="IEq36"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2376\times 2288$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:mn>2376</mml:mn><mml:mo>×</mml:mo><mml:mn>2288</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq36.gif"/></alternatives></inline-formula>). Recall of the model in the top panel of Fig. <xref rid="Fig4" ref-type="fig">4</xref>b reveals that below 0.1 test image resolution (<inline-formula id="IEq37"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$238\times 229$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mn>238</mml:mn><mml:mo>×</mml:mo><mml:mn>229</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq37.gif"/></alternatives></inline-formula>) all colonies disappear according to the model due to their small size. As expected, this occurs first for Petites which are composed of fewer pixels. As we move towards lower resolutions starting at <inline-formula id="IEq38"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M76"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq38.gif"/></alternatives></inline-formula>0.4 of test image resolution (<inline-formula id="IEq39"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$950\times 915$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mn>950</mml:mn><mml:mo>×</mml:mo><mml:mn>915</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq39.gif"/></alternatives></inline-formula>), we see that Petite colony precision drastically decreases due to misclassifications of small imaging artifacts as Petites. The same decrease in precision occurs for Grandes but at even lower test image resolutions. Petite frequency prediction error is also shown in the bottom panel as a function of test image resolution. Remarkably, at 0.4 test image resolution and above (<inline-formula id="IEq40"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$950\times 915$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mn>950</mml:mn><mml:mo>×</mml:mo><mml:mn>915</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq40.gif"/></alternatives></inline-formula> or <inline-formula id="IEq41"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M82"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq41.gif"/></alternatives></inline-formula>1M px<inline-formula id="IEq42"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M84"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq42.gif"/></alternatives></inline-formula>), prediction accuracy is comparable to the results on our (<inline-formula id="IEq43"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2376\times 2288$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:mn>2376</mml:mn><mml:mo>×</mml:mo><mml:mn>2288</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq43.gif"/></alternatives></inline-formula>) resolution plate images. In general, the resolution threshold where Petite detection degrades most rapidly is dependent on experimental conditions that dictate Petite colony size. For our particular experimental conditions, this threshold indicates that a rapid degradation in Petite detection performance occurs below <inline-formula id="IEq44"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$4\times$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:mn>4</mml:mn><mml:mo>×</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq44.gif"/></alternatives></inline-formula> the resolution where Petite colonies vanish.<fig id="Fig4"><label>Fig. 4</label><caption><p><italic>petiteFinder</italic> performance compared to manual counting alongside a test of model robustness. <bold>a</bold> A plate-wise comparison of predicted and manually counted Petite colony frequencies. The red curves are the predictions and the black curves are manual counting. The average absolute deviation between predicted and ground truth Petite percentage (prediction error) is 1.7%. The gray envelope is the binomial sampling error (ground truth ± standard deviation), assuming that Petite production is a Bernoulli process with a probability equal to the ground truth frequency when sampling 78 colonies per plate image. <bold>b</bold> Top panel: Precision and recall of each colony category as a function of test image resolution normalized by the image resolution of the training data. Bottom panel: Absolute error in petite frequency as a function of test image resolution. The error is defined as the deviation between predicted and ground truth Petite frequency. Labels are also included to denote absolute image resolutions</p></caption><graphic xlink:href="12859_2023_5168_Fig4_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec17">
      <title>Comparing performance with semi-supervised methods</title>
      <p id="Par27">To provide context for the performance of <italic>petiteFinder</italic>, here we compare its performance on the test set to our own semi-supervised method tailored to Petite/Grande detection as well as the popular OpenCFU [<xref ref-type="bibr" rid="CR13">13</xref>] and CellProfiler [<xref ref-type="bibr" rid="CR14">14</xref>] pipelines.</p>
      <p id="Par28">As a stepping stone towards building <italic>petiteFinder</italic>, we developed a semi-supervised colony detection approach that incorporates Otsu’s thresholding [<xref ref-type="bibr" rid="CR29">29</xref>], watershed segmentation [<xref ref-type="bibr" rid="CR30">30</xref>], and plate detection with a Hough transform [<xref ref-type="bibr" rid="CR31">31</xref>]. We then relied on two features of Petite/Grande colonies that were biologically relevant to the classification problem, the size and intensity of colonies, and clustered colonies based on these features with average-linkage agglomerative clustering. The complete development of this method can be found in Additional File <xref rid="MOESM1" ref-type="media">1</xref>: Appendix A. Like most existing semi-supervised methods, the application of our semi-supervised pipeline required a choice of minimum/maximum colony sizes, which were selected to be 40 px<inline-formula id="IEq45"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M90"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq45.gif"/></alternatives></inline-formula>/6000 px<inline-formula id="IEq46"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^2$$\end{document}</tex-math><mml:math id="M92"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq46.gif"/></alternatives></inline-formula> by averaging the optimal choices for these parameters shown in Additional File <xref rid="MOESM1" ref-type="media">1</xref>: Table A.1, following a parameter grid search. The same minimum and maximum colony sizes were adopted for OpenCFU and CellProfiler to ensure a fair comparison. More details on the choices for other parameters in these pipelines can be found in Methods: <xref rid="Sec12" ref-type="sec">Predictions with published semi-supervised methods</xref>.</p>
      <p id="Par29">First, we compare the colony segmentation performance of these semi-supervised methods to <italic>petiteFinder</italic>. The results are shown in Table <xref rid="Tab2" ref-type="table">2</xref>, where precision and recall, which are class agnostic in the case of segmentation, are shown for IOU thresholds of 0.25 and 0.5. A small IOU threshold of 0.25 is important in this comparison because classical segmentation can produce bounding boxes smaller than the colonies themselves or the bounding boxes drawn by humans in the test set. OpenCFU and our semi-supervised approach exhibit comparable performance, with OpenCFU having a marginal advantage across all metrics and IOU thresholds. CellProfiler exhibits the lowest segmentation precision across semi-supervised approaches as a result of false positives due to refraction artifacts near the edges of Petri dishes (an example is shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. B.2). The tradeoff, however, is that CellProfiler exhibits the highest segmentation recall across all semi-supervised methods. Examples of the failure modes of these semi-supervised methods can be found in Appendix B, Additional File <xref rid="MOESM1" ref-type="media">1</xref>: Figs B.1–B.5. In contrast to the semi-supervised methods, <italic>petiteFinder</italic> performs admirably, with better segmentation performance than the semi-supervised methods across all metrics. In particular, <italic>petiteFinder</italic> improves segmentation precision at 0.25 IOU compared to the next best semi-supervised method by 11%, and recall by 19%.<table-wrap id="Tab2"><label>Table 2</label><caption><p>A comparison of segmentation performance across existing semi-supervised colony detection methods, our own semi-supervised approach, and <italic>petiteFinder</italic>. Parameter regimes for each method are described in the text. Segmentation accuracy on the test dataset is displayed as class agnostic precision and recall at the two bounding box IOU thresholds of 0.25 and 0.5</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Method (IOU)</th><th align="left" colspan="2">Segmentation precision</th><th align="left" colspan="2">Segmentation recall</th></tr><tr><th align="left">(0.25)</th><th align="left">(0.5)</th><th align="left">(0.25)</th><th align="left">(0.5)</th></tr></thead><tbody><tr><td align="left">OpenCFU</td><td align="left">0.88</td><td align="left">0.54</td><td align="left">0.75</td><td align="left">0.65</td></tr><tr><td align="left">CellProfiler</td><td align="left">0.56</td><td align="left">0.32</td><td align="left">0.84</td><td align="left">0.75</td></tr><tr><td align="left">Our semi-supervised</td><td align="left">0.81</td><td align="left">0.50</td><td align="left">0.73</td><td align="left">0.63</td></tr><tr><td align="left">petiteFinder</td><td align="left"><bold>0.98</bold></td><td align="left"><bold>0.97</bold></td><td align="left"><bold>1.0</bold></td><td align="left"><bold>1.0</bold></td></tr></tbody></table><table-wrap-foot><p>Bold numbers indicate the maximum in each column</p></table-wrap-foot></table-wrap></p>
      <p id="Par30">Next, we compare colony detection performance, which is a combination of colony segmentation and classification. To do so with OpenCFU, which only provides segmentation, we applied the same unsupervised clustering of colony size/intensity as in our semi-supervised pipeline to the segmented regions. This reflects the canonical use of many of these segmentation pipelines, where users often apply their own classification methods to segmentation results. For CellProfiler, colonies were classified as Grande or Petite by applying a size threshold on the segmented mask. Results are shown in Table <xref rid="Tab3" ref-type="table">3</xref>, where Grande and Petite precision and recall are shown for 0.25 and 0.5 IOU thresholds. Grande precision and recall are larger on average than for Petite colonies across all methods. This isn’t too surprising, as small colonies have a greater potential to be filtered out from the background through size thresholding when comparable in size to artifacts or dust. Smaller colonies are also more likely to be eliminated through coarse graining during successive convolutions or when edge detection/texture filters are applied. OpenCFU coupled with our unsupervised clustering marginally outperforms <italic>petiteFinder</italic> in Grande precision, with an improvement of 2% in precision at 0.25 IOU. However, <italic>petiteFinder</italic> outperforms all other tested methods in Grande recall and Petite precision and recall. The Grande precision of <italic>petiteFinder</italic> is 27% better than the next best performing semi-supervised method at 0.25 IOU. More impressively, given the difficulty of detecting Petite colonies, <italic>petiteFinder</italic> improves Petite precision and recall by 59% and 18% over the next best performing semi-supervised pipeline at 0.25 IOU. Notably, this performance improvement is achieved without requiring any user input. This is in contrast to the finely tuned segmentation parameters that were adopted by both OpenCFU and CellProfiler from our semi-supervised colony detection approach.<table-wrap id="Tab3"><label>Table 3</label><caption><p>A comparison of the object detection performance (segmentation + classification) across existing semi-supervised colony detection methods, our own semi-supervised approach, and <italic>petiteFinder</italic>. OpenCFU was modified by applying size/intensity average linkage clustering from our semi-supervised pipeline following its segmentation (referred to in table as + clust.). With CellProfiler, size filtering following segmentation was used to classify colonies as Grande or Petite. A version of CellProfiler with our unsupervised size/intensity clustering is also shown</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Method (IOU)</th><th align="left" colspan="2">Grande precision</th><th align="left" colspan="2">Grande recall</th><th align="left" colspan="2">Petite precision</th><th align="left" colspan="2">Petite recall</th></tr><tr><th align="left">(0.25)</th><th align="left">(0.5)</th><th align="left">(0.25)</th><th align="left">(0.5)</th><th align="left">(0.25)</th><th align="left">(0.5)</th><th align="left">(0.25)</th><th align="left">(0.5)</th></tr></thead><tbody><tr><td align="left">OpenCFU + clust.</td><td align="left"><bold>1.00</bold></td><td align="left"><bold>0.97</bold></td><td align="left">0.78</td><td align="left">0.78</td><td align="left">0.61</td><td align="left">0.06</td><td align="left">0.54</td><td align="left">0.10</td></tr><tr><td align="left">CellProfiler</td><td align="left">0.97</td><td align="left">0.95</td><td align="left">0.76</td><td align="left">0.75</td><td align="left">0.40</td><td align="left">0.07</td><td align="left">0.83</td><td align="left">0.47</td></tr><tr><td align="left">CellProfiler + clust.</td><td align="left">0.95</td><td align="left">0.94</td><td align="left">0.62</td><td align="left">0.61</td><td align="left">0.38</td><td align="left">0.07</td><td align="left">0.83</td><td align="left">0.48</td></tr><tr><td align="left">Our semi-supervised</td><td align="left">0.99</td><td align="left">0.93</td><td align="left">0.60</td><td align="left">0.58</td><td align="left">0.46</td><td align="left">0.06</td><td align="left">0.52</td><td align="left">0.13</td></tr><tr><td align="left"><italic>petiteFinder</italic></td><td align="left">0.98</td><td align="left">0.96</td><td align="left"><bold>0.99</bold></td><td align="left"><bold>0.99</bold></td><td align="left"><bold>0.97</bold></td><td align="left"><bold>0.96</bold></td><td align="left"><bold>0.98</bold></td><td align="left"><bold>0.98</bold></td></tr></tbody></table><table-wrap-foot><p>Parameter regimes for each method are described in the text. Grande and Petite precision and recall are shown with bounding box IOU thresholds of 0.25 and 0.5. Bold numbers indicate the maximum in each column</p></table-wrap-foot></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec18">
    <title>Discussion</title>
    <p id="Par31">In this study we introduced <italic>petiteFinder</italic>, a computer vision tool to detect Grande and Petite colonies and determine Petite colony frequencies from images of Petri dishes. <italic>petiteFinder</italic> is the first computer vision pipeline tailored for this application to the best of our knowledge. We showed that it performs comparably to human annotation, with errors that are smaller on average than the theoretical sampling error. Overall, the average difference in computed Petite percentages between <italic>petiteFinder</italic> predictions and manually annotated colonies was 1.7%. We also detailed best practices for using the tool, including minimum image resolutions and protocols to recreate imaging conditions. When <italic>petiteFinder</italic> is run on a GPU such as an Nvidia GTX 1070, each Petri dish image is processed in <inline-formula id="IEq47"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M94"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq47.gif"/></alternatives></inline-formula>2 s. Depending on colony density, this is a 10–100 fold improvement in throughput relative to manual counting without any user input. <italic>petiteFinder</italic> can also be run on a CPU, and, although the inference will be significantly slower (<inline-formula id="IEq48"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M96"><mml:mo>∼</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq48.gif"/></alternatives></inline-formula>2 min per image), it still comes with the benefit of being completely automated. We believe that this advancement in throughput and detailed protocols for imaging and experimental conditions will drastically increase this assay’s statistical power and repeatability.</p>
    <p id="Par32">While on average <italic>petiteFinder</italic> performed admirably, under 0.1 Petite frequency we see a larger prediction error than binomial sampling error from a distribution of cells with a fixed probability of becoming Petite. This is due to the sensitivity to false positives at low Petite frequencies. To address this issue and enable modifications to model predictions, we designed a GUI that allows experimentalists to visually explore and amend prediction outputs from <italic>petiteFinder</italic>. This ‘amend’ function lets users draw and remove bounding boxes around colonies following the initial prediction. Beyond performance and usability, we also emphasized how this computer vision problem of identifying Petite colonies highlighted ongoing difficulties in small object detection. We motivated changes to existing object detection architectures that were necessary to detect Petite colonies in this study, even with state-of-the-art architectures.</p>
    <p id="Par33">Regarding the development of this pipeline, a natural question is whether or not a supervised deep learning architecture is necessary to solve this problem with sufficient accuracy. Numerous popular semi-supervised approaches exist for colony segmentation, such as OpenCFU [<xref ref-type="bibr" rid="CR13">13</xref>], CellProfiler [<xref ref-type="bibr" rid="CR14">14</xref>], and AutoCellSeg [<xref ref-type="bibr" rid="CR15">15</xref>]. These pipelines use a variety of thresholding and edge detection algorithms to segment colonies from the background of plate images, are immensely popular in the bioinformatics community, and perform comparably to humans in certain assays [<xref ref-type="bibr" rid="CR13">13</xref>–<xref ref-type="bibr" rid="CR15">15</xref>]. Therefore, is it necessary to leverage deep-learning to solve this problem? To address this question, we directly compared segmentation and classification performance between semi-supervised methods and <italic>petiteFinder</italic> on the test image set. We showed that <italic>petiteFinder</italic> outperforms all of the tested methods at colony segmentation. While <italic>petiteFinder</italic> was outperformed by 2% in Grande precision by a modified OpenCFU implementation, <italic>petiteFinder</italic> was an improvement of <inline-formula id="IEq49"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ge 18\%$$\end{document}</tex-math><mml:math id="M98"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>18</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2023_5168_Article_IEq49.gif"/></alternatives></inline-formula> across all other accuracy metrics compared to the next best semi-supervised methods. Most notably, <italic>petiteFinder</italic> improved Petite precision and Recall by 59% and 18%, which are the most important metrics when calculating Petite frequencies. These improvements place <italic>petiteFinder</italic> prediction error below theoretical sampling error in most regimes, which is not the case for semi-supervised methods applied to this problem (see Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figs. A.2b, A.5, B.4, B.5 for examples). Besides these performance improvements, <italic>petiteFinder</italic> also improves throughput as it requires no mandatory user input, which is in stark contrast to the finely tuned semi-supervised methods that generally require user input per image to address varying experimental conditions. A general discussion of the user input requirements of these methods can be found in Additional File <xref rid="MOESM1" ref-type="media">1</xref>: Section B.1</p>
    <p id="Par34">Finally, it is important to comment on comparisons to existing deep-learning colony detection methods. A relevant comparison is the supervised red/white yeast colony detection pipeline described in [<xref ref-type="bibr" rid="CR17">17</xref>]. This pipeline can be used for Petite frequency calculations in strains with an appropriate genetic background or with colonies that have been treated with tetrazolium. In yeast strains with specific mutations in the adenine synthesis pathway, an intermediate compound (initially white) accumulates and turns red when oxidized in respiring cells. It is also possible to treat cells in any genetic background with a tetrazolium-agar overlay to induce a transition from a white to red colony surface, specifically in Grande cells [<xref ref-type="bibr" rid="CR10">10</xref>]. While the pipeline in [<xref ref-type="bibr" rid="CR17">17</xref>] performs admirably, and could be modified for Petite detection with the red/white colony assay, there are two disadvantages to using the red/white assay over our experimental approach. First, the red/white assay is accompanied by a potentially cumbersome set of experimental constraints. The red/white assay requires constraints on the media (adenine limited media) and a specific genetic background of the strains, or chemical treatments that have to be carefully applied after colony growth. On the other hand, large/small colony detection only requires constraints on the media. Second, for red pigments to form, experimentalists often need to wait further after colony growth or chemical treatment which decreases experimental efficiency compared to our approach. With respect to the object detection pipeline in [<xref ref-type="bibr" rid="CR17">17</xref>], one downside is that it requires post-processing of segmentation results, including heuristics on eccentricity and absolute size of colonies in pixels. Furthermore, assuming perfect segmentation in the study [<xref ref-type="bibr" rid="CR17">17</xref>] (where segmentation accuracy is not reported), <italic>petiteFinder</italic> still achieves higher accuracy in Grande/Petite classification compared to white/red classification in experiments.</p>
  </sec>
  <sec id="Sec19">
    <title>Conclusion</title>
    <p id="Par35">In this study we developed <italic>petiteFinder</italic>, an automated computer vision tool to detect Grande and Petite yeast colonies and determine Petite frequencies from images of Petri dishes. Colony detection with <italic>petiteFinder</italic> results in high accuracy Petite and Grande localization in images in a completely automated fashion. It achieves accuracy comparable to human annotation but at up to 100 times the speed and outperforms semi-supervised Grande/Petite colony classification approaches. By constructing this tool and providing details of experimental conditions, we hope this study will enable larger-scale experiments that rely on Petite colony frequencies to infer mitochondrial function in yeast.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec20">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2023_5168_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1</bold>. Appendix A, B, and C for petiteFinder.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>The authors thank numerous members of the Goyal lab for their thoughtful comments and discussions. They also thank members of the Humans Learning Machine Learning group (HLML) at the University of Toronto, in particular Jeremy Rothschild, for their comments on the manuscript. E.K. thanks Dr. Sarah Rauscher for funding support.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>CJN and SG conceptualized the project. Both CJN and EK implemented, modified, and trained computer vision models in hyperparameter grid searches. CJN and EK also wrote the software for both the GUI and CLI. EK wrote tool installation and usage documentation. CJN performed the experiments and labeled data, evaluated model performance, created manuscript figures, and wrote the initial draft. EK edited the manuscript. CJN constructed and evaluated the semi-supervised approach in Additional File <xref rid="MOESM1" ref-type="media">1</xref>. S.G. acquired funding and provided feedback on the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The authors (excluding E.K.) received funding from the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant RGPIN-2015-0, the Simons Foundation Grant 326844 in the Mathematical Modeling of Living Systems, and funding for equipment from the Canadian Foundation for Innovation (CFI) Grant 32708.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>Source code, detailed documentation on installation and use, modifiable 3D print files, and all labeled data in this study are available at <ext-link ext-link-type="uri" xlink:href="http://www.github.com/javathejhut/petiteFinder">www.github.com/javathejhut/petiteFinder</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par36">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par37">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par38">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ephrussi</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hottinguer</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Tavlitzki</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Action de l’acriflovine sur les levures: ii-etude genetique de mutant petite colonie</article-title>
        <source>Ann Inst Pasteur</source>
        <year>1949</year>
        <volume>76</volume>
        <fpage>419</fpage>
        <lpage>450</lpage>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ephrussi</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <source>Nucleo-cytoplasmic relations in micro-organisms–their bearing on cell heredity and differentiation</source>
        <year>1953</year>
        <publisher-loc>Oxford</publisher-loc>
        <publisher-name>Oxford at the Clarendon Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Contamine</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Picard</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Maintenance and integrity of the mitochondrial genome: a plethora of nuclear genes in the budding yeast</article-title>
        <source>Microbiol Mol Biol Rev</source>
        <year>2000</year>
        <volume>64</volume>
        <fpage>281</fpage>
        <lpage>315</lpage>
        <pub-id pub-id-type="doi">10.1128/mmbr.64.2.281-315.2000</pub-id>
        <?supplied-pmid 10839818?>
        <pub-id pub-id-type="pmid">10839818</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dimitrov</surname>
            <given-names>LN</given-names>
          </name>
          <name>
            <surname>Brem</surname>
            <given-names>RB</given-names>
          </name>
          <name>
            <surname>Kruglyak</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gottschling</surname>
            <given-names>DE</given-names>
          </name>
        </person-group>
        <article-title>Polymorphisms in multiple genes contribute to the spontaneous mitochondrial genome instability of saccharomyces cerevisiae s288c strains</article-title>
        <source>Genetics</source>
        <year>2009</year>
        <volume>183</volume>
        <fpage>365</fpage>
        <lpage>383</lpage>
        <pub-id pub-id-type="doi">10.1534/genetics.109.104497</pub-id>
        <?supplied-pmid 19581448?>
        <pub-id pub-id-type="pmid">19581448</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ling</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Shibata</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Recombination-dependent mtdna partitioning: in vivo role of mhr1p to promote pairing of homologous dna</article-title>
        <source>EMBO J</source>
        <year>2002</year>
        <volume>21</volume>
        <fpage>4730</fpage>
        <lpage>4740</lpage>
        <pub-id pub-id-type="doi">10.1093/emboj/cdf466</pub-id>
        <?supplied-pmid 12198175?>
        <pub-id pub-id-type="pmid">12198175</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ling</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Shibata</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Mhr1p-dependent concatemeric mitochondrial dna formation for generating yeast mitochondrial homoplasmic cells</article-title>
        <source>Mol Biol Cell</source>
        <year>2004</year>
        <pub-id pub-id-type="doi">10.1091/mbc.E03-07-0508</pub-id>
        <?supplied-pmid 14565971?>
        <pub-id pub-id-type="pmid">14565971</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shibata</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ling</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Dna recombination protein-dependent mechanism of homoplasmy and its proposed functions</article-title>
        <source>Mitochondrion</source>
        <year>2007</year>
        <pub-id pub-id-type="doi">10.1016/j.mito.2006.11.024</pub-id>
        <?supplied-pmid 17280877?>
        <pub-id pub-id-type="pmid">17280877</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ling</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Bradshaw</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Yoshida</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Prevention of mitochondrial genomic instability in yeast by the mitochondrial recombinase mhr1</article-title>
        <source>Sci Rep</source>
        <year>2019</year>
        <pub-id pub-id-type="doi">10.1038/s41598-019-41699-9</pub-id>
        <?supplied-pmid 31772241?>
        <pub-id pub-id-type="pmid">31772241</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Karavaeva</surname>
            <given-names>IE</given-names>
          </name>
          <name>
            <surname>Golyshev</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Smirnova</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Sokolov</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Severin</surname>
            <given-names>FF</given-names>
          </name>
          <name>
            <surname>Knorre</surname>
            <given-names>DA</given-names>
          </name>
        </person-group>
        <article-title>Mitochondrial depolarization in yeast zygotes inhibits clonal expansion of selfish mtdna</article-title>
        <source>J Cell Sci</source>
        <year>2017</year>
        <volume>130</volume>
        <fpage>1274</fpage>
        <lpage>1284</lpage>
        <pub-id pub-id-type="doi">10.1242/jcs.197269</pub-id>
        <?supplied-pmid 28193734?>
        <pub-id pub-id-type="pmid">28193734</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hess</surname>
            <given-names>DC</given-names>
          </name>
          <name>
            <surname>Myers</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Huttenhower</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hibbs</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Hayes</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Paw</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Clore</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Mendoza</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Luis</surname>
            <given-names>BS</given-names>
          </name>
          <name>
            <surname>Nislow</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Giaever</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Costanzo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Troyanskaya</surname>
            <given-names>OG</given-names>
          </name>
          <name>
            <surname>Caudy</surname>
            <given-names>AA</given-names>
          </name>
        </person-group>
        <article-title>Computationally driven, quantitative experiments discover genes required for mitochondrial biogenesis</article-title>
        <source>PLoS Genet</source>
        <year>2009</year>
        <pub-id pub-id-type="doi">10.1371/journal.pgen.1000407</pub-id>
        <?supplied-pmid 19300474?>
        <pub-id pub-id-type="pmid">19300474</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zamaroczy</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Marotta</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Faugeron-fonty</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Goursot</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Mangin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Baldacci</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Bernardi</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The origins of replication of the yeast mitochondrial genome and the phenomenon of suppressivity</article-title>
        <source>Nature</source>
        <year>1981</year>
        <pub-id pub-id-type="doi">10.1038/292075a0</pub-id>
        <?supplied-pmid 7024821?>
        <pub-id pub-id-type="pmid">7024821</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nunn</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Goyal</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Contingency and selection in mitochondrial genome dynamics</article-title>
        <source>eLife</source>
        <year>2022</year>
        <volume>11</volume>
        <fpage>76557</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.76557</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Geissmann</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Opencfu, a new free and open-source software to count cell colonies and other circular objects</article-title>
        <source>PLoS ONE</source>
        <year>2013</year>
        <volume>8</volume>
        <issue>2</issue>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0054072</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bray</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Vokes</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Carpenter</surname>
            <given-names>AE</given-names>
          </name>
        </person-group>
        <article-title>Using cellprofiler for automatic identification and measurement of biological objects in images</article-title>
        <source>Curr Protocols Mol Biol</source>
        <year>2015</year>
        <pub-id pub-id-type="doi">10.1002/0471142727.mb1417s109</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khan</surname>
            <given-names>AUM</given-names>
          </name>
          <name>
            <surname>Torelli</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wolf</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Gretz</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Autocellseg: robust automatic colony forming unit (cfu)/cell analysis using adaptive image segmentation and easy-to-use post-editing techniques</article-title>
        <source>Sci Rep</source>
        <year>2018</year>
        <pub-id pub-id-type="doi">10.1038/s41598-018-24916-9</pub-id>
        <?supplied-pmid 30568257?>
        <pub-id pub-id-type="pmid">30568257</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siragusa</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dall’Olio</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fredericia</surname>
            <given-names>PM</given-names>
          </name>
          <name>
            <surname>Jensen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Groesser</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Cell colony counter called coconut</article-title>
        <source>PLOS ONE</source>
        <year>2018</year>
        <volume>13</volume>
        <issue>11</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0205823</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Carl</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Duempelmann</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shimada</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bühler</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>A fully automated deep learning pipeline for high-throughput colony segmentation and classification</article-title>
        <source>Biol Open</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1242/bio.052936</pub-id>
        <?supplied-pmid 32487517?>
        <pub-id pub-id-type="pmid">32487517</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dijkstra</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>van de Loosdrecht</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Atsma</surname>
            <given-names>WA</given-names>
          </name>
          <name>
            <surname>Schomaker</surname>
            <given-names>LRB</given-names>
          </name>
          <name>
            <surname>Wiering</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>Centroidnetv2: a hybrid deep neural network for small-object segmentation and counting</article-title>
        <source>Neurocomputing</source>
        <year>2021</year>
        <volume>423</volume>
        <fpage>490</fpage>
        <lpage>505</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2020.10.075</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Wang J, Chen K, Yang S, Loy CC, Lin D. Region proposal by guided anchoring. In Proceedings of the IEEE computer society conference on computer vision and pattern recognition. 2019. 10.1109/CVPR.2019.00308.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Akyon FC, Altinuc SO, Temizel A. Slicing aided hyper inference and fine-tuning for small object detection. 2022. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2202.06934">arXiv:2202.06934</ext-link> [Cs]. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/org">arXiv.org</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ren</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Girshick</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Faster r-cnn: towards real-time object detection with region proposal networks</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2017</year>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2016.2577031</pub-id>
        <?supplied-pmid 29990186?>
        <pub-id pub-id-type="pmid">29990186</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. 2016. 10.1109/CVPR.2016.90.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Lin TY, Dolláir P, Girshick R, He K, Hariharan B, Belongie S. Feature pyramid networks for object detection. In: Proceedings 30th IEEE conference on computer vision and pattern recognition, CVPR 2017. 2017. 10.1109/CVPR.2017.106.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Russell</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Torralba</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>KP</given-names>
          </name>
          <name>
            <surname>Freeman</surname>
            <given-names>WT</given-names>
          </name>
        </person-group>
        <article-title>Labelme: a database and web-based tool for image annotation</article-title>
        <source>Int J Comput Vis</source>
        <year>2008</year>
        <pub-id pub-id-type="doi">10.1007/s11263-007-0090-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fukushima</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</article-title>
        <source>Biol Cybern</source>
        <year>1980</year>
        <volume>36</volume>
        <issue>4</issue>
        <fpage>193</fpage>
        <lpage>202</lpage>
        <pub-id pub-id-type="doi">10.1007/BF00344251</pub-id>
        <?supplied-pmid 7370364?>
        <pub-id pub-id-type="pmid">7370364</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lecun</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Haffner</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Gradient-based learning applied to document recognition</article-title>
        <source>Proc IEEE</source>
        <year>1998</year>
        <volume>86</volume>
        <issue>11</issue>
        <fpage>2278</fpage>
        <lpage>2324</lpage>
        <pub-id pub-id-type="doi">10.1109/5.726791</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>A review of object detection based on deep learning</article-title>
        <source>Multimed Tools Appl</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1007/s11042-020-08976-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Lin T-Y, Maire M, Belongie S, Bourdev L, Girshick R, Hays J, Perona P, Ramanan D, Zitnick CL, Dolláir, P. Microsoft coco: common objects in context. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. 2015.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Otsu</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Threshold selection method from gray-level histograms</article-title>
        <source>IEEE Trans Syst Man Cybern</source>
        <year>1979</year>
        <pub-id pub-id-type="doi">10.1109/tsmc.1979.4310076</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Digabel H, Lantuejoul C. Iterative algorithms. In: Proceedings of the 2nd European Symposium quantitative analysis of microstructures in material science, biology and medicine; 1978, 85–89.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Hough PVC. A method and means for recognition complex patterns; us patent: Us3069654a. US Patent. 1962.</mixed-citation>
    </ref>
  </ref-list>
</back>
