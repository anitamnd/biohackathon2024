<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Genome Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genome Res</journal-id>
    <journal-id journal-id-type="hwp">genome</journal-id>
    <journal-id journal-id-type="publisher-id">GENOME</journal-id>
    <journal-title-group>
      <journal-title>Genome Research</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1088-9051</issn>
    <issn pub-type="epub">1549-5469</issn>
    <publisher>
      <publisher-name>Cold Spring Harbor Laboratory Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8494213</article-id>
    <article-id pub-id-type="pmid">34035047</article-id>
    <article-id pub-id-type="medline">9509184</article-id>
    <article-id pub-id-type="doi">10.1101/gr.271874.120</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Method</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A joint deep learning model enables simultaneous batch effect correction, denoising, and clustering in single-cell transcriptomics</article-title>
      <alt-title alt-title-type="left-running">Lakkis et al.</alt-title>
      <alt-title alt-title-type="right-running">Simultaneous batch effect correction and denoising</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Lakkis</surname>
          <given-names>Justin</given-names>
        </name>
        <xref rid="af1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>David</given-names>
        </name>
        <xref rid="af2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Yuanchao</given-names>
        </name>
        <xref rid="af1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Gang</given-names>
        </name>
        <xref rid="af3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Kui</given-names>
        </name>
        <xref rid="af4" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pan</surname>
          <given-names>Huize</given-names>
        </name>
        <xref rid="af5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ungar</surname>
          <given-names>Lyle</given-names>
        </name>
        <xref rid="af6" ref-type="aff">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Reilly</surname>
          <given-names>Muredach P.</given-names>
        </name>
        <xref rid="af5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-9600-8984</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Xiangjie</given-names>
        </name>
        <xref rid="af3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Mingyao</given-names>
        </name>
        <xref rid="af1" ref-type="aff">1</xref>
      </contrib>
    </contrib-group>
    <aff id="af1"><label>1</label>Department of Biostatistics, Epidemiology, and Informatics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, Pennsylvania 19104, USA;</aff>
    <aff id="af2"><label>2</label>Graduate Group in Genomics and Computational Biology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, Pennsylvania 19104, USA;</aff>
    <aff id="af3"><label>3</label>School of Statistics and Data Science, Key Laboratory for Medical Data Analysis and Statistical Research of Tianjin, Nankai University, Tianjin 300071, China;</aff>
    <aff id="af4"><label>4</label>Department of Information Theory and Data Science, School of Mathematical Sciences and LPMC, Nankai University, Tianjin 300071, China;</aff>
    <aff id="af5"><label>5</label>Division of Cardiology, Department of Medicine, Columbia University Irving Medical Center, New York, New York 10032, USA;</aff>
    <aff id="af6"><label>6</label>Department of Computer and Information Science, School of Engineering and Applied Sciences, University of Pennsylvania, Philadelphia, Pennsylvania 19104, USA</aff>
    <author-notes>
      <corresp>Corresponding authors: <email>jlakks@gmail.com</email>, <email>xiangjie631@outlook.com</email>, <email>mingyao@pennmedicine.upenn.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>10</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <month>10</month>
      <year>2021</year>
    </pub-date>
    <volume>31</volume>
    <issue>10</issue>
    <fpage>1753</fpage>
    <lpage>1766</lpage>
    <history>
      <date date-type="received">
        <day>23</day>
        <month>9</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>5</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>
        <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/site/misc/terms.xhtml" ext-link-type="uri">© 2021 Lakkis et al.; Published by Cold Spring Harbor Laboratory Press</ext-link>
      </copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This article, published in <italic toggle="yes">Genome Research</italic>, is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), as described at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pdf" xlink:href="1753.pdf"/>
    <abstract>
      <p>Recent developments of single-cell RNA-seq (scRNA-seq) technologies have led to enormous biological discoveries. As the scale of scRNA-seq studies increases, a major challenge in analysis is batch effects, which are inevitable in studies involving human tissues. Most existing methods remove batch effects in a low-dimensional embedding space. Although useful for clustering, batch effects are still present in the gene expression space, leaving downstream gene-level analysis susceptible to batch effects. Recent studies have shown that batch effect correction in the gene expression space is much harder than in the embedding space. Methods such as Seurat 3.0 rely on the mutual nearest neighbor (MNN) approach to remove batch effects in gene expression, but MNN can only analyze two batches at a time, and it becomes computationally infeasible when the number of batches is large. Here, we present CarDEC, a joint deep learning model that simultaneously clusters and denoises scRNA-seq data while correcting batch effects both in the embedding and the gene expression space. Comprehensive evaluations spanning different species and tissues showed that CarDEC outperforms Scanorama, DCA + Combat, scVI, and MNN. With CarDEC denoising, non-highly variable genes offer as much signal for clustering as the highly variable genes (HVGs), suggesting that CarDEC substantially boosted information content in scRNA-seq. We also showed that trajectory analysis using CarDEC's denoised and batch-corrected expression as input revealed marker genes and transcription factors that are otherwise obscured in the presence of batch effects. CarDEC is computationally fast, making it a desirable tool for large-scale scRNA-seq studies.</p>
    </abstract>
    <counts>
      <page-count count="14"/>
    </counts>
  </article-meta>
</front>
<body>
  <p>Single-cell RNA sequencing (scRNA-seq) analysis has substantially advanced our understanding of cellular heterogeneity and transformed biomedical research. However, the analysis of scRNA-seq data remains confounded by batch effects, which are inevitable in analyses of human tissue and are prevalent in many scRNA-seq studies in general (<xref rid="GR271874LAKC9" ref-type="bibr">Hicks et al. 2018</xref>; <xref rid="GR271874LAKC14" ref-type="bibr">Lähnemann et al. 2020</xref>). Several methods have been developed to remove batch effects in scRNA-seq data analysis (<xref rid="GR271874LAKC8" ref-type="bibr">Haghverdi et al. 2018</xref>; <xref rid="GR271874LAKC17" ref-type="bibr">Lopez et al. 2018</xref>; <xref rid="GR271874LAKC1" ref-type="bibr">Barkas et al. 2019</xref>; <xref rid="GR271874LAKC13" ref-type="bibr">Korsunsky et al. 2019</xref>; <xref rid="GR271874LAKC25" ref-type="bibr">Stuart et al. 2019</xref>; <xref rid="GR271874LAKC30" ref-type="bibr">Welch et al. 2019</xref>; <xref rid="GR271874LAKC16" ref-type="bibr">Li et al. 2020</xref>; <xref rid="GR271874LAKC21" ref-type="bibr">Polanski et al. 2020</xref>). These methods can be divided into two categories: (1) batch correction in the low-dimensional embedding space, and (2) batch correction in the original gene expression space. Most published papers belong to the first category (<xref rid="GR271874LAKC1" ref-type="bibr">Barkas et al. 2019</xref>; <xref rid="GR271874LAKC13" ref-type="bibr">Korsunsky et al. 2019</xref>; <xref rid="GR271874LAKC30" ref-type="bibr">Welch et al. 2019</xref>; <xref rid="GR271874LAKC16" ref-type="bibr">Li et al. 2020</xref>; <xref rid="GR271874LAKC21" ref-type="bibr">Polanski et al. 2020</xref>). Although useful for profiling the overall characteristics of cells such as clustering and trajectory reconstruction, these methods cannot be used for downstream gene-level analysis like differential expression and coexpression analysis.</p>
  <p>A recent benchmarking study has shown that correcting batch effects in the gene expression space is much more challenging than in the embedding space (<xref rid="GR271874LAKC18" ref-type="bibr">Luecken et al. 2020</xref>). Popular methods such as Seurat 3.0 (<xref rid="GR271874LAKC25" ref-type="bibr">Stuart et al. 2019</xref>) rely on the mutual nearest neighbor (MNN) approach (<xref rid="GR271874LAKC8" ref-type="bibr">Haghverdi et al. 2018</xref>) to remove batch effects in the gene expression space, but MNN can only analyze two batches at a time. Its performance is affected by the order in which batches are corrected and it quickly becomes computationally infeasible when the number of batches gets large. Moreover, our evaluations indicate that MNN performs poorly for removing batch effects for genes that are not highly variable. Non-highly variable genes represent the majority of genes in the genome, in which batch effects constitute a larger fraction of variance in the transcriptome and are much harder to correct.</p>
  <p>To address this gap in the literature, we present count-adapted regularized deep embedded clustering (CarDEC), a joint deep learning framework for simultaneous batch effect correction, denoising, and clustering of scRNA-seq data. Rather than explicitly modeling batch effect, CarDEC jointly optimizes its reconstruction loss with a self-supervised clustering loss. By minimizing a clustering loss iteratively, the batch effects in the embedding are reduced and cell type signal is improved (<xref rid="GR271874LAKC16" ref-type="bibr">Li et al. 2020</xref>). The denoised gene expression values, computed from this embedding using a decoder, are then corrected for batch effects as well. To address the difficulty of batch correcting genes that are not highly variable, which suffer from a lower cell type signal-to-noise ratio, we designed CarDEC using a branching architecture that treats highly variable genes (HVGs) and the remaining genes, which we designate as lowly variable genes (LVGs), as distinct feature blocks.</p>
  <p>CarDEC is unique among batch effect correction methods in that it implicitly corrects for batch effects through joint optimization of its dual objective function rather than explicitly modeling batch effects using batch indicators as in methods such as MNN (<xref rid="GR271874LAKC8" ref-type="bibr">Haghverdi et al. 2018</xref>) and scVI (<xref rid="GR271874LAKC17" ref-type="bibr">Lopez et al. 2018</xref>). Moreover, it corrects batch effects both in the low-dimensional embedding space and the original gene expression space. CarDEC's architecture is founded on the idea of treating HVGs and LVGs as different “feature blocks,” which enables CarDEC to use the HVGs to drive the clustering loss, while still allowing the LVG reconstructions to depend on the rich, batch-corrected embedding learned from the HVGs, to help remove batch effects in the LVGs.</p>
  <sec sec-type="results" id="s1">
    <title>Results</title>
    <sec id="s1a">
      <title>Overview of CarDEC and evaluation</title>
      <p>An outline of the CarDEC workflow is shown in <xref rid="GR271874LAKF1" ref-type="fig">Figure 1</xref>. CarDEC starts with data preprocessing and pretraining of an autoencoder using HVGs with a mean squared error reconstruction loss function. After pretraining, the weights learned from the pretrained autoencoder are transferred over to the main CarDEC model, which treats HVGs and LVGs as different feature blocks. The main CarDEC loss function is a weighted combination of the reconstruction losses for the HVGs and the LVGs, and a self-supervised clustering loss function driven by the HVGs. This combined loss function allows CarDEC to preserve local structure of the data during clustering (<xref rid="GR271874LAKC7" ref-type="bibr">Guo et al. 2017</xref>). By minimizing this self-supervised combined loss function, CarDEC not only improves the low-dimensional embedding for clustering but the reconstructed genewise features, which are computed as a function of the low-dimensional embedding, are also denoised and batch effect–corrected, leading to improved gene expression quality.</p>
      <fig position="float" id="GR271874LAKF1">
        <label>Figure 1.</label>
        <caption>
          <p>The workflow of CarDEC. The CarDEC workflow can be summarized in four steps that are depicted here: preprocessing, pretraining, denoising, and optionally, denoising on the count scale.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="1753f01" position="float"/>
      </fig>
      <p>We evaluated CarDEC on a diverse set of challenging real data sets that range from human to mouse and have different flavors of batch effects. In our evaluations, we wished to assess two properties of CarDEC: (1) its ability to recover biological signals in the data, and (2) its ability to remove spurious technical signals driven by batch effects. An ideal method should strive to remove batch effects while maintaining true biological variations. We compared CarDEC with several state-of-the-art scRNA-seq methods for denoising, batch effect correction, and clustering. scVI (<xref rid="GR271874LAKC17" ref-type="bibr">Lopez et al. 2018</xref>) and DCA (<xref rid="GR271874LAKC5" ref-type="bibr">Eraslan et al. 2019</xref>) are multiuse methods that provide denoised counts in the gene expression feature space and also a low-dimensional embedding that can be used for tasks like clustering and visualization. scVI also attempts to correct for batch effects by conditioning on batch annotation when modeling the denoised counts with a zero-inflated negative binomial distribution. Because DCA is not designed for batch effect correction, to make a fair comparison, we applied Combat (<xref rid="GR271874LAKC11" ref-type="bibr">Johnson et al. 2007</xref>) to DCA denoised gene expression. MNN (<xref rid="GR271874LAKC8" ref-type="bibr">Haghverdi et al. 2018</xref>) is a batch correction method that merges batches in a pairwise manner and generates batch-corrected gene expression on a cosine scale. We used the implementation of the MNN method provided in the R programming language (<xref rid="GR271874LAKC23" ref-type="bibr">R Core Team 2020</xref>). Scanorama (<xref rid="GR271874LAKC10" ref-type="bibr">Hie et al. 2019</xref>) is also based on the mutual nearest neighbor idea, but it finds matching elements among all batches at once, thus speeding it up computationally and making the method invariant to batch order. scDeepCluster (<xref rid="GR271874LAKC28" ref-type="bibr">Tian et al. 2019</xref>) is a clustering method that also draws inspiration from the self-supervised clustering loss (<xref rid="GR271874LAKC7" ref-type="bibr">Guo et al. 2017</xref>). We provide the exact software implementations of these packages that we used in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Table S3</ext-link>.</p>
      <p>To measure the degree of batch mixing, we examined the batchwise centroids after denoising and/or batch correction with each method by calculating a coefficient of variation (CV) metric. For each gene, a CV is calculated for a given cell type using the centroid of each batch in that cell type. Then, to obtain a single CV score, we take the weighted average of the cell type–specific CVs, in which the weight of a cell type is the fraction of the data set's cells that belong to that cell type. The reason for computing CV scores within cell types is that we expect minimal biological heterogeneity within cell types, so in the absence of batch effects we expect batch centroids to be similar to one another within, but not between, cell types. A higher value of CV corresponds to greater variation of gene expression among batches and less batch mixing, whereas a good batch effect removal method should drive the CV value close to zero.</p>
    </sec>
    <sec id="s1b">
      <title>Application to human pancreatic islet data from four protocols</title>
      <p>A unique feature of CarDEC is the branching architecture for both the HVGs and the LVGs. To show that this architecture is key in removing batch effects, we combined four data sets consisting of scRNA-seq expression data in human pancreas generated using Fluidigm C1 (<xref rid="GR271874LAKC15" ref-type="bibr">Lawlor et al. 2017</xref>), Smart-seq2 (<xref rid="GR271874LAKC24" ref-type="bibr">Segerstolpe et al. 2016</xref>), CEL-Seq (<xref rid="GR271874LAKC6" ref-type="bibr">Grün et al. 2016</xref>), and CEL-Seq2 (<xref rid="GR271874LAKC19" ref-type="bibr">Muraro et al. 2016</xref>). This is a challenging task because there are strong batch differences among these different scRNA-seq protocols, and analysis using the raw data as input yielded low adjusted Rand indexes (ARIs) (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S1</ext-link>). The branching architecture was designed with two objectives in mind. First, we wish to show that when correcting batch effects and denoising both the HVGs and the LVGs, using a branching model that treats these feature blocks differently improves the quality of denoised expression values relative to a naive architecture that treats these feature blocks the same. Second, we hope to design a model architecture such that including the LVGs in the model does not worsen denoising and batch effect correction quality of the HVGs, relative to a naive model that only denoises the HVGs and does not attempt to denoise LVGs.</p>
      <p>As shown in <xref rid="GR271874LAKF2" ref-type="fig">Figure 2</xref>, the branching architecture posts significant performance boosts over the naive architecture that treated all genes as the same feature block in the input. The branching architecture performed better for denoising both the HVGs (ARI of 0.93 over 0.72) and the LVGs (ARI of 0.83 over 0.67) relative to the naive architecture (<xref rid="GR271874LAKF2" ref-type="fig">Fig. 2</xref>A,B), underscoring the necessity of using the branching architecture to denoise all genes as efficiently as possible. We also observed that for the purpose of denoising and batch correcting only the HVGs, the branching architecture performed just as well as a naive model that only included the HVGs and completely discarded the LVGs (ARI of 0.93 vs. 0.95) (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S2</ext-link>). This verifies that the branching architecture does not trade off denoising and batch correction effectiveness on the HVGs at all to denoise the LVGs. Additionally, the denoised counts from CarDEC showed less batch effects compared to denoised expression from Scanorama, scVI, and batch-corrected expression from MNN (<xref rid="GR271874LAKF2" ref-type="fig">Fig. 2</xref>A,B). <xref rid="GR271874LAKF2" ref-type="fig">Figure 2</xref>C shows that genewise CV scores obtained from CarDEC are the closest to zero among all compared methods. We also noticed that the clustering accuracy obtained when clustering is performed using denoised values in the gene expression space is similar to the clustering accuracy obtained when using the embedding of CarDEC to do clustering (<xref rid="GR271874LAKF2" ref-type="fig">Fig. 2</xref>D).</p>
      <fig position="float" id="GR271874LAKF2">
        <label>Figure 2.</label>
        <caption>
          <p>Justification for the branching architecture in CarDEC. The CarDEC API splits the input matrix into HVGs and LVGs and treats them separately with a “Branching” architecture as in <xref rid="GR271874LAKF1" ref-type="fig">Figure 1</xref>. Alternatively, we can use a “Naive” model that treats all features the same regardless of gene expression variance. The naive model consists of an autoencoder with a clustering loss in addition to the reconstruction loss. Here, we show the utility of the branching architecture. The HVGs and LVGs were clustered separately, and the ARI of assignments is provided along with a UMAP plot. The <italic toggle="yes">top</italic> row was colored by cell type, the <italic toggle="yes">bottom</italic> row by scRNA-seq protocol. (<italic toggle="yes">A</italic>) UMAP embedding computed from the denoised HVG counts for each method: CarDEC with Branching architecture, CarDEC with Naive Architecture, Scanorama, scVI, and MNN. (<italic toggle="yes">B</italic>) UMAP embedding computed from the denoised LVG counts for each method. Figure legends are the same as those in <italic toggle="yes">A</italic>. (<italic toggle="yes">C</italic>) Density plot of genewise coefficient of variation (CV) among batch centroids. Density plots are provided for HVGs and LVGs separately. (<italic toggle="yes">D</italic>) Clustering accuracy metrics were obtained using the embedding-based methods to cluster the data, rather than running Louvain on the full gene expression space. Results for “Raw” were obtained by using Louvain's algorithm on the original HVG counts and are provided as a baseline to which embedding-based clustering results may be compared.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="1753f02" position="float"/>
      </fig>
    </sec>
    <sec id="s1c">
      <title>Application to macaque retina data with multilevel batch effect</title>
      <p>After finalizing the CarDEC architecture, we next evaluated the performance of CarDEC on a macaque retina data set (<xref rid="GR271874LAKC20" ref-type="bibr">Peng et al. 2019</xref>). This data set poses a great challenge for batch effect correction and denoising because it features strong, multilevel batch effects, with cells sequenced from two different regions, four different macaques, and 30 different samples (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S3</ext-link>).</p>
      <p>For the task of denoising and batch effect correction in the gene expression space, CarDEC was again the best performing method (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figs. S4, S5</ext-link>), followed by scVI whose ARIs are close to CarDEC. CarDEC and scVI not only removed the multilevel batch effects but also preserved inter–cell type variation. The ARI for clustering using the LVG denoised and batch effect–corrected counts from CarDEC is 0.98 and is 0.97 for scVI (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>B), which is as high as that when using the HVGs to do clustering (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>A). As a comparison, the ARI is only 0.15 using the LVG raw counts as input for clustering (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S3</ext-link>). This suggests that the denoising and batch correction in CarDEC and scVI substantially boosted the signal-to-noise ratio in the LVGs. Moreover, CarDEC's and scVI's genewise CVs are the closest to zero, providing evidence that cells were mixed well by batch by these two methods (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>C; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S6</ext-link>).</p>
      <fig position="float" id="GR271874LAKF3">
        <label>Figure 3.</label>
        <caption>
          <p>Comparison of different methods on the macaque retina data set. (<italic toggle="yes">A</italic>) UMAP embedding computed from the denoised HVG counts for each method. The <italic toggle="yes">top</italic> row was colored by cell type; the <italic toggle="yes">bottom</italic> row was colored by Macaque ID. Cells were also clustered with Louvain's algorithm. (<italic toggle="yes">B</italic>) UMAP embedding computed from the denoised LVG counts for each method. Figure legends are the same as those in <italic toggle="yes">A</italic>. (<italic toggle="yes">C</italic>) Density plot of genewise CV among batch centroids. Density plots are provided for HVGs and LVGs separately. Centroids computed with sample ID as batch definition. (<italic toggle="yes">D</italic>) Clustering accuracy metrics were obtained using the embedding-based methods to cluster the data, rather than running Louvain on the full gene expression space. Results for “Raw” were obtained by using Louvain's algorithm on the original HVG counts and are provided as a baseline to which embedding-based clustering results may be compared.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="1753f03" position="float"/>
      </fig>
      <p>The other methods all struggled with batch effects in the denoised counts. Scanorama largely failed to correct batch effects: when using Scanorama batch-corrected gene expression as input, the cells were separated primarily by batch rather than by cell type. For the LVGs, its ARI is as low as that when using the LVG raw counts as input for clustering (Scanorama 0.21 vs. raw 0.15) (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>B; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S3</ext-link>). DCA had slightly higher ARIs than Scanorama for both the HVGs and the LVGs, although both are significantly lower than CarDEC and scVI (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>A,B). MNN performed much better than Scanorama and DCA for batch correcting the HVG counts, achieving an ARI of 0.91 (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>A). However, it still fell short of CarDEC and scVI for this evaluation (CarDEC ARI 0.98 and scVI ARI 0.96). Looking more closely at the HVG UMAP plots, the batches were mixed less thoroughly with MNN than they were for CarDEC and scVI, and the cells were separated less by cell type, indicating that MNN failed to completely recover cell type variation. This is further confirmed by the genewise CV density plot in which the MNN density curve is further away from zero than CarDEC and scVI (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>C). For removing batch effects in the LVG counts, MNN was the worst performing method because it removed nearly all biological variations, leaving only batch effects.</p>
      <p>For the simpler task of clustering using the low-dimensional embedding representation, existing methods did considerably better than they did at batch effect correction in the gene expression space, but still fell short of CarDEC and scVI (<xref rid="GR271874LAKF3" ref-type="fig">Fig. 3</xref>D; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S7</ext-link>). CarDEC and scVI achieved ARIs of nearly 1 for clustering using the embedding. DCA and scDeepCluster performed better than Louvain's algorithm using raw HVGs, but still fell short of achieving as high an ARI as CarDEC and scVI. Scanorama struggled on this data set with an ARI of only 0.57.</p>
    </sec>
    <sec id="s1d">
      <title>Application to mouse cortex and PBMC data from four protocols</title>
      <p>We next compared different methods using a mouse cortex data set (<xref rid="GR271874LAKC4" ref-type="bibr">Ding et al. 2020</xref>). This data set poses a great challenge for batch correction and denoising on two fronts (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S9</ext-link>). First, it shows very serious batch effects because cells were generated using four different scRNA-seq protocols. Furthermore, this data set is heavily dominated by excitatory and inhibitory neurons, and the other cell types are rare, so preserving biological variation is especially imperative for detecting and analyzing these rarer subpopulations.</p>
      <p>For the task of denoising and batch correcting the gene expression space, CarDEC and scVI performed considerably better than the other methods (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>). CarDEC performed the best, followed closely by scVI, at balancing between removing batch effects while preserving as much cell type variability as possible. For both CarDEC and scVI, the ARIs are similar when using the HVG denoised counts and the LVG denoised counts as input for clustering (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>A,B). As a comparison, the ARIs are only 0.28 and 0.26 when using the HVG and the LVG raw counts as input for clustering, respectively (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S9</ext-link>). The relatively low ARI when using the HVG raw counts as input for clustering shows the strong batch effects in this data set. However, for this challenging data set, using CarDEC denoised and batch-corrected LVG counts, the ARI increased to 0.78, suggesting that CarDEC substantially boosted the signal-to-noise ratio in the LVGs by simultaneous denoising and batch effect removal. We observed a similar signal boost by scVI in which the ARI for the LVGs is 0.73. The genewise CVs for CarDEC are also the closest to zero among all methods (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>C). Although scVI achieved high ARIs for both the HVG and LVG denoised gene expression, the cells appeared to be less well mixed than CarDEC (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>A,B), which is in agreement with its larger CVs than CarDEC.</p>
      <fig position="float" id="GR271874LAKF4">
        <label>Figure 4.</label>
        <caption>
          <p>Comparison of different methods on the mouse cortex data set. (<italic toggle="yes">A</italic>) UMAP embedding computed from the denoised HVG counts for each method. The <italic toggle="yes">top</italic> row was colored by cell type; the <italic toggle="yes">bottom</italic> row was colored by batch. Cells were also clustered with Louvain's algorithm, and the resultant ARI is provided. (<italic toggle="yes">B</italic>) UMAP embedding computed from the denoised LVG counts for each method. Figure legends are the same as those in <italic toggle="yes">A</italic>. (<italic toggle="yes">C</italic>) Density plot of genewise CV among batch centroids. Density plots are provided for HVGs and LVGs separately. (<italic toggle="yes">D</italic>) Clustering accuracy metrics obtained using the embedding-based methods to cluster the data, rather than running Louvain on the full gene expression space. Results for “Raw” were obtained by using Louvain's algorithm on the original HVG counts and are provided as a baseline against which embedding-based clustering results may be compared.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="1753f04" position="float"/>
      </fig>
      <p>DCA largely failed for this data set (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>A,B), although its denoised gene expression was also batch corrected by Combat. For both the HVGs and the LVGs, DCA separated the cells purely by scRNA-seq protocol with no mixing of cells from different batches. After denoising using DCA and batch correction with Combat, cell variation was driven entirely by batch, rendering the denoised counts ineffective for downstream analyses. For batch correcting the HVGs, Scanorama was the third-best performer (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>A), followed by MNN. MNN did not merge batches to the extent that CarDEC did and failed to preserve as much cell type variability, causing cell types to mix more. For removing batch effects in the LVGs, MNN did considerably worse than CarDEC and scVI (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>B). It suffered from the same problems as DCA for the LVGs in that cell type variation was lost and all variability was driven by batch. We also noticed that the CVs for DCA are the closest to zero; however, the small CVs are mainly a result of the overcorrection of Combat as the ARIs are low for both the HVGs and the LVGs.</p>
      <p>Owing to the strong batch effects in this data set, even the simpler task of clustering using embedding was very difficult (<xref rid="GR271874LAKF4" ref-type="fig">Fig. 4</xref>D; <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S10</ext-link>). In particular, scDeepCluster performed poorly at this task, scoring a lower ARI than a straightforward application of Louvain's algorithm to the raw data. The ARI for Scanorama is only slightly better than that obtained from the raw data. For this task, scVI was the leader, achieving an ARI of 0.74, followed closely by CarDEC with an ARI of 0.73.</p>
      <p>We also analyzed a data set of human PBMCs from the same study (<xref rid="GR271874LAKC4" ref-type="bibr">Ding et al. 2020</xref>) as the mouse cortex data. This data set was similar to the cortex data set, featuring eight batches spanning five scRNA-seq protocols and the results were largely the same: CarDEC and scVI were the best performers for denoising/batch correcting the HVGs and also the best for denoising/batch correcting the LVGs (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figs. S12–S14</ext-link>).</p>
    </sec>
    <sec id="s1e">
      <title>Application to human monocyte data with pseudotemporal structure</title>
      <p>We next show the utility of CarDEC for improving trajectory analysis for cells with pseudotemporal structure. We analyzed an scRNA-seq data set generated from monocytes derived from human peripheral blood mononuclear cells by Ficoll separation followed by CD14- and CD16-positive cell selection (<xref rid="GR271874LAKC16" ref-type="bibr">Li et al. 2020</xref>). This data set includes 10,878 monocytes from one healthy subject. The cells were processed in three batches from blood drawn on three different days. Although monocytes can be classified as classical (CD14<sup>++</sup>/CD16<sup>−</sup>), intermediate (CD14<sup>++</sup>/CD16<sup>+</sup>), and nonclassical patrolling (CD14<sup>−</sup>/CD16<sup>++</sup>) subpopulations based on surface markers, our previous analysis based on scRNA-seq data indicates that these cells show continuous transcriptional characteristics and trajectory analysis is an appropriate approach to characterize them (<xref rid="GR271874LAKC16" ref-type="bibr">Li et al. 2020</xref>). This data set has strong batch effects (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S16</ext-link>). To reconstruct the trajectories of these cells, for each method, we first denoised and/or batch corrected the gene expression matrix, which was then fed into Monocle 3 (<xref rid="GR271874LAKC2" ref-type="bibr">Cao et al. 2019</xref>) to estimate the pseudotime of each cell.</p>
      <p><xref rid="GR271874LAKF5" ref-type="fig">Figure 5</xref>A shows that CarDEC yields the best pseudotime analysis results with cells from the three batches well mixed, and a clear pseudotemporal path emerged. The batchwise density plots show that the three batches have similar pseudotime distributions, suggesting that CarDEC successfully removed batch effects. The plots of <italic toggle="yes">FCGR3A</italic> (known marker gene for nonclassical monocytes) and <italic toggle="yes">S100A8</italic> (known marker gene for classical monocytes) gene expression also showed expected patterns (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S17</ext-link>). There are two key points of evidence from these marker gene plots suggesting that CarDEC recovered biological signal. First, for each marker gene, the expression levels are virtually identical across batches for all pseudotime points, which indicates that batch effects were removed for each gene expression and pseudotime relationship. Also, <italic toggle="yes">FCGR3A</italic> gene expression decreases monotonically with pseudotime, whereas <italic toggle="yes">S100A8</italic> expression increases monotonically with pseudotime. This is exactly the kind of behavior we expect from these marker genes. Because <italic toggle="yes">FCGR3A</italic> and <italic toggle="yes">S100A8</italic> are markers for the nonclassical and classical monocytes, respectively, we expect a good pseudotime analysis to segment the monocytes from nonclassical to classical (or vice versa) and for <italic toggle="yes">FCGR3A</italic> and <italic toggle="yes">S100A8</italic> expressions to be monotonic functions of pseudotime with opposite trends. By denoising and batch correcting gene counts, CarDEC successfully mixed batches and recovered biological signal down to the individual marker gene level.</p>
      <fig position="float" id="GR271874LAKF5">
        <label>Figure 5.</label>
        <caption>
          <p>Comparison of different methods for pseudotime analysis in the human monocyte data. The analysis is performed on monocytes derived from three technical replicates from the same subject. For each method, the full data set was denoised/batch corrected and then fed to Monocle 3 for pseudotime analysis. We show the UMAP embedding colored by batch (column 1) and estimated pseudotime (column 2). We also visualize the kernel density distribution of pseudotime by batch (column 3) and plot the distributions of marker genes <italic toggle="yes">FCGR3A</italic> and <italic toggle="yes">S100A8</italic> against pseudotime (columns 4 and 5, respectively). (<italic toggle="yes">A</italic>) Pseudotime analysis when using denoised/batch-corrected gene expression matrix from CarDEC as input. (<italic toggle="yes">B</italic>) Pseudotime analysis when using batch-corrected gene expression matrix from Scanorama as input. (<italic toggle="yes">C</italic>) Pseudotime analysis when using denoised gene expression matrix from DCA but with Combat post hoc batch correction as input. (<italic toggle="yes">D</italic>) Pseudotime analysis when using denoised/batch-corrected gene expression matrix from scVI as input. (<italic toggle="yes">E</italic>) Pseudotime analysis when using batch-corrected gene expression matrix from MNN as input.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="1753f05" position="float"/>
      </fig>
      <p>In contrast, no other methods were able to achieve CarDEC's success in improving pseudotime analysis. Scanorama (<xref rid="GR271874LAKF5" ref-type="fig">Fig. 5</xref>B), DCA (<xref rid="GR271874LAKF5" ref-type="fig">Fig. 5</xref>C), and MNN (<xref rid="GR271874LAKF5" ref-type="fig">Fig. 5</xref>E) all failed to mix batches in the UMAP embedding from Monocle 3. Although scVI (<xref rid="GR271874LAKF5" ref-type="fig">Fig. 5</xref>D) mixed batches well in the UMAP embedding, the pseudotime distributions showed substantial variation across batches. For Scanorama, DCA, and MNN, neither of the marker genes show strong monotonic trends as a function of the pseudotime, and for each marker gene, the relationship between expression and pseudotime varied by batch. These issues suggest that Scanorama, DCA, and MNN confounded biological signal and obscured signals from canonical markers of established subpopulations, <italic toggle="yes">FCGR3A</italic> and <italic toggle="yes">S100A8</italic>, as marker genes.</p>
      <p>There are other approaches to using these denoising and batch correction methods for pseudotime analysis. For example, one can subset the denoised and batch-corrected matrix to include only the HVGs and then feed this into Monocle 3 (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figs. S18, S20</ext-link>). Alternatively, one can use the embedding from CarDEC, Scanorama, DCA, or scVI as the reduced dimension space to build the Monocle 3 pseudotime graph (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figs. S19, S21</ext-link>). In both these other cases, the conclusions are largely the same: CarDEC is the best method for improving pseudotime analysis.</p>
      <p>Next, we examined whether the denoised and batch-corrected gene expression values can help improve gene expression quality for biological discovery. We focused our analyses on 61 transcription factors (TFs) that were expressed in the monocyte data and also found to be differentially expressed among classical, intermediate, and nonclassifcal monocytes by <xref rid="GR271874LAKC32" ref-type="bibr">Wong et al. (2011)</xref>. Among these 61 TFs, 23 were selected as HVGs and the remaining 38 were designated LVGs. <xref rid="GR271874LAKF6" ref-type="fig">Figure 6</xref>A shows that the CarDEC denoised gene expression revealed a gradually decreasing trend from nonclassical to classical for TFs that are known to be highly expressed in nonclassical monocytes, for example, <italic toggle="yes">TCF7L2</italic>, <italic toggle="yes">POU2F2</italic>, <italic toggle="yes">CEBPA</italic>, and <italic toggle="yes">HSBP1</italic>. We also observed expected gene expression increase from nonclassical to classical for TFs that are known to be highly expressed in classical monocytes, for example, <italic toggle="yes">NFE2</italic>, <italic toggle="yes">CEBPD</italic>, <italic toggle="yes">GAS7</italic>, and <italic toggle="yes">MBD2</italic>. Notably, some of the TFs with these expected expression patterns were not selected as HVGs, suggesting that denoising and batch correction in CarDEC helped recover the true biological variations in both HVGs and LVGs. In contrast, when using raw UMI counts as input, the heat map did not reveal any meaningful biological patterns even for those TFs that were selected as HVGs (<xref rid="GR271874LAKF6" ref-type="fig">Fig. 6</xref>B).</p>
      <fig position="float" id="GR271874LAKF6">
        <label>Figure 6.</label>
        <caption>
          <p>Comparison of different methods for differential expression analysis of transcription factors in the human monocyte data. (<italic toggle="yes">A</italic>) Heat map of scaled gene expression for CarDEC. Pseudotime was inferred based on embedding obtained from CarDEC using Monocle 3. (<italic toggle="yes">B</italic>) Heat map of scaled raw UMI counts. Pseudotime was inferred based on embedding obtained from the scaled raw UMI counts using Monocle 3. (<italic toggle="yes">C</italic>) <italic toggle="yes">P</italic>-values obtained from differential expression analysis among the three batches over pseudotime. For each method, the pseudotime was inferred based on embedding obtained from the corresponding method. The red dotted line corresponds to <italic toggle="yes">P</italic>-value = 0.01. The <italic toggle="yes">top</italic> panel is for the 23 HVG TFs, and the <italic toggle="yes">bottom</italic> panel is for the 38 LVG TFs. (<italic toggle="yes">D</italic>) Denoised and batch-corrected gene expression for CarDEC, batch-corrected gene expression for Scanorama, denoised gene expression for DCA with Combat post hoc batch correction, denoised and batch-corrected gene expression for scVI, and batch-corrected gene expression for MNN over pseudotime for four selected TFs: <italic toggle="yes">HIF1A</italic>, <italic toggle="yes">HES4</italic>, <italic toggle="yes">HSBP1</italic>, and <italic toggle="yes">GAS7</italic>. For each method, the pseudotime was inferred based on embedding from the corresponding method.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="1753f06" position="float"/>
      </fig>
      <p>An important task in trajectory analysis is to identify genes whose expression values change over pseudotime and whether the expression patterns are different between conditions (e.g., healthy vs. diseased) over pseudotime. Avoiding false positive results is critical because failure of doing so may lead to follow-up of a wrong signal. Because the three batches were obtained from the same subject, we do not expect to detect significant gene expression differences over pseudotime among them. To this end, we performed differential expression analysis and compared the distributions of gene expression changes over pseudotime across the three batches. We performed hypothesis tests using the “<italic toggle="yes">gam</italic>” function in R package <italic toggle="yes">mgcv</italic> and tested whether gene expression patterns for the three batches are significantly different over pseudotime. <xref rid="GR271874LAKF6" ref-type="fig">Figure 6</xref>C shows the <italic toggle="yes">P</italic>-values from this differential expression analysis for each method. CarDEC is much more effective in removing batch effects than Scanorama, DCA, scVI, and MNN. For the 23 HVG TFs, the median −log<sub>10</sub>
<italic toggle="yes">P</italic>-value for CarDEC is 0.30, whereas the median −log<sub>10</sub>
<italic toggle="yes">P</italic>-values for Scanorama, DCA, scVI, and MNN are 18.37, 5.29, 25.90, and 28.52, respectively. For the 38 LVG TFs, the median −log<sub>10</sub>
<italic toggle="yes">P</italic>-value for CarDEC is increased to 3.70, but still much lower than the other methods (9.81 for Scanorama, 6.36 for DCA, 39.19 for scVI, and 9.07 for MNN). These results indicate that failure to correct for batch effects could lead to a severe inflation of false positive results. <xref rid="GR271874LAKF6" ref-type="fig">Figure 6</xref>D shows four selected TFs, for which the denoised and batch-corrected gene expression for CarDEC agreed well among the three batches, further confirming the effectiveness of CarDEC in removing batch effects in the gene expression space.</p>
    </sec>
    <sec id="s1f">
      <title>CarDEC is scalable to large data sets</title>
      <p>As the scale of scRNA-seq continues to grow, it becomes increasingly important for a method to be scalable to large data sets. To evaluate the scalability of CarDEC, we leveraged a data set of 104,694 human fetal liver cells (<xref rid="GR271874LAKC22" ref-type="bibr">Popescu et al. 2019</xref>). Because we are principally interested in the problem of denoising and batch correcting in the full gene expression space, we retained all 21,521 genes after initial filtering for this analysis. For CarDEC we benchmarked two variations: a version that provides only denoised/batch-corrected expression in the <italic toggle="yes">Z</italic>-score space (CarDEC <italic toggle="yes">Z</italic>-score) and a version that provides denoised/batch-corrected expression in the count space (CarDEC Count).</p>
      <p>We evaluated the run time needed to process 10%, 20%, 40%, 60%, 80%, and 100% of cells in the human fetal liver data set for CarDEC, Scanorama, DCA, scVI, and MNN. All evaluations were performed on a 2019 edition MacBook Pro with 2.4 GHz 8-Core Intel Core i9 CPU and 32 GB of memory. CarDEC, DCA, and scVI were all trained with early stopping to halt training upon convergence. The results are shown in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figure S22</ext-link>. Both versions of CarDEC as well as DCA scaled approximately linearly with the number of cells and all three of these methods finished the analysis in &lt;3.5 h. We were unable to train scVI on &gt;60% of the cells, because the jupyter kernel crashed midtraining for 80% of the cells. scVI also took considerably longer to run. At 60% of the data, CarDEC <italic toggle="yes">Z</italic>-score, DCA, and CarDEC Count took ∼40 min, 1 h, and 1.5 h, respectively. In contrast, scVI took ∼3 h and 45 min to analyze this data. Scanorama had serious scalability issues. Like scVI, we could not run Scanorama for &gt;60% of the data. Among the data points that we do have, Scanorama's run time is clearly not <italic toggle="yes">O</italic>(<italic toggle="yes">n</italic><sub>cells</sub>), whereas CarDEC, DCA, and scVI scale roughly linearly owing to the minibatch gradient descent algorithm that trains all of them (any non-monotonicity is a result of early stopping variation). Scanorama's run time appears to be parabolic as a function of sample size. MNN also has serious scalability issues, which is consistent with a recent benchmarking study (<xref rid="GR271874LAKC8" ref-type="bibr">Haghverdi et al. 2018</xref>). It took &gt;12 h to analyze 20% of the data and &gt;47 h to analyze 40% of the data. We could not run MNN in &lt;48 h using &gt;40% of the data.</p>
    </sec>
    <sec id="s1g">
      <title>CarDEC is robust to hyperparameters</title>
      <p>CarDEC involves several parameters that need to be tuned. To evaluate if CarDEC is robust to different choices of these parameters, we conducted additional analyses. First, we evaluated the performance of CarDEC for the <italic toggle="yes">α</italic> weight parameter, which is used when combining the self-supervised clustering loss and the reconstruction losses. The <italic toggle="yes">α</italic> parameter can be set to any value in the range of [0, 2]. Because a weight of 1 is the midpoint of this range, we chose it as a natural default. To evaluate the robustness of CarDEC to the choice of <italic toggle="yes">α</italic>, we varied its value across the set [0.1, 0.55, 1.0, 1.45, 1.9] and measured how the ARI changes for both the HVGs and the LVGs for each chosen value of <italic toggle="yes">α</italic> with all other parameters held equal. As shown in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figure S23</ext-link>, CarDEC is robust to this choice of parameter.</p>
      <p>Next, we evaluated the performance of CarDEC when varying the number of clusters for clustering. To show that CarDEC is robust to this parameter, we cannot rely on ARI, because the maximum achievable ARI for any clustering method decreases the more the number of clusters is misspecified relative to the number of labels/cell types in the set of gold standard labels. Instead, we chose to show that increasing the number of clusters specified for CarDEC just splits existing clusters, without substantially changing cell type signals/separation. To do this, we fit CarDEC on the pancreas data set repeatedly, varying the number of clusters with each fit. The numbers of clusters selected were 5, 9, 11, 14, and 18, respectively. As shown in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figure S24A</ext-link>, even when the number of clusters is increased from 5 to 18, the cells were still separated mainly by their gold standard cell type labels. Closer examination of the UMAPs revealed that increasing the number of clusters usually just split cell types into two or more cluster label bins to accommodate surplus cluster labels, without changing the underlying structure of the UMAP plot. The CV score distributions shown in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figure S24B</ext-link> further supports that CarDEC is robust to the choice of the number of clusters because the CV score distributions were largely unchanged when the number of clusters varied. We also visualized how cells in a cluster were split when CarDEC was refit with an increasing number of clusters using a Sankey Plot. As shown in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figure S24C</ext-link>, in nearly all cases, increasing the number of clusters just split existing clusters.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s2">
    <title>Discussion</title>
    <p>We developed CarDEC, a joint deep learning model, that removes batch effects not only in the low-dimensional embedding space but also across the entire gene expression space. As shown in our evaluations and a recent benchmarking study (<xref rid="GR271874LAKC18" ref-type="bibr">Luecken et al. 2020</xref>), it is considerably harder to correct for batch effects in the gene expression space than in the embedding space, and especially hard to correct for batch effects in LVGs, which constitute the majority of the transcriptome. CarDEC was built to tackle these challenges. To remove batch effects in the gene expression space, we minimize a loss function that combines clustering and reconstruction losses. The self-supervised clustering loss, driven by HVGs, regularizes the embedding and removes batch effects in the embedding. The rich, batch-corrected embedding is then used to compute an effectively batch-corrected representation in the original gene expression space. To address the difficulty associated with batch correcting LVGs, we implemented a branching architecture, for which embeddings are computed separately for HVGs and LVGs and in which only the HVG embedding is used to compute the clustering loss. Using the pancreatic islet data sets generated from four scRNA-seq protocols, we showed that this branching architecture substantially improved batch effect removal on both the HVG and LVG gene expression spaces, as compared to the naive architecture.</p>
    <p>Across a variety of data sets, with batch effects spanning multiple complexities in level and strength, we showed that CarDEC consistently led in its ability to remove batch effects. CarDEC was consistently the best for removing batch effects in all capacities: in the embedding space, the HVG expression space, and the LVG expression space. We showed that with appropriate denoising and batch correction, the LVGs offer as much signal for clustering as the HVGs, suggesting that CarDEC has substantially boosted the amount of information content in scRNA-seq. We also showed that by batch correcting gene expression counts, CarDEC improved pseudotemporal analysis of human monocytes, an example of how batch correction can be used to improve downstream analyses.</p>
    <p>CarDEC removes batch effects in the LVG denoised gene expression based on the embedding layer that concatenates the HVG embedding. A potential concern of this concatenation is that the denoised LVG expression values might contain artificially introduced signals from the HVGs. To examine this, we focused on the bottom 16,215 genes in the pancreas data set by variance and evaluated the performance of CarDEC when varying the number of HVGs. Then, we fit CarDEC for various numbers of HVGs and evaluated the ARI obtained from clustering the denoised expression for these 16,215 genes. If the LVGs contain artificial signals from the HVGs, then we would expect the ARI computed from the bottom 16,125 genes to vary by how many HVGs were used to train CarDEC. As shown in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figure S25</ext-link>, this is not the case. We observed that ARI on the LVG set increased modestly when the number of HVGs was increased from 500 to 1000, likely because 500 HVGs were too few highly variable features. From 1000 up to 3000 inclusive, the ARI on the LVG set was very stable. After 3000 HVGs, there was a modest drop in the LVG set's ARI, but this is likely because too many noisy features were introduced into the HVG set, which hurt the quality of the KL divergence gradients. Because the 16,125 LVG set's ARI is fairly invariant to the number of HVGs used, especially in the range of 1000 to 3000 HVGs, we can infer that the model architecture is not adding significant artificial signals from the HVGs to the LVGs.</p>
    <p>In this article, we focused on the analyses when using all genes as input. Because Scanorama, DCA, scVI, and MNN are intended to be used with HVGs only, we reanalyzed every data set with only HVGs selected as the input using every method. As expected, many methods performed better when only HVGs were modeled (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Figs. S2, S8</ext-link>, <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">S11</ext-link>, <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">S15</ext-link>). However, for the macaque retina data, Scanorama still struggled to remove its batch effects even when only HVGs were considered. For this challenging data set, the ARI from Scanorama is only 0.18, which is much lower than all the other methods (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Fig. S8</ext-link>).</p>
    <p>Current scRNA-seq studies often include a large number of cells generated from many samples, across multiple conditions, and possibly using different protocols. Removing batch effects is critical for data integration. Because CarDEC provides efficient batch correction in the full gene expression space, it can be used for a wide array of analyses to facilitate biological discovery. Harmonized counts in the gene expression space can be used to estimate unbiased, batch-corrected log fold changes, which can be used to identify marker genes for different cell types. These counts can also be used to reconstruct trajectories and identify genes showing pseudotemporal patterns. Last, CarDEC is computationally fast and memory efficient, making it a desirable tool for analyses of complex data in large-scale single-cell transcriptomics studies.</p>
  </sec>
  <sec sec-type="methods" id="s3">
    <title>Methods</title>
    <p>The CarDEC workflow (<xref rid="GR271874LAKF1" ref-type="fig">Fig. 1</xref>) involves four steps: preprocessing, pretraining, gene expression denoising in <italic toggle="yes">Z</italic>-score space, and (optionally) denoising in count space. Below we briefly describe each of these steps. Details of the implementation is described in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Note 1</ext-link>, and the hyperparameters of CarDEC are shown in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Table S1</ext-link>.</p>
    <sec id="s3a">
      <title>Step 1: preprocessing</title>
      <p>We first remove any cells expressing less than 200 genes and then remove any genes expressed in less than 30 of the remaining cells. Let <bold>X</bold> be an <italic toggle="yes">n</italic> × <italic toggle="yes">p</italic> gene count matrix with <italic toggle="yes">n</italic> cells and <italic toggle="yes">p</italic> genes after filtering. The gene expression values are normalized. In the first step, cell-level normalization is performed, in which gene expression for a given gene in each cell is divided by the total gene expression across all genes in the cell, multiplied by the median total expression across all cells, and then transformed to a natural log scale. In the second step, gene-level normalization is performed, in which the cell-level normalized values for each gene are standardized by subtracting the mean and dividing by the standard deviation across all cells within the same batch for the given gene. Highly variable genes (HVGs) are selected based on the log-normalized counts using the approach introduced by <xref rid="GR271874LAKC25" ref-type="bibr">Stuart et al. (2019</xref>) and implemented in the “pp.highly_variable_genes” function with “batch_key” parameter in the SCANPY package (version ≥1.4) (<xref rid="GR271874LAKC31" ref-type="bibr">Wolf et al. 2018</xref>). The remaining genes that are not selected as HVGs are considered lowly variable genes (LVGs). We note that many of the LVGs still show cell-to-cell variability and are useful for clustering analysis after appropriate denoising and batch effect correction. We select 2000 HVGs for all analyses in this article.</p>
    </sec>
    <sec id="s3b">
      <title>Step 2: pretraining using the HVGs</title>
      <p>The pretraining step is a straightforward implementation of an autoencoder. Let <italic toggle="yes">p</italic><sub>HVG</sub> be the number of HVGs selected in Step 1, and <bold>Y</bold><sub>HVG</sub> be the corresponding <italic toggle="yes">n</italic> × <italic toggle="yes">p</italic><sub>HVG</sub> matrix of normalized expression, subsetted to include only the HVGs. Define a standard autoencoder for <bold>Y</bold><sub>HVG</sub> with encoder and decoder represented by <italic toggle="yes">f</italic><sub><italic toggle="yes">E</italic>,HVG</sub> (·; <italic toggle="yes">W</italic><sub><italic toggle="yes">E</italic>,HVG</sub>) and <italic toggle="yes">f</italic><sub><italic toggle="yes">D</italic>,HVG</sub> (·; <italic toggle="yes">W</italic><sub><italic toggle="yes">D</italic>,HVG</sub>), respectively. The weights <italic toggle="yes">W</italic><sub><italic toggle="yes">E</italic>,HVG</sub> and <italic toggle="yes">W</italic><sub><italic toggle="yes">D</italic>,HVG</sub> are randomly initialized using the glorot uniform approach and are tuned during pretraining. We use the tanh activation for the output of the encoder, and the linear activation function for the output of the decoder. For all intermediate hidden layers in the encoder and decoder, we use the ReLu activation function. The autoencoder is pretrained with mean squared error loss using minibatch gradient descent with the Adam optimizer (<xref rid="GR271874LAKC12" ref-type="bibr">Kingma and Ba 2015</xref>).</p>
    </sec>
    <sec id="s3c">
      <title>Step 3: denoising <italic toggle="yes">Z</italic>-scores</title>
      <p>In this step, we use an expanded, branching architecture to accommodate LVGs and introduce a clustering loss that regularizes the embedding and improves batch mixing and denoising especially in the gene space. Let <italic toggle="yes">p</italic><sub>LVG</sub> be the number of LVGs selected in Step 1, and <bold>Y</bold><sub>LVG</sub> be the corresponding <italic toggle="yes">n</italic> × <italic toggle="yes">p</italic><sub>LVG</sub> matrix of normalized expression, subsetted to include only the LVGs, and <bold><italic toggle="yes">y</italic></bold><sub><italic toggle="yes">i</italic>, HVG</sub> and <bold><italic toggle="yes">y</italic></bold><sub><italic toggle="yes">i</italic>, LVG</sub> be the vectors of HVGs and LVGs, respectively in cell <italic toggle="yes">i</italic>. We retain the encoder and decoder mappings for HVGs, <italic toggle="yes">f</italic><sub><italic toggle="yes">E</italic>,HVG</sub> (·; <italic toggle="yes">W</italic><sub><italic toggle="yes">E</italic>,HVG</sub>) and <italic toggle="yes">f</italic><sub><italic toggle="yes">D</italic>,HVG</sub> (·; <italic toggle="yes">W</italic><sub><italic toggle="yes">D</italic>,HVG</sub>) from Step 2, including the learned weights <italic toggle="yes">W</italic><sub><italic toggle="yes">E</italic>,HVG</sub> and <italic toggle="yes">W</italic><sub><italic toggle="yes">D</italic>,HVG</sub>. We introduce a clustering layer that takes the HVG embedding <bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub> = <italic toggle="yes">f</italic><sub><italic toggle="yes">E</italic>,HVG</sub> ( <bold><italic toggle="yes">y</italic></bold><sub><italic toggle="yes">i</italic>, HVG</sub> ; <italic toggle="yes">W</italic><sub><italic toggle="yes">E</italic>,HVG</sub>) as input and returns for each cell a vector of cluster membership probabilities for <italic toggle="yes">h</italic> clusters, where <italic toggle="yes">h</italic> is a user-specified number. For this clustering layer, we introduce an <italic toggle="yes">h</italic> × <italic toggle="yes">d</italic> matrix of trainable weights/cluster centroids <bold>M</bold>, where the <italic toggle="yes">j</italic>th row of <bold>M</bold> is a cluster centroid <bold><italic toggle="yes">μ</italic></bold><sub><italic toggle="yes">j</italic></sub>, and <italic toggle="yes">d</italic> is dimension of the embedding.</p>
      <p>To initialize <bold>M</bold>, we run Louvain's algorithm on the embeddings {<bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub> :<italic toggle="yes">i</italic> ∈ {1, 2, …, <italic toggle="yes">n</italic>}} learned from the pretrained autoencoder and find the cluster centroid for each cluster. The clustering layer computes a vector of cluster membership probabilities for cell <italic toggle="yes">i</italic>, denoted by <bold><italic toggle="yes">q</italic></bold><sub><italic toggle="yes">i</italic></sub>. Let <italic toggle="yes">q</italic><sub><italic toggle="yes">ij</italic></sub>, the <italic toggle="yes">j</italic>th element of <bold><italic toggle="yes">q</italic></bold><sub><italic toggle="yes">i</italic></sub>, denote the probability that cell <italic toggle="yes">i</italic> belongs to cluster <italic toggle="yes">j</italic>. Then the membership probabilities are computed using a <italic toggle="yes">t</italic>-distribution kernel as follows:
<disp-formula id="GR271874LAKUM1"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM1" display="block" overflow="scroll"><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo fence="true">∥</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo fence="true">∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>∑</mml:mo><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo fence="true">∥</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo fence="true">∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:math></disp-formula>
Because we do not have cell type labels in an unsupervised analysis, we create “pseudolabels” that can be used in place of real labels for optimizing clustering weights. Inspired by <xref rid="GR271874LAKC33" ref-type="bibr">Xie et al. (2016)</xref>, these pseudolabels are computed from the membership probabilities <italic toggle="yes">q</italic><sub><italic toggle="yes">ij</italic></sub> as follows:<disp-formula id="GR271874LAKUM2"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM2" display="block" overflow="scroll"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mspace width="0.4em"/><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:math></disp-formula>
Let <bold><italic toggle="yes">p</italic></bold><sub><italic toggle="yes">i</italic></sub> be an <italic toggle="yes">h</italic>-dimensional vector whose <italic toggle="yes">j</italic>th element is <italic toggle="yes">p</italic><sub><italic toggle="yes">ij</italic></sub>. Then the clustering loss for cell <italic toggle="yes">i</italic> is defined as the following Kullback–Leibler divergence (KLD):<disp-formula id="GR271874LAKUM3"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM3" display="block" overflow="scroll"><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">KLD</mml:mi></mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo fence="false">|</mml:mo><mml:mrow><mml:mo fence="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:munder><mml:mo>⁡</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mspace width="0.4em"/><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:mspace width="0.4em"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula>
This loss is a component of the total loss defined later. Because it takes the embedding vectors <bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub> as input, minimizing this objective function can refine the embedding and help to remove batch effects from denoised counts computed using this embedding as input. The use of this KLD loss function was inspired by DESC (<xref rid="GR271874LAKC16" ref-type="bibr">Li et al. 2020</xref>), which has shown that batch effects can be gradually removed over iterations. The intuition is to use “easy-to-cluster” cells, that is, cells with “pseudolabels,” to guide the neural network to learn cluster-specific gene expression features while ignoring other unwanted noises such as batch effects. Over iterations, the algorithm ignores information unrelated to cell clustering by adjusting the network weights using the gradient descent algorithm and learns cluster-specific information. During the iterative update procedure, cells that are initially assigned to the same cluster are moved closer and closer to the cluster centroid, hence removing batch effects in the embedding space. Because the algorithm learns information on cell clusters from those “easy-to-cluster cells” while ignoring other irrelevant information by constructing the auxiliary distribution <italic toggle="yes">P</italic> and optimizing the KL divergence between <italic toggle="yes">P</italic> and <italic toggle="yes">Q</italic>, then as long as technical differences (e.g., between batches) are smaller than biological differences (e.g., between cell types), it can remove batch effect successfully.</p>
      <p>We also introduce encoder and decoder mappings <italic toggle="yes">f</italic><sub><italic toggle="yes">E</italic>,LVG</sub> (·; <italic toggle="yes">W</italic><sub><italic toggle="yes">E</italic>,LVG</sub>) and <italic toggle="yes">f</italic><sub><italic toggle="yes">D</italic>,LVG</sub> (·; <italic toggle="yes">W</italic><sub><italic toggle="yes">D</italic>,LVG</sub>) to address the problem of denoising and batch correction for the LVGs. Unlike the HVG decoder <italic toggle="yes">f</italic><sub><italic toggle="yes">D</italic>,HVG</sub>, the LVG decoder <italic toggle="yes">f</italic><sub><italic toggle="yes">D</italic>,LVG</sub> (·; <italic toggle="yes">W</italic><sub><italic toggle="yes">D</italic>, LVG</sub>) does not map the low-dimension embedding <bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,LVG</sub> alone to reconstruct <inline-formula id="il1"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IL1" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> in the original <italic toggle="yes">p</italic><sub>LVG</sub>-dimension space. Rather, we concatenate the HVG and LVG embeddings together, and feed the combined vector [<bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub>
<bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,LVG</sub>] into the decoder to denoise and batch correct LVG expression in the original <italic toggle="yes">p</italic><sub>LVG</sub>-dimension space. That is,<disp-formula id="GR271874LAKUM15"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM4" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.4em"/><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mspace width="0.4em"/></mml:mrow><mml:mspace width="0.4em"/><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>;</mml:mo><mml:mspace width="0.4em"/><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula>
</p>
      <p>This concatenated embedding is critical because it allows CarDEC to only use the high signal-to-noise ratio HVGs to drive the clustering loss, while still using the rich, batch-corrected embedding that is refined using this clustering loss to denoise and batch correct LVGs. The activation functions for the encoder and decoder of the LVGs are similarly defined as the autoencoder in Step 2.</p>
      <p>To train this branching model, we first introduce two reconstruction losses, one for the HVGs and one for the LVGs computed as follows for cell <italic toggle="yes">i</italic>:<disp-formula id="GR271874LAKUM4"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM5" display="block" overflow="scroll"><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mspace width="0.4em"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:msup><mml:mrow><mml:mo fence="true">∥</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo fence="true">∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mstyle></mml:math></disp-formula>
<disp-formula id="GR271874LAKUM5"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM6" display="block" overflow="scroll"><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mspace width="0.4em"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:msup><mml:mrow><mml:mo fence="true">∥</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo fence="true">∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:math></disp-formula>
Then the total loss is calculated as a multicomponent loss function as follows:<disp-formula id="GR271874LAKUM6"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM7" display="block" overflow="scroll"><mml:msub><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">LVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>
where <italic toggle="yes">α</italic> is a hyperparameter ranging from 0 to 2 that balances reconstruction loss with clustering loss. We set <italic toggle="yes">α</italic> at 1 as default value. The total loss is minimized in an iterative fashion until certain convergence criteria are satisfied.</p>
    </sec>
    <sec id="s3d">
      <title>Step 4: denoising gene expression counts</title>
      <p>In Step 3, the denoised expression values obtained from the decoder are on a <italic toggle="yes">Z</italic>-score scale and are not naturally comparable to raw UMI counts. To remedy this, we offer an optional downstream modeling step that provides denoised expression values on the original count scale. This strategy involves finding mean and dispersion parameters that maximize a negative binomial likelihood. We choose the negative binomial distribution because previous studies have shown that UMI counts are not zero-inflated, and the negative binomial distribution fits the data well (<xref rid="GR271874LAKC3" ref-type="bibr">Chen et al. 2018</xref>; <xref rid="GR271874LAKC29" ref-type="bibr">Wang et al. 2018</xref>; <xref rid="GR271874LAKC27" ref-type="bibr">Svensson 2020</xref>).</p>
      <p>After the training in Step 3, we have obtained batch-corrected low-dimension embeddings, <bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub> and <bold><italic toggle="yes">z</italic></bold><sub><italic toggle="yes">i</italic>,LVG</sub> for each cell <italic toggle="yes">i</italic> from the fine-tuned HVG and LVG encoders. We will use two separate neural networks to maximize the negative binomial losses: one for the HVGs and one for the LVGs. These models are completely separate from one another but are trained almost identically with only minor differences. The goal is to map the embeddings into the full gene space to obtain mean and dispersion parameters for each gene. Without loss of generality, we use the HVGs as an example to illustrate how the neural network is built.</p>
      <p>The vector of genewise means <bold><italic toggle="yes">μ</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub> and vector genewise dispersions <bold><italic toggle="yes">θ</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub> are given below:<disp-formula id="GR271874LAKUM7"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM8" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
<disp-formula id="GR271874LAKUM8"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM9" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">softplus</mml:mi></mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula>
where <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub> is the size factor for cell <italic toggle="yes">i</italic>, <bold>W</bold><sub><italic toggle="yes">μ</italic>,HVG</sub> and <bold>W</bold><sub><italic toggle="yes">θ</italic>,HVG</sub> are trainable weight matrices, and exp and softplus are activation functions that are applied elementwise. For each gene <italic toggle="yes">j</italic> in cell <italic toggle="yes">i</italic>, we compute the negative log likelihood of the negative binomial distribution as<disp-formula id="GR271874LAKUM9"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM10" display="block" overflow="scroll"><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.4em"/><mml:mo>+</mml:mo><mml:mspace width="0.4em"/><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">x</italic><sub><italic toggle="yes">ij</italic></sub> is the original count in HVG gene <italic toggle="yes">j</italic> for cell <italic toggle="yes">i</italic>, and where <italic toggle="yes">μ</italic><sub><italic toggle="yes">ij</italic></sub> and <italic toggle="yes">θ</italic><sub><italic toggle="yes">ij</italic></sub> are the <italic toggle="yes">j</italic>th elements of <bold><italic toggle="yes">μ</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub> and <bold><italic toggle="yes">θ</italic></bold><sub><italic toggle="yes">i</italic>,HVG</sub>, respectively. For the HVG count model, the full loss for cell <italic toggle="yes">i</italic> is then <inline-formula id="il3"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IL2" display="inline" overflow="scroll"><mml:msub><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mspace width="0.4em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mspace width="0.4em"/><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">HVG</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The loss for the LVG count model can be similarly defined. Both the HVG and LVG count models are trained using their own early stopping and learning rate decay convergence monitoring.</p>
    </sec>
    <sec id="s3e">
      <title>Evaluation of batch effect removal in the gene expression space and the embedding space</title>
      <p>Here, we briefly describe the workflow to evaluate batch effect removal and comparison between different methods (for details, see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Note 2</ext-link>). First, we evaluated the performance of different methods in removing batch effect in the gene expression space. For this evaluation, we considered CarDEC, Scanorama, DCA with post hoc batch effect correction by Combat, scVI, and MNN. We ran all denoising/batch correction methods on the full data matrix and then presented clustering results for denoised HVGs and denoised LVGs separately by subsetting the HVGs and LVGs from the full denoised/batch-corrected expression matrix. The subsetted matrix that includes only the HVGs (or LVGs) is then passed down to the Louvain's clustering algorithm. All steps in this workflow are identical for both the HVGs and the LVGs, and all methods used the same HVGs and LVGs as input for clustering. Furthermore, on a given data set, we benchmarked all methods with the same number of clusters. Second, we evaluated batch effect removal for the embedded representations of scRNA-seq. For this evaluation we considered CarDEC, Scanorama, DCA with post hoc batch effect correction by Combat, scVI, and scDeepCluster. We excluded MNN because it has no embedding functionality. We included “raw” as a control method for comparison, which is just subsetting the raw data to include only the HVGs, and then running the clustering workflow.</p>
    </sec>
    <sec id="s3f">
      <title>Coefficient of variation (CV) analysis</title>
      <p>To measure batch mixing, we examined the batchwise centroids before and after denoising. Let <bold>X<sup>′</sup></bold> be a matrix of gene expression counts (including both HVGs and LVGs). <bold>X<sup>′</sup></bold> can be the matrix of raw counts or the denoised/batch-corrected counts from any of CarDEC, Scanorama, DCA with post hoc batch effect correction by Combat, scVI, or MNN. For CarDEC, we only considered denoised counts, not denoised expression in the <italic toggle="yes">Z</italic>-score space. If <bold>X<sup>′</sup></bold> consists of MNN-corrected expression, then we did not preprocess the data because MNN denoised expression is on a cosine scale. In the case of MNN, Scanorama, and DCA after Combat correction, a fraction of expression counts can be negative, which poses difficulties when computing coefficients of variation. To circumvent this issue, any expression values after correction by these methods that are negative were truncated to zero for the CV analysis. For all other methods we have denoised expression in the non-negative count space, so we performed cell normalization and log normalization on <bold>X<sup>′</sup></bold>, exactly in the same way described in the Step 1 (preprocessing) of CarDEC.</p>
      <p>Next, we describe how the CV scores are calculated. Let <inline-formula id="il4"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IL3" display="inline" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> be the expression value in gene <italic toggle="yes">j</italic> of cell <italic toggle="yes">i</italic> in <bold>X<sup>′</sup></bold>. Let <italic toggle="yes">S</italic><sub><italic toggle="yes">ab</italic></sub> be a set of integers defined such that <italic toggle="yes">i</italic> ∈ <italic toggle="yes">S</italic><sub><italic toggle="yes">ab</italic></sub> if and only if cell <italic toggle="yes">i</italic> belongs to cell type <italic toggle="yes">a</italic> and is sequenced from batch <italic toggle="yes">b</italic>. Furthermore, let <inline-formula id="il5"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IL4" display="inline" overflow="scroll"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>j</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mn>1</mml:mn></mml:math></inline-formula> be the centroid (mean expression) of batch <italic toggle="yes">b</italic> for gene <italic toggle="yes">j</italic> of cell type <italic toggle="yes">a</italic>. Let <italic toggle="yes">C</italic><sub><italic toggle="yes">aj</italic></sub> = {<italic toggle="yes">c</italic><sub><italic toggle="yes">ajb</italic></sub>} be the collection of batch centroids for gene <italic toggle="yes">j</italic> in cell type <italic toggle="yes">a</italic>. We can now define a cell type–specific CV as follows:<disp-formula id="GR271874LAKUM10"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM11" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">CV</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Var</mml:mi></mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:msqrt></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Mean</mml:mi></mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:math></disp-formula>
where <italic toggle="yes">γ</italic> = 10<sup>−12</sup> is a small constant to mitigate computational instability. A higher value of CV<sub><italic toggle="yes">aj</italic></sub> corresponds to greater variation among batches and less batch mixing for cell type <italic toggle="yes">a</italic>, so a good batch effect removal method should drive CV<sub><italic toggle="yes">aj</italic></sub> closer to zero. Normalizing by mean expression adjusts the metric for how highly expressed the gene is, so that CVs from more highly expressed genes are comparable to CVs from less highly expressed genes.</p>
      <p>To consolidate our results across cell types, so that we can present a single distribution of CV scores across all cell types, we combine the cell type–specific CV score <italic toggle="yes">s</italic>. Then we summarize the cell type–specific CV scores by taking a weighted average of these scores across cell types, in which the weight of a cell type is proportional to that cell type's frequency in the data set. Specifically, the weight for cell type <italic toggle="yes">a</italic> is computed as <inline-formula id="il6"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IL5" display="inline" overflow="scroll"><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mn>1</mml:mn></mml:math></inline-formula>, where <italic toggle="yes">a</italic><sub><italic toggle="yes">i</italic></sub> is the cell type of cell <italic toggle="yes">i</italic>. The combined CV score is calculated as follows:<disp-formula id="GR271874LAKUM11"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM12" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">CV</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>a</mml:mi></mml:munder><mml:mrow><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">CV</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.4em"/></mml:math></disp-formula>
</p>
    </sec>
    <sec id="s3g">
      <title>Evaluation metrics for clustering</title>
      <p>For all our benchmark data sets, we used the cell type labels reported in the original papers as the gold standard. The clustering performance of each method was mainly evaluated using the adjusted Rand index (ARI), calculated as follows:<disp-formula id="GR271874LAKUM12"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM13" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">ARI</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:math></disp-formula>
where <italic toggle="yes">n</italic><sub><italic toggle="yes">ij</italic></sub> is the number of cells in both cluster <italic toggle="yes">i</italic> from the cluster assignments obtained when benchmarking and in cell type <italic toggle="yes">j</italic> according to the gold standard cell type labels. <italic toggle="yes">a</italic><sub><italic toggle="yes">i</italic></sub> is the total number of cells in cluster <italic toggle="yes">i</italic> from the cluster assignments obtained when benchmarking, <italic toggle="yes">b</italic><sub><italic toggle="yes">j</italic></sub> is the total number of cells in cell type <italic toggle="yes">j</italic> according to the gold standard cell type labels from the original study, and <italic toggle="yes">n</italic> is the total number of cells. Additionally, we also computed normalized mutual information (NMI) and purity, calculated as follows:<disp-formula id="GR271874LAKUM13"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM14" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">NMI</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle><mml:mrow><mml:mfrac><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo movablelimits="false">∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle><mml:mrow><mml:mfrac><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>
<disp-formula id="GR271874LAKUM14"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="UM15" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">Purity</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mo movablelimits="true">max</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:munder><mml:mo>⁡</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:math></disp-formula>
</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="PMC_1" content-type="local-data">
      <caption>
        <title>Supplemental Material</title>
      </caption>
      <media mimetype="text" mime-subtype="html" xlink:href="supp_31_10_1753__DC1.html"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="x-zip-compressed" xlink:href="supp_gr.271874.120_Supplemental_Codes.zip"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="x-zip-compressed" xlink:href="supp_gr.271874.120_Supplemental_master.zip"/>
      <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_gr.271874.120_Supplemental_Material.pdf"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>This work was supported by the following grants: R01GM125301 (M.L.), R01EY030192 (M.L.), R01EY031209 (M.L.), R01HL113147 (M.L. and M.P.R.), and R01HL150359 (M.L. and M.P.R.). We thank Sean Simmons and Jiarui Ding for their help on the mouse cortex and human PBMC data analysis. We also thank Romain Lopez and Adam Gayoso for letting us know about the scVI update, which has greatly improved its performance.</p>
    <p><italic toggle="yes">Author contributions:</italic> This study was conceived of and led by M.L. J.L. designed the model and algorithm, implemented the CarDEC software, and led data analysis with input from M.L. and X.L. X.L. led data analysis for the human monocyte data and designed the workflow figure. D.W., G.H., and K.W. participated in the early stage of algorithm design and testing. Y.Z. provided input on memory management and analysis for the human monocyte data. L.U. provided input on the model and algorithm design. H.P. and M.P.R. provided input on the human monocyte data analysis. J.L. and M.L. wrote the paper with feedback from all coauthors.</p>
  </ack>
  <fn-group>
    <fn fn-type="supplementary-material">
      <p>[Supplemental material is available for this article.]</p>
    </fn>
    <fn>
      <p>Article published online before print. Article, supplemental material, and publication date are at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.genome.org/cgi/doi/10.1101/gr.271874.120" ext-link-type="uri">https://www.genome.org/cgi/doi/10.1101/gr.271874.120</ext-link>.</p>
    </fn>
    <fn>
      <p>Freely available online through the <italic toggle="yes">Genome Research</italic> Open Access option.</p>
    </fn>
  </fn-group>
  <sec id="s4">
    <title>Data sets</title>
    <p>We analyzed multiple published scRNA-seq data sets, which are available through the accession numbers reported in the original articles: (1) human pancreatic islet data: CEL-Seq (NCBI Gene Expression Omnibus [GEO; <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.ncbi.nlm.nih.gov/geo/">https://www.ncbi.nlm.nih.gov/geo/</uri>] GSE81076), CEL-Seq2 (GEO GSE85241), Fluidigm C1 (GEO GSE86469), and Smart-seq2 (ArrayExpress [<uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.ebi.ac.uk/arrayexpress/">https://www.ebi.ac.uk/arrayexpress/</uri>] E-MTAB-5061); (2) bipolar cells from mouse retina (GEO GSE81904); (3) bipolar cells from macaque retina (GEO GSE118480); (4) mouse cortex data (Single Cell Portal [<uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://singlecell.broadinstitute.org/single_cell">https://singlecell.broadinstitute.org/single_cell</uri>] SCP425); (5) human PBMC data (Single Cell Portal SCP424); (6) human monocyte data (GEO GSE146974); and (7) human fetal liver data (Array Express E-MTAB-7407). Details of these data sets are described in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Table S2</ext-link>.</p>
  </sec>
  <sec id="s5">
    <title>Software availability</title>
    <p>An open-source implementation of the CarDEC algorithm can be downloaded from GitHub (<uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/jlakkis/CarDEC">https://github.com/jlakkis/CarDEC</uri>) and is available as <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Code</ext-link>. Code to reproduce all our analyses can be found on GitHub (<uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/jlakkis/CarDEC_Codes">https://github.com/jlakkis/CarDEC_Codes</uri>) and is also available as <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://genome.cshlp.org/lookup/suppl/doi:10.1101/gr.271874.120/-/DC1" ext-link-type="uri">Supplemental Code</ext-link>.</p>
  </sec>
  <sec id="s6">
    <title>Competing interest statement</title>
    <p>The authors declare no competing interests.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="GR271874LAKC1">
      <mixed-citation publication-type="journal"><string-name><surname>Barkas</surname><given-names>N</given-names></string-name>, <string-name><surname>Petukhov</surname><given-names>V</given-names></string-name>, <string-name><surname>Nikolaeva</surname><given-names>D</given-names></string-name>, <string-name><surname>Lozinsky</surname><given-names>Y</given-names></string-name>, <string-name><surname>Demharter</surname><given-names>S</given-names></string-name>, <string-name><surname>Khodosevich</surname><given-names>K</given-names></string-name>, <string-name><surname>Kharchenko</surname><given-names>PV</given-names></string-name>. <year>2019</year>. <article-title>Joint analysis of heterogeneous single-cell RNA-seq data set collections</article-title>. <source>Nat Methods</source><volume>16</volume>: <fpage>695</fpage>–<lpage>698</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0466-z</pub-id><pub-id pub-id-type="pmid">31308548</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC2">
      <mixed-citation publication-type="journal"><string-name><surname>Cao</surname><given-names>J</given-names></string-name>, <string-name><surname>Spielmann</surname><given-names>M</given-names></string-name>, <string-name><surname>Qiu</surname><given-names>X</given-names></string-name>, <string-name><surname>Huang</surname><given-names>X</given-names></string-name>, <string-name><surname>Ibrahim</surname><given-names>DM</given-names></string-name>, <string-name><surname>Hill</surname><given-names>AJ</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Mundlos</surname><given-names>S</given-names></string-name>, <string-name><surname>Christiansen</surname><given-names>L</given-names></string-name>, <string-name><surname>Steemers</surname><given-names>FJ</given-names></string-name>, <etal/><year>2019</year>. <article-title>The single-cell transcriptional landscape of mammalian organogenesis</article-title>. <source>Nature</source><volume>566</volume>: <fpage>496</fpage>–<lpage>502</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-019-0969-x</pub-id><pub-id pub-id-type="pmid">30787437</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC3">
      <mixed-citation publication-type="journal"><string-name><surname>Chen</surname><given-names>W</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <string-name><surname>Easton</surname><given-names>J</given-names></string-name>, <string-name><surname>Finkelstein</surname><given-names>D</given-names></string-name>, <string-name><surname>Wu</surname><given-names>G</given-names></string-name>, <string-name><surname>Chen</surname><given-names>X</given-names></string-name>. <year>2018</year>. <article-title>UMI-count modeling and differential expression analysis for single-cell RNA sequencing</article-title>. <source>Genome Biol</source><volume>19</volume>: <fpage>70</fpage>. <pub-id pub-id-type="doi">10.1186/s13059-018-1438-9</pub-id><pub-id pub-id-type="pmid">29855333</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC4">
      <mixed-citation publication-type="journal"><string-name><surname>Ding</surname><given-names>J</given-names></string-name>, <string-name><surname>Adiconis</surname><given-names>X</given-names></string-name>, <string-name><surname>Simmons</surname><given-names>SK</given-names></string-name>, <string-name><surname>Kowalczyk</surname><given-names>MS</given-names></string-name>, <string-name><surname>Hession</surname><given-names>CC</given-names></string-name>, <string-name><surname>Marjanovic</surname><given-names>ND</given-names></string-name>, <string-name><surname>Hughes</surname><given-names>TK</given-names></string-name>, <string-name><surname>Wadsworth</surname><given-names>MH</given-names></string-name>, <string-name><surname>Burks</surname><given-names>T</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>LT</given-names></string-name>, <etal/><year>2020</year>. <article-title>Systematic comparison of single-cell and single-nucleus RNA-sequencing methods</article-title>. <source>Nat Biotechnol</source><volume>38</volume>: <fpage>737</fpage>–<lpage>746</lpage>. <pub-id pub-id-type="doi">10.1038/s41587-020-0465-8</pub-id><pub-id pub-id-type="pmid">32341560</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC5">
      <mixed-citation publication-type="journal"><string-name><surname>Eraslan</surname><given-names>G</given-names></string-name>, <string-name><surname>Simon</surname><given-names>LM</given-names></string-name>, <string-name><surname>Mircea</surname><given-names>M</given-names></string-name>, <string-name><surname>Mueller</surname><given-names>NS</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name>. <year>2019</year>. <article-title>Single-cell RNA-seq denoising using a deep count autoencoder</article-title>. <source>Nat Commun</source><volume>10</volume>: <fpage>390</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-018-07931-2</pub-id><pub-id pub-id-type="pmid">30674886</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC6">
      <mixed-citation publication-type="journal"><string-name><surname>Grün</surname><given-names>D</given-names></string-name>, <string-name><surname>Muraro</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Boisset</surname><given-names>JC</given-names></string-name>, <string-name><surname>Wiebrands</surname><given-names>K</given-names></string-name>, <string-name><surname>Lyubimova</surname><given-names>A</given-names></string-name>, <string-name><surname>Dharmadhikari</surname><given-names>G</given-names></string-name>, <string-name><surname>van den Born</surname><given-names>M</given-names></string-name>, <string-name><surname>van Es</surname><given-names>J</given-names></string-name>, <string-name><surname>Jansen</surname><given-names>E</given-names></string-name>, <string-name><surname>Clevers</surname><given-names>H</given-names></string-name>, <etal/><year>2016</year>. <article-title>De novo prediction of stem cell identity using single-cell transcriptome data</article-title>. <source>Cell Stem Cell</source><volume>19</volume>: <fpage>266</fpage>–<lpage>277</lpage>. <pub-id pub-id-type="doi">10.1016/j.stem.2016.05.010</pub-id><pub-id pub-id-type="pmid">27345837</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC7">
      <mixed-citation publication-type="confproc"><string-name><surname>Guo</surname><given-names>X</given-names></string-name>, <string-name><surname>Gao</surname><given-names>L</given-names></string-name>, <string-name><surname>Liu</surname><given-names>X</given-names></string-name>, <string-name><surname>Yin</surname><given-names>J</given-names></string-name>. <year>2017</year>. <article-title>Improved deep embedded clustering with local structure preservation</article-title>. In <conf-name>Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</conf-name>, <conf-loc>Melbourne, Australia</conf-loc>, pp. <fpage>1753</fpage>–<lpage>1759</lpage>. <pub-id pub-id-type="doi">10.24963/ijcai.2017/243</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC8">
      <mixed-citation publication-type="journal"><string-name><surname>Haghverdi</surname><given-names>L</given-names></string-name>, <string-name><surname>Lun</surname><given-names>ATL</given-names></string-name>, <string-name><surname>Morgan</surname><given-names>MD</given-names></string-name>, <string-name><surname>Marioni</surname><given-names>JC</given-names></string-name>. <year>2018</year>. <article-title>Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors</article-title>. <source>Nat Biotechnol</source><volume>36</volume>: <fpage>421</fpage>–<lpage>427</lpage>. <pub-id pub-id-type="doi">10.1038/nbt.4091</pub-id><pub-id pub-id-type="pmid">29608177</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC9">
      <mixed-citation publication-type="journal"><string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Townes</surname><given-names>FW</given-names></string-name>, <string-name><surname>Teng</surname><given-names>M</given-names></string-name>, <string-name><surname>Irizarry</surname><given-names>RA</given-names></string-name>. <year>2018</year>. <article-title>Missing data and technical variability in single-cell RNA-sequencing experiments</article-title>. <source>Biostatistics</source><volume>19</volume>: <fpage>562</fpage>–<lpage>578</lpage>. <pub-id pub-id-type="doi">10.1093/biostatistics/kxx053</pub-id><pub-id pub-id-type="pmid">29121214</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC10">
      <mixed-citation publication-type="journal"><string-name><surname>Hie</surname><given-names>B</given-names></string-name>, <string-name><surname>Bryson</surname><given-names>B</given-names></string-name>, <string-name><surname>Berger</surname><given-names>B</given-names></string-name>. <year>2019</year>. <article-title>Efficient integration of heterogeneous single-cell transcriptomes using Scanorama</article-title>. <source>Nat Biotechnol</source><volume>37</volume>: <fpage>685</fpage>–<lpage>691</lpage>. <pub-id pub-id-type="doi">10.1038/s41587-019-0113-3</pub-id><pub-id pub-id-type="pmid">31061482</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC11">
      <mixed-citation publication-type="journal"><string-name><surname>Johnson</surname><given-names>WE</given-names></string-name>, <string-name><surname>Li</surname><given-names>C</given-names></string-name>, <string-name><surname>Rabinovic</surname><given-names>A</given-names></string-name>. <year>2007</year>. <article-title>Adjusting batch effects in microarray expression data using empirical Bayes methods</article-title>. <source>Biostatistics</source><volume>8</volume>: <fpage>118</fpage>–<lpage>127</lpage>. <pub-id pub-id-type="doi">10.1093/biostatistics/kxj037</pub-id><pub-id pub-id-type="pmid">16632515</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC12">
      <mixed-citation publication-type="confproc"><string-name><surname>Kingma</surname><given-names>DP</given-names></string-name>, <string-name><surname>Ba</surname><given-names>JL</given-names></string-name>. <year>2015</year>. <article-title>ADAM: a method for stochastic optimization</article-title>. In <conf-name>3rd International Conference on Learning Representations</conf-name>, <conf-loc>San Diego</conf-loc>. <comment>arXiv:1412.6980v9 [cs.LG]</comment>.</mixed-citation>
    </ref>
    <ref id="GR271874LAKC13">
      <mixed-citation publication-type="journal"><string-name><surname>Korsunsky</surname><given-names>I</given-names></string-name>, <string-name><surname>Millard</surname><given-names>N</given-names></string-name>, <string-name><surname>Fan</surname><given-names>J</given-names></string-name>, <string-name><surname>Slowikowski</surname><given-names>K</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>F</given-names></string-name>, <string-name><surname>Wei</surname><given-names>K</given-names></string-name>, <string-name><surname>Baglaenko</surname><given-names>Y</given-names></string-name>, <string-name><surname>Brenner</surname><given-names>M</given-names></string-name>, <string-name><surname>Loh</surname><given-names>PR</given-names></string-name>, <string-name><surname>Raychaudhuri</surname><given-names>S</given-names></string-name>. <year>2019</year>. <article-title>Fast, sensitive and accurate integration of single-cell data with Harmony</article-title>. <source>Nat Methods</source><volume>16</volume>: <fpage>1289</fpage>–<lpage>1296</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0619-0</pub-id><pub-id pub-id-type="pmid">31740819</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC14">
      <mixed-citation publication-type="journal"><string-name><surname>Lähnemann</surname><given-names>D</given-names></string-name>, <string-name><surname>Köster</surname><given-names>J</given-names></string-name>, <string-name><surname>Szczurek</surname><given-names>E</given-names></string-name>, <string-name><surname>McCarthy</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Hicks</surname><given-names>SC</given-names></string-name>, <string-name><surname>Robinson</surname><given-names>MD</given-names></string-name>, <string-name><surname>Vallejos</surname><given-names>CA</given-names></string-name>, <string-name><surname>Campbell</surname><given-names>KR</given-names></string-name>, <string-name><surname>Beerenwinkel</surname><given-names>N</given-names></string-name>, <string-name><surname>Mahfouz</surname><given-names>A</given-names></string-name>, <etal/><year>2020</year>. <article-title>Eleven grand challenges in single-cell data science</article-title>. <source>Genome Biol</source><volume>21</volume>: <fpage>31</fpage>. <pub-id pub-id-type="doi">10.1186/s13059-020-1926-6</pub-id><pub-id pub-id-type="pmid">32033589</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC15">
      <mixed-citation publication-type="journal"><string-name><surname>Lawlor</surname><given-names>N</given-names></string-name>, <string-name><surname>George</surname><given-names>J</given-names></string-name>, <string-name><surname>Bolisetty</surname><given-names>M</given-names></string-name>, <string-name><surname>Kursawe</surname><given-names>R</given-names></string-name>, <string-name><surname>Sun</surname><given-names>L</given-names></string-name>, <string-name><surname>Sivakamasundari</surname><given-names>V</given-names></string-name>, <string-name><surname>Kycia</surname><given-names>I</given-names></string-name>, <string-name><surname>Robson</surname><given-names>P</given-names></string-name>, <string-name><surname>Stitzel</surname><given-names>ML</given-names></string-name>. <year>2017</year>. <article-title>Single-cell transcriptomes identify human islet cell signatures and reveal cell-type–specific expression changes in type 2 diabetes</article-title>. <source>Genome Res</source><volume>27</volume>: <fpage>208</fpage>–<lpage>222</lpage>. <pub-id pub-id-type="doi">10.1101/gr.212720.116</pub-id><pub-id pub-id-type="pmid">27864352</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC16">
      <mixed-citation publication-type="journal"><string-name><surname>Li</surname><given-names>X</given-names></string-name>, <string-name><surname>Wang</surname><given-names>K</given-names></string-name>, <string-name><surname>Lyu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Pan</surname><given-names>H</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>J</given-names></string-name>, <string-name><surname>Stambolian</surname><given-names>D</given-names></string-name>, <string-name><surname>Susztak</surname><given-names>K</given-names></string-name>, <string-name><surname>Reilly</surname><given-names>MP</given-names></string-name>, <string-name><surname>Hu</surname><given-names>G</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name>. <year>2020</year>. <article-title>Deep learning enables accurate clustering with batch effect removal in single-cell RNA-seq analysis</article-title>. <source>Nat Commun</source><volume>11</volume>: <fpage>2338</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-020-15851-3</pub-id><pub-id pub-id-type="pmid">32393754</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC17">
      <mixed-citation publication-type="journal"><string-name><surname>Lopez</surname><given-names>R</given-names></string-name>, <string-name><surname>Regier</surname><given-names>J</given-names></string-name>, <string-name><surname>Cole</surname><given-names>MB</given-names></string-name>, <string-name><surname>Jordan</surname><given-names>MI</given-names></string-name>, <string-name><surname>Yosef</surname><given-names>N</given-names></string-name>. <year>2018</year>. <article-title>Deep generative modeling for single-cell transcriptomics</article-title>. <source>Nat Methods</source><volume>15</volume>: <fpage>1053</fpage>–<lpage>1058</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0229-2</pub-id><pub-id pub-id-type="pmid">30504886</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC18">
      <mixed-citation publication-type="journal"><string-name><surname>Luecken</surname><given-names>MD</given-names></string-name>, <string-name><surname>Büttner</surname><given-names>M</given-names></string-name>, <string-name><surname>Chaichoompu</surname><given-names>K</given-names></string-name>, <string-name><surname>Danese</surname><given-names>A</given-names></string-name>, <string-name><surname>Interlandi</surname><given-names>M</given-names></string-name>, <string-name><surname>Mueller</surname><given-names>MF</given-names></string-name>, <string-name><surname>Strobl</surname><given-names>DC</given-names></string-name>, <string-name><surname>Zappia</surname><given-names>L</given-names></string-name>, <string-name><surname>Dugas</surname><given-names>M</given-names></string-name>, <string-name><surname>Colome-Tatche</surname><given-names>M</given-names></string-name>, <etal/><year>2020</year>. <article-title>Benchmarking atlas-level data integration in single-cell genomics</article-title>. <source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.05.22.111161</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC19">
      <mixed-citation publication-type="journal"><string-name><surname>Muraro</surname><given-names>MJ</given-names></string-name>, <string-name><surname>Dharmadhikari</surname><given-names>G</given-names></string-name>, <string-name><surname>Grün</surname><given-names>D</given-names></string-name>, <string-name><surname>Groen</surname><given-names>N</given-names></string-name>, <string-name><surname>Dielen</surname><given-names>T</given-names></string-name>, <string-name><surname>Jansen</surname><given-names>E</given-names></string-name>, <string-name><surname>van Gurp</surname><given-names>L</given-names></string-name>, <string-name><surname>Engelse</surname><given-names>MA</given-names></string-name>, <string-name><surname>Carlotti</surname><given-names>F</given-names></string-name>, <string-name><surname>de Koning</surname><given-names>EJ</given-names></string-name>, <etal/><year>2016</year>. <article-title>A single-cell transcriptome atlas of the human pancreas</article-title>. <source>Cell Syst</source><volume>3</volume>: <fpage>385</fpage>–<lpage>394.e3</lpage>. <pub-id pub-id-type="doi">10.1016/j.cels.2016.09.002</pub-id><pub-id pub-id-type="pmid">27693023</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC20">
      <mixed-citation publication-type="journal"><string-name><surname>Peng</surname><given-names>YR</given-names></string-name>, <string-name><surname>Shekhar</surname><given-names>K</given-names></string-name>, <string-name><surname>Yan</surname><given-names>W</given-names></string-name>, <string-name><surname>Herrmann</surname><given-names>D</given-names></string-name>, <string-name><surname>Sappington</surname><given-names>A</given-names></string-name>, <string-name><surname>Bryman</surname><given-names>GS</given-names></string-name>, <string-name><surname>van Zyl</surname><given-names>T</given-names></string-name>, <string-name><surname>Do</surname><given-names>MTH</given-names></string-name>, <string-name><surname>Regev</surname><given-names>A</given-names></string-name>, <string-name><surname>Sanes</surname><given-names>JR</given-names></string-name>. <year>2019</year>. <article-title>Molecular classification and comparative taxonomics of foveal and peripheral cells in primate retina</article-title>. <source>Cell</source><volume>176</volume>: <fpage>1222</fpage>–<lpage>1237.e22</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2019.01.004</pub-id><pub-id pub-id-type="pmid">30712875</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC21">
      <mixed-citation publication-type="journal"><string-name><surname>Polanski</surname><given-names>K</given-names></string-name>, <string-name><surname>Young</surname><given-names>MD</given-names></string-name>, <string-name><surname>Miao</surname><given-names>Z</given-names></string-name>, <string-name><surname>Meyer</surname><given-names>KB</given-names></string-name>, <string-name><surname>Teichmann</surname><given-names>SA</given-names></string-name>, <string-name><surname>Park</surname><given-names>JE</given-names></string-name>. <year>2020</year>. <article-title>BBKNN: fast batch alignment of single cell transcriptomes</article-title>. <source>Bioinformatics</source><volume>36</volume>: <fpage>964</fpage>–<lpage>965</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btz625</pub-id><pub-id pub-id-type="pmid">31400197</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC22">
      <mixed-citation publication-type="journal"><string-name><surname>Popescu</surname><given-names>DM</given-names></string-name>, <string-name><surname>Botting</surname><given-names>RA</given-names></string-name>, <string-name><surname>Stephenson</surname><given-names>E</given-names></string-name>, <string-name><surname>Green</surname><given-names>K</given-names></string-name>, <string-name><surname>Webb</surname><given-names>S</given-names></string-name>, <string-name><surname>Jardine</surname><given-names>L</given-names></string-name>, <string-name><surname>Calderbank</surname><given-names>EF</given-names></string-name>, <string-name><surname>Polanski</surname><given-names>K</given-names></string-name>, <string-name><surname>Goh</surname><given-names>I</given-names></string-name>, <string-name><surname>Efremova</surname><given-names>M</given-names></string-name>, <etal/><year>2019</year>. <article-title>Decoding human fetal liver haematopoiesis</article-title>. <source>Nature</source><volume>574</volume>: <fpage>365</fpage>–<lpage>371</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-019-1652-y</pub-id><pub-id pub-id-type="pmid">31597962</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC23">
      <mixed-citation publication-type="book"><collab>R Core Team</collab>. <year>2020</year>. <source>R: a language and environment for statistical computing</source>. <publisher-name>R Foundation for Statistical Computing</publisher-name>, <publisher-loc>Vienna</publisher-loc>. <comment><uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.R-project.org/">https://www.R-project.org/</uri></comment>.</mixed-citation>
    </ref>
    <ref id="GR271874LAKC24">
      <mixed-citation publication-type="journal"><string-name><surname>Segerstolpe</surname><given-names>A</given-names></string-name>, <string-name><surname>Palasantza</surname><given-names>A</given-names></string-name>, <string-name><surname>Eliasson</surname><given-names>P</given-names></string-name>, <string-name><surname>Andersson</surname><given-names>EM</given-names></string-name>, <string-name><surname>Andréasson</surname><given-names>AC</given-names></string-name>, <string-name><surname>Sun</surname><given-names>X</given-names></string-name>, <string-name><surname>Picelli</surname><given-names>S</given-names></string-name>, <string-name><surname>Sabirsh</surname><given-names>A</given-names></string-name>, <string-name><surname>Clausen</surname><given-names>M</given-names></string-name>, <string-name><surname>Bjursell</surname><given-names>MK</given-names></string-name>, <etal/><year>2016</year>. <article-title>Single-cell transcriptome profiling of human pancreatic islets in health and type 2 diabetes</article-title>. <source>Cell Metab</source><volume>24</volume>: <fpage>593</fpage>–<lpage>607</lpage>. <pub-id pub-id-type="doi">10.1016/j.cmet.2016.08.020</pub-id><pub-id pub-id-type="pmid">27667667</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC25">
      <mixed-citation publication-type="journal"><string-name><surname>Stuart</surname><given-names>T</given-names></string-name>, <string-name><surname>Butler</surname><given-names>A</given-names></string-name>, <string-name><surname>Hoffman</surname><given-names>P</given-names></string-name>, <string-name><surname>Hafemeister</surname><given-names>C</given-names></string-name>, <string-name><surname>Papalexi</surname><given-names>E</given-names></string-name>, <string-name><surname>Mauck</surname><given-names>WM</given-names><suffix>III</suffix></string-name>, <string-name><surname>Hao</surname><given-names>Y</given-names></string-name>, <string-name><surname>Stoeckius</surname><given-names>M</given-names></string-name>, <string-name><surname>Smibert</surname><given-names>P</given-names></string-name>, <string-name><surname>Satija</surname><given-names>R</given-names></string-name>. <year>2019</year>. <article-title>Comprehensive integration of single-cell data</article-title>. <source>Cell</source><volume>177</volume>: <fpage>1888</fpage>–<lpage>1902.e21</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2019.05.031</pub-id><pub-id pub-id-type="pmid">31178118</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC27">
      <mixed-citation publication-type="journal"><string-name><surname>Svensson</surname><given-names>V</given-names></string-name>. <year>2020</year>. <article-title>Droplet scRNA-seq is not zero-inflated</article-title>. <source>Nat Biotechnol</source><volume>38</volume>: <fpage>147</fpage>–<lpage>150</lpage>. <pub-id pub-id-type="doi">10.1038/s41587-019-0379-5</pub-id><pub-id pub-id-type="pmid">31937974</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC28">
      <mixed-citation publication-type="journal"><string-name><surname>Tian</surname><given-names>T</given-names></string-name>, <string-name><surname>Ji</surname><given-names>W</given-names></string-name>, <string-name><surname>Qi</surname><given-names>S</given-names></string-name>, <string-name><surname>Wei</surname><given-names>Z</given-names></string-name>. <year>2019</year>. <article-title>Clustering single-cell RNA-seq data with a model-based deep learning approach</article-title>. <source>Nat Mach Intell</source><volume>1</volume>: <fpage>191</fpage>–<lpage>198</lpage>. <pub-id pub-id-type="doi">10.1038/s42256-019-0037-0</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC29">
      <mixed-citation publication-type="journal"><string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Huang</surname><given-names>M</given-names></string-name>, <string-name><surname>Torre</surname><given-names>E</given-names></string-name>, <string-name><surname>Dueck</surname><given-names>H</given-names></string-name>, <string-name><surname>Shaffer</surname><given-names>S</given-names></string-name>, <string-name><surname>Murray</surname><given-names>J</given-names></string-name>, <string-name><surname>Raj</surname><given-names>A</given-names></string-name>, <string-name><surname>Li</surname><given-names>M</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>NR</given-names></string-name>. <year>2018</year>. <article-title>Gene expression distribution deconvolution in single-cell RNA sequencing</article-title>. <source>Proc Natl Acad Sci</source><volume>115</volume>: <fpage>E6437</fpage>–<lpage>E6446</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1721085115</pub-id><pub-id pub-id-type="pmid">29946020</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC30">
      <mixed-citation publication-type="journal"><string-name><surname>Welch</surname><given-names>JD</given-names></string-name>, <string-name><surname>Kozareva</surname><given-names>V</given-names></string-name>, <string-name><surname>Ferreira</surname><given-names>A</given-names></string-name>, <string-name><surname>Vanderburg</surname><given-names>C</given-names></string-name>, <string-name><surname>Martin</surname><given-names>C</given-names></string-name>, <string-name><surname>Macosko</surname><given-names>EZ</given-names></string-name>. <year>2019</year>. <article-title>Single-Cell multi-omic integration compares and contrasts features of brain cell identity</article-title>. <source>Cell</source><volume>177</volume>: <fpage>1873</fpage>–<lpage>1887.e17</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2019.05.006</pub-id><pub-id pub-id-type="pmid">31178122</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC31">
      <mixed-citation publication-type="journal"><string-name><surname>Wolf</surname><given-names>FA</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>P</given-names></string-name>, <string-name><surname>Theis</surname><given-names>FJ</given-names></string-name>. <year>2018</year>. <article-title>SCANPY: large-scale single-cell gene expression data analysis</article-title>. <source>Genome Biol</source><volume>19</volume>: <fpage>15</fpage>. <pub-id pub-id-type="doi">10.1186/s13059-017-1382-0</pub-id><pub-id pub-id-type="pmid">29409532</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC32">
      <mixed-citation publication-type="journal"><string-name><surname>Wong</surname><given-names>KL</given-names></string-name>, <string-name><surname>Tai</surname><given-names>JJ</given-names></string-name>, <string-name><surname>Wong</surname><given-names>WC</given-names></string-name>, <string-name><surname>Han</surname><given-names>H</given-names></string-name>, <string-name><surname>Sem</surname><given-names>X</given-names></string-name>, <string-name><surname>Yeap</surname><given-names>WH</given-names></string-name>, <string-name><surname>Kourilsky</surname><given-names>P</given-names></string-name>, <string-name><surname>Wong</surname><given-names>SC</given-names></string-name>. <year>2011</year>. <article-title>Gene expression profiling reveals the defining features of the classical, intermediate, and nonclassical human monocyte subsets</article-title>. <source>Blood</source><volume>118</volume>: <fpage>e16</fpage>–<lpage>e31</lpage>. <pub-id pub-id-type="doi">10.1182/blood-2010-12-326355</pub-id><pub-id pub-id-type="pmid">21653326</pub-id></mixed-citation>
    </ref>
    <ref id="GR271874LAKC33">
      <mixed-citation publication-type="confproc"><string-name><surname>Xie</surname><given-names>J</given-names></string-name>, <string-name><surname>Girshick</surname><given-names>R</given-names></string-name>, <string-name><surname>Farhadi</surname><given-names>A</given-names></string-name>. <year>2016</year>. <article-title>Unsupervised deep embedding for clustering analysis</article-title>. In <conf-name>Proceedings, 33rd International Conference on Machine Learning</conf-name>, <conf-loc>New York</conf-loc>, pp. <fpage>478</fpage>–<lpage>487</lpage>. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://JMLR.org">JMLR.org</uri>.</mixed-citation>
    </ref>
  </ref-list>
</back>
