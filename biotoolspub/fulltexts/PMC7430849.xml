<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7430849</article-id>
    <article-id pub-id-type="pmid">32758139</article-id>
    <article-id pub-id-type="publisher-id">3697</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-020-03697-x</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9034-9905</contrib-id>
        <name>
          <surname>Gamaarachchi</surname>
          <given-names>Hasindu</given-names>
        </name>
        <address>
          <email>hasindu@unsw.edu.au</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lam</surname>
          <given-names>Chun Wai</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jayatilaka</surname>
          <given-names>Gihan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Samarakoon</surname>
          <given-names>Hiruna</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Simpson</surname>
          <given-names>Jared T.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Smith</surname>
          <given-names>Martin A.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
        <xref ref-type="aff" rid="Aff7">7</xref>
        <xref ref-type="aff" rid="Aff8">8</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Parameswaran</surname>
          <given-names>Sri</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.1005.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 4902 0432</institution-id><institution>School of Computer Science and Engineering, UNSW Sydney, </institution></institution-wrap>Sydney, Australia </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.415306.5</institution-id><institution-id institution-id-type="ISNI">0000 0000 9983 6924</institution-id><institution>Kinghorn Centre for Clinical Genomics, Garvan Institute of Medical Research, </institution></institution-wrap>Sydney, Australia </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.11139.3b</institution-id><institution-id institution-id-type="ISNI">0000 0000 9816 8637</institution-id><institution>Department of Computer Engineering, University of Peradeniya, </institution></institution-wrap>Peradeniya, Sri Lanka </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.419890.d</institution-id><institution-id institution-id-type="ISNI">0000 0004 0626 690X</institution-id><institution>Ontario Institute for Cancer Research, </institution></institution-wrap>Toronto, Canada </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Computer Science, University of Toronto, </institution></institution-wrap>Toronto, Canada </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.1005.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 4902 0432</institution-id><institution>St-Vincent’s Clinical School, Faculty of Medicine, UNSW Sydney, </institution></institution-wrap>Sydney, Australia </aff>
      <aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="GRID">grid.411418.9</institution-id><institution-id institution-id-type="ISNI">0000 0001 2173 6322</institution-id><institution>CHU Sainte-Justine Research Centre, </institution></institution-wrap>Montreal, Canada </aff>
      <aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="GRID">grid.14848.31</institution-id><institution-id institution-id-type="ISNI">0000 0001 2292 3357</institution-id><institution>Department of Biochemistry and Molecular Medicine, Faculty of Medicine, University of Montreal, </institution></institution-wrap>Montreal, Canada </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>5</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>5</day>
      <month>8</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>21</volume>
    <elocation-id>343</elocation-id>
    <history>
      <date date-type="received">
        <day>2</day>
        <month>4</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>23</day>
        <month>7</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed <italic>f5c</italic>) to efficiently run on heterogeneous CPU-GPU architectures.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how <italic>f5c</italic> can perform ∼3-5 × faster than an optimised version of the original CPU-only implementation of ABEA in the <italic>Nanopolish</italic> software package. We also show that <italic>f5c</italic> enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for <italic>f5c</italic> along with GPU optimised ABEA is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hasindu2008/f5c">https://github.com/hasindu2008/f5c</ext-link>.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Nanopore</kwd>
      <kwd>Signal alignment</kwd>
      <kwd>Event alignment</kwd>
      <kwd>Methylation</kwd>
      <kwd>GPU</kwd>
      <kwd>GPU acceleration</kwd>
      <kwd>Optimisation</kwd>
      <kwd>SoC</kwd>
      <kwd>Nanopolish</kwd>
      <kwd>f5c</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Advances in genomic technologies have improved the feasibility and accessibility of rapid species identification, accurate clinical diagnostics, and specialised therapeutics, amongst other applications. The latest generation (third generation) of sequencing technologies generate data in the order of terabytes. Oxford Nanopore Technologies’ (ONT) pocket-sized MinION device generates ∼1 TB of raw signal data during a typical sequencing run, while their high-throughput PromethION device can generate &gt;50TB of data in &lt;60h. Computational analysis of such massive data currently poses a challenge.</p>
    <p>Nanopore sequencing measures characteristic disruptions in the electric current (referred to hereafter as <italic>raw signal</italic>) when DNA passes through a nanopore (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The instantaneous current measured in the R9.4.1 pore model depends on 5-6 contiguous bases [<xref ref-type="bibr" rid="CR1">1</xref>]. The measured signal also presents stochastic noise due to a number of factors [<xref ref-type="bibr" rid="CR2">2</xref>]. Additionally, the speed of the DNA strand moving through the pore can vary, causing the signal to warp in the time domain [<xref ref-type="bibr" rid="CR2">2</xref>]. The <italic>raw signal</italic> is converted to nucleotide strings (reads) through a process called base-calling (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Despite recent improvements, nanopore base-calling often introduces errors (∼3-5% at the time of writing) given the use of probabilistic methods to infer biological sequences from often noisy raw signal [<xref ref-type="bibr" rid="CR3">3</xref>]. To overcome base-calling errors, raw signal can be revisited to improve the reconstitution of the base-called sequence <italic>a posteriori</italic> (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). This process, termed ‘polishing’, can correct base-calling errors by aligning the raw signal to a biological reference sequence [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>], thus identifying idiosyncrasies in the raw signal by comparing observed signal levels to the expected levels at all aligned positions. Polishing can also reveal base substitutions (i.e. mutations) or base modifications such as 5-methylcytosine (5mC), a dynamic biochemical modification of DNA that is associated with genetic activity and regulation [<xref ref-type="bibr" rid="CR6">6</xref>]. Detecting 5mC bases is important for the study of DNA methylation in the field of epigenetics [<xref ref-type="bibr" rid="CR7">7</xref>].
<fig id="Fig1"><label>Fig. 1</label><caption><p>Nanopore DNA sequencing and associated data analysis. A consumable flowcell containing an array of hundreds or thousands of such nanopores is loaded into the sequencing device (e.g. MinION). Ionic current (in pico amperes) is measured when DNA strands pass through nanopores to produce the <italic>raw signal</italic>, which is eventually basecalled. The base-called reads are then aligned to a reference genome. The raw signal is then revisited during the polishing step. Images of nanopore devices are reproduced with permission from ONT</p></caption><graphic xlink:href="12859_2020_3697_Fig1_HTML" id="MO1"/></fig></p>
    <p>A crucial algorithmic component of polishing is the alignment of raw signal—a time series of electric current—to a biological reference sequence. One of the first and most popular raw nanopore signal alignment algorithms is implemented in <italic>Nanopolish</italic> [<xref ref-type="bibr" rid="CR6">6</xref>], which employs a dynamic programming strategy referred to as Adaptive Banded Event Alignment (ABEA). ABEA is one of the most time consuming steps during the process of analysing raw nanopore data. For instance, in-house profiling revealed that when performing methylation detection with <italic>Nanopolish</italic>, the ABEA step alone consumes ∼70% of the total CPU time. Considering the increasing amount of data generated by high-throughput nanopore sequencers, solutions are required to accelerate ABEA and reduce the turnaround time of certain nanopore sequencing applications, such as real-time polishing or methylation detection.</p>
    <p>In this study, we describe and dissect the ABEA algorithm in detail to optimise and parallelise its execution to exploit heterogeneous CPU-GPU architectures, commonplace in mainstream computing systems. We demonstrate the utility of our GPU-optimised ABEA by incorporating a completely re-engineered version of the popular methylation detection tool <italic>Nanopolish</italic>. First, we modified the original <italic>Nanopolish</italic> methylation detection tool to efficiently utilise existing CPU resources, which we refer to as <italic>f5c</italic>. Then, we incorporated a GPU-optimised ABEA algorithm into <italic>f5c</italic>. We demonstrate how <italic>f5c</italic> enables DNA methylation detection using nanopore sequencers in real-time (i.e. on-the-fly processing of the output) by using a lightweight embedded computer system equipped with a GPU (e.g., NVIDIA Jetson TX2). We also demonstrate how <italic>f5c</italic> benefits a wide range of computing devices, from embedded systems and laptops to workstations and high performance servers. <italic>f5c</italic> is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hasindu2008/f5c">https://github.com/hasindu2008/f5c</ext-link>.</p>
  </sec>
  <sec id="Sec2">
    <title>The ABEA algorithm</title>
    <p>ABEA was first introduced in the raw nanopore signal analysis package <italic>Nanopolish</italic> [<xref ref-type="bibr" rid="CR6">6</xref>]. The origin of the ABEA algorithm can be tracked to the Smith-Waterman (SW) dynamic programming sequence alignment algorithm that was first described in 1981. The original SW algorithm has a computational complexity of <italic>O</italic>(<italic>n</italic><sup>2</sup>) and is most practical when the sequences are very short. Several optimisations to SW have since been introduced. Heuristic approaches, such as banded SW, attempt to reduce the search space by limiting computation along the diagonal of the dynamic programming table [<xref ref-type="bibr" rid="CR8">8</xref>]. While the banded approach is suitable for fast alignment of second-generation sequencing data—which are composed of relatively short reads—it is less so for third generation long reads, as significantly longer width is required to contain the alignment within the band. The more recent Suzuki-Kasahara (SK) algorithm [<xref ref-type="bibr" rid="CR9">9</xref>] uses a heuristic optimisation to banded SW that allows the band to adapt and move during the alignment, thus containing the optimal alignment within the band while allowing large gaps in the alignment. The SK algorithm is well-suited for aligning long and error-prone third generation reads in base-space (nucleotide sequences). The SK alignment algorithm was later modified and extended to ABEA in <italic>Nanopolish</italic> to enable signal-space alignment of time series signal data instead of nucleotide sequences. A simplified example of the ABEA algorithm and a representative dynamic programming table is shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Algorithm 1 summarises the ABEA algorithm and the reader may refer to <xref rid="MOESM1" ref-type="media">Supplementary Materials</xref> for a detailed explanation.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Nanopore raw signal, events and ABEA algorithm. In <bold>a</bold><italic>events</italic> are the result of the event detection step (time series segmentation of the raw signal based on abrupt changes — detailed in <xref rid="MOESM1" ref-type="media">Supplementary Materials</xref>) and <italic>true annotation</italic> is the expected output of ABEA. In <bold>b</bold>, <bold>c</bold> and <bold>d</bold>, vertical axis represents the events and horizontal axis represents the <italic>ref</italic> k-mers (k-mers within the base-called read). The dynamic programming table (DP table) is for 13 events, indexed from <italic>e</italic><sub>0</sub>−<italic>e</italic><sub>12</sub> vertically, and the <italic>ref</italic> k-mers, indexed from <italic>k</italic><sub>0</sub>−<italic>k</italic><sub>5</sub> horizontally. For computational and memory efficiency, only the diagonal bands (marked using blue rectangles) with a band width of <italic>W</italic> (typically <italic>W</italic>=100 for nanopore signals) are computed. The bands are computed along the diagonal from top-left (<italic>b0</italic>) to bottom-right (<italic>b17</italic>). Each cell score is computed in function of five factors: scores from the three neighbouring cells (up, left and diagonal); the corresponding <italic>ref</italic> k-mer; and, the event (shown for the cell <italic>e</italic><sub>6</sub>, <italic>k</italic><sub>3</sub> via red arrows in c). Observe that all the cells in the <italic>n</italic><sup>th</sup> band can be computed in parallel as long as the <italic>n</italic>−1<sup>th</sup> and <italic>n</italic>−2<sup>th</sup> bands are computed beforehand. To contain the optimal alignment, the band adapts by moving down or to the right as shown using blue arrows. The adaptive band movement is determined by the Suzuki-Kasahara heuristic rule [<xref ref-type="bibr" rid="CR9">9</xref>]</p></caption><graphic xlink:href="12859_2020_3697_Fig2_HTML" id="MO2"/></fig></p>
    <p>
      <graphic position="anchor" xlink:href="12859_2020_3697_Figa_HTML" id="MO7"/>
    </p>
  </sec>
  <sec id="Sec3">
    <title>Methods</title>
    <sec id="Sec4">
      <title>CPU-GPU optimisations</title>
      <p><italic>f5c</italic> employs a fork-join multi-threading model (with work stealing) implemented using C POSIX threads.</p>
      <p>Implementing the ABEA algorithm for GPU execution is not a straightforward task due to three main factors: (i) inefficient memory access patterns, which are not ideal for GPUs with relatively less powerful and smaller caches (compared to CPUs), resulting in frequent instruction stalls; (ii) read lengths of the input vary significantly (from ∼100 bases to &gt;1M bases), requiring millions to billions of dynamic memory allocations—an expensive operation in GPUs; and (iii) non uniform distribution of read lengths in the input causes irregular utilisation of GPU cores. These challenges were overcome by: (i) tailoring the algorithm and GPU user-managed cache to exploit cache friendly memory access patterns; (ii) employing a custom heuristic-based memory allocation scheme; and (iii) using a heuristic-based work partitioning and load balancing scheme between CPU and GPU.</p>
      <p>The GPU implementation of ABEA algorithm was performed using CUDA C. A brief summary of our optimisations is listed below.</p>
      <p><bold>Parallelisation and computational optimisations:</bold> To achieve fast performance on GPUs, their thousands of tiny computing cores must be sufficiently occupied. For this, thousands of parallel threads must be launched, which requires thousands of parallel tasks. This is achieved by processing a batch of reads in parallel and concurrently computing all the cells of a dynamic programming matrix band (Fig. <xref rid="Fig2" ref-type="fig">2</xref>b, lines ??-?? in Algorithm 1). As the bandwidth is 100 cells, a read batch of a few hundred can sufficiently occupy thousands of GPU cores. GPU core utilisation is further enhanced by improving memory access latency by using the GPU’s fast cache memory (shared memory) and a technique called memory coalescing. The current, previous and 2<sup>nd</sup> previous bands, which are frequently accessed by hundreds of threads in parallel, are kept in the shared memory. Data arrays such as the <italic>score</italic> array, <italic>trace</italic> array, reference k-mers and events that are in slow DRAM (global memory) are placed (laid out) such that contiguous threads access contiguous memory locations. This facilitates memory coalescing (one memory access can fetch data required by a large number of threads), consequently reducing the number of accesses to DRAM.</p>
      <p><bold>Memory optimisation:</bold> Dynamic memory allocations in the GPU memory are expensive and must be minimised for fast performance. We significantly reduced the number of dynamic memory allocations by employing a lightweight heuristic-based custom memory allocation scheme. In brief, large chunks of contiguous memory are pre-allocated when initiating the program to accommodate a batch of reads, which are then reused throughout the execution of the program. The sizes of these large chunks are determined by the available GPU memory and a heuristically determined value for the average number of events per base (i.e. average value of the number of events divided by the read length).</p>
      <p><bold>Heterogeneous processing:</bold> If all queried reads were of similar length, GPU threads that process the reads would complete approximately at the same time, and thus GPU cores will be equally busy throughout the execution. However, nanopore read length distributions can include reads which are significantly longer than the average read length. When the GPU threads process reads in parallel, longer reads cause all other GPU threads to wait until processing of the longest read is completed. These waiting threads lead to underutilisation of GPU cores. This issue is remedied by employing heterogeneous processing, where the CPU processes these very long reads while the GPU is processing the rest of the reads in parallel. CPU cores have a higher clock frequency than the GPU cores, therefore such very long reads can be independently and quickly processed by the CPU while the remaining reads are processed by GPU cores in parallel.</p>
      <p>A detailed breakdown of these optimisations, experimental evidence that justify design and optimisation decisions—including a section describing the fundamentals of GPU architecture and programming—can be found in <xref rid="MOESM1" ref-type="media">Supplementary Materials</xref>.</p>
    </sec>
    <sec id="Sec5">
      <title>Biological data analysis</title>
      <p>Comparative performance benchmarking was performed using the publicly available NA12878 (human genome) “Nanopore WGS Consortium” sequencing data [<xref ref-type="bibr" rid="CR4">4</xref>]. The datasets used for the experiments, their statistics (number of reads, total bases, mean read length and maximum read length) and their source are listed in Table <xref rid="Tab1" ref-type="table">1</xref>. <italic>D</italic><sub><italic>small</italic></sub>, a small subset, was used for testing a wide range of systems (all systems in Table <xref rid="Tab2" ref-type="table">2</xref>, i.e. embedded system, low-end and high-end laptops, workstation and a high-performance server). Two complete nanopore MinION data sets (<italic>D</italic><sub><italic>ligation</italic></sub> and <italic>D</italic><sub><italic>rapid</italic></sub>) are only tested on three systems due to the larger run-time and incidental access to the other two systems. <italic>D</italic><sub><italic>ligation</italic></sub> and <italic>D</italic><sub><italic>rapid</italic></sub> represent the two existing nanopore sample preparation methods (ligation and rapid [<xref ref-type="bibr" rid="CR10">10</xref>]) that affects the read length distribution.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Information of the datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><bold>Dataset</bold></th><th align="left"><bold>Number of reads</bold></th><th align="left"><bold>Number of bases (Gbases)</bold></th><th align="left"><bold>Mean read length (Kbases)</bold></th><th align="left"><bold>Max read length (Kbases)</bold></th><th align="left"><bold>Source / SRA accession</bold></th></tr></thead><tbody><tr><td align="left"><italic>D</italic><sub><italic>small</italic></sub></td><td align="justify">19275</td><td align="justify">0.15</td><td align="justify">7.7</td><td align="justify">196</td><td align="justify">[<xref ref-type="bibr" rid="CR11">11</xref>]</td></tr><tr><td align="left"><italic>D</italic><sub><italic>ligation</italic></sub></td><td align="justify">451020</td><td align="justify">3.62</td><td align="justify">8.0</td><td align="justify">1500</td><td align="justify">ERR2184733</td></tr><tr><td align="left"><italic>D</italic><sub><italic>rapid</italic></sub></td><td align="justify">270189</td><td align="justify">2.73</td><td align="justify">10.0</td><td align="justify">386</td><td align="justify">ERR2184734</td></tr></tbody></table></table-wrap><table-wrap id="Tab2"><label>Table 2</label><caption><p>Different systems used for experiments</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><bold>System Name</bold></th><th align="left"><bold>Info</bold></th><th align="left"><bold>CPU</bold></th><th align="left"><bold>CPU cores/ threads</bold></th><th align="left"><bold>RAM (GB)</bold></th><th align="left"><bold>GPU</bold></th><th align="left"><bold>GPU mem (GB)</bold></th><th align="left"><bold>GPU arch</bold></th></tr></thead><tbody><tr><td align="justify">SoC</td><td align="justify">NVIDIA Jetson TX2 embedded module</td><td align="justify">ARMv8 Cortex-A57 + NVIDIA Denver2</td><td align="justify">6 / 6</td><td align="justify">8</td><td align="left">Tegra</td><td align="justify">shared with RAM</td><td align="justify">Pascal / 6.2</td></tr><tr><td align="justify">lapL</td><td align="justify">Acer F5-573G laptop</td><td align="justify">i7-7500U</td><td align="justify">2/4</td><td align="justify">8</td><td align="left">Geforce 940M</td><td align="justify">4</td><td align="justify">Maxwell / 5.0</td></tr><tr><td align="justify">lapH</td><td align="justify">Dell XPS 15 laptop</td><td align="justify">i7-8750H</td><td align="justify">6/12</td><td align="justify">16</td><td align="left">Geforce 1050 Ti</td><td align="justify">4</td><td align="justify">Pascal / 6.1</td></tr><tr><td align="justify">ws</td><td align="justify">HP Z640 workstation</td><td align="justify">Xeon E5-1630</td><td align="justify">4/8</td><td align="justify">32</td><td align="left">Tesla K40</td><td align="justify">12</td><td align="justify">Kepler / 3.5</td></tr><tr><td align="justify">HPC</td><td align="justify">Dell PowerEdge</td><td align="justify">Xeon Silver 4114</td><td align="justify">20/40</td><td align="justify">376</td><td align="left">Tesla V100</td><td align="justify">16</td><td align="justify">Volta / 7.0</td></tr><tr><td align="justify"/><td align="justify">C4140</td><td align="justify"/><td align="justify"/><td align="justify"/><td align="left"/><td align="justify"/><td align="justify"/></tr></tbody></table></table-wrap></p>
      <p>For “<xref rid="Sec7" ref-type="sec">Speedup of ABEA algorithm</xref>”, time measurements were obtained by inserting <italic>gettimeofday</italic> timestamp function invocations directly into the C source code. Total execution time and the peak RAM usage in “<xref rid="Sec8" ref-type="sec">Comparative performance of <italic>f5c</italic> with <italic>Nanopolish</italic></xref>” sections were measured by running the <italic>GNU time</italic> utility with the <italic>verbose</italic> option.</p>
    </sec>
  </sec>
  <sec id="Sec6" sec-type="results">
    <title>Results</title>
    <sec id="Sec7">
      <title>Speedup of ABEA algorithm</title>
      <p>We initially compared the optimised GPU version with the optimised CPU version of the ABEA algorithm (not the unoptimised CPU version in the original <italic>Nanopolish</italic>, see below) by executing them on publicly available raw nanopore genome sequencing data. The CPU version was run with maximum supported threads on the tested systems. The optimised CPU version will be henceforth referred to as <italic>C-opti</italic> and the optimised GPU version will be referred to as <italic>G-opti</italic>.</p>
      <p>First we benchmarked on five different systems (Table <xref rid="Tab2" ref-type="table">2</xref>) over <italic>D</italic><sub><italic>small</italic></sub> dataset. Speedups (including all the overheads) observed for <italic>G-opti</italic> compared to <italic>C-opti</italic> are: ∼4.5× on the low-end-laptop and the workstation; ∼4× on Jetson TX2 SoC; and ∼3× on high-end-laptop and HPC (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Note that only a ∼3× speedup was observed on high-end-laptop and HPC (versus &gt;=4 × on other systems) due to the CPU on those particular systems having a comparatively higher amount of CPU cores (12 and 40 respectively).
<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance comparison of ABEA on CPU vs GPU over a wide range of systems. Runtime for <italic>C-opti</italic> (left bars) and the <italic>G-opti</italic> (right bars). Runtime for the GPU has been broken down into: compute kernel time; different overheads (memory copying to/from the GPU, data serialisation time), and the extra CPU time due to CPU processing of the reads. The compute kernel time includes the sum of time for all GPU kernels. The extra CPU time is the additional time spent by the CPU to process <italic>very long reads</italic> and <italic>ultra long reads</italic> (see <xref rid="MOESM1" ref-type="media">Supplementary materials</xref>) assigned to the CPU (excluding the processing time that overlaps with the GPU execution, i.e. only the extra time which the GPU has to wait after the execution is included)</p></caption><graphic xlink:href="12859_2020_3697_Fig3_HTML" id="MO3"/></fig></p>
      <p>We next benchmarked on two larger datasets (<italic>D</italic><sub><italic>rapid</italic></sub> and <italic>D</italic><sub><italic>ligation</italic></sub>). A speedup up of ∼3× was observed for all three systems for the two big datasets— <italic>D</italic><sub><italic>ligation</italic></sub> and <italic>D</italic><sub><italic>rapid</italic></sub> (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). Due to more ultra long reads (&gt;100kb) in <italic>D</italic><sub><italic>ligation</italic></sub> and <italic>D</italic><sub><italic>rapid</italic></sub> than in <italic>D</italic><sub><italic>small</italic></sub>, the overall speedup for <italic>SoC</italic> is limited to around ∼3× compared to ∼4× for <italic>D</italic><sub><italic>small</italic></sub>.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Performance comparison of ABEA on CPU vs GPU across over large datasets Runtime for <italic>C-opti</italic> (left bars) and the <italic>G-opti</italic> (right bars). Runtime for the GPU has been broken down into: compute kernel time; different overheads (memory copying to/from the GPU, data serialisation time), extra CPU time due to <italic>very long reads</italic> and <italic>ultra long reads</italic> (see <xref rid="MOESM1" ref-type="media">Supplementary materials</xref>)</p></caption><graphic xlink:href="12859_2020_3697_Fig4_HTML" id="MO4"/></fig></p>
      <p>It is noteworthy to mention that comparing performance to the unoptimised CPU version in <italic>Nanopolish</italic> is not straightforward, as the time for individual components (e.g. ABEA) cannot be accurately measured because each read executes on its own code path (detailed in <xref rid="MOESM1" ref-type="media">Supplementary Materials</xref>). We nonetheless estimated the runtime of unoptimised ABEA by injecting timestamp (<italic>gettimeofday</italic>) functions into the original <italic>Nanopolish</italic> code, directly before and after the ABEA component to measure runtimes for individual reads. <italic>Nanopolish</italic> was launched with multiple threads and the runtimes were averaged by the number of threads to get a reasonable estimate for ABEA. When evaluated using the <italic>D</italic><sub><italic>small</italic></sub> dataset, the optimised ABEA CPU version in <italic>f5c</italic> was ∼1.3-1.7 × times faster than the unoptimised ABEA in the original <italic>Nanopolish</italic> program (∼1.4× speedup on Jetson TX2, workstation and HPC, ∼1.7× on low-end-laptop and ∼1.3× on high-end-laptop).</p>
    </sec>
    <sec id="Sec8">
      <title>Comparative performance of <italic>f5c</italic> with <italic>Nanopolish</italic></title>
      <p>The overall performance of the GPU-accelerated ABEA algorithm was evaluated through a DNA methylation (5-methylcytosine) detection work-flow. We compared the total runtime for methylation calling using the original <italic>Nanopolish</italic> against <italic>f5c</italic> (both CPU-only and GPU-accelerated versions) by running on two publicly available nanopore datasets (see “<xref rid="Sec3" ref-type="sec">Methods</xref>” section).</p>
      <p>We refer to the original <italic>Nanopolish</italic> (version 0.9) as <italic>nanopolish-unopti</italic>, <italic>f5c</italic> run only on the CPU as <italic>f5c-C-opti</italic> and GPU accelerated <italic>f5c</italic> as <italic>f5c-G-opti</italic>. We executed <italic>nanopolish-unopti</italic>, <italic>f5c-C-opti</italic> and <italic>f5c-G-opti</italic> on the full datasets <italic>D</italic><sub><italic>rapid</italic></sub> and <italic>D</italic><sub><italic>ligation</italic></sub>. Note that all execution instances were performed with the maximum number of CPU threads available on each system.</p>
      <p><italic>f5c-C-opti</italic> on the <italic>D</italic><sub><italic>rapid</italic></sub> dataset was: ∼2× faster than <italic>nanopolish-unopti</italic> on <italic>SoC</italic> and <italic>lapH</italic> and ∼4× faster on <italic>HPC</italic>. On <italic>D</italic><sub><italic>ligation</italic></sub>, <italic>nanopolish-unopti</italic> crashed on <italic>SoC</italic> (limited by 8GB RAM) and <italic>lapH</italic> (16GB RAM) due to the Linux Out Of Memory (OOM) killer [<xref ref-type="bibr" rid="CR12">12</xref>] (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). On <italic>D</italic><sub><italic>ligation</italic></sub>, <italic>f5c-C-opti</italic> on <italic>HPC</italic> was not only 6 × faster than <italic>nanopolish-unopti</italic>, but also consumed only ∼15 GB RAM, as opposed to &gt;100 GB used by <italic>nanopolish-unopti</italic> (both with 40 compute threads). Hence, it is evident that CPU optimisations alone can do significant improvements.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Comparison of <italic>f5c</italic> to <italic>Nanopolish</italic>. The reported run-times are for the complete methylation calling and also include disk I/O time</p></caption><graphic xlink:href="12859_2020_3697_Fig5_HTML" id="MO5"/></fig></p>
      <p>When comparing the total execution time (including disk I/O) of the entire methylation calling process with different hardware acceleration options in <italic>f5c</italic>, <italic>f5c-G-opti</italic> was 1.7 × faster than <italic>f5c-C-opti</italic> on <italic>SoC</italic>, 1.5-1.6 × on <italic>lapH</italic> and &lt;1.4× on <italic>HPC</italic> (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). On <italic>HPC</italic>, the speedup was limited to &lt;1.4× due to file I/O being the bottleneck. N.B. only the ABEA algorithm step utilises the GPU acceleration.</p>
      <p>For the <italic>D</italic><sub><italic>rapid</italic></sub> dataset, the execution time of <italic>f5c-G-opti</italic> versus <italic>nanopolish-unopti</italic> was ∼4×, ∼3× and ∼6× faster on <italic>SoC</italic>, <italic>lapH</italic> and <italic>HPC</italic>, respectively (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). On the <italic>D</italic><sub><italic>ligation</italic></sub> dataset on <italic>HPC</italic>, <italic>f5c-G-opti</italic> was a remarkable ∼9× faster.</p>
      <p>Although parameters that may affect biological accuracy were untouched, we did observe subtle variations in the output as a consequence of hardware-based fluctuations in the treatment of floating point units. We assessed the impact of these subtle variations on the measurement of relative methylation frequencies by comparing results for <italic>Nanopolish</italic>, <italic>f5c-C-opti</italic> and <italic>f5c-G-opti</italic> on the <italic>D</italic><sub><italic>small</italic></sub> dataset, which encompasses 5M bases of human chromosome 20 with an average read coverage of 30 ×. Of the ∼32,000 surveyed CpG sites, <italic>f5c-C-opti</italic> and <italic>f5c-G-opti</italic> produced different methylation frequencies for only 6 (∼0.02%) and 65 (∼0.2%) positions, with an average position-specific difference in methylation frequency values of ∼1.5% and ∼0.4%, respectively. Both variants of <italic>f5c</italic> yielded overall Pearson correlation values of 0.99999 with <italic>Nanopolish</italic>. Moreover, the overall correlation between <italic>Nanopolish</italic> and bisulfite sequencing data from NA12878 is 0.88723, while the correlation for <italic>f5c-C-opti</italic> and <italic>f5c-G-opti</italic> is 0.88723 and 0.88724, respectively. The impact of hardware-based differences in the calculation of methylation frequencies is therefore negligible.</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Discussion and future work</title>
    <p>High-throughput nanopore data analysis is a relatively new field that emerged with the release of the first ONT sequencing device (MinION) in 2014. Numerous nanopore data analysis algorithms have since been developed by biologists and bioinformaticians. However, work that explores computational bottlenecks, acceleration and parallisation techniques for such algorithms are limited, especially for those that exploit raw nanopore signal data, such as the ABEA algorithm.</p>
    <p>There are a handful of methods that have been developed to accelerate the analysis of nanopore data. The proprietary base-calling software <italic>Guppy</italic> developed by ONT exploits NVIDIA GPUs for fast and accurate processing of raw nanopore data via deep neural networks [<xref ref-type="bibr" rid="CR3">3</xref>]. Although the design details of <italic>Guppy</italic> are not publicly disclosed, they are likely to have benefited by a plethora of work focusing on GPU optimisations for neural networks. Another example of highly optimised software for third generation sequencing data is <italic>minimap2</italic>, a popular open source sequence aligner for long reads (including nanopore reads) that has recently been accelerated with the simultaneous use of GPUs and Intel Xeon Phi co-processors [<xref ref-type="bibr" rid="CR13">13</xref>]. However, alignment in base-space is considerably different from signal-space, which is explored in this work. Recently, the NVIDIA corporation has shown an interest in developing open source libraries such as <italic>Clara Genomics</italic>[<xref ref-type="bibr" rid="CR14">14</xref>] for accelerating long read data analysis on their GPUs. The <italic>Clara Genomics</italic> library contributes to nanopore data analysis domain through the acceleration of core algorithmic components such as all-vs-all read mapping and partial order alignments for genome assembly. Nonetheless, none of these algorithms focus on accelerating signal-space alignment.</p>
    <p>A number of GPU accelerated versions of SW alignment have previously been reported [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR17">17</xref>]. However, differences between SW and ABEA significantly affect the efficient mapping of the algorithm and data structures to GPU architectures. For instance, band movement in ABEA during execution and random memory accesses to the pore-model in ABEA affect data dependencies (thus, the parallelism) and the memory layout (thus, the memory access patterns). Therefore, the GPU acceleration solutions proposed in these reports are ill-suited for ABEA. In addition, the above-mentioned works were developed for short, static read-lengths. Third generation sequencers produce variable long read lengths that vary significantly over a given dataset. Consequently, the strategies we disclose herein for efficient GPU memory allocation and load balancing are novel and significant improvements for ABEA.</p>
    <p>Moreover, we demonstrate that a complete DNA methylation analysis of a human genome using raw Oxford <italic>Nanopolish</italic> sequencing data can be executed on an embedded system (e.g., a SoC equipped with ARM processor and an NVIDIA GPU) as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. The data processing speed is sufficient to keep up with data generated in real-time by four Oxford Nanopore MinION devices in parallel, or a GridION sequencer. GPU-enabled <italic>f5c</italic> can process such data using a single NVIDIA TX2 SoC, at a speed of &gt;600 Kbases per second to keep up with the sequencing output (∼600 Kbases per second [<xref ref-type="bibr" rid="CR18">18</xref>]), as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. Conversely, if the original <italic>Nanopolish</italic> was executed on the NVIDIA TX2 SoC, the processing speed is limited to ∼256 Kbases per second. The base-space alignment speed of ∼715 Kbases/s in Fig. <xref rid="Fig6" ref-type="fig">6</xref> was obtained by running Minimap2 [<xref ref-type="bibr" rid="CR19">19</xref>] on the Jetson TX2 with only 8GB using the partitioned-index approach we previously presented in [<xref ref-type="bibr" rid="CR20">20</xref>].
<fig id="Fig6"><label>Fig. 6</label><caption><p>Human genome processing on-the-fly</p></caption><graphic xlink:href="12859_2020_3697_Fig6_HTML" id="MO6"/></fig></p>
    <p>It is also noteworthy to mention that we used <italic>Nanopolish</italic> v0.9 for the performance comparisons as subsequent releases of the software incorporated some of our optimisations, excluding those that did not require major code refactoring, such as GPU implementation, threading models and I/O processing interleaving. Furthermore, the optimisations we performed were focused on restructuring and fine-tuning the implementation of the algorithm to conform with computer hardware. Parameters that might affect the biological accuracy were untouched. Still, we extensively compared results of <italic>f5c</italic> with that of <italic>Nanopolish</italic> and verified that they are almost identical, greatly surpassing variation observed using alternative experimental approaches (i.e, bisulfite sequencing for 5mC detection).</p>
    <p>Our work can not only reduce the hardware and bandwidth requirements for analysing raw Nanopore data, but can also improve the turnaround time for performing reference-guided raw nanopore signal processing, an analytic process that is used for base-calling and detecting non-standard nucleotides. In addition to embedded systems, our work benefits all computational systems, with or without GPU. For instance, our work enables methylation calling on laptops with &lt;16GB of RAM. Furthermore, we have demonstrated that <italic>a posteriori</italic> methylation calling execution with <italic>f5c</italic> on high performance computers also benefits from a significant speedup.</p>
  </sec>
  <sec id="Sec10" sec-type="conclusion">
    <title>Conclusions</title>
    <p>ABEA is a prominent bioinformatics algorithm for raw nanopore signal analysis. Although this algorithm is not massively parallel, we present a highly efficient implementation of ABEA that includes the (optional) use of GPUs. Through a number of memory optimisations and a heterogeneous processing strategy that uses both CPU and GPU, we were able to overcome several inherent challenges, such as prominent variations in sequencing read lengths. Our optimisations yield around 3-5 × performance improvement on a CPU-GPU system when compared to CPU only. We demonstrate that these optimisations are sufficient for the execution and completion of a DNA methylation detection workflow on an embedded SoC equipped with a hexa-core ARM processor and NVIDIA GPU (256 cores) in real-time. This work not only benefits embedded SoCs, but also a wide range of systems equipped with GPUs, from laptops to servers, as highlighted by a 9 × speedup and 6-fold memory reduction when performing methylation detection on a high-performance computing server. The source code of <italic>f5c</italic> is made available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hasindu2008/f5c">https://github.com/hasindu2008/f5c</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec11">
      <supplementary-material content-type="local-data" id="MOESM1">
        <media xlink:href="12859_2020_3697_MOESM1_ESM.pdf">
          <caption>
            <p><bold>Additional file 1</bold> Supplementary materials. PDF file that details all the supplementary materials.</p>
          </caption>
        </media>
      </supplementary-material>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>ABEA</term>
        <def>
          <p>Adaptive banded event alignment</p>
        </def>
      </def-item>
      <def-item>
        <term>CPU</term>
        <def>
          <p>Central processing unit</p>
        </def>
      </def-item>
      <def-item>
        <term>GPU</term>
        <def>
          <p>Graphics processing unit</p>
        </def>
      </def-item>
      <def-item>
        <term>SoC</term>
        <def>
          <p>System on chip</p>
        </def>
      </def-item>
      <def-item>
        <term>HPC</term>
        <def>
          <p>High-performance computer/computing</p>
        </def>
      </def-item>
      <def-item>
        <term>ONT</term>
        <def>
          <p>Oxford nanopore technologies</p>
        </def>
      </def-item>
      <def-item>
        <term>SW</term>
        <def>
          <p>Smith-waterman</p>
        </def>
      </def-item>
      <def-item>
        <term>SK</term>
        <def>
          <p>Suzuki-kasahara</p>
        </def>
      </def-item>
      <def-item>
        <term>POSIX</term>
        <def>
          <p>Portable operating system interface</p>
        </def>
      </def-item>
      <def-item>
        <term>CUDA</term>
        <def>
          <p>Compute unified device architecture</p>
        </def>
      </def-item>
      <def-item>
        <term>DRAM</term>
        <def>
          <p>Dynamic random access memory</p>
        </def>
      </def-item>
      <def-item>
        <term>RAM</term>
        <def>
          <p>Random access memory</p>
        </def>
      </def-item>
      <def-item>
        <term>GNU</term>
        <def>
          <p>GNU’s not unix</p>
        </def>
      </def-item>
      <def-item>
        <term>OOM</term>
        <def>
          <p>Out Of memory</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>Martin A. Smith and Sri Parameswaran contributed equally to this work.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12859-020-03697-x.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank NVIDIA for providing the Jetson TX2 board (to University of New South Wales) and Tesla K40 GPU (to University of Peradeniya) through the GPU donation programme. We thank Dr. Roshan Ragel and Dr. Swarnalatha Radhakrishnan at University of Peradeniya who assisted the research. We thank our colleagues who provided support, especially, James Ferguson and Shaun Carswell at Garvan Institute of Medical Research; Thomas Daniell, Hassaan Saadat and Darshana Jayasinghe at University of New South Wales; Geesara Pratap at Innopolis University; and, Pim Schravendijk. We also thank the Data Intensive Computer Engineering (DICE) team at Data Sciences Platform, Garvan Institute of Medical Research.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>H.G. and S.P. conceived the study. H.G., C.W.L., H.S. and G.J. re-engineered, wrote, modified and optimised software. H.G. designed, developed and optimised the GPU implementation. H.G. and C.W.L. conducted the experiments and benchmarks. M.A.S., J.T.S and S.P. provided strategic oversight for the work. H.G, M.A.S. and S.P wrote and revised the manuscript. J.T.S. critically revised the manuscript. All author(s) read and approved the manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>J.T.S. is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>All data generated or analysed during this study are included in this published article and its <xref rid="MOESM1" ref-type="media">supplementary information files</xref>. Source code of <italic>f5c</italic> is available in the GitHub repository, <ext-link ext-link-type="uri" xlink:href="https://github.com/hasindu2008/f5c">https://github.com/hasindu2008/f5c</ext-link>. A reproducible Code Ocean compute capsule is available at 10.24433/CO.3078978.v1</p>
  </notes>
  <notes id="FPar1">
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable.</p>
  </notes>
  <notes id="FPar2">
    <title>Consent for publication</title>
    <p>Not applicable.</p>
  </notes>
  <notes id="FPar3" notes-type="COI-statement">
    <title>Competing interests</title>
    <p>H.G. received a travel bursary from Oxford Nanopore Technologies to present at conferences. J.T.S. receives research funding from ONT and has received travel support to attend and speak at meetings organized by ONT. M. A. S. received travel and accommodation expenses to speak at Oxford Nanopore Technologies conferences and are listed as inventors on patent PCT/AU2018/050265 relating to signal alignment.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Giordano</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Ning</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Oxford nanopore minion sequencing and genome assembly</article-title>
        <source>Genomics Proteomics Bioinforma</source>
        <year>2016</year>
        <volume>14</volume>
        <issue>5</issue>
        <fpage>265</fpage>
        <lpage>79</lpage>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rang</surname>
            <given-names>FJ</given-names>
          </name>
          <name>
            <surname>Kloosterman</surname>
            <given-names>WP</given-names>
          </name>
          <name>
            <surname>de Ridder</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>From squiggle to basepair: computational approaches for improving nanopore sequencing read accuracy</article-title>
        <source>Genome Biol</source>
        <year>2018</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>90</fpage>
        <?supplied-pmid 30005597?>
        <pub-id pub-id-type="pmid">30005597</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wick</surname>
            <given-names>RR</given-names>
          </name>
          <name>
            <surname>Judd</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Holt</surname>
            <given-names>KE</given-names>
          </name>
        </person-group>
        <article-title>Performance of neural network basecalling tools for oxford nanopore sequencing</article-title>
        <source>Genome Biol</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>129</fpage>
        <?supplied-pmid 31234903?>
        <pub-id pub-id-type="pmid">31234903</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jain</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Koren</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Miga</surname>
            <given-names>KH</given-names>
          </name>
          <name>
            <surname>Quick</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rand</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Sasani</surname>
            <given-names>TA</given-names>
          </name>
          <name>
            <surname>Tyson</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Beggs</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Dilthey</surname>
            <given-names>AT</given-names>
          </name>
          <name>
            <surname>Fiddes</surname>
            <given-names>IT</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Nanopore sequencing and assembly of a human genome with ultra-long reads</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <issue>4</issue>
        <fpage>338</fpage>
        <?supplied-pmid 29431738?>
        <pub-id pub-id-type="pmid">29431738</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Loman</surname>
            <given-names>NJ</given-names>
          </name>
          <name>
            <surname>Quick</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Simpson</surname>
            <given-names>JT</given-names>
          </name>
        </person-group>
        <article-title>A complete bacterial genome assembled de novo using only nanopore sequencing data</article-title>
        <source>Nat Methods</source>
        <year>2015</year>
        <volume>12</volume>
        <issue>8</issue>
        <fpage>733</fpage>
        <?supplied-pmid 26076426?>
        <pub-id pub-id-type="pmid">26076426</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Simpson</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Workman</surname>
            <given-names>RE</given-names>
          </name>
          <name>
            <surname>Zuzarte</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>David</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Dursi</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Timp</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Detecting dna cytosine methylation using nanopore sequencing</article-title>
        <source>Nat Methods</source>
        <year>2017</year>
        <volume>14</volume>
        <issue>4</issue>
        <fpage>407</fpage>
        <?supplied-pmid 28218898?>
        <pub-id pub-id-type="pmid">28218898</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bird</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Dna methylation patterns and epigenetic memory</article-title>
        <source>Genes Dev</source>
        <year>2002</year>
        <volume>16</volume>
        <issue>1</issue>
        <fpage>6</fpage>
        <lpage>21</lpage>
        <?supplied-pmid 11782440?>
        <pub-id pub-id-type="pmid">11782440</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chao</surname>
            <given-names>K-M</given-names>
          </name>
          <name>
            <surname>Pearson</surname>
            <given-names>WR</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Aligning two sequences within a specified diagonal band</article-title>
        <source>Bioinformatics</source>
        <year>1992</year>
        <volume>8</volume>
        <issue>5</issue>
        <fpage>481</fpage>
        <lpage>7</lpage>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Suzuki</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kasahara</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Introducing difference recurrence relations for faster semi-global alignment of long sequences</article-title>
        <source>BMC Bioinformatics</source>
        <year>2018</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>45</fpage>
        <?supplied-pmid 29504909?>
        <pub-id pub-id-type="pmid">29504909</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <mixed-citation publication-type="other">Technologies ON. Ligation sequencing kit 1D or rapid sequencing kit. 2017. <ext-link ext-link-type="uri" xlink:href="https://store.nanoporetech.com/media/Ligation_Sequencing_Kit_1D_or_Rapid_Sequencing_Kit_v5_Feb2017.pdf">https://store.nanoporetech.com/media/Ligation_Sequencing_Kit_1D_or_Rapid_Sequencing_Kit_v5_Feb2017.pdf</ext-link>. Accessed 29 July 2020.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <mixed-citation publication-type="other">Simpson J. Stats and analysis. 2017. <ext-link ext-link-type="uri" xlink:href="https://nanopolish.readthedocs.io/en/latest/quickstart_call_methylation.html">https://nanopolish.readthedocs.io/en/latest/quickstart_call_methylation.html</ext-link>. Accessed 29 July 2020.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <mixed-citation publication-type="other">Chase R. How to configure the linux out-of-memory killer. 2013. <ext-link ext-link-type="uri" xlink:href="https://www.oracle.com/technical-resources/articles/it-infrastructure/dev-oom-killer.html">https://www.oracle.com/technical-resources/articles/it-infrastructure/dev-oom-killer.html</ext-link>. Accessed 29 July 2020.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Feng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Accelerating long read alignment on three processors</article-title>
        <source>Proceedings of the 48th International Conference on Parallel Processing</source>
        <year>2019</year>
        <publisher-loc>Kyoto</publisher-loc>
        <publisher-name>ACM</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <mixed-citation publication-type="other">NVIDIA. Clara genomics. 2020. <ext-link ext-link-type="uri" xlink:href="https://developer.nvidia.com/Clara-Genomics">https://developer.nvidia.com/Clara-Genomics</ext-link>. Accessed 20 Jan 2020.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Johnson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Vaidya</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Gpu accelerated smith-waterman</article-title>
        <source>International Conference on Computational Science</source>
        <year>2006</year>
        <publisher-loc>Berlin</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Manavski</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Valle</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Cuda compatible gpu cards as efficient hardware accelerators for smith-waterman sequence alignment</article-title>
        <source>BMC Bioinformatics</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>2</issue>
        <fpage>10</fpage>
        <pub-id pub-id-type="pmid">18182099</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Maskell</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Schmidt</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>CUDASW++: optimizing Smith-Waterman sequence database searches for CUDA-enabled graphics processing units</article-title>
        <source>BMC Res Notes</source>
        <year>2009</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>73</fpage>
        <?supplied-pmid 19416548?>
        <pub-id pub-id-type="pmid">19416548</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <mixed-citation publication-type="other">Technologies ON. MinIT is out - an analysis and device control accessory to enable powerful, real-time DNA/RNA sequencing by anyone, anywhere. 2018. <ext-link ext-link-type="uri" xlink:href="https://nanoporetech.com/about-us/news/minit-launch">https://nanoporetech.com/about-us/news/minit-launch</ext-link>. Accessed 29 July 2020.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Minimap2: pairwise alignment for nucleotide sequences</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>18</issue>
        <fpage>191</fpage>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gamaarachchi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Parameswaran</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>Featherweight long read alignment using partitioned reference indexes</article-title>
        <source>Sci Rep</source>
        <year>2019</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>4318</fpage>
        <?supplied-pmid 30867495?>
        <pub-id pub-id-type="pmid">30867495</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
