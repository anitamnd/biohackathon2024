<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10148686</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbad052</article-id>
    <article-id pub-id-type="publisher-id">vbad052</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>HMMerge: an ensemble method for multiple sequence alignment</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8676-7565</contrib-id>
        <name>
          <surname>Park</surname>
          <given-names>Minhyuk</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="http://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software" degree-contribution="equal">Software</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Validation" vocab-term-identifier="http://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/visualization" degree-contribution="equal">Visualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <aff><institution>Department of Computer Science, University of Illinois Urbana-Champaign</institution>, Urbana, IL 61801, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7717-3514</contrib-id>
        <name>
          <surname>Warnow</surname>
          <given-names>Tandy</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="http://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="equal">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="http://credit.niso.org/contributor-roles/project-administration" degree-contribution="equal">Project administration</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role>
        <xref rid="vbad052-cor1" ref-type="corresp"/>
        <aff><institution>Department of Computer Science, University of Illinois Urbana-Champaign</institution>, Urbana, IL 61801, <country country="US">USA</country></aff>
        <!--warnow@illinois.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Lengauer</surname>
          <given-names>Thomas</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="vbad052-cor1">To whom correspondence should be addressed. <email>warnow@illinois.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-04-17">
      <day>17</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <issue>1</issue>
    <elocation-id>vbad052</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>06</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>13</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>13</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>29</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbad052.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Despite advances in method development for multiple sequence alignment over the last several decades, the alignment of datasets exhibiting substantial sequence length heterogeneity, especially when the input sequences include very short sequences (either as a result of sequencing technologies or of large deletions during evolution) remains an inadequately solved problem.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present HMMerge, a method to compute an alignment of datasets exhibiting high sequence length heterogeneity, or to add short sequences into a given ‘backbone’ alignment. HMMerge builds on the technique from its predecessor alignment methods, UPP and WITCH, which build an ensemble of profile HMMs to represent the backbone alignment and add the remaining sequences into the backbone alignment using the ensemble. HMMerge differs from UPP and WITCH by building a new ‘merged’ HMM from the ensemble, and then using that merged HMM to align the query sequences. We show that HMMerge is competitive with WITCH, with an advantage over WITCH when adding very short sequences into backbone alignments.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>HMMerge is freely available at <ext-link xlink:href="https://github.com/MinhyukPark/HMMerge" ext-link-type="uri">https://github.com/MinhyukPark/HMMerge</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2006069</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Multiple sequence alignment (MSA) is a necessary first step in many common bioinformatics pipelines, such as phylogenetic tree inference and metagenomic taxon identification, and so obtaining high quality MSAs has high relevance in downstream analyses (<xref rid="vbad052-B10" ref-type="bibr">Matsen <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="vbad052-B14" ref-type="bibr">Morrison, 2006</xref>). One of the challenges in multiple sequence alignment is when the input sequence dataset has highly variable sequence lengths, a property that is found in many biological datasets (<xref rid="vbad052-B15" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic>, 2015</xref>). Sequence length heterogeneity can be caused by evolutionary processes (e.g. large indels), but is also produced when datasets include reads generated by Illumina and other short read sequencing technologies (<xref rid="vbad052-B20" ref-type="bibr">Shendure and Ji, 2008</xref>).</p>
    <p>UPP (<xref rid="vbad052-B15" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic>, 2015</xref>) and its successor WITCH (<xref rid="vbad052-B19" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2022</xref>) are methods that are designed to align datasets when the input has sequence length heterogeneity. Both methods use a two-stage approach, where they first identify and extract a subset of the input sequences (based on their sequence length) that are considered to be ‘full-length’, and then align these sequences, forming the ‘backbone alignment’. Both then build an ensemble of profile Hidden Markov Models (eHMM) to represent the backbone alignment, where each profile HMM is built on a subset of the input sequences in the backbone alignment [see <xref rid="vbad052-B3" ref-type="bibr">Durbin <italic toggle="yes">et al.</italic> (1998)</xref> for an introduction to profile Hidden Markov Models]. UPP adds each of the remaining sequences (called ‘queries’) to the backbone alignment, as follows: (i) each query sequence selects a best-fitting HMM from the eHMM based on the bit scores, (ii) the Viterbi algorithm is used to find an optimal path for the query sequence through the selected HMM and (iii) the match states in the optimal path define an alignment of the query sequence to the backbone alignment, which is used to add the query sequence into the backbone alignment. WITCH elaborates on this approach by weighting each profile HMM with the probability it has of generating the query sequence, and then combines the optimal alignments (one such alignment for each profile HMM in the eHMM) into a consensus alignment using the Graph Clustering Merger from <xref rid="vbad052-B22" ref-type="bibr">Smirnov and Warnow (2021a</xref>). Both UPP and WITCH produce more accurate alignments than standard methods, including MAGUS (<xref rid="vbad052-B22" ref-type="bibr">Smirnov and Warnow, 2021a</xref>), when datasets have fragmentary sequences (<xref rid="vbad052-B15" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="vbad052-B19" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2022</xref>), and WITCH generally dominates UPP for accuracy (<xref rid="vbad052-B19" ref-type="bibr">Shen <italic toggle="yes">et al.</italic>, 2022</xref>).</p>
    <p>Here, we present HMMerge, a new approach for computing alignments. We follow the same initial steps as WITCH and UPP (i.e. we use the same technique to build the backbone alignment and the ensemble of HMMs representing the backbone alignment). We then deviate from WITCH in several ways. First, we use only a selected subset of the HMMs from the WITCH ensemble of HMMs for the HMMerge ensemble. Second, instead of aligning the query sequence to each HMM and then computing a consensus of these extended alignments, we use the HMMerge ensemble of HMMs to build a new HMM (not a standard profile HMM, however) to represent the backbone alignment. The topology of the HMM is the same for all query sequences but the numeric parameters (transition and emission probabilities) are derived for each query sequence. Finally, given a query sequence, the numeric parameters are computed and then used to align the query sequence to the backbone alignment.</p>
    <p>As this study shows, using both simulated and biological data, HMMerge is competitive with WITCH when aligning datasets with sequence length heterogeneity (sometimes more accurate and sometimes less accurate), and has an advantage in some cases when there are very short sequences in the dataset. More generally, we show that two-stage methods, including the use of MAFFT-addfragments (<xref rid="vbad052-B8" ref-type="bibr">Katoh and Frith, 2012</xref>), provide more reliable accuracy when aligning datasets with sequence length heterogeneity than standard methods.</p>
  </sec>
  <sec>
    <title>2 Methods</title>
    <p>We first describe HMMerge, which is our new approach for aligning sequence datasets that exhibit sequence length heterogeneity. We then describe the experimental study we used to evaluate HMMerge.</p>
    <sec>
      <title>2.1 HMMerge</title>
      <p>HMMerge operates in three stages: the backbone stage, the construction of the eHMM for the backbone, and then the search-and-align stage. HMMerge uses the same process for stages 1 and 2 as handled by both UPP and WITCH, but then differs from both for the third stage. Due to space limitations, we briefly review the first two stages, and provide details only for the third stage for HMMerge; see <xref rid="vbad052-B19" ref-type="bibr">Shen <italic toggle="yes">et al.</italic> (2022)</xref> for additional details about how these first two stages are performed in WITCH.</p>
      <sec>
        <title>2.1.1 Stage 1: computing the backbone alignment</title>
        <p>In the backbone stage, the input sequences are split into two sets, with one set containing some of the ‘full-length’ sequences and the remaining sequences denoted ‘query’ sequences. An alignment is built on the full-length sequences, using external methods [e.g. PASTA (<xref rid="vbad052-B13" ref-type="bibr">Mirarab <italic toggle="yes">et al.</italic>, 2015</xref>) or MAGUS]. However, any method can be used to produce the backbone alignment, and the use of the Bayesian method BAli-Phy (<xref rid="vbad052-B26" ref-type="bibr">Suchard and Redelings, 2006</xref>) for statistical alignment was studied in this context (<xref rid="vbad052-B16" ref-type="bibr">Nute and Warnow, 2016</xref>).</p>
      </sec>
      <sec>
        <title>2.1.2 Stage 2: computing the eHMM</title>
        <p>Once the backbone alignment is computed, a tree is computed on the backbone alignment [e.g. using a maximum likelihood method, such as FastTree 2 (<xref rid="vbad052-B18" ref-type="bibr">Price <italic toggle="yes">et al.</italic>, 2010</xref>) or RAxML (<xref rid="vbad052-B24" ref-type="bibr">Stamatakis, 2014</xref>)]. Then, the backbone tree is decomposed into subsets by edge deletions (removing ‘centroid edges’ that split the leaf-set into two roughly equally sized parts) until each subset is at most a given size specified by the user. For HMMerge, we stopped at subset size 50, for the sake of runtime (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials Section S5</xref>). The full set of backbone sequences and any subset produced by the decomposition pipeline becomes one of the subsets. A profile HMM is constructed on each subset using <italic toggle="yes">hmmbuild</italic> from the HMMER suite (<xref rid="vbad052-B4" ref-type="bibr">Eddy, 2011</xref>). The collection of profile HMMs produced in this stage is referred to as an ‘ensemble of HMMs’ for the backbone alignment, or ‘eHMM’.</p>
      </sec>
      <sec>
        <title>2.1.3 Stage 3: search-and-align stage</title>
        <p>For this stage, HMMalign builds a new HMM (not a profile HMM, however), based on a selected subset of the HMMs in the ensemble. Here, we explored several options for the selection. The default case is where we use just the HMMs based on the minimal sequence subsets, which are pairwise-disjoint; we refer to this as the Disjoint(50) eHMM. We also explore Disjoint(50)+BB, which is where we add the HMM for the full backbone alignment to Disjoint(50). Finally, we explore UPP(50), which is where we use the same ensemble as used by UPP decomposing to size 50, which is based on a hierarchical set of sequence subsets. Henceforth, when we refer to ‘eHMM’, we mean whichever eHMM has been selected, but the default in our experiments is to use Disjoint(50).</p>
        <p>To add a given query sequence into the backbone alignment using HMMalign, each query sequence scores each HMM in the eHMM according to an ‘adjusted’ bit score, which is designed to be an estimate of the probability that the HMM generated the given query sequence [see <xref rid="vbad052-B19" ref-type="bibr">Shen <italic toggle="yes">et al.</italic> (2022)</xref> for the derivation of the adjusted bit score]. Note that the choice of eHMM affects the adjusted bitscore calculation, since these depend on whether or not the subsets are disjoint, as described in <xref rid="vbad052-B19" ref-type="bibr">Shen <italic toggle="yes">et al.</italic> (2022)</xref>.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Merged HMM construction</title>
      <p>HMMerge computes the topology of the merged HMM from the ensemble of HMMs, and each query sequence then defines the numeric parameters on this common topology. Here we describe first how we compute the topology, and then how we define the numeric parameters.</p>
      <p>Since every HMM in the ensemble is constructed for a sub-alignment of the backbone alignment (induced by a subset of the rows of the alignment matrix), each match state in each of these HMMs corresponds to a specific column (also known as ‘site’) in the backbone alignment. The merged HMM will have the same set of states (match state, insertion states and deletion states) as the HMM for the backbone alignment, but there may be additional edges in the merged HMM, as we now describe. Suppose for example one of the subset alignments is entirely gapped in sites 10 through 20, but otherwise all the sites have at least one letter and so are not entirely gapped. For this subset alignment, the HMM will have match states for all sites in the backbone alignment other than those for sites 10 through 20. Therefore, the HMM for this subset alignment will have a transition from the match state for backbone alignment site 9 to the match state for backbone alignment site 21, as well as other transition edges. These transition edges will be included in the merged HMM topology. As a result, the merged HMM is not a standard profile HMM.</p>
      <p>Although the topology remains fixed for each query sequence, the numeric parameters (i.e. transition probabilities and emission probabilities) depend on the query sequence. Each query sequence assigns a weight to each HMM using the adjusted bitscore, which reflects the probability that the HMM produced the query sequence; see <xref rid="vbad052-B19" ref-type="bibr">Shen <italic toggle="yes">et al.</italic> (2022)</xref>. In the merged HMM for that given query sequence, we then use these bit scores to compute the numeric parameters, as follows. To compute the transition probability on an edge from state A to state B, we compute the weighted sum of the transition probabilities on the same edge across all HMMs that have that edge, where the weight for a given HMM is the adjusted bit score of that HMM for that query sequence. Similarly, the emission probabilities for a match state are computed by the weighted sum of the emission probabilities for that match state across the HMMs that have that match state.</p>
      <p>Given the ensemble of HMMs and a single query sequence, we use this process to compute the merged HMM. Note that the HMMs for the different query sequences differ only in the numeric parameters, and that the topology of the merged HMMs has all the edges from the HMMs in the ensemble.</p>
    </sec>
    <sec>
      <title>2.3 Modifying the merged HMM to enable glocal alignment</title>
      <p>Once the merged HMM is defined for the given query sequence, we use a standard Viterbi algorithm to align the query sequences to the merged HMM. This alignment defines an extended alignment of the query sequence to the backbone alignment in the usual way. However, since the Viterbi algorithm is naturally a global alignment algorithm, we introduce additional edges to the merged HMM in order to enable a glocal alignment.</p>
      <p>A glocal alignment is a hybrid approach in which the entirety of one sequence is aligned to a segment from another sequence. An example where this may be useful is aligning a short sequence to a long sequence. In this case, we would like to align the entirety of the short sequence to a specific region in the longer sequence. In order to allow for glocal alignment without incurring any penalties, i.e. aligning a query sequence to a specific region of the backbone alignment, we need to allow for our HMM algorithm to be able to start at any match state and end at any match state.</p>
      <p>We define two new probabilities, <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">entry</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">exit</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, which represent the transition probabilities from the start state to each match state and from each match and delete states to the end state, respectively; see <xref rid="vbad052-F1" ref-type="fig">Figure 1</xref>. Let <italic toggle="yes">S</italic> be the number of match states. <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">exit</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a constant 0.1 whereas <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">entry</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>0.1</mml:mn></mml:mrow><mml:mi>S</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>. To account for the new edges, we normalize the edge weights such that all outgoing edge weights sum to 1 for each state.</p>
      <fig position="float" id="vbad052-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Equal entry exit HMM example. Here, we show a visualization of an example HMM with equal entry and exit probability edges. <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>entry</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>exit</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> represent the probabilities of a path taking that edge. <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> stands for the <italic toggle="yes">i</italic>th match state, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> stands for the <italic toggle="yes">i</italic>th insertion state, and <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> stands for the <italic toggle="yes">i</italic>th deletion state. Only the insertion and match states emit letters</p>
        </caption>
        <graphic xlink:href="vbad052f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.4 Combining the extended alignments</title>
      <p>After all query sequences are added to the backbone alignment, the final alignment is produced through transitivity (this is the same technique as used in UPP and WITCH). Note however that homologies in the final alignment only take place through the match states—letters that are introduced through insertion states are never considered homologous to any other letters. These letters that are added through insertion states are indicated through the use of lower-case letters in the output alignment.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Experimental study design</title>
    <p>We performed a sequence of experiments. In the first two experiments, we explored HMMerge in comparison to other methods using the default eHMM, Disjoint(50). We then performed an additional experiment where we varied the selection of HMMs for the ensemble. While we used some standard methods [e.g. MAFFT (<xref rid="vbad052-B9" ref-type="bibr">Katoh <italic toggle="yes">et al.</italic>, 2002</xref>) and MUSCLE (<xref rid="vbad052-B5" ref-type="bibr">Edgar, 2004</xref>)], a major focus of this study is on two-stage methods, like HMMerge, that operate by constructing a backbone alignment and then adding the remaining sequences into the backbone alignment. Thus, we also used UPP, WITCH and the use of MAFFT-addfrags in this study. On all datasets tested, these four two-stage methods used the same backbone alignments computed by MAGUS and backbone trees computed by FastTree (<xref rid="vbad052-B18" ref-type="bibr">Price <italic toggle="yes">et al.</italic>, 2010</xref>). All the tested datasets exhibit sequence length heterogeneity, as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S10–S14</xref>.</p>
    <sec>
      <title>3.1 Experiment 1: analyses of simulated datasets with introduced fragmentation</title>
      <p>In Experiment 1, we explored both standard and two-stage methods on simulated datasets with introduced fragmentation.</p>
    </sec>
    <sec>
      <title>3.2 Experiment 2: analyses of biological datasets</title>
      <p>In this experiment, we examined both standard and two-stage methods on five rRNA datasets from the Comparative Ribosomal Website (CRW) (<xref rid="vbad052-B2" ref-type="bibr">Cannone <italic toggle="yes">et al.</italic>, 2002</xref>).</p>
    </sec>
    <sec>
      <title>3.3 Experiment 3: exploring results with changes to the eHMM</title>
      <p>In the previous two experiments, we used Disjoint(50) for the eHMMs we used for HMMerge. In this experiment, we explored the impact of using a larger eHMM –that is, Disjoint(50)+BB (i.e. including the HMM for the backbone alignment) or UPP(50) [i.e. using all the HMMs in the UPP(50) ensemble]. We perform this experiment on a subset of the study datasets.</p>
    </sec>
    <sec>
      <title>3.4 Simulated datasets</title>
      <p>We created high-fragmentary (HF) versions of simulated nucleotide datasets, each with 1000 sequences, using three different simulators: ROSE (<xref rid="vbad052-B25" ref-type="bibr">Stoye <italic toggle="yes">et al.</italic>, 1998</xref>), RNASim (<xref rid="vbad052-B13" ref-type="bibr">Mirarab <italic toggle="yes">et al.</italic>, 2015</xref>) and INDELible (<xref rid="vbad052-B6" ref-type="bibr">Fletcher and Yang, 2009</xref>). To make these HF versions, we used the same technique and parameters as in <xref rid="vbad052-B23" ref-type="bibr">Smirnov and Warnow (2021b</xref>). These HF datasets have 1000 sequences, and half of the sequences have been trimmed (i.e. a prefix and suffix are deleted) to produce a substring that is on average 25% of the median length with a standard deviation of 60 base pairs. These datasets consist of 500 full-length sequences and 500 fragmentary sequences.</p>
      <p>The ROSE simulated datasets have 15 model conditions each with 20 replicates, where each model condition varies by the average length of gaps (‘S’ for Short, ‘M’ for Medium or ‘L’ for Long) and by their varying substitution rates (models are numbered 1 through 5, and the substitution rate decreases as the number increases).</p>
      <p>The RNASim simulated datasets were originally used to evaluate alignment methods in <xref rid="vbad052-B13" ref-type="bibr">Mirarab <italic toggle="yes">et al.</italic> (2015)</xref>, and the simulation protocol for generating these datasets is described in Appendix A in the supplementary materials for <xref rid="vbad052-B13" ref-type="bibr">Mirarab <italic toggle="yes">et al.</italic> (2015)</xref>. These sequences evolve under a biophysical model that enforces selection in order to maintain RNA secondary structure. We use HF versions from <xref rid="vbad052-B23" ref-type="bibr">Smirnov and Warnow (2021b</xref>) and we also made an ultra-high fragmentary, or ‘UHF’, version of the dataset by setting the target mean to be exactly half of the HF condition. The target mean sequence length was 388 for the HF condition and 194 for the UHF condition. The standard deviation remained at 60, which is the same as the original study. We used 10 replicates each for both datasets.</p>
      <p>The INDELible datasets were created for this study. The model tree for the simulation was taken from the set of gene trees from the ASTRAL-II study (<xref rid="vbad052-B12" ref-type="bibr">Mirarab and Warnow, 2015</xref>). In order to make alignment estimation challenging, we scaled the branch lengths of the model tree by a factor of two. Since these simulated datasets evolve without indels, we modified the simulation to produce indels. The indel gap length distribution was taken from the PASTA study (<xref rid="vbad052-B13" ref-type="bibr">Mirarab <italic toggle="yes">et al.</italic>, 2015</xref>), where INDELible was used to generate simulated datasets. We simulated sequences under these conditions with an indel rate of 0.001 and 0.005, relative to a substitution rate of 1. These sequences were then fragmented according to the HF protocol described above. 10 replicates were created for each indel rate model condition.</p>
    </sec>
    <sec>
      <title>3.5 Biological datasets</title>
      <p>We used datasets from the Comparative RNA Website (CRW) (<xref rid="vbad052-B2" ref-type="bibr">Cannone <italic toggle="yes">et al.</italic>, 2002</xref>), which have curated alignments based on rRNA structure for the 23S and 5S ribosomal RNA genes. We chose 23S.A, 23S.C 5S.3, 5S.E and 5S.T for our study. These datasets vary in how much sequence length variability they have, with 23S datasets exhibiting more fragmentation than the 5S datasets (<xref rid="vbad052-F2" ref-type="fig">Fig. 2</xref>).</p>
      <fig position="float" id="vbad052-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Sequence length heterogeneity histograms for two biological datasets (23S.A and 5S.3) from the Comparative Ribosomal Website (<xref rid="vbad052-B2" ref-type="bibr">Cannone <italic toggle="yes">et al.</italic>, 2002</xref>)</p>
        </caption>
        <graphic xlink:href="vbad052f2" position="float"/>
      </fig>
      <p>To separate the biological datasets into backbone sequences and query sequences, we split the sequences using visual inspection of their sequence length histograms. As a result, 23S.A and 23S.C were both split at 1250 (so that sequences shorter than 1250 in length were considered query sequences and the rest were backbone sequences), and 5S.3, 5S.E, and 5S.T were split at 100 (with the corresponding definition).</p>
      <p>For the simulated datasets, we summarize the empirical properties in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>. For the CRW biological datasets, we summarize the empirical properties in <xref rid="vbad052-T1" ref-type="table">Table 1</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>.</p>
      <table-wrap position="float" id="vbad052-T1">
        <label>Table 1.</label>
        <caption>
          <p>Biological DNA/RNA dataset overview</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Name</th>
              <th rowspan="1" colspan="1">No. of sequences</th>
              <th rowspan="1" colspan="1">Avg. <italic toggle="yes">p</italic>-dist.</th>
              <th rowspan="1" colspan="1">Avg. len.</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">23S.A</td>
              <td rowspan="1" colspan="1">214</td>
              <td rowspan="1" colspan="1">0.293</td>
              <td rowspan="1" colspan="1">1851</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">23S.C</td>
              <td rowspan="1" colspan="1">374</td>
              <td rowspan="1" colspan="1">0.143</td>
              <td rowspan="1" colspan="1">2087</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.3</td>
              <td rowspan="1" colspan="1">5507</td>
              <td rowspan="1" colspan="1">0.417</td>
              <td rowspan="1" colspan="1">106</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.E</td>
              <td rowspan="1" colspan="1">2774</td>
              <td rowspan="1" colspan="1">0.305</td>
              <td rowspan="1" colspan="1">96</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.T</td>
              <td rowspan="1" colspan="1">5751</td>
              <td rowspan="1" colspan="1">0.425</td>
              <td rowspan="1" colspan="1">106</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: Here, we show the basic empirical statistics about the datasets used in this study. <italic toggle="yes">p</italic>-dist. refers to the normalized Hamming distance [i.e. the number of positions where the two sequences have different letters divided by the number of positions where both sequences have letters (are not gapped)].</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.6 MSA methods</title>
      <p>We compare our new MSA pipeline, HMMerge, to three other two-stage methods (UPP, WITCH and MAFFT-addfragments), each using the same backbone alignment. We also compare these two-stage methods to a collection of leading MSA methods, including MAGUS, PASTA, Clustal Omega (<xref rid="vbad052-B21" ref-type="bibr">Sievers <italic toggle="yes">et al.</italic>, 2011</xref>), MUSCLE (<xref rid="vbad052-B5" ref-type="bibr">Edgar, 2004</xref>), MAFFT (<xref rid="vbad052-B9" ref-type="bibr">Katoh <italic toggle="yes">et al.</italic>, 2002</xref>) and T-COFFEE (<xref rid="vbad052-B7" ref-type="bibr">Garriga <italic toggle="yes">et al.</italic>, 2019</xref>). The only methods that were not run in their default modes were MAFFT, which was run using the L-INS-i algorithm (to maximize accuracy), and T-COFFEE, which was run using the regressive mode. The exact commands and versions for each of the methods are supplied in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials Section S1</xref>.</p>
    </sec>
    <sec>
      <title>3.7 Computational resources</title>
      <p>All runs of HMMerge, WITCH, UPP and MAFFT-addfrags were run on the Illinois Campus Cluster with 16 cores available for parallelism and a default memory limit of 64GB. The standard methods (MAGUS, PASTA, MAFFT, Clustal Omega, T-COFFEE and MUSCLE) were run on BlueWaters (<xref rid="vbad052-B1" ref-type="bibr">Bode <italic toggle="yes">et al.</italic>, 2013</xref>) for the ROSE and CRW datasets. However, as discussed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials Section S5</xref>, HMMerge needed extra memory for some analyses, which required us to use a high-memory machine with up to 1TB of memory for these analyses.</p>
    </sec>
    <sec>
      <title>3.8 Evaluation criteria</title>
      <p>Alignment error was calculated using FastSP (<xref rid="vbad052-B11" ref-type="bibr">Mirarab and Warnow, 2011</xref>). SPFN and SPFP are based on pairwise homologies, i.e. pairs of letters that appear in the same column of the estimated or reference alignment. Thus, SPFN, or sum-of-pairs false negatives, is the fraction of true pairwise homologies (i.e. homologies in the reference alignment) that are not found in the estimated alignment, while SPFP, or sum-of-pairs false positives, is the fraction of putative homologies in the estimated alignment that are not in the reference alignment. Note that letters that are emitted by our HMM-based alignment method through insertion states are never considered homologous to any other letters, and are represented by lower-case letters in the output alignment.</p>
      <p>We include both standard methods (i.e. methods that do not operate in two stages) as well as two-stage methods. When we include standard methods in the comparison, we report ‘total’ alignment error, which is alignment error on the entire sequence dataset. However, when we compare two-stage methods to each other, we report ‘query-only’ alignment error. This allows us to take advantage of the fact that all the two-stage methods are using the same backbone alignment.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Results</title>
    <sec>
      <title>4.1 Experiment 1: analyses of simulated datasets with introduced fragmentation</title>
      <sec>
        <title>4.1.1 ROSE-HF nucleotide simulated datasets</title>
        <p>The comparison of six standard methods (MAGUS, PASTA, T-COFFEE, MUSCLE, MAFFT-linsi and Clustal-Omega) and UPP on the 15 ROSE model conditions is given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. While all methods have nearly the same accuracy on the easier model conditions, the gap between methods increases with the difficulty of the model condition. UPP was consistently the method with the least error on the harder model conditions, and for the three hardest model conditions (1000L3-HF, 1000S1-HF and 1000M1-HF) there is a gap of more than 0.1 in average alignment error between UPP and the next best method, which is MAGUS.</p>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref> compares HMMerge, WITCH and UPP for query-only alignment error across the nine hardest model conditions. In this comparison, UPP always has the highest average query-only error, and HMMerge is always at least as accurate as WITCH. However, the gap between WITCH and HMMerge is never more than 0.020. Also, MAGUS has higher error than these three two-phase methods (HMMerge, WITCH and UPP), as seen in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S3</xref>.</p>
        <p>A comparison between all four two-stage methods on the three hardest model conditions, 1000S1-HF, 1000L3-HF and 1000M1-HF (<xref rid="vbad052-F3" ref-type="fig">Fig. 3</xref>), shows that HMMerge and WITCH have the lowest average error (and never differ by more than 0.012), followed by UPP, and finally by MAFFT-addfrags.</p>
        <fig position="float" id="vbad052-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Query sequence alignment error of two-stage methods on ROSE simulated datasets with introduced fragmentation. Each model condition has 20 replicates; error bars show standard error</p>
          </caption>
          <graphic xlink:href="vbad052f3" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>4.1.2 RNASim1000-HF and RNASim1000-UHF datasets</title>
        <p>A comparison between the standard methods and the two-stage methods is shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S6</xref>. The four two-stage methods, MAGUS and MAFFT-linsi have average alignment error between 0.101 and 0.127 while the remaining methods have average alignment error that is never less than 0.250. MAGUS and MAFFT-linsi always have higher average alignment error than the four two-stage methods, and the difference is always at least 0.007.</p>
        <p>Comparing the four two-stage methods to each other with respect to query-only alignment error (<xref rid="vbad052-T2" ref-type="table">Table 2</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>), we see the following trends. UPP, WITCH and HMMerge never differ by more than 0.005 for average alignment error and MAFFT-addfrags always has higher average alignment error. For example, on the HF condition, MAFFT-addfrags has 0.123 average alignment error and the other three methods have average error between 0.100 and 0.101. On the UHF condition, MAFFT-addfrags has 0.126 average alignment error and the other three methods have average error between 0.103 and 0.108. In sum, UPP, WITCH and HMMerge are very close in accuracy, and all are somewhat more accurate than MAFFT-addfrags.</p>
        <table-wrap position="float" id="vbad052-T2">
          <label>Table 2.</label>
          <caption>
            <p>Query sequence alignment error of two-stage methods on RNASim1000 with introduced fragmentation</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">RNASim1000</th>
                <th rowspan="1" colspan="1">HMMerge</th>
                <th rowspan="1" colspan="1">WITCH</th>
                <th rowspan="1" colspan="1">UPP</th>
                <th rowspan="1" colspan="1">MAFFT addfrags</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">HF—average</td>
                <td rowspan="1" colspan="1">0.100</td>
                <td rowspan="1" colspan="1">0.101</td>
                <td rowspan="1" colspan="1">0.100</td>
                <td rowspan="1" colspan="1">0.123</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">HF—SPFN</td>
                <td rowspan="1" colspan="1">0.102</td>
                <td rowspan="1" colspan="1">0.103</td>
                <td rowspan="1" colspan="1">0.108</td>
                <td rowspan="1" colspan="1">0.126</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">HF—SPFP</td>
                <td rowspan="1" colspan="1">0.098</td>
                <td rowspan="1" colspan="1">0.099</td>
                <td rowspan="1" colspan="1">0.092</td>
                <td rowspan="1" colspan="1">0.120</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">UHF—average</td>
                <td rowspan="1" colspan="1">0.103</td>
                <td rowspan="1" colspan="1">0.105</td>
                <td rowspan="1" colspan="1">0.108</td>
                <td rowspan="1" colspan="1">0.126</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">UHF—SPFN</td>
                <td rowspan="1" colspan="1">0.107</td>
                <td rowspan="1" colspan="1">0.108</td>
                <td rowspan="1" colspan="1">0.123</td>
                <td rowspan="1" colspan="1">0.128</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">UHF—SPFP</td>
                <td rowspan="1" colspan="1">0.099</td>
                <td rowspan="1" colspan="1">0.102</td>
                <td rowspan="1" colspan="1">0.093</td>
                <td rowspan="1" colspan="1">0.124</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec>
        <title>4.1.3 INDELible datasets</title>
        <p>Results on the INDELIBLE datasets, shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref>, show that the lowest average alignment error achieved by a standard method on the 0.001-HF condition was 0.102, achieved by MAGUS, with PASTA at 0.105; MAFFT-linsi was higher at 0.212, and all the other standard methods had errors at least 0.309. In contrast, all four two-stage methods had error rates between 0.072 and 0.083. The trends on the 0.005-HF condition were similar, with the lowest average alignment error of a standard method achieved by MAGUS at 0.353 (with the next lowest error at 0.479, achieved by MAFFT-linsi). In contrast, the four two-stage methods had average alignment error between 0.279 and 0.295. Thus, for the INDELIBLE model conditions, there was a clear gap between the two-stage methods and the standard methods.</p>
        <p>We compare the four two-stage methods with respect to query-only alignment error in <xref rid="vbad052-F4" ref-type="fig">Figure 4</xref>. MAFFT-addfrags has higher average alignment error than the other three methods; for example, it has error of 0.147 on the 0.001-HF condition compared to the second highest error of 0.121, attained by UPP, and error of 0.326 on the 0.005-HF condition compared to the second highest error of 0.321, attained by HMMerge. Overall, MAFFT-addfrags has higher average error on these conditions than the other three two-stage methods, but differences between the four two-stage methods are generally small.</p>
        <fig position="float" id="vbad052-F4">
          <label>Fig. 4.</label>
          <caption>
            <p>Query sequence alignment error of two-stage methods on INDELible simulated datasets with introduced fragmentation. The model conditions have 10 replicates; error bars show standard error</p>
          </caption>
          <graphic xlink:href="vbad052f4" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>4.2 Experiment 2: results on biological datasets</title>
      <p>A comparison of all methods, including the standard methods, is given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S8</xref>. Error rates are highest on 5S.3 and 5S.T, compared to the 23S datasets and 5S.E. However, based on this figure, it is clear that MUSCLE, T-COFFEE and Clustal-Omega have substantially higher average error than the other alignment methods. Average error for the remaining methods (the four two-stage methods, MAGUS, MAFFT-linsi and PASTA) are generally close, but with an advantage to the two-stage methods, as we now describe.</p>
      <p>On the 23S.A dataset, MAFFT-linsi and MAGUS have the lowest error (0.074), followed closely by the four two-stage methods at 0.076–0.077. On the 23S.C dataset, MAFFT-linsi has the lowest error (0.038), followed closely by the four two-stage methods at 0.039, and by MAGUS at 0.040. On the 5S.E dataset, MAFFT-linsi has the lowest error (0.020), followed closely by the four two-stage methods and MAGUS at 0.024–0.029. On the 5S.3 dataset, MAFFT-addfrags has the lowest error (0.096), followed closely by the other three two-stage methods (0.099–0.101); the lowest error for any standard method is 0.105, achieved by PASTA. Finally, on the 5S.T dataset, MAFFT-addfrags has the lowest error (0.097), followed closely by the other three two-stage methods (0.099–0.102); the lowest error for any standard method is 0.108, achieved by MAGUS. We also explored the impact of using MAFFT-linsi for the backbone alignment instead of MAGUS on these datasets; as seen in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S9</xref>, this reduced accuracy rather than improving it. Finally, it is worth noting that MAFFT-linsi was the most accurate on three datasets (23S.A, 23S.C and 5S.E), and although it did not fall in the top category for the two remaining datasets, 5S.T and 5S.3, it fell in the middle of the methods with respect to accuracy.</p>
      <p>With the exception of MAFFT-linsi (and perhaps MAGUS, which also generally came close to the four two-stage methods), the trends on these five CRW datasets show that the four two-stage methods reliably have lower average alignment error than the standard methods.</p>
      <p>A comparison of the four two-stage methods with respect to query-only alignment error (<xref rid="vbad052-T3" ref-type="table">Table 3</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>) show that no single two-stage method reliably was more accurate than the others, but we note that HMMerge specifically was less competitive on the 5S datasets than it was on the 23S datasets.</p>
      <table-wrap position="float" id="vbad052-T3">
        <label>Table 3.</label>
        <caption>
          <p>Query sequence alignment error of two-stage methods on CRW biological datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">HMMerge</th>
              <th rowspan="1" colspan="1">WITCH</th>
              <th rowspan="1" colspan="1">UPP</th>
              <th rowspan="1" colspan="1">MAFFT addfrags</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">23S.A—average</td>
              <td rowspan="1" colspan="1">0.084</td>
              <td rowspan="1" colspan="1">0.121</td>
              <td rowspan="1" colspan="1">0.107</td>
              <td rowspan="1" colspan="1">0.091</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">23S.A—SPFN</td>
              <td rowspan="1" colspan="1">0.103</td>
              <td rowspan="1" colspan="1">0.174</td>
              <td rowspan="1" colspan="1">0.148</td>
              <td rowspan="1" colspan="1">0.105</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">23S.A—SPFP</td>
              <td rowspan="1" colspan="1">0.066</td>
              <td rowspan="1" colspan="1">0.068</td>
              <td rowspan="1" colspan="1">0.065</td>
              <td rowspan="1" colspan="1">0.077</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">23S.C—average</td>
              <td rowspan="1" colspan="1">0.039</td>
              <td rowspan="1" colspan="1">0.037</td>
              <td rowspan="1" colspan="1">0.035</td>
              <td rowspan="1" colspan="1">0.040</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">23S.C—SPFN</td>
              <td rowspan="1" colspan="1">0.039</td>
              <td rowspan="1" colspan="1">0.036</td>
              <td rowspan="1" colspan="1">0.036</td>
              <td rowspan="1" colspan="1">0.039</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">23S.C—SPFP</td>
              <td rowspan="1" colspan="1">0.039</td>
              <td rowspan="1" colspan="1">0.038</td>
              <td rowspan="1" colspan="1">0.035</td>
              <td rowspan="1" colspan="1">0.041</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.3—average</td>
              <td rowspan="1" colspan="1">0.106</td>
              <td rowspan="1" colspan="1">0.087</td>
              <td rowspan="1" colspan="1">0.096</td>
              <td rowspan="1" colspan="1">0.050</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.3—SPFN</td>
              <td rowspan="1" colspan="1">0.129</td>
              <td rowspan="1" colspan="1">0.120</td>
              <td rowspan="1" colspan="1">0.138</td>
              <td rowspan="1" colspan="1">0.059</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.3—SPFP</td>
              <td rowspan="1" colspan="1">0.084</td>
              <td rowspan="1" colspan="1">0.053</td>
              <td rowspan="1" colspan="1">0.055</td>
              <td rowspan="1" colspan="1">0.042</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.E—average</td>
              <td rowspan="1" colspan="1">0.091</td>
              <td rowspan="1" colspan="1">0.060</td>
              <td rowspan="1" colspan="1">0.083</td>
              <td rowspan="1" colspan="1">0.068</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.E—SPFN</td>
              <td rowspan="1" colspan="1">0.103</td>
              <td rowspan="1" colspan="1">0.077</td>
              <td rowspan="1" colspan="1">0.120</td>
              <td rowspan="1" colspan="1">0.071</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.E—SPFP</td>
              <td rowspan="1" colspan="1">0.079</td>
              <td rowspan="1" colspan="1">0.042</td>
              <td rowspan="1" colspan="1">0.045</td>
              <td rowspan="1" colspan="1">0.064</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.T—average</td>
              <td rowspan="1" colspan="1">0.106</td>
              <td rowspan="1" colspan="1">0.076</td>
              <td rowspan="1" colspan="1">0.096</td>
              <td rowspan="1" colspan="1">0.053</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.T—SPFN</td>
              <td rowspan="1" colspan="1">0.122</td>
              <td rowspan="1" colspan="1">0.093</td>
              <td rowspan="1" colspan="1">0.129</td>
              <td rowspan="1" colspan="1">0.054</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5S.T—SPFP</td>
              <td rowspan="1" colspan="1">0.090</td>
              <td rowspan="1" colspan="1">0.058</td>
              <td rowspan="1" colspan="1">0.062</td>
              <td rowspan="1" colspan="1">0.051</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>4.3 Experiment 3: impact of changing the eHMM</title>
      <p>Inspired by results reported in <xref rid="vbad052-B15" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic> (2015)</xref> that showed that using hierarchical ensembles instead of disjoint ensembles improved accuracy, we explored changes to the eHMM we use in HMMerge to see if adding HMMs would improve accuracy. Recall that by default, HMMerge uses Disjoint(50). In this experiment, we also explore the use of Disjoint(50)+BB [i.e. adding the HMM for the full backbone alignment to Disjoint(50)] as well as using the entire UPP(50) ensemble. We explored this partially for some simulated datasets as well.</p>
      <p>On the three CRW 5S datasets (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>), Disjoint(50) and Disjoint(50)+BB had the same alignment error. The same was true for two simulated datasets (INDELible 0.001-HF and ROSE 1000S1-HF). On the other hand, using the UPP(50) eHMM improved accuracy compared to Disjoint(50). Specifically, average alignment error dropped from 0.106 to 0.102 for the 5S.3 dataset, from 0.91 to 0.89 for the 5S.E dataset, and from 0.106 to 0.096 for the 5S.T dataset.</p>
      <p>Thus, this experiment suggests the possibility that HMMerge accuracy could improve by using larger ensembles [i.e. adding HMMs to the Disjoint(50) ensemble], but also suggests that it is not sufficient to simply add the HMM for the backbone alignment. See <xref rid="sup1" ref-type="supplementary-material">Supplementary Materials</xref> Section S4 for additional results and discussion.</p>
    </sec>
  </sec>
  <sec>
    <title>5 Discussion</title>
    <p>This study introduced HMMerge, a new technique for aligning datasets that exhibit sequence length heterogeneity. Like its predecessors, WITCH and UPP, it operates by constructing a backbone alignment of full-length sequences and then adds the remaining sequences into the backbone alignment using a method based on hidden Markov models. This study showed that HMMerge, WITCH and UPP all tended to have close accuracy, and generally that HMMerge and WITCH were more accurate than UPP. We also observed that using MAFFT-addfrags to add the remaining sequences into the backbone alignment had comparable accuracy to HMMerge, WITCh and UPP under some conditions. Finally, we saw that standard methods (i.e. methods that do not operate in this two-stage manner) tend to have lower accuracy than two-stage methods.</p>
    <p>It is interesting however to consider the difference between trends observed on the five biological datasets and the simulated datasets. Specifically, for the simulated datasets, we saw generally that the four two-stage methods had reliably lower error than the standard methods, except when the mutation rate was low (as indicated by a low average <italic toggle="yes">p</italic>-distance). The biological CRW datasets have generally lower <italic toggle="yes">p</italic>-distances than the harder simulated model conditions, and on these biological datasets, we saw that MAFFT-linsi was the most accurate method on three of the datasets and that MAGUS also was close to the two-stage methods in accuracy. Thus, the likely explanation for this difference may be the mutation rate, as the conditions where the two-stage methods had clear dominance over the standard methods had high rates of evolution as well as substantial fragmentation. Thus, it may be that two-stage methods may only be needed when datasets exhibit both these factors: substantial sequence length heterogeneity and also large <italic toggle="yes">p</italic>-distances.</p>
    <p>It is also interesting to consider why sometimes, but not always, HMMerge is more accurate than WITCH. Based on the trends shown in the simulated datasets and the contrast between its performance on the 23S and 5S biological datasets, we conjecture that HMMerge may provide an advantage under conditions where there are many very short sequences. If this is the case, the choice between WITCH and HMMerge might be based on the type of sequence length heterogeneity in the dataset.</p>
    <p>This study suggests several directions for future research. Clearly, HMMerge is more computationally intensive to use than WITCH or UPP (<xref rid="sup1" ref-type="supplementary-material">Supplementary Materials Section S5</xref>); hence, improving its implementation is necessary. However, changes to the design may also yield improved accuracy, as the preliminary results we obtained in modifying HMMerge through changes to its eHMM [and especially through the use of the UPP(50) eHMM] suggest.</p>
    <p>From an algorithms design perspective, WITCH and HMMerge both benefit from the use of adjusted bit-scores, which is an innovation relative to UPP. They also both use the same ensemble of HMMs for the representation of the backbone alignment, but beyond this they differ. WITCH computes an extended alignment from each of the profile HMMs for a given query, and then uses a graph-based algorithm to combine these extended alignments into a single extended alignment. In contrast, given the query sequence, HMMerge produces a new HMM with a topology that has the potential to differ from that of the canonical profile HMM topology used for each HMM in the given eHMM, and then uses that new HMM to align the query sequence. This new profile HMM creation is the novel algorithmic aspect of HMMerge. As we demonstrated in this study, this machine learning model provides an advantage over WITCH in some cases. Future research should explore additional algorithm design strategies to determine how to best take advantage of this insight.</p>
  </sec>
  <sec>
    <title>6 Conclusion</title>
    <p>HMMerge is a multiple sequence alignment method that was designed to address the challenge of aligning datasets that exhibit high levels of sequence length heterogeneity. HMMerge operates in two stages, where the first stage extracts and aligns a subset of the sequences it considers to be full-length (thus producing a backbone alignment), and in the second stage it adds the remaining sequences into the backbone alignment. HMMerge builds on techniques in previous methods that use ensembles of profile HMMs to represent the backbone alignment, but does so by creating a new HMM with more edges than a standard profile HMM. As our study shows, this novel machine learning model enables HMMerge to improve on WITCH when adding very short sequences into the backbone alignment, and is otherwise competitive with WITCH (sometimes better, sometimes not as good).</p>
    <p>There are implications of this study for both biologists and algorithms developers. For the biologists, the implications are that when aligning datasets with fragmentary sequences, standard methods (such as MAFFT, T-COFFEE, MUSCLE, Clustal Omega, etc.) may not provide good accuracy, and instead alignment methods that are designed for use on such datasets should be considered. Here we would recommend the use of a two-stage method, though the conditions under which each such method might provide an advantage over the others are not yet understood.</p>
    <p>For the algorithms designer, this study shows the potential benefits to be gained from novel uses of ensembles of profile Hidden Markov Models to represent backbone alignments. Furthermore, although WITCH and HMMerge both provide improved accuracy compared to UPP, which was the first method in this category, it seems very likely that additional algorithmic exploration could lead to improved accuracy and potentially faster methods. We hope that this study will lead to new algorithmic advances, in order to best improve alignment accuracy under conditions with sequence length heterogeneity, since these are increasingly common in biological datasets.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbad052_Supplementary_Data</label>
      <media xlink:href="vbad052_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Author contributions</title>
    <p>M.P. and T.W. conceived of HMMerge, M.P. implemented the algorithm and conducted the experiments and M.P. and T.W. wrote and reviewed the manuscript.</p>
    <p>Minhyuk Park (Conceptualization [equal], Data curation [equal], Formal analysis [equal], Methodology [equal], Software [equal], Validation [equal], Visualization [equal], Writing—original draft [equal], Writing—review &amp; editing [equal], and Tandy Warnow (Conceptualization [equal], Funding acquisition [equal], Project administration [equal], Writing—original draft [equal], Writing—review &amp; editing [equal]).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Software and data availability</title>
    <p>HMMerge is freely available at <ext-link xlink:href="https://github.com/MinhyukPark/HMMerge" ext-link-type="uri">https://github.com/MinhyukPark/HMMerge</ext-link>. The INDELible datasets are available at the Illinois Data Bank (<xref rid="vbad052-B17" ref-type="bibr">Park and Warnow, 2023</xref>).</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by funds from the National Science Foundation (NSF: 2006069). It was also supported by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under the Secure Biosystems Design Initiative and by the Laboratory Directed Research and Development (LDRD) program of Sandia National Laboratories, which is a multimission laboratory managed and operated by National Technology and Engineering Solutions of Sandia, LLC, a wholly owned subsidiary of Honeywell International Inc, for the U.S. Department of Energy’s National Nuclear Security Administration under contract DE-NA0003525.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbad052-B1">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bode</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <part-title>The Blue Waters Super-System for Super-Science</part-title>. In: Vitter, J. (ed.) <source>Contemporary High Performance Computing</source>. <publisher-name>Chapman and Hall/CRC</publisher-name>, <publisher-loc>New York</publisher-loc>, pp. <fpage>339</fpage>–<lpage>366</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad052-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cannone</surname><given-names>J.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2002</year>) <article-title>The comparative RNA web (CRW) site: an online database of comparative sequence and structure information for ribosomal, intron, and other RNAs</article-title>. <source>BMC Bioinformatics</source>, <volume>3</volume>, <fpage>1</fpage>–<lpage>31</lpage>.<pub-id pub-id-type="pmid">11818024</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B3">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Durbin</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>1998</year>) <source>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids</source>. <publisher-name>Cambridge University Press</publisher-name>, <publisher-loc>Cambridge</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="vbad052-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eddy</surname><given-names>S.R.</given-names></string-name></person-group> (<year>2011</year>) <article-title>Accelerated profile HMM searches</article-title>. <source>PLoS Comput. Biol</source>., <volume>7</volume>, <fpage>e1002195</fpage>.<pub-id pub-id-type="pmid">22039361</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Edgar</surname><given-names>R.C.</given-names></string-name></person-group> (<year>2004</year>) <article-title>MUSCLE: multiple sequence alignment with high accuracy and high throughput</article-title>. <source>Nucleic Acids Res</source>., <volume>32</volume>, <fpage>1792</fpage>–<lpage>1797</lpage>.<pub-id pub-id-type="pmid">15034147</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fletcher</surname><given-names>W.</given-names></string-name>, <string-name><surname>Yang</surname><given-names>Z.</given-names></string-name></person-group> (<year>2009</year>) <article-title>INDELible: a flexible simulator of biological sequence evolution</article-title>. <source>Mol. Biol. Evol</source>., <volume>26</volume>, <fpage>1879</fpage>–<lpage>1888</lpage>.<pub-id pub-id-type="pmid">19423664</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garriga</surname><given-names>E.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Large multiple sequence alignments with a root-to-leaf regressive method</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>1466</fpage>–<lpage>1470</lpage>.<pub-id pub-id-type="pmid">31792410</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katoh</surname><given-names>K.</given-names></string-name>, <string-name><surname>Frith</surname><given-names>M.C.</given-names></string-name></person-group> (<year>2012</year>) <article-title>Adding unaligned sequences into an existing alignment using MAFFT and LAST</article-title>. <source>Bioinformatics</source>, <volume>28</volume>, <fpage>3144</fpage>–<lpage>3146</lpage>.<pub-id pub-id-type="pmid">23023983</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katoh</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2002</year>) <article-title>MAFFT: a novel method for rapid multiple sequence alignment based on fast Fourier transform</article-title>. <source>Nucleic Acids Res</source>., <volume>30</volume>, <fpage>3059</fpage>–<lpage>3066</lpage>.<pub-id pub-id-type="pmid">12136088</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Matsen</surname><given-names>F.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>pplacer: linear time maximum-likelihood and Bayesian phylogenetic placement of sequences onto a fixed reference tree</article-title>. <source>BMC Bioinformatics</source>, <volume>11</volume>, <fpage>1</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">20043860</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirarab</surname><given-names>S.</given-names></string-name>, <string-name><surname>Warnow</surname><given-names>T.</given-names></string-name></person-group> (<year>2011</year>) <article-title>FastSP: linear time calculation of alignment accuracy</article-title>. <source>Bioinformatics</source>, <volume>27</volume>, <fpage>3250</fpage>–<lpage>3258</lpage>.<pub-id pub-id-type="pmid">21984754</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirarab</surname><given-names>S.</given-names></string-name>, <string-name><surname>Warnow</surname><given-names>T.</given-names></string-name></person-group> (<year>2015</year>) <article-title>ASTRAL-II: coalescent-based species tree estimation with many hundreds of taxa and thousands of genes</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>i44</fpage>–<lpage>i52</lpage>.<pub-id pub-id-type="pmid">26072508</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mirarab</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>PASTA: Ultra-Large Multiple Sequence Alignment for Nucleotide and Amino-Acid Sequences</article-title>. <source>J. Comput. Biol</source>., <volume>22</volume>, <fpage>377</fpage>–<lpage>386</lpage>.<pub-id pub-id-type="pmid">25549288</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morrison</surname><given-names>D.A.</given-names></string-name></person-group> (<year>2006</year>) <article-title>Multiple sequence alignment for phylogenetic purposes</article-title>. <source>Aust. Syst. Bot</source>., <volume>19</volume>, <fpage>479</fpage>–<lpage>539</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad052-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname><given-names>N.-P.D.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Ultra-large alignments using phylogeny-aware profiles</article-title>. <source>Genome Biol</source>., <volume>16</volume>, <fpage>1</fpage>–<lpage>15</lpage>.<pub-id pub-id-type="pmid">25583448</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nute</surname><given-names>M.</given-names></string-name>, <string-name><surname>Warnow</surname><given-names>T.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Scaling statistical multiple sequence alignment to large datasets</article-title>. <source>BMC Genomics</source>, <volume>17</volume>, <fpage>135</fpage>–<lpage>144</lpage>.<pub-id pub-id-type="pmid">26911875</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Park</surname><given-names>M.</given-names></string-name>, <string-name><surname>Warnow</surname><given-names>T.</given-names></string-name></person-group> (<year>2023</year>) [Dataset] INDELible simulated datesets with sequence length heterogeneity. Illinois Data Bank. <pub-id pub-id-type="doi">10.13012/B2IDB-0900513_V1</pub-id>.</mixed-citation>
    </ref>
    <ref id="vbad052-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Price</surname><given-names>M.N.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>FastTree 2 – approximately maximum-likelihood trees for large alignments</article-title>. <source>PLoS ONE</source>, <volume>5</volume>, <fpage>e9490</fpage>.<pub-id pub-id-type="pmid">20224823</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>WITCH: improved multiple sequence alignment through weighted consensus HMM alignment</article-title>. <source>J. Comput. Biol</source>., <volume>29</volume>, <fpage>782</fpage>–<lpage>801</lpage>.<pub-id pub-id-type="pmid">35575747</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shendure</surname><given-names>J.</given-names></string-name>, <string-name><surname>Ji</surname><given-names>H.</given-names></string-name></person-group> (<year>2008</year>) <article-title>Next-generation DNA sequencing</article-title>. <source>Nat. Biotechnol</source>., <volume>26</volume>, <fpage>1135</fpage>–<lpage>1145</lpage>.<pub-id pub-id-type="pmid">18846087</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sievers</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2011</year>) <article-title>Fast, scalable generation of high-quality protein multiple sequence alignments using Clustal Omega</article-title>. <source>Mol. Syst. Biol</source>., <volume>7</volume>, <fpage>539</fpage>.<pub-id pub-id-type="pmid">21988835</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smirnov</surname><given-names>V.</given-names></string-name>, <string-name><surname>Warnow</surname><given-names>T.</given-names></string-name></person-group> (<year>2021a</year>) <article-title>MAGUS: multiple sequence alignment using graph clUStering</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>1666</fpage>–<lpage>1672</lpage>.<pub-id pub-id-type="pmid">33252662</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smirnov</surname><given-names>V.</given-names></string-name>, <string-name><surname>Warnow</surname><given-names>T.</given-names></string-name></person-group> (<year>2021b</year>) <article-title>Phylogeny estimation given sequence length heterogeneity</article-title>. <source>Syst. Biol</source>., <volume>70</volume>, <fpage>268</fpage>–<lpage>282</lpage>.<pub-id pub-id-type="pmid">32692823</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stamatakis</surname><given-names>A.</given-names></string-name></person-group> (<year>2014</year>) <article-title>RAxML version 8: a tool for phylogenetic analysis and post-analysis of large phylogenies</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>1312</fpage>–<lpage>1313</lpage>.<pub-id pub-id-type="pmid">24451623</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stoye</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>1998</year>) <article-title>Rose: generating sequence families</article-title>. <source>Bioinformatics</source>, <volume>14</volume>, <fpage>157</fpage>–<lpage>163</lpage>.<pub-id pub-id-type="pmid">9545448</pub-id></mixed-citation>
    </ref>
    <ref id="vbad052-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suchard</surname><given-names>M.A.</given-names></string-name>, <string-name><surname>Redelings</surname><given-names>B.D.</given-names></string-name></person-group> (<year>2006</year>) <article-title>Bali-Phy: simultaneous Bayesian inference of alignment and phylogeny</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>2047</fpage>–<lpage>2048</lpage>.<pub-id pub-id-type="pmid">16679334</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
