<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7005902</article-id>
    <article-id pub-id-type="publisher-id">14529</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-020-14529-0</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>An interactive ImageJ plugin for semi-automated image denoising in electron microscopy</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes" equal-contrib="yes">
        <name>
          <surname>Roels</surname>
          <given-names>Joris</given-names>
        </name>
        <address>
          <email>joris.roels@ugent.vib.be</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9226-0103</contrib-id>
        <name>
          <surname>Vernaillen</surname>
          <given-names>Frank</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kremer</surname>
          <given-names>Anna</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gonçalves</surname>
          <given-names>Amanda</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Aelterman</surname>
          <given-names>Jan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6246-5538</contrib-id>
        <name>
          <surname>Luong</surname>
          <given-names>Hiêp Q.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Goossens</surname>
          <given-names>Bart</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Philips</surname>
          <given-names>Wilfried</given-names>
        </name>
        <xref ref-type="aff" rid="Aff6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lippens</surname>
          <given-names>Saskia</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0415-1506</contrib-id>
        <name>
          <surname>Saeys</surname>
          <given-names>Yvan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000104788040</institution-id><institution-id institution-id-type="GRID">grid.11486.3a</institution-id><institution>VIB, Center for Inflammation Research, </institution></institution-wrap>Technologiepark 71, B-9052 Ghent, Belgium </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2069 7798</institution-id><institution-id institution-id-type="GRID">grid.5342.0</institution-id><institution>Ghent University, Department of Applied Mathematics, Computer Science and Statistics, </institution></institution-wrap>Krijgslaan 281-S9, B-9000 Ghent, Belgium </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000000104788040</institution-id><institution-id institution-id-type="GRID">grid.11486.3a</institution-id><institution>VIB, Bioinformatics Core, </institution></institution-wrap>Rijvisschestraat 126 3R, B-9052 Ghent, Belgium </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000000104788040</institution-id><institution-id institution-id-type="GRID">grid.11486.3a</institution-id><institution>VIB, Bioimaging Core, </institution></institution-wrap>Technologiepark 71, B-9052 Ghent, Belgium </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2069 7798</institution-id><institution-id institution-id-type="GRID">grid.5342.0</institution-id><institution>Ghent University, Department of Biomedical Molecular Biology, </institution></institution-wrap>Technologiepark 71, B-9052 Ghent, Belgium </aff>
      <aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2069 7798</institution-id><institution-id institution-id-type="GRID">grid.5342.0</institution-id><institution>Ghent University/IMEC, Department of Telecommunications and Information Processing, </institution></institution-wrap>St-Pietersnieuwstraat 41, B-9000 Ghent, Belgium </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>7</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>7</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>11</volume>
    <elocation-id>771</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>1</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The recent advent of 3D in electron microscopy (EM) has allowed for detection of nanometer resolution structures. This has caused an explosion in dataset size, necessitating the development of automated workflows. Moreover, large 3D EM datasets typically require hours to days to be acquired and accelerated imaging typically results in noisy data. Advanced denoising techniques can alleviate this, but tend to be less accessible to the community due to low-level programming environments, complex parameter tuning or a computational bottleneck. We present DenoisEM: an interactive and GPU accelerated denoising plugin for ImageJ that ensures fast parameter tuning and processing through parallel computing. Experimental results show that DenoisEM is one order of magnitude faster than related software and can accelerate data acquisition by a factor of 4 without significantly affecting data quality. Lastly, we show that image denoising benefits visualization and (semi-)automated segmentation and analysis of ultrastructure in various volume EM datasets.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Large 3D electron microscopy data sets frequently contain noisy data due to accelerated imaging, and denoising techniques require specialised skill sets. Here the authors introduce DenoisEM, an ImageJ plugin that democratises denoising EM data sets, enabling fast parameter tuning and processing through parallel computing.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Image processing</kwd>
      <kwd>Software</kwd>
      <kwd>Electron microscopy</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/100012331</institution-id>
            <institution>Agentschap Innoveren en Ondernemen (Flanders Innovation &amp; Entrepreneurship)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>IWT.141703</award-id>
        <principal-award-recipient>
          <name>
            <surname>Roels</surname>
            <given-names>Joris</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100007229</institution-id>
            <institution>Bijzonder Onderzoeksfonds (Special Research Fund)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>BOF15/PDO/003</award-id>
        <principal-award-recipient>
          <name>
            <surname>Roels</surname>
            <given-names>Joris</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">The field of three-dimensional electron microscopy (3D EM) covers several technologies that unveil a sample at nanometer (nm) resolution. The classical setup typically involves serial sectioning and high-resolution imaging by transmission EM (TEM). Lots of progress has been made in this field by automating acquisition, which eventually enabled successful imaging of the complete <italic>Drosophila melanogaster</italic> brain at synaptic resolution<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. The development of serial block face (SBF) scanning EM (SEM) techniques has made 3D EM more easily available for large-scale imaging of biological samples<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. SBF-SEM repetitively acquires a 2D SEM image from the smoothened sample surface (or block face) and then removes the top of the sample with a diamond knife ultramicrotome<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup>, revealing the next sample surface to be imaged. Eventually, this results in a stack of 2D images that can be compiled to a high-resolution 3D volume image. A similar slice-and-view approach is used in focused ion beam (FIB) SEM, where the block face is removed by FIB milling. While both SBF-SEM and FIB-SEM have the potential to generate images at 3- to 5-nm lateral resolution, the FIB milling is more precise than the mechanical SBF-SEM slicing, resulting in a maximal axial resolution of 5 and 20 nm, respectively<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR6">6</xref></sup>.</p>
    <p id="Par4">Over the past years, there has been a substantial increase in the use of these techniques in life science research<sup><xref ref-type="bibr" rid="CR7">7</xref>–<xref ref-type="bibr" rid="CR12">12</xref></sup>. The advantage of generating high-resolution 3D information, and also a comprehensive view of a complete cell or tissue, has invited the scientific community to apply these techniques for many different research questions. Recent ambitious research projects, such as imaging 10<sup>7</sup> μm<sup>3</sup> sections of Drosophila brain and mammalian neuronal tissue<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup> at 8 nm<sup>3</sup> isotropic resolution for connectomics research have taken volume EM imaging to a next level. Even considering the impressive tenfold speedup obtained by Xu et al.<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, it still requires 6 months and six FIB-SEM machines to section an entire Drosophila ventral nerve cord of ~2.6 × 10<sup>7</sup> μm<sup>3</sup> voxels. Note that the classical image acquisition setup with a single FIB-SEM machine, used by most other research facilities, would require more than 5 years. Consequently, this approach is limited in terms of scalability. A potential solution arises in the dwell-time acquisition parameter, i.e., the time that is used to “illuminate” one pixel. Shorter dwell times have two advantages: shorter total acquisition time and less risk to overexposure artefacts such as charging. However, the noise level increases as the dwell time decreases, which can introduce issues with regard to subsequent visualization, segmentation, and analysis of ultrastructure.</p>
    <p id="Par5">For the last few years, there has been great progress in computer vision research, particularly in image denoising, which aims to restore the true image signal from noisy data. State-of-the-art denoising methods are based on multiresolution shrinkage<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR15">15</xref></sup>, nonlocal pixel averaging<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>, Bayesian estimation<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>, or convolutional neural networks<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. Many of these methods have shown remarkable performance for 3D EM applications<sup><xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR25">25</xref></sup>. Even though most of these methods are available to the community, they are often impractical due to low-level programming environments, parameter sensitivity, and high computational demands. We believe that an interactive approach is required as the restored image data can only be validated by experts. Nevertheless, the existing interactive denoising frameworks<sup><xref ref-type="bibr" rid="CR26">26</xref>–<xref ref-type="bibr" rid="CR28">28</xref></sup> tend to rely on parameters that are difficult to interpret and/or are computationally too intensive for efficient tuning and scaling toward large-scale 3D data sets, such as the teravoxel size data sets generated by Xu et al.<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> Furthermore, the current state-of-the-art in image restoration is evolving fast, prompting the need for a framework that is easily extendible with new algorithms.</p>
    <p id="Par6">In this work, we propose an interactive and user-friendly framework called DenoisEM equipped with state-of-the-art image restoration algorithms, combined with intuitive parameter interpretation available through ImageJ<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. The computational backend is accelerated via GPU-based massive parallel computing and a high-level programming language called Quasar<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. We show that by using DenoisEM data acquisition times can be reduced by a factor of 4 without significantly affecting image quality. We also show that visualization and automated segmentation and analysis can be improved by using the denoising algorithms that are implemented in DenoisEM. Our plugin is publicly available at <ext-link ext-link-type="uri" xlink:href="http://bioimagingcore.be/DenoisEM">http://bioimagingcore.be/DenoisEM</ext-link>.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>Interactive semi-automated image restoration with DenoisEM</title>
      <p id="Par7">Many solutions have been proposed for restoration of EM images<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. However, practical solutions that allow for user feedback to apply state-of-the-art denoising on large 3D EM data sets generated by e.g., SEM or serial section TEM are not readily available. Optimal finetuning of parameters in denoising is crucial, and this requires expert intervention. Therefore, we wanted to offer a tool that is based on a human-in-the-loop approach. To tackle this challenge, we developed DenoisEM, a GPU accelerated denoising plugin with an interactive workflow that allows for efficient interaction and feedback by the expert. DenoisEM is a plugin for ImageJ<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>, an open-source program that is extensively used in the microscopy community. The plugin allows for quick testing, comparison, and application of different denoising solutions, and can be used for any modality that generates 3D image data. The plugin workflow (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>) consists of six steps: data loading, initialization, region-of-interest (ROI) selection, noise estimation, interactive parameter optimization, and final batch processing. Each step is automated as much as possible, and user interaction is only required in the selection of the ROI and parameter settings. DenoisEM is highly optimized and offers parameter tuning at low latency due to a GPU accelerated back-end engine called Quasar.<fig id="Fig1"><label>Fig. 1</label><caption><title>Graphical workflow of our proposed framework that includes a human in the loop.</title><p>An image is loaded and the computation backend is prepared. Next, the user selects a ROI that is representative for the complete data set. The noise level is automatically estimated to derive near optimal parameter initialization (see “Parameter estimation” section in Supplementary Figs. <xref rid="MOESM1" ref-type="media">16,</xref>
<xref rid="MOESM1" ref-type="media">17</xref>). Next, the biological expert can optimize the parameter settings at a low latency visualization of the results according to their preferences (typically w.r.t. visualization and/or subsequent segmentation of specific objects). Once the optimal parameters for a specific algorithm are found, the complete data set is ready to be processed. The computationally intensive parts of the workflow are GPU accelerated and indicated with the Quasar logo<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>.</p></caption><graphic xlink:href="41467_2020_14529_Fig1_HTML" id="d29e521"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Intuitive and interactive user interface</title>
      <p id="Par8">DenoisEM guides the user through the denoising process via a simple interactive user interface (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>) in a step-by-step procedure:<list list-type="bullet"><list-item><p id="Par9">The user starts by opening a 2D or 3D image in ImageJ. During startup of the plugin, this image is assigned as the reference image for restoration and all computational resources (CPU and, if available, GPU) are prepared (Fig. <xref rid="Fig2" ref-type="fig">2</xref>a).</p></list-item><list-item><p id="Par10">Next, the user can select a particular (2D) region-of-interest (ROI) in the reference image that is representative for the data set and for the analysis that follows restoration (e.g., visualization or segmentation of specific structures). This can be intuitively performed using the available selection tools in ImageJ. At this point, the noise level is automatically estimated on the ROI, so that initial parameter settings of the available algorithms are at a favorable starting point for further finetuning in the next step. For more details regarding the noise and parameter estimation, we refer to the respective “Methods” sections and Supplementary Figs. <xref rid="MOESM1" ref-type="media">16</xref>, <xref rid="MOESM1" ref-type="media">17</xref>.</p></list-item><list-item><p id="Par11">The next step involves algorithm selection and interactive finetuning of the parameter settings. For high-quality image restoration this needs to be done carefully for each data set, because EM data can be highly variable due to different factors, like sample preparation procedures, acquisition circumstances, cell type, etc. Moreover, each denoising algorithm has its advantages and disadvantages and depending on the data and parameter settings the result can vary significantly (see Supplementary Figs. <xref rid="MOESM1" ref-type="media">2</xref>–<xref rid="MOESM1" ref-type="media">10</xref>). For example, Gaussian filters are very effective in noise removal at the cost of edge blurring (for large values of <italic>σ</italic>), while the nonlocal means filter is ideal for the data with many repetitive patterns, but computationally intensive (for large window sizes). Note that denoising inherently always boils down to a trade-off between noise reduction and sharpness. For use cases where sharpness is of high importance, we offer an optional panel that estimates the sharpness of the image<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>.</p><p id="Par012">A strong asset of DenoisEM is that different algorithms (listed and briefly discussed in “Methods”), including recently developed ones, can be found in one single tool and are practical to use due to GPU acceleration. Switching between algorithms is done by checking the corresponding box and different parameters can be set by sliders. Typically, the influence of different parameter settings is demonstrated at low latency, which facilitates the finetuning process. When visualization would lag, it is indicated by a red frame around the denoised ROI. Tooltips indicate the influence of the parameter on the result (e.g., noise reduction or sharpening). When the user proceeds to a different algorithm or to the next step, the previous parameters are cached, making it feasible to switch back if necessary.</p></list-item><list-item><p id="Par12">In the final step, the user can apply the desired denoising algorithm and its corresponding parameters on the complete image. A new image is generated and the user can then save the denoised image using ImageJ. We recommend to save the image in TIFF format in order to store the metadata that also contain the information on the denoising algorithm and parameters. These parameter values can then be applied later on to new data sets.</p></list-item></list><fig id="Fig2"><label>Fig. 2</label><caption><title>An overview of the user interface (UI) of the DenoisEM plugin for ImageJ.</title><p>It is structured as a wizard that guides the user through the denoising process in a sequence of steps. <bold>a</bold> In ImageJ, the user loads an image or image stack for denoising and starts the DenoisEM plugin. The UI wizard appears, and the computational backend for parallel processing on the CPU/GPU (Quasar) is initialized. <bold>b</bold> In the next step, the user chooses any of the open images for denoising and selects a ROI on which denoising will be previewed. <bold>c</bold> Next, the main panel in the plugin appears. At the top it shows side-by-side the noisy original as well as the denoised version of the selected ROI. In the bottom left corner, the user can select one of eight denoising algorithms. The bottom right has controls for specifying the algorithm parameters. Typically, if the algorithm or its parameters are changed, the denoised ROI at the top is updated virtually instantaneously. This allows the user to easily assess the effect of algorithms and parameter settings. <bold>d</bold> After optimal settings are chosen, the user is shown a short summary and (for image stacks) can select the image slices that need to be denoised. During denoising, the user is shown progress feedback. <bold>e</bold> When denoising is finished, a new image or image stack is created and displayed. The original image (stack) is left untouched.</p></caption><graphic xlink:href="41467_2020_14529_Fig2_HTML" id="d29e592"/></fig></p>
      <p id="Par13">We provide eight different denoising algorithms in DenoisEM: Gaussian filtering, wavelet thresholding<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR33">33</xref>–<xref ref-type="bibr" rid="CR37">37</xref></sup>, anisotropic diffusion<sup><xref ref-type="bibr" rid="CR38">38</xref>–<xref ref-type="bibr" rid="CR40">40</xref></sup>, bilateral filtering<sup><xref ref-type="bibr" rid="CR41">41</xref>–<xref ref-type="bibr" rid="CR43">43</xref></sup>, Tikhonov denoising/deconvolution<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>, total variation denoising<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>, Bayesian least-squares Gaussian scale mixtures<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, and nonlocal means denoising/deconvolution<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR25">25</xref>,<xref ref-type="bibr" rid="CR46">46</xref></sup>. For more details about these algorithms, we refer to the Methods section. Supplementary Figs. <xref rid="MOESM1" ref-type="media">2</xref>–<xref rid="MOESM1" ref-type="media">10</xref> show the effect of applying each of these denoising algorithms under several different parameters on the same noisy image patch. The plugin user manual, available through Supplementary Note <xref rid="MOESM1" ref-type="media">3</xref>, describes the different algorithms and the associated parameters from a user perspective.</p>
      <p id="Par14">Because the DenoisEM plugin allows to select any image that is open in the program, it allows for alternating with other applications in ImageJ. After each step in the workflow, it is possible to go back to previous steps and at no point the original image is overwritten.</p>
    </sec>
    <sec id="Sec5">
      <title>Improved visualization of 3D EM ultrastructure</title>
      <p id="Par15">We used DenoisEM on SBF-SEM images of an Arabidopsis thaliana root tip. The en bloc stained sample was prepared as described<sup><xref ref-type="bibr" rid="CR47">47</xref>,<xref ref-type="bibr" rid="CR48">48</xref></sup>, and a SBF-SEM data set was recorded with a Zeiss Merlin with 3View. The original image contained a significant amount of noise and we used the DenoisEM plugin to test different denoising solutions, under visual assessment by a biology expert. Denoising was done by applying Tikhonov deconvolution (<italic>λ</italic> = 1.5, <italic>σ</italic> = 0.31, and <italic>N</italic> = 86 iterations), and Fig. <xref rid="Fig3" ref-type="fig">3</xref> shows the result of the denoising on four different ROIs from the data sets, and for each ROI both an XY and a YZ orthogonal view is shown. In this particular case, mild denoising was applied to avoid the loss of structural details in the image. Nevertheless, there was an effect on image quality and improved recognition of certain subcellular structures, e.g., the nuclear membrane (Fig. <xref rid="Fig3" ref-type="fig">3b,</xref> ROI 1) or endoplasmic reticulum (Fig. <xref rid="Fig3" ref-type="fig">3</xref>b, ROI 3). Note that the image quality has also improved in the axial direction, even though the plugin performs lateral slice-by-slice denoising. We found that the noise level was decreased by two orders of magnitude (Fig. <xref rid="Fig3" ref-type="fig">3</xref>c) using a median absolute deviation noise level estimator.<fig id="Fig3"><label>Fig. 3</label><caption><title>An SBF-SEM section of an Arabidopsis thaliana root tip and four ROIs that show the denoising performance of DenoisEM.</title><p><bold>a</bold> The original image and four annotated ROIs and <bold>b</bold> a qualitative comparison of the original and denoised cross sections. For each ROI we show an XY and YZ section to illustrate that the image quality also improves along the <italic>Z</italic> direction, even though DenoisEM restores each XY slice independently. <bold>c</bold> For each ROI, we provide an estimation of the noise standard deviation <italic>σ</italic><sub><italic>n</italic></sub> ref. <sup><xref ref-type="bibr" rid="CR51">51</xref></sup> in the raw and denoised patch to illustrate the image quality quantitatively. Note that the noise level decreases by almost two orders of magnitude.</p></caption><graphic xlink:href="41467_2020_14529_Fig3_HTML" id="d29e722"/></fig></p>
      <p id="Par16">In a next example, we used SBF-SEM images of mouse heart tissue, prepared and imaged as described by Vanslembrouck et al.<sup><xref ref-type="bibr" rid="CR49">49</xref></sup> Figure <xref rid="Fig4" ref-type="fig">4</xref>a shows an unprocessed 2D image of heart smooth muscle cells. The sarcomeres can be recognized with the A-bands as darker zones and the I-bands as brighter zones. We applied the anisotropic diffusion algorithm (step size <italic>η</italic> =  0.07, <italic>N</italic> = 6 iterations and a diffusion factor <italic>κ</italic> = 0.18) on this data using DenoisEM. The effect of denoising is shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>b, while Fig. <xref rid="Fig4" ref-type="fig">4</xref>e, f shows the corresponding intensity histogram before and after denoising. Denoising is beneficial for the interpretation of the sarcomere organization, since the A- and I-bands can be better distinguished after noise removal. This is illustrated in Fig. <xref rid="Fig4" ref-type="fig">4</xref>c, d, where intensity thresholding is used to generate a magenta and green mask for the A- and I-bands, respectively.<fig id="Fig4"><label>Fig. 4</label><caption><title>Influence of denoising on thresholding segmentation of A/I-bands in mouse heart tissue SBF-SEM data.</title><p><bold>a</bold> One image of an SBF-SEM datastack is shown. The inset shows a zoom in the region indicated by the box. <bold>b</bold> The same image is shown after applying denoising. For visualization, thresholding was applied for two ranges of intensity values and a magenta mask was used to indicate A-bands, a green mask to indicate I-bands. <bold>c</bold>, <bold>d</bold> show the masks for the raw and denoised data, respectively. <bold>e</bold>, <bold>f</bold> show the intensity histograms that correspond to images (<bold>a</bold>) and (<bold>b</bold>), with indication in magenta and green of the threshold values that were used to generate images (<bold>c</bold>) and (<bold>d</bold>).</p></caption><graphic xlink:href="41467_2020_14529_Fig4_HTML" id="d29e791"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>Increased throughput of 3D EM imaging</title>
      <p id="Par17">Noise levels inversely correlate with the acquisition dwell time, meaning that long dwell times will always give a better result with respect to noise levels in an image. However, for SBF-SEM, long dwell times have the overall downside that the generation of a single data set can result in multiple imaging days. In addition, this also leads to electron charging artifacts and difficult slicing of the specimen. Ideally, shorter dwell times should be used, without the trade-off of too much noise in the image. Therefore, we acquired an image at 1 μs dwell time and used DenoisEM to generate a denoised 1-μs image and compared this to images acquired at longer dwell times of 2 μs and 4 μs (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). The general image quality of the fast denoised image is improved, and for recognition of structures this can correspond to the image that was acquired at 4 μs. This means that the use of fast denoised images, instead of slower imaging, has an impact on the general acquisition time. If data are generated at 10-nm pixels, with 100 nm slicing of a block of 100 × 100 × 500 μm<sup>3</sup>, this means that 500x images are acquired and 499 slicings are done. Each slicing event takes 18 s, and the acquisition of one image takes 6’40” at a dwell time of 4 μs, leading to a general acquisition and slicing time of 58 h. If DenoisEM is applied to improve image quality, and 1-μs dwell time can be used, one image can be acquired in 1’40” and the whole data set can be acquired in 16 h. Note that the additional processing in the latter case is no bottleneck due to GPU acceleration. We employed Tikhonov deconvolution, which required only slightly more than 5 min on a basic laptop workstation with an NVIDIA Quadro P2000 GPU. This means that our plugin is able to accelerate the throughput of EM imaging by a factor of 3.5 without sacrificing image quality.<fig id="Fig5"><label>Fig. 5</label><caption><title>A comparison of short dwell times (+ denoising) and long dwell times.</title><p>An image acquired at a short dwell time, (<bold>a</bold>) before and (<bold>b</bold>) after denoising, and images acquired at (<bold>c</bold>) two and (<bold>d</bold>) four times longer dwell times. Notice how the noise level decreases and visualization of ultrastructure improves as the dwell time increases. By including denoising in the pipeline, we can benefit from both high-quality visualization and short dwell times.</p></caption><graphic xlink:href="41467_2020_14529_Fig5_HTML" id="d29e825"/></fig></p>
      <p id="Par18">Note that an alternative to increase the acquisition throughput is to employ larger pixel sizes. However, this results in a significant loss of resolution. DenoisEM is provided with state-of-the-art denoising and deconvolution algorithms that reduce noise without significantly affecting image sharpness. To show this, we have acquired the same image as in Fig. <xref rid="Fig5" ref-type="fig">5</xref>d with a pixel size of 20 nm (i.e., a fourfold imaging acceleration factor, similar to Fig. <xref rid="Fig5" ref-type="fig">5</xref>b). To analyze the resolution/sharpness of the image, we inspect the Fourier spectrum (see Supplementary Fig. <xref rid="MOESM1" ref-type="media">11</xref>). The corresponding spectrum shows significantly less high-frequency components, in comparison with our proposed approach that includes DenoisEM. This becomes even more clear after removing the low-frequency components of the spectrum and applying the inverse transform to the image domain. We note that the resulting edge map contains significantly more structural detail in the proposed method, whereas the image sampled at 20-nm pixel size is less sharp and contains more noise.</p>
    </sec>
    <sec id="Sec7">
      <title>Improved segmentation quality and faster image analysis</title>
      <p id="Par19">Mouse heart tissue was prepared as in Vanslembrouck et al.<sup><xref ref-type="bibr" rid="CR49">49</xref></sup> and imaged using FIB-SEM. In this particular data set, the lateral view shows a transverse filament section (Fig. <xref rid="Fig6" ref-type="fig">6</xref>a). The noise in the image is removed with DenoisEM by applying the nonlocal means algorithm with damping parameter <italic>h</italic> = 0.23, half window size <italic>B</italic> = 6 and half search window size <italic>W</italic> = 9 (Fig. <xref rid="Fig6" ref-type="fig">6</xref>d). For both the raw and denoised data, a rendering mask was created by intensity-based thresholding (Fig. <xref rid="Fig6" ref-type="fig">6</xref>b, e) with the ImageJ 3D Viewer (Fig. <xref rid="Fig6" ref-type="fig">6</xref>c, f). Denoising was crucial for the 3D visualization of the filaments as separate objects. For counting these, we chose the corresponding region in the raw and denoised image (Fig. <xref rid="Fig6" ref-type="fig">6</xref>g, i). Two experts counted the number of filaments in these ROIs three times, using the ImageJ Cell Counter plugin. Cell Counter allows a user to identify an object with a mouse-click and indicates each click on the image with a yellow pixel. When the experts performed the counting, it was more straightforward to recognize individual filaments in the denoised image, and the results in Fig. <xref rid="Fig6" ref-type="fig">6</xref>k showed a lower count in the raw image, as compared with the denoised image. As an alternative for counting objects, the ImageJ Analyze Particles was used on a thresholded image. With this automatic segmentation tool, the number of counted objects in the denoised image corresponds to the manual counting, especially when applying a watershed filter prior to Analyze Particles (Fig. <xref rid="Fig6" ref-type="fig">6</xref>j, k). The same analysis on the raw image, resulted in values that are off by a factor of more than 1.7 compared with manual counting (Fig. <xref rid="Fig6" ref-type="fig">6</xref>h, k). This demonstrates that the raw images were not suited for automatic object counting, and that the introduction of expert-guided denoising can prepare the images for an automatic analysis workflow. Also timewise, there was a clear benefit, since the analysis by thresholding, watershed, and the Analyze Particles tool required 20 s per image on average, while manual counting required at least 2.5 min.<fig id="Fig6"><label>Fig. 6</label><caption><title>Denoising influence on sarcomere segmentation and counting in mouse heart tissue FIB-SEM data.</title><p>A 3D ROI from a FIB-SEM data set, acquired at isotropic 5-nm resolution, from mouse heart tissue was used for denoising. <bold>a</bold> An XY view of 330 × 300 pixels of the raw image. <bold>b</bold> The image was used for creating a mask (in green) by intensity thresholding. <bold>c</bold> This mask was used for 3D rendering with the ImageJ 3D Viewer. <bold>d</bold> The data were denoised with DenoisEM, using the NLM algorithm, and <bold>e</bold>, <bold>f</bold> segmented by thresholding. <bold>g</bold> The ROI indicated in panel (<bold>a</bold>) was used for manual counting of sarcomeres with the ImageJ Cell Counter Plugin. <bold>h</bold> Each item counted is indicated with a magenta dot. Panels (<bold>i</bold>) and (<bold>j</bold>) show the counting results on the denoised data. <bold>k</bold> A graph showing the number of sarcomeres counted, either manual by three different individuals or by the ImageJ Analyse Particles tool on a thresholded image, with or without watershed.</p></caption><graphic xlink:href="41467_2020_14529_Fig6_HTML" id="d29e929"/></fig></p>
      <p id="Par20">To illustrate how our plugin can improve automated segmentation quality, we have performed experiments with the CREMI challenge data set (<ext-link ext-link-type="uri" xlink:href="https://cremi.org/">https://cremi.org/</ext-link>) where volumes of serial section TEM of the adult fly brain are considered for neuron reconstruction. We extracted the outer neuron membranes by computing the edges between the different neurons (using a Sobel filter) and dilating these edges by five pixels, the mean membrane width in the data set. We use the pixel classifier from the ilastik framework<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> to predict neuronal membranes. The prediction uses intensity, edge, and texture features and a random forest pixel classifier combined with a small number of annotated pixels: ~4000 and 7000 membrane and background pixels, respectively (see top-left image in Fig. <xref rid="Fig7" ref-type="fig">7</xref>). To evaluate the influence of noise and denoising, we simulate noise of variable levels (i.e., <italic>σ</italic><sub><italic>n</italic></sub> = 0.01, 0.05, 0.1, 0.2) on the original (approximately noise-free) data and denoised these noisy data sets with the nonlocal means algorithm with a half window size <italic>B</italic> = 4, half search window size <italic>W</italic> = 5 and damping parameter <italic>h</italic> = 0.05, 0.15, 0.4, 0.7, respectively. Expert intervention was necessary to finetune the damping parameter such that neuronal membranes were preserved for each noise level. Segmentation is performed on both the noisy and denoised data sets using the same annotated pixels. Figure <xref rid="Fig7" ref-type="fig">7</xref> shows the generated probability maps and segmentation masks, and Fig. <xref rid="Fig8" ref-type="fig">8</xref> illustrates the quantitative results in relation to the noise level by means of the Dice coefficient (<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=2\frac{\left|P\cap S\right|}{\left|P\right|+\left|S\right|}$$\end{document}</tex-math><mml:math id="M2"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mfenced close="∣" open="∣" separators=""><mml:mrow><mml:mi>P</mml:mi><mml:mo>∩</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced close="∣" open="∣" separators=""><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close="∣" open="∣" separators=""><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>P</italic> and <italic>S</italic> are the set of predicted and true foreground/background pixels, respectively). The results show that even a more advanced segmentation algorithm such as random forests pixel classification is not robust enough, as segmentation quality increases whenever denoising is performed as a pre-processing step. This is especially notable for higher noise levels, which is often the case when a short acquisition time was used (e.g., due to time or sample restrictions). Given that the pixel dwell time is inversely related to the noise level <italic>σ</italic> in the image, it can be inferred from Fig. <xref rid="Fig8" ref-type="fig">8</xref> that equal segmentation performance is achievable by accelerating the image acquisition by a factor of 20 (<italic>σ</italic> = 0.01 vs. <italic>σ</italic> = 0.2) and including denoising. The segmentation results even improved for a tenfold acquisition acceleration (<italic>σ</italic> = 0.01 vs. <italic>σ</italic> =  0.1) when denoising is included. Practically speaking, this implies that acquisition times can be reduced from hours to minutes without sacrificing segmentation quality. Note that the denoising itself does not require a significant amount of overhead: e.g., the processing time for nonlocal means on a single CREMI data set volume (1250 × 1250 × 125 pixels) requires less than a minute with a modern GPU.<fig id="Fig7"><label>Fig. 7</label><caption><title>Influence of denoising on pixel-classification-based membrane segmentation in TEM data.</title><p>The first column shows the input, the top image additionally shows a fraction of the labels that were used for training. The second column shows the probability output map of the random forest pixel classifier from ilastik. The third column shows the segmentation result by thresholding the probability maps, and the fourth column the ground truth segmentation (the Dice coefficient is shown in the upper left corner). Noise artifacts are clearly visible in the segmentation and can be avoided by denoising as a pre-processing step. Notice that denoising can even improve the segmentation result.</p></caption><graphic xlink:href="41467_2020_14529_Fig7_HTML" id="d29e1037"/></fig><fig id="Fig8"><label>Fig. 8</label><caption><title>Segmentation quality of the automated membrane segmentation in the CREMI data set using ilastik.</title><p>As the noise level in the data increases, the segmentation quality is significantly influenced whereas denoising pre-processing stabilizes (and even improves) the segmentation quality.</p></caption><graphic xlink:href="41467_2020_14529_Fig8_HTML" id="d29e1048"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Performance at low latency and easily extensible</title>
      <p id="Par21">In order to allow for a user in the loop, it is necessary to compute restoration results at a low latency, so that the user can test different parameter settings as fast as possible. The computational backend of DenoisEM relies on a freely available programming framework called Quasar<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, which reduces the complexity of heterogeneous programming on CPUs and GPUs to programming in a high-level language like MATLAB/Python without significant runtime influence. Quasar is therefore ideal for development of novel image processing algorithms, as prototyping is accelerated by parallel computing on the GPU and/or CPU.</p>
      <p id="Par22">As the plugin’s host application (ImageJ) is implemented in the Java programming language, we developed a bridge between Java and Quasar to connect front and backend. This bridge uses the Java Native Interface (JNI) to wrap Quasar objects and functions in Java equivalents, providing an abstraction layer that separates the complexity of the Quasar C++ API from the DenoisEM plugin. The bridge is DenoisEM-agnostic and by itself a useful general building block for other applications wishing to leverage Quasar from within a Java environment. The DenoisEM plugin and the source code for the plugin, the Java-Quasar bridge and the denoising algorithms are freely available for noncommercial use.</p>
      <p id="Par23">We have compared the Quasar algorithm implementations available in DenoisEM to existing open-source implementations, which are typically not GPU accelerated. Figure <xref rid="Fig9" ref-type="fig">9</xref> shows a comparison for bilateral filtering<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>, anisotropic diffusion<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>, BLS-GSM<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, and nonlocal means denoising<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> (results of the remaining methods can be found in the Supplementary Fig. <xref rid="MOESM1" ref-type="media">13</xref>). The results show that the Quasar implementations are one to two orders of magnitude faster than the classical CPU-based implementations. Considering a latency threshold of 100 ms (i.e., 10 FPS), this allows real-time processing of megapixel images for the bilateral filter, anisotropic diffusion and the more recently proposed nonlocal means algorithm. State-of-the-art denoising algorithms such as BLS-GSM used to take seconds to minutes for only a few megapixel sized images, whereas our Quasar implementation requires up to 1 s for 16 megapixel images. This allows for much faster parameter tuning by the expert. Note that this acceleration can also be obtained by incorporating e.g., CUDA libraries in the baseline implementations; however, this approach would require more development time and we believe that the high-level nature of Quasar is more scalable to this end. The high-level Quasar API has been demonstrated to support rapid software development without compromising performance in direct comparison with other popular GPU development platforms such as CUDA (see the work of Goossens et al.<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>). In addition, we can observe that the obtained GPU speedups increase for larger inputs, which is desirable for large-scale computing. This is due to the fact that more pixels can be processed in parallel, and bounded by the amount of cores in the available GPU hardware.<fig id="Fig9"><label>Fig. 9</label><caption><title>Computational performance comparison of Quasar-based and alternative available implementations.</title><p>Absolute computational performance (in milliseconds) of (<bold>a</bold>) bilateral filtering<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>, (<bold>b</bold>) anisotropic diffusion<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>, (<bold>c</bold>) BLS-GSM<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, and (<bold>d</bold>) nonlocal means denoising<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> for different input sizes. A comparison is made between our proposed GPU-based Quasar framework and alternative implementations that are available to the scientific community: bilateral filter (ImageJ<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> and MATLAB<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> based), anisotropic diffusion (ImageJ<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> and MATLAB<sup><xref ref-type="bibr" rid="CR55">55</xref></sup> based), BLS-GSM (MATLAB<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>) and nonlocal means denoising (ImageJ<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> and MATLAB<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> based). For each algorithm, we consider inputs of 256<sup>2</sup>, 512<sup>2</sup>, 1024<sup>2</sup>, 2048<sup>2</sup>, and 4096<sup>2</sup> pixels. In general, our Quasar implementation performs 10 to 100 times faster compared with the existing software packages. Notice that the obtained speedup increases as the input image size increases due to the fact that GPUs are able to process more pixels in parallel.</p></caption><graphic xlink:href="41467_2020_14529_Fig9_HTML" id="d29e1173"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec9" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par24">There is an increasing need for higher throughput in volumetric electron microscopy (EM) imaging. Faster acquisition typically results in a higher noise level, which can impede ultrastructure analysis. Consequently, to scale up 3D EM image acquisition, there is a growing demand for fast and effective denoising algorithms. Moreover, as the final purpose of 3D EM imaging can be diverse (e.g., visualization, segmentation, counting, etc.), there is no one-fits-all algorithm. This can be seen by the plethora of algorithms that are currently applied in many 3D EM applications<sup><xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR25">25</xref></sup>.</p>
    <p id="Par25">In this work, we present DenoisEM, an interactive and GPU accelerated denoising tool for volumetric data (particularly 3D EM), accessible through ImageJ. The broad range of denoising possibilities offered in one solution, make DenoisEM very versatile. Parameter tuning is efficient due to the GPU accelerated backend, which allows for visualization of different parameter settings at low latency. Reproducibility is also guaranteed by saving the algorithm parameter settings as metadata. This can be useful in a later stage, e.g., for other data sets that require exactly the same processing.</p>
    <p id="Par26">We show that we can increase the throughput of 3D EM by a factor of 4 without affecting image quality.</p>
    <p id="Par27">We validated the potential improvements that DenoisEM can provide in 3D EM image interpretation by denoising SBF-SEM image data of an Arabidopsis thaliana root tip. Experts confirmed that structures such as the nuclear membrane and endoplasmic reticulum were easier to recognize in the denoised data by optimally tuning the denoising parameters. As a second use case, we used DenoisEM on noisy SBF-SEM data of mouse heart tissue and improved the visualization of sarcomeres as the A and I-bands were better separated.</p>
    <p id="Par28">We assessed the effect of denoising on 3D EM data as a processing step prior to automated segmentation, both intensity-based thresholding and pixel-level higher-order feature classifiers. An interesting conclusion is that segmentation quality does not significantly decrease for denoised noisy inputs compared with those that are noise-free. Consequently, the acquisition time can be shortened to increase throughput or avoid overexposure, without significantly affecting subsequent segmentation results obtained by classical methods, such as thresholding or pixel classification.</p>
    <p id="Par29">An important note is that most denoising algorithms are limited in performance by a trade-off between noise reduction and edge blurring. Blur affects the resolving power of ultrastructure boundaries and is therefore not desired in most experiments. The trade-off is typically moderated through (a combination of) parameters and should therefore be tuned properly in order not to “overprocess” data sets. We believe that validation of the optimal parameter settings can only be performed by experts. DenoisEM allows for fast comparison of different parameter settings and state-of-the-art algorithms through its accelerated backend.</p>
    <p id="Par30">We believe that DenoisEM is a plugin, accessible to the life science community, that can significantly improve the quality and throughput of large-scale 3D EM imaging. Although we focus our plugin on 3D EM data, it can also be used for any (2D/3D) grayscale image producing modality (e.g., medical or astronomical data). Future work will focus on predictive parameter optimization based on regression models and correlation analysis between the parameters of different algorithms. By keeping track of the EM metadata (e.g., modality, cell type, acquisition time, etc.) and the eventual objective (segmentation or visualization), we believe that parameter optimization can be further automated. In addition, we will also extend the DenoisEM framework to multichannel image data to include the light microscopy community. Moreover, the high-level nature of Quasar allows us to easily implement novel restoration algorithms (e.g., based on convolutional neural networks) that could further improve the restoration quality.</p>
  </sec>
  <sec id="Sec10">
    <title>Methods</title>
    <sec id="Sec11">
      <title>Sample preparation</title>
      <p id="Par31">Animals were sacrificed for dissection. C57BL/6 wild-type female mice of 8 weeks old were maintained in standard specific pathogen-free (SPF) housing according to the European rules on animal welfare at the animal facility of the Center for Inflammation Research at VIB (Ghent, Belgium). Mice were anesthetized by intraperitoneal injection of ketamine/xylazine (70 mg of ketamine and 10 mg of xylazine per kg of body weight) and perfused, first with PBS containing heparin (20 units/ml) for 2 min, followed by 2% paraformaldehyde (PFA; AppliChem, Darmstadt, Germany), 2.5% glutaraldehyde (Electron Microscopy Sciences (EMS), Hatfield, PA USA) in 0.15 M cacodylate buffer (Sigma-Aldrich, Overijse, Belgium), pH 7.4, for 10 min. Next, heart muscle tissue was isolated and fixed overnight using 2% PFA, 2.5% glutaraldehyde in 0.15 M cacodylate buffer, pH 7.4. Samples were thoroughly washed in 0.15 M cacodylate buffer, pH 7.4, before small blocks were dissected to proceed with the staining protocol. Post-fixation was performed by incubating tissue blocks in 1% osmium (EMS), 1.5% potassium ferrocyanide (EMS) in 0.15 M cacodylate buffer, pH 7.4.</p>
      <p id="Par32">For SBF-SEM, post-fixation with osmium was followed by incubation in 1% thiocarbohydrazide (TCH; EMS) and subsequent washes in double-deionized water (ddH2O). Next, a second incubation in 2% osmium in ddH<sub>2</sub>O was performed. Both TCH and the second osmication were repeated after this. The samples were then washed in ddH<sub>2</sub>O and placed in 2% uranic acetate (UA; EMS). After the following washing step, Walton’s lead aspartate staining was performed for 30 min at 60 °C. For this, a 30 mM l-aspartic acid solution was used to freshly dissolve lead nitrate (20 mM, pH 5.5) just before incubation.</p>
      <p id="Par33">For FIB-SEM, the fixed tissue blocks were washed in ddH<sub>2</sub>O for four consecutive steps, refreshing the ddH<sub>2</sub>O after every step. Next, incubation in 1% osmium in ddH<sub>2</sub>O was followed by washing in ddH<sub>2</sub>O, incubation in 1% UA and again washing steps with ddH<sub>2</sub>O.</p>
      <p id="Par34">After the final washing steps, samples for both FIB-SEM and SBF-SEM were dehydrated using solutions of 50, 70, 90, and twice 100% ethanol. Samples were then placed in 100% acetone and embedded in Spurr’s resin (EMS) by incubation in 50% Spurr’s in acetone, followed by four incubations in 100% Spurr’s. Polymeration was done overnight at 60 °C. Except for the Walton’s lead staining, all steps were performed using a Pelco Biowave Pro Microwave Tissue Processor (Tedpella Inc, Redding, CA, USA).</p>
      <p id="Par35">For SBF-SEM, the sample was mounted onto an aluminum pin, trimmed into a pyramid shape using an ultramicrotome (Leica, Ultracut) and the block surface was trimmed until smooth and at least a small part of tissue was present at the block face. Next, samples were coated with 5 nm of platinum (Pt) in a Quorum Q 150T ES sputter coater (<ext-link ext-link-type="uri" xlink:href="http://www.quorumtech.com">www.quorumtech.com</ext-link>). The aluminum pins were placed in the Gatan 3View2 in a Zeiss Merlin SEM. For FIB-SEM samples were mounted on Aluminum stubs (EMS) and coated with 10 nm of Pt.</p>
    </sec>
    <sec id="Sec12">
      <title>Image acquisition</title>
      <p id="Par36">For SBF-SEM acquisitions, a Zeiss Merlin with Gatan 3View2 was used. Acquisition parameters for images of heart tissue were acceleration voltage of 1.7 kV and 100 pA, dwell time of 1 μs. Images were collected at 8000 × 8000 pixels with a pixel size of 12.44 nm, and slicing was done at z-steps of 50 nm. For image reconstructions, a ROI of 1500 × 1500 pixels was chosen and its 101 consecutive images. Acquisition parameters for images of Arabidopsis thaliana root tips in Fig. <xref rid="Fig3" ref-type="fig">3</xref> were collected at acceleration voltage of 1.6 kV and 80 pA, dwell time of 1 μs. The pixel size was 13 nm, and the slice thickness 70 nm. For Fig. <xref rid="Fig5" ref-type="fig">5,</xref> a root tip was imaged at 1.6 kV and 100 pA. A region of 2000 × 2000 pixels with 8-nm pixel size was acquired with increasing dwell times of 1, 2, and 4 μs. FIB-SEM imaging of murine heart tissue samples was done with a Zeiss Crossbeam 540 at 5-nm pixels and slicing at 5-nm sections.</p>
    </sec>
    <sec id="Sec13">
      <title>Implemented restoration methods</title>
      <p id="Par37">In this section, we will give a brief overview of the implemented algorithms. This includes the median absolute deviation (MAD) noise estimator, least-squares parameter estimator, Gaussian filtering (GF), wavelet thresholding (WT), anisotropic diffusion (AD), bilateral filtering (BF), Tikhonov denoising/deconvolution (TIK-DEN/DEC), total variation denoising (TV-DEN), Bayesian least-squares Gaussian scale mixtures (BLS-GSM), and nonlocal means denoising/deconvolution (NLM/NLMD). The restoration methods are complementary in terms of computation time and restoration performance: e.g., algorithms such as BLS-GSM and NLMD are computationally more intensive than, for example, GF and AD, but the former are more likely to outperform the latter. This trade-off between computation time and image quality can be tuned by the expert. In Supplementary Figs. <xref rid="MOESM1" ref-type="media">2</xref>–<xref rid="MOESM1" ref-type="media">10</xref>, we illustrate the influence of the implemented methods and their respective parameters on the restored image.</p>
      <p id="Par38">We will denote 3D images as vectors by stacking the pixels using slice-by-slice raster scanning ordering. More specifically, the acquired image <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{y}}\in {{\mathbb{R}}}^{N}$$\end{document}</tex-math><mml:math id="M4"><mml:mi mathvariant="bold">y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq2.gif"/></alternatives></inline-formula> (where <italic>N</italic> is the number of voxels in the image) is assumed to be degraded by blur and additive noise:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{y}}={\bf{H}}{\bf{x}}+{\bf{n}},$$\end{document}</tex-math><mml:math id="M6"><mml:mi mathvariant="bold">y</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mi mathvariant="bold">x</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">n</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{x}}\in {{\mathbb{R}}}^{N}$$\end{document}</tex-math><mml:math id="M8"><mml:mi mathvariant="bold">x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq3.gif"/></alternatives></inline-formula> is the underlying, degradation-free image, <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{H}}\in {{\mathbb{R}}}^{N\times N}$$\end{document}</tex-math><mml:math id="M10"><mml:mi mathvariant="bold">H</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq4.gif"/></alternatives></inline-formula> represents the microscope point-spread function (PSF), and <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{n}}\in {{\mathbb{R}}}^{N}$$\end{document}</tex-math><mml:math id="M12"><mml:mi mathvariant="bold">n</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq5.gif"/></alternatives></inline-formula> is a stochastic, noise term. The noise term is assumed to be mean-zero and with a constant variance, i.e., <inline-formula id="IEq6"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[{\bf{C}}\right]}_{i,i}={\sigma }^{2}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq6.gif"/></alternatives></inline-formula> (where <bold>C</bold> is the noise-covariance matrix).</p>
      <p id="Par39">Note that all the described denoising algorithms are independent of the dimensionality of the data set. Consequently, all of these methods can be implemented in 3D, which can improve restoration quality. However, this comes at the cost of memory and compute time. As an illustration, we have implemented the Gaussian filter, bilateral filter, and tikhonov denoising in 3D and concluded that the small increase in denoising performance was not convincingly worth the computational cost (typically 50% more) and memory overhead (typically overflow at 0.5 GV images with a 4 GB GPU). For more details on this comparison, we refer to Supplementary Fig. <xref rid="MOESM1" ref-type="media">14</xref>. For this reason, the described methods are implemented in 2D, and volumes are processed in a slice-by-slice fashion. We do, however, consider efficient 3D implementations as future work.</p>
      <p id="Par40">Noise estimation: This involves the task of estimating the noise variance <italic>σ</italic><sup>2</sup> based on the acquired image <bold>y</bold>. The method that is implemented in our plugin is the median absolute deviation (MAD) noise estimator:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\sigma }={\rm{med}}\left(\left|{\bf{y}}-{\rm{med}}\left({\bf{y}}\right)\right|\right),$$\end{document}</tex-math><mml:math id="M16"><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi mathvariant="normal">med</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfenced close="∣" open="∣" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">med</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq7"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{med}}\left(\cdot \right)$$\end{document}</tex-math><mml:math id="M18"><mml:mi mathvariant="normal">med</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq7.gif"/></alternatives></inline-formula> denotes the median operator. The absolute difference of <bold>y</bold> and its median value provides a pixel-wise, noise-robust measure of how much the signal deviates from its expected value. Taking the median over these values therefore gives a robust estimation of the noise standard deviation over the complete image <bold>y</bold>.</p>
      <p id="Par41">Blur estimation: This involves the task of quantifying the amount of blur in an image, i.e., a sharp image would have a metric of 0, and this value increases to 1 as the amount of blur increases. The implemented approach explains blur as the difference between the pixel variation of the original image <bold>y</bold> and a smoothened version <inline-formula id="IEq8"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{y}}^{\prime} ={{\bf{S}}}_{{\rm{x}}}{\bf{y}}$$\end{document}</tex-math><mml:math id="M20"><mml:msup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">y</mml:mi></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq8.gif"/></alternatives></inline-formula>, where <bold>S</bold><sub>x</sub> is a horizontal smoothing kernel. The pixel variation is defined as:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{v}}}_{{\rm{x}}}=\max \left(0,{{\bf{D}}}_{{\rm{x}}}{\bf{y}}-{{\bf{D}}}_{{\rm{x}}}{\bf{y}}^{\prime} \right),$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>max</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <bold>D</bold><sub>x</sub> expresses the variation along the x-axis (e.g., a first-order derivative approximation). These pixel-wise variations are aggregated to a single value and normalized as follows:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{{\rm{x}}}=\frac{{\sum }_{i}{\left[{{\bf{D}}}_{{\rm{x}}}{\bf{y}}\right]}_{i}-{\sum }_{i}{\left[{{\bf{v}}}_{{\rm{x}}}\right]}_{i}}{{\sum }_{i}{\left[{{\bf{D}}}_{{\rm{x}}}{\bf{y}}\right]}_{i}}.$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>This value expresses the blur level along the horizontal direction. However, a similar approach can be used to extract a blur estimation <italic>b</italic><sub>y</sub> along the vertical direction. The final blur metric is simply the maximum of both values.</p>
      <p id="Par42">Parameter estimation: Consider an algorithm <bold>f</bold><sub><bold><italic>θ</italic></bold></sub>( ⋅ ) with parameters <inline-formula id="IEq9"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\boldsymbol{\theta }}\in {{\mathbb{R}}}^{p}$$\end{document}</tex-math><mml:math id="M26"><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq9.gif"/></alternatives></inline-formula> that maps a noisy image <bold>y</bold> onto a noise-free estimation <inline-formula id="IEq10"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\bf{x}}}={{\bf{f}}}_{{\boldsymbol{\theta }}}({\bf{y}})$$\end{document}</tex-math><mml:math id="M28"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq10.gif"/></alternatives></inline-formula>. Based on the estimated noise level <inline-formula id="IEq11"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\sigma }$$\end{document}</tex-math><mml:math id="M30"><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq11.gif"/></alternatives></inline-formula> (see Eq. (<xref rid="Equ2" ref-type="">2</xref>)), we estimate the optimal parameter settings through parameterized polynomial expressions w.r.t. a training data set of noise-free benchmark EM images <bold>x</bold><sub><italic>k</italic></sub>, for <italic>k</italic> = 1, . . . , <italic>K</italic> (<italic>K</italic> = 100 in our case). These images were degraded with Gaussian noise of different levels <italic>σ</italic><sub><italic>m</italic></sub> resulting in noisy images <bold>y</bold><sub><italic>k</italic>,<italic>m</italic></sub>. The optimal parameters <inline-formula id="IEq12"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\boldsymbol{\theta }}}_{m}\in {{\mathbb{R}}}^{p}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq12.gif"/></alternatives></inline-formula> were determined for each noise level <italic>σ</italic><sub><italic>m</italic></sub> in least-squares sense:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\boldsymbol{\theta }}}_{m}=\arg \min_{{\boldsymbol{\theta }}}\sum _{k}{\left\Vert {{\bf{f}}}_{{\boldsymbol{\theta }}}({{\bf{y}}}_{k,m})-{{\bf{x}}}_{k}\right\Vert }^{2}$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mrow><mml:mo mathsize="big"> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>Next, the polynomial coefficient parameters <inline-formula id="IEq13"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{a}}}_{j}\in {{\mathbb{R}}}^{q}$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq13.gif"/></alternatives></inline-formula> were optimized with a least-squares fit:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{a}}}_{j}=\arg \min_{{\bf{a}}}\sum _{m}{\left({\left[{{\boldsymbol{\theta }}}_{m}\right]}_{j}-\sum _{i}{\left[{\bf{a}}\right]}_{i}{\sigma }_{m}^{i}\right)}^{2}$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mrow><mml:mo mathsize="big"> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>Finally, the estimated parameters that correspond to the estimated noise level <inline-formula id="IEq14"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\sigma }$$\end{document}</tex-math><mml:math id="M40"><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq14.gif"/></alternatives></inline-formula> are computed as:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[\hat{{\boldsymbol{\theta }}}\right]}_{j}=\sum _{i}{[{{\bf{a}}}_{j}]}_{i}{\hat{\sigma }}^{i}.$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big"> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>In practice, we concluded that, depending on the algorithm, a linear or quadratic polynomial fit (<italic>q</italic> = 1, 2) approximates the optimal parameters (in least-squares sense) sufficiently close (see Supplementary Figs. <xref rid="MOESM1" ref-type="media">15,</xref>
<xref rid="MOESM1" ref-type="media">16</xref>).</p>
      <p id="Par43">Gaussian filter: This is a special case of linear, smoothing filters which combine pixel values linearly in a local neighborhood in order to restore a pixel value. Practically, this comes down to a convolution of the noisy image <bold>y</bold> with a convolution kernel <bold>G</bold> (which is Gaussian in this case).</p>
      <p id="Par44">Wavelet thresholding: Wavelet transforms separate image information across multiple frequency scales and magnitudes. Noise tends to be spread among all the transformed coefficients whereas the coefficients that represent actual discontinuities typically stand out. Therefore, a popular method to reduce the amount of noise in an image is to reduce the magnitude of the transformed coefficients, this is also known as wavelet shrinkage. More specifically, the restored image is found by transforming the image <bold>y</bold> to the wavelet domain, shrink the noisy coefficients and transform back to the spatial domain:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\bf{x}}}={{\bf{W}}}^{H}\left(\tau \left({\bf{W}}{\bf{y}}\right)\right),$$\end{document}</tex-math><mml:math id="M44"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>τ</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <bold>W</bold> represents the used wavelet transform and <bold>W</bold><sup><italic>H</italic></sup> is its Hermitian transpose. The shrinkage function <italic>τ</italic> is typically the soft-thresholding operator:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tau \left({\bf{z}}\right)={\rm{sign}}\left({\bf{z}}\right)\max \left(\left|{\bf{z}}\right|-T,0\right),$$\end{document}</tex-math><mml:math id="M46"><mml:mi>τ</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">sign</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow></mml:mfenced><mml:mi>max</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfenced close="∣" open="∣" separators=""><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow></mml:mfenced><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where all the functions operate component-wise and <italic>T</italic> is a thresholding parameter.</p>
      <p id="Par45">Anisotropic diffusion: The anisotropic diffusion filter, commonly used in the context of EM image restoration, introduces nonlinearity by describing linear filters in a partial differential equation (PDE) domain and extending it to a nonlinear case. The true image <bold>x</bold> is embedded in a family of images <bold>x</bold><sub><italic>t</italic></sub>, obtained by convolving the image <bold>x</bold> with Gaussian filters with a variance that increases with <italic>t</italic>. This diffusion process can be described by the so-called linear diffusion heat equation:<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{\partial {{\bf{x}}}_{t}}{\partial t}=\nabla \cdot \left(\nabla {{\bf{x}}}_{t}\right),$$\end{document}</tex-math><mml:math id="M48"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>∇</mml:mo><mml:mo>⋅</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>∇</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>where  ∇ represents the gradient operator with respect to the spatial coordinates. This isotropic diffusion method ignores edge information and consequently blurs edges. The anisotropic diffusion filter mitigates this by integrating a gradient magnitude weighting function:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{\partial {{\bf{x}}}_{t}}{\partial t}=\nabla \cdot \left(c\left({\left\Vert \nabla {{\bf{x}}}_{t}\right\Vert }_{2}\right)\nabla {{\bf{x}}}_{t}\right).$$\end{document}</tex-math><mml:math id="M50"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>∇</mml:mo><mml:mo>⋅</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>c</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:mo>∇</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>∇</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>Two nonlinear gradient regularization functions are commonly used:<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c(s)=\exp \left(-{\left(\frac{s}{\kappa }\right)}^{2}\right),$$\end{document}</tex-math><mml:math id="M52"><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c(s)=\frac{1}{1+{\left(\frac{s}{\kappa }\right)}^{2}},$$\end{document}</tex-math><mml:math id="M54"><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>where <italic>κ</italic> &gt; 0 is a parameter that offers a trade-off between noise reduction and edge preservation. The idea is that the function <italic>c</italic>( ⋅ ) returns small values for large gradient magnitudes and vice versa such that edges are less diffused (i.e., blurred) and only in the direction of the edge (e.g., to avoid that horizontal edges will be blurred in the horizontal direction).</p>
      <p id="Par46">Bilateral filter: It is argued that local linear filters (such as the Gaussian filter) tend to oversmooth image edges and require nonlinearities in order to obtain a better restoration estimate. In former EM research, the bilateral filter is used as an alternative: this is a locally adaptive spatial filter that avoids oversmoothing by averaging less aggressively along edges. More specifically, the restored <italic>i</italic>th pixel <inline-formula id="IEq15"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[\hat{{\bf{x}}}\right]}_{i}$$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq15.gif"/></alternatives></inline-formula> is computed as:<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[\hat{{\bf{x}}}\right]}_{i}=\sum _{j}{f}_{{\rm{int}}}(|{[{\bf{y}}]}_{i}-{[{\bf{y}}]}_{j}|){f}_{{\rm{sp}}}({\Vert {{\bf{p}}}_{i}-{{\bf{p}}}_{j}\Vert }_{2}){[{\bf{y}}]}_{j},$$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big"> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">int</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">sp</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq16"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{{\rm{int}}},{f}_{{\rm{sp}}}:{\mathbb{R}}\to {\mathbb{R}}$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">int</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">sp</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq16.gif"/></alternatives></inline-formula> are kernel functions that weigh the intensity and spatial distance, respectively, and <inline-formula id="IEq17"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{p}}}_{i}\in {{\mathbb{R}}}^{3}$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq17.gif"/></alternatives></inline-formula> represents the 3D spatial position vector that corresponds to the index <italic>i</italic>. Similar to the Gaussian filter, pixels <inline-formula id="IEq18"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[{\bf{y}}\right]}_{j}$$\end{document}</tex-math><mml:math id="M64"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq18.gif"/></alternatives></inline-formula> nearby the reference pixel <inline-formula id="IEq19"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[{\bf{y}}\right]}_{i}$$\end{document}</tex-math><mml:math id="M66"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq19.gif"/></alternatives></inline-formula> will be assigned larger averaging weights through <italic>f</italic><sub>sp</sub>. However, pixel intensities that differ very much from the reference pixel (typically edges) are assigned low-weight values through <italic>f</italic><sub>int</sub>, which leads to less blurring along edges.</p>
      <p id="Par47">Tikhonov deconvolution: Tikhonov restoration exploits the fact that images generally consist of many smooth regions separated by a much smaller amount of edges. As a consequence, the total edge magnitude in the restored image should be penalized, in other words:<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\bf{x}}}=\arg \min_{{\bf{x}}}{\left\Vert {\bf{y}}-{\bf{H}}{\bf{x}}\right\Vert }_{2}^{2}+\lambda {\left\Vert {\bf{L}}{\bf{x}}\right\Vert }_{2}^{2},$$\end{document}</tex-math><mml:math id="M68"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:mi mathvariant="bold">L</mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula>where <bold>L</bold> is typically a matrix that acts as a gradient or Laplacian operator in order to quantify edges in the image (we use the Laplacian).</p>
      <p id="Par48">Total variation deconvolution: The total variation prior (TV) assumes that natural images <bold>x</bold> should consist of flat regions delineated by a relatively small amount of edges. Mathematically, this is expressed as minimizing the total variation of the image:<disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\bf{x}}}=\arg \min_{{\bf{x}}}{\left\Vert {\bf{y}}-{\bf{H}}{\bf{x}}\right\Vert }_{2}^{2}+\lambda \sum _{i}\sqrt{{\left[{{\bf{D}}}_{{\rm{x}}}{\bf{x}}\right]}_{i}^{2}+{[{{\bf{D}}}_{{\rm{y}}}{\bf{x}}]}_{i}^{2}+{\left[{{\bf{D}}}_{{\rm{z}}}{\bf{x}}\right]}_{i}^{2}},$$\end{document}</tex-math><mml:math id="M70"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msqrt><mml:msubsup><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">z</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula>where <bold>D</bold><sub>x</sub>, <bold>D</bold><sub>y</sub>, and <bold>D</bold><sub>z</sub> are matrices that express the variation of the image along the <italic>x</italic>, <italic>y</italic>, and <italic>z</italic>-axis, respectively (e.g., first-order derivative approximations).</p>
      <p id="Par49">BLS-GSM: The BLS-GSM method decomposes the image into <italic>J</italic> scales and <italic>K</italic> oriented pyramid subbands, denoises the high-pass subbands and inverts the pyramid transform. An <italic>M</italic> × <italic>M</italic> neighborhood around a reference coefficient <inline-formula id="IEq20"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[{\bf{v}}\right]}_{c}$$\end{document}</tex-math><mml:math id="M72"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq20.gif"/></alternatives></inline-formula> of a subband is considered and represented as a vector <bold>v</bold>, by column stacking. These coefficients are then modeled as Gaussian Scale Mixtures (GSM), i.e., the product of a Gaussian distributed vector <inline-formula id="IEq21"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{u}}\mathop{=}\limits^{d}{\mathcal{N}}\left({\bf{0}},{{\bf{C}}}_{{\rm{u}}}\right)$$\end{document}</tex-math><mml:math id="M74"><mml:mi mathvariant="bold">u</mml:mi><mml:mover accent="true"><mml:mrow><mml:mo>=</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mover><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq21.gif"/></alternatives></inline-formula> (where <inline-formula id="IEq22"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathop{=}\limits^{d}$$\end{document}</tex-math><mml:math id="M76"><mml:mover accent="true"><mml:mrow><mml:mo> =</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq22.gif"/></alternatives></inline-formula> indicates distribution equality) and the square root of an independent, positive scalar random variable <italic>z</italic>:<disp-formula id="Equ17"><label>17</label><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{v}}\mathop{=}\limits^{d}\sqrt{z}{\bf{u}},$$\end{document}</tex-math><mml:math id="M78"><mml:mi mathvariant="bold">v</mml:mi><mml:mover accent="true"><mml:mrow><mml:mo>=</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mover><mml:msqrt><mml:mi>z</mml:mi></mml:msqrt><mml:mi mathvariant="bold">u</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ17.gif" position="anchor"/></alternatives></disp-formula>such that a noisy neighborhood patch <bold>w</bold> is described by:<disp-formula id="Equ18"><label>18</label><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{w}}={\bf{v}}+{\bf{n}},$$\end{document}</tex-math><mml:math id="M80"><mml:mi mathvariant="bold">w</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">v</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">n</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ18.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq23"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{n}}\mathop{=}\limits^{d}{\mathcal{N}}\left({\bf{0}},{{\bf{C}}}_{{\rm{n}}}\right)$$\end{document}</tex-math><mml:math id="M82"><mml:mi mathvariant="bold">n</mml:mi><mml:mover accent="true"><mml:mrow><mml:mo>=</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mover><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold">0</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq23.gif"/></alternatives></inline-formula> are the noise coefficients. Based on this model, the reference coefficient is approximated using the Bayesian least-squares (BLS) estimator which reduces to:<disp-formula id="Equ19"><label>19</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[\hat{{\bf{v}}}\right]}_{c}={\int _{0}^{\infty }}{\rm{P}}\left(z| {\bf{w}}\right){\rm{E}}\left[{\left[{\bf{v}}\right]}_{c}| {\bf{w}},z\right]\ dz,$$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mi mathvariant="normal">P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>z</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:mfenced><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mfenced><mml:mspace width="0.33em"/><mml:mi>d</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ19.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq24"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{P}}\left(z| {\bf{w}}\right)$$\end{document}</tex-math><mml:math id="M86"><mml:mi mathvariant="normal">P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>z</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq24.gif"/></alternatives></inline-formula> is found with Bayes’ rule, and <inline-formula id="IEq25"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{E}}\left[{\bf{v}}| {\bf{w}},z\right]$$\end{document}</tex-math><mml:math id="M88"><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">v</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq25.gif"/></alternatives></inline-formula> is computed as a local linear Wiener estimate:<disp-formula id="Equ20"><label>20</label><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{E}}\left[{\bf{v}}| {\bf{w}},z\right]=z{{\bf{C}}}_{{\rm{u}}}{\left(z{{\bf{C}}}_{{\rm{u}}}+{{\bf{C}}}_{{\rm{n}}}\right)}^{-1}{\bf{w}}.$$\end{document}</tex-math><mml:math id="M90"><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">v</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>z</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ20.gif" position="anchor"/></alternatives></disp-formula>Mainly due to accurate statistical noise modeling, BLS-GSM has become the state-of-the-art in multiresolution-based denoising.</p>
      <p id="Par50">Nonlocal means denoising: Since the introduction of the nonlocal means (NLM) filter, self-similarity denoising approaches gained a lot of interest because of their high performance. More specifically, the NLM algorithm estimates the noise-free image pixels as weighted averages of acquired pixel values:<disp-formula id="Equ21"><label>21</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[\hat{{\bf{x}}}\right]}_{i}=\frac{\sum _{j}{w}_{i,j}{\left[{\bf{y}}\right]}_{j}}{\sum _{j}{w}_{i,j}}.$$\end{document}</tex-math><mml:math id="M92"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mo mathsize="big"> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ21.gif" position="anchor"/></alternatives></disp-formula>The self-similarity constraint turns up in the way the weights <italic>w</italic><sub><italic>i</italic>,<italic>j</italic></sub> are computed: these should be large (respectively, small) for similar (respectively, dissimilar) pixels <italic>i</italic> and <italic>j</italic>. Pixel similarity is defined along a local pixel neighborhood, and searched for in both a local and nonlocal region:<disp-formula id="Equ22"><label>22</label><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${w}_{i,j}=\exp \left(-\frac{1}{2}\frac{{\Vert {{\bf{y}}}_{{N}_{i}}-{{\bf{y}}}_{{N}_{j}}\Vert }_{2}^{2}}{h}\right)$$\end{document}</tex-math><mml:math id="M94"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ22.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq26"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{y}}}_{{N}_{i}}$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq26.gif"/></alternatives></inline-formula> denotes a local neighborhood <italic>N</italic><sub><italic>i</italic></sub> of the acquired pixel <inline-formula id="IEq27"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\left[y\right]}_{i}$$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2020_14529_Article_IEq27.gif"/></alternatives></inline-formula>, and <italic>h</italic> is a similarity damping parameter.</p>
      <p id="Par51">It has been shown that the NLM algorithm can be equivalently expressed by means of a Bayesian estimator with nonlocal image prior. An NLM deconvolution algorithm can be derived by extending the Bayesian estimator with nonlocal prior to a deconvolution estimator:<disp-formula id="Equ23"><label>23</label><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\bf{x}}}=\arg \min_{{\bf{x}}}{\left\Vert {\bf{y}}-{\bf{H}}{\bf{x}}\right\Vert }_{2}^{2}+\lambda \sum _{i,j=0}^{N-1}{w}_{i,j}{\Vert {[{\bf{x}}]}_{i}-{[{\bf{x}}]}_{j}\Vert }_{2}^{2}.$$\end{document}</tex-math><mml:math id="M100"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2020_14529_Article_Equ23.gif" position="anchor"/></alternatives></disp-formula>where <italic>λ</italic> is a regularization parameter and <bold>H</bold> is the estimated PSF of the microscope.</p>
    </sec>
    <sec id="Sec14">
      <title>Image restoration settings for the experiments</title>
      <p id="Par52">Most image restoration methods have parameters that may affect computational performance: e.g., search windows, block sizes, number of iterations, etc. For computational comparison, we selected parameter settings that corresponded to those that were most frequently preferred by biological experts during our experiments. In particular, we only report the parameters that affect computation time:<list list-type="bullet"><list-item><p id="Par53">Gaussian filter: window size 7 × 7 (fixed in the plugin)</p></list-item><list-item><p id="Par54">Wavelet thresholding: 3D dual-tree complex wavelet transform, 6 scales</p></list-item><list-item><p id="Par55">Anisotropic diffusion: <italic>N</italic> = 5 iterations</p></list-item><list-item><p id="Par56">Bilateral filter: window size 15 × 15 (fixed in the plugin)</p></list-item><list-item><p id="Par57">Tikhonov denoising: <italic>N</italic> = 10 iterations</p></list-item><list-item><p id="Par58">Total variation denoising: <italic>N</italic> = 100 iterations</p></list-item><list-item><p id="Par59">BLS-GSM: <italic>J</italic> = 3 scales, window size 3 × 3 (fixed in the plugin)</p></list-item><list-item><p id="Par60">Nonlocal means denoising: half window size <italic>B</italic> = 4, half search window size <italic>W</italic> = 5</p></list-item><list-item><p id="Par61">Nonlocal means deconvolution: half window size <italic>B</italic> = 4, half search window size <italic>W</italic> = 5, <italic>N</italic> = 20 iterations</p></list-item></list></p>
      <p id="Par152">The algorithms were implemented in Quasar and compared to open-source MATLAB-based and ImageJ-based implementations if available. The experiments were performed with an Intel(R) Core(TM) i7-4930K CPU @ 3.40 GHz and an NVIDIA GeForce GTX 1070 GPU and repeated for various sizes of 2D input images (256<sup>2</sup>, 512<sup>2</sup> up to 4096<sup>2</sup>). For more details, we refer to Supplementary Fig. <xref rid="MOESM1" ref-type="media">13</xref>.</p>
      <p id="Par62">SBF-SEM images, acquired with the Zeiss Merlin and Gatan 3View2 detector, are originally generated as 16-bit images. All image restoration techniques (denoising, registration, segmentation) were performed with floating point precision. The mouse lung artery data were restored using wavelet thresholding with a threshold value of <italic>T</italic> = 0.08. The Arabidopsis thaliana root tip was restored using Tikhonov deconvolution with the following parameters: <italic>λ</italic> = 1.5, <italic>σ</italic> = 0.31, and <italic>N</italic> = 86 iterations. The murine heart tissue data set was processed with anisotropic diffusion with a step size <italic>ν</italic> = 0.07, <italic>N</italic> = 6 iterations and a diffusion factor <italic>κ</italic> = 0.18. ImageJ was used to apply thresholding on the raw and denoised image. The values of the selected intensities for the A-bands (shown in red in Fig. <xref rid="Fig4" ref-type="fig">4</xref>) were [30300, 30700] and [30589, 30674] for the raw and denoised image, respectively. The values of the selected intensities for the I-bands (shown in green in Fig. <xref rid="Fig4" ref-type="fig">4</xref>) were [30800, 31300] for both the raw and denoised image. The mouse heart tissue was denoised using nonlocal means with damping parameter <italic>h</italic>  = 0.23, half window size <italic>B</italic> = 6 and half search window size <italic>W</italic> = 9. A reference area of 340 × 340 pixels and 117 sections was cropped and used in local template matching for registration. Reconstruction was performed similarly as with the murine heart tissue, using threshold values from the interval [32, 78]. As a final step, a conversion to 8-bit was always done before exporting to PNG, to allow for final visualization. Graphics design was performed using Matlab, GIMP, Inkscape, and MS Office.</p>
    </sec>
    <sec id="Sec15">
      <title>Statistics and reproducibility</title>
      <p id="Par63">All denoising and segmentation experiments were repeated for at least ten times on different regions of interest on the data, and similar results were validated. Experiments that involved counting were repeated for three times by two independent investigators, and similar results were obtained. Timing experiments were repeated for 20 times with a similar outcome as a result. Supplementary Note <xref rid="MOESM1" ref-type="media">2</xref> provides a data reproducibility statement on this paper.</p>
    </sec>
    <sec id="Sec16">
      <title>Reporting summary</title>
      <p id="Par64">Further information on research design is available in the <xref rid="MOESM3" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec17">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2020_14529_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2020_14529_MOESM2_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="41467_2020_14529_MOESM3_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Peer review information</bold> <italic>Nature Communications</italic> thanks Stephan Saalfeld and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.</p>
    </fn>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>These authors contributed equally: Joris Roels, Frank Vernaillen.</p>
    </fn>
    <fn>
      <p>These authors jointly supervised this work: Saskia Lippens, Yvan Saeys.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> is available for this paper at 10.1038/s41467-020-14529-0.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>This research has been made possible by the Agency for Flanders Innovation &amp; Entrepreneurship (Grant Number: IWT.141703), BOF (Grant number: BOF15/PDO/003) and the Flemish Government under the “Onderzoeksprogramma Artificiële Intelligentie (AI) Vlaanderen” program. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan X Pascal GPU used for this research. The Zeiss Merlin with 3View and Zeiss CrossBeam 540 were purchased by funding from the CLEM-grant and VIB Technology Fund.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>J.R., F.V., A.K., A.G. and S.L. conceived and designed the experiments. J.R., J.A., H.L. and B.G. implemented the denoising and registration algorithms. F.V. and B.G. developed the software plugin. J.R., F.V., A.K., A. G., J.A., H.L., B.G., W.P., S.L. and Y.S. analyzed the results and wrote the paper.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The DenoisEM plugin is available on our webpage (<ext-link ext-link-type="uri" xlink:href="https://bioimagingcore.be/DenoisEM">https://bioimagingcore.be/DenoisEM</ext-link>) and figshare (10.6084/m9.figshare.9929201). A user manual is provided on the webpage (<ext-link ext-link-type="uri" xlink:href="http://bioimagingcore.be/DenoisEM/user-manual.pdf">http://bioimagingcore.be/DenoisEM/user-manual.pdf</ext-link>, 10.6084/m9.figshare.9929888). The raw data that was used for this paper are located on our webpage (<ext-link ext-link-type="uri" xlink:href="https://bioimagingcore.be/DenoisEM/data">https://bioimagingcore.be/DenoisEM/data</ext-link>, 10.6084/m9.figshare.9929183). The source data underlying Figs. <xref rid="Fig1" ref-type="fig">1</xref>–<xref rid="Fig9" ref-type="fig">9</xref> and Supplementary Figs. <xref rid="MOESM1" ref-type="media">1</xref>–<xref rid="MOESM1" ref-type="media">17</xref> are provided as a Source Data file (10.6084/m9.figshare.9929216).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>We stimulate the community to build on our work by open-sourcing DenoisEM (<ext-link ext-link-type="uri" xlink:href="https://github.com/vibbits/EMDenoising">https://github.com/vibbits/EMDenoising</ext-link>) and the Java-Quasar bridge that (<ext-link ext-link-type="uri" xlink:href="https://github.com/vibbits/JavaQuasarBridge">https://github.com/vibbits/JavaQuasarBridge</ext-link>). Supplementary code for the automated parameter estimation is provided on figshare (10.6084/m9.figshare.9929228).</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par65">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A complete electron microscopy volume of the brain of adult Drosophila melanogaster</article-title>
        <source>Cell</source>
        <year>2018</year>
        <volume>174</volume>
        <fpage>730</fpage>
        <lpage>743.e22</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id>
        <pub-id pub-id-type="pmid">30033368</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kremer</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Developing 3D SEM in a broad biological context</article-title>
        <source>J. Microsc.</source>
        <year>2015</year>
        <volume>259</volume>
        <fpage>80</fpage>
        <lpage>96</lpage>
        <pub-id pub-id-type="doi">10.1111/jmi.12211</pub-id>
        <pub-id pub-id-type="pmid">25623622</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">Leighton, S. B. SEM images of block faces, cut by a miniature microtome within the SEM—a technical note. <italic>Scanning Electron Microscopy</italic><bold>2</bold>, 73–76 (1981).</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Denk</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Horstmann</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Serial block-face scanning electron microscopy to reconstruct three-dimensional tissue nanostructure</article-title>
        <source>PLoS Biol.</source>
        <year>2004</year>
        <volume>2</volume>
        <fpage>e329</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.0020329</pub-id>
        <pub-id pub-id-type="pmid">15514700</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peddie</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Collinson</surname>
            <given-names>LM</given-names>
          </name>
        </person-group>
        <article-title>Exploring the third dimension: volume electron microscopy comes of age</article-title>
        <source>Micron</source>
        <year>2014</year>
        <volume>61</volume>
        <fpage>9</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.1016/j.micron.2014.01.009</pub-id>
        <pub-id pub-id-type="pmid">24792442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Webb, R. I. &amp; Schieber, N. L. Volume scanning electron microscopy: serial block-face scanning electron microscopy focussed ion beam scanning electron microscopy. in <italic>Cellular Imaging: Electron Tomography and Related Techniques</italic> (ed Hanssen, E.) 117–148 (Springer International Publishing, Cham, 2018).</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Helmstaedter</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Connectomic reconstruction of the inner plexiform layer in the mouse retina</article-title>
        <source>Nature</source>
        <year>2013</year>
        <volume>500</volume>
        <fpage>168</fpage>
        <lpage>174</lpage>
        <pub-id pub-id-type="doi">10.1038/nature12346</pub-id>
        <pub-id pub-id-type="pmid">23925239</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pfeifer</surname>
            <given-names>CR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantitative analysis of mouse pancreatic islet architecture by serial block-face SEM</article-title>
        <source>J. Struct. Biol.</source>
        <year>2015</year>
        <volume>189</volume>
        <fpage>44</fpage>
        <lpage>52</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2014.10.013</pub-id>
        <pub-id pub-id-type="pmid">25448885</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Reese</surname>
            <given-names>SP</given-names>
          </name>
          <name>
            <surname>Farhang</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Poulson</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Parkman</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>Nanoscale imaging of collagen gels with focused ion beam milling and scanning electron microscopy</article-title>
        <source>Biophys. J.</source>
        <year>2016</year>
        <volume>111</volume>
        <fpage>1797</fpage>
        <lpage>1804</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bpj.2016.08.039</pub-id>
        <pub-id pub-id-type="pmid">27760365</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sakaguchi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Miyazaki</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Fujioka</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kaneko</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Murata</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Three-dimensional analysis of morphological changes in the malaria parasite infected red blood cell by serial block-face scanning electron microscopy</article-title>
        <source>J. Struct. Biol.</source>
        <year>2016</year>
        <volume>193</volume>
        <fpage>162</fpage>
        <lpage>171</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2016.01.003</pub-id>
        <pub-id pub-id-type="pmid">26772147</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Leapman</surname>
            <given-names>RD</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Quantitative analysis of immature secretory granules in beta cells of mouse pancreatic islets by serial block-face scanning electron microscopy</article-title>
        <source>Biophys. J.</source>
        <year>2018</year>
        <volume>114</volume>
        <fpage>370A</fpage>
        <pub-id pub-id-type="doi">10.1016/j.bpj.2017.11.2050</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>CS</given-names>
          </name>
          <name>
            <surname>Hayworth</surname>
            <given-names>KJ</given-names>
          </name>
          <name>
            <surname>Pang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Hess</surname>
            <given-names>HF</given-names>
          </name>
        </person-group>
        <article-title>Breaking barriers of FIB-SEM for large volume connectomics and cell biology</article-title>
        <source>Microsc. Microanal.</source>
        <year>2018</year>
        <volume>24</volume>
        <fpage>1228</fpage>
        <lpage>1229</lpage>
        <pub-id pub-id-type="doi">10.1017/S1431927618006621</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Xu, C. S., Pang, S., Hayworth, K. J. &amp; Hess, H. F. Enabling, FIB-enabling FIB-SEM systems for large volume connectomics and cell biology. Preprint at <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/852863v1">https://www.biorxiv.org/content/10.1101/852863v1</ext-link> (2019).</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Portilla</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Strela</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Wainwright</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Simoncelli</surname>
            <given-names>EP</given-names>
          </name>
        </person-group>
        <article-title>Image denoising using scale mixtures of Gaussians in the wavelet domain</article-title>
        <source>IEEE Transac. Image Process.</source>
        <year>2003</year>
        <volume>12</volume>
        <fpage>1338</fpage>
        <lpage>1351</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2003.818640</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dabov</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Foi</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Image denoising with block-matching and 3D filtering</article-title>
        <source>Electron. Imaging</source>
        <year>2006</year>
        <volume>6064</volume>
        <fpage>1</fpage>
        <lpage>12</lpage>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Buades, A., Coll, B. &amp; Morel, J.-M. A non-local algorithm for image denoising. in <italic>Computer Vision and Pattern Recognition</italic>, Vol. 2, 60–65 (IEEE Computer Society Conference, 2005).</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Jia, C. &amp; Evans, B. L. Patch-based image deconvolution via joint modeling of sparse priors. (eds. Dooms A. &amp; Piater J. H.) in <italic>IEEE International Conference on Image Processing</italic>, 681–684 (IEEE, 2011).</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Aelterman, J. et al. Combined non-local and multi-resolution sparsity prior in image restoration. (eds. Rao R. &amp; Gurram P.) in <italic>IEEE International Conference on Image Processing</italic>, 3049–3052 (IEEE, 2012).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Zhang, K., Zuo, W., Gu, S. &amp; Zhang, L. Learning deep CNN denoiser prior for image restoration. (eds. Mortensen E.) in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic>, 2808–2817 (IEEE, 2017).</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wei</surname>
            <given-names>DY</given-names>
          </name>
          <name>
            <surname>Yin</surname>
            <given-names>CC</given-names>
          </name>
        </person-group>
        <article-title>An optimized locally adaptive non-local means denoising filter for cryo-electron microscopy data</article-title>
        <source>J. Struct. Biol.</source>
        <year>2010</year>
        <volume>172</volume>
        <fpage>211</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2010.06.021</pub-id>
        <pub-id pub-id-type="pmid">20599508</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hovden</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Xin</surname>
            <given-names>HL</given-names>
          </name>
          <name>
            <surname>Muller</surname>
            <given-names>DA</given-names>
          </name>
        </person-group>
        <article-title>Extended depth of field for high-resolution scanning transmission electron microscopy</article-title>
        <source>Microsc. Microanal.</source>
        <year>2011</year>
        <volume>17</volume>
        <fpage>75</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1017/S1431927610094171</pub-id>
        <pub-id pub-id-type="pmid">21122192</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Kushwaha, H. S., Tanwar, S., Rathore, K. S. &amp; Srivastava, S. De-noising filters for TEM (transmission electron microscopy) image of nanomaterials. (eds. Choudhary R. K., Verma M. &amp; Saini S.) in <italic>Conference on Advanced Computing and Communication Technologies</italic>, 276–281 (ABC Group of Publication 2011).</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>An improved Wiener deconvolution filter for high-resolution electron microscopy images</article-title>
        <source>Micron</source>
        <year>2013</year>
        <volume>50</volume>
        <fpage>1</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1016/j.micron.2013.03.005</pub-id>
        <pub-id pub-id-type="pmid">23628497</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ahmed</surname>
            <given-names>SS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Nonparametric denoising methods based on contourlet transform with sharp frequency localization: application to low exposure time electron microscopy images</article-title>
        <source>Entropy</source>
        <year>2015</year>
        <volume>17</volume>
        <fpage>3461</fpage>
        <lpage>3478</lpage>
        <pub-id pub-id-type="doi">10.3390/e17053461</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Roels, J. et al. Bayesian deconvolution of scanning electron microscopy images using point-spread function estimation and non-local regularization. (eds. Principe J.) in <italic>International Conference of the IEEE Engineering in Medicine and Biology Society</italic>, 443–447 (IEEE, 2016).</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Linnenbrügger, N. DeconvolutionJ. <ext-link ext-link-type="uri" xlink:href="https://imagej.nih.gov/ij/plugins/fftj.html">https://imagej.nih.gov/ij/plugins/fftj.html</ext-link> (2001).</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Luisier, F. PureDenoise. <ext-link ext-link-type="uri" xlink:href="http://bigwww.epfl.ch/algorithms/denoise/">http://bigwww.epfl.ch/algorithms/denoise/</ext-link> (2010).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sage</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeconvolutionLab2: an open-source software for deconvolution microscopy</article-title>
        <source>Methods</source>
        <year>2017</year>
        <volume>115</volume>
        <fpage>28</fpage>
        <lpage>41</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ymeth.2016.12.015</pub-id>
        <pub-id pub-id-type="pmid">28057586</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schindelin</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fiji: an open-source platform for biological-image analysis</article-title>
        <source>Nat. Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <fpage>676</fpage>
        <lpage>682</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id>
        <pub-id pub-id-type="pmid">22743772</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goossens</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Dataflow management, dynamic load balancing and concurrent processing for real-time embedded vision applications using Quasar</article-title>
        <source>Int. J. Circuit Theory Appl.</source>
        <year>2018</year>
        <volume>46</volume>
        <fpage>1733</fpage>
        <lpage>1755</lpage>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roels</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An overview of state-of-the-art image restoration in electron microscopy</article-title>
        <source>J. Microsc.</source>
        <year>2018</year>
        <volume>271</volume>
        <fpage>239</fpage>
        <lpage>254</lpage>
        <pub-id pub-id-type="doi">10.1111/jmi.12716</pub-id>
        <pub-id pub-id-type="pmid">29882967</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Crete, F., Dolmiere, T., Ladret, P. &amp; Nicolas, M. The blur effect: perception and estimation with a new no-reference perceptual blur metric. (eds. Rogowitz B. E., Pappas T. N. &amp; Daly S. J.) in <italic>Human Vision and Electronic Imaging XII</italic> 196–206 (SPIE 2007).</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mallat</surname>
            <given-names>SG</given-names>
          </name>
        </person-group>
        <article-title>A theory for multiresolution signal decomposition: the wavelet representation</article-title>
        <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
        <year>1989</year>
        <volume>11</volume>
        <fpage>674</fpage>
        <lpage>693</lpage>
        <pub-id pub-id-type="doi">10.1109/34.192463</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Daubechies</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>The wavelet transform, time-frequency localization and signal analysis</article-title>
        <source>IEEE Trans. Inform. Theory</source>
        <year>1990</year>
        <volume>36</volume>
        <fpage>961</fpage>
        <lpage>1005</lpage>
        <pub-id pub-id-type="doi">10.1109/18.57199</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Donoho</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Johnstone</surname>
            <given-names>JM</given-names>
          </name>
        </person-group>
        <article-title>Ideal spatial adaptation by wavelet shrinkage</article-title>
        <source>Biometrika</source>
        <year>1994</year>
        <volume>81</volume>
        <fpage>425</fpage>
        <lpage>455</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/81.3.425</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Selesnick</surname>
            <given-names>IW</given-names>
          </name>
        </person-group>
        <article-title>The design of approximate Hilbert transform pairs of wavelet bases</article-title>
        <source>IEEE Transac. Signal Proces.</source>
        <year>2002</year>
        <volume>50</volume>
        <fpage>1144</fpage>
        <lpage>1152</lpage>
        <pub-id pub-id-type="doi">10.1109/78.995070</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sorzano</surname>
            <given-names>COS</given-names>
          </name>
          <name>
            <surname>Ortiz</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>López</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rodrigo</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Improved Bayesian image denoising based on wavelets with applications to electron microscopy</article-title>
        <source>Pattern Recogn.</source>
        <year>2006</year>
        <volume>39</volume>
        <fpage>1205</fpage>
        <lpage>1213</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2005.12.009</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Perona</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Malik</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Scale-space and edge detection using anisotropic diffusion</article-title>
        <source>IEEE Transac. Pattern Anal. Mach. Intell.</source>
        <year>1990</year>
        <volume>12</volume>
        <fpage>629</fpage>
        <lpage>639</lpage>
        <pub-id pub-id-type="doi">10.1109/34.56205</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Frangakis</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Hegerl</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Nonlinear anisotropic diffusion in three-dimensional electron microscopy</article-title>
        <source>Scale-Space Theor. Comput. Vis.</source>
        <year>1999</year>
        <volume>1682</volume>
        <fpage>386</fpage>
        <lpage>397</lpage>
        <pub-id pub-id-type="doi">10.1007/3-540-48236-9_34</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Tasdizen, T., Whitaker, R., Marc, R. &amp; Jones, B. Enhancement of cell boundaries in transmission electron microscopy images. (eds. Tubaro S.) in <italic>IEEE International Conference on Image Processing</italic>, Vol. 2, 129–132 (IEEE, 2005).</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Tomasi, C. &amp; Manduchi, R. Bilateral filtering for gray and color images. in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic> 839–846 (IEEE, 1998).</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>ML</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Bajaj</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Chiu</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Applications of a bilateral denoising filter in biological electron microscopy</article-title>
        <source>J. Struct. Biol.</source>
        <year>2003</year>
        <volume>144</volume>
        <fpage>114</fpage>
        <lpage>122</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2003.09.028</pub-id>
        <pub-id pub-id-type="pmid">14643214</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pantelic</surname>
            <given-names>RS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The discriminative bilateral filter: an enhanced denoising filter for electron microscopy data</article-title>
        <source>J. Struct. Biol.</source>
        <year>2006</year>
        <volume>155</volume>
        <fpage>395</fpage>
        <lpage>408</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2006.03.030</pub-id>
        <pub-id pub-id-type="pmid">16774838</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Tikhonov</surname>
            <given-names>AN</given-names>
          </name>
          <name>
            <surname>Leonov</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Yagola</surname>
            <given-names>AG</given-names>
          </name>
        </person-group>
        <source>Nonlinear Ill-posed Problems</source>
        <year>1998</year>
        <publisher-loc>Dordrecht, Netherlands</publisher-loc>
        <publisher-name>Springer Netherlands</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rudin</surname>
            <given-names>LI</given-names>
          </name>
          <name>
            <surname>Osher</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fatemi</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Nonlinear total variation based noise removal algorithms</article-title>
        <source>Physica D</source>
        <year>1992</year>
        <volume>60</volume>
        <fpage>259</fpage>
        <lpage>268</lpage>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Goossens, B., Luong, Q., Pizurica, A. &amp; Philips, W. An improved non-local denoising algorithm. (eds. Bregovic R.) in <italic>International Workshop on Local and Non-Local Approximation in Image Processing</italic>, 143–156 (IEEE, 2008).</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fendrych</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Programmed cell death controlled by ANAC033/SOMBRERO determines root cap organ size in Arabidopsis</article-title>
        <source>Curr. Biolo.</source>
        <year>2014</year>
        <volume>24</volume>
        <fpage>931</fpage>
        <lpage>940</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2014.03.025</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <mixed-citation publication-type="other">Guérin, C. J., Kremer, A., Borghgraef, P. &amp; Lippens, S. Targeted studies using serial block face and focused ion beam scan electron microscopy. <italic>J. Vis. Exp.</italic><bold>150</bold>, e59480 (2019).</mixed-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vanslembrouck</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Three-dimensional reconstruction of the intercalated disc including the intercellular junctions by applying volume scanning electron microscopy</article-title>
        <source>Histochem. Cell Biol.</source>
        <year>2018</year>
        <volume>149</volume>
        <fpage>479</fpage>
        <lpage>490</lpage>
        <pub-id pub-id-type="doi">10.1007/s00418-018-1657-x</pub-id>
        <pub-id pub-id-type="pmid">29508067</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">Sommer, C., Straehle, C., Kothe, U. &amp; Hamprecht, F.A. Ilastik: Interactive learning and segmentation toolkit. (eds. Wernick M. &amp; Tian J.) in <italic>IEEE International Symposium on Biomedical Imaging</italic>, 230–233 (IEEE, 2011).</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Liu, X., Tanaka, M. &amp; Okutomi, M. Noise level estimation using weak textured patches of a single noisy image. (eds. Rao R. &amp; Gurram P.) in <italic>IEEE International Conference on Image Processing</italic>, 665–668 (IEEE, 2012).</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Sage, D. &amp; Chaudhury, K. N. Bilateral filter (ImageJ). <ext-link ext-link-type="uri" xlink:href="http://bigwww.epfl.ch/algorithms/bilateral-filter/">http://bigwww.epfl.ch/algorithms/bilateral-filter/</ext-link> (2011).</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Chaudhury, K. Bilateral filter (Matlab). <ext-link ext-link-type="uri" xlink:href="https://nl.mathworks.com/matlabcentral/fileexchange/56158-fast-and-accurate-bilateral-filtering">https://nl.mathworks.com/matlabcentral/fileexchange/56158-fast-and-accurate-bilateral-filtering</ext-link> (2016).</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Pilny, V. &amp; Janacek, J. Anisotropic diffusion (ImageJ). <ext-link ext-link-type="uri" xlink:href="https://imagej.nih.gov/ij/plugins/anisotropic-diffusion-2d.html">https://imagej.nih.gov/ij/plugins/anisotropic-diffusion-2d.html</ext-link> (2005).</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <mixed-citation publication-type="other">Lopes, D. Anisotropic diffusion (Matlab). <ext-link ext-link-type="uri" xlink:href="https://nl.mathworks.com/matlabcentral/fileexchange/14995-anisotropic-diffusion-perona-malik">https://nl.mathworks.com/matlabcentral/fileexchange/14995-anisotropic-diffusion-perona-malik</ext-link> (2007).</mixed-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Portilla, J. BLS-GSM (Matlab). <ext-link ext-link-type="uri" xlink:href="https://www.io.csic.es/PagsPers/JPortilla/software/file/3-bls-gsm-image-denoising-toolbox-in-matlab">https://www.io.csic.es/PagsPers/JPortilla/software/file/3-bls-gsm-image-denoising-toolbox-in-matlab</ext-link> (2010).</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Behnel, P. &amp; Wagner, T. Non-local means (ImageJ). <ext-link ext-link-type="uri" xlink:href="https://imagej.net/Non_Local_Means_Denoise">https://imagej.net/Non_Local_Means_Denoise</ext-link> (2016).</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Goossens, B. Non-local means (Matlab). <ext-link ext-link-type="uri" xlink:href="https://quasar.ugent.be/bgoossen/download_nlmeans/">https://quasar.ugent.be/bgoossen/download_nlmeans/</ext-link> (2008).</mixed-citation>
    </ref>
  </ref-list>
</back>
