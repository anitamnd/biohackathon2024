<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7355299</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa404</article-id>
    <article-id pub-id-type="publisher-id">btaa404</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Systems Biology and Networks</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Identifiability and experimental design in perturbation studies</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gross</surname>
          <given-names>Torsten</given-names>
        </name>
        <xref ref-type="aff" rid="btaa404-aff1">b1</xref>
        <xref ref-type="aff" rid="btaa404-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa404-aff3">b3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Blüthgen</surname>
          <given-names>Nils</given-names>
        </name>
        <xref ref-type="aff" rid="btaa404-aff1">b1</xref>
        <xref ref-type="aff" rid="btaa404-aff2">b2</xref>
        <xref ref-type="aff" rid="btaa404-aff3">b3</xref>
        <xref ref-type="corresp" rid="btaa404-cor1"/>
        <!--<email>nils.bluethgen@charite.de</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa404-aff1"><label>b1</label><institution>Institut für Pathologie, Charité-Universitätsmedizin Berlin</institution>, Berlin, <country country="DE">Germany</country></aff>
    <aff id="btaa404-aff2"><label>b2</label><institution>IRI Life Sciences, Humboldt University</institution>, Berlin, <country country="DE">Germany</country></aff>
    <aff id="btaa404-aff3"><label>b3</label><institution>Berlin Institute of Health</institution>, Berlin, <country country="DE">Germany</country></aff>
    <author-notes>
      <corresp id="btaa404-cor1">To whom correspondence should be addressed. E-mail: <email>nils.bluethgen@charite.de</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-07-13">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>13</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>Suppl 1</issue>
    <issue-title>ISMB 2020 Proceedings</issue-title>
    <fpage>i482</fpage>
    <lpage>i489</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa404.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>A common strategy to infer and quantify interactions between components of a biological system is to deduce them from the network’s response to targeted perturbations. Such perturbation experiments are often challenging and costly. Therefore, optimizing the experimental design is essential to achieve a meaningful characterization of biological networks. However, it remains difficult to predict which combination of perturbations allows to infer specific interaction strengths in a given network topology. Yet, such a description of identifiability is necessary to select perturbations that maximize the number of inferable parameters.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We show analytically that the identifiability of network parameters can be determined by an intuitive maximum-flow problem. Furthermore, we used the theory of matroids to describe identifiability relationships between sets of parameters in order to build identifiable effective network models. Collectively, these results allowed to device strategies for an optimal design of the perturbation experiments. We benchmarked these strategies on a database of human pathways. Remarkably, full network identifiability was achieved, on average, with less than a third of the perturbations that are needed in a random experimental design. Moreover, we determined perturbation combinations that additionally decreased experimental effort compared to single-target perturbations. In summary, we provide a framework that allows to infer a maximal number of interaction strengths with a minimal number of perturbation experiments.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>IdentiFlow is available at github.com/GrossTor/IdentiFlow.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Deutsche Forschungsgemeinschaft</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001659</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>RTG2424</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Rapid technological progress in experimental techniques allows to quantify a multitude of cellular components in ever increasing level of detail. Yet, to gain a mechanistic understanding of the cell requires to map out causal relations between molecular entities. As causality cannot be inferred from observational data alone (<xref rid="btaa404-B32" ref-type="bibr">Pearl, 2009</xref>), a common approach is to observe the system’s response to a set of localized perturbations (<xref rid="btaa404-B36" ref-type="bibr">Sachs, 2005</xref>) and reconstruct a directed interaction network from such data. Examples for such perturbations are ligands and small molecule inhibitors for the study of signaling pathways, or siRNA knockdowns and CRISPR knockouts of targets in gene regulatory networks.</p>
    <p>A recurring idea within the large body of according network inference methods (<xref rid="btaa404-B28" ref-type="bibr">Marbach <italic>et al.</italic>, 2010</xref>) is to conceive the system as ordinary differential equations and describe edges in the directed network by the entries of an inferred Jacobian matrix (<xref rid="btaa404-B3" ref-type="bibr">Bonneau <italic>et al.</italic>, 2006</xref>; <xref rid="btaa404-B7" ref-type="bibr">Bruggeman, 2002</xref>; <xref rid="btaa404-B15" ref-type="bibr">Gardner, 2003</xref>; <xref rid="btaa404-B24" ref-type="bibr">Kholodenko, 2007</xref>; <xref rid="btaa404-B39" ref-type="bibr">Tegner <italic>et al.</italic>, 2003</xref>; <xref rid="btaa404-B40" ref-type="bibr">Timme, 2007</xref>). Such methods have been successfully applied to describe various types of regulatory networks in different organisms (<xref rid="btaa404-B2" ref-type="bibr">Arrieta-Ortiz <italic>et al.</italic>, 2015</xref>; <xref rid="btaa404-B6" ref-type="bibr">Brandt <italic>et al.</italic>, 2019</xref>; <xref rid="btaa404-B8" ref-type="bibr">Ciofani <italic>et al.</italic>, 2012</xref>; <xref rid="btaa404-B26" ref-type="bibr">Klinger <italic>et al.</italic>, 2013</xref>; <xref rid="btaa404-B27" ref-type="bibr">Lorenz <italic>et al.</italic>, 2009</xref>). They are continuously improved, e.g. to reduce the effect of noise, incorporate heterogeneous datasets, or allow for the analysis of single-cell data (<xref rid="btaa404-B12" ref-type="bibr">Dorel <italic>et al.</italic>, 2018</xref>; <xref rid="btaa404-B17" ref-type="bibr">Greenfield <italic>et al.</italic>, 2013</xref>; <xref rid="btaa404-B23" ref-type="bibr">Kang <italic>et al.</italic>, 2015</xref>; <xref rid="btaa404-B25" ref-type="bibr">Klinger and Blüthgen, 2018</xref>; <xref rid="btaa404-B38" ref-type="bibr">Santra <italic>et al.</italic>, 2018</xref>, <xref rid="btaa404-B37" ref-type="bibr">2013</xref>) and have thus become a standard research tool. Nevertheless, identifiability (<xref rid="btaa404-B16" ref-type="bibr">Godfrey and DiStefano, 1985</xref>; <xref rid="btaa404-B20" ref-type="bibr">Hengl <italic>et al.</italic>, 2007</xref>) of the inferred network parameters within a specific perturbation setup has not yet been rigorously analyzed, even though a limited number of practically feasible perturbations renders many systems underdetermined (<xref rid="btaa404-B3" ref-type="bibr">Bonneau <italic>et al.</italic>, 2006</xref>; <xref rid="btaa404-B10" ref-type="bibr">De Smet and Marchal, 2010</xref>; <xref rid="btaa404-B29" ref-type="bibr">Meinshausen <italic>et al.</italic>, 2016</xref>). Some inference methods do apply different heuristics, such as network sparsity, to justify parameter regularization (<xref rid="btaa404-B3" ref-type="bibr">Bonneau <italic>et al.</italic>, 2006</xref>; <xref rid="btaa404-B15" ref-type="bibr">Gardner, 2003</xref>; <xref rid="btaa404-B39" ref-type="bibr">Tegner <italic>et al.</italic>, 2003</xref>), or numerically analyze identifiability through an exploration of the parameter space using a profile likelihood approach (<xref rid="btaa404-B34" ref-type="bibr">Raue <italic>et al.</italic>, 2009</xref>). Yet, neither approach provides a structural understanding on how parameter identifiability relates to network topology and the targets of the perturbations. However, such structural understanding is required to systematically define identifiable effective network models and to optimize the sequence of applied perturbations. The latter is of particular interest because perturbation experiments are often costly and laborious, which demands to determine the minimal set of perturbations that reveals a maximal number of network parameters. To address these challenges, this work derives analytical results that explain the identifiability of network parameters in terms of simple network properties, which allow to optimize the experimental design.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>We consider a network of <inline-formula id="IE1"><mml:math id="IM1"><mml:mi mathvariant="normal">n</mml:mi></mml:math></inline-formula> interacting nodes whose abundances, <bold><italic>x</italic></bold>, evolve in time according to a set of (unknown) differential equations
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
    <p>The network can be experimentally manipulated by <inline-formula id="IE2"><mml:math id="IM2"><mml:mi mathvariant="normal">p</mml:mi></mml:math></inline-formula> different types of perturbations, each represented by one of the <inline-formula id="IE3"><mml:math id="IM3"><mml:mi mathvariant="normal">p</mml:mi></mml:math></inline-formula> entries of parameter vector <bold><italic>p</italic></bold>. We only consider binary perturbations that can either be switched on or off. Without loss of generality, we define <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> such that the <italic>k</italic>-th type of perturbation changes parameter <italic>p<sub>k</sub></italic> from its unperturbed state <italic>p<sub>k</sub></italic> = 0 to a perturbed state <italic>p<sub>k</sub> </italic>=<italic> </italic>1.</p>
    <p>The main assumption is that after a perturbation the observed system relaxes into stable steady state, <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:mo mathvariant="bold-italic">φ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, of <xref ref-type="disp-formula" rid="E1">Equation (1)</xref>. Stability arises when the real parts of the eigenvalue of the <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:math></inline-formula> Jacobian matrix, <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, evaluated at these fixed points, <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, are all negative within the experimentally accessible perturbation space (no bifurcation points). This implies that <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is invertible, for which case the implicit function theorem states that <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:mi mathvariant="bold-italic">φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is unique and continuously differentiable, and
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mo>φ</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:math></inline-formula> Sensitivity matrix entry, <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, quantifies the effect of the <italic>j</italic>-th perturbation type on node <italic>i</italic>. Dropping functions’ arguments is shorthand for the evaluation at the unperturbed state, <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">0</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">0</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
    <sec>
      <title>2.1 A linear response approximation</title>
      <p>A perturbation experiment consists of q perturbations, each of which involves a single or a combination of perturbation types, represented by binary vector <bold><italic>p</italic></bold>, which forms the columns of the <inline-formula id="IE16"><mml:math id="IM15"><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">q</mml:mi></mml:mrow></mml:math></inline-formula> design matrix <italic>P</italic>. The steady states after each perturbation, <inline-formula id="IE17"><mml:math id="IM16"><mml:mrow><mml:mi mathvariant="bold-italic">φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, are measured and their differences to the unperturbed steady state form the columns of the <inline-formula id="IE18"><mml:math id="IM17"><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">q</mml:mi></mml:mrow></mml:math></inline-formula> global response matrix <italic>R</italic>. Assuming that perturbations are sufficiently mild, the steady state function becomes nearly linear within the relevant parameter domain
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mo mathvariant="bold-italic">φ</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>φ</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">0</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mo>φ</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Replacing the partial derivative with the help of <xref ref-type="disp-formula" rid="E2">Equation (2)</xref> and writing the equation for all <inline-formula id="IE19"><mml:math id="IM18"><mml:mi mathvariant="normal">q</mml:mi></mml:math></inline-formula> perturbations yields
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mrow><mml:mi>R</mml:mi><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>S</mml:mi><mml:mi>P</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>This equation relates the known experimental design matrix, <italic>P</italic>, and the measured global responses, <italic>R</italic>, to quantities that we wish to infer: the nodes’ interaction strengths, <italic>J</italic>, and their sensitivity to perturbations, <italic>S</italic>.</p>
      <p>A dynamic system defined by rates <inline-formula id="IE20"><mml:math id="IM19"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, with any full rank <inline-formula id="IE21"><mml:math id="IM20"><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:math></inline-formula> matrix <italic>W</italic>, has the same steady states but different Jacobian and sensitivity matrices, namely <inline-formula id="IE22"><mml:math id="IM21"><mml:mrow><mml:mi>W</mml:mi><mml:mi>J</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE23"><mml:math id="IM22"><mml:mrow><mml:mi>W</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula>, as the original system, defined by <xref ref-type="disp-formula" rid="E1">Equation (1)</xref>. It is thus impossible to uniquely infer <italic>J</italic> or <italic>S</italic> from observations of the global response alone, and prior knowledge in matrices <italic>J</italic> and <italic>S</italic> is required to further constrain the problem. In the following, we assume that prior knowledge exists about the network topology, i.e. about zero entries in <italic>J</italic>, as they correspond to non-existent edges. Likewise, we assume that the targets of the different types of perturbations are known, which implies known zero entries in <italic>S</italic> for non-targeted nodes. In line with prior studies (<xref rid="btaa404-B24" ref-type="bibr">Kholodenko, 2007</xref>), we also fix the diagonal of the Jacobian matrix
<disp-formula id="E5"><mml:math id="M5"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1.</mml:mn></mml:mrow></mml:math></disp-formula></p>
      <p>Thus, for the <italic>i</italic>-th row of <italic>J</italic>, we can define index lists <inline-formula id="IE24"><mml:math id="IM23"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE25"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to identify its known and unknown entries. The first indicates missing edges or the self loop and the second edges going into node <italic>i</italic>. These lists have <inline-formula id="IE26"><mml:math id="IM25"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE27"><mml:math id="IM26"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> entries, respectively, with
<disp-formula id="E6"><label>(5)</label><mml:math id="M6"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">n</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Analogously, for the <italic>i</italic>-th row of <italic>S</italic>, we define index lists <inline-formula id="IE28"><mml:math id="IM27"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE29"><mml:math id="IM28"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, with
<disp-formula id="E7"><label>(6)</label><mml:math id="M7"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>to report its unknown and known entries. These describe the perturbations that do not target or, respectively, target node <italic>i</italic>.</p>
      <p>We show in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S1 that <xref ref-type="disp-formula" rid="E4">Equation (4)</xref> can be repartitioned to obtain a system of linear equations for each row in <italic>J</italic> and <italic>S</italic>, exclusively in the
<disp-formula id="E8"><mml:math id="M8"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></disp-formula>unknown parameters, which we collect in vector <inline-formula id="IE30"><mml:math id="IM29"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Thus, there is a <inline-formula id="IE31"><mml:math id="IM30"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> matrix <italic>V<sub>i</sub></italic>, such that
<disp-formula id="E9"><label>(7)</label><mml:math id="M9"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>∀</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE32"><mml:math id="IM31"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is some specific solution to the equation system. We further show in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S1 that <italic>V<sub>i</sub></italic> is a basis of the kernel of
<disp-formula id="E10"><label>(8)</label><mml:math id="M10"><mml:mrow><mml:msub><mml:mrow><mml:mo>Ψ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mn>0</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE33"><mml:math id="IM32"><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE34"><mml:math id="IM33"><mml:mrow><mml:msub><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the identity and zero matrix of annotated dimensionality. The <inline-formula id="IE35"><mml:math id="IM34"><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mo>×</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> matrix <inline-formula id="IE36"><mml:math id="IM35"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> consists of the columns of <inline-formula id="IE37"><mml:math id="IM36"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> that are selected by indices in <inline-formula id="IE38"><mml:math id="IM37"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Finally, <inline-formula id="IE39"><mml:math id="IM38"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>×</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:math></inline-formula> matrix <inline-formula id="IE40"><mml:math id="IM39"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE41"><mml:math id="IM40"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:math></inline-formula> matrix <inline-formula id="IE42"><mml:math id="IM41"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> shall be formed by taking rows of <italic>S<sup>T</sup></italic> according to indices in <inline-formula id="IE43"><mml:math id="IM42"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE44"><mml:math id="IM43"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. These matrix partitionings are demonstrated for a toy example in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S1</xref>. Furthermore, in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S1, we derive the following expression for the solution space dimensionality
<disp-formula id="E11"><mml:math id="M11"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>−</mml:mo><mml:mtext>rank</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <fig id="btaa404-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>A maximum-flow problem determines the identifiability of interaction strengths and perturbation sensitivities when reconstructing a network from perturbation data. (<bold>A</bold>) Example network with three perturbations (yellow squares) to illustrate the algorithm. (<bold>B</bold>) The corresponding flow network to determine the identifiability of the edges into node 3 and the sensitivity of node 3 to perturbations. The flow passing through any node (besides source and sink) must not exceed one. A path carrying the resulting maximal flow of one is denoted in red (note that it is not unique). (<bold>C</bold>) The interaction strength between a given node and node 3 is identifiable if and only if the maximum flow is reduced after removing that node’s edge to the sink node. In this example, there are alternative max-flow paths that re-establish a unit-flow after removal of the according edges. Thus, the respective interaction strengths are non-identifiable. (<bold>D</bold>) Similarly, the sensitivity of node 3 to perturbation 3 is identifiable, if and only if the depicted extension of the flow network does not increase the maximum flow. In this example, the maximum flow is increased by one, again revealing non-identifiability. Note that such flow representations provide an intuitive understanding on how alterations in the network or perturbation setting affect identifiability. For example, it is obvious that if the toy model would not contain an edge from node 3 to 4, the edge from 2 to 3 would become identifiable</p>
        </caption>
        <graphic xlink:href="btaa404f1"/>
      </fig>
    </sec>
    <sec>
      <title>2.2 Identifiability conditions</title>
      <p>The system is underdetermined when <inline-formula id="IE45"><mml:math id="IM44"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. But independent of <inline-formula id="IE46"><mml:math id="IM45"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, a parameter is identifiable if the solution space is orthogonal to its according axis direction. This idea can be expressed as algebraic identifiability conditions. Accordingly, we show in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S1 that the unknown interaction strength <inline-formula id="IE47"><mml:math id="IM46"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is identifiable if and only if
<disp-formula id="E12"><label>(9)</label><mml:math id="M12"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>rank</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∖</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>rank</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE48"><mml:math id="IM47"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∖</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is matrix <inline-formula id="IE49"><mml:math id="IM48"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> with the <italic>j</italic>-th column removed. Furthermore, the unknown sensitivity <inline-formula id="IE50"><mml:math id="IM49"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is identifiable if and only if
<disp-formula id="E13"><label>(10)</label><mml:math id="M13"><mml:mrow><mml:mtext>rank</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>rank</mml:mtext><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="true">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE51"><mml:math id="IM50"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> denotes the <italic>j</italic>-th row of matrix <inline-formula id="IE52"><mml:math id="IM51"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. However, the ranks depend on the unknown network parameters themselves and can thus not be directly computed. Yet, we can show how a reasonable assumption makes this possible and allows to express the identifiability conditions as an intuitive maximum-flow problem.</p>
      <p>First, we rewrite the identity <inline-formula id="IE53"><mml:math id="IM52"><mml:mrow><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as
<disp-formula id="E14"><mml:math id="M14"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:mrow/><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with <italic>δ<sub>kl</sub></italic> being the Kronecker delta (recall that <inline-formula id="IE54"><mml:math id="IM53"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). We can view this equation as a recurrence relation and repeatedly replace the <inline-formula id="IE55"><mml:math id="IM54"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> terms in the sum. The sum contains non-vanishing terms for each edge that leaves node <italic>l</italic>. Therefore, each replacement leads to the next downstream node, so that eventually one arrives at
<disp-formula id="E15"><mml:math id="M15"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mo> </mml:mo><mml:mo>↣</mml:mo><mml:mo> </mml:mo><mml:mi>k</mml:mi><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>with</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>l</mml:mi><mml:mo>↣</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">ω</mml:mi><mml:mo> </mml:mo><mml:mo>∈</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>Ω</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>→</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow/></mml:munderover></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">ω</mml:mi><mml:mo>|</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>ω</mml:mo></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where the set <inline-formula id="IE56"><mml:math id="IM55"><mml:mrow><mml:msub><mml:mrow><mml:mo>Ω</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>→</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains elements, <inline-formula id="IE57"><mml:math id="IM56"><mml:mi mathvariant="bold-italic">ω</mml:mi></mml:math></inline-formula>, for every path from node <italic>l</italic> to node <italic>k</italic>, each of which lists the nodes along that path. Strictly speaking, these elements are walks rather than paths because some nodes will appear multiple times if loops exist between <italic>l</italic> and <italic>k</italic>. In fact, with loops, <inline-formula id="IE58"><mml:math id="IM57"><mml:mrow><mml:msub><mml:mrow><mml:mo>Ω</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>→</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains an infinite number of walks of unbounded lengths. But as the real part of all eigenvalues of <italic>J</italic> is assumed negative, the associated products of interaction strengths converge to zero with increasing walk length.</p>
      <p>To simplify our notation, we want to expand the network by considering perturbations <inline-formula id="IE59"><mml:math id="IM58"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as additional nodes, each with edges that are directed toward that perturbation’s targets. Furthermore, letting the interaction strength associated with these new edges be given by the appropriate entries in <italic>S</italic> we can rewrite the matrix product
<disp-formula id="E16"><mml:math id="M16"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>↣</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE60"><mml:math id="IM59"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE61"><mml:math id="IM60"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denote the <italic>l</italic>-th entry in <inline-formula id="IE62"><mml:math id="IM61"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE63"><mml:math id="IM62"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, respectively. As every finite-dimensional matrix has a rank decomposition, we can further write
<disp-formula id="E17"><label>(11)</label><mml:math id="M17"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE64"><mml:math id="IM63"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>×</mml:mo><mml:mtext>rank</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> matrix <inline-formula id="IE65"><mml:math id="IM64"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE66"><mml:math id="IM65"><mml:mrow><mml:mtext>rank</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> matrix <italic>Y<sub>i</sub></italic> have full rank. Finding such a decomposition therefore reveals the rank of <inline-formula id="IE67"><mml:math id="IM66"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. To this end, we propose
<disp-formula id="E18"><mml:math id="M18"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>↣</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>and</mml:mtext><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mo>↣</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>y<sub>in</sub></italic> denotes the <italic>n</italic>-th component of a certain list of nodes <inline-formula id="IE68"><mml:math id="IM67"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. In order for <xref ref-type="disp-formula" rid="E17">Equation (11)</xref> to hold, it must be possible to split each path from any perturbation <inline-formula id="IE69"><mml:math id="IM68"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to any node <inline-formula id="IE70"><mml:math id="IM69"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> into a section that leads from the perturbation to a node in <inline-formula id="IE71"><mml:math id="IM70"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and a subsequent section that leads from this node to <inline-formula id="IE72"><mml:math id="IM71"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For an extended graph that includes an additional source node, with outgoing edges to each perturbation in <inline-formula id="IE73"><mml:math id="IM72"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and an additional sink node, with incoming edges from all nodes in <inline-formula id="IE74"><mml:math id="IM73"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (see <xref ref-type="fig" rid="btaa404-F1">Fig. 1B</xref>), <inline-formula id="IE75"><mml:math id="IM74"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> thus constitutes a vertex cut whose removal disconnects the graph and separates the source and the sink node into distinct connected components. Next, we want to show that if <inline-formula id="IE76"><mml:math id="IM75"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a minimum vertex cut, the rank of <inline-formula id="IE77"><mml:math id="IM76"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> equals the size of <inline-formula id="IE78"><mml:math id="IM77"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Because <xref ref-type="disp-formula" rid="E17">Equation (11)</xref> is a rank decomposition this is equivalent to showing that the according matrices <inline-formula id="IE79"><mml:math id="IM78"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <italic>Y<sub>i</sub></italic> have full rank. To do so, we apply Menger’s theorem (<xref rid="btaa404-B30" ref-type="bibr">Menger, 1927</xref>), which states that the minimal size of <inline-formula id="IE80"><mml:math id="IM79"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> equals the maximum number of vertex-disjoint paths from the source to the sink node. This also implies that each of these vertex-disjoint paths goes through a different node of the vertex cut <inline-formula id="IE81"><mml:math id="IM80"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Recall that entries in <inline-formula id="IE82"><mml:math id="IM81"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> constitute sums over paths from perturbation to vertex cut nodes, so that we could write
<disp-formula id="E19"><mml:math id="M19"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE83"><mml:math id="IM82"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> only contains the vertex-disjoint paths and <inline-formula id="IE84"><mml:math id="IM83"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the sums over the remaining paths. As each of these vertex-disjoint paths ends in a different vertex cut node, any column in <inline-formula id="IE85"><mml:math id="IM84"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> can contain no more than a single non-zero entry. Furthermore, as a consequence of Menger’s theorem there are exactly <inline-formula id="IE86"><mml:math id="IM85"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> non-zero columns. Because these paths are indeed vertex disjoint also no row in <inline-formula id="IE87"><mml:math id="IM86"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> has more than a single non-zero entry. Thus, the non-zero columns are independent, showing that <inline-formula id="IE88"><mml:math id="IM87"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> has full rank. We further assume that adding <inline-formula id="IE89"><mml:math id="IM88"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ϒ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> does not reduce rank, which also gives <inline-formula id="IE90"><mml:math id="IM89"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> full rank. In the context of biological networks, there are two different scenarios that could lead to a violation of this non-cancellation assumption. The first is that network parameters are perfectly tuned to lie inside a specific algebraic variety (a manifold in parameter space) such that certain columns (or rows) of <inline-formula id="IE91"><mml:math id="IM90"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> become linearly dependent or zero. This would e.g. be the case if, for a given vertex-disjoint path, there also is an alternative path whose associated product of interaction strengths has the same magnitude as that of the vertex-disjoint path but opposite sign, making their sum vanish. However, we consider it implausible for biological networks to be fine-tuned to such a degree that they could achieve such perfect self-compensation of perturbations, and rule out this possibility. A more realistic scenario is that network parameters are zero and thereby lead to zero columns or rows in <inline-formula id="IE92"><mml:math id="IM91"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> or <italic>Y<sub>i</sub></italic>, which make these matrices rank deficient. In practice, such zero-parameters can occur e.g. if a perturbation is not effective on (one of) its target(s), or if robustness effects (<xref rid="btaa404-B14" ref-type="bibr">Fritsche-Guenther <italic>et al.</italic>, 2011</xref>) obstruct the propagation of the perturbation signal at a certain link. But essentially, this means that our prior knowledge about the network included practically non-existing links or perturbation targets. If the network topology and perturbation targets are correctly stated and take these effects into consideration, there will be no zero-parameters and therefore the non-cancellation assumption holds. We explore the consequences of incomplete or flawed prior knowledge in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S5.</p>
      <p>Having shown <inline-formula id="IE93"><mml:math id="IM92"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϒ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to be of full rank, the same line of reasoning will demonstrate a full rank for matrix <italic>Y<sub>i</sub></italic> as well, which implies that indeed
<disp-formula id="E20"><label>(12)</label><mml:math id="M20"><mml:mrow><mml:mtext>rank</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE94"><mml:math id="IM93"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a minimum vertex cut between source and sink node. This equation has the crucial benefit that <inline-formula id="IE95"><mml:math id="IM94"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> does not depend on any unknown parameters and can be computed as the maximum flow from source to sink node with all nodes having unit capacity (<xref rid="btaa404-B1" ref-type="bibr">Ahuja <italic>et al.</italic>, 1993</xref>), as detailed in <xref ref-type="fig" rid="btaa404-F1">Figure 1B</xref>. A flow is defined as a mapping from a network edge to a positive real number that is smaller than the edge’s capacity. Additionally, the sum of flows entering a node must equal the sum of the flows exiting a node, except for the source and the sink nodes. The maximum-flow problem is to attribute (permissible) flow values to all edges, such that the sum of flows leaving the source (which is equal to the sum of flows entering the sink) is maximal. In our case, however, we did not define edge but node capacities, meaning that the sum of flows passing through any node must not exceed one. Yet, we can express such unit node capacities as unit edge capacities in an extended flow network. It is defined by replacing every node by an <italic>in</italic>- and an <italic>out</italic>-node, where all incoming edges target the <italic>in</italic>-node, all outgoing edges start from the <italic>out</italic>-node, and the <italic>in</italic>-node has an edge to the <italic>out</italic>-node.</p>
      <p>This maximum-flow problem allows to express the algebraic identifiability conditions (9) and (10) in terms of network properties, providing an intuitive relationship between network topology, perturbation targets and identifiability. Specifically, <inline-formula id="IE96"><mml:math id="IM95"><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is identifiable if and only if the removal of the edge from node <inline-formula id="IE97"><mml:math id="IM96"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to the sink node reduces the maximum flow of the network, see <xref ref-type="fig" rid="btaa404-F1">Figure 1C</xref>, and <inline-formula id="IE98"><mml:math id="IM97"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is identifiable if and only if the maximum flow does not increase when an additional edge connects the source node with perturbation node <inline-formula id="IE99"><mml:math id="IM98"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, see <xref ref-type="fig" rid="btaa404-F1">Figure 1D</xref>. In <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S5, we simulate a perturbation experiment to numerically verify these findings.</p>
    </sec>
    <sec>
      <title>2.3 Identifiability relationships</title>
      <p>Often, network inference is an underdetermined problem (<xref rid="btaa404-B10" ref-type="bibr">De Smet and Marchal, 2010</xref>; <xref rid="btaa404-B18" ref-type="bibr">Gross <italic>et al.</italic>, 2019</xref>). Thus, to achieve identifiable effective network models, certain parameters have to be set to constant values, such that the remaining parameters become uniquely determinable. This requires an understanding of the identifiability relationships between parameters, i.e. we need to know which parameter becomes identifiable when other parameters are fixed. Supplementary Equation (18) formally relates these relationships to the ranks of certain linear subspaces of the range of <inline-formula id="IE100"><mml:math id="IM99"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> as defined in <xref ref-type="disp-formula" rid="E9">Equation (7)</xref>. It shows that for each network node there is a set of parameters amongst which identifiability relationships can exist. Such a set contains those interaction strengths that quantify the edges, which target the associated node, and the associated node’s sensitivities to perturbations. Furthermore, we show in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S2 that the identifiability relationships of such parameter groups can be described as a matroid (<xref rid="btaa404-B41" ref-type="bibr">Whitney, 1935</xref>). Matroids can be defined in terms of their circuits. Here, a circuit is a set of parameters with the property that any of its parameters becomes identifiable if and only if all others are fixed. Therefore, circuits describe all minimal parameter subsets that could be fixed to obtain an identifiable network.</p>
      <p>We enumerated the set of circuits with an incremental polynomial-time algorithm (<xref rid="btaa404-B4" ref-type="bibr">Boros <italic>et al.</italic>, 2003</xref>). This algorithm requires an independence oracle that indicates linear dependence of subsets of columns of <inline-formula id="IE101"><mml:math id="IM100"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S2 shows that we can construct such an oracle by considering linear dependence within the dual matroid, which amounts to determining
<disp-formula id="E21"><mml:math id="M21"><mml:mrow><mml:mtext>rank</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="script">P</mml:mi><mml:mo stretchy="false">˜</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>J</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Matrices <inline-formula id="IE102"><mml:math id="IM101"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE103"><mml:math id="IM102"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are truncated identity matrices defined in Supplementary Equations (19) and (20). Yet, the crucial point of this expression is that it has the same form as the left-hand side of <xref ref-type="disp-formula" rid="E20">Equation (12)</xref>. We can therefore conveniently determine it by solving a simple maximum-flow problem.</p>
      <p><xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S2 shows how to transform the circuits into cyclic flats. These provide a more convenient representation of the identifiability relationships, which we clarify at an example in <xref ref-type="fig" rid="btaa404-F2">Figure 2</xref>. Finally, certain scenarios constrain the choice of fixable parameters, e.g. when quantifying multiple isogenic cell lines (<xref rid="btaa404-B5" ref-type="bibr">Bosdriesz <italic>et al.</italic>, 2018</xref>). <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S2 describes a greedy algorithm that takes such preferences into consideration.</p>
    </sec>
    <sec>
      <title>2.4 Experimental design strategies</title>
      <p>We assume that we are given a set of <inline-formula id="IE104"><mml:math id="IM103"><mml:mi mathvariant="normal">p</mml:mi></mml:math></inline-formula> perturbations, each of which targets a different subset of nodes. In the following, we will define different experimental design strategies that suggest different sequences in which these perturbations should be applied. By means of our understanding of identifiability, we can determine <italic>ξ<sub>i</sub></italic>, the number of identifiable edges after having performed the first <italic>i</italic> perturbations in such a sequence. Our goal is to find a strategy for which this number of identifiable edges increases fastest. Thus, as a measure of a sequence’s optimality, we can define an identifiability area under the curve (AUC)
<disp-formula id="E22"><label>(13)</label><mml:math id="M22"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">p</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>ξ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>ξ</mml:mo></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>ξ</italic> is the number of edges in the network. For any network and perturbation sequence, this score ranges between 0 and 1.</p>
      <p>Consider a directed graph with <inline-formula id="IE105"><mml:math id="IM104"><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> nodes, each of which represents a different subset of the <inline-formula id="IE106"><mml:math id="IM105"><mml:mi mathvariant="normal">p</mml:mi></mml:math></inline-formula> perturbations. Each edge in this graph shall connect such a perturbation subset to one of its proper supersets that contains one additional perturbation. Then, we can view perturbation sequences as paths on this graph, starting from the empty perturbation subset. We shall define design strategies as rules that describe which perturbation(s) could be performed next, given the perturbations that have already been applied. These rules thus represent edges on the graph and will therefore determine which perturbation sequences are associated with a given strategy. To enumerate these perturbation sequences, we implemented a depth-first search. The details of our algorithm are described in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S3. Here, we provide an overview over the different implemented strategies.</p>
      <p>An obvious approach to design an optimal strategy is to simply consider all remaining perturbations as next possible perturbations. This <italic>exhaustive</italic> strategy is therefore associated with the entire set of possible perturbation sequences. We are therefore guaranteed to find those sequences amongst them that maximize the identifiability AUC. On the downside, this strategy quickly becomes computationally intractable when the set of perturbations becomes large (we analyze computational complexity of the different strategies in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S3). Therefore, we also implemented strategies with more restrictive rules. A <italic>random</italic> strategy will, at each step, randomly choose one of the remaining perturbations. This will thus result in a single random perturbation sequence. A <italic>naive</italic> strategy is based on the notion that perturbations should be more informative if they cause a response at a large number of nodes. Thus, this strategy considers the perturbed nodes for each of the remaining perturbations and computes the number of network nodes to which these are connected to by a path. It then selects those perturbations as possible next perturbations, which maximize this number. In contrast, the <italic>single-target</italic> strategy makes use of the maximum-flow approach, as it selects perturbations that will, first, maximize the number of identifiable edges, and second, minimize the overall dimensionality of the solution space, <inline-formula id="IE107"><mml:math id="IM106"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Finally, the <italic>multi-target</italic> strategy is similar to the single-target approach, except that it not only considers single but combinations of perturbations. That is, we allow any perturbation combination to be considered as a single perturbation experiment, which will then perturb all targets of the combined perturbations. Clearly, this can open an excessively large search space, when the number of possible perturbations is big. We therefore implemented a tractable, step-wise procedure to build up perturbation combinations, which is described in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S3.</p>
      <p>As these strategies allow for multiple perturbations to be considered next in the sequence, they are associated not only to a single but to many sequences (which we enumerate by the depth-first search). Amongst them, we can then choose the ones that maximize the optimality score defined in <xref ref-type="disp-formula" rid="E22">Equation (13)</xref>. However, for large systems, the number of these strategy-associated sequences can become too large to be completely enumerated. We therefore also implemented an approach to randomly sample from this sequence set, as follows. For a given strategy, instead of considering the entire set of possible next perturbations, we only randomly pick a single one. The strategy will then be associated with a single sequence. Every time we repeat this procedure, we randomly sample from the (original) strategy-associated sequences.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Identifiability and identifiability relationships</title>
      <p>Perturbation experiments are frequently used to infer and quantify interactions in biological networks. But whether a given network edge can indeed be uniquely quantified from experimentally observed perturbation responses depends on the specific targets of the perturbations and the topology of the network. In order to build interpretable network models and guide experimental design, we need to elucidate this identifiability status of the network parameters. Here, we view a biological system as a weighted directed network, and assume that perturbations are sufficiently mild to cause a linear steady state response. This allows to relate the interaction strengths between nodes (i.e. the entries in the Jacobian matrix <italic>J</italic>) and the sensitivity to perturbations (i.e. the entries in the sensitivity matrix <italic>S</italic>) to the measured responses [<xref ref-type="disp-formula" rid="E4">Equation (4)]</xref>, an approach that is widely known as modular response analysis (<xref rid="btaa404-B24" ref-type="bibr">Kholodenko, 2007</xref>). We derived analytical identifiability conditions [<xref ref-type="disp-formula" rid="E12">Equations (9)</xref> and <xref ref-type="disp-formula" rid="E13">(10)]</xref> that describe whether this relation allows to uniquely determine the network parameters for the given network topology and the experimental setting. However, these conditions cannot be directly evaluated, as they depend on the (unknown) network parameters themselves. But instead, they can be reformulated as intuitive maximum-flow problems, if one disregards singular conditions of self-cancelling perturbations.</p>
      <p>The derivation and details are given in Section 2 but briefly, to determine the identifiability of either the interaction strength from node <italic>j</italic> to node <italic>i</italic>, or the sensitivity of node <italic>i</italic> to perturbation <italic>p</italic>, the following flow network is considered: The original network is extended by (i) adding a node for each perturbation that does not target node <italic>i</italic> and connecting it to the respective perturbation’s target(s), (ii) adding a ‘source’ node that connects to all those perturbation nodes and (iii) having all nodes that target node <italic>i</italic> connect to an additional ‘sink’ node, see <xref ref-type="fig" rid="btaa404-F1">Figure 1B</xref>. Furthermore, all nodes (except source and sink) and all edges have a flow capacity of one. To reveal identifiability, we need to determine the network’s maximum flow from source to sink. This is a classic problem in computer science, which we solve using the Edmonds–Karp algorithm (<xref rid="btaa404-B11" ref-type="bibr">Dinic, 1970</xref>; <xref rid="btaa404-B13" ref-type="bibr">Edmonds and Karp, 1972</xref>) as implemented in the Networkx package (<xref rid="btaa404-B19" ref-type="bibr">Hagberg <italic>et al.</italic>, 2008</xref>). Then, the interaction strength from node <italic>j</italic> to node <italic>i</italic> is identifiable if and only if the removal of the edge from node <italic>j</italic> to the sink node reduces the maximum flow, see <xref ref-type="fig" rid="btaa404-F1">Figure 1C</xref>. Similarly, node <italic>i’</italic>s sensitivity to perturbation <italic>p</italic> is identifiable if and only if the maximum flow does not increase after linking the source to an additional node that is in turn connected to all targets of perturbation <italic>p</italic>, see <xref ref-type="fig" rid="btaa404-F1">Figure 1D</xref>.</p>
      <p>Often, experimental settings do not allow determining all unknown parameters (<xref rid="btaa404-B10" ref-type="bibr">De Smet and Marchal, 2010</xref>; <xref rid="btaa404-B18" ref-type="bibr">Gross <italic>et al.</italic>, 2019</xref>). Nevertheless, they constrain the solution space such that after fixing one or multiple parameters, others become identifiable. We found that such identifiability relationships can be described by matroids, which are combinatorial structures that generalize the notion of linear dependence (see Section 2). This is demonstrated for an example perturbation experiment on the network displayed in <xref ref-type="fig" rid="btaa404-F2">Figure 2A</xref>.
</p>
      <fig id="btaa404-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>(<bold>A</bold>) An example network with three perturbations (yellow squares), where nodes 4 and 5 are associated with non-identifiable parameters (grey). (<bold>B</bold>) Their identifiability relationships are represented by the lattices of cyclic flats of rank <italic>r</italic>. Each cyclic flat consists of the annotated elements in addition to elements from its preceding cyclic flats. All parameters of a cyclic flat with rank <italic>r</italic> become identifiable if at least <italic>r</italic> independent flat parameters are fixed</p>
        </caption>
        <graphic xlink:href="btaa404f2"/>
      </fig>
      <p>Each node is associated with a set of parameters amongst which identifiability relationships can exist. Such a set contains those interaction strengths, which quantify the edges that target the associated node, and that node’s sensitivities to perturbations. Here, nodes 4 and 5 are associated with sets of non-identifiable parameters. For example, for node 5, these are <italic>J</italic><sub>56</sub> and <italic>S</italic><sub>53</sub>. We represent the matroid for such a parameter set as a hierarchy (lattice) of cyclic flats, as shown in <xref ref-type="fig" rid="btaa404-F2">Figure 2B</xref>. A cyclic flat is a set of parameters with an associated rank <italic>r</italic>. It has the property that all of its parameters become identifiable, if amongst them at least <italic>r</italic> independent parameters are fixed. Parameters are independent if none of them becomes identifiable after fixing the others. For node 5, parameters <italic>J</italic><sub>56</sub> and <italic>S</italic><sub>53</sub> only form a single cyclic flat with <italic>r </italic>=<italic> </italic>1, and thus fixing either one parameter makes the other identifiable. The identifiability relationships among the six parameters associated with node 4 are more complex. For example, <italic>J</italic><sub>43</sub> and <italic>S</italic><sub>41</sub> form a cyclic flat with <italic>r </italic>=<italic> </italic>1 and thus fixing one, fixes the other. Yet together with <italic>J</italic><sub>45</sub> and <italic>S</italic><sub>43</sub>, they form a cyclic flat with <italic>r </italic>=<italic> </italic>2, thus fixing e.g. <italic>S</italic><sub>41</sub> and <italic>S</italic><sub>43</sub> will allow unique determination of <italic>J</italic><sub>43</sub> and <italic>J</italic><sub>45</sub>. In contrast, fixing <italic>J</italic><sub>43</sub> and <italic>S</italic><sub>41</sub> does not render any other parameter identifiable because they are not independent. This illustrates how the matroid description allows to generate effective models, i.e. models where a minimum number of parameters has to be set to fixed values to allow for a unique estimation of all other parameters. Importantly, the lattice of cyclic flats can be derived without specifying unknown parameters by solving a sequence of maximum-flow problems (see Section 2).</p>
      <p>Collectively, our results provide a concise framework to algorithmically determine identifiability of network parameters and to construct identifiable effective networks when the experimental setting does not suffice to uniquely determine the original network structure.</p>
    </sec>
    <sec>
      <title>3.2 Experimental design</title>
      <p>Next, we applied our identifiability analysis to optimize experimental design, i.e. to minimize the number of perturbation experiments that is required to uniquely determine a network’s interaction strengths. For this, we designed the following strategies to determine an optimal sequence from a set of available perturbations: The <italic>exhaustive</italic> strategy considers all possible sequences and selects the best performing amongst them. As this approach entails a prohibitive computational effort for larger networks, we also designed approaches that select perturbation sequences in a step-wise manner: The <italic>single-target</italic> strategy chooses next perturbations such that they increases the number of identifiable edges most. The <italic>multi-target</italic> strategy is similar to the single-target strategy except that it not only considers a single but any combination of perturbations. In contrast, the <italic>naive</italic> strategy does not use our identifiability analysis. Rather, it chooses perturbations first that cause a response at the largest possible number of nodes (see Section 2 for details).</p>
      <p>We first scrutinized the proposed experimental design strategies on the example network shown in <xref ref-type="fig" rid="btaa404-F2">Figure 2</xref>. We defined six different types of perturbations, each of which targets a (different) single node, or any combination of such for the multi-target strategy. <xref ref-type="fig" rid="btaa404-F3">Figure 3A</xref> shows how the number of identifiable edges increases with the number of performed perturbations for each strategy. A single strategy is associated with multiple sequences, as described in Section 2. Accordingly, <xref ref-type="fig" rid="btaa404-F3">Figure 3A</xref> shows the performance distribution over all these sequences. In practice, we would only select the best performing sequence amongst them. Nevertheless, the depicted distributions are informative because for larger networks we can no longer enumerate all but only a (random) subset of conforming sequences, as described in Section 2.
</p>
      <fig id="btaa404-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>(<bold>A</bold>) The same network topology as in <xref ref-type="fig" rid="btaa404-F2">Figure 2</xref> was subjected to a set of perturbations that target each node individually. Shown are distributions of numbers of identifiable edges for different experimental design strategies and an increasing number of perturbations. (<bold>B</bold>) All perturbation sequences associated with the single-target strategy and (<bold>C</bold>) one sequence associated with the multi-target sequence</p>
        </caption>
        <graphic xlink:href="btaa404f3"/>
      </fig>
      <p>When comparing the methods, we found that each strategy’s average performance is higher than the average performance of all possible sequences.</p>
      <p>Moreover, the ‘naive’ strategy that did not use our framework mostly required all six perturbations to fully identify all parameters, whereas the single-target and exhaustive strategies only needed five, and the multi-target strategy only four perturbations. <xref ref-type="fig" rid="btaa404-F3">Figure 3B and C</xref> display all perturbation sequences associated with the single-target strategy, and one sequence associated with the multi-target strategy, respectively, and illustrate which network edge becomes identifiable at which step in the sequence.</p>
      <p>To systematically analyze if and how our approach improves experimental design, we benchmarked the different strategies on all 267 non-trivial human KEGG (<xref rid="btaa404-B22" ref-type="bibr">Kanehisa <italic>et al.</italic>, 2019</xref>) pathways, ranging from 5 to 120 nodes (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S4 for details). Again, we assumed that perturbations can target (all) single nodes. For each network, we sampled 10 conforming sequences per strategy (as described in Section 2) and compared against the performance of 10 randomly chosen sequences. As a performance measure of each sequence, we considered the number of identifiable edges as a function of the number of perturbations and computed a normalized AUC, as defined in <xref ref-type="disp-formula" rid="E22">Equation (13)</xref>. <xref ref-type="fig" rid="btaa404-F4">Figure 4A</xref> shows the result of this benchmark, and confirms the trend already observed for the example in <xref ref-type="fig" rid="btaa404-F3">Figure 3A:</xref> compared to choosing perturbations randomly, the naive strategy improved identifiability. Performance was further increased when we applied our single-target strategy, yet the multi-target strategy clearly performed best. An exhaustive enumeration of all sequences is not feasible for all KEGG networks. However, we found for a subset of small networks that there is no performance difference between the exhaustive and the single-target strategy, as shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S5A</xref>.
</p>
      <fig id="btaa404-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Performance of different experimental design strategies on 267 human KEGG pathways. (<bold>A</bold>) Identifiability AUC, defined as area under the number of identified nodes versus number of perturbation curve, see <xref ref-type="disp-formula" rid="E22">Equation (13)</xref>. (<bold>B</bold>) For each network and strategy, the average number of perturbations required for full identifiability is shown relative to the average number required for a random strategy. (<bold>C</bold>) The fraction of required perturbations correlated against the isolation score of a network [<xref ref-type="disp-formula" rid="E23">Equation (14)]</xref>, <inline-formula id="IE108"><mml:math id="IM107"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula>: Spearman’s rank correlation. (<bold>D</bold>) The fraction between multi-target perturbations with a specific number of targets and all multi-target perturbations (experiments) in KEGG networks of the annotated size range</p>
        </caption>
        <graphic xlink:href="btaa404f4"/>
      </fig>
      <p>Furthermore, we determined the number of perturbations that is required for full network identifiability (shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S6</xref>) and computed the fraction between a given strategy and the random sequences, see <xref ref-type="fig" rid="btaa404-F4">Figure 4B</xref>. We found that the average number of required perturbations can be reduced to less than one-third or even less than a quarter, when using a single-target or multi-target strategy, respectively. To verify that the performance of the multi-target strategy is not only due to its much larger set of perturbation choices, we also measured the performance of random sequences of perturbation combinations, shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S7</xref>. While such a multi-random strategy increases the performance compared to the random strategy, it is still inferior to the single- and multi-target approach.</p>
      <p>We next investigated which network properties led to a performance increase using our strategies. Intuitively, perturbations might be more informative if their response propagates to large parts of the network. We therefore hypothesized that a careful experimental design is particularly beneficial when networks contain many isolated nodes with little connection to the rest of the network because, in contrast to a random choice, a good strategy could then avoid perturbing such non-informative targets. On the contrary, the sequence of perturbations is irrelevant in the extreme case of a fully connected network. To investigate this hypothesis we defined a network’s isolation score as
<disp-formula id="E23"><label>(14)</label><mml:math id="M23"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>with</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>π</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>∃</mml:mo><mml:mo> </mml:mo><mml:mtext>path</mml:mtext><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>→</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>∄</mml:mo><mml:mo> </mml:mo><mml:mtext>path</mml:mtext><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mo>→</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p><xref ref-type="fig" rid="btaa404-F4">Figure 4C</xref> shows that indeed the isolation score negatively correlates with the previously defined fraction of perturbations required for full network identifiability. Furthermore, we also observed a positive correlation between isolation score and the difference in the identifiability AUC between non-random and random strategies, as shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S5B</xref>. This suggests that indeed our experimental design strategies increase their performance with increasing network isolation.</p>
      <p>When response signals converge at a node, the individual contribution from each incoming edge cannot be distinguished. Thus, the advantage of a multi-target perturbation to potentially track signal propagation through larger parts of the network is counter-balanced if it leads to more convergent signal propagation. This is prevented when the (combined) perturbations target isolated parts of the network. Therefore, the strongest correlation in <xref ref-type="fig" rid="btaa404-F4">Figure 4C</xref> is found for the multi-target strategy because with higher isolation score we can expect to find more such isolated subnetworks. And indeed, <xref ref-type="fig" rid="btaa404-F4">Figure 4D</xref> shows that the multi-target strategy typically suggest combinations of multiple single-target perturbations, especially in larger networks.</p>
      <p>In summary, we have developed an algorithmic approach to determine structural identifiability for a given network. This approach allows to derive experimental design strategies that drastically reduce experimental effort in perturbation studies. In particular, the multi-target strategy proved most efficient. Potentially, this finding has practical relevance because in many experimental contexts it easy to combine perturbations, e.g. by multiplexed CRISPR knockouts (<xref rid="btaa404-B31" ref-type="bibr">Minkenberg <italic>et al.</italic>, 2017</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>We have shown analytically that the identifiability of parameters in linear perturbation networks can be described as a simple maximum-flow problem (summarized in <xref ref-type="fig" rid="btaa404-F1">Fig. 1</xref>). All that is required to perform this analysis is an accurate specification of the (directed) network topology and the targets of the perturbations. This includes the consideration of e.g. robustness or perturbation off-target effects that are specific to the experimental setup and that can influence the wiring of the network. A failure to do so might break the non-cancellation assumption (discussed in Section 2) and thereby lead to flawed identifiability statements, as shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Material</xref> S5.</p>
    <p>Our intuitive description of identifiability not only explains how to achieve fully identifiable effective network models (<xref ref-type="fig" rid="btaa404-F2">Fig. 2</xref>), but also enables us to optimize the design of perturbation experiments (<xref ref-type="fig" rid="btaa404-F3">Fig. 3</xref>). As a test case, we examined all human KEGG pathways and found that our method typically allows to cut down the number of perturbations required for full identifiability to one fourth compared to choosing perturbation targets randomly (<xref ref-type="fig" rid="btaa404-F4">Fig. 4</xref>). We provide a python implementation of our results at github.com/GrossTor/IdentiFlow, which allows to determine identifiability, perform matroid computations that display identifiability relationships between parameters and optimize experimental design. The package relies on standard maximum-flow algorithms from the Networkx package (<xref rid="btaa404-B19" ref-type="bibr">Hagberg <italic>et al.</italic>, 2008</xref>).</p>
    <p>Technically, it would be possible to cope with non-identifiable parameters numerically, as was done previously (<xref rid="btaa404-B3" ref-type="bibr">Bonneau <italic>et al.</italic>, 2006</xref>; <xref rid="btaa404-B12" ref-type="bibr">Dorel <italic>et al.</italic>, 2018</xref>; <xref rid="btaa404-B15" ref-type="bibr">Gardner, 2003</xref>; <xref rid="btaa404-B39" ref-type="bibr">Tegner <italic>et al.</italic>, 2003</xref>). Yet, these procedures tend to be computationally expensive, might depend on heuristic thresholds and are thus not guaranteed to work, in general, which makes them inadequate tools for experimental design. Even more importantly, the benefit of the maximum-flow perspective is that identifiability can be intuitively understood in relation to the network topology and the targets of the perturbations. This means that instead of requiring numerical procedures on a case by case basis, our approach uses intuitively understandable flow networks to link identifiability to the network topology and perturbation setup. This provides a comprehensive overview on which edges become identifiable under which perturbations. For one, this permits a straightforward optimization of the experimental design, as shown before. But even in a situation where the set of perturbations is <italic>a priori</italic> fixed because of experimental constraints, our approach concisely reveals which network topologies are in principle amenable to a meaningful analysis. Thereby, it maps out the range of answerable biological questions. For example, for the toy network depicted in <xref ref-type="fig" rid="btaa404-F1">Figure 1A</xref>, we could ask whether node 2 or node 4 activates node 3 more strongly, which would be an important question if the activity of node 3 is associated with a certain phenotype that we try to influence by inhibiting either node 2 or node 4. <xref ref-type="fig" rid="btaa404-F1">Figure 1C</xref> showed that this is not answerable because both edges are non-identifiable. However, the maximum-flow approach makes it obvious that the question could indeed be addressed if there was another edge from node 1 to node 3 (as this creates an additional edge from node 1 to the source node in the flow net in <xref ref-type="fig" rid="btaa404-F1">Figure 1B</xref> that increases the maximum flow to two).</p>
    <p>Our analysis describes the identifiability of parameters in a network model whose steady state changes linearly with the magnitude of a perturbation. But clearly, biological systems generally break linearity assumptions in varying degrees, which bears asking how useful our description is. In principle, we could expand the steady state function <xref ref-type="disp-formula" rid="E3">Equation (3)</xref> to higher orders and attempt to also infer non-linear rate terms, which are products of different node and perturbation magnitudes. However such products no longer have any meaningful network interpretation, as they cannot be reasonably assigned to any edge. Therefore we argue that the linearity assumption is essential to derive a useful effective network description, if we choose to interpret the biological systems in terms of ordinary differential equations. On the downside, the biological meaning of interaction strengths becomes increasingly obscure the more the system violates the linearity assumption (<xref rid="btaa404-B33" ref-type="bibr">Prabakaran <italic>et al.</italic>, 2014</xref>). Even though our method could still correctly reveal which linear network parameters are uniquely determined by the data, it is questionable how useful this information is, if this value no longer holds a biological meaning. In particular, this could diminish the benefit of a multi-target experimental design strategy, as combined perturbations might push the system into saturation. Hence, even though our maximum-flow approach is independent of the actual measured response data, a strongly non-linear behavior of the underlying biological system can render it irrelevant. We therefore need to carefully consider when a linear network model is an adequate description.</p>
    <p>Importantly, our approach described in this article solely addresses the problem of structural identifiability. In contrast, problems with so-called practical identifiability arise from insufficient quality of experimental data (<xref rid="btaa404-B35" ref-type="bibr">Raue <italic>et al.</italic>, 2011</xref>). Thus, even when the structural identifiability condition for a specific parameter holds, it does not necessarily mean that its value can be reliably estimated. The maximum-flow approach can be used before experiments are conducted, and thus is agnostic to information about noise that could potentially render a structurally identifiable parameter practically non-identifiable. Similarly, it cannot cope with missing measurements of a node’s steady state response, which is a common challenge in novel single-cell perturbation studies (<xref rid="btaa404-B9" ref-type="bibr">Datlinger <italic>et al.</italic>, 2017</xref>; <xref rid="btaa404-B21" ref-type="bibr">Jaitin <italic>et al.</italic>, 2016</xref>). Yet, in these scenarios, our approach can provide an experimental strategy to construct a structurally identifiable model. And subsequently, established methods can be used efficiently to handle practical non-identifiability (<xref rid="btaa404-B12" ref-type="bibr">Dorel <italic>et al.</italic>, 2018</xref>; <xref rid="btaa404-B34" ref-type="bibr">Raue <italic>et al.</italic>, 2009</xref>).</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work has been supported by the Deutsche Forschungsgemeinschaft [RTG2424] CompCancer.</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa404_Supplementary_Data</label>
      <media xlink:href="btaa404_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa404-B1">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Ahuja</surname><given-names>R.K.</given-names></name></person-group><etal>et al</etal> (<year>1993</year>) <source>Network Flows: Theory, Algorithms, and Applications</source>. 
<publisher-name>Prentice Hall</publisher-name>, 
<publisher-loc>Englewood Cliffs, NJ, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa404-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Arrieta-Ortiz</surname><given-names>M.L.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>An experimentally supported model of the <italic>Bacillus subtilis</italic> global transcriptional regulatory network</article-title>. <source>Mol. Syst. Biol</source>., <volume>11</volume>, <fpage>839</fpage>.<pub-id pub-id-type="pmid">26577401</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bonneau</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>The Inferelator: an algorithm for learning parsimonious regulatory networks from systems-biology data sets de novo</article-title>. <source>Genome Biol</source>., <volume>7</volume>, <fpage>R36</fpage>.<pub-id pub-id-type="pmid">16686963</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Boros</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) <chapter-title>Algorithms for enumerating circuits in matroids</chapter-title> In <person-group person-group-type="editor"><name name-style="western"><surname>Ibaraki</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (eds.), <source>Algorithms and Computation. Lecture Notes in Computer Science</source>. 
<publisher-name>Springer</publisher-name>, 
<publisher-loc>Berlin, Heidelberg, Germany</publisher-loc>, pp. <fpage>485</fpage>–<lpage>494</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa404-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bosdriesz</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Comparative network reconstruction using mixed integer programming</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>i997</fpage>–<lpage>i1004</lpage>.<pub-id pub-id-type="pmid">30423075</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brandt</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Cell type-dependent differential activation of ERK by oncogenic KRAS in colon cancer and intestinal epithelium</article-title>. <source>Nat. Commun</source>., <volume>10</volume>, <fpage>2919</fpage>.<pub-id pub-id-type="pmid">31266962</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bruggeman</surname><given-names>F.J.</given-names></name></person-group> (<year>2002</year>) 
<article-title>Modular response analysis of cellular regulatory networks</article-title>. <source>J. Theor. Biol</source>., <volume>218</volume>, <fpage>507</fpage>–<lpage>520</lpage>.<pub-id pub-id-type="pmid">12384053</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ciofani</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>A validated regulatory network for Th17 cell specification</article-title>. <source>Cell</source>, <volume>151</volume>, <fpage>289</fpage>–<lpage>303</lpage>.<pub-id pub-id-type="pmid">23021777</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Datlinger</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Pooled CRISPR screening with single-cell transcriptome readout</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>297</fpage>–<lpage>301</lpage>.<pub-id pub-id-type="pmid">28099430</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>De Smet</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Marchal</surname><given-names>K.</given-names></name></person-group> (<year>2010</year>) 
<article-title>Advantages and limitations of current network inference methods</article-title>. <source>Nat. Rev. Microbiol</source>., <volume>8</volume>, <fpage>717</fpage>–<lpage>729</lpage>.<pub-id pub-id-type="pmid">20805835</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dinic</surname><given-names>E.A.</given-names></name></person-group> (<year>1970</year>) 
<article-title>Algorithm for solution of a problem of maximum flow in networks with power estimation</article-title>. <source>Sov. Math. Dokl</source>., <volume>11</volume>, <fpage>1277</fpage>–<lpage>1280</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa404-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dorel</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Modelling signalling networks from perturbation data</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>4079</fpage>–<lpage>4086</lpage>.<pub-id pub-id-type="pmid">29931053</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Edmonds</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Karp</surname><given-names>R.M.</given-names></name></person-group> (<year>1972</year>) 
<article-title>Theoretical improvements in algorithmic efficiency for network flow problems</article-title>. <source>J. ACM</source>, <volume>19</volume>, <fpage>248</fpage>–<lpage>264</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa404-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fritsche-Guenther</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Strong negative feedback from Erk to Raf confers robustness to MAPK signalling</article-title>. <source>Mol. Syst. Biol</source>., <volume>7</volume>, <fpage>489</fpage>.<pub-id pub-id-type="pmid">21613978</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gardner</surname><given-names>T.S.</given-names></name></person-group> (<year>2003</year>) 
<article-title>Inferring genetic networks and identifying compound mode of action via expression profiling</article-title>. <source>Science</source>, <volume>301</volume>, <fpage>102</fpage>–<lpage>105</lpage>.<pub-id pub-id-type="pmid">12843395</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Godfrey</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>DiStefano</surname><given-names>J.</given-names></name></person-group> (<year>1985</year>) 
<article-title>Identifiability of model parameter</article-title>. <source>IFAC Proc</source>., <volume>18</volume>, <fpage>89</fpage>–<lpage>114</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa404-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Greenfield</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Robust data-driven incorporation of prior knowledge into the inference of dynamic regulatory networks</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>1060</fpage>–<lpage>1067</lpage>.<pub-id pub-id-type="pmid">23525069</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gross</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Robust network inference using response logic</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>i634</fpage>–<lpage>i642</lpage>.<pub-id pub-id-type="pmid">31510692</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Hagberg</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Exploring network structure, dynamics, and function using networkx</article-title>. <italic>Technical Report LA-UR-08-05495; LA-UR-08-5495</italic>
<publisher-name>Los Alamos National Lab. (LANL</publisher-name>), 
<publisher-loc>Los Alamos, NM, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa404-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hengl</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Data-based identifiability analysis of non-linear dynamical models</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>2612</fpage>–<lpage>2618</lpage>.<pub-id pub-id-type="pmid">17660526</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jaitin</surname><given-names>D.A.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Dissecting immune circuits by linking CRISPR-pooled screens with single-cell RNA-Seq</article-title>. <source>Cell</source>, <volume>167</volume>, <fpage>1883</fpage>–<lpage>1896.e15</lpage>.<pub-id pub-id-type="pmid">27984734</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kanehisa</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>New approach for understanding genome variations in KEGG</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D590</fpage>–<lpage>D595</lpage>.<pub-id pub-id-type="pmid">30321428</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kang</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Discriminating direct and indirect connectivities in biological networks</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>112</volume>, <fpage>12893</fpage>–<lpage>12898</lpage>.<pub-id pub-id-type="pmid">26420864</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kholodenko</surname><given-names>B.N.</given-names></name></person-group> (<year>2007</year>) 
<article-title>Untangling the signalling wires</article-title>. <source>Nat. Cell Biol</source>., <volume>9</volume>, <fpage>247</fpage>–<lpage>249</lpage>.<pub-id pub-id-type="pmid">17330115</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Klinger</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Blüthgen</surname><given-names>N.</given-names></name></person-group> (<year>2018</year>) 
<article-title>Reverse engineering gene regulatory networks by modular response analysis—a benchmark</article-title>. <source>Essays Biochem</source>., <volume>62</volume>, <fpage>535</fpage>–<lpage>547</lpage>.<pub-id pub-id-type="pmid">30315094</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Klinger</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Network quantification of EGFR signaling unveils potential for targeted combination therapy</article-title>. <source>Mol. Syst. Biol</source>., <volume>9</volume>, <fpage>673</fpage>.<pub-id pub-id-type="pmid">23752269</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lorenz</surname><given-names>D.R.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>A network biology approach to aging in yeast</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>106</volume>, <fpage>1145</fpage>–<lpage>1150</lpage>.<pub-id pub-id-type="pmid">19164565</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Marbach</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Revealing strengths and weaknesses of methods for gene network inference</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>107</volume>, <fpage>6286</fpage>–<lpage>6291</lpage>.<pub-id pub-id-type="pmid">20308593</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meinshausen</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Methods for causal inference from gene perturbation experiments and validation</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>113</volume>, <fpage>7361</fpage>–<lpage>7368</lpage>.<pub-id pub-id-type="pmid">27382150</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Menger</surname><given-names>K.</given-names></name></person-group> (<year>1927</year>) 
<article-title>Zur allgemeinen Kurventheorie</article-title>. <source>Fundam. Math</source>., <volume>10</volume>, <fpage>96</fpage>–<lpage>115</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa404-B31">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Minkenberg</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) <chapter-title>Chapter seven—CRISPR/Cas9-enabled multiplex genome editing and its application</chapter-title> In: <person-group person-group-type="editor"><name name-style="western"><surname>Weeks</surname><given-names>D.P.</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>B.</given-names></name></person-group> (eds.), <source>Progress in Molecular Biology and Translational Science. Gene Editing in Plants</source>. <source>Vol. 149</source>, 
<publisher-name>Academic Press</publisher-name>, San Diego, CA, USA, pp. <fpage>111</fpage>–<lpage>132</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa404-B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Pearl</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>) <source>Causality: Models, Reasoning and Inference</source>. <edition>2nd edn.</edition><publisher-name>Cambridge University Press</publisher-name>, 
<publisher-loc>New York, NY, USA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btaa404-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Prabakaran</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Paradoxical results in perturbation-based signaling network reconstruction</article-title>. <source>Biophys. J</source>., <volume>106</volume>, <fpage>2720</fpage>–<lpage>2728</lpage>.<pub-id pub-id-type="pmid">24940789</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Raue</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile likelihood</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>1923</fpage>–<lpage>1929</lpage>.<pub-id pub-id-type="pmid">19505944</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Raue</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Addressing parameter identifiability by model-based experimentation</article-title>. <source>IET Syst. Biol</source>., <volume>5</volume>, <fpage>120</fpage>–<lpage>130</lpage>.<pub-id pub-id-type="pmid">21405200</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sachs</surname><given-names>K.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Causal protein-signaling networks derived from multiparameter single-cell data</article-title>. <source>Science</source>, <volume>308</volume>, <fpage>523</fpage>–<lpage>529</lpage>.<pub-id pub-id-type="pmid">15845847</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Santra</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Integrating Bayesian variable selection with modular response analysis to infer biochemical network topology</article-title>. <source>BMC Syst. Biol</source>., <volume>7</volume>, <fpage>57</fpage>.<pub-id pub-id-type="pmid">23829771</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Santra</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Reconstructing static and dynamic models of signaling pathways using modular response analysis</article-title>. <source>Curr. Opin. Syst. Biol</source>., <volume>9</volume>, <fpage>11</fpage>–<lpage>21</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa404-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tegner</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>Reverse engineering gene networks: integrating genetic perturbations with dynamical modeling</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>100</volume>, <fpage>5944</fpage>–<lpage>5949</lpage>.<pub-id pub-id-type="pmid">12730377</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Timme</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>) 
<article-title>Revealing network connectivity from response dynamics</article-title>. <source>Phys. Rev. Lett</source>., <volume>98</volume>, <fpage>224101</fpage>.<pub-id pub-id-type="pmid">17677845</pub-id></mixed-citation>
    </ref>
    <ref id="btaa404-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Whitney</surname><given-names>H.</given-names></name></person-group> (<year>1935</year>) 
<article-title>On the abstract properties of linear dependence</article-title>. <source>Am. J. Math</source>., <volume>57</volume>, <fpage>509</fpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
