<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pone.0286728.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10237395</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-22-27603</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Ontologies</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Data Visualization</subject>
            <subj-group>
              <subject>Infographics</subject>
              <subj-group>
                <subject>Graphs</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Eukaryota</subject>
            <subj-group>
              <subject>Animals</subject>
              <subj-group>
                <subject>Vertebrates</subject>
                <subj-group>
                  <subject>Amniotes</subject>
                  <subj-group>
                    <subject>Birds</subject>
                    <subj-group>
                      <subject>Raptors</subject>
                      <subj-group>
                        <subject>Owls</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Zoology</subject>
          <subj-group>
            <subject>Animals</subject>
            <subj-group>
              <subject>Vertebrates</subject>
              <subj-group>
                <subject>Amniotes</subject>
                <subj-group>
                  <subject>Birds</subject>
                  <subj-group>
                    <subject>Raptors</subject>
                    <subj-group>
                      <subject>Owls</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Computational Biology</subject>
          <subj-group>
            <subject>Genome Analysis</subject>
            <subj-group>
              <subject>Gene Ontologies</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Genome Analysis</subject>
              <subj-group>
                <subject>Gene Ontologies</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Architecture</subject>
          <subj-group>
            <subject>User Interfaces</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Eukaryota</subject>
            <subj-group>
              <subject>Plants</subject>
              <subj-group>
                <subject>Trees</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Navigation</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>OntoTrek: 3D visualization of application ontology class hierarchies</article-title>
      <alt-title alt-title-type="running-head">OntoTrek</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8844-9165</contrib-id>
        <name>
          <surname>Dooley</surname>
          <given-names>Damion</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4312-5992</contrib-id>
        <name>
          <surname>Nguyen</surname>
          <given-names>Matthew H.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Hsiao</surname>
          <given-names>William W. L.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Faculty of Health Sciences, Simon Fraser University, Burnaby, British Columbia, Canada</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Bioinformatics Graduate Program, University of British Columbia, Vancouver, British Columbia, Canada</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Chunghwa Telecom Co. Ltd., TAIWAN</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>damion_dooley@sfu.ca</email> (DD); <email>wwhsiao@sfu.ca</email> (WWLH)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>2</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>18</volume>
    <issue>6</issue>
    <elocation-id>e0286728</elocation-id>
    <history>
      <date date-type="received">
        <day>6</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Dooley et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Dooley et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0286728.pdf"/>
    <abstract>
      <p>An application ontology often reuses terms from other related, compatible ontologies. The extent of this interconnectedness is not readily apparent when browsing through larger textual presentations of term class hierarchies, be it Manchester text format OWL files or within an ontology editor like Protege. Users must either note ontology sources in term identifiers, or look at ontology import file term origins. Diagrammatically, this same information may be easier to perceive in 2 dimensional network or hierarchical graphs that visually code ontology term origins. However, humans, having stereoscopic vision and navigational acuity around colored and textured shapes, should benefit even more from a coherent 3-dimensional interactive visualization of ontology that takes advantage of perspective to offer both foreground focus on content and a stable background context. We present OntoTrek, a 3D ontology visualizer that enables ontology stakeholders—students, software developers, curation teams, and funders—to recognize the presence of imported terms and their domains, ultimately illustrating how projects can capture knowledge through a vocabulary of interwoven community-supported ontology resources.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100008762</institution-id>
            <institution>Genome Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>286GET</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hsiao</surname>
            <given-names>William W. L.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100007917</institution-id>
            <institution>Agricultural Research Service</institution>
          </institution-wrap>
        </funding-source>
        <award-id>58-8040-8-014-F</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hsiao</surname>
            <given-names>William W. L.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000038</institution-id>
            <institution>Natural Sciences and Engineering Research Council of Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CGS-M</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4312-5992</contrib-id>
          <name>
            <surname>Nguyen</surname>
            <given-names>Matthew H.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>DD is funded by Genome Canada Project 286GET and the USDA NACA Contract 58-8040-8-014-F to WWLH. MHN is funded by CGS-M Scholarship. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="3"/>
      <table-count count="0"/>
      <page-count count="7"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All relevant data for this study are publicly available from the GitHub repository (<ext-link xlink:href="https://github.com/cidgoh/ontotrek" ext-link-type="uri">https://github.com/cidgoh/ontotrek</ext-link>).</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All relevant data for this study are publicly available from the GitHub repository (<ext-link xlink:href="https://github.com/cidgoh/ontotrek" ext-link-type="uri">https://github.com/cidgoh/ontotrek</ext-link>).</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>There are currently many challenges in educating stakeholders with little ontology familiarity about the implications of trying to describe a domain of interest within the context of current ontology domain coverage, and curation and infrastructure components necessary to support such an effort. Moreover, it is difficult to visualize the interconnectedness between different ontologies using existing tools. Most ontology visualization tools produce a 2-dimensional representation. Protégé [<xref rid="pone.0286728.ref001" ref-type="bibr">1</xref>] is the most widely used software for building and maintaining ontologies, but uses a 2D expandable hierarchic tree representation of terms that requires clicking and scrolling to assess the structure and magnitude of an ontology. Additional plugins can be added to Protégé, such as OntoGraf which adds interactive navigation of ontology terms and relationships. However, such a visualizer still struggles to represent large ontologies in a clean manner, often containing illegible labels and crowded layouts with overlapping edges when zoomed-out, and when zoomed-in, the challenge of tracing edges that journey out of viewport scope. Here “viewport” refers to an interactive software application window where the ontology is rendered.</p>
    <p>There have also been ontology visualization approaches that provide a 3D hierarchic representation. OntoSphere [<xref rid="pone.0286728.ref002" ref-type="bibr">2</xref>] aims to represent ontology semantics beyond the basic class-subclass hierarchy by providing a few views including a RootFocus summary view which represents unexplored branches as larger balls, and leaf nodes are shown as small balls, while edges between nodes indicate some level of focused exploration, all presented on the surface of a larger semi-transparent sphere. The TreeFocus view provides a 3 tier exploration of a node and its parent and child subclass (taxonomic) context as well. Neither of the views provides full top-down hierarchies, or an indication of imported vs. home-grown entities.</p>
    <p>One major concern about many existing 2D and 3D graph diagram tools is that they depend on nondeterministic force-directed graph algorithms that generate an unpredictable orientation and layout of nodes over time often as a result of randomly placed initial nodes [<xref rid="pone.0286728.ref003" ref-type="bibr">3</xref>]. Users can only counteract this to some degree by manually fixing or “pinning” specific nodes. One resilient approach is the “Botanical Tree” algorithm [<xref rid="pone.0286728.ref004" ref-type="bibr">4</xref>], which builds branch widths according to a size metric of branch content, and concludes with “phiballs”, spheres that are decorated with either a conical cap, or multiple polka dots that represent each leaf edge emanating from that juncture. Guided by the class structure of an upper-level ontology, these trees could provide a consistent layout steered by branch bifurcation and leaf volume.</p>
    <p>Here, we present OntoTrek, a lightweight, javascript-based, open-source web browser application to help visualize ontologies in a 3-dimensional representation. Inspired by the “Botanical Tree” algorithm, our method exposes the leaf and node structure to provide labelling as well as other functionalities. It explores the idea that humans benefit from data representations that maintain spatial consistency across successive presentations. This translates to enabling users to virtually fly around and through the OntoTrek 3D viewport’s representation of an ontology. The main use case of Ontotrek is to visually answer the question of how many different ontologies are imported into a given ontology, and which classes they appear under. The use-case arises in situations where ontologies are importing terms from other ontologies in order to facilitate data harmonization, as exemplified by the Open Biological and Biomedical Ontologies (OBO) Foundry [<xref rid="pone.0286728.ref005" ref-type="bibr">5</xref>], which contains many ontologies that follow the same set of principles including a commitment to collaborative development, conformance to an upper level ontology like the Basic Formal Ontology (BFO) [<xref rid="pone.0286728.ref006" ref-type="bibr">6</xref>], and the reuse of common object properties. Well known examples of OBO Foundry ontologies are the domain specific Gene Ontology (GO) and the Human Disease Ontology (DOID). OBO Foundry also contains application ontologies which often reuse terms from other related upper-level or domain-specific ontologies. The main goal during OntoTrek development was to have a browser-based user interface, allowing the ability to navigate through an ontology’s class-subclass hierarchy. Moreover, large ontologies should be supported, with legible node layers and quick rendering times.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Design and implementation</title>
    <p>OntoTrek is built in JavaScript using 3d-force-graph (<ext-link xlink:href="https://github.com/vasturiano/3d-force-graph" ext-link-type="uri">https://github.com/vasturiano/3d-force-graph</ext-link>), a light-weight and very fast WebGL 3D graph rendering software that provides a suite of graph node and edge rendering features along with some user interface interactivity. These features are crucial for enabling smooth navigation of an ontology having thousands of terms. As with most graphics libraries, there are ultimately limits to 3d-force-graph rendering time as a function of both CPU performance and the count of ontology terms to process, and limits to built-in navigation algorithms, which we discuss below.</p>
    <sec id="sec003">
      <title>Ontology structure</title>
      <p>OntoTrek reads, parses and visualizes an OWL ontology file directly, either from an example selection of OBO Foundry ontology files that sit in OntoTrek’s data folder, or by dynamically fetching one from a user-provided URL. This allows new or in-development ontologies to be viewed. OntoTrek renders class-subclass relations starting from parent-less entities (e.g. owl:Thing or “entity”, from BFO). Many OWL ontologies explicitly use the single <bold>owl:Thing</bold> “root node” as the top class/node of an umbrella-shaped tree. An ontology can have other top level nodes which have no superclass connection to owl:Thing explicitly stated. OntoTrek shows these (including bfo:Entity) as “stand alone” nodes, disconnected from owl:Thing.</p>
      <p>If a class has multiple superclasses, only the first one listed (as an owl:subClassOf parent node) will be used in the hierarchy. As well, OntoTrek doesn’t render other kinds of relations that axioms reference, nor will it show classes which only appear in axioms and not in the class hierarchy. OntoTrek’s design objective is primarily to focus on an informative display of the class hierarchy itself; we have not embarked on the very careful work required to display other kinds of relations in a limited / local way that does not overwhelm the visual interface. One can foresee an object-centric display involving the engineering of templates, each focusing on an ontology term class that represents a type of object, and edges emanating from it to other objects and data properties as required by relevant axioms.</p>
      <p>The visible structure drawn must be largely deterministic, placing nodes consistently in the same region relative to each other on each fresh generation of the visualization, thus keeping the location of terms consistent. Most force graph algorithms can be set to be deterministic, and OntoTrek uses 3d-force-graph this way. If an ontology is loaded into OntoTrek, and its class structure is identical to a previous loading, then its visual structure will be identical. Of course, modifications to an ontology’s class structure likely result in visual changes over time, sometimes radically, depending on how high up the hierarchy that term additions or deletions occur. A few strategies described below ameliorate this inconsistency.</p>
      <p>OntoTrek allows an upper-level ontology (such as BFO 2.1’s 34 terms) to have nodes whose positions are fixed (so-called “pinned” nodes), such that a force-directed algorithm which is positioning underlying nodes (classes of other subordinate ontologies) iterates from that fixed upper-level node constellation. This is key to providing a recognizable and semantically relevant layout from the summit of the term landscape, in which for example one branch or pole from the root node holds upper level ontology continuants or endurants, and another holds occurants or perdurants, and so on. Consequently, even high-level restructuring of underlying ontology hierarchies doesn’t radically change the shape of the overall visualization. A configuration file (the “/js/lookup_tables.json” layout object) holds pinned nodes, which are automatically referenced by any loaded ontology.</p>
    </sec>
    <sec id="sec004">
      <title>Ontology rendering</title>
      <p>At least one rendered view should reflect an ontology’s stated or inferred class hierarchy, so there can be a “top” and a “bottom” in 3D space for aligning this hierarchy in. Navigation through the viewport should give visual clues as to where the “top” is, and it should be easy to reestablish an “up” perspective on ontology contents after navigating around them from any orientation. OntoTrek orients each top-level node’s hierarchy in the viewport in the same vertical direction. The depth of a node from its root(s) is apparent by placing nodes of a given degree of depth (n = 1,2,3, …) in a correspondingly deep horizontal plane, yielding a stratified appearance. Top level terms—which OntoTrek’s demo ontologies often refer to—represent upper level ontology terms of the Basic Formal Ontology, and are given a larger size, enabling them to be discerned while substantially zoomed-out from the graph. A bright yellow color also enhances their visibility, and pinning provides stability.</p>
      <p>For most ontologies listed in the Search tab’s pulldown list menu, performance of the initial force graph rendering phase would be slower if done from scratch, but these ontologies are assisted by a cache file containing the coordinates of a previous graph rendering.</p>
      <p>Force graph solutions often encounter problems with an initial state of (pseudo)randomly positioned nodes and connecting edges which undergo the force algorithm’s attraction and repulsion kinetics. With larger node count, “ostracised” nodes are often trapped in territory that their long edges can’t contract them out of. The OntoTrek solution is, starting with the root node(s), to dynamically add generations of child nodes as the algorithm runs, allowing it to settle on the positions of each generation before advancing to the next, which encourages the local positioning of primary subclass nodes. Subsequent generations are spawned on lower tiers pseudo-randomly with respect to their parents. The algorithm basically builds mountains of terms from the top-down, with lower-tier nodes pulling away from each other to help reduce density in the hierarchy, while pinned top level nodes ensure that underlying nodes follow the same topology.</p>
      <p>The consistent color coding of term nodes is key to illustrating the interconnectedness of 3rd party ontologies. A lookup table assigns colors to most of OBO Foundry’s ontology prefixes so that any of an ontology’s nodes receives the same color, enabling easier visual recognition, although ontology term reuse can involve upwards of 30 prefixes and their colors (for example, OBI, the Ontology for Biomedical Investigations, imports terms having over 20 different prefixes [<xref rid="pone.0286728.ref007" ref-type="bibr">7</xref>]).</p>
      <p>Increased foreground detail, including textual legibility, enables us to navigate to places in the hierarchy visually according to other cues besides text. The 3D landscape also allows structure to be “stored” in plain view at scale, which is a kind of data compression as long as some user memory of its content is accessible, which currently is achieved by mouseover identification of distant node entities. Currently we present only the matched entity label on that event, but this could be modified to show a node’s upper level ontology category or content as a summary view.</p>
      <p>OntoTrek actually has a hybrid 3D and 2D view, available by toggling the “<bold>Underlying ontology branches rendered as vertical slice(s)</bold>” setting, which illustrates benefits of both combined by showing an upper level ontology in 3D, and underlying ontologies in vertical planes of 2D hierarchies. This option provides a fly-through view that separates out the labels which is quite effective with a medium sized ontology like AGRO or GenEpiO. The algorithm, like the general 3D one, could be improved to add more space to lower level nodes and their labels.</p>
      <p>Term labels and synonyms can be searched in the OntoTrek interface (specifically on the side bar, in the Term Search and Term Context boxes in <xref rid="pone.0286728.g001" ref-type="fig">Fig 1</xref>) in order to locate and travel to the term node of interest. A pull-down list of all terms available in the ontology is given, but this also contains the usability feature that as one types, both term label and synonyms can be searched, so that ‘dog’, though not present in the label, will return term ‘Cannis lupus familiaris’. This enables people to use colloquial vocabulary to access information a formal ontology can provide. A matching term is displayed along with its parent(s) and children, and its definition and ontology lookup service links for OntoBee.org and EMBL-EBI Ontology Lookup Service shown in <xref rid="pone.0286728.g001" ref-type="fig">Fig 1</xref>. Clicking on a node link or dashboard “children” menu selection triggers a focus on the child node.</p>
      <fig position="float" id="pone.0286728.g001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0286728.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Example of the user interface of Ontotrek while selecting the AGRO term “conflagration”.</title>
          <p>Here we demonstrate the dashboard which presents the term definition as well as ontology service lookup links.</p>
        </caption>
        <graphic xlink:href="pone.0286728.g001" position="float"/>
      </fig>
      <p>There are a few Settings tab options that can improve rendering performance. These should be turned on or off before starting to render a selected ontology.</p>
      <list list-type="order">
        <list-item>
          <p><bold>Show labels</bold>: By default, OntoTrek renders both a node label, AND a semi-transparent background box slightly behind it, to help with legibility. This feature is costly, but it can be turned off with the “Show labels” toggle.</p>
        </list-item>
        <list-item>
          <p><bold>Show a wireframe view</bold>: By default, OntoTrek renders heavier edges the higher up one goes in the hierarchy, with lower level edges past a certain depth having just 1 unit of thickness, which doesn’t invoke polygon rendering. This option sets edges to have the fastest 1 unit of thickness for any edge, aside from the top-level ontology ones, which are untouched. (This option also eliminates transparency on the default labels shown with “Show labels” set to true).</p>
        </list-item>
        <list-item>
          <p><bold>Render from top down to this node depth</bold>: This option allows display of only upper levels of more massive ontologies if desired.</p>
        </list-item>
        <list-item>
          <p><bold>Show deprecated terms</bold>: By default deprecated terms are hidden from display to reduce clutter for ontologies that include these terms as parent-less top-level nodes.</p>
        </list-item>
      </list>
      <p>Users can rotate, zoom, or pan the display. Clicking on any node in the Ontotrek viewport causes the node to be highlighted in red, and also triggers a transition animation that moves the viewport camera perspective to an angled view close to and above the node. This built-in force-graph-3d feature is problematic because the “rollercoaster” transition animation doesn’t keep the viewport itself oriented vertically, so it is up to a user to try to realign the view after the transition has finished.</p>
      <p>OntoTrek is hosted at <ext-link xlink:href="http://genepio.org/ontotrek/" ext-link-type="uri">http://genepio.org/ontotrek/</ext-link>. A user guide is provided at <ext-link xlink:href="https://github.com/cidgoh/ontotrek/wiki" ext-link-type="uri">https://github.com/cidgoh/ontotrek/wiki</ext-link>. Users can also build and run OntoTrek on their own computer. OntoTrek source code is available at <ext-link xlink:href="https://github.com/cidgoh/ontotrek" ext-link-type="uri">https://github.com/cidgoh/ontotrek</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec005">
    <title>Discussion</title>
    <p>The main aim of OntoTrek is the visualization of term reuse in ontologies, which is demonstrated by a number of reference and application ontologies that illustrate varying degrees of reuse of upper level BFO classes and terms from other ontologies. <xref rid="pone.0286728.g002" ref-type="fig">Fig 2</xref> shows OBI, containing both its own terms (nodes and edges coloured in white), and the BFO upper framework (coloured in yellow) as well as terms of other ontologies (e.g. PATO in green). A comprehensive list of referenced ontologies, with the number of terms referenced and their corresponding colour code, can be accessed from the “Legend” tab.</p>
    <fig position="float" id="pone.0286728.g002">
      <object-id pub-id-type="doi">10.1371/journal.pone.0286728.g002</object-id>
      <label>Fig 2</label>
      <caption>
        <title>OBI visualization in OntoTrek (with labels hidden).</title>
        <p>The OntoTrek structure shows the interconnectedness of different ontologies within OBI. For example, the green subtree shows PATO, the orange subtree shows GO, the blue subtree shows CL and the yellow parent tree shows the BFO backbone. White nodes are unique OBI terms.</p>
      </caption>
      <graphic xlink:href="pone.0286728.g002" position="float"/>
    </fig>
    <p>An example of an included reference ontology within OntoTrek is DOID (Human Disease Ontology) shown in <xref rid="pone.0286728.g003" ref-type="fig">Fig 3</xref>. It does not reference terms from other ontologies, including the BFO backbone. The <bold>owl:Thing</bold> node is still included, but is not connected to any term within the DOID ontology. In this case, the root node/top point of the tree is the base term of the ontology (i.e. disease).</p>
    <fig position="float" id="pone.0286728.g003">
      <object-id pub-id-type="doi">10.1371/journal.pone.0286728.g003</object-id>
      <label>Fig 3</label>
      <caption>
        <title>DOID visualization in OntoTrek (with labels hidden).</title>
        <p>The yellow disconnected node is the owl:Thing root of BFO. The OntoTrek structure shows that DOID doesn’t share any terms with other ontologies. It also does not contain the BFO backbone, observed from the lack of a branch between its root and the owl:Thing node.</p>
      </caption>
      <graphic xlink:href="pone.0286728.g003" position="float"/>
    </fig>
    <p>Although OntoTrek can theoretically display ontologies of any size, ones that have less than 10,000 terms are easier to load on contemporary personal computers (OntoTrek was developed on a Mac Powerbook in which ontologies like AGRO with over 4,000 terms renders quickly). The coordinate caching system enables larger ontologies to quickly render rather than be delayed by the force graph algorithm’s iteration time. Going beyond the previously mentioned performance related label and edge rendering settings, a more sophisticated future approach would provide a richer information display just for the line-of-sight vicinity of the mouse cursor, assuming that is where the user’s attention is focused. Label rendering could be eliminated for more distant or peripheral nodes. This would also reduce clutter, and pave the way for display of multiple ontologies side-by-side in the viewport.</p>
    <p>Finally, it will be important to eliminate changes in pitch and roll in the animation algorithm experienced when zooming into a node. A top down perspective should be maintained during flight. Ideally the viewport is stabilized in the same way when a user manually navigates through the 3D space.</p>
  </sec>
  <sec sec-type="conclusions" id="sec006">
    <title>Conclusion</title>
    <p>OntoTrek is a 3D ontology viewer that provides an interactive user experience through a single viewport. OntoTrek’s ease of use is aimed not only at ontology curators, but also those unfamiliar with ontologies and their structure. A clear representation of the interconnectedness of ontologies is shown, while keeping an intuitive hierarchical structure. In addition to the included OBO Foundry ontologies, users can load other web-hosted OWL ontology files for visualization. OntoTrek is primarily intended for ontology display, but with continued development and support, could target the visualization of graph databases containing ontology-driven content.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We thank the reviewers for suggested improvements to the application.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0286728.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Musen</surname><given-names>MA</given-names></name>. <article-title>The Protégé Project: A Look Back and a Look Forward</article-title>. <source>AI Matters</source>. <year>2015</year>;<volume>1</volume>(<issue>4</issue>):<fpage>4</fpage>–<lpage>12</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1145/2757001.2757003</pub-id><?supplied-pmid 27239556?><pub-id pub-id-type="pmid">27239556</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0286728.ref002">
      <label>2</label>
      <mixed-citation publication-type="other">Bosca A, Bonino D. OntoSphere3D: A Multidimensional Visualization Tool for Ontologies. In: 17th International Workshop on Database and Expert Systems Applications (DEXA’06); 2006. p. 339–343.</mixed-citation>
    </ref>
    <ref id="pone.0286728.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Dudáš</surname><given-names>M</given-names></name>, <name><surname>Lohmann</surname><given-names>S</given-names></name>, <name><surname>Svátek</surname><given-names>V</given-names></name>, <name><surname>Pavlov</surname><given-names>D</given-names></name>. <article-title>Ontology visualization methods and tools: a survey of the state of the art</article-title>. <source>The Knowledge Engineering Review</source>. <year>2018</year>;<volume>33</volume>:<fpage>e10</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1017/S0269888918000073</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0286728.ref004">
      <label>4</label>
      <mixed-citation publication-type="other">Kleiberg E, van de Wetering H, van Wijk JJ. Botanical visualization of huge hierarchies. In: IEEE Symposium on Information Visualization, 2001. INFOVIS 2001.; 2001. p. 87–94.</mixed-citation>
    </ref>
    <ref id="pone.0286728.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>B</given-names></name>, <name><surname>Ashburner</surname><given-names>M</given-names></name>, <name><surname>Rosse</surname><given-names>C</given-names></name>, <name><surname>Bard</surname><given-names>J</given-names></name>, <name><surname>Bug</surname><given-names>W</given-names></name>, <name><surname>Ceusters</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>The OBO Foundry: coordinated evolution of ontologies to support biomedical data integration</article-title>. <source>Nature Biotechnology</source>. <year>2007</year>;<volume>25</volume>(<issue>11</issue>):<fpage>1251</fpage>–<lpage>1255</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt1346</pub-id><?supplied-pmid 17989687?><pub-id pub-id-type="pmid">17989687</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0286728.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">Smith B, Kumar A, Bittner T. Basic Formal Ontology for Bioinformatics. IFOMIS Reports; 2005.</mixed-citation>
    </ref>
    <ref id="pone.0286728.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Bandrowski</surname><given-names>A</given-names></name>, <name><surname>Brinkman</surname><given-names>R</given-names></name>, <name><surname>Brochhausen</surname><given-names>M</given-names></name>, <name><surname>Brush</surname><given-names>MH</given-names></name>, <name><surname>Bug</surname><given-names>B</given-names></name>, <name><surname>Chibucos</surname><given-names>MC</given-names></name>, <etal>et al</etal>. <article-title>The Ontology for Biomedical Investigations</article-title>. <source>PLOS ONE</source>. <year>2016</year>;<volume>11</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>19</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0154556</pub-id><?supplied-pmid 27128319?><pub-id pub-id-type="pmid">27128319</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pone.0286728.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Abel C.H. Chen</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Abel C.H. Chen</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">22 Nov 2022</named-content>
    </p>
    <p><!-- <div> -->PONE-D-22-27603<!-- </div> --><!-- <div> -->OntoTrek: 3D visualization of application ontology class hierarchies<!-- </div> --><!-- <div> -->PLOS ONE</p>
    <p>Dear Dr. Hsiao,</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Please submit your revised manuscript by Jan 06 2023 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list></p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Abel C.H. Chen</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Journal Requirements:</p>
    <p>When submitting your revision, we need you to address these additional requirements.</p>
    <p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at </p>
    <p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and </p>
    <p>
      <ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
    </p>
    <p>2. Thank you for stating the following financial disclosure: </p>
    <p> "DD is funded by Genome Canada Project 286GET and the USDA NACA Contract 58-8040-8-014-F to WWLH. MHN is funded by CGS-M Scholarship."</p>
    <p>Please state what role the funders took in the study.  If the funders had no role, please state: "The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript." </p>
    <p>If this statement is not correct you must amend it as needed. </p>
    <p>Please include this amended Role of Funder statement in your cover letter; we will change the online submission form on your behalf.</p>
    <p>3. PLOS requires an ORCID iD for the corresponding author in Editorial Manager on papers submitted after December 6th, 2016. Please ensure that you have an ORCID iD and that it is validated in Editorial Manager. To do this, go to ‘Update my Information’ (in the upper left-hand corner of the main menu), and click on the Fetch/Validate link next to the ORCID field. This will take you to the ORCID site and allow you to create a new iD or authenticate a pre-existing iD in Editorial Manager. Please see the following video for instructions on linking an ORCID iD to your Editorial Manager account: <ext-link xlink:href="https://www.youtube.com/watch?v=_xcclfuvtxQ" ext-link-type="uri">https://www.youtube.com/watch?v=_xcclfuvtxQ</ext-link></p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Partly</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: N/A</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: The authors describe a 3-D visualization system for browsing the content of an ontology. One of the main motivations seems to be to be able to visualize which content from external terminologies is imported into the ontology and under which branches of the ontology it is found. In testing the interface is challenging to use. For any ontology with more than a tiny number of classes, it is hard to see the different nodes, and the UI zooms in and out confusingly. A positive aspect is that ontology content from different sources is colored differently, so that the source can be observed at a glance.</p>
    <p>I think there are three main aspects the authors could clarify or develop further that would help to make this system more usable:</p>
    <p>1. Performance is a serious problem when browsing real world ontologies in the system.</p>
    <p>2. The majority of usages of external content in OBO ontologies is via composition, rather than inheritance. For example an HPO phenotype is related to the affected anatomical structure. For this reason it would be valuable to traverse these kinds of links rather than just subClassOf.</p>
    <p>3. The main issue that I think should either receive more development, or be addressed more clearly in the paper, is what purpose does the third dimension serve? It seems like many of their ideas (e.g., clearly denoting external content, showing the branching pattern from superclass to subclass) could be supported by a (possibly more scalable) two dimensional system. If one dimension denotes more-general-to-more-specific, and the second dimension separates peer terms from each other, what does change in the third dimension indicate?</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>**********</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0286728.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">15 Apr 2023</named-content>
    </p>
    <p>please see uploaded file titled "Ontotrek Response to Reviewers"</p>
    <supplementary-material id="pone.0286728.s001" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Ontotrek Response to Reviewers.pdf</named-content></p>
      </caption>
      <media xlink:href="pone.0286728.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pone.0286728.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Abel C.H. Chen</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Abel C.H. Chen</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">23 May 2023</named-content>
    </p>
    <p>OntoTrek: 3D visualization of application ontology class hierarchies</p>
    <p>PONE-D-22-27603R1</p>
    <p>Dear Dr. Hsiao,</p>
    <p>We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p>
    <p>Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p>
    <p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p>
    <p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p>
    <p>Kind regards,</p>
    <p>Abel C.H. Chen</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Additional Editor Comments (optional):</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.<!-- </font> --></p>
    <p>Reviewer #1: All comments have been addressed</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: N/A</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: The figure images are somewhat low resolution; the live application is a bit sharper. If possible, I suggest updating them.</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>**********</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0286728.r004" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r004</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Abel C.H. Chen</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Abel C.H. Chen</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj004" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">26 May 2023</named-content>
    </p>
    <p>PONE-D-22-27603R1 </p>
    <p>OntoTrek: 3D visualization of application ontology class hierarchies </p>
    <p>Dear Dr. Hsiao:</p>
    <p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
    <p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p>
    <p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p>
    <p>Thank you for submitting your work to PLOS ONE and supporting open access. </p>
    <p>Kind regards, </p>
    <p>PLOS ONE Editorial Office Staff</p>
    <p>on behalf of</p>
    <p>Dr. Abel C.H. Chen </p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
  </body>
</sub-article>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pone.0286728.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10237395</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-22-27603</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Ontologies</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Data Visualization</subject>
            <subj-group>
              <subject>Infographics</subject>
              <subj-group>
                <subject>Graphs</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Eukaryota</subject>
            <subj-group>
              <subject>Animals</subject>
              <subj-group>
                <subject>Vertebrates</subject>
                <subj-group>
                  <subject>Amniotes</subject>
                  <subj-group>
                    <subject>Birds</subject>
                    <subj-group>
                      <subject>Raptors</subject>
                      <subj-group>
                        <subject>Owls</subject>
                      </subj-group>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Zoology</subject>
          <subj-group>
            <subject>Animals</subject>
            <subj-group>
              <subject>Vertebrates</subject>
              <subj-group>
                <subject>Amniotes</subject>
                <subj-group>
                  <subject>Birds</subject>
                  <subj-group>
                    <subject>Raptors</subject>
                    <subj-group>
                      <subject>Owls</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Computational Biology</subject>
          <subj-group>
            <subject>Genome Analysis</subject>
            <subj-group>
              <subject>Gene Ontologies</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Genome Analysis</subject>
              <subj-group>
                <subject>Gene Ontologies</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Software Engineering</subject>
          <subj-group>
            <subject>Computer Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Architecture</subject>
          <subj-group>
            <subject>User Interfaces</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Eukaryota</subject>
            <subj-group>
              <subject>Plants</subject>
              <subj-group>
                <subject>Trees</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Navigation</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>OntoTrek: 3D visualization of application ontology class hierarchies</article-title>
      <alt-title alt-title-type="running-head">OntoTrek</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8844-9165</contrib-id>
        <name>
          <surname>Dooley</surname>
          <given-names>Damion</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4312-5992</contrib-id>
        <name>
          <surname>Nguyen</surname>
          <given-names>Matthew H.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Hsiao</surname>
          <given-names>William W. L.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Faculty of Health Sciences, Simon Fraser University, Burnaby, British Columbia, Canada</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Bioinformatics Graduate Program, University of British Columbia, Vancouver, British Columbia, Canada</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Chunghwa Telecom Co. Ltd., TAIWAN</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>damion_dooley@sfu.ca</email> (DD); <email>wwhsiao@sfu.ca</email> (WWLH)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>2</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>18</volume>
    <issue>6</issue>
    <elocation-id>e0286728</elocation-id>
    <history>
      <date date-type="received">
        <day>6</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Dooley et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Dooley et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0286728.pdf"/>
    <abstract>
      <p>An application ontology often reuses terms from other related, compatible ontologies. The extent of this interconnectedness is not readily apparent when browsing through larger textual presentations of term class hierarchies, be it Manchester text format OWL files or within an ontology editor like Protege. Users must either note ontology sources in term identifiers, or look at ontology import file term origins. Diagrammatically, this same information may be easier to perceive in 2 dimensional network or hierarchical graphs that visually code ontology term origins. However, humans, having stereoscopic vision and navigational acuity around colored and textured shapes, should benefit even more from a coherent 3-dimensional interactive visualization of ontology that takes advantage of perspective to offer both foreground focus on content and a stable background context. We present OntoTrek, a 3D ontology visualizer that enables ontology stakeholders—students, software developers, curation teams, and funders—to recognize the presence of imported terms and their domains, ultimately illustrating how projects can capture knowledge through a vocabulary of interwoven community-supported ontology resources.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100008762</institution-id>
            <institution>Genome Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>286GET</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hsiao</surname>
            <given-names>William W. L.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100007917</institution-id>
            <institution>Agricultural Research Service</institution>
          </institution-wrap>
        </funding-source>
        <award-id>58-8040-8-014-F</award-id>
        <principal-award-recipient>
          <name>
            <surname>Hsiao</surname>
            <given-names>William W. L.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000038</institution-id>
            <institution>Natural Sciences and Engineering Research Council of Canada</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CGS-M</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4312-5992</contrib-id>
          <name>
            <surname>Nguyen</surname>
            <given-names>Matthew H.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>DD is funded by Genome Canada Project 286GET and the USDA NACA Contract 58-8040-8-014-F to WWLH. MHN is funded by CGS-M Scholarship. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="3"/>
      <table-count count="0"/>
      <page-count count="7"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All relevant data for this study are publicly available from the GitHub repository (<ext-link xlink:href="https://github.com/cidgoh/ontotrek" ext-link-type="uri">https://github.com/cidgoh/ontotrek</ext-link>).</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All relevant data for this study are publicly available from the GitHub repository (<ext-link xlink:href="https://github.com/cidgoh/ontotrek" ext-link-type="uri">https://github.com/cidgoh/ontotrek</ext-link>).</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>There are currently many challenges in educating stakeholders with little ontology familiarity about the implications of trying to describe a domain of interest within the context of current ontology domain coverage, and curation and infrastructure components necessary to support such an effort. Moreover, it is difficult to visualize the interconnectedness between different ontologies using existing tools. Most ontology visualization tools produce a 2-dimensional representation. Protégé [<xref rid="pone.0286728.ref001" ref-type="bibr">1</xref>] is the most widely used software for building and maintaining ontologies, but uses a 2D expandable hierarchic tree representation of terms that requires clicking and scrolling to assess the structure and magnitude of an ontology. Additional plugins can be added to Protégé, such as OntoGraf which adds interactive navigation of ontology terms and relationships. However, such a visualizer still struggles to represent large ontologies in a clean manner, often containing illegible labels and crowded layouts with overlapping edges when zoomed-out, and when zoomed-in, the challenge of tracing edges that journey out of viewport scope. Here “viewport” refers to an interactive software application window where the ontology is rendered.</p>
    <p>There have also been ontology visualization approaches that provide a 3D hierarchic representation. OntoSphere [<xref rid="pone.0286728.ref002" ref-type="bibr">2</xref>] aims to represent ontology semantics beyond the basic class-subclass hierarchy by providing a few views including a RootFocus summary view which represents unexplored branches as larger balls, and leaf nodes are shown as small balls, while edges between nodes indicate some level of focused exploration, all presented on the surface of a larger semi-transparent sphere. The TreeFocus view provides a 3 tier exploration of a node and its parent and child subclass (taxonomic) context as well. Neither of the views provides full top-down hierarchies, or an indication of imported vs. home-grown entities.</p>
    <p>One major concern about many existing 2D and 3D graph diagram tools is that they depend on nondeterministic force-directed graph algorithms that generate an unpredictable orientation and layout of nodes over time often as a result of randomly placed initial nodes [<xref rid="pone.0286728.ref003" ref-type="bibr">3</xref>]. Users can only counteract this to some degree by manually fixing or “pinning” specific nodes. One resilient approach is the “Botanical Tree” algorithm [<xref rid="pone.0286728.ref004" ref-type="bibr">4</xref>], which builds branch widths according to a size metric of branch content, and concludes with “phiballs”, spheres that are decorated with either a conical cap, or multiple polka dots that represent each leaf edge emanating from that juncture. Guided by the class structure of an upper-level ontology, these trees could provide a consistent layout steered by branch bifurcation and leaf volume.</p>
    <p>Here, we present OntoTrek, a lightweight, javascript-based, open-source web browser application to help visualize ontologies in a 3-dimensional representation. Inspired by the “Botanical Tree” algorithm, our method exposes the leaf and node structure to provide labelling as well as other functionalities. It explores the idea that humans benefit from data representations that maintain spatial consistency across successive presentations. This translates to enabling users to virtually fly around and through the OntoTrek 3D viewport’s representation of an ontology. The main use case of Ontotrek is to visually answer the question of how many different ontologies are imported into a given ontology, and which classes they appear under. The use-case arises in situations where ontologies are importing terms from other ontologies in order to facilitate data harmonization, as exemplified by the Open Biological and Biomedical Ontologies (OBO) Foundry [<xref rid="pone.0286728.ref005" ref-type="bibr">5</xref>], which contains many ontologies that follow the same set of principles including a commitment to collaborative development, conformance to an upper level ontology like the Basic Formal Ontology (BFO) [<xref rid="pone.0286728.ref006" ref-type="bibr">6</xref>], and the reuse of common object properties. Well known examples of OBO Foundry ontologies are the domain specific Gene Ontology (GO) and the Human Disease Ontology (DOID). OBO Foundry also contains application ontologies which often reuse terms from other related upper-level or domain-specific ontologies. The main goal during OntoTrek development was to have a browser-based user interface, allowing the ability to navigate through an ontology’s class-subclass hierarchy. Moreover, large ontologies should be supported, with legible node layers and quick rendering times.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Design and implementation</title>
    <p>OntoTrek is built in JavaScript using 3d-force-graph (<ext-link xlink:href="https://github.com/vasturiano/3d-force-graph" ext-link-type="uri">https://github.com/vasturiano/3d-force-graph</ext-link>), a light-weight and very fast WebGL 3D graph rendering software that provides a suite of graph node and edge rendering features along with some user interface interactivity. These features are crucial for enabling smooth navigation of an ontology having thousands of terms. As with most graphics libraries, there are ultimately limits to 3d-force-graph rendering time as a function of both CPU performance and the count of ontology terms to process, and limits to built-in navigation algorithms, which we discuss below.</p>
    <sec id="sec003">
      <title>Ontology structure</title>
      <p>OntoTrek reads, parses and visualizes an OWL ontology file directly, either from an example selection of OBO Foundry ontology files that sit in OntoTrek’s data folder, or by dynamically fetching one from a user-provided URL. This allows new or in-development ontologies to be viewed. OntoTrek renders class-subclass relations starting from parent-less entities (e.g. owl:Thing or “entity”, from BFO). Many OWL ontologies explicitly use the single <bold>owl:Thing</bold> “root node” as the top class/node of an umbrella-shaped tree. An ontology can have other top level nodes which have no superclass connection to owl:Thing explicitly stated. OntoTrek shows these (including bfo:Entity) as “stand alone” nodes, disconnected from owl:Thing.</p>
      <p>If a class has multiple superclasses, only the first one listed (as an owl:subClassOf parent node) will be used in the hierarchy. As well, OntoTrek doesn’t render other kinds of relations that axioms reference, nor will it show classes which only appear in axioms and not in the class hierarchy. OntoTrek’s design objective is primarily to focus on an informative display of the class hierarchy itself; we have not embarked on the very careful work required to display other kinds of relations in a limited / local way that does not overwhelm the visual interface. One can foresee an object-centric display involving the engineering of templates, each focusing on an ontology term class that represents a type of object, and edges emanating from it to other objects and data properties as required by relevant axioms.</p>
      <p>The visible structure drawn must be largely deterministic, placing nodes consistently in the same region relative to each other on each fresh generation of the visualization, thus keeping the location of terms consistent. Most force graph algorithms can be set to be deterministic, and OntoTrek uses 3d-force-graph this way. If an ontology is loaded into OntoTrek, and its class structure is identical to a previous loading, then its visual structure will be identical. Of course, modifications to an ontology’s class structure likely result in visual changes over time, sometimes radically, depending on how high up the hierarchy that term additions or deletions occur. A few strategies described below ameliorate this inconsistency.</p>
      <p>OntoTrek allows an upper-level ontology (such as BFO 2.1’s 34 terms) to have nodes whose positions are fixed (so-called “pinned” nodes), such that a force-directed algorithm which is positioning underlying nodes (classes of other subordinate ontologies) iterates from that fixed upper-level node constellation. This is key to providing a recognizable and semantically relevant layout from the summit of the term landscape, in which for example one branch or pole from the root node holds upper level ontology continuants or endurants, and another holds occurants or perdurants, and so on. Consequently, even high-level restructuring of underlying ontology hierarchies doesn’t radically change the shape of the overall visualization. A configuration file (the “/js/lookup_tables.json” layout object) holds pinned nodes, which are automatically referenced by any loaded ontology.</p>
    </sec>
    <sec id="sec004">
      <title>Ontology rendering</title>
      <p>At least one rendered view should reflect an ontology’s stated or inferred class hierarchy, so there can be a “top” and a “bottom” in 3D space for aligning this hierarchy in. Navigation through the viewport should give visual clues as to where the “top” is, and it should be easy to reestablish an “up” perspective on ontology contents after navigating around them from any orientation. OntoTrek orients each top-level node’s hierarchy in the viewport in the same vertical direction. The depth of a node from its root(s) is apparent by placing nodes of a given degree of depth (n = 1,2,3, …) in a correspondingly deep horizontal plane, yielding a stratified appearance. Top level terms—which OntoTrek’s demo ontologies often refer to—represent upper level ontology terms of the Basic Formal Ontology, and are given a larger size, enabling them to be discerned while substantially zoomed-out from the graph. A bright yellow color also enhances their visibility, and pinning provides stability.</p>
      <p>For most ontologies listed in the Search tab’s pulldown list menu, performance of the initial force graph rendering phase would be slower if done from scratch, but these ontologies are assisted by a cache file containing the coordinates of a previous graph rendering.</p>
      <p>Force graph solutions often encounter problems with an initial state of (pseudo)randomly positioned nodes and connecting edges which undergo the force algorithm’s attraction and repulsion kinetics. With larger node count, “ostracised” nodes are often trapped in territory that their long edges can’t contract them out of. The OntoTrek solution is, starting with the root node(s), to dynamically add generations of child nodes as the algorithm runs, allowing it to settle on the positions of each generation before advancing to the next, which encourages the local positioning of primary subclass nodes. Subsequent generations are spawned on lower tiers pseudo-randomly with respect to their parents. The algorithm basically builds mountains of terms from the top-down, with lower-tier nodes pulling away from each other to help reduce density in the hierarchy, while pinned top level nodes ensure that underlying nodes follow the same topology.</p>
      <p>The consistent color coding of term nodes is key to illustrating the interconnectedness of 3rd party ontologies. A lookup table assigns colors to most of OBO Foundry’s ontology prefixes so that any of an ontology’s nodes receives the same color, enabling easier visual recognition, although ontology term reuse can involve upwards of 30 prefixes and their colors (for example, OBI, the Ontology for Biomedical Investigations, imports terms having over 20 different prefixes [<xref rid="pone.0286728.ref007" ref-type="bibr">7</xref>]).</p>
      <p>Increased foreground detail, including textual legibility, enables us to navigate to places in the hierarchy visually according to other cues besides text. The 3D landscape also allows structure to be “stored” in plain view at scale, which is a kind of data compression as long as some user memory of its content is accessible, which currently is achieved by mouseover identification of distant node entities. Currently we present only the matched entity label on that event, but this could be modified to show a node’s upper level ontology category or content as a summary view.</p>
      <p>OntoTrek actually has a hybrid 3D and 2D view, available by toggling the “<bold>Underlying ontology branches rendered as vertical slice(s)</bold>” setting, which illustrates benefits of both combined by showing an upper level ontology in 3D, and underlying ontologies in vertical planes of 2D hierarchies. This option provides a fly-through view that separates out the labels which is quite effective with a medium sized ontology like AGRO or GenEpiO. The algorithm, like the general 3D one, could be improved to add more space to lower level nodes and their labels.</p>
      <p>Term labels and synonyms can be searched in the OntoTrek interface (specifically on the side bar, in the Term Search and Term Context boxes in <xref rid="pone.0286728.g001" ref-type="fig">Fig 1</xref>) in order to locate and travel to the term node of interest. A pull-down list of all terms available in the ontology is given, but this also contains the usability feature that as one types, both term label and synonyms can be searched, so that ‘dog’, though not present in the label, will return term ‘Cannis lupus familiaris’. This enables people to use colloquial vocabulary to access information a formal ontology can provide. A matching term is displayed along with its parent(s) and children, and its definition and ontology lookup service links for OntoBee.org and EMBL-EBI Ontology Lookup Service shown in <xref rid="pone.0286728.g001" ref-type="fig">Fig 1</xref>. Clicking on a node link or dashboard “children” menu selection triggers a focus on the child node.</p>
      <fig position="float" id="pone.0286728.g001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0286728.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Example of the user interface of Ontotrek while selecting the AGRO term “conflagration”.</title>
          <p>Here we demonstrate the dashboard which presents the term definition as well as ontology service lookup links.</p>
        </caption>
        <graphic xlink:href="pone.0286728.g001" position="float"/>
      </fig>
      <p>There are a few Settings tab options that can improve rendering performance. These should be turned on or off before starting to render a selected ontology.</p>
      <list list-type="order">
        <list-item>
          <p><bold>Show labels</bold>: By default, OntoTrek renders both a node label, AND a semi-transparent background box slightly behind it, to help with legibility. This feature is costly, but it can be turned off with the “Show labels” toggle.</p>
        </list-item>
        <list-item>
          <p><bold>Show a wireframe view</bold>: By default, OntoTrek renders heavier edges the higher up one goes in the hierarchy, with lower level edges past a certain depth having just 1 unit of thickness, which doesn’t invoke polygon rendering. This option sets edges to have the fastest 1 unit of thickness for any edge, aside from the top-level ontology ones, which are untouched. (This option also eliminates transparency on the default labels shown with “Show labels” set to true).</p>
        </list-item>
        <list-item>
          <p><bold>Render from top down to this node depth</bold>: This option allows display of only upper levels of more massive ontologies if desired.</p>
        </list-item>
        <list-item>
          <p><bold>Show deprecated terms</bold>: By default deprecated terms are hidden from display to reduce clutter for ontologies that include these terms as parent-less top-level nodes.</p>
        </list-item>
      </list>
      <p>Users can rotate, zoom, or pan the display. Clicking on any node in the Ontotrek viewport causes the node to be highlighted in red, and also triggers a transition animation that moves the viewport camera perspective to an angled view close to and above the node. This built-in force-graph-3d feature is problematic because the “rollercoaster” transition animation doesn’t keep the viewport itself oriented vertically, so it is up to a user to try to realign the view after the transition has finished.</p>
      <p>OntoTrek is hosted at <ext-link xlink:href="http://genepio.org/ontotrek/" ext-link-type="uri">http://genepio.org/ontotrek/</ext-link>. A user guide is provided at <ext-link xlink:href="https://github.com/cidgoh/ontotrek/wiki" ext-link-type="uri">https://github.com/cidgoh/ontotrek/wiki</ext-link>. Users can also build and run OntoTrek on their own computer. OntoTrek source code is available at <ext-link xlink:href="https://github.com/cidgoh/ontotrek" ext-link-type="uri">https://github.com/cidgoh/ontotrek</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec005">
    <title>Discussion</title>
    <p>The main aim of OntoTrek is the visualization of term reuse in ontologies, which is demonstrated by a number of reference and application ontologies that illustrate varying degrees of reuse of upper level BFO classes and terms from other ontologies. <xref rid="pone.0286728.g002" ref-type="fig">Fig 2</xref> shows OBI, containing both its own terms (nodes and edges coloured in white), and the BFO upper framework (coloured in yellow) as well as terms of other ontologies (e.g. PATO in green). A comprehensive list of referenced ontologies, with the number of terms referenced and their corresponding colour code, can be accessed from the “Legend” tab.</p>
    <fig position="float" id="pone.0286728.g002">
      <object-id pub-id-type="doi">10.1371/journal.pone.0286728.g002</object-id>
      <label>Fig 2</label>
      <caption>
        <title>OBI visualization in OntoTrek (with labels hidden).</title>
        <p>The OntoTrek structure shows the interconnectedness of different ontologies within OBI. For example, the green subtree shows PATO, the orange subtree shows GO, the blue subtree shows CL and the yellow parent tree shows the BFO backbone. White nodes are unique OBI terms.</p>
      </caption>
      <graphic xlink:href="pone.0286728.g002" position="float"/>
    </fig>
    <p>An example of an included reference ontology within OntoTrek is DOID (Human Disease Ontology) shown in <xref rid="pone.0286728.g003" ref-type="fig">Fig 3</xref>. It does not reference terms from other ontologies, including the BFO backbone. The <bold>owl:Thing</bold> node is still included, but is not connected to any term within the DOID ontology. In this case, the root node/top point of the tree is the base term of the ontology (i.e. disease).</p>
    <fig position="float" id="pone.0286728.g003">
      <object-id pub-id-type="doi">10.1371/journal.pone.0286728.g003</object-id>
      <label>Fig 3</label>
      <caption>
        <title>DOID visualization in OntoTrek (with labels hidden).</title>
        <p>The yellow disconnected node is the owl:Thing root of BFO. The OntoTrek structure shows that DOID doesn’t share any terms with other ontologies. It also does not contain the BFO backbone, observed from the lack of a branch between its root and the owl:Thing node.</p>
      </caption>
      <graphic xlink:href="pone.0286728.g003" position="float"/>
    </fig>
    <p>Although OntoTrek can theoretically display ontologies of any size, ones that have less than 10,000 terms are easier to load on contemporary personal computers (OntoTrek was developed on a Mac Powerbook in which ontologies like AGRO with over 4,000 terms renders quickly). The coordinate caching system enables larger ontologies to quickly render rather than be delayed by the force graph algorithm’s iteration time. Going beyond the previously mentioned performance related label and edge rendering settings, a more sophisticated future approach would provide a richer information display just for the line-of-sight vicinity of the mouse cursor, assuming that is where the user’s attention is focused. Label rendering could be eliminated for more distant or peripheral nodes. This would also reduce clutter, and pave the way for display of multiple ontologies side-by-side in the viewport.</p>
    <p>Finally, it will be important to eliminate changes in pitch and roll in the animation algorithm experienced when zooming into a node. A top down perspective should be maintained during flight. Ideally the viewport is stabilized in the same way when a user manually navigates through the 3D space.</p>
  </sec>
  <sec sec-type="conclusions" id="sec006">
    <title>Conclusion</title>
    <p>OntoTrek is a 3D ontology viewer that provides an interactive user experience through a single viewport. OntoTrek’s ease of use is aimed not only at ontology curators, but also those unfamiliar with ontologies and their structure. A clear representation of the interconnectedness of ontologies is shown, while keeping an intuitive hierarchical structure. In addition to the included OBO Foundry ontologies, users can load other web-hosted OWL ontology files for visualization. OntoTrek is primarily intended for ontology display, but with continued development and support, could target the visualization of graph databases containing ontology-driven content.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We thank the reviewers for suggested improvements to the application.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0286728.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Musen</surname><given-names>MA</given-names></name>. <article-title>The Protégé Project: A Look Back and a Look Forward</article-title>. <source>AI Matters</source>. <year>2015</year>;<volume>1</volume>(<issue>4</issue>):<fpage>4</fpage>–<lpage>12</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1145/2757001.2757003</pub-id><?supplied-pmid 27239556?><pub-id pub-id-type="pmid">27239556</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0286728.ref002">
      <label>2</label>
      <mixed-citation publication-type="other">Bosca A, Bonino D. OntoSphere3D: A Multidimensional Visualization Tool for Ontologies. In: 17th International Workshop on Database and Expert Systems Applications (DEXA’06); 2006. p. 339–343.</mixed-citation>
    </ref>
    <ref id="pone.0286728.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Dudáš</surname><given-names>M</given-names></name>, <name><surname>Lohmann</surname><given-names>S</given-names></name>, <name><surname>Svátek</surname><given-names>V</given-names></name>, <name><surname>Pavlov</surname><given-names>D</given-names></name>. <article-title>Ontology visualization methods and tools: a survey of the state of the art</article-title>. <source>The Knowledge Engineering Review</source>. <year>2018</year>;<volume>33</volume>:<fpage>e10</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1017/S0269888918000073</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0286728.ref004">
      <label>4</label>
      <mixed-citation publication-type="other">Kleiberg E, van de Wetering H, van Wijk JJ. Botanical visualization of huge hierarchies. In: IEEE Symposium on Information Visualization, 2001. INFOVIS 2001.; 2001. p. 87–94.</mixed-citation>
    </ref>
    <ref id="pone.0286728.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>B</given-names></name>, <name><surname>Ashburner</surname><given-names>M</given-names></name>, <name><surname>Rosse</surname><given-names>C</given-names></name>, <name><surname>Bard</surname><given-names>J</given-names></name>, <name><surname>Bug</surname><given-names>W</given-names></name>, <name><surname>Ceusters</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>The OBO Foundry: coordinated evolution of ontologies to support biomedical data integration</article-title>. <source>Nature Biotechnology</source>. <year>2007</year>;<volume>25</volume>(<issue>11</issue>):<fpage>1251</fpage>–<lpage>1255</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt1346</pub-id><?supplied-pmid 17989687?><pub-id pub-id-type="pmid">17989687</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0286728.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">Smith B, Kumar A, Bittner T. Basic Formal Ontology for Bioinformatics. IFOMIS Reports; 2005.</mixed-citation>
    </ref>
    <ref id="pone.0286728.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Bandrowski</surname><given-names>A</given-names></name>, <name><surname>Brinkman</surname><given-names>R</given-names></name>, <name><surname>Brochhausen</surname><given-names>M</given-names></name>, <name><surname>Brush</surname><given-names>MH</given-names></name>, <name><surname>Bug</surname><given-names>B</given-names></name>, <name><surname>Chibucos</surname><given-names>MC</given-names></name>, <etal>et al</etal>. <article-title>The Ontology for Biomedical Investigations</article-title>. <source>PLOS ONE</source>. <year>2016</year>;<volume>11</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>19</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0154556</pub-id><?supplied-pmid 27128319?><pub-id pub-id-type="pmid">27128319</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pone.0286728.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Abel C.H. Chen</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Abel C.H. Chen</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">22 Nov 2022</named-content>
    </p>
    <p><!-- <div> -->PONE-D-22-27603<!-- </div> --><!-- <div> -->OntoTrek: 3D visualization of application ontology class hierarchies<!-- </div> --><!-- <div> -->PLOS ONE</p>
    <p>Dear Dr. Hsiao,</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Please submit your revised manuscript by Jan 06 2023 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list></p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Abel C.H. Chen</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Journal Requirements:</p>
    <p>When submitting your revision, we need you to address these additional requirements.</p>
    <p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at </p>
    <p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and </p>
    <p>
      <ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
    </p>
    <p>2. Thank you for stating the following financial disclosure: </p>
    <p> "DD is funded by Genome Canada Project 286GET and the USDA NACA Contract 58-8040-8-014-F to WWLH. MHN is funded by CGS-M Scholarship."</p>
    <p>Please state what role the funders took in the study.  If the funders had no role, please state: "The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript." </p>
    <p>If this statement is not correct you must amend it as needed. </p>
    <p>Please include this amended Role of Funder statement in your cover letter; we will change the online submission form on your behalf.</p>
    <p>3. PLOS requires an ORCID iD for the corresponding author in Editorial Manager on papers submitted after December 6th, 2016. Please ensure that you have an ORCID iD and that it is validated in Editorial Manager. To do this, go to ‘Update my Information’ (in the upper left-hand corner of the main menu), and click on the Fetch/Validate link next to the ORCID field. This will take you to the ORCID site and allow you to create a new iD or authenticate a pre-existing iD in Editorial Manager. Please see the following video for instructions on linking an ORCID iD to your Editorial Manager account: <ext-link xlink:href="https://www.youtube.com/watch?v=_xcclfuvtxQ" ext-link-type="uri">https://www.youtube.com/watch?v=_xcclfuvtxQ</ext-link></p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Partly</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: N/A</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: The authors describe a 3-D visualization system for browsing the content of an ontology. One of the main motivations seems to be to be able to visualize which content from external terminologies is imported into the ontology and under which branches of the ontology it is found. In testing the interface is challenging to use. For any ontology with more than a tiny number of classes, it is hard to see the different nodes, and the UI zooms in and out confusingly. A positive aspect is that ontology content from different sources is colored differently, so that the source can be observed at a glance.</p>
    <p>I think there are three main aspects the authors could clarify or develop further that would help to make this system more usable:</p>
    <p>1. Performance is a serious problem when browsing real world ontologies in the system.</p>
    <p>2. The majority of usages of external content in OBO ontologies is via composition, rather than inheritance. For example an HPO phenotype is related to the affected anatomical structure. For this reason it would be valuable to traverse these kinds of links rather than just subClassOf.</p>
    <p>3. The main issue that I think should either receive more development, or be addressed more clearly in the paper, is what purpose does the third dimension serve? It seems like many of their ideas (e.g., clearly denoting external content, showing the branching pattern from superclass to subclass) could be supported by a (possibly more scalable) two dimensional system. If one dimension denotes more-general-to-more-specific, and the second dimension separates peer terms from each other, what does change in the third dimension indicate?</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>**********</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0286728.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">15 Apr 2023</named-content>
    </p>
    <p>please see uploaded file titled "Ontotrek Response to Reviewers"</p>
    <supplementary-material id="pone.0286728.s001" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Ontotrek Response to Reviewers.pdf</named-content></p>
      </caption>
      <media xlink:href="pone.0286728.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pone.0286728.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Abel C.H. Chen</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Abel C.H. Chen</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">23 May 2023</named-content>
    </p>
    <p>OntoTrek: 3D visualization of application ontology class hierarchies</p>
    <p>PONE-D-22-27603R1</p>
    <p>Dear Dr. Hsiao,</p>
    <p>We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p>
    <p>Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p>
    <p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p>
    <p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p>
    <p>Kind regards,</p>
    <p>Abel C.H. Chen</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Additional Editor Comments (optional):</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <!-- <font color="black"> -->
      <bold>Comments to the Author</bold>
    </p>
    <p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.<!-- </font> --></p>
    <p>Reviewer #1: All comments have been addressed</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->2. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p>
    <p>Reviewer #1: N/A</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p>
    <p>Reviewer #1: Yes</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->6. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p>
    <p>Reviewer #1: The figure images are somewhat low resolution; the live application is a bit sharper. If possible, I suggest updating them.</p>
    <p>**********</p>
    <p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p>
    <p>Reviewer #1: No</p>
    <p>**********</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0286728.r004" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0286728.r004</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Abel C.H.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Abel C.H. Chen</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Abel C.H. Chen</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0286728" id="rel-obj004" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">26 May 2023</named-content>
    </p>
    <p>PONE-D-22-27603R1 </p>
    <p>OntoTrek: 3D visualization of application ontology class hierarchies </p>
    <p>Dear Dr. Hsiao:</p>
    <p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
    <p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p>
    <p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p>
    <p>Thank you for submitting your work to PLOS ONE and supporting open access. </p>
    <p>Kind regards, </p>
    <p>PLOS ONE Editorial Office Staff</p>
    <p>on behalf of</p>
    <p>Dr. Abel C.H. Chen </p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
  </body>
</sub-article>
