<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Cancers (Basel)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Cancers (Basel)</journal-id>
    <journal-id journal-id-type="publisher-id">cancers</journal-id>
    <journal-title-group>
      <journal-title>Cancers</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2072-6694</issn>
    <publisher>
      <publisher-name>MDPI</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7913958</article-id>
    <article-id pub-id-type="pmid">33557152</article-id>
    <article-id pub-id-type="doi">10.3390/cancers13040617</article-id>
    <article-id pub-id-type="publisher-id">cancers-13-00617</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PathoFusion: An Open-Source AI Framework for Recognition of Pathomorphological Features and Mapping of Immunohistochemical Data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0669-6358</contrib-id>
        <name>
          <surname>Bao</surname>
          <given-names>Guoqing</given-names>
        </name>
        <xref ref-type="aff" rid="af1-cancers-13-00617">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Xiuying</given-names>
        </name>
        <xref ref-type="aff" rid="af1-cancers-13-00617">1</xref>
        <xref rid="c1-cancers-13-00617" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Ran</given-names>
        </name>
        <xref ref-type="aff" rid="af2-cancers-13-00617">2</xref>
        <xref ref-type="aff" rid="af3-cancers-13-00617">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Loh</surname>
          <given-names>Christina</given-names>
        </name>
        <xref ref-type="aff" rid="af2-cancers-13-00617">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3129-1114</contrib-id>
        <name>
          <surname>Adeyinka</surname>
          <given-names>Oreoluwa Daniel</given-names>
        </name>
        <xref ref-type="aff" rid="af2-cancers-13-00617">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pieris</surname>
          <given-names>Dula Asheka</given-names>
        </name>
        <xref ref-type="aff" rid="af2-cancers-13-00617">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cherepanoff</surname>
          <given-names>Svetlana</given-names>
        </name>
        <xref ref-type="aff" rid="af4-cancers-13-00617">4</xref>
        <xref ref-type="aff" rid="af5-cancers-13-00617">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gracie</surname>
          <given-names>Gary</given-names>
        </name>
        <xref ref-type="aff" rid="af4-cancers-13-00617">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lee</surname>
          <given-names>Maggie</given-names>
        </name>
        <xref ref-type="aff" rid="af5-cancers-13-00617">5</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>McDonald</surname>
          <given-names>Kerrie L.</given-names>
        </name>
        <xref ref-type="aff" rid="af6-cancers-13-00617">6</xref>
        <xref ref-type="aff" rid="af7-cancers-13-00617">7</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-9317-9526</contrib-id>
        <name>
          <surname>Nowak</surname>
          <given-names>Anna K.</given-names>
        </name>
        <xref ref-type="aff" rid="af6-cancers-13-00617">6</xref>
        <xref ref-type="aff" rid="af8-cancers-13-00617">8</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Banati</surname>
          <given-names>Richard</given-names>
        </name>
        <xref ref-type="aff" rid="af6-cancers-13-00617">6</xref>
        <xref ref-type="aff" rid="af9-cancers-13-00617">9</xref>
        <xref ref-type="aff" rid="af10-cancers-13-00617">10</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Buckland</surname>
          <given-names>Michael E.</given-names>
        </name>
        <xref ref-type="aff" rid="af5-cancers-13-00617">5</xref>
        <xref ref-type="aff" rid="af6-cancers-13-00617">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Graeber</surname>
          <given-names>Manuel B.</given-names>
        </name>
        <xref ref-type="aff" rid="af2-cancers-13-00617">2</xref>
        <xref rid="c1-cancers-13-00617" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Lyng</surname>
          <given-names>Fiona M.</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
      <contrib contrib-type="editor">
        <name>
          <surname>Brousset</surname>
          <given-names>Pierre</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
      <contrib contrib-type="editor">
        <name>
          <surname>Weis</surname>
          <given-names>Serge</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <aff id="af1-cancers-13-00617"><label>1</label>School of Computer Science, The University of Sydney, J12/1 Cleveland St, Darlington, Sydney, NSW 2008, Australia; <email>guoqing.bao@sydney.edu.au</email></aff>
    <aff id="af2-cancers-13-00617"><label>2</label>Ken Parker Brain Tumour Research Laboratories, Brain and Mind Centre, Faculty of Medicine and Health, The University of Sydney, Sydney, NSW 2006, Australia; <email>raxu4545@uni.sydney.edu.au</email> (R.X.); <email>cloh4889@uni.sydney.edu.au</email> (C.L.); <email>oade2535@uni.sydney.edu.au</email> (O.D.A.); <email>dpie0799@uni.sydney.edu.au</email> (D.A.P.)</aff>
    <aff id="af3-cancers-13-00617"><label>3</label>Department of Neurosurgery, Xuanwu Hospital, Capital Medical University, No. 45 Changchun Street, Beijing 100053, China</aff>
    <aff id="af4-cancers-13-00617"><label>4</label>St Vincent’s Hospital, Victoria Street, Darlinghurst, NSW 2010, Australia; <email>svetlana.cherepanoff@gmail.com</email> (S.C.); <email>gary.gracie@svha.org.au</email> (G.G.)</aff>
    <aff id="af5-cancers-13-00617"><label>5</label>Department of Neuropathology, RPA Hospital and Brain and Mind Centre, Faculty of Medicine and Health, The University of Sydney, Sydney, NSW 2006, Australia; <email>maggie.lee@sydney.edu.au</email> (M.L.); <email>michael.buckland@sydney.edu.au</email> (M.E.B.)</aff>
    <aff id="af6-cancers-13-00617"><label>6</label>Cooperative Trials Group of Neuro-Oncology (COGNO), Sydney, NSW 1450, Australia; <email>k.mcdonald@braincancerconsultancy.com</email> (K.L.M.); <email>anna.nowak@uwa.edu.au</email> (A.K.N.); <email>rib@ansto.gov.au</email> (R.B.)</aff>
    <aff id="af7-cancers-13-00617"><label>7</label>Brain Cancer Consultancy, Sydney, NSW 2040, Australia</aff>
    <aff id="af8-cancers-13-00617"><label>8</label>Department of Medical Oncology, University of Western Australia, Perth, WA 6009, Australia</aff>
    <aff id="af9-cancers-13-00617"><label>9</label>Life Sciences, Australian Nuclear Science and Technology Organisation, Sydney, NSW 2234, Australia</aff>
    <aff id="af10-cancers-13-00617"><label>10</label>Medical Imaging and Radiation Sciences, Brain and Mind Centre, Faculty of Medicine and Health, The University of Sydney, Sydney, NSW 2006, Australia</aff>
    <author-notes>
      <corresp id="c1-cancers-13-00617"><label>*</label>Correspondence: <email>xiu.wang@sydney.edu.au</email> (X.W.); <email>manuel.graeber@sydney.edu.au</email> (M.B.G.)</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>04</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <volume>13</volume>
    <issue>4</issue>
    <elocation-id>617</elocation-id>
    <history>
      <date date-type="received">
        <day>08</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>1</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 by the authors.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license license-type="open-access">
        <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract>
      <sec>
        <title>Simple Summary</title>
        <p>We present an open-source AI framework for marking, training, and automated recognition of pathological features in whole-slide scans of diagnostic tissue sections. The integrated system permits high-resolution qualitative as well as quantitative morphological analyses of entire histological slides and harbors significant potential to facilitate the microscopic analysis of complex pathomorphological problems and the simultaneous mapping of immunohistochemical markers in routine slide diagnostics.</p>
      </sec>
      <sec>
        <title>Abstract</title>
        <p>We have developed a platform, termed PathoFusion, which is an integrated system for marking, training, and recognition of pathological features in whole-slide tissue sections. The platform uses a bifocal convolutional neural network (BCNN) which is designed to simultaneously capture both index and contextual feature information from shorter and longer image tiles, respectively. This is analogous to how a microscopist in pathology works, identifying a cancerous morphological feature in the tissue context using first a narrow and then a wider focus, hence bifocal. Adjacent tissue sections obtained from glioblastoma cases were processed for hematoxylin and eosin (H&amp;E) and immunohistochemical (CD276) staining. Image tiles cropped from the digitized images based on markings made by a consultant neuropathologist were used to train the BCNN. PathoFusion demonstrated its ability to recognize malignant neuropathological features autonomously and map immunohistochemical data simultaneously. Our experiments show that PathoFusion achieved areas under the curve (AUCs) of 0.985 ± 0.011 and 0.988 ± 0.001 in patch-level recognition of six typical pathomorphological features and detection of associated immunoreactivity, respectively. On this basis, the system further correlated CD276 immunoreactivity to abnormal tumor vasculature. Corresponding feature distributions and overlaps were visualized by heatmaps, permitting high-resolution qualitative as well as quantitative morphological analyses for entire histological slides. Recognition of more user-defined pathomorphological features can be added to the system and included in future tissue analyses. Integration of PathoFusion with the day-to-day service workflow of a (neuro)pathology department is a goal. The software code for PathoFusion is made publicly available.</p>
      </sec>
    </abstract>
    <kwd-group>
      <kwd>artificial intelligence</kwd>
      <kwd>bifocal convolutional neural network</kwd>
      <kwd>CD276</kwd>
      <kwd>malignant glioma</kwd>
      <kwd>microvascular proliferation</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="sec1-cancers-13-00617">
    <title>1. Introduction</title>
    <p>Image analysis is a driver for the development of artificial intelligence (AI) applications and great progress has been made in recent years following the introduction of convolutional neural networks (CNNs) [<xref rid="B1-cancers-13-00617" ref-type="bibr">1</xref>,<xref rid="B2-cancers-13-00617" ref-type="bibr">2</xref>]. Morphological disciplines such as pathology are likely to benefit from the development of specific AI, and publications on the use of CNNs in pathology as well as neuropathology have begun to appear [<xref rid="B3-cancers-13-00617" ref-type="bibr">3</xref>,<xref rid="B4-cancers-13-00617" ref-type="bibr">4</xref>]. An AI-supported workflow in pathology can already be envisioned.</p>
    <p>Immune checkpoint markers are of special interest in cancer research because they may represent powerful new therapeutic targets, as suggested by the significant progress made, especially in the field of melanoma [<xref rid="B5-cancers-13-00617" ref-type="bibr">5</xref>,<xref rid="B6-cancers-13-00617" ref-type="bibr">6</xref>,<xref rid="B7-cancers-13-00617" ref-type="bibr">7</xref>,<xref rid="B8-cancers-13-00617" ref-type="bibr">8</xref>,<xref rid="B9-cancers-13-00617" ref-type="bibr">9</xref>]. Microvascular proliferation is one of the essential hallmarks of glioblastoma [<xref rid="B10-cancers-13-00617" ref-type="bibr">10</xref>]. It is a more specific and reliable sign of malignancy than necrosis, another key morphological feature that distinguishes glioblastoma from WHO grade III glioma. While it is not only endothelial cells that constitute the cellular substrate of microvascular proliferation [<xref rid="B11-cancers-13-00617" ref-type="bibr">11</xref>,<xref rid="B12-cancers-13-00617" ref-type="bibr">12</xref>,<xref rid="B13-cancers-13-00617" ref-type="bibr">13</xref>], recent reports have shown that CD276 (B7-H3), an immune checkpoint marker of prognostic significance [<xref rid="B14-cancers-13-00617" ref-type="bibr">14</xref>,<xref rid="B15-cancers-13-00617" ref-type="bibr">15</xref>,<xref rid="B16-cancers-13-00617" ref-type="bibr">16</xref>], is strongly expressed by abnormal endothelial cells in various cancers including glioblastoma (<xref ref-type="app" rid="app1-cancers-13-00617">Figure S1</xref>) [<xref rid="B14-cancers-13-00617" ref-type="bibr">14</xref>,<xref rid="B17-cancers-13-00617" ref-type="bibr">17</xref>,<xref rid="B18-cancers-13-00617" ref-type="bibr">18</xref>,<xref rid="B19-cancers-13-00617" ref-type="bibr">19</xref>]. The inclusion of immunohistochemical (IHC) data has become a standard for cancer diagnostics and research. </p>
    <p>Given the complex morphological characteristics of human tissue biopsies, their analysis requires an ever-increasing amount of computing resources and advanced learning algorithms. The arrival of more advanced deep CNNs in recent years has made the analysis of whole-slide tissue sections possible. For example, deep residual networks (ResNet) [<xref rid="B20-cancers-13-00617" ref-type="bibr">20</xref>] introduced skip connection to eliminate singularities and alleviate the vanishing gradient problem, which enables training of CNNs that are hundreds and even thousands of layers deep. One of the widely used ResNet models is ResNet-50, which is 50 layers deep and has been used as the reference when comparing network performances. Even more complex architecture such as Xception [<xref rid="B21-cancers-13-00617" ref-type="bibr">21</xref>] integrated skip connection with depth-wise separable convolution and achieved superior performance in comparison to its predecessors. </p>
    <p>On the basis of advanced deep learning models, we have developed an integrated system, termed PathoFusion, which is an AI-based platform for marking, training, and recognition of pathological features in whole-slide images (WSIs). We have used tissue sections obtained from glioblastoma cases to evaluate the system. Adjacent tissue sections were processed for hematoxylin and eosin (H&amp;E) staining and IHC (CD276), respectively, and scanned. PathoFusion is designed to meet three goals: (i) efficient training of convolutional neural networks to recognize key pathomorphological features in routine H&amp;E-stained, scanned histological slides; (ii) improved model generation and increased effectiveness of feature recognition, thus requiring fewer physical cases than conventionally needed for neural network training; and (iii) establishing a method that allows the inclusion of immunohistochemical (IHC) data in the automated analysis given the great importance of immunohistochemistry in contemporary slide-based analyses.</p>
  </sec>
  <sec sec-type="results" id="sec2-cancers-13-00617">
    <title>2. Results</title>
    <sec id="sec2dot1-cancers-13-00617">
      <title>2.1. Recognition of Morphological Features and Associated Immunoreactivity</title>
      <p>A bifocal convolutional neural network (BCNN) was designed and integrated into the PathoFusion platform to make use of bifocal image pairs as described in the methods section. The BCNN was trained on full training/cross-validation data and was subsequently evaluated on H&amp;E and IHC test data, respectively. The predicted class of each paired image patch was assessed against expert marking (ground truth). As shown in <xref ref-type="fig" rid="cancers-13-00617-f001">Figure 1</xref>A,B, PathoFusion reliably identified morphological features (area under the curve (AUC) of 0.985 ± 0.011, precision of 94.4%, and sensitivity of 94.7%) and immunoreactivities (AUC of 0.988 ± 0.001, precision of 96.2%, and sensitivity of 96.1%), respectively, enabling correlation of the tissue expression of CD276 with diagnostic morphological features. </p>
      <p>PathoFusion achieved higher prediction performance for microvascular proliferation (AUC of 0.994) and geographic necrosis (AUC of 0.994) than palisading necrosis (AUC of 0.964); <xref ref-type="fig" rid="cancers-13-00617-f001">Figure 1</xref>A. This result is consistent with a real-world scenario because the latter is also more difficult to identify for human observers. Therefore, the six selected pathomorphological features are currently not recognized at the same level. This is also apparent from the confusion matrix in the left panel of <xref ref-type="fig" rid="cancers-13-00617-f002">Figure 2</xref>. In the much simpler binary case of immunostained sections, PathoFusion achieved the same high performance in recognition of both positive (AUC of 0.990) and negative (AUC of 0.987) tissue areas (<xref ref-type="fig" rid="cancers-13-00617-f001">Figure 1</xref>B and <xref ref-type="fig" rid="cancers-13-00617-f002">Figure 2</xref> (right panel)) as expected.</p>
      <p>As shown in <xref ref-type="fig" rid="cancers-13-00617-f001">Figure 1</xref>C, the BCNN integrated into our framework achieved higher performance than popular state-of-the-art deep learning models, including ResNet-50, Xception and transfer learning (TL)- [<xref rid="B22-cancers-13-00617" ref-type="bibr">22</xref>,<xref rid="B23-cancers-13-00617" ref-type="bibr">23</xref>,<xref rid="B24-cancers-13-00617" ref-type="bibr">24</xref>] based Xception (pretrained on ImageNet [<xref rid="B25-cancers-13-00617" ref-type="bibr">25</xref>]). Importantly, however, the BCNN utilizes only half of the number of network parameters compared to ResNet-50 and Xception, suggesting that our BCNN is a more efficient neural network for the analysis of histopathology images. In addition, the BCNN achieved superior performance compared to its subnet implementation (<xref ref-type="fig" rid="cancers-13-00617-f001">Figure 1</xref>C), which demonstrated the effectiveness of the bifocal design. An analysis of the mechanisms underlying such a performance gain is beyond the scope of this work and has been dealt with elsewhere [<xref rid="B26-cancers-13-00617" ref-type="bibr">26</xref>].</p>
    </sec>
    <sec id="sec2dot2-cancers-13-00617">
      <title>2.2. Analysis of Entire Histological Sections</title>
      <p>The capability of PathoFusion in tile-level recognition formed the basis for the automated analysis of entire histological sections. As shown in <xref ref-type="fig" rid="cancers-13-00617-f003">Figure 3</xref>, adjacent whole-slide H&amp;E and IHC images were recognized by the PathoFusion framework and converted into heatmaps which visualize the tissue distribution of the six chosen morphological features (first column) as well as corresponding immunoreactivity (subsequent two columns). Sample matching signals of detected microvascular proliferation in H&amp;E whole-slide tissue sections are illustrated in <xref ref-type="fig" rid="cancers-13-00617-f004">Figure 4</xref>A. The predicted heatmaps can be transparently overlaid onto the corresponding H&amp;E-stained tissue sections to allow direct visual inspection and comparative checking (Video S1). The examples shown in <xref ref-type="fig" rid="cancers-13-00617-f005">Figure 5</xref> demonstrate that the BCNN-recognized morphological features closely match the neuropathological features delineated by expert marking. Certain morphological features of which subcategories exist will benefit from additional refinement. Quantitative analysis of sample cases revealed that microvascular proliferation accounted for a sizeable fraction of the H&amp;E heatmaps in line with microscopic appearance (<xref ref-type="app" rid="app1-cancers-13-00617">Table S1</xref>).</p>
      <p>The literature on CD276 tissue staining is limited. We have checked the antibody labeling using a second automated stainer system employing both tumor and non-tumor tissue for control (we compared Leica vs. Ventana). The staining of abnormal tumor blood vessels was strong in both cases. However, it appears that the Ventana method may be more sensitive and there is some interesting immunolabeling outside blood vessels with the latter. Clearly, the additional result deserves further scrutiny.</p>
    </sec>
    <sec id="sec2dot3-cancers-13-00617">
      <title>2.3. Fusion of Bimodal Neuropathological Images</title>
      <p>In addition to recognizing key pathomorphological features in glioblastoma, PathoFusion was shown to be capable of simultaneously mapping the expression of immunoreactivity (CD276 in this work) in adjacent tissue sections, facilitating the interpretation of complex immunohistochemical staining results. The correlative overlap between morphological features and immunoreactivity in the bimodal whole-slide images was visualized through image fusion of the corresponding predicted heatmaps. As shown in <xref ref-type="fig" rid="cancers-13-00617-f003">Figure 3</xref>, the H&amp;E-based heatmaps (first column) were fused with the aligned IHC heatmaps (third column), which resulted in correlation heatmaps (last column) representing feature overlap of the two modalities. For example, the color magenta represents matching signals in tissue areas harboring both microvascular proliferation and associated CD276 immunopositivity. The close association between CD276 and microvascular proliferation in (glioblastoma multiforme) GBM biopsies was clearly demonstrated, permitting qualitative as well as quantitative tissue analyses. Matching signals between microvascular proliferation and CD276 immunopositivity are further illustrated in <xref ref-type="fig" rid="cancers-13-00617-f004">Figure 4</xref>B. </p>
      <p>Quantitative and correlation analyses confirmed that microvascular proliferation had a significantly higher (specific) CD276 expression compared to visually negative normal blood vessels (<xref ref-type="app" rid="app1-cancers-13-00617">Table S2</xref> and <xref ref-type="app" rid="app1-cancers-13-00617">Figure S1</xref>). However, a detailed analysis of CD276 expression is beyond the scope of this paper.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec3-cancers-13-00617">
    <title>3. Discussion</title>
    <p>Morphological diagnostic work in pathology, and especially in neuropathology—given the great structural complexity of the nervous system—has elements of an art. In fact, “painting with words” is a skill taught for the writing of useful microscopic reports that convey a synthesis of complex visual information, requiring both creativity and imagination for their generation. It may seem counterintuitive, therefore, that an AI should be capable of acquiring the equivalent of typical human skills, but similar developments are occurring in other fields, in- and outside of medicine—in software programming and even music, to name a few.</p>
    <p>The PathoFusion framework introduced here provides new tools that may facilitate the transfer of pathomorphological feature detection knowledge to machines. The framework is suited for the analysis of pathomorphological hallmarks in whole histological slides, as also demonstrated in Video S1, allowing the development of a specific (neuro)pathological AI. Both marking and training times can be reduced when using the integrated system, accommodating the time constraints relevant to busy clinical consultants. Expert input is the key limiting factor, since the marking of pathological features (“ground truth”) cannot be delegated to less well-trained observers. On the other hand, a comparatively small cohort of human biopsies was required to carry out the necessary training, which resulted in high testing performance. Being able to train neural networks effectively on the basis of a relatively small number of cases should be useful in many scenarios. </p>
    <p>The histological slides used in pathology and neuropathology can be scanned and converted into digital images. Those images contain an exceptionally rich variety of structural detail and staining patterns. The file size of these images is extremely large (gigabytes), which makes them very challenging to process using conventional methods. However, in all other respects, the images used here are comparable to the digital photographs that are widely employed and have become a predominant focus of AI research. CNNs have been found to be particularly suited for the analysis of images.</p>
    <p>A number of earlier studies have demonstrated the utility of repurposing CNN models pretrained on natural image collections such as ImageNet for medical image analysis [<xref rid="B27-cancers-13-00617" ref-type="bibr">27</xref>,<xref rid="B28-cancers-13-00617" ref-type="bibr">28</xref>]. This approach is referred to as transfer learning and has worked well in some cases where a close relationship exists between the source and target domains, but failed in other instances where knowledge learned from the source domain was less general across sub-domains [<xref rid="B29-cancers-13-00617" ref-type="bibr">29</xref>,<xref rid="B30-cancers-13-00617" ref-type="bibr">30</xref>,<xref rid="B31-cancers-13-00617" ref-type="bibr">31</xref>]. However, our study obviates the need for transfer learning through the use of a dual-path CNN model utilizing bifocal image tiles as input. Our model achieved better recognition performance than popular deep learning models, including ResNet-50 and Xception, pretrained on ImageNet, thus eliminating the need for resource-intensive pretraining.</p>
    <p>The prognostic marker CD276 was chosen as a proof-of-concept example, allowing our AI system to validate its recognition ability autonomously by producing a fusion heatmap that demonstrates the overlap between a morphological feature, microvascular proliferation, and CD276 immunoreactivity. The specific task of mapping CD276 to a subset of blood vessels, and endothelial cells of abnormal tumor blood vessels in particular, can also be performed by a human observer, which is why this marker was chosen for machine recognition because a widely accepted feature is more convincing. A human observer may even be able to perform systematic recognition of a morphological feature in an entire histological section, but it would be a very tedious and time-consuming exercise. Interestingly, CD276 labeling in the present study was strong in tumor vasculature, as expected, but not limited to it when using the Ventana automated tissue staining system. We believe that the CD276 labeling noted when using this staining system deserves further analysis, which is beyond the scope of this manuscript. Extravascular CD276 labeling, which appeared to be partly cellular, is very interesting with regard to the function of CD276 as an immune checkpoint molecule.</p>
    <p>Following training, our BCNNs reliably identified the key morphological features that they had been trained to recognize with AUC performances of 0.985 and 0.988 on H&amp;E and immunohistochemical images, respectively. This formed the basis for the ability to correlate the occurrence of individual pathomorphological features with the tissue expression of CD276. Notably, the close association between CD276 and microvascular proliferation in GBM was faithfully reproduced and visualized by the heatmaps, permitting high-resolution (40× primary magnification) qualitative as well as quantitative morphological analyses of complete histological sections. The method presented here allows quantification of the occurrence of key morphological features and simultaneous matching of immunoreactivities (or other molecular histological data such as in situ hybridization results) to those features. This has not been possible before and may harbor significant potential for brain mapping projects (e.g., Allen Atlas). Another important quality of the PathoFusion framework consists of the independence of its prediction and fusion processes, which do not require human intervention once the BCNN model has been properly trained. The framework is expected to provide a comparable performance on other tumor types and also on non-neoplastic pathological lesions, provided that a qualified observer (experienced consultant) performs the marking, thus establishing the relevant ground truth which is necessary for CNN training. </p>
    <p>There are several methods available to facilitate slide diagnostics—for example, Digital Slide Archive is a web-based interactive system for annotating whole-slide histopathology images which shows a similarity in function to the labeling module of PathoFusion; Cytomine is a machine learning-based open-source platform for collaborative analysis of multi-gigapixel images, but it requires users to provide customized scripts for image analysis. Distinct from Digital Slide Archive and Cytomine, Digipath is the product of a company that provides hardware (e.g., a scanner) as well as online training courses. Compared to all of these, PathoFusion is a light-weight automated framework for the analysis of multi-modal histopathology images, which provides functions ranging from annotation, training and whole-slide image detection to cross-modality quantitative analysis. PathoFusion is also flexible and can be integrated in existing annotation systems, such as Digital Slide Archive, or enhance existing hardware solutions, e.g., a scanner that is capable of detecting tissue structures as well as producing heatmaps for abnormalities.</p>
    <p>The present study has the following limitations. Firstly, we acknowledge that training for the recognition of some pathomorphological features could be improved further by creating more subcategories as well as carefully defining any similar-appearing morphologies (mimics that can cause diagnostic pitfalls), e.g., geographic necrosis with and without bleeding, and palisading necrosis vs. tumor cell palisades without necrosis. Secondly, many additional pathomorphological features could be added to the training in order to be fully prepared for possible confounding pathological signs of unrelated but co-occurring diseases. Thirdly, the quantifications performed in this study were carried out for formal reasons and are not necessarily biologically understood. For instance, some of the novel CD276 immunohistochemical results such as lower-level CD276 expression outside of the tumor vasculature when using the Ventana system deserve additional study.</p>
  </sec>
  <sec id="sec4-cancers-13-00617">
    <title>4. Materials and Methods </title>
    <sec id="sec4dot1-cancers-13-00617">
      <title>4.1. Clinical Cases</title>
      <p>Paraffin sections of 34 WHO grade IV glioma samples, provided by the Australian Genomics and Clinical Outcomes of Glioma (AGOG) tissue bank, were used for this study (University of Sydney Human Ethics Committee Project number 2016/027). Paraffin sections were stained with H&amp;E and scanned at 40X magnification using an Olympus VS-120 scanner. Adjacent sections were processed for CD276 immunohistochemistry at St. Vincent’s Hospital, Sydney, and at the Department of Neuropathology of Royal Prince Alfred Hospital, respectively.</p>
    </sec>
    <sec id="sec4dot2-cancers-13-00617">
      <title>4.2. PathoFusion Framework</title>
      <sec id="sec4dot2dot1-cancers-13-00617">
        <title>4.2.1. Expert Marking and Datasets</title>
        <p>An in-house labeling website was developed to facilitate marking of morphological features by a neuropathology consultant (<xref ref-type="app" rid="app1-cancers-13-00617">Figure S2</xref>). The website forms part of the PathoFusion framework, which, in addition to conventional web server hard- and software, makes use of a laptop computer for manually marking relevant structures. For the initial training and subsequent testing of the BCNN, six typical morphological features were chosen and marked by a consultant neuropathologist (M.B.G.) following WHO criteria [<xref rid="B10-cancers-13-00617" ref-type="bibr">10</xref>] where appropriate: palisading necrosis (I), microvascular proliferation (II), histologically normal-appearing blood vessels (III), geographic necrosis (IV), brain tissue (V), and tumor background (extensive diffuse infiltration of brain tissue by glioma cells, (VI). We used approximately 850 marking dots on average in each whole-slide image to cover six typical pathomorphological features. Each marking dot used for labeling a relevant feature provided the tissue section co-ordinates for a whole or part of a specific morphological feature of interest.</p>
        <p>In brief, a total of 58,526 paired image tiles (sizes of 512 × 512 and 256 × 256 pixels, respectively) were extracted from the 34 H&amp;E whole-slide scans. Every paired image tile was based on one of 29,106 individually marked coordinates (epicenters for extraction) for the recognition of the six selected morphological features. In contrast, the marking of IHC images included only two criteria, i.e., the presence or absence of brown diaminobenzidine-peroxidase reaction product indicating antibody binding, which was based on pixel intensity. A total of 20,644 paired image tiles were extracted from CD276 slide scans. Furthermore, 6648 paired image tiles from 10% of the cases were employed for testing and 51,878 paired image tiles from the remaining scans were used for training and cross-validation. Training and testing data were extracted from different cases and there was no overlap between them. Details of the marking and extraction procedure are illustrated in <xref ref-type="fig" rid="cancers-13-00617-f006">Figure 6</xref>A.</p>
      </sec>
      <sec id="sec4dot2dot2-cancers-13-00617">
        <title>4.2.2. Bifocal Convolutional Neural Network (BCNN)</title>
        <p>The BCNN employed in the PathoFusion framework possesses two input paths that accept one narrow-focus image tile and one paired wide-focus image tile simultaneously. This network is designed to capture both index and contextual feature information from shorter and longer image tiles, respectively. This is analogous to how a human observer works, identifying a feature in the tissue context using first a narrow and then a wider focus (hence, bifocal). Thus, the BCNN consists of two convolutional subnets, one module for feature concatenation, and a layer for classification (<xref ref-type="fig" rid="cancers-13-00617-f006">Figure 6</xref>B). Each subnet has a structure similar to ResNet-26 [<xref rid="B20-cancers-13-00617" ref-type="bibr">20</xref>] but without skip connections [<xref rid="B20-cancers-13-00617" ref-type="bibr">20</xref>]. Detailed information and mathematical formulas characterizing the network are beyond the scope of this paper and have been described elsewhere [<xref rid="B26-cancers-13-00617" ref-type="bibr">26</xref>]; however, core information has been added as supplementary material.</p>
      </sec>
      <sec id="sec4dot2dot3-cancers-13-00617">
        <title>4.2.3. Recognition of Morphological Features and Associated Immunoreactivity</title>
        <p>At the training stage, image augmentation including rotation, contrast, and sharpness adjustments was randomly applied to bifocal image tiles before they were fed into the BCNN model (<xref ref-type="fig" rid="cancers-13-00617-f006">Figure 6</xref>B). The actual training input was therefore diversified and expanded greatly (<italic>n</italic><sup>2</sup> times) compared to conventional methods (<italic>n</italic> times) (left panel, <xref ref-type="fig" rid="cancers-13-00617-f006">Figure 6</xref>A), where <italic>n</italic> is the number of augmentation types. Following training of the model, paired image tiles were extracted from the upper L to bottom R of the whole-slide test images with a stride of 50 pixels (middle panel, <xref ref-type="fig" rid="cancers-13-00617-f006">Figure 6</xref>C). Each foreground image patch pair was classified by the model and assigned to one of the expert-defined morphological feature or immunoreactivity categories—for example, microvascular proliferation and immunopositive expression. The prediction results were converted into feature heatmaps using pseudo-colors (bottom R, <xref ref-type="fig" rid="cancers-13-00617-f006">Figure 6</xref>). It is worth noting that no augmentation was involved at the recognition stage.</p>
      </sec>
      <sec id="sec4dot2dot4-cancers-13-00617">
        <title>4.2.4. Method for Fusing Bimodal Histological Images</title>
        <p>An image fusion method was developed to visualize the correlation (spatial overlap) between recognized morphological features and immunohistochemical staining results (both were BCNN predictions) using bimodal images. In order to achieve this, H&amp;E and IHC whole-slide images were first processed by the pretrained BCNN model (<xref ref-type="fig" rid="cancers-13-00617-f007">Figure 7</xref>A) and then converted into heatmaps (<xref ref-type="fig" rid="cancers-13-00617-f007">Figure 7</xref>B). Since the corresponding H&amp;E and IHC images were obtained from adjacent tissue sections of the same biopsy, an image registration algorithm [<xref rid="B32-cancers-13-00617" ref-type="bibr">32</xref>], making use of feature point correspondences to establish matching signals, was used to align (pair) the IHC heatmap with the corresponding H&amp;E feature heatmap to allow subsequent combined analysis (<xref ref-type="fig" rid="cancers-13-00617-f007">Figure 7</xref>C). The aligned heatmaps were then merged to create the fusion heatmap, and each color in the final fused correlation heatmap represents a distinct spatial association between one of the morphological features and immunoreactivity.</p>
      </sec>
      <sec id="sec4dot2dot5-cancers-13-00617">
        <title>4.2.5. Quantitative Analysis</title>
        <p>The area percentage for each of the six morphological features within H&amp;E whole-slide images was first determined based on classification heatmaps denoted as <inline-formula><mml:math id="mm1"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Accordingly, <inline-formula><mml:math id="mm2"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>h</mml:mi><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the percentage of immunohistochemically positive and negative areas in relation to whole-slide IHC image scans. Next, the percentage of CD276 positivity for each of the diagnostic morphological features was calculated based on the correlation heatmaps as
<inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>,where <inline-formula><mml:math id="mm4"><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the intersection between a morphological feature <inline-formula><mml:math id="mm5"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> and an immunopositive area, while <inline-formula><mml:math id="mm6"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the area taken by a morphological feature <inline-formula><mml:math id="mm7"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
      </sec>
      <sec id="sec4dot2dot6-cancers-13-00617">
        <title>4.2.6. Data Availability and Experimental Reproducibility</title>
        <p>The dataset and the source code used in this study have been released to the public at <uri xlink:href="https://github.com/guoqingbao/Pathofusion">https://github.com/guoqingbao/Pathofusion</uri>. The source code written for our pathology image marking website will be provided for non-commercial and research purposes upon request.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec5-cancers-13-00617">
    <title>5. Conclusions</title>
    <p>Taken together, our results demonstrate that routine histopathological sections from a comparatively small number of cases can be used to train a BCNN effectively. Applied to entire histological sections, PathoFusion has the potential to facilitate the microscopic analysis of complex immunohistochemical markers and H&amp;E-stained tissues in real-world scenarios. In addition, color normalization of histopathology images [<xref rid="B33-cancers-13-00617" ref-type="bibr">33</xref>] may make our method more widely applicable, i.e., when dealing with stained images from different laboratories where variations in color and intensity of the images exist. We are working on improving the capabilities of PathoFusion further by adding more feature definitions and refining the categorization of complex pathomorphological entities such as necrosis subtypes. Integration of the system with the workflows of a neuropathology or pathology department is a goal. In the future, a fully developed expert AI system may especially benefit patients in geographic areas that do not have local access to specialist pathological services such as neuropathology.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>Biopsies were provided by the Australian Genomics and Clinical Outcomes of Glioma (AGOG) tissue bank.</p>
  </ack>
  <fn-group>
    <fn>
      <p><bold>Publisher’s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <app-group>
    <app id="app1-cancers-13-00617">
      <title>Supplementary Materials</title>
      <p>The following are available online at <uri xlink:href="https://www.mdpi.com/2072-6694/13/4/617/s1">https://www.mdpi.com/2072-6694/13/4/617/s1</uri>, Figure S1: CD276 immunopositivity of glioblastoma vasculature., Figure S2: Pathology image labeling module., Table S1: Percentage of each diagnostic feature within whole-slide H&amp;E and IHC images (sample)., Table S2: Percentage of CD276 positivity for each diagnostic morphological feature (sample)., Video S1: Video demonstration of the AI framework for detection of cancerous features in whole-slide tissue sections.</p>
      <supplementary-material content-type="local-data" id="cancers-13-00617-s001">
        <media xlink:href="cancers-13-00617-s001.pdf">
          <caption>
            <p>Click here for additional data file.</p>
          </caption>
        </media>
      </supplementary-material>
    </app>
  </app-group>
  <notes>
    <title>Author Contributions</title>
    <p>Conceptualization, M.B.G., X.W. and G.B.; methodology, G.B.; software, G.B. and M.B.G.; validation, M.B.G., G.B., R.X., C.L., O.D.A., D.A.P. and S.C.; formal analysis, G.B.; investigation, M.B.G., G.B., X.W. and R.X.; resources, G.G., M.L., K.L.M., A.K.N., R.B. and M.E.B.; data curation, G.B., R.X. and M.B.G.; writing—original draft preparation, G.B. and M.B.G.; writing—review and editing, G.B., M.B.G. and R.X.; visualization, G.B.; supervision, M.B.G. and X.W.; project administration, M.B.G., A.K.N., R.B. and M.E.B.; funding acquisition, M.B.G. All authors have read and agreed to the published version of the manuscript.</p>
  </notes>
  <notes>
    <title>Funding</title>
    <p>Aspects of this work were funded by an Australian Research Council (ARC) grant, DP150104472 (MBG).</p>
  </notes>
  <notes>
    <title>Institutional Review Board Statement</title>
    <p>The study was conducted according to the guidelines of the Declaration of Helsinki, and approved by the Institutional Review Board (or Ethics Committee) of The University of Sydney (Project No.: 2016/027, Approval Date: 14 February 2016).</p>
  </notes>
  <notes>
    <title>Informed Consent Statement</title>
    <p>Informed consent was obtained from all subjects involved in the study.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data Availability Statement</title>
    <p>The datasets for image patches presented in this study are openly available in <uri xlink:href="https://github.com/guoqingbao/Pathofusion/tree/master/data">https://github.com/guoqingbao/Pathofusion/tree/master/data</uri>; Data of the tissue sections are available from the authors.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Conflicts of Interest</title>
    <p>The authors declare no conflict of interest.</p>
  </notes>
  <ref-list>
    <title>References</title>
    <ref id="B1-cancers-13-00617">
      <label>1.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Convolutional networks for images, speech, and time series</article-title>
        <source>The Handbook of Brain Theory and Neural Networks</source>
        <publisher-name>The MIT Press</publisher-name>
        <publisher-loc>Cambridge, MA, USA</publisher-loc>
        <year>1995</year>
        <volume>Volume 3361</volume>
        <fpage>1995</fpage>
      </element-citation>
    </ref>
    <ref id="B2-cancers-13-00617">
      <label>2.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.E.</given-names>
          </name>
        </person-group>
        <article-title>Imagenet classification with deep convolutional neural networks</article-title>
        <source>Advances in Neural Information Processing Systems</source>
        <publisher-name>NIPS</publisher-name>
        <publisher-loc>Lake Tahoe, Nevada, USA</publisher-loc>
        <year>2012</year>
        <fpage>1097</fpage>
        <lpage>1105</lpage>
      </element-citation>
    </ref>
    <ref id="B3-cancers-13-00617">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Niazi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Parwani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Gurcan</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Digital pathology and artificial intelligence</article-title>
        <source>Lancet Oncol.</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>e253</fpage>
        <lpage>e261</lpage>
        <pub-id pub-id-type="doi">10.1016/S1470-2045(19)30154-8</pub-id>
        <pub-id pub-id-type="pmid">31044723</pub-id>
      </element-citation>
    </ref>
    <ref id="B4-cancers-13-00617">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Signaevsky</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Prastawa</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Farrell</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Tabish</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Baldwin</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Iida</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>Koll</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Bryce</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Purohit</surname>
            <given-names>D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Artificial intelligence in neuropathology: Deep learning-based assessment of tauopathy</article-title>
        <source>Lab. Invest.</source>
        <year>2019</year>
        <volume>99</volume>
        <fpage>1019</fpage>
        <lpage>1029</lpage>
        <pub-id pub-id-type="doi">10.1038/s41374-019-0202-4</pub-id>
        <?supplied-pmid 30770886?>
        <pub-id pub-id-type="pmid">30770886</pub-id>
      </element-citation>
    </ref>
    <ref id="B5-cancers-13-00617">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Marzese</surname>
            <given-names>D.M.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>C.C.</given-names>
          </name>
          <name>
            <surname>Kelly</surname>
            <given-names>D.F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>B7H3 regulates differentiation and serves as a potential biomarker and theranostic target for human glioblastoma</article-title>
        <source>Lab. Invest.</source>
        <year>2019</year>
        <volume>99</volume>
        <fpage>1117</fpage>
        <lpage>1129</lpage>
        <pub-id pub-id-type="doi">10.1038/s41374-019-0238-5</pub-id>
        <?supplied-pmid 30914782?>
        <pub-id pub-id-type="pmid">30914782</pub-id>
      </element-citation>
    </ref>
    <ref id="B6-cancers-13-00617">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Papanicolau-Sengos</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Pabla</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lenzo</surname>
            <given-names>F.L.</given-names>
          </name>
          <name>
            <surname>Kato</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kurzrock</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>DePietro</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nesline</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Conroy</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Glenn</surname>
            <given-names>S.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identification of targets for prostate cancer immunotherapy</article-title>
        <source>Prostate</source>
        <year>2019</year>
        <volume>79</volume>
        <fpage>498</fpage>
        <lpage>505</lpage>
        <pub-id pub-id-type="doi">10.1002/pros.23756</pub-id>
        <?supplied-pmid 30614027?>
        <pub-id pub-id-type="pmid">30614027</pub-id>
      </element-citation>
    </ref>
    <ref id="B7-cancers-13-00617">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Majzner</surname>
            <given-names>R.G.</given-names>
          </name>
          <name>
            <surname>Theruvath</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>Nellan</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Heitzeneder</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Mount</surname>
            <given-names>C.W.</given-names>
          </name>
          <name>
            <surname>Rietberg</surname>
            <given-names>S.P.</given-names>
          </name>
          <name>
            <surname>Linde</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Rota</surname>
            <given-names>C.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>CAR T Cells Targeting B7-H3, a Pan-Cancer Antigen, Demonstrate Potent Preclinical Activity Against Pediatric Solid Tumors and Brain Tumors</article-title>
        <source>Clin. Cancer Res.</source>
        <year>2019</year>
        <volume>25</volume>
        <fpage>2560</fpage>
        <lpage>2574</lpage>
        <pub-id pub-id-type="doi">10.1158/1078-0432.CCR-18-0432</pub-id>
        <?supplied-pmid 30655315?>
        <pub-id pub-id-type="pmid">30655315</pub-id>
      </element-citation>
    </ref>
    <ref id="B8-cancers-13-00617">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dong</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yue</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Hanley</surname>
            <given-names>S.J.B.</given-names>
          </name>
          <name>
            <surname>Watari</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>B7H3 As a Promoter of Metastasis and Promising Therapeutic Target</article-title>
        <source>Front. Oncol.</source>
        <year>2018</year>
        <volume>8</volume>
        <fpage>264</fpage>
        <pub-id pub-id-type="doi">10.3389/fonc.2018.00264</pub-id>
        <?supplied-pmid 30035102?>
        <pub-id pub-id-type="pmid">30035102</pub-id>
      </element-citation>
    </ref>
    <ref id="B9-cancers-13-00617">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rogiers</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Boekhout</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Schwarze</surname>
            <given-names>J.K.</given-names>
          </name>
          <name>
            <surname>Awada</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Blank</surname>
            <given-names>C.U.</given-names>
          </name>
          <name>
            <surname>Neyns</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Long-Term Survival, Quality of Life, and Psychosocial Outcomes in Advanced Melanoma Patients Treated with Immune Checkpoint Inhibitors</article-title>
        <source>J. Oncol.</source>
        <year>2019</year>
        <volume>2019</volume>
        <fpage>5269062</fpage>
        <pub-id pub-id-type="doi">10.1155/2019/5269062</pub-id>
        <?supplied-pmid 31182961?>
        <pub-id pub-id-type="pmid">31182961</pub-id>
      </element-citation>
    </ref>
    <ref id="B10-cancers-13-00617">
      <label>10.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Louis</surname>
            <given-names>D.N.</given-names>
          </name>
          <name>
            <surname>Ohgaki</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Wiestler</surname>
            <given-names>O.D.</given-names>
          </name>
          <name>
            <surname>Cavenee</surname>
            <given-names>W.K.</given-names>
          </name>
        </person-group>
        <source>World Health Organization Histological Classification of Tumours of the Central Nervous System</source>
        <publisher-name>International Agency for Research on Cancer</publisher-name>
        <publisher-loc>Lyon, France</publisher-loc>
        <year>2016</year>
      </element-citation>
    </ref>
    <ref id="B11-cancers-13-00617">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rojianl</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Dorovini-Zis</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Microvascular proliferation in glioblastoma multiforme</article-title>
        <source>J. Neuropathol. Exp. Neurol.</source>
        <year>1990</year>
        <volume>49</volume>
        <fpage>300</fpage>
        <pub-id pub-id-type="doi">10.1097/00005072-199005000-00125</pub-id>
      </element-citation>
    </ref>
    <ref id="B12-cancers-13-00617">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wesseling</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Schlingemann</surname>
            <given-names>R.O.</given-names>
          </name>
          <name>
            <surname>Rietveld</surname>
            <given-names>F.J.</given-names>
          </name>
          <name>
            <surname>Link</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Burger</surname>
            <given-names>P.C.</given-names>
          </name>
          <name>
            <surname>Ruiter</surname>
            <given-names>J.D.</given-names>
          </name>
        </person-group>
        <article-title>Early and extensive contribution of pericytes/vascular smooth muscle cells to microvascular proliferation in glioblastoma multiforme: An immuno-light and immuno-electron microscopic study</article-title>
        <source>J. Neuropathol. Exp. Neurol.</source>
        <year>1995</year>
        <volume>54</volume>
        <fpage>304</fpage>
        <lpage>310</lpage>
        <pub-id pub-id-type="doi">10.1097/00005072-199505000-00003</pub-id>
        <?supplied-pmid 7745429?>
        <pub-id pub-id-type="pmid">7745429</pub-id>
      </element-citation>
    </ref>
    <ref id="B13-cancers-13-00617">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brat</surname>
            <given-names>D.J.</given-names>
          </name>
          <name>
            <surname>van Meir</surname>
            <given-names>E.G.</given-names>
          </name>
        </person-group>
        <article-title>Glomeruloid microvascular proliferation orchestrated by VPF/VEGF: A new world of angiogenesis research</article-title>
        <source>Am. J. Pathol.</source>
        <year>2001</year>
        <volume>158</volume>
        <fpage>789</fpage>
        <lpage>796</lpage>
        <pub-id pub-id-type="doi">10.1016/S0002-9440(10)64025-4</pub-id>
        <pub-id pub-id-type="pmid">11238026</pub-id>
      </element-citation>
    </ref>
    <ref id="B14-cancers-13-00617">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Takashima</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Kawaguchi</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hayano</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Yamanaka</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>CD276 and the gene signature composed of GATA3 and LGALS3 enable prognosis prediction of glioblastoma multiforme</article-title>
        <source>PLoS ONE</source>
        <year>2019</year>
        <volume>14</volume>
        <elocation-id>e0216825</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0216825</pub-id>
        <?supplied-pmid 31075138?>
        <pub-id pub-id-type="pmid">31075138</pub-id>
      </element-citation>
    </ref>
    <ref id="B15-cancers-13-00617">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Inamura</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Yokouchi</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Kobayashi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Sakakibara</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Ninomiya</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Subat</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Nagano</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Nomura</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Okumura</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shibutani</surname>
            <given-names>T.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tumor B7-H3 (CD276) expression and smoking history in relation to lung adenocarcinoma prognosis</article-title>
        <source>Lung Cancer</source>
        <year>2017</year>
        <volume>103</volume>
        <fpage>44</fpage>
        <lpage>51</lpage>
        <pub-id pub-id-type="doi">10.1016/j.lungcan.2016.11.013</pub-id>
        <?supplied-pmid 28024695?>
        <pub-id pub-id-type="pmid">28024695</pub-id>
      </element-citation>
    </ref>
    <ref id="B16-cancers-13-00617">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Benzon</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>S.G.</given-names>
          </name>
          <name>
            <surname>Haffner</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Takhar</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Erho</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Yousefi</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Hurley</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bishop</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>Tosoian</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ghabili</surname>
            <given-names>K.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Correlation of B7-H3 with androgen receptor, immune pathways and poor outcome in prostate cancer: An expression-based analysis</article-title>
        <source>Prostate Cancer Prostatic Dis.</source>
        <year>2017</year>
        <volume>20</volume>
        <fpage>28</fpage>
        <lpage>35</lpage>
        <pub-id pub-id-type="doi">10.1038/pcan.2016.49</pub-id>
        <pub-id pub-id-type="pmid">27801901</pub-id>
      </element-citation>
    </ref>
    <ref id="B17-cancers-13-00617">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lemke</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pfenning</surname>
            <given-names>P.-N.</given-names>
          </name>
          <name>
            <surname>Sahm</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Klein</surname>
            <given-names>A.-C.</given-names>
          </name>
          <name>
            <surname>Kempf</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Warnken</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Schnölzer</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tudoran</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Weller</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Platten</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Costimulatory protein 4IgB7H3 drives the malignant phenotype of glioblastoma by mediating immune escape and invasiveness</article-title>
        <source>Clin. Cancer Res.</source>
        <year>2012</year>
        <volume>18</volume>
        <fpage>105</fpage>
        <lpage>117</lpage>
        <pub-id pub-id-type="doi">10.1158/1078-0432.CCR-11-0880</pub-id>
        <pub-id pub-id-type="pmid">22080438</pub-id>
      </element-citation>
    </ref>
    <ref id="B18-cancers-13-00617">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kraan</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Broek</surname>
            <given-names>P.V.D.</given-names>
          </name>
          <name>
            <surname>Verhoef</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Grunhagen</surname>
            <given-names>D.J.</given-names>
          </name>
          <name>
            <surname>Taal</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Gratama</surname>
            <given-names>J.W.</given-names>
          </name>
          <name>
            <surname>Sleijfer</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Endothelial CD276 (B7-H3) expression is increased in human malignancies and distinguishes between normal and tumour-derived circulating endothelial cells</article-title>
        <source>Br. J. Cancer</source>
        <year>2014</year>
        <volume>111</volume>
        <fpage>149</fpage>
        <lpage>156</lpage>
        <pub-id pub-id-type="doi">10.1038/bjc.2014.286</pub-id>
        <pub-id pub-id-type="pmid">24892449</pub-id>
      </element-citation>
    </ref>
    <ref id="B19-cancers-13-00617">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gootjes</surname>
            <given-names>E.C.</given-names>
          </name>
          <name>
            <surname>Kraan</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Buffart</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Verhoef</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Verheul</surname>
            <given-names>H.M.</given-names>
          </name>
          <name>
            <surname>Sleijfer</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>ORCHESTRA Study Group CD276-positive circulating endothelial cells in advanced colorectal cancer</article-title>
        <source>J. Clin. Oncol.</source>
        <year>2019</year>
        <volume>37</volume>
        <fpage>572</fpage>
        <pub-id pub-id-type="doi">10.1200/JCO.2019.37.4_suppl.572</pub-id>
      </element-citation>
    </ref>
    <ref id="B20-cancers-13-00617">
      <label>20.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Deep residual learning for image recognition</article-title>
        <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>
        <conf-loc>Las Vegas, NV, USA</conf-loc>
        <conf-date>27–30 June 2016</conf-date>
        <fpage>770</fpage>
        <lpage>778</lpage>
      </element-citation>
    </ref>
    <ref id="B21-cancers-13-00617">
      <label>21.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Chollet</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Xception: Deep learning with depthwise separable convolutions</article-title>
        <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>
        <conf-loc>Honolulu, HI, USA</conf-loc>
        <conf-date>21–26 July 2017</conf-date>
        <fpage>1251</fpage>
        <lpage>1258</lpage>
      </element-citation>
    </ref>
    <ref id="B22-cancers-13-00617">
      <label>22.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Mezirow</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Transformative Dimensions of Adult Learning</article-title>
        <source>Proceedings of the ERIC</source>
        <conf-loc>Alexandria, VA, USA</conf-loc>
        <conf-date>30 October–1 November 1991</conf-date>
      </element-citation>
    </ref>
    <ref id="B23-cancers-13-00617">
      <label>23.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Raina</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Battle</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Packer</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Ng</surname>
            <given-names>A.Y.</given-names>
          </name>
        </person-group>
        <article-title>Self-taught learning: Transfer learning from unlabeled data</article-title>
        <source>Proceedings of the 24th International Conference on Machine Learning</source>
        <conf-loc>Corvalis, OR, USA</conf-loc>
        <conf-date>20–24 June 2007</conf-date>
        <publisher-name>ACM</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year>2007</year>
        <fpage>759</fpage>
        <lpage>766</lpage>
      </element-citation>
    </ref>
    <ref id="B24-cancers-13-00617">
      <label>24.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning of representations for unsupervised and transfer learning</article-title>
        <source>Proceedings of the ICML Workshop on Unsupervised and Transfer Learning</source>
        <conf-loc>Edinburgh, UK</conf-loc>
        <conf-date>1–26 July 2012</conf-date>
        <fpage>17</fpage>
        <lpage>36</lpage>
      </element-citation>
    </ref>
    <ref id="B25-cancers-13-00617">
      <label>25.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Socher</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L.-J.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Fei-Fei</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Imagenet: A large-scale hierarchical image database</article-title>
        <source>Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition</source>
        <conf-loc>Miami, FL, USA</conf-loc>
        <conf-date>20–25 June 2009</conf-date>
        <fpage>248</fpage>
        <lpage>255</lpage>
      </element-citation>
    </ref>
    <ref id="B26-cancers-13-00617">
      <label>26.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Bao</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Graeber</surname>
            <given-names>M.B.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>A Bifocal Classification and Fusion Network for Multimodal Image Analysis in Histopathology</article-title>
        <source>Proceedings of the 16th International Conference on Control, Automation, Robotics and Vision (ICARCV 2020)</source>
        <conf-loc>Shenzhen, China</conf-loc>
        <conf-date>13–15 December 2020.</conf-date>
      </element-citation>
    </ref>
    <ref id="B27-cancers-13-00617">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shan</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Kruger</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Kalra</surname>
            <given-names>M.K.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Cong</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>3-D Convolutional Encoder-Decoder Network for Low-Dose CT via Transfer Learning From a 2-D Trained Network</article-title>
        <source>IEEE Trans. Med Imaging</source>
        <year>2018</year>
        <volume>37</volume>
        <fpage>1522</fpage>
        <lpage>1534</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2018.2832217</pub-id>
        <?supplied-pmid 29870379?>
        <pub-id pub-id-type="pmid">29870379</pub-id>
      </element-citation>
    </ref>
    <ref id="B28-cancers-13-00617">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Samala</surname>
            <given-names>R.K.</given-names>
          </name>
          <name>
            <surname>Chan</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Hadjiiski</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Helvie</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>Richter</surname>
            <given-names>C.D.</given-names>
          </name>
          <name>
            <surname>Cha</surname>
            <given-names>K.H.</given-names>
          </name>
        </person-group>
        <article-title>Breast Cancer Diagnosis in Digital Breast Tomosynthesis: Effects of Training Sample Size on Multi-Stage Transfer Learning Using Deep Neural Nets</article-title>
        <source>IEEE Trans. Med Imaging</source>
        <year>2019</year>
        <volume>38</volume>
        <fpage>686</fpage>
        <lpage>696</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2018.2870343</pub-id>
        <?supplied-pmid 31622238?>
        <pub-id pub-id-type="pmid">31622238</pub-id>
      </element-citation>
    </ref>
    <ref id="B29-cancers-13-00617">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weiss</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Khoshgoftaar</surname>
            <given-names>T.M.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>A survey of transfer learning</article-title>
        <source>J. Big Data</source>
        <year>2016</year>
        <volume>3</volume>
        <fpage>9</fpage>
        <pub-id pub-id-type="doi">10.1186/s40537-016-0043-6</pub-id>
      </element-citation>
    </ref>
    <ref id="B30-cancers-13-00617">
      <label>30.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Kornblith</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shlens</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>Q.V.</given-names>
          </name>
        </person-group>
        <article-title>Do better imagenet models transfer better?</article-title>
        <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>
        <conf-loc>Long Beach, CA, USA</conf-loc>
        <conf-date>15–20 June 2019</conf-date>
        <fpage>2661</fpage>
        <lpage>2671</lpage>
      </element-citation>
    </ref>
    <ref id="B31-cancers-13-00617">
      <label>31.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Raghu</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kleinberg</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Transfusion: Understanding transfer learning for medical imaging</article-title>
        <source>Advances in Neural Information Processing Systems</source>
        <publisher-name>Vancouver Convention Center</publisher-name>
        <publisher-loc>Vancouver, BC, Canada</publisher-loc>
        <year>2019</year>
        <fpage>3342</fpage>
        <lpage>3352</lpage>
      </element-citation>
    </ref>
    <ref id="B32-cancers-13-00617">
      <label>32.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Dubrofsky</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Homography Estimation</article-title>
        <source>Master’s Thesis</source>
        <publisher-name>Univerzita Britské Kolumbie</publisher-name>
        <publisher-loc>Vancouver, BC, Canada</publisher-loc>
        <year>2009</year>
      </element-citation>
    </ref>
    <ref id="B33-cancers-13-00617">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Janowczyk</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Basavanhally</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Madabhushi</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Stain normalization using sparse autoencoders (StaNoSA): Application to digital pathology</article-title>
        <source>Comput. Med Imaging Graph.</source>
        <year>2017</year>
        <volume>57</volume>
        <fpage>50</fpage>
        <lpage>61</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compmedimag.2016.05.003</pub-id>
        <?supplied-pmid 27373749?>
        <pub-id pub-id-type="pmid">27373749</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="cancers-13-00617-f001" orientation="portrait" position="float">
    <label>Figure 1</label>
    <caption>
      <p>Receiver operating characteristic (ROC) and area under the curve (AUC) performance on test data. ROC/AUC performance of the bifocal convolutional neural network (BCNN) for recognition of hematoxylin and eosin (H&amp;E) (<bold>A</bold>) and immunohistochemical (IHC) (<bold>B</bold>) features. (<bold>C</bold>) Comparison of ROC/AUC performance of BCNN with state-of-the-art deep learning methods.</p>
    </caption>
    <graphic xlink:href="cancers-13-00617-g001"/>
  </fig>
  <fig id="cancers-13-00617-f002" orientation="portrait" position="float">
    <label>Figure 2</label>
    <caption>
      <p>Confusion matrices for recognition of H&amp;E (left) and IHC (right) features (BCNN; normalized).</p>
    </caption>
    <graphic xlink:href="cancers-13-00617-g002"/>
  </fig>
  <fig id="cancers-13-00617-f003" orientation="portrait" position="float">
    <label>Figure 3</label>
    <caption>
      <p>Predicted heatmaps of test cases showing distribution of machine-recognized features. First column: heatmaps showing the distribution of pathomorphological features predicted from scanned H&amp;E whole-slide images; second and third columns: heatmaps of the same cases showing the distribution of CD276 immunoreactivity before and after image registration, respectively; last column: CD276 expression mapped to pathomorphological features following image registration. Note: Probability heatmaps in the second column were generated using prediction probabilities as weighting factors for pseudo-color mapping, which were then converted into classification heatmaps before image registration (third column) and image fusion (fourth column).</p>
    </caption>
    <graphic xlink:href="cancers-13-00617-g003"/>
  </fig>
  <fig id="cancers-13-00617-f004" orientation="portrait" position="float">
    <label>Figure 4</label>
    <caption>
      <p>Heatmaps illustrating the relationship between H&amp;E images and CD276 immunohistochemistry. (<bold>A</bold>) Predicted probability heatmap of key morphological features in relation to the corresponding H&amp;E image. (<bold>B</bold>) Correlation heatmap and the spatial overlaps between H&amp;E-stained morphological structures and CD276 immunoreactivity.</p>
    </caption>
    <graphic xlink:href="cancers-13-00617-g004"/>
  </fig>
  <fig id="cancers-13-00617-f005" orientation="portrait" position="float">
    <label>Figure 5</label>
    <caption>
      <p>Transparent overlays (left column) of predicted feature distribution heatmaps on original whole-slide test images (right column). Images and crops from the images were randomly selected. (<bold>A</bold>,<bold>B</bold>) Machine-recognized tissue areas (arrows; predicted to contain microvascular proliferation) closely match the expert marking (annotated yellow dots). (<bold>C</bold>) A machine-recognized tumor-infiltrated brain tissue sample (long arrow) also shows incipient microvascular proliferation (short arrows). (<bold>D</bold>) Another illustration of recognized pathomorphological features showing different subcategories of tissue necrosis: geographic necrosis (long arrows) and palisading necrosis (short arrows).</p>
    </caption>
    <graphic xlink:href="cancers-13-00617-g005"/>
  </fig>
  <fig id="cancers-13-00617-f006" orientation="portrait" position="float">
    <label>Figure 6</label>
    <caption>
      <p>Overview of the PathoFusion framework for recognition of pathological features. Upper panel (<bold>A</bold>): Typical pathomorphological features are manually marked on whole-slide scans with the help of a labeling website (<xref ref-type="app" rid="app1-cancers-13-00617">Figure S2</xref>). Three examples are shown: palisading necrosis (black dots), microvascular proliferation (yellow dots), and tumor background (defined as extensive diffuse infiltration of brain tissue by glioma cells, green dots). Based on the marking coordinates, 256 × 256- and 512 × 512-pixel paired image tiles are extracted (<bold>A</bold>, center panel), followed by image augmentation to expand the training dataset. In the next step (<bold>B</bold>), paired augmented image tiles are fed into the BCNN for supervised learning. (<bold>C</bold>) Test cases are used to evaluate recognition performance. The distribution of key morphological features is obtained for entire scanned slides as illustrated by the prediction (probability) heatmap. Note: the pseudo-colors of the heatmap are different from the colors used for marking.</p>
    </caption>
    <graphic xlink:href="cancers-13-00617-g006"/>
  </fig>
  <fig id="cancers-13-00617-f007" orientation="portrait" position="float">
    <label>Figure 7</label>
    <caption>
      <p>Overview of the PathoFusion framework for mapping of immunohistochemical data to morphological features. Whole-slide histopathology images of different modalities (<bold>A</bold>) are processed by the BCNN and used to generate heatmaps, showing the predicted distribution of morphological features and CD276 expression patterns, respectively (<bold>B</bold>). The immunohistochemical heatmap is then aligned with the H&amp;E heatmap using image registration (<bold>C</bold>, lower panel). The correlation between the two modalities can be visualized through fusion of the corresponding heatmaps. Each color in the correlation heatmap (<bold>C</bold>, upper panel) indicates an overlap between the two modalities. The asterisks indicate that further marking and training are required to differentiate subcategories of palisading and geographic necrosis, respectively (see text for further explanation). The overlap between microvascular proliferation and CD276 immunopositivity is of special interest (magenta color in the upper panel of <bold>C</bold>).</p>
    </caption>
    <graphic xlink:href="cancers-13-00617-g007"/>
  </fig>
</floats-group>
