<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Artif Intell</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Artif Intell</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Artif. Intell.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Artificial Intelligence</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2624-8212</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8202286</article-id>
    <article-id pub-id-type="publisher-id">659622</article-id>
    <article-id pub-id-type="doi">10.3389/frai.2021.659622</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Artificial Intelligence</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>InferBERT: A Transformer-Based Causal Inference Framework for Enhancing Pharmacovigilance</article-title>
      <alt-title alt-title-type="left-running-head">Wang et al.</alt-title>
      <alt-title alt-title-type="right-running-head">InferBERT</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Xingqiao</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1296943/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Xiaowei</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">*</xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/989111/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tong</surname>
          <given-names>Weida</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/39650/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Roberts</surname>
          <given-names>Ruth</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/532797/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Zhichao</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">*</xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/293118/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><label><sup>1</sup></label>Department of Information Science, University of Arkansas at Little Rock, <addr-line>Little Rock</addr-line>, <addr-line>AR</addr-line>, <country>United States</country></aff>
    <aff id="aff2"><label><sup>2</sup></label>FDA/National Center for Toxicological Research, <addr-line>Jefferson</addr-line>, <addr-line>AR</addr-line>, <country>United States</country></aff>
    <aff id="aff3"><label><sup>3</sup></label>ApconiX Ltd, Alderley Park, <addr-line>Alderley Edge</addr-line>, <country>United Kingdom</country></aff>
    <aff id="aff4"><label><sup>4</sup></label>Department of Biosciences, University of Birmingham, <addr-line>Birmingham</addr-line>, <country>United Kingdom</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link ext-link-type="uri" xlink:href="https://loop.frontiersin.org/people/35327/overview">Alejandro F. Frangi</ext-link>, University of Leeds, United Kingdom</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link ext-link-type="uri" xlink:href="https://loop.frontiersin.org/people/834819/overview">Yonghui Wu</ext-link>, University of Florida, United States</p>
        <p><ext-link ext-link-type="uri" xlink:href="https://loop.frontiersin.org/people/613837/overview">Himanshu Arora</ext-link>, University of Miami, United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Xiaowei Xu, <email>xwxu@ualr.edu</email>; Zhichao Liu, <email>Zhichao.Liu@fda.hhs.gov</email></corresp>
      <fn fn-type="other">
        <p>This article was submitted to Medicine and Public Health, a section of the journal Frontiers in Artificial Intelligence</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>4</volume>
    <elocation-id>659622</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>1</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>06</day>
        <month>5</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2021 Wang, Xu, Tong, Roberts and Liu.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Wang, Xu, Tong, Roberts and Liu</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p><bold>Background:</bold> T ransformer-based language models have delivered clear improvements in a wide range of natural language processing (NLP) tasks. However, those models have a significant limitation; specifically, they cannot infer causality, a prerequisite for deployment in pharmacovigilance, and health care. Therefore, these transformer-based language models should be developed to infer causality to address the key question of the cause of a clinical outcome.</p>
      <p><bold>Results:</bold> In this study, we propose an innovative causal inference model–InferBERT, by integrating the A Lite Bidirectional Encoder Representations from Transformers (ALBERT) and Judea Pearl’s Do-calculus to establish potential causality in pharmacovigilance. Two FDA Adverse Event Reporting System case studies, including Analgesics-related acute liver failure and Tramadol-related mortalities, were employed to evaluate the proposed InferBERT model. The InferBERT model yielded accuracies of 0.78 and 0.95 for identifying Analgesics-related acute liver failure and Tramadol-related death cases, respectively. Meanwhile, the inferred causes of the two clinical outcomes, (i.e. acute liver failure and death) were highly consistent with clinical knowledge. Furthermore, inferred causes were organized into a causal tree using the proposed recursive do-calculus algorithm to improve the model’s understanding of causality. Moreover, the high reproducibility of the proposed InferBERT model was demonstrated by a robustness assessment.</p>
      <p><bold>Conclusion:</bold> The empirical results demonstrated that the proposed InferBERT approach is able to both predict clinical events and to infer their causes. Overall, the proposed InferBERT model is a promising approach to establish causal effects behind text-based observational data to enhance our understanding of intrinsic causality.</p>
      <p><bold>Availability and implementation:</bold> The InferBERT model and preprocessed FAERS data sets are available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/XingqiaoWang/DeepCausalPV-master">https://github.com/XingqiaoWang/DeepCausalPV-master</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>artificial intelligence</kwd>
      <kwd>natural language processing</kwd>
      <kwd>language models</kwd>
      <kwd>causal inference</kwd>
      <kwd>pharmacovigilance</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>Introduction</title>
    <p>The rise of artificial intelligence (AI) has transformed many aspects of human life, especially in healthcare, personal transport, law-making, and entertainment (<xref rid="B18" ref-type="bibr">Silver et al., 2017</xref>; <xref rid="B1" ref-type="bibr">Awad et al., 2018</xref>; <xref rid="B20" ref-type="bibr">Topol, 2019</xref>; <xref rid="B25" ref-type="bibr">Woo, 2019</xref>). One of the breakthroughs in AI is the advent of transformer-based language models, that can achieve state-of-the-art (SOTA) performance in a wide range of natural language processing (NLP) tasks (<xref rid="B7" ref-type="bibr">Devlin et al., 2018</xref>; <xref rid="B13" ref-type="bibr">Lan et al., 2019</xref>; <xref rid="B6" ref-type="bibr">Brown et al., 2020</xref>; <xref rid="B26" ref-type="bibr">Zaheer et al., 2020</xref>). Data set size and the number of parameters tend to increase exponentially with language model development in pursuit of improved model performance. For example, the GPT3 model consisted of 175 billion parameters and was trained with 499 billion tokens (<xref rid="B6" ref-type="bibr">Brown et al., 2020</xref>). Consequently, the achieved high prediction performance came at the expense of model interpretability (<xref rid="B14" ref-type="bibr">Moraffah et al., 2020</xref>). Another critical limitation of transformer-based language models is the lack of ability to infer causality. Model interpretability and lack of causal inference affect the dissemination of AI-powered models in critical fields, particularly in healthcare and pharmacovigilance where model interpretability is vital for deployment (<xref rid="B11" ref-type="bibr">Feder et al., 2020</xref>).</p>
    <p>The goal of this project is to develop a model that can infer the causality of clinical outcome from unstructured pharmacovigilance reports. Causality (also referred to as causation or cause and effect) is the influence by which one event, process, or state (a cause) contributes to the production of another event, process or state (an effect). Causal inference is the process of identifying the cause and effect based on the conditions of the occurrence of the event (<xref rid="B15" ref-type="bibr">Pearl, 2010</xref>). There is a fundamental difference between causal inference and association inference: causal inference analyzes the response of the effect variable when the cause is changed (<xref rid="B16" ref-type="bibr">Pearl and Mackenzie, 2018</xref>).</p>
    <p>One of the conventional approaches to prove cause and effect is a randomized controlled trial. In a randomized controlled trial, the test subject is randomly assigned to the treatment or control groups, which are identical in every way other than one group receives drug (treatment) and one receives placebo (control). If the clinical outcome is better in one group than the other with statistical significance, then causality is established. However, conducting a randomized controlled trial to establish causality relationships is often time consuming, expensive and can be impractical in the real world. For example, it would be impractical to conduct a randomized controlled trial to demonstrate causality regarding the impact of a vegetarian diet on life expectancy. Thus, there is a pressing need to develop AI-powered language models that can identify potential causality from accumulated real-world data.</p>
    <p>Only one attempt has been made so far to perform causal inference using text as a potential cause of an effect (<xref rid="B24" ref-type="bibr">Veitch et al., 2020</xref>). The study proposed a low-level text representation (called causally sufficient embeddings) for empirical estimations of causal effects on observed text documents. Two text corpora were used to address the following specific causal questions: 1) Does adding a theorem to a paper affect its chance of acceptance? 2) Does labeling a post with the author’s gender affect post popularity? However, the approach required external treatment and outcome information for the text corpus and could not estimate the causal relationship among the variables within the text corpus. To date, there remains an absence of any reports that infer cause and effect relationships between terms or variables, (e.g. treatment and clinical outcome) within a text.</p>
    <p>One of the potential applications of transformer-based language models for causal inference is pharmacovigilance. Pharmacovigilance, also known as drug safety, is the pharmacological science related to collecting, detecting, assessing, monitoring, and preventing adverse effects with pharmaceutical products (<xref rid="B9" ref-type="bibr">Edwards, 2012</xref>). The FDA Adverse Event Reporting System (FAERS) is an essential pharmacovigilance resource containing rich information on adverse event and medication error reports. The larger number of FAERS case reports comprising confounders, treatments, and clinical outcomes could be utilized to recognize adverse drug reactions (ADRs) and establish a potential causal relationship between the drug and the adverse events to further support regulatory decision making.</p>
    <p>In this study, we propose a novel transformer-based causal inference model—InferBERT, by integrating A Lite Bidirectional Encoder Representations from Transformers (ALBERT) <xref rid="B13" ref-type="bibr">Lan et al. (2019)</xref> and Judea Pearl’s do-calculus <xref rid="B15" ref-type="bibr">Pearl (2010)</xref> to infer causality for pharmacovigilance using FAERS case report data. We employed two FAERS case report data sets to estimate the potential causes of Analgesics-related acute liver failure and Tramadol-related mortalities to prove the concept. Furthermore, identified causes were visualized by a proposed causal tree, which was calculated using recursive do-calculus and verified with evidence from clinical trial studies and FDA drug labeling.</p>
  </sec>
  <sec sec-type="materials|methods" id="s2">
    <title>Materials and Methods</title>
    <p><xref ref-type="fig" rid="F1">Figure 1</xref> illustrates the workflow of the study:<list list-type="simple"><list-item><p>1. The FDA Adverse Event Reporting System (FAERS) case reports, including Analgesics-related acute liver failure and Tramadol-related mortalities, were extracted and preprocessed.</p></list-item><list-item><p>2. The preprocessed case reports were converted into the sentence-like descriptions for the subsequent pretrained language model ALBERT.</p></list-item><list-item><p>3. We fine-tuned the pretrained ALBERT model based on the transformed sentence-like descriptions to predict Analgesics-related acute liver failure and Tramadol-related mortalities, respectively.</p></list-item><list-item><p>4. Do-calculus was implemented into the fine-tuned ALBERT models for causal inference.</p></list-item></list>
</p>
    <fig id="F1" position="float">
      <label>FIGURE 1</label>
      <caption>
        <p>Workflow of the study.</p>
      </caption>
      <graphic xlink:href="frai-04-659622-g001"/>
    </fig>
    <sec id="s2-1">
      <title>Clinical Knowledge</title>
      <p>The two critical aspects of causal relations in pharmacovigilance are 1) a drug causes the particular adverse drug reaction and 2) the causal relationship between the adverse drug reaction and different clinical factors needs to be established. Therefore, we employed two FAERS datasets, including Analgesics-induced acute liver failure, and Tramadol-related mortalities, to investigate the performance of the proposed Deep Causal Pharmacovigilance (InferBERT) approach.</p>
      <sec id="s2-1-1">
        <title>Analgesics-Induced Acute Liver Failure</title>
        <p>Analgesics or painkillers form a group of drugs used to achieve analgesia and relief from pain. Analgesics include acetaminophen (APAP), the nonsteroidal anti-inflammatory drugs (NSAIDs) such as the salicylates, and opioid drugs such as morphine and oxycodone. Analgesics are one of the most common causes of drug-induced acute liver failure (<xref rid="B5" ref-type="bibr">Björnsson, 2010</xref>). Among different analgesics, APAP-induced hepatotoxicity remains a global issue. For example, in the United States, it accounts for more than 50% of overdose-related acute liver failure (ALF), and approximately 20% of the liver transplant cases (<xref rid="B4" ref-type="bibr">Bernal and Wendon, 2013</xref>). Furthermore, APAP is also combined with prescribed—or is formulated with—opioid analgesics to boost pain relief, which increases the possibility of overdose or even abuse (<xref rid="B3" ref-type="bibr">Basco et al., 2016</xref>). The mortality rate of ALF is approximately 67–75% before liver transplantation (<xref rid="B4" ref-type="bibr">Bernal and Wendon, 2013</xref>). Also, it was reported that APAP-induced ALF is more common and more severe in women based on the Acute Liver Failure Study Group cohort study (<xref rid="B17" ref-type="bibr">Rubin et al., 2018</xref>).</p>
      </sec>
      <sec id="s2-1-2">
        <title>Tramadol-Related Mortalities</title>
        <p>Tramadol is an opioid-related medicine used to treat severe pain. In the United States, there is a Boxed Warning to Tramadol labeling to ensure appropriate inclusion of the serious adverse reactions such as addiction, abuse, and misuse, life-threatening respiratory depression, accidental ingestion, and interaction with drugs affecting cytochrome P450 isoenzymes. In particular, the statement “Do not prescribe tramadol for patients who are suicidal or addiction-prone. Consideration should be given to the use of non-narcotic analgesics in patients who are suicidal or depressed” is highlighted in the Drug Abuse and Dependence section of the US FDA label (<ext-link ext-link-type="uri" xlink:href="http://dailymed.nlm.nih.gov/dailymed/downloadpdffile.cfm?setId=5bee381f-b14a-e62b-e053-2991aa0a3c2b">http://dailymed.nlm.nih.gov/dailymed/downloadpdffile.cfm?setId=5bee381f-b14a-e62b-e053-2991aa0a3c2b</ext-link>). Furthermore, post-marketing adverse events such as QT prolongation and Torsade de Pointes have been reported with tramadol use, which is included in the Adverse Reaction section.</p>
      </sec>
    </sec>
    <sec id="s2-2">
      <title>Preprocessing of FAERS Case Reports</title>
      <p>The FAERS case reports curated in the PharmaPendium database (<ext-link ext-link-type="uri" xlink:href="https://www.pharmapendium.com/login/email">https://www.pharmapendium.com/login/email</ext-link>) were used in this study. Specifically, we used the search query “Effects: (Acute liver fibrosis and cirrhosis, OR Acute liver failure and associated disorders, OR Cholestasis and jaundice) AND Drugs by AND-groups: [Analgesics (Any Role)]” to extract 45,773 FAERS case reports for Analgesics-induced acute liver failure. We employed the search query “Drugs: (Tramadol Hydrochloride) AND Drugs Reported Role: (Drug’s Reported Role: Primary Suspect Drug OR Secondary Suspect Drug)” and obtained 39,930 FAERS case reports for Tramadol-related mortalities.</p>
      <p>The FAERS data in the PharmaPendium database has been preprocessed, including removing duplicating records, normalizing drug names, and standardizing adverse events terminology. However, some hurdles still exist for consolidating the information to carry out causal inference. Therefore, we implemented the following data cleaning procedure to further process the datasets:<list list-type="simple"><list-item><p>1) We normalized the terms such as “UNK,” “UNKNOWN,” “()” and considered them as missing values.</p></list-item><list-item><p>2) Considering the different doses used in FAERS case reports, we unified the dose unit into milligram (mg). We categorized the dose into two classes: large than 100 mg and less than 100 mg.</p></list-item><list-item><p>3) We categorized the patient age into four groups: less than 18 years old, 18–39 years old, 40–64 years old, and older than 65 years.</p></list-item><list-item><p>4) For the tramadol-related mortalities dataset, we excluded the case reports without clinical outcome information since we used the clinical outcome as the prediction endpoint. As a result, we obtained a total of 36,661 and 27,245 case reports for Analgesics-induced acute liver failure and Tramadol-related mortalities, respectively.</p></list-item></list>
</p>
    </sec>
    <sec id="s2-3">
      <title>Sentence Generation With FAERS Case Reports</title>
      <p>Our proposed model for causal inference, InferBERT, is based on the transformer model <xref rid="B13" ref-type="bibr">Lan et al. (2019)</xref>, which is a sequence transduction model that requires sequences as the input. Therefore, we extracted sentences from each of the FAERS case reports. Specifically, the FAERS case reports are denoted as <italic>D</italic>, <italic>D</italic> = (<italic>d</italic>
<sub>1</sub>, <italic>d</italic>
<sub>2</sub>, … , <italic>d</italic>
<sub>N</sub>), <italic>d</italic>
<sub><italic>i</italic></sub> is the <italic>i</italic>th case report of the dataset, <italic>N</italic> is the total number of case reports. Suppose that there are <italic>M</italic> clinical features, (e.g. gender, age, primary suspect drug, dose) for the FAERS case report dataset <italic>D</italic>. Each clinical feature consists of a set of terms. For example, the <italic>jth</italic> feature <italic>f</italic>
<sub><italic>j</italic></sub> consists of a set of terms <italic>T</italic>
<sub><italic>j</italic></sub> (e.g., feature gender includes terms male and female) as value, where <italic>T</italic>
<sub><italic>j</italic></sub> = (<italic>t</italic>
<sub><italic>j</italic>1</sub>, <italic>t</italic>
<sub><italic>j</italic>2</sub>, … , <italic>t</italic>
<sub><italic>jG</italic></sub>), <italic>G</italic> represents the total number of terms for a particular clinical feature. For example, clinic feature “Indication” may take a value such as “Pain” or “Suicide Attempt.” Then, <italic>d</italic>
<sub><italic>i</italic></sub> = (<italic>f</italic>
<sub><italic>i</italic>1</sub>, <italic>f</italic>
<sub><italic>i</italic>2</sub>, … , <italic>f</italic>
<sub><italic>i</italic>M</sub>), where <italic>f</italic>
<sub><italic>ij</italic></sub> is the <italic>jth</italic> feature of the <italic>ith</italic> instance, and <italic>f</italic>
<sub><italic>ij</italic></sub> ⊂ <italic>T</italic>
<sub>j</sub>. Without losing generality, we set the <italic>f</italic>
<sub><italic>m</italic></sub> as the end point, which means the <italic>mth</italic> clinical feature in the dataset <italic>D</italic> will be the target of classification and causal inference.</p>
      <p>Then, we transformed each case report <italic>d</italic>
<sub><italic>i</italic></sub> into the corresponding sentence <italic>s</italic>
<sub><italic>i</italic></sub>. For example, in the FAERS dataset, the clinical features included gender, age, primary suspect drug, dose, indication, adverse events, and outcomes in each case report d<sub>i</sub>. The generated sentence followed the template listed below:</p>
      <p>Patient (gender and age) takes a primary suspect drug to treat which disease and cause some adverse events, leading to outcomes.</p>
      <p>Then we generated the sentence set <italic>S</italic>, <italic>S</italic> = (<italic>s</italic>
<sub>1</sub>, <italic>s</italic>
<sub>2</sub>, … , <italic>s</italic>
<sub><italic>N</italic></sub>).</p>
      <p>For the Analgesics-induced acute liver failure data, the term “acute liver failure” in clinical feature “adverse event” was used as the endpoint. Of 36,661 FAERS case reports, 15,224 cases with “acute liver failure” were considered as positives and remaining 21,437 cases as negatives (positive/negative ratio = 0.71). For Tramadol-related death data, the clinical feature “outcomes” was used as the endpoint. The case reports with the term “death” in the clinical feature “outcomes” were considered as positives and other case reports were used as negatives. Accordingly, a total of the 27,245 case reports with 9,846 positives and 17,399 negatives were obtained (positive/negative ratio = 0.57). Next, we employed a stratified splitting strategy to divide each sentence set <italic>S</italic> into three sets, including a training set (for training the model), a development set (for model selection), and a test set (for model validation) with an approximate ratio of 0.64: 0.16: 0.20. The detailed information of the two datasets was listed in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap id="T1" position="float">
        <label>TABLE 1</label>
        <caption>
          <p>Sentence sets of Analgesics-related acute liver failure and Tramadol-related mortalities.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Endpoints</th>
              <th align="center" rowspan="1" colspan="1">Datasets</th>
              <th align="center" rowspan="1" colspan="1">Number of positives</th>
              <th align="center" rowspan="1" colspan="1">Number of negatives</th>
              <th align="center" rowspan="1" colspan="1">Positive versus negative ratio</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td rowspan="4" align="left" colspan="1">Acute liver failure</td>
              <td align="left" rowspan="1" colspan="1">Total</td>
              <td align="center" rowspan="1" colspan="1">15,224</td>
              <td align="center" rowspan="1" colspan="1">21,437</td>
              <td align="center" rowspan="1" colspan="1">0.71</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Training set</td>
              <td align="center" rowspan="1" colspan="1">9,798</td>
              <td align="center" rowspan="1" colspan="1">13,663</td>
              <td align="center" rowspan="1" colspan="1">0.71</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Develop set</td>
              <td align="center" rowspan="1" colspan="1">2,399</td>
              <td align="center" rowspan="1" colspan="1">3,467</td>
              <td align="center" rowspan="1" colspan="1">0.69</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Test set</td>
              <td align="center" rowspan="1" colspan="1">3,027</td>
              <td align="center" rowspan="1" colspan="1">4,307</td>
              <td align="center" rowspan="1" colspan="1">0.70</td>
            </tr>
            <tr>
              <td rowspan="4" align="left" colspan="1">Tramadol-related death</td>
              <td align="left" rowspan="1" colspan="1">Total</td>
              <td align="center" rowspan="1" colspan="1">9,846</td>
              <td align="center" rowspan="1" colspan="1">17,399</td>
              <td align="center" rowspan="1" colspan="1">0.57</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Training set</td>
              <td align="center" rowspan="1" colspan="1">6,250</td>
              <td align="center" rowspan="1" colspan="1">11,185</td>
              <td align="center" rowspan="1" colspan="1">0.56</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Develop set</td>
              <td align="center" rowspan="1" colspan="1">1,588</td>
              <td align="center" rowspan="1" colspan="1">2,722</td>
              <td align="center" rowspan="1" colspan="1">0.57</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Test set</td>
              <td align="center" rowspan="1" colspan="1">2,008</td>
              <td align="center" rowspan="1" colspan="1">3,442</td>
              <td align="center" rowspan="1" colspan="1">0.58</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s2-4">
      <title>ALBERT-Based Classification Model</title>
      <p>Bidirectional Encoder Representations from Transformers (BERT) is a transformer that learns contextual bidirectional representations from unlabeled text documents by jointly conditioning on both left and right contexts (<xref rid="B23" ref-type="bibr">Vaswani et al., 2017</xref>; <xref rid="B7" ref-type="bibr">Devlin et al., 2018</xref>). BERT employed two training strategies, including a masked language model (MLM) and Next Sentence Prediction (NSP), to learn bidirectional representations. In the MLM, 15% of words in a sequence are replaced with a (MASK) token, and the model attempts to predict the original value of the masked words, based on the context provided by the other, non-masked, words in the sequence. In the NSP, the model receives pairs of sentences as input and learns to predict if the second sentence in the pair is the subsequent sentence in the original document. The BERT model has achieved state-of-the-art performance on most NLP tasks, requiring minimal task-specific architectural modification.</p>
      <p>Increasing the model size of pre-trained language models often results in an improved model performance for downstream tasks. However, The GPU/TPU memory limitations, longer training times, and model overfitting generate obstacles to further expand the model size. To address these obstacles, Google AI proposed a Lite BERT (ALBERT) by adopting three techniques to trim down BERT (<xref rid="B13" ref-type="bibr">Lan et al., 2019</xref>). First, factorized embedding parameterization was used to break down token embeddings into two small embedding matrixes. After applying this decomposition, embeddings parameters can be reduced from (number of tokens × hidden layer size) to (number of tokens × token embedding size + token embedding size × hidden layer size). The reduction of parameters is significant, especially when the hidden layer size is much larger than the token embedding size. Second, cross-layer parameter sharing was proposed to prevent an increasing number of parameters with increased depth of the model. ALBERT is configured to share all parameters which include feed-forward network and attention parameters across layers. Lastly, a sentence-order prediction (SOP) loss was developed to model inter-sentence coherence in ALBERT, enabling the new model to perform more robustly in multi-sentence encoding tasks. To summarize, we chose ALBERT over BERT because it achieved an equivalent accuracy, if not better, with a much smaller model size.</p>
      <p>The ALBERT<sub>base</sub> classification model was employed to classify the endpoint term of each instance. We build a simple SoftMax classifier for the downstream classification task of the ALBERT model. In the ALBERT model, the learned representation vector of the (CLS) special token of the last layer acts as the input of the downstream model, with no hidden layers. The dimensionality of the output layer in the classification model is two, where the SoftMax function is adopted to classify whether the endpoint term exists or not. The loss function of the classification model is shown as follows:<disp-formula id="e1"><mml:math id="m1"><mml:mrow><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mi>i</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math><label>(1)</label></disp-formula>where, <italic>F</italic>(<italic>s</italic>
<sub><italic>i</italic></sub>) is the output of the classification model for <italic>s</italic>
<sub><italic>i</italic></sub>, which is a calculated probability of the predicted class of <italic>s</italic>
<sub><italic>i</italic></sub>. <italic>p</italic>
<sub><italic>i</italic></sub> is the true probability of the end point of <italic>s</italic>
<sub><italic>i</italic></sub>.</p>
      <p>We denote <italic>p</italic>′<sub><italic>i</italic></sub> = <italic>F</italic>(<italic>s</italic>
<sub><italic>i</italic></sub>), as the output of classification model, where <italic>p</italic>′<sub><italic>i</italic></sub> is the positive probability of the end point for instance <italic>i</italic>. Then, the output set, (i.e. conditional probability distribution) of the classification model can be denoted as <italic>O</italic>, <italic>O</italic> = ( <italic>p</italic>′<sub>1</sub>, <italic>p</italic>′<sub>2</sub>, … , <italic>p</italic>′<sub>N</sub>), <italic>i</italic> ϵ (1, 2, … , <italic>N</italic>).</p>
    </sec>
    <sec id="s2-5">
      <title>Causal Inference Using Do-Calculus Section</title>
      <p>Since the transformer is a generative model, the ALBERT based classification model can be seen as a conditional probability distribution <italic>p</italic> (endpoint|clinical features) of the endpoint in the clinical feature in FAERS case reports. However, this conditional probability distribution could not provide convincing evidence of causal effects, similar in the way as one cannot conclude causal effects from a randomized clinical trial with only the treatment group. To empirically estimate the potential clinical features causing the endpoint, we used the Judea Pearl’s Do-calculus framework (<xref rid="B21" ref-type="bibr">Tucci, 2013</xref>; <xref rid="B16" ref-type="bibr">Pearl and Mackenzie, 2018</xref>). The Do-calculus aims to investigate the interventional conditional probability distribution of <italic>p</italic>[endpoint|DO(clinical features)] by counterfactually changing the clinical features. In this study, we considered the clinical features as the cause of the endpoint if there is a statistically significant difference between the interventional conditional probability distributions of <italic>p</italic>[endpoint|DO(clinical features)] and <italic>p</italic>[endpoint|NOT DO(clinical features)].</p>
      <p>Based on the conditional probability distribution <italic>O</italic> generated from our developed ALBERT<sub>base</sub> classifier, we performed the Do-calculus procedure to estimate the cause of the endpoint. The pseudo code of the Do-calculus procedure is shown below.</p>
      <p><bold>Algorithm 1:</bold> Do-calculus algorithm.</p>
      <p>
        <inline-graphic xlink:href="frai-04-659622-fx1.jpg"/>
      </p>
      <p>For all the terms in each clinical feature, we applied the Do-calculus algorithm to check whether it is the cause of the endpoint. For a term <italic>t</italic>
<sub><italic>jk</italic></sub>, if a case report <italic>d</italic>
<sub><italic>i</italic></sub> contains <italic>t</italic>
<sub><italic>jk</italic></sub>, we say it is Do <italic>t</italic>
<sub><italic>jk</italic></sub>, while if <italic>f</italic>
<sub><italic>ij</italic></sub>≠∅ and <italic>t</italic>
<sub><italic>jk</italic></sub> is not in <italic>f</italic>
<sub><italic>ij</italic></sub>, then it is not do <italic>t</italic>
<sub><italic>jk</italic></sub>. We assigned the case <italic>d</italic>
<sub><italic>i</italic></sub> to different sets, <italic>L1</italic> and <italic>L2</italic>. <italic>L1</italic> is the set of case reports do <italic>t</italic>
<sub><italic>jk</italic></sub>, while <italic>L2</italic> consists of those case reports not do <italic>t</italic>
<sub><italic>jk</italic></sub>. We used the one tail z-test to evaluate whether instances in <italic>L1</italic> have significant differences to those in <italic>L2</italic>. For example, if the endpoint term is <italic>f</italic>
<sub><italic>m</italic></sub> and we want to see the impact of <italic>t</italic>
<sub><italic>11</italic></sub> (the first term of the first feature), then for each instance <italic>d</italic>
<sub><italic>i</italic></sub> we have the probability of <italic>f</italic>
<sub><italic>m</italic></sub> being positive as follows:<disp-formula id="e2"><mml:math id="m2"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(2)</label></disp-formula>
</p>
      <p>As shown in <xref ref-type="disp-formula" rid="e3">Eqs. 3</xref>, <xref ref-type="disp-formula" rid="e4">4</xref>, for those instances do <italic>t</italic>
<sub>11</sub>, the set is <italic>L1</italic>, while those not do the set is <italic>L2</italic>.<disp-formula id="e3"><mml:math id="m3"><mml:mrow><mml:mi>L</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:msup><mml:mi>p</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>i</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:msup><mml:mi>p</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(3)</label></disp-formula>
<disp-formula id="e4"><mml:math id="m4"><mml:mrow><mml:mi>L</mml:mi><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:msup><mml:mi>p</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>i</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:msup><mml:mi>p</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>∉</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math><label>(4)</label></disp-formula>
</p>
      <p>To establish all the causal terms of the end point, we evaluated every term in each feature. This generated the term set <italic>L</italic>, which is the set of all the terms in each feature that satisfy the statistical significance test.</p>
    </sec>
    <sec id="s2-6">
      <title>Causal Tree Construction</title>
      <p>To further explore the causal relationship among the enriched causal terms, we built a causal tree based on the Do-calculus. For each term in <italic>L</italic>, which has significant relationship with the end point <italic>f</italic>
<sub><italic>m</italic></sub>, we explored the secondary causal terms. For example, if <italic>t</italic>
<sub>11</sub> is a term in <italic>L</italic> (i.e., an established cause), and we wanted to verify whether <italic>t</italic>
<sub>21</sub> is a secondary cause for the endpoint <italic>f</italic>
<sub><italic>m</italic></sub>, then we fixed the <italic>t</italic>
<sub>11</sub> term and performed a statistical significance test on the difference between the instances following distribution shown as <xref ref-type="disp-formula" rid="e5">Eq. 5</xref> and that following distribution shown as <xref ref-type="disp-formula" rid="e6">Eq. 6</xref>.<disp-formula id="e5"><mml:math id="m5"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(5)</label></disp-formula>
<disp-formula id="e6"><mml:math id="m6"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mi>ϵ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub><mml:mo>∉</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(6)</label></disp-formula>
</p>
      <p>By recursively performing the do-calculus algorithm on the subset of <italic>L</italic>1, we found the set of secondary terms <italic>L</italic>′ based on each term <italic>t</italic> in the set <italic>L</italic>. Consequently, the enriched causal factors could be arranged in a hierarchical tree structure. To provide more interpretable results, we only focused on the most significant causal factors by restricting the maximum number of causal factors that is equal to the tree level. In other words, in tree level <italic>N</italic>, the number of retained causal factors was less or equal to <italic>N</italic>.</p>
    </sec>
    <sec id="s2-7">
      <title>Robustness Evaluation</title>
      <p>The proposed InferBERT model is based on the fine-tuned pretrained ALBERT<sub>base</sub> for text classification and causal inference. Application of pretrained language models to the supervised downstream task is designed in the BERT model and its derivatives such as ALBERT. However, this process can be less than robust: even with the same parameter values, distinct random seeds can lead to different results (<xref rid="B8" ref-type="bibr">Dodge et al., 2020</xref>). To investigate the reproducibility of our InferBERT model, we repeated parallel experiments with the same parameters. Two strategies were applied to compare the enriched causal terms (terms hereafter) from the do-calculus algorithm. First, a Venn diagram was used to compare the consistency of the enriched terms among the different runs. The average percentage of enriched terms per repeated run was calculated by the following <xref ref-type="disp-formula" rid="e7">Eq. 7</xref>:<disp-formula id="e7"><mml:math id="m7"><mml:mrow><mml:mtext>average percentage of enriched terms</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:mrow><mml:mtext>number of common enriched terms in all runs </mml:mtext></mml:mrow><mml:mrow><mml:mtext>number of enriched terms in run </mml:mtext><mml:mi>i</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(7)</label></disp-formula>where <italic>T</italic> is total number of repeated runs.</p>
      <p>Second, the percentage of overlapped terms (POT) strategy was used to investigate the consistency of the order of enriched terms. Specifically, we ranked the enriched terms based on their z-score from high to low. We then calculated the POT by the number of overlapping terms among three repeated runs divided by the number of enriched terms in each subset of the ranked enriched term list.</p>
    </sec>
    <sec id="s2-8">
      <title>Conventional Causal Inference Methods</title>
      <p>To further verify the results yielded by the proposed InferBERT model, we employed three conventional causal inference methods including the proportional reporting ratio (PRR) <xref rid="B10" ref-type="bibr">Evans et al. (2001)</xref>, the reporting odds ratio (ROR) <xref rid="B22" ref-type="bibr">Van Puijenbroek et al. (2002)</xref>, and the empirical Bayes geometric mean (EBGM) <xref rid="B19" ref-type="bibr">Szarfman et al. (2002)</xref> for the causal inference of the two datasets. Specifically, we calculated the signal scores for the enriched teams from the proposed InferBERT model using the three conventional approaches to investigate whether these clinically verified terms could be identified. The three conventional methods are widely used for safety signal detection to prioritize the potential causal factors in FAERS datasets. PRR and ROR are based on the case frequency and statistical measures, while EBGM is based on Bayesian estimation. In this study, the standard cut-off values for enriching the safety signal were used. For the PRR, a signal is detected if the number of co-occurrences is three or more and the PRR is two or more with an associated χ<sup>2</sup> value of four or more. For the ROR, a signal is detected if the lower limit of the 95% two-sided confidence interval exceeds one. For the EBGM, a signal is enriched when the lower one-sided 95% confidence limit of the EBGM (EB05) equal or more than two.</p>
    </sec>
    <sec id="s2-9">
      <title>Implementation of the InferBERT</title>
      <p>To facilitate the application of our model, we developed a standalone package to simplify the implementation process. The current version of the InferBERT is based on a lite version of BERT (ALBERT, <ext-link ext-link-type="uri" xlink:href="https://github.com/google-research/bert">https://github.com/google-research/bert</ext-link>) under Python 3.6 and TensorFlow version 1.15. We evaluated our proposed InferBERT model on one NVIDIA Tesla V100 GPU. For Analgesics-induced acute liver failure and Tramadol-related mortalities datasets, the average runtime was 7.5 and 6 h. We incorporated the causal function into the ALBERT source code and make it publicly available through <ext-link ext-link-type="uri" xlink:href="https://github.com/XingqiaoWang/DeepCausalPV-master">https://github.com/XingqiaoWang/DeepCausalPV-master</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3-1">
      <title>Construction of Artificial Sentences Based on FAERS Case Reports</title>
      <p><xref ref-type="fig" rid="F2">Figure 2</xref> illustrates the sequence length distribution for two sentence sets, respectively. The average and standard deviation of sequence lengths were 41.34 ± 11.14 and 56.94 ± 36.40 for the Analgesics-induced acute liver failure and Tramadol-related mortalities sentence sets, respectively. Considering the adverse event feature was designed as the endpoint for Analgesics-induced acute liver failure, the shorter average sequence was expected. We further calculated the term frequency-inverse document frequency (tf-idf), and the top 10 terms with the highest tf-idf values are listed in <xref rid="T2" ref-type="table">Table 2</xref>. The most frequent terms for Analgesics-induced acute liver failure sentence set were acetylcysteine, <italic>acinetobacter</italic>, alafenamide, altered, and appendicectomy. Terms including abacavir, indomethacin, glossodynia, idiopathic, and amnestic showed the highest tf-idf values in the Tramadol-related mortalities sentence set.</p>
      <fig id="F2" position="float">
        <label>FIGURE 2</label>
        <caption>
          <p>The distribution of sequence length: <bold>(A)</bold> Analgesics-induced acute liver failure; and <bold>(B)</bold> Tramadol-related mortalities.</p>
        </caption>
        <graphic xlink:href="frai-04-659622-g002"/>
      </fig>
      <table-wrap id="T2" position="float">
        <label>TABLE 2</label>
        <caption>
          <p>Top 10 most frequent terms in the two sentence sets based on the tf-idf values.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th colspan="2" align="center" rowspan="1">Analgesics-related acute liver failure</th>
              <th colspan="2" align="center" rowspan="1">Tramadol-related mortalities</th>
            </tr>
            <tr>
              <th align="left" rowspan="1" colspan="1">Terms</th>
              <th align="center" rowspan="1" colspan="1">Tf-idf value</th>
              <th align="center" rowspan="1" colspan="1">Terms</th>
              <th align="center" rowspan="1" colspan="1">Tf-idf value</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">Acetylcysteine</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Abacavir</td>
              <td align="center" rowspan="1" colspan="1">0.0323</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Acinetobacter</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Indomethacin</td>
              <td align="center" rowspan="1" colspan="1">0.0323</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Alafenamide</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Glossodynia</td>
              <td align="center" rowspan="1" colspan="1">0.0315</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Altered</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Idiopathic</td>
              <td align="center" rowspan="1" colspan="1">0.0315</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Appendicectomy</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Amnestic</td>
              <td align="center" rowspan="1" colspan="1">0.0312</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Appetite</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Assault</td>
              <td align="center" rowspan="1" colspan="1">0.0312</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Assist</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Axetil</td>
              <td align="center" rowspan="1" colspan="1">0.0312</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Atherosclerosis</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Bradyarrhythmia</td>
              <td align="center" rowspan="1" colspan="1">0.0312</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Brucellosis</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Brugada</td>
              <td align="center" rowspan="1" colspan="1">0.0312</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Cabazitaxel</td>
              <td align="center" rowspan="1" colspan="1">0.0318</td>
              <td align="center" rowspan="1" colspan="1">Cardiorenal</td>
              <td align="center" rowspan="1" colspan="1">0.0312</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s3-2">
      <title>ALBERT Model Development</title>
      <p>ALBERT<sub>base</sub> model developed on the 16G BOOKCORPUS <xref rid="B27" ref-type="bibr">Zhu et al. (2015)</xref> and English Wikipedia <xref rid="B7" ref-type="bibr">Devlin et al. (2018)</xref> were employed in this study. The ALBERT<sub>base</sub> model consisted of 12 repeating layers, 128 embeddings, 768 hidden, and 12 heads with 11 M parameters. We further fine-tuned the ALBERT<sub>base</sub> model with training sets and determined the optimized models based on text classification results in the development sets for the endpoints, (i.e. acute liver failure and death). We used one NVIDIA V100 (32 GB) GPU for fine-tuning the model. For the Analgesics-induced acute liver failure dataset, the maximum sequence length was fixed to 128, and the mini-batch size was set to 128. A total of 10,000 training steps were implemented with 2,000-step warmup, and the checkpoint step was set to 500 for recording the prediction results. For the Tramadol-related mortalities dataset, we used the same parameter settings except for a longer maximum sequence length, (i.e. 256). More training steps, (i.e. 20,000 steps) were selected as well since the Tramadol-average sequence length was longer than that of the Analgesics-induced acute liver failure dataset.</p>
      <p><xref ref-type="fig" rid="F3">Figure 3</xref> depicts the trends of loss and accuracy, along with training steps based on development sets. The cross-entropy loss tended to be stable after 4,000 training steps and 5,000 steps for the Analgesics-induced acute liver failure dataset and Tramadol-related mortalities dataset, respectively. Furthermore, the accuracies of the two datasets changed minimally after steps 3,000 and 5,000. Here, we selected the optimized fine-tuned model based on the steps with the maximum accuracy, i.e., 5,500 steps and 10,000 steps for the Analgesics-induced acute liver failure dataset and Tramadol-related mortalities dataset, respectively.</p>
      <fig id="F3" position="float">
        <label>FIGURE 3</label>
        <caption>
          <p>The relationship between cross-entropy loss and accuracy and training steps in fine-tuned ALBERT models: <bold>(A)</bold> Analgesics-induced acute liver failure; and <bold>(B)</bold> Tramadol-related mortalities. The red and gray colors denote the accuracy and cross-entropy loss, respectively.</p>
        </caption>
        <graphic xlink:href="frai-04-659622-g003"/>
      </fig>
    </sec>
    <sec id="s3-3">
      <title>Causal Inference</title>
      <p>To investigate whether the proposed InferBERT approach could capture the causal factors aligned with clinical knowledge, we further carried out the do-calculus analysis to decipher the causal factors for the Analgesics-induced acute liver failure and Tramadol-related mortalities datasets. There are 42 and 48 clinical terms enriched with an adjusted <italic>p</italic> value less than 0.05 using a one-tail z-test for the Analgesics-induced acute liver failure and Tramadol-related mortalities datasets, respectively (see <xref ref-type="sec" rid="s9">Supplementary Table S1</xref>). The clinical terms were distributed into different clinical feature categories, including adverse events, primary suspect drug (psd), age, dose, and gender. Among the enriched clinical terms, the clinical terms with the highest z-score in each clinical feature category were considered as root causes of endpoints (<xref rid="T3" ref-type="table">Table 3</xref>).</p>
      <table-wrap id="T3" position="float">
        <label>TABLE 3</label>
        <caption>
          <p>Enriched causal clinical terms by the proposed InferBERT AI model.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Clinical categories</th>
              <th align="center" rowspan="1" colspan="1">Clinical terms</th>
              <th align="center" rowspan="1" colspan="1">Z-score</th>
              <th align="center" rowspan="1" colspan="1">Average of do probabilities</th>
              <th align="center" rowspan="1" colspan="1">Average of not do probabilities</th>
              <th align="center" rowspan="1" colspan="1">Adjusted <italic>p</italic> value</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td colspan="6" align="left" rowspan="1">Analgesics-induced acute liver failure</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> primary suspect drug</td>
              <td align="center" rowspan="1" colspan="1">APAP</td>
              <td align="center" rowspan="1" colspan="1">153.92</td>
              <td align="center" rowspan="1" colspan="1">0.84</td>
              <td align="center" rowspan="1" colspan="1">0.33</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Age</td>
              <td align="center" rowspan="1" colspan="1">18–39</td>
              <td align="center" rowspan="1" colspan="1">36.01</td>
              <td align="center" rowspan="1" colspan="1">0.54</td>
              <td align="center" rowspan="1" colspan="1">0.35</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Gender</td>
              <td align="center" rowspan="1" colspan="1">Female</td>
              <td align="center" rowspan="1" colspan="1">17.06</td>
              <td align="center" rowspan="1" colspan="1">0.41</td>
              <td align="center" rowspan="1" colspan="1">0.35</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Dose</td>
              <td align="center" rowspan="1" colspan="1">Larger than 100 mg</td>
              <td align="center" rowspan="1" colspan="1">8.93</td>
              <td align="center" rowspan="1" colspan="1">0.39</td>
              <td align="center" rowspan="1" colspan="1">0.35</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Outcome</td>
              <td align="center" rowspan="1" colspan="1">Death</td>
              <td align="center" rowspan="1" colspan="1">119.33</td>
              <td align="center" rowspan="1" colspan="1">0.68</td>
              <td align="center" rowspan="1" colspan="1">0.30</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td colspan="6" align="left" rowspan="1">Tramadol-related mortalities</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Adversary events</td>
              <td align="center" rowspan="1" colspan="1">Completed suicide</td>
              <td align="center" rowspan="1" colspan="1">252.27</td>
              <td align="center" rowspan="1" colspan="1">1.00</td>
              <td align="center" rowspan="1" colspan="1">0.28</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Age</td>
              <td align="center" rowspan="1" colspan="1">40–64</td>
              <td align="center" rowspan="1" colspan="1">18.33</td>
              <td align="center" rowspan="1" colspan="1">0.44</td>
              <td align="center" rowspan="1" colspan="1">0.32</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Gender</td>
              <td align="center" rowspan="1" colspan="1">Male</td>
              <td align="center" rowspan="1" colspan="1">3.62</td>
              <td align="center" rowspan="1" colspan="1">0.37</td>
              <td align="center" rowspan="1" colspan="1">0.34</td>
              <td align="char" char="." rowspan="1" colspan="1">0.0001</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Dose</td>
              <td align="center" rowspan="1" colspan="1">Drug abuse</td>
              <td align="center" rowspan="1" colspan="1">38.77</td>
              <td align="center" rowspan="1" colspan="1">0.74</td>
              <td align="center" rowspan="1" colspan="1">0.33</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"> Primary suspect drug</td>
              <td align="center" rowspan="1" colspan="1">Hydrocodone bitartrate</td>
              <td align="center" rowspan="1" colspan="1">23.67</td>
              <td align="center" rowspan="1" colspan="1">0.91</td>
              <td align="center" rowspan="1" colspan="1">0.36</td>
              <td align="center" rowspan="1" colspan="1">&lt; 1E-16</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>For Analgesics-induced acute liver failure, the enriched root causal factors (z-score) including primary suspect drug<sup>—</sup>APAP (153.92), age<sup>—</sup>18–39 (36.01), gender<sup>—</sup>female (17.06), dose<sup>—</sup>larger than 100 mg (8.93), and outcome<sup>—</sup>death (119.33) were enriched, which is highly consistent with the clinical backgrounds mentioned above. For Tramadol-related mortalities, the enriched root causal factors (z-score) consisted of primary suspect drug<sup>—</sup>Hydrocodone Bitartrate (23.66), age<sup>—</sup>40–64 (18.33), gender–male (3.62), dose<sup>—</sup>drug abuse (38.77), and adverse events<sup>—</sup>Completed suicide (252.27), which is aligned with its clinical background.</p>
      <p>To further uncover the interrelationship among causal factors, we implemented a causal tree analysis using the causal factor with highest z-score as a start point. <xref ref-type="fig" rid="F4">Figure 4</xref> illustrates the constructed causal tree for the endpoints. The link was established with an adjusted <italic>p</italic> value less than 0.05 using a one-tail z-test. For Analgesics-induced acute liver failure, the causal tree penetrated the root cause of Analgesics-induced acute liver failure in patients taking APAP. Furthermore, among the patients taking APAP, the age group 40–64 and women were more likely to take APAP. Moreover, compared to men, women with APAP overdose were more likely to have ALI/ALF, or even death. For Tramadol-related mortalities, the causal tree only consisted of the root level, suggesting that completed suicide was the leading cause of Tramadol-related death.</p>
      <fig id="F4" position="float">
        <label>FIGURE 4</label>
        <caption>
          <p>Causal trees for <bold>(A)</bold> Analgesics-induced acute liver failure; and <bold>(B)</bold> Tramadol-related mortalities. The number attached to each arrow denotes the z-score.</p>
        </caption>
        <graphic xlink:href="frai-04-659622-g004"/>
      </fig>
    </sec>
    <sec id="s3-4">
      <title>Robustness Analysis</title>
      <p><xref ref-type="fig" rid="F5">Figure 5</xref> depicts the robustness assessment of the proposed InferBERT model. Venn diagrams showed an average of 82.4 and 95.8% of enriched terms from all the three repeated runs for Analgesics-induced acute liver failure and Tramadol-related mortalities, respectively. Furthermore, the top-ranked enriched terms were very consistent among the top-ranked lists of different repeated runs, as shown in the POT curves of <xref ref-type="fig" rid="F5">Figure 5</xref>. The POT values of the top 10 ranked terms among the three runs were 0.8 and one for Analgesics-induced acute liver failure and Tramadol-related mortalities, respectively. Altogether, the proposed InferBERT model yielded highly repeatable results with great potential for use in further real-world applications. This result indicates that our proposed InferBERT framework is robust, which is an important advantage over other machine learning approaches that are solely based on data without reasoning causality inference.</p>
      <fig id="F5" position="float">
        <label>FIGURE 5</label>
        <caption>
          <p>Robustness evaluation of the proposed InferBERT model. The yellow and green colors denote Analgesics-induced acute liver failure and Tramadol-related mortalities datasets, respectively. The Venn diagram illustrates the overlapping of the enriched causal terms by three repeated runs. The percentage of overlapping terms (POPs) shown in the dotted-line curve represent the consistency among ranked order terms from the three repeated runs.</p>
        </caption>
        <graphic xlink:href="frai-04-659622-g005"/>
      </fig>
    </sec>
    <sec id="s3-5">
      <title>Comparison With the Conventional Causal Inference Methods</title>
      <p>We further compared the proposed InferBERT model with three conventional signal detection methods (i.e., PRR, ROR, and EBGM) widely applied in pharmacovigilance. <xref ref-type="fig" rid="F6">Figure 6</xref> illustrated the overlapping terms enriched by the InferBERT model and three conventional methods. The InferBERT model identified more causal factors than three conventional approaches. For Analgesics-induced acute liver failure dataset, the number of enriched terms were ranked as InferBERT model (43 terms) &gt; ROR (23 terms) &gt; PRR (2 terms) &gt; EBGM (0 term). Notably, InferBERT discovers all the causal factors that identified by other conventional methods. On the other hand, all conventional methods missed some of the causal factors discovered by InferBERT, which are verified by the clinical knowledge. Furthermore, the top-ranking terms, (i.e. ranked terms based on the scores in each method) such as “APAP” and “death” were enriched among the four methods, demonstrating the consistency of the proposed method and conventional approaches (<xref ref-type="sec" rid="s9">Supplementary Table S2</xref>). A similar observation was also showed in the Tramadol-related mortalities. The proposed InferBERT model identified the most terms (50), followed by ROR (43), PRR (13), and EBGM (9). The top enriched term “completed suicide” was identified by all four methods. The more enriched terms from the proposed InferBERT model may benefit from the superior ability to uncover the hidden relationship between variables by the transformer model.</p>
      <fig id="F6" position="float">
        <label>FIGURE 6</label>
        <caption>
          <p>Comparison between the proposed InferBERT model and the three conventional causal inference models including PRR, ROR EBGM: <bold>(A)</bold> Analgesics-induced acute liver failure; and <bold>(B)</bold> Tramadol-related mortalities datasets, respectively.</p>
        </caption>
        <graphic xlink:href="frai-04-659622-g006"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>Transformer-based language models have greatly expanded the potential of NLP applications. However, few attempts have been made to apply transformer-based language models to address an unmet need for enhanced model-based reasoning for causality. To our best knowledge, the current study and description of InferBERT is the first to succeed in causal inference, aimed at boosting pharmacovigilance. To investigate the performance of our proposed InferBERT model, we used two FAERS case studies, Analgesics-induced acute liver failure and Tramadol-related mortalities, to prove the concept. The root causes of the two datasets were identified, and the results were consistent with the causal relationship derived from real-world data. Moreover, the proposed causal tree seamlessly linked the enriched causal factors into a hierarchical structure to decipher the interrelationship among the causal factors. Furthermore, the high reproducibility of the proposed InferBERT model warrants its potential real-world application.</p>
    <p>The FAERS database is an essential resource for hypothesis generation to support pharmacovigilance. However, FAERS data derive from a spontaneous submission by pharmaceutical companies and physicians. There are many data integrity issues such as duplicate records, unstandardized terminologies, missed values, and missing information. Tremendous efforts have been made to clean, normalize, and standardize the data and format, enabling researchers to fully take advantage of the datasets (<xref rid="B2" ref-type="bibr">Banda et al., 2016</xref>). In this study, we have used an innovative approach to convert FAERS case reports to sentence-like descriptions as the input for transformer-based language models. This greatly simplified the data preprocessing and overcame the need for a process to handle any missing values. In this study, we employed the preprocessed FARES data curated by the commercial database PharmaPendium (<ext-link ext-link-type="uri" xlink:href="https://www.pharmapendium.com/login">https://www.pharmapendium.com/login</ext-link>), where the original FAERS data is preprocessed for consolidating all relevant data, normalizing different term usage, de-duplicating records, and mapping to either RxNorm (for drugs) or any other controlled terminology (for adverse events), as well as negations. For the further application of the original FAERS, the positive/negative sample definition should be more cautious since the negation issue could deteriorate the quality of positive and negative classification and further decrease the reliability of the causal inference results.</p>
    <p>To demonstrate the performance of the proposed InferBERT model, we employed synthetic sentences constructed by standard terminology from the processed FAERS data. The data quality of data resources is crucial for applying the model for causality analysis. For example, the complex causal relationship is embedded in the electronic medical records (EMR), which is essential to suggest the right clinical decision and improve the clinical outcome. Initial efforts such as ClinicalBERT have been proposed to address the clinical questions. A further investigation to combine the ClinicalBERT <xref rid="B12" ref-type="bibr">Huang et al.(2019)</xref> with our proposed causal inference strategy may be a promising direction to expand the utility of the current InferBERT model.</p>
    <p>There are two limitations in the current version of the InferBERT model, which needs to further investigation. First, we developed the InferBERT model based on FAERS data with a fixed pattern. Further investigation on the different types of free-text data in the biomedical fields is a “must” to evaluate the generalization of the proposed model. Second, we only investigated the model performance with two endpoints (i.e., Analgesics-related acute liver failure and Tramadol-related death). The proposed InferBERT model should be further evaluated with diverse free text-based biomedical datasets to lay out the pros and cons in real-world applications. </p>
    <p>It would be valuable to consider some additional studies to investigate potential further improvement of the proposed InferBERT model. Firstly, the proposed InferBERT model was developed based on the ALBERT<sub>base</sub> model. Other transformer-based language models could be further investigated to improve causal inference results. A comparative analysis between different transformer models on the improved performance is strongly recommended. The comparison could address the impact factor of model performance such as computational power, computer time, and improvement of model performance, which could be very helpful to select the “fit-for-purpose” model to carry out the causal inference toward real-world application. Secondly, the language model represents the interrelationship of variables in a probabilistic graph. Therefore, Bayesian theory could be considered as a possible route to improve causal inference. The proposed model needs to predefine the endpoint to carry out the causal analysis. The combination of the transformer model and Bayesian approaches may be a promising solution to comprehensively evaluate the causal relationship among different variables in the data. Thirdly, in the current study, we focus on the identification of causal factors of the endpoint. The developed InferBERT model could be utilized to test the potential influence of endpoints for any term combination, which may provide further confidence and establish a causality-based Question and Answering system. Lastly, the current developed InferBERT model is a supervised-based causal inference system. Future work for self-learning of interrelationships among variables directly derived from the pre-trained language models may provide a more intelligent way to identify causal factors for any clinical outcome.</p>
    <p>Despite the current attention around AI, most AI-powered language models focus on predicting outcomes rather than understanding causality. Here, we explored the potential utility of transformer-based language models for causal inference in pharmacovigilance. We hope our study can further trigger community interest to examine the potential of AI for understanding the data and to improve the causal interpretability of AI models in the biomedical field.</p>
  </sec>
</body>
<back>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>The original contributions presented in the study are included in the article/<xref ref-type="sec" rid="s9">Supplementary Material</xref>, further inquiries can be directed to the corresponding authors.</p>
  </sec>
  <sec id="s6">
    <title>Author Contributions</title>
    <p>XX devised the deep causal model applied to this study. ZL and WT conceived and designed the study of utilizing the model for pharmacovigilance. XW coded the deep causal model. XW and ZL performed data analysis. ZL, XW, and XX wrote the manuscript. WT and RR revised the manuscript. All authors read and approved the final manuscript.</p>
  </sec>
  <sec id="s7">
    <title>Disclaimer</title>
    <p>This article reflects the views of the authors and does not necessarily reflect those of the U.S. Food and Drug Administration. Any mention of commercial products is for clarification and is not intended as an endorsement.</p>
  </sec>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of Interest</title>
    <p>RR is co-founder and co-director of ApconiX, an integrated toxicology and ion channel company that provides expert advice on non-clinical aspects of drug discovery and drug development to academia, industry, and not-for-profit organizations.</p>
    <p>The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec id="s9">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/frai.2021.659622/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/frai.2021.659622/full#supplementary-material</ext-link>
</p>
    <supplementary-material content-type="local-data" id="SM1">
      <media xlink:href="Table2.XLSX">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM2">
      <media xlink:href="Table1.XLSX">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Awad</surname><given-names>E.</given-names></name><name><surname>Dsouza</surname><given-names>S.</given-names></name><name><surname>Kim</surname><given-names>R.</given-names></name><name><surname>Schulz</surname><given-names>J.</given-names></name><name><surname>Henrich</surname><given-names>J.</given-names></name><name><surname>Shariff</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>The Moral Machine experiment</article-title>. <source>Nature</source>
<volume>563</volume> (<issue>7729</issue>), <fpage>59</fpage>–<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-018-0637-6</pub-id>
<pub-id pub-id-type="pmid">30356211</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banda</surname><given-names>J. M.</given-names></name><name><surname>Evans</surname><given-names>L.</given-names></name><name><surname>Vanguri</surname><given-names>R. S.</given-names></name><name><surname>Tatonetti</surname><given-names>N. P.</given-names></name><name><surname>Ryan</surname><given-names>P. B.</given-names></name><name><surname>Shah</surname><given-names>N. H.</given-names></name></person-group> (<year>2016</year>). <article-title>A Curated and Standardized Adverse Drug Event Resource to Accelerate Drug Safety Research</article-title>. <source>Sci. Data</source>
<volume>3</volume>, <fpage>160026</fpage>. <pub-id pub-id-type="doi">10.1038/sdata.2016.26</pub-id>
<pub-id pub-id-type="pmid">27193236</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basco</surname><given-names>W. T.</given-names></name><name><surname>Garner</surname><given-names>S. S.</given-names></name><name><surname>Ebeling</surname><given-names>M.</given-names></name><name><surname>Hulsey</surname><given-names>T. C.</given-names></name><name><surname>Simpson</surname><given-names>K.</given-names></name></person-group> (<year>2016</year>). <article-title>Potential Acetaminophen and Opioid Overdoses in Young Children Prescribed Combination Acetaminophen/Opioid Preparations</article-title>. <source>Pediatr. Qual. Saf.</source>
<volume>1</volume> (<issue>2</issue>), <fpage>e007</fpage>. <pub-id pub-id-type="doi">10.1097/pq9.0000000000000007</pub-id>
<pub-id pub-id-type="pmid">29862380</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernal</surname><given-names>W.</given-names></name><name><surname>Wendon</surname><given-names>J.</given-names></name></person-group> (<year>2013</year>). <article-title>Acute Liver Failure</article-title>. <source>N. Engl. J. Med.</source>
<volume>369</volume> (<issue>26</issue>), <fpage>2525</fpage>–<lpage>2534</lpage>. <pub-id pub-id-type="doi">10.1056/NEJMra1208937</pub-id>
<pub-id pub-id-type="pmid">24369077</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Björnsson</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). <article-title>Review Article: Drug-Induced Liver Injury in Clinical Practice</article-title>. <source>Aliment. Pharmacol. Ther.</source>
<volume>32</volume> (<issue>1</issue>), <fpage>3</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1111/j.1365-2036.2010.04320.x</pub-id>
<pub-id pub-id-type="pmid">20374223</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>T. B.</given-names></name><name><surname>Mann</surname><given-names>B.</given-names></name><name><surname>Ryder</surname><given-names>N.</given-names></name><name><surname>Subbiah</surname><given-names>M.</given-names></name><name><surname>Kaplan</surname><given-names>J.</given-names></name><name><surname>Dhariwal</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2020</year>). <source>Language Models Are Few-Shot Learners</source>. <comment>arXiv preprint arXiv:2005.14165</comment>.</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>J.</given-names></name><name><surname>Chang</surname><given-names>M.-W.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Toutanova</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <source>Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding</source>.<comment>arXiv preprint arXiv:1810.04805</comment>.</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dodge</surname><given-names>J.</given-names></name><name><surname>Ilharco</surname><given-names>G.</given-names></name><name><surname>Schwartz</surname><given-names>R.</given-names></name><name><surname>Farhadi</surname><given-names>A.</given-names></name><name><surname>Hajishirzi</surname><given-names>H.</given-names></name><name><surname>Smith</surname><given-names>N.</given-names></name></person-group> (<year>2020</year>). <source>Fine-tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping</source>.<comment>arXiv preprint arXiv:2002.06305</comment>.</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>I. R.</given-names></name></person-group> (<year>2012</year>). <article-title>Considerations on Causality in Pharmacovigilance</article-title>. <source>Int. J. Risk Saf. Med.</source>
<volume>24</volume> (<issue>1</issue>), <fpage>41</fpage>–<lpage>54</lpage>. <pub-id pub-id-type="doi">10.3233/jrs-2012-0552</pub-id>
<pub-id pub-id-type="pmid">22436259</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>S. J. W.</given-names></name><name><surname>Waller</surname><given-names>P. C.</given-names></name><name><surname>Davis</surname><given-names>S.</given-names></name></person-group> (<year>2001</year>). <article-title>Use of Proportional Reporting Ratios (PRRs) for Signal Generation from Spontaneous Adverse Drug Reaction Reports</article-title>. <source>Pharmacoepidem. Drug Safe.</source>
<volume>10</volume> (<issue>6</issue>), <fpage>483</fpage>–<lpage>486</lpage>. <pub-id pub-id-type="doi">10.1002/pds.677</pub-id>
</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Feder</surname><given-names>A.</given-names></name><name><surname>Oved</surname><given-names>N.</given-names></name><name><surname>Shalit</surname><given-names>U.</given-names></name><name><surname>Reichart</surname><given-names>R.</given-names></name></person-group> (<year>2020</year>). <source>CausaLM: Causal Model Explanation through Counterfactual Language Models</source>.<comment>arXiv preprint arXiv:2005.13407</comment>.</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>K.</given-names></name><name><surname>Altosaar</surname><given-names>J.</given-names></name><name><surname>Ranganath</surname><given-names>R.</given-names></name></person-group> (<year>2019</year>). <source>Clinicalbert: Modeling Clinical Notes and Predicting Hospital Readmission</source>. <comment>arXiv preprint arXiv:1904.05342</comment>.</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lan</surname><given-names>Z.</given-names></name><name><surname>Chen</surname><given-names>M.</given-names></name><name><surname>Goodman</surname><given-names>S.</given-names></name><name><surname>Gimpel</surname><given-names>K.</given-names></name><name><surname>Sharma</surname><given-names>P.</given-names></name><name><surname>Soricut</surname><given-names>R.</given-names></name></person-group> (<year>2019</year>). <source>Albert: A Lite Bert for Self-Supervised Learning of Language Representations</source>. <comment>arXiv preprint arXiv:1909.11942</comment>.</mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moraffah</surname><given-names>R.</given-names></name><name><surname>Karami</surname><given-names>M.</given-names></name><name><surname>Guo</surname><given-names>R.</given-names></name><name><surname>Raglin</surname><given-names>A.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name></person-group> (<year>2020</year>). <article-title>Causal Interpretability for Machine Learning - Problems, Methods and Evaluation</article-title>. <source>SIGKDD Explor. Newsl.</source>
<volume>22</volume> (<issue>1</issue>), <fpage>18</fpage>–<lpage>33</lpage>. <pub-id pub-id-type="doi">10.1145/3400051.3400058</pub-id>
</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J.</given-names></name></person-group> (<year>2010</year>). <article-title>An Introduction to Causal Inference</article-title>. <source>The Int. J. biostatistics</source>
<volume>6</volume> (<issue>2</issue>), <fpage>7</fpage>. <pub-id pub-id-type="doi">10.2202/1557-4679.1203</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J.</given-names></name><name><surname>Mackenzie</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <source>The Book of Why: The New Science of Cause and Effect</source>. <publisher-name>Basic Books</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>J. B.</given-names></name><name><surname>Hameed</surname><given-names>B.</given-names></name><name><surname>Gottfried</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>W. M.</given-names></name><name><surname>Sarkar</surname><given-names>M.</given-names></name></person-group><collab>Acute Liver Failure Study Group</collab> (<year>2018</year>). <article-title>Acute Liver Failure StudyAcetaminophen-Induced Acute Liver Failure Is More Common and More Severe in Women</article-title>. <source>Clin. Gastroenterol. Hepatol.</source>
<volume>16</volume> (<issue>6</issue>), <fpage>936</fpage>–<lpage>946</lpage>. <pub-id pub-id-type="doi">10.1016/j.cgh.2017.11.042</pub-id>
<pub-id pub-id-type="pmid">29199145</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silver</surname><given-names>D.</given-names></name><name><surname>Schrittwieser</surname><given-names>J.</given-names></name><name><surname>Simonyan</surname><given-names>K.</given-names></name><name><surname>Antonoglou</surname><given-names>I.</given-names></name><name><surname>Huang</surname><given-names>A.</given-names></name><name><surname>Guez</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Mastering the Game of Go without Human Knowledge</article-title>. <source>Nature</source>
<volume>550</volume> (<issue>7676</issue>), <fpage>354</fpage>–<lpage>359</lpage>. <pub-id pub-id-type="doi">10.1038/nature24270</pub-id>
<pub-id pub-id-type="pmid">29052630</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szarfman</surname><given-names>A.</given-names></name><name><surname>Machado</surname><given-names>S. G.</given-names></name><name><surname>O,Neill</surname><given-names>R. T.</given-names></name></person-group> (<year>2002</year>). <article-title>Use of Screening Algorithms and Computer Systems to Efficiently Signal Higher-Than-Expected Combinations of Drugs and Events in the US FDA,s Spontaneous Reports Database</article-title>. <source>Drug Saf.</source>
<volume>25</volume> (<issue>6</issue>), <fpage>381</fpage>–<lpage>392</lpage>. <pub-id pub-id-type="doi">10.2165/00002018-200225060-00001</pub-id>
<pub-id pub-id-type="pmid">12071774</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Topol</surname><given-names>E. J.</given-names></name></person-group> (<year>2019</year>). <article-title>High-performance Medicine: the Convergence of Human and Artificial Intelligence</article-title>. <source>Nat. Med.</source>
<volume>25</volume> (<issue>1</issue>), <fpage>44</fpage>–<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1038/s41591-018-0300-7</pub-id>
<pub-id pub-id-type="pmid">30617339</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tucci</surname><given-names>R. R.</given-names></name></person-group> (<year>2013</year>). <source>Introduction to Judea Pearl's Do-Calculus</source>. <comment>arXiv preprint arXiv:1305.5506</comment>
</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Puijenbroek</surname><given-names>E. n. P.</given-names></name><name><surname>Bate</surname><given-names>A.</given-names></name><name><surname>Leufkens</surname><given-names>H. G. M.</given-names></name><name><surname>Lindquist</surname><given-names>M.</given-names></name><name><surname>Orre</surname><given-names>R.</given-names></name><name><surname>Egberts</surname><given-names>A. C. G.</given-names></name></person-group> (<year>2002</year>). <article-title>A Comparison of Measures of Disproportionality for Signal Detection in Spontaneous Reporting Systems for Adverse Drug Reactions</article-title>. <source>Pharmacoepidem. Drug Safe.</source>
<volume>11</volume> (<issue>1</issue>), <fpage>3</fpage>–<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1002/pds.668</pub-id>
</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A.</given-names></name><name><surname>Shazeer</surname><given-names>N.</given-names></name><name><surname>Parmar</surname><given-names>N.</given-names></name><name><surname>Uszkoreit</surname><given-names>J.</given-names></name><name><surname>Jones</surname><given-names>L.</given-names></name><name><surname>Gomez</surname><given-names>A. N.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Attention Is All You Need</article-title>. <conf-name>Advances In Neural Information Processing Systems</conf-name>, <fpage>5998</fpage>–<lpage>6008</lpage>. </mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Veitch</surname><given-names>V.</given-names></name><name><surname>Sridhar</surname><given-names>D.</given-names></name><name><surname>Blei</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Adapting Text Embeddings for Causal Inference</article-title>. <conf-name>Conference On Uncertainty In Artificial Intelligence: PMLR</conf-name>, <fpage>919</fpage>–<lpage>928</lpage>. </mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woo</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>An AI Boost for Clinical Trials</article-title>. <source>Nature</source>
<volume>573</volume> (<issue>7775</issue>), <fpage>S100</fpage>–<lpage>S102</lpage>. <pub-id pub-id-type="doi">10.1038/d41586-019-02871-3</pub-id>
<pub-id pub-id-type="pmid">31554996</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zaheer</surname><given-names>M.</given-names></name><name><surname>Guruganesh</surname><given-names>G.</given-names></name><name><surname>Dubey</surname><given-names>A.</given-names></name><name><surname>Ainslie</surname><given-names>J.</given-names></name><name><surname>Alberti</surname><given-names>C.</given-names></name><name><surname>Ontanon</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2020</year>). <source>Big Bird: Transformers for Longer Sequences</source>. <comment>arXiv preprint arXiv:2007.14062</comment>
</mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Kiros</surname><given-names>R.</given-names></name><name><surname>Zemel</surname><given-names>R.</given-names></name><name><surname>Salakhutdinov</surname><given-names>R.</given-names></name><name><surname>Urtasun</surname><given-names>R.</given-names></name><name><surname>Torralba</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Aligning Books and Movies: Towards story-like Visual Explanations by Watching Movies and reading Books</article-title>. <conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name>, <fpage>19</fpage>–<lpage>27</lpage>. </mixed-citation>
    </ref>
  </ref-list>
</back>
