<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_XPRO101583 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEfx1 jpg ?>
<?FILEfx2 jpg ?>
<?FILEfx3 jpg ?>
<?FILEsi1 gif ?>
<?FILEsi2 gif ?>
<?FILEsi3 gif ?>
<?FILEsi4 gif ?>
<?FILEsi5 gif ?>
<?FILEsi6 gif ?>
<?FILEsi7 gif ?>
<?FILEsi8 gif ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">STAR Protoc</journal-id>
    <journal-id journal-id-type="iso-abbrev">STAR Protoc</journal-id>
    <journal-title-group>
      <journal-title>STAR Protocols</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2666-1667</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9307566</article-id>
    <article-id pub-id-type="pii">S2666-1667(22)00463-4</article-id>
    <article-id pub-id-type="doi">10.1016/j.xpro.2022.101583</article-id>
    <article-id pub-id-type="publisher-id">101583</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Protocol</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Protocol for using Ciclops to build models trained on cross-platform transcriptome data for clinical outcome prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Chou</surname>
          <given-names>Elysia</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Zhang</surname>
          <given-names>Hanrui</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au3">
        <name>
          <surname>Guan</surname>
          <given-names>Yuanfang</given-names>
        </name>
        <email>gyuanfan@umich.edu</email>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="fn1" ref-type="fn">3</xref>
        <xref rid="fn2" ref-type="fn">4</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <aff id="aff1"><label>1</label>Department of Computational Medicine and Bioinformatics, Michigan Medicine, University of Michigan, Ann Arbor, MI 48109, USA</aff>
      <aff id="aff2"><label>2</label>Department of Internal Medicine, Michigan Medicine, University of Michigan, Ann Arbor, MI 48109, USA</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>∗</label>Corresponding author <email>gyuanfan@umich.edu</email></corresp>
      <fn id="fn1">
        <label>3</label>
        <p id="ntpara0010">Technical contact</p>
      </fn>
      <fn id="fn2">
        <label>4</label>
        <p id="ntpara0015">Lead contact</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <day>16</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <volume>3</volume>
    <issue>3</issue>
    <elocation-id>101583</elocation-id>
    <permissions>
      <copyright-statement>© 2022 The Authors</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="abs0010">
      <title>Summary</title>
      <p>Designing robust, generalizable models based on cross-platform data to predict clinical outcomes remains challenging. Building explainable models is important because models may perform differently depending on the conditions of the samples. Here, we describe the use of Ciclops (cross-platform training in clinical outcome predictions), freely available software that can build explainable models to deliver across cross-platform datasets for predicting clinical outcomes. This protocol also utilizes SHAP, a post-training analysis allowing for assessing potential biomarkers of the clinical outcome under study.</p>
      <p>For complete details on the use and execution of this protocol, please refer to <xref rid="bib15" ref-type="bibr">Zhang et al. (2022)</xref>.</p>
    </abstract>
    <abstract abstract-type="graphical" id="abs0015">
      <title>Graphical abstract</title>
      <fig id="undfig1" position="anchor">
        <graphic xlink:href="fx1"/>
      </fig>
    </abstract>
    <abstract abstract-type="author-highlights" id="abs0020">
      <title>Highlights</title>
      <p>
        <list list-type="simple" id="ulist0010">
          <list-item id="u0010">
            <label>•</label>
            <p id="p0010">Build robust clinical outcome prediction models using cross-platform transcriptome data</p>
          </list-item>
          <list-item id="u0015">
            <label>•</label>
            <p id="p0015">Applicable to datasets from different studies measuring different clinical outcomes</p>
          </list-item>
          <list-item id="u0020">
            <label>•</label>
            <p id="p0020">Perform key preprocessing steps of imputation and cross-platform quantile normalization</p>
          </list-item>
          <list-item id="u0025">
            <label>•</label>
            <p id="p0025">Analyze feature importance in LightGBM, XGBoost, and Random Forest models with SHAP</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract abstract-type="editor-highlights" id="abs0025">
      <p>Publisher’s note: Undertaking any experimental protocol requires adherence to local institutional guidelines for laboratory safety and ethics.</p>
    </abstract>
    <abstract abstract-type="teaser" id="abs0030">
      <p>Designing robust, generalizable models based on cross-platform data to predict clinical outcomes remains challenging. Building explainable models is important because models may perform differently depending on the conditions of the samples. Here, we describe the use of Ciclops (cross-platform training in clinical outcome predictions), freely available software that can build explainable models to deliver across cross-platform datasets for predicting clinical outcomes. This protocol also utilizes SHAP, a post-training analysis allowing for assessing potential biomarkers of the clinical outcome under study.</p>
    </abstract>
    <kwd-group id="kwrds0010">
      <title>Subject areas</title>
      <kwd>Bioinformatics</kwd>
      <kwd>Clinical Protocol</kwd>
      <kwd>Genomics</kwd>
      <kwd>Systems biology</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Before you begin</title>
    <p id="p0035">Consistency and reproducibility are key to the generalizability of using transcriptomic data to predict clinical outcomes. Datasets that differ with regards to experimental platforms, measurement targets, geographic sampling sites, and timing of sample collection present practical challenges to building transferable prediction models. Being able to leverage cross-platform datasets when building clinical prediction models would not only allow for widespread applicability of the model, but also increase our confidence in the robustness of the biomarkers that result from feature importance analysis.</p>
    <p id="p0040">Studies analyzing the consistency of various microarray platforms have been conducted for as long as microarrays have been in use (<xref rid="bib3" ref-type="bibr">Guo et al., 2006</xref>; <xref rid="bib1" ref-type="bibr">Fan et al., 2010</xref>), providing us with preprocessing methods to consider before attempting to build cross-platform prediction models. Proper preprocessing, cross-platform normalization, and appropriate selection of machine learning methods can lead to novel scientific discoveries, even when integrating microarray and RNAseq data (<xref rid="bib2" ref-type="bibr">Fauteux et al., 2021</xref>). With the wealth of transcriptome data being produced every year, developing more approaches to integrate various relevant datasets across platforms and across data collection methods carries the potential to uncover new scientific insights.</p>
    <p id="p0045">Here, we present our protocol for using Ciclops (Cross-platform training In Clinical Outcome PredictionS) to build predictive models trained on transcriptome data. These models are then evaluated on external datasets the user provides. Our package is versatile, easy to install, and straightforward to use with a one-line command in the terminal. Our package’s pipeline, which was central to winning the 2019 Malaria DREAM Challenge (<xref rid="bib12" ref-type="bibr">Sage Bionetworks, 2018</xref>), performs imputation and quantile normalization on the datasets before model construction. Additionally, Ciclops allows users to investigate the top features contributing to model performance using SHAP analysis (<xref rid="bib7" ref-type="bibr">Lundberg and Lee 2017</xref>). With SHAP, researchers can build explainable models and assess the significance of certain biomarkers of the clinical outcome under study.</p>
    <sec id="sec1.1">
      <title>Software prerequisites and data requirements</title>
      <p id="p0050">Ciclops can be run on Linux and Mac operating systems with Python 3. Before launching Ciclops, ensure your versions of Python (&gt;=3.8), LightGBM (&gt;=3.3.2) and XGBoost (&gt;=1.6.0) meet the minimum version requirements (see <xref rid="sec10" ref-type="sec">key resources table</xref>). It is also recommended that users have Conda installed.</p>
      <p id="p0055">Users should also prepare the transcriptomic datasets they wish to analyze using Ciclops, as well as the labels for the clinical outcomes they wish to study. While Ciclops can be applied to datasets from different studies measuring different clinical outcomes, here we illustrate how to use Ciclops using two datasets from GEO, which can be downloaded by using the script in <ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/ciclops/tree/main/external_data" id="intref0015">https://github.com/GuanLab/ciclops/tree/main/external_data</ext-link>. Both example datasets were used in our previous analysis (<xref rid="bib15" ref-type="bibr">Zhang et al., 2022</xref>) and contain binary labels for fast or slow clearance rate of the parasite under study. While it is not necessary to download this data, it may be of interest to test whether Ciclops works as expected in your local environment. While this example only uses binary classification, Ciclops can also be used for multiclass classification or regression analysis.</p>
    </sec>
    <sec id="sec1.2">
      <title>Create a virtual environment for your project (recommended)</title>
      <p id="p0060">
        <disp-quote>
          <p>
            <inline-graphic xlink:href="fx2.gif"/>
            <bold>Timing: 5 min</bold>
          </p>
        </disp-quote>
      </p>
      <p id="p0065">While this step is optional, it is recommended that users create a virtual environment to install and run Ciclops to ensure following the protocol goes smoothly.<list list-type="simple" id="olist0010"><list-item id="o0010"><label>1.</label><p id="p0070">Create a new environment and specify a version of Python that Ciclops is compatible with:</p></list-item></list><boxed-text id="dtbox1"><p id="p0075">conda create--name [ENV_NAME] python=3.8</p></boxed-text></p>
      <p id="p0080">where you can enter the name of your environment in the place of the square brackets. You can also install Ciclops’ dependencies in this step, such as <italic>numpy</italic> and <italic>scikitlearn</italic> (see <xref rid="sec10" ref-type="sec">key resources table</xref>).<list list-type="simple" id="olist0015"><list-item id="o0015"><label>2.</label><p id="p0085">When you are ready to use this protocol, activate the environment:</p></list-item></list><boxed-text id="dtbox2"><p id="p0090">conda activate [ENV_NAME]</p></boxed-text></p>
      <p id="p0095">and use the command:<boxed-text id="dtbox3"><p id="p0100">conda deactivate</p></boxed-text></p>
      <p id="p0105">when you wish to deactivate this environment.</p>
    </sec>
  </sec>
  <sec id="sec10">
    <title>Key resources table</title>
    <p id="p0575">
      <table-wrap position="float" id="undtbl1">
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th>REAGENT or RESOURCE</th>
              <th>SOURCE</th>
              <th>IDENTIFIER</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="3">
                <bold>Software and algorithms</bold>
              </td>
            </tr>
            <tr>
              <td colspan="3">
                <hr/>
              </td>
            </tr>
            <tr>
              <td>Python (&gt;=3.8)</td>
              <td>Python Software Foundation</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://www.python.org/downloads/release/python-3812/" id="intref0030">https://www.python.org/downloads/release/python-3812/</ext-link>
              </td>
            </tr>
            <tr>
              <td>numpy (&gt;=1.21.5)</td>
              <td>
                <xref rid="bib4" ref-type="bibr">Harris et al. (2020)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/numpy/" id="intref0035">https://pypi.org/project/numpy/</ext-link>
              </td>
            </tr>
            <tr>
              <td>pandas (&gt;=1.4.1)</td>
              <td>
                <xref rid="bib8" ref-type="bibr">McKinney (2010)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://pandas.pydata.org/" id="intref0040">https://pandas.pydata.org/</ext-link>
              </td>
            </tr>
            <tr>
              <td>scikit-learn (&gt;=1.0.2)</td>
              <td>
                <xref rid="bib11" ref-type="bibr">Pedregosa et al. (2011)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/" id="intref0045">https://scikit-learn.org/stable/</ext-link>
              </td>
            </tr>
            <tr>
              <td>scipy (&gt;=1.8.0)</td>
              <td>
                <xref rid="bib14" ref-type="bibr">Virtanen et al. (2020)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://scipy.org/" id="intref0050">https://scipy.org/</ext-link>
              </td>
            </tr>
            <tr>
              <td>matplotlib (&gt;=3.5.1)</td>
              <td>
                <xref rid="bib5" ref-type="bibr">Hunter (2007)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://matplotlib.org/" id="intref0055">https://matplotlib.org/</ext-link>
              </td>
            </tr>
            <tr>
              <td>matplotlib-venn (&gt;=0.11.7)</td>
              <td>Konstantin Tretyakov</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/matplotlib-venn/" id="intref0060">https://pypi.org/project/matplotlib-venn/</ext-link>
              </td>
            </tr>
            <tr>
              <td>lightgbm (&gt;=3.3.2)</td>
              <td>Microsoft Corporation</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://lightgbm.readthedocs.io/en/latest/" id="intref0065">https://lightgbm.readthedocs.io/en/latest/</ext-link>
              </td>
            </tr>
            <tr>
              <td>shap (&gt;=0.40.0)</td>
              <td>
                <xref rid="bib7" ref-type="bibr">Lundberg and Lee (2017)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://shap.readthedocs.io/en/latest/index.html" id="intref0070">https://shap.readthedocs.io/en/latest/index.html</ext-link>
              </td>
            </tr>
            <tr>
              <td>xgboost (&gt;=1.6.0)</td>
              <td>
                <xref rid="bib16" ref-type="bibr">Chen and Guestrin (2016)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://xgboost.readthedocs.io/en/stable/" id="intref0075">https://xgboost.readthedocs.io/en/stable/</ext-link>
              </td>
            </tr>
            <tr>
              <td>GEOparse (&gt;= 2.0.3)</td>
              <td>Rafal Gumienny</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://geoparse.readthedocs.io/en/latest/index.html" id="intref0080">https://geoparse.readthedocs.io/en/latest/index.html</ext-link>
              </td>
            </tr>
            <tr>
              <td>tqdm (&gt;=4.63.0)</td>
              <td>
                <xref rid="bib17" ref-type="bibr">da Costa-Luis (2022)</xref>
              </td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://github.com/tqdm/tqdm" id="intref0085">https://github.com/tqdm/tqdm</ext-link>
              </td>
            </tr>
            <tr>
              <td>Ciclops</td>
              <td>This paper</td>
              <td><ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/ciclops/" id="intref0090">https://pypi.org/project/ciclops/</ext-link> or <ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/ciclops" id="intref0095">https://github.com/GuanLab/ciclops</ext-link> (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6686200" id="intref0100">https://doi.org/10.5281/zenodo.6686200</ext-link>)</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </p>
  </sec>
  <sec id="sec2">
    <title>Materials and equipment</title>
    <p id="p0110">A minimum of 16 GB local memory is recommended (see <xref rid="tbl1" ref-type="table">Table 1</xref> for computational resources used in this study). However, for larger datasets, you may want to run Ciclops on a computing cluster with multiple cores and larger RAM to shorten the run time. Since Ciclops was developed on an Ubuntu Linux system with Python 3 (&gt;=3.8), it is recommended to run Ciclops on a Linux machine (Linux, Mac OS, or Windows Subsystem for Linux).<table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>Computational resources used in this study</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Operating system</th><th>Version</th></tr></thead><tbody><tr><td>Ubuntu</td><td>20.04.3 LTS (Focal Fossa)</td></tr><tr><td colspan="2"><hr/></td></tr><tr><td><bold>CPU Information</bold></td><td><bold>Value</bold></td></tr><tr><td colspan="2"><hr/></td></tr><tr><td>RAM</td><td>16 GB</td></tr><tr><td>Cores</td><td>6</td></tr><tr><td>Processor speed</td><td>1.1 GHz</td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="sec3">
    <title>Step-by-step method details</title>
    <sec id="sec3.1">
      <title>Download Ciclops and install prerequisites</title>
      <p id="p0115">
        <disp-quote>
          <p>
            <inline-graphic xlink:href="fx2.gif"/>
            <bold>Timing: 5 min</bold>
          </p>
        </disp-quote>
      </p>
      <p id="p0120">Obtain the latest version of Ciclops, which can be found on PyPI or our GitHub (<xref rid="fig1" ref-type="fig">Figure 1</xref>).<list list-type="simple" id="olist0020"><list-item id="o0020"><label>1.</label><p id="p0125">Install Ciclops via pip:</p></list-item></list><boxed-text id="dtbox4"><p id="p0130">pip install ciclops</p></boxed-text><fig id="fig1"><label>Figure 1</label><caption><p>Model installation using pip or git and the main dependencies</p></caption><graphic xlink:href="gr1"/></fig></p>
      <p id="p0135">or use the following command to clone the protocol directory from our GitHub repository to your local directory:<boxed-text id="dtbox5"><p id="p0140">git clone<ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/ciclops.git" id="intref0020">https://github.com/GuanLab/ciclops.git</ext-link></p></boxed-text><disp-quote><p><inline-graphic xlink:href="fx3.gif"/><bold>CRITICAL:</bold> Refer to the <xref rid="sec10" ref-type="sec">key resources table</xref> to ensure your local environment is compatible with all the package’s dependencies, in case installation errors occur (<xref rid="sec7" ref-type="sec">troubleshooting 1</xref>).</p></disp-quote><disp-quote><p><bold><italic>Optional:</italic></bold> Once installed, you can run the following command to see if Ciclops was installed properly:</p></disp-quote><boxed-text id="dtbox6"><p id="p0145">ciclops--help</p></boxed-text></p>
      <p id="p0150">If any errors or warnings occur due to clashing package versions, see <xref rid="sec7" ref-type="sec">troubleshooting 2</xref>.</p>
      <p id="p0155">Additionally, if you are cloning the GitHub repository, you can download the example data from GEO using the Python script in the external_data/ directory:<boxed-text id="dtbox7"><p id="p0160">python3 getGEO.py</p></boxed-text></p>
      <p id="p0165">This script obtains two transcriptomic datasets: 1) <italic>in vitro</italic> data of P. falciparum (GEO: GSE151189) (<xref rid="bib10" ref-type="bibr">Mok et al., 2021</xref>), used as the training set in our example; and 2) <italic>ex vivo</italic> data of P. falciparum from a different study (GEO: GSE59098) (<xref rid="bib9" ref-type="bibr">Mok et al., 2015</xref>), used as the test set in our example. In this protocol, these data are used only for illustrative purposes.</p>
    </sec>
    <sec id="sec3.2">
      <title>Prepare data</title>
      <p id="p0170">
        <disp-quote>
          <p>
            <inline-graphic xlink:href="fx2.gif"/>
            <bold>Timing: 10 min</bold>
          </p>
        </disp-quote>
      </p>
      <p id="p0175">In this step, format the data so that it will be suitable for use with Ciclops (<xref rid="tbl2" ref-type="table">Table 2</xref>). The data should be in csv format.<list list-type="simple" id="olist0025"><list-item id="o0025"><label>2.</label><p id="p0180">Select datasets and preprocess the data.<list list-type="simple" id="olist0030"><list-item id="o0030"><label>a.</label><p id="p0185">Select at least two transcriptomic datasets that you wish to build a predictive model with: one training set and at least one test/validation set.</p></list-item><list-item id="o0035"><label>b.</label><p id="p0190">Ensure the labels are somewhat consistent between the training and test set based on the biological context of the problem you are trying to solve.</p></list-item></list></p></list-item></list><disp-quote><p><bold><italic>Note:</italic></bold> As an example, in our original study, the training set’s labels were fast or slow clearance rate of the parasite after introduction of the drug in question and the test set’s labels were the drug’s IC50. Since lower IC50 should correspond to faster clearance rate, ‘fast’ was labeled as 0, and ‘slow’ was labeled as 1.</p></disp-quote><list list-type="simple" id="olist0035"><list-item id="o0040"><label>3.</label><p id="p0195">Format both datasets such that the features and labels are arranged correctly (<xref rid="tbl2" ref-type="table">Table 2</xref>).<list list-type="simple" id="olist0040"><list-item id="o0045"><label>a.</label><p id="p0200">Ensure the columns are gene expression levels for each gene and that the rows are samples.</p></list-item><list-item id="o0050"><label>b.</label><p id="p0205">Put the sample names or numbers in the first column.<list list-type="simple" id="olist0045"><list-item id="o0055"><label>i.</label><p id="p0210">If the datasets being used do not contain sample numbers, put a column of numbers in the first column as a placeholder.</p></list-item></list></p></list-item><list-item id="o0060"><label>c.</label><p id="p0215">Put the labels in the last column.</p></list-item></list></p></list-item></list><disp-quote><p><inline-graphic xlink:href="fx3.gif"/><bold>CRITICAL:</bold> 1.) All datasets used with Ciclops should follow the format above, as Ciclops assumes the first and last column are sample numbers and labels respectively. 2.) While these datasets can be collected from different platforms and/or use different clinical outcome metrics (e.g., the training set and test set are transcriptome profiles measured using different platforms; or the labels are different metrics for measuring a similar clinical outcome), they must share a set of common genes in order to build a model (<xref rid="sec7" ref-type="sec">troubleshooting 3</xref>).</p></disp-quote><disp-quote><p><bold><italic>Optional:</italic></bold> 1.) If the datasets you have selected still contain raw data, preprocess both training and test data, following standard protocol according to their respective platforms. For transcriptomic datasets, this often involves feature extraction, QC, and some form of normalization, among other preprocessing steps. For example, while we use the processed data from GEO as our example files, we could have also elected to use the raw data the authors provided instead. In that case, we would have preprocessed the datasets individually as described in the methods of our original study (<xref rid="bib15" ref-type="bibr">Zhang et al., 2022</xref>). Subsequently, Ciclops will perform imputation and cross-platform quantile normalization to normalize the training and test data with respect to each other. 2.) In the case of missing values in the datasets, it is recommended that researchers enter ‘NaN’ in those positions rather than leaving them blank. 3.) At this stage, imputing missing values is not necessary, as Ciclops performs gene-wise imputation before training the models, i.e., a sample’s missing value is replaced with the relevant gene’s average expression level. Users can perform different imputation methods in this step if they so wish.</p></disp-quote><table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Example data format for both training and test sets</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Sample</th><th>Gene 1</th><th>Gene 2</th><th>…</th><th>Gene p</th><th>Label</th></tr></thead><tbody><tr><td>1</td><td>0.15</td><td>0.39</td><td>…</td><td>-2.05</td><td>0</td></tr><tr><td>2</td><td>0.01</td><td>-0.47</td><td>…</td><td>-1.14</td><td>1</td></tr><tr><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td></tr><tr><td>N</td><td>0.53</td><td>-1.12</td><td>…</td><td>0.29</td><td>0</td></tr></tbody></table><table-wrap-foot><fn><p>Note that the label can be categorical or continuous.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec3.3">
      <title>Train models, evaluate results, and visualize top contributing features</title>
      <p id="p0220">
        <disp-quote>
          <p>
            <inline-graphic xlink:href="fx2.gif"/>
            <bold>Timing: ∼ 0.5 h (depending on data size and model)</bold>
          </p>
        </disp-quote>
      </p>
      <p id="p0225">With a one-line command, Ciclops allows the user to preprocess the data (imputation and quantile normalization), perform ten-fold cross-validation on the training set, and perform the transfer learning on the test set (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Additionally, if specified, Ciclops will carry out SHAP analysis with a visualization report of top contributing features for both training and test sets.<list list-type="simple" id="olist0050"><list-item id="o0065"><label>4.</label><p id="p0230">Run Ciclops using the following command:<boxed-text id="dtbox8"><p id="p0235">ciclops--train_path [TRAIN_PATH]--valid_path [VALID_PATH] -m [MODEL_TYPE]--no_quantile--shap -n [TOP_GENES]</p></boxed-text></p><p id="p0240">The arguments are defined as follows:<list list-type="simple" id="olist0055"><list-item id="o0070"><label>a.</label><p id="p0245">--train_path [TRAIN_PATH]: the path to the csv file containing the training data prepared in the previous steps. For example, if using the example data, enter the path to the file in_vitro_GSE151189.csv.</p></list-item><list-item id="o0075"><label>b.</label><p id="p0250">--valid_path [VALID_PATH]: the path to the csv file containing the transfer validation or test data prepared in the previous steps. For example, if using the example data, enter the path to the file ex_vivo_GSE59098.csv.</p></list-item><list-item id="o0080"><label>c.</label><p id="p0255">-m [MODEL_TYPE]: the machine learning model to use. The default is LightGBM; however, the user can specify that one of the following models be used instead, using the specified argument:<list list-type="simple" id="olist0060"><list-item id="o0085"><label>i.</label><p id="p0260">lgb: LightGBM.</p></list-item><list-item id="o0090"><label>ii.</label><p id="p0265">xgb: XGBoost.</p></list-item><list-item id="o0095"><label>iii.</label><p id="p0270">rf: Random Forest.</p></list-item><list-item id="o0100"><label>iv.</label><p id="p0275">gpr: Gaussian Process Regression.</p></list-item><list-item id="o0105"><label>v.</label><p id="p0280">lr: Linear Regression.</p></list-item></list></p></list-item><list-item id="o0110"><label>d.</label><p id="p0285">--no_quantile: if this argument is used, Ciclops will not perform quantile normalization on the training and test data. The user should exclude this argument if they wish to perform quantile normalization on the data.</p></list-item><list-item id="o0115"><label>e.</label><p id="p0290">--shap: if this argument is specified, Ciclops will perform SHAP analysis on the training and test data.</p></list-item><list-item id="o0120"><label>f.</label><p id="p0295">-n [TOP_GENES]: if using the --shap argument, users can set the number of top-contributing genes to compare between the training and test set with the -n flag. The default is 20.<disp-quote><p><bold><italic>Note:</italic></bold> 1.) When deliberating what model type to use, LightGBM would generally be a good place to start since it performs well in our experience and is very efficient for training large datasets such as transcriptomic data that Ciclops is intended for (<xref rid="bib6" ref-type="bibr">Ke et al., 2017</xref>). While XGBoost is not as fast in that regard (<xref rid="bib6" ref-type="bibr">Ke et al., 2017</xref>), comparing your LightGBM model to models trained by XGBoost and Random Forest can give you insight into the performance of tree-based learners versus kernel-based algorithms such as GPR and linear regression, which have more straightforward interpretability. 2.) If testing Ciclops with the example data, which is relatively small, running the command in step 4 should take no more than five minutes. Since we anticipate Ciclops being used for much larger datasets, as was done in our original study, the timing estimate given above is based on our original study. As mentioned in the <xref rid="sec2" ref-type="sec">materials and equipment</xref> section, running Ciclops on a computing cluster with multiple cores and larger RAM will shorten the runtime. 3.) Unless both datasets have been jointly normalized during your preprocessing step, it is recommended to exclude the --no_quantile argument, as quantile normalization played a key role in building a successful prediction model in our original publication. 4.) In Ciclops, SHAP can only be used with tree-based models (i.e., LightGBM, Random Forest, XGBoost) as that is mainly what SHAP is designed for. It is infeasible to perform SHAP analysis on regression models with the thousands of features that transcriptome data usually comes with. 5.) At the time of writing, the <italic>shap</italic> package utilizes the <italic>IPython.core.display</italic> module for creating interactive plots. Since storing SHAP values and generating SHAP summary plots was sufficient in our original study, Ciclops only makes use of the non-interactive plot functions of the <italic>shap</italic> package. Therefore, if applicable, users can ignore the warning, "IPython could not be loaded!" and do not need to have IPython installed.</p></disp-quote><disp-quote><p><inline-graphic xlink:href="fx3.gif"/><bold>CRITICAL:</bold> 1.) In order for Ciclops to run, ensure the paths to both training and test data files are correct. 2.) Unless you intend on using a tree-based model (e.g., LightGBM, Random Forest, XGBoost), exclude or minimize the number of features that are categorical, as most models implemented in Ciclops were designed to operate on ordinal, numeric values. If you wish to include categorical features, encode them as ordinal, numeric values before training. 3.) While the parameters of the five models implemented in Ciclops worked for our original study and allowed us to win the 2019 Dream Malaria challenge (<xref rid="tbl3" ref-type="table">Table 3</xref>), we encourage users to tune the hyperparameters in order to obtain the best model fit for their datasets (see <xref rid="sec7" ref-type="sec">troubleshooting 4</xref>). 4.) While both example datasets use binary labels, Ciclops can also build models where the labels of one or both datasets are continuous values. Use evaluation metrics that are suitable to assess the outcomes you are trying to predict with your model (see <xref rid="sec5" ref-type="sec">quantification and statistical analysis</xref>).</p></disp-quote></p><p id="p0300"><table-wrap position="anchor" id="tbl3"><label>Table 3</label><caption><p>Parameters used in the different machine learning models</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Parameter</th><th>Value</th><th>Description</th></tr></thead><tbody><tr><td colspan="3"><bold>LightGBM</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td>boosting_type</td><td>‘gbdt’</td><td>The gradient boosting method to use.</td></tr><tr><td>objective</td><td>‘regression’</td><td>The learning task (regression, binary classification, etc.).</td></tr><tr><td>num_leaves</td><td>5</td><td>The maximum number of leaves in a tree.</td></tr><tr><td>learning_rate</td><td>0.05</td><td>The learning rate for the gradient boosting model.</td></tr><tr><td>Verbose</td><td>0</td><td>The level of verbosity, mainly for debugging.</td></tr><tr><td>n_estimators</td><td>800</td><td>The number of boosted trees to build in order to improve the fit.</td></tr><tr><td>reg_alpha</td><td>2.0</td><td>The L1 regularization term for combatting overfitting.</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td colspan="3"><bold>XGBoost</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td>N/A</td><td>Default</td><td>N/A</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td colspan="3"><bold>Random Forest</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td>max_depth</td><td>2</td><td>The maximum tree depth.</td></tr><tr><td>n_estimators</td><td>100</td><td>The number of trees to use in the model.</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td colspan="3"><bold>Gaussian Process Regression (GPR)</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td>Kernel</td><td>DotProduct() + WhiteKernel()</td><td>Defines a Gaussian process by describing the covariance of the Gaussian process random variables. To explore the kernels that can be used with GPR, please refer to the <italic>scikit-learn</italic> documentation.</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td colspan="3"><bold>Linear Regression</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td>N/A</td><td>Default</td><td>N/A</td></tr></tbody></table></table-wrap></p></list-item></list></p></list-item></list><fig id="fig2"><label>Figure 2</label><caption><p>Workflow</p><p>Using a one-line command, Ciclops first preprocesses both training and testing datasets by performing gene-wise imputation and quantile normalization. The program then trains the specified machine learning model using ten-fold cross-validation. Finally, it evaluates these models on the provided test set. This workflow does not include SHAP analysis.</p></caption><graphic xlink:href="gr2"/></fig></p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>Expected outcomes</title>
    <p id="p0305">After running Ciclops using the command in step 4, the results can be found in the following newly-created subdirectories.</p>
    <p id="p0310">The first directory listed will be the training directory. This directory contains the train and test splits for each fold of the ten-fold cross-validation performed on the training dataset. As for the predicted labels for each sample in the test dataset, they are in the directory called validation. Next, the models generated from the ten-fold cross-validation are saved in the params directory. These saved models, named fold_∗_model.sav, can be reloaded using <italic>pickle</italic>, a standard module in Python. The fourth directory, called performance, contains the models’ evaluation results from each cross-validation fold for both training and test sets, as well as the results with a 95% confidence interval obtained by bootstrapping.</p>
    <p id="p0315">Finally, if the --shap argument is specified, the results from the SHAP analysis will be stored in the SHAP directory. In this directory, the training and validation subdirectories contain figures with the top contributing genes and their SHAP values (SHAP_importance_∗.pdf) (<xref rid="fig3" ref-type="fig">Figure 3</xref>A) as well as csv files containing all genes and their SHAP values, for each cross-validation fold. The figure named intersection_venn_top_∗_genes.pdf displays a Venn diagram of the top contributing genes in the training and test/validation datasets, and shows how many of these genes overlap (<xref rid="fig3" ref-type="fig">Figure 3</xref>B). The last file you will find will be named intersection_list_top_∗_genes.txt. It lists the top contributing genes that overlap between the SHAP analysis done on the training set and the SHAP analysis done on the test/validation set.<fig id="fig3"><label>Figure 3</label><caption><p>Results from SHAP analysis after running Ciclops on the example data</p><p>(A) Beeswarm plot of the top 20 genes contributing to the model, with their respective SHAP values.</p><p>(B) Venn diagram of the top 20 genes resulting from the SHAP analysis on both the training set and test/validation set, showing how many overlap.</p></caption><graphic xlink:href="gr3"/></fig></p>
    <p id="p0320">When reviewing these results, verify that the performance results make sense; for example, the correlation coefficients are not NaN or the AUROC is higher than 0.5 (<xref rid="sec7" ref-type="sec">troubleshooting 5</xref>).</p>
  </sec>
  <sec id="sec5">
    <title>Quantification and statistical analysis</title>
    <p id="p0325">Ciclops reports four metrics to evaluate model performance: AUROC, AUPRC, Pearson’s r, and Spearman’s ρ. They each have their own applications. For binary classification problems, you can look at the following:<list list-type="simple" id="ulist0015"><list-item id="u0030"><label>•</label><p id="p0330"><bold>AUROC</bold> (Area Under the Receiver Operating Characteristic curve): The AUROC is a measure of the model’s ability to differentiate between classes, generally ranging in value from 0.5 (random classifier) to 1.0 (perfect classifier). In statistics terms, AUROC is the area under the ROC curve, which plots the true positive rate (TPR) against the false positive rate (FPR) across different decision thresholds:</p></list-item></list><boxed-text id="dtbox9"><p id="p0335"><disp-formula id="ufd1"><mml:math id="M1" altimg="si1.gif"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mtext> </mml:mtext><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext> </mml:mtext><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mtext>;</mml:mtext></mml:mrow></mml:math></disp-formula><disp-formula id="ufd2"><mml:math id="M2" altimg="si2.gif"><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="p0340">TP: True Positive; TN: True Negative; FP: False Positive; FN: False Negative.</p></boxed-text></p>
    <p id="p0345">In Ciclops, the AUROC is computed using the <italic>sklearn.metrics</italic> module in Python.<list list-type="simple" id="ulist0020"><list-item id="u0035"><label>•</label><p id="p0350"><bold>AUPRC</bold> (Area Under the Precision-Recall Curve): The AUPRC is generally used when dealing with highly imbalanced datasets. The baseline AUPRC is given by the proportion of true positive samples in the dataset and an AUPRC closer to 1.0 (correlating with high precision and high recall) is preferred. The AUPRC measures the area under the PR curve, which plots the precision against the recall (equivalent to TPR) across different decision thresholds:</p></list-item></list><boxed-text id="dtbox10"><p id="p0355"><disp-formula id="ufd3"><mml:math id="M3" altimg="si3.gif"><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mtext> </mml:mtext><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mtext> </mml:mtext><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext> </mml:mtext><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="ufd4"><mml:math id="M4" altimg="si4.gif"><mml:mrow><mml:mi mathvariant="italic">Recall</mml:mi><mml:mtext> </mml:mtext><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mtext> </mml:mtext><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext> </mml:mtext><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p></boxed-text></p>
    <p id="p0595">In Ciclops, the AUPRC is computed using the <italic>sklearn.metrics</italic> module in Python.</p>
    <p id="p0365">For regression problems, you can use the following of the reported metrics:<list list-type="simple" id="ulist0025"><list-item id="u0040"><label>•</label><p id="p0370"><bold>Pearson’s r</bold> (Pearson correlation coefficient): the Pearson correlation coefficient measures the linear correlation between the predicted values and the actual values. The correlation coefficient is the ratio between the covariance and the product of the respective standard deviations:</p></list-item></list><boxed-text id="dtbox11"><p id="p0375"><disp-formula id="ufd5"><mml:math id="M5" altimg="si5.gif"><mml:mrow><mml:mi>r</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:msqrt><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>;</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="p0380"><italic>x</italic><sub><italic>i</italic></sub>: predicted value of sample i;</p><p id="p0385"><inline-formula><mml:math id="M6" altimg="si6.gif"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>: mean of the prediction values;</p><p id="p0390"><italic>y</italic><sub><italic>i</italic></sub>: actual value of sample i;</p><p id="p0395"><inline-formula><mml:math id="M7" altimg="si7.gif"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>: mean of the actual values.</p></boxed-text></p>
    <p id="p0400">The Pearson correlation coefficient varies in range from -1 to 1. Both extremes indicate a strong linear correlation, while 0 indicates no correlation. In Ciclops, Pearson’s r is computed using the <italic>scipy.stats</italic> module in Python.<list list-type="simple" id="ulist0030"><list-item id="u0045"><label>•</label><p id="p0405"><bold>Spearman’s ρ</bold> (Spearman rank-order correlation coefficient): The Spearman rank-order correlation coefficient is a nonparametric assessment of how well the predicted values and actual values can be described using a monotonic function:</p></list-item></list><boxed-text id="dtbox12"><p id="p0410"><disp-formula id="ufd6"><mml:math id="M8" altimg="si8.gif"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mtext>1</mml:mtext><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>6</mml:mn><mml:mo>∑</mml:mo><mml:msubsup><mml:mtext>d</mml:mtext><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>;</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="p0415"><italic>d</italic><sub><italic>i</italic></sub>: the difference between the ranks of predicted value i and actual value i;</p><p id="p0420"><italic>n</italic>: number of observations.</p></boxed-text></p>
    <p id="p0425">Like Pearson’s r, Spearman’s ρ varies between -1 to 1. Both extremes indicate a perfect monotonic relationship, while 0 implies no correlation. In Ciclops, Spearman’s ρ is calculated using the <italic>scipy.stats</italic> module in Python.</p>
    <p id="p0430">Users can also implement customized evaluation metrics relevant to their research questions using the results from running Ciclops.</p>
  </sec>
  <sec id="sec6">
    <title>Limitations</title>
    <p id="p0435">When using Ciclops for cross-platform model building, the model performance will vary based on the training dataset, the test dataset, and the machine learning method being applied. Users may even see model performance vary across different test sets generated in the same study, but under different conditions. These disparities in model performance may be due to the nature of the data collection methods, environmental factors drastically impacting gene expression and/or clinical outcomes, or large biological variability which the model fails to explain. Therefore, users must be critical and careful in their research design before considering the strategy implemented in Ciclops.</p>
    <p id="p0440">Another limitation is that because SHAP analysis works best and fastest with tree-based models, it is not implemented for use with the regression models that can be used in Ciclops (namely, Gaussian Process Regression and Linear Regression). Since transcriptomic data typically contain thousands of genes’ expression levels, it would be too computationally expensive to use SHAP with these regression models. Users are recommended to explore alternative methods of feature importance analysis for these models if they deem it necessary.</p>
    <p id="p0445">Finally, users are also limited in their choice of machine learning algorithms. While the algorithms implemented in Ciclops have been popular in recent years for their top performance, users may wish to implement a different machine learning algorithm of their choice. In this case, users can modify the source code to fit their needs.</p>
  </sec>
  <sec id="sec7">
    <title>Troubleshooting</title>
    <sec id="sec7.1">
      <title>Problem 1</title>
      <p id="p0450">Ciclops failed to install due to uninstalled dependencies (step 1).</p>
    </sec>
    <sec id="sec7.2">
      <title>Potential solution</title>
      <p id="p0455">Refer to the <xref rid="sec10" ref-type="sec">key resources table</xref> to manually install the packages, paying attention to the minimum version requirement.</p>
    </sec>
    <sec id="sec7.3">
      <title>Problem 2</title>
      <p id="p0460">Ciclops fails to run due to clashing dependencies or deprecation warnings (step 1).</p>
    </sec>
    <sec id="sec7.4">
      <title>Potential solution</title>
      <p id="p0465">Some of Ciclops’ dependencies have dependencies of their own, which may have differing version requirements.<list list-type="simple" id="ulist0035"><list-item id="u0050"><label>•</label><p id="p0470">If you get a deprecation warning on the command line after calling Ciclops, consult the <xref rid="sec10" ref-type="sec">key resources table</xref> to upgrade all of Ciclops’ dependencies to their most recent version, despite the minimum version requirement being lower.</p></list-item><list-item id="u0055"><label>•</label><p id="p0475">If you get an error because other packages in your local environment have version requirements of certain dependencies that clash with that of Ciclops, consult the documentation of the packages with clashing dependencies. If you can reinstall a version of the clashing dependency that satisfies both Ciclops and the other package’s version requirements, do so using the command:</p></list-item></list><boxed-text id="dtbox13"><p id="p0480">pip install [dependency]==[version]</p></boxed-text></p>
      <p id="p0485">If there is no version overlap between Ciclops and the other package, consider creating a new virtual environment for your project by using <italic>conda</italic> or <italic>virtualenv</italic> for Python 3 and installing all of Ciclops’ dependencies listed in the <xref rid="sec10" ref-type="sec">key resources table</xref> in this virtual environment before installing Ciclops.</p>
    </sec>
    <sec id="sec7.5">
      <title>Problem 3</title>
      <p id="p0490">Ciclops does not produce the expected results because the program cannot find common genes between the training and test set (step 2a, <xref rid="sec4" ref-type="sec">expected outcomes</xref>). You may have noticed this because the csv files containing the train/test splits in the ./training directory only have two columns: sample names and labels, missing any gene expression columns; or your output after running Ciclops resembles that of <xref rid="fig4" ref-type="fig">Figure 4</xref>.<fig id="fig4"><label>Figure 4</label><caption><p>Troubleshooting example</p><p>Some of the output of Ciclops if the datasets provided to the program do not share any genes.</p></caption><graphic xlink:href="gr4"/></fig></p>
    </sec>
    <sec id="sec7.6">
      <title>Potential solution</title>
      <p id="p0495">
        <list list-type="simple" id="ulist0040">
          <list-item id="u0060">
            <label>•</label>
            <p id="p0500">If your datasets have genes in common, but have different naming schemes, ensure the gene names are consistent between the training and test sets before running Ciclops.</p>
          </list-item>
          <list-item id="u0065">
            <label>•</label>
            <p id="p0505">If your datasets do not have genes in common, select different datasets that have genes in common in order to build a predictive model.</p>
          </list-item>
        </list>
      </p>
    </sec>
    <sec id="sec7.7">
      <title>Problem 4</title>
      <p id="p0510">Users wish to use different hyperparameters for the machine learning models implemented in Ciclops.</p>
    </sec>
    <sec id="sec7.8">
      <title>Potential solution</title>
      <p id="p0515">We encourage users to tune the hyperparameters of the models they wish to use if they are trying to improve model performance. The hyperparameter settings in Ciclops are listed in <xref rid="tbl3" ref-type="table">Table 3</xref>, and can be modified by editing the model.py script in the source code. For more detailed information on parameter options and ranges, please refer to the documentation of the machine learning model you wish to tune.<list list-type="simple" id="ulist0045"><list-item id="u0070"><label>•</label><p id="p0520">As an example, if you are trying to tune the hyperparameters of a LightGBM model, you may experiment with smaller values for ‘num_leaves’ and ‘n_estimators’ if your model is overfitting. Alternatively, you may wish to speed up the training process by increasing the ‘learning_rate’ hyperparameter, or try to achieve higher prediction accuracy by lowering the learning rate.</p></list-item><list-item id="u0075"><label>•</label><p id="p0525">Note that the optimal hyperparameters for your model may depend on the characteristics of the datasets you are using; for example, the number of features or samples in your datasets.</p></list-item></list></p>
    </sec>
    <sec id="sec7.9">
      <title>Problem 5</title>
      <p id="p0530">Ciclops does not produce the expected results (<xref rid="sec4" ref-type="sec">expected outcomes</xref>). Your results may resemble the output presented in <xref rid="fig4" ref-type="fig">Figure 4</xref>, or your results seem too extreme in the statistical sense (for example, confidence intervals spanning [0, 1] for AUPRC, or NaN values for any of the evaluation metrics).</p>
    </sec>
    <sec id="sec7.10">
      <title>Potential solution</title>
      <p id="p0535">
        <list list-type="simple" id="ulist0050">
          <list-item id="u0080">
            <label>•</label>
            <p id="p0540">Consult the potential solution to <xref rid="sec7.5" ref-type="sec">problem 3</xref> if you used datasets that did not have any genes in common.</p>
          </list-item>
          <list-item id="u0085">
            <label>•</label>
            <p id="p0545">If your results don’t make sense, examine the datasets to make sure they are not empty.</p>
          </list-item>
          <list-item id="u0090">
            <label>•</label>
            <p id="p0550">Examine your datasets for any outliers, and do some sanity checks on all your features and labels.</p>
          </list-item>
          <list-item id="u0095">
            <label>•</label>
            <p id="p0555">Tune the hyperparameters to obtain a better fit (see <xref rid="sec7.7" ref-type="sec">problem 4</xref>) and try different models that can be used with Ciclops.</p>
          </list-item>
        </list>
      </p>
    </sec>
  </sec>
  <sec id="sec8">
    <title>Resource availability</title>
    <sec id="sec8.1">
      <title>Lead contact</title>
      <p id="p0560">Further information and requests for resources and reagents should be directed to and will be fulfilled by the lead contact, Yuanfang Guan (<ext-link ext-link-type="uri" xlink:href="mailto:gyuanfan@umich.edu" id="intref0025">gyuanfan@umich.edu</ext-link>).</p>
    </sec>
    <sec id="sec8.2">
      <title>Materials availability</title>
      <p id="p0565">This study did not generate any new unique reagents.</p>
    </sec>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib16">
      <element-citation publication-type="journal" id="sref16">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Guestrin</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>XGBoost: A Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.San Francisco, California, USA:</article-title>
        <source>Association for Computing Machinery</source>
        <year>2016</year>
      </element-citation>
    </ref>
    <ref id="bib17">
      <element-citation publication-type="journal" id="optgPPFLkhfrz">
        <person-group person-group-type="author">
          <name>
            <surname>da Costa-Luis</surname>
            <given-names>C.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>tqdm: A fast, extensible progress bar for Python and CLI</article-title>
        <source>Zenodo</source>
        <year>2022</year>
        <pub-id pub-id-type="doi">10.5281/zenodo.4531988</pub-id>
      </element-citation>
    </ref>
    <ref id="bib1">
      <element-citation publication-type="journal" id="sref1">
        <person-group person-group-type="author">
          <name>
            <surname>Fan</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Lobenhofer</surname>
            <given-names>E.K.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Walker</surname>
            <given-names>S.J.</given-names>
          </name>
          <name>
            <surname>Chu</surname>
            <given-names>T.M.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Consistency of predictive signature genes and classifiers generated using different microarray platforms</article-title>
        <source>Pharmacogenomics J.</source>
        <volume>10</volume>
        <year>2010</year>
        <fpage>247</fpage>
        <lpage>257</lpage>
        <pub-id pub-id-type="pmid">20676064</pub-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Fauteux</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Surendra</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>McComb</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>J.J.</given-names>
          </name>
        </person-group>
        <article-title>Identification of transcriptional subtypes in lung adenocarcinoma and squamous cell carcinoma through integrative analysis of microarray and RNA sequencing data</article-title>
        <source>Sci. Rep.</source>
        <volume>11</volume>
        <year>2021</year>
        <fpage>8709</fpage>
        <pub-id pub-id-type="pmid">33888829</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <element-citation publication-type="journal" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Lobenhofer</surname>
            <given-names>E.K.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Shippy</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Harris</surname>
            <given-names>S.C.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Mei</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Herman</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Goodsaid</surname>
            <given-names>F.M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Rat toxicogenomic study reveals analytical consistency across microarray platforms</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>24</volume>
        <year>2006</year>
        <fpage>1162</fpage>
        <lpage>1169</lpage>
        <pub-id pub-id-type="pmid">17061323</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Harris</surname>
            <given-names>C.R.</given-names>
          </name>
          <name>
            <surname>Millman</surname>
            <given-names>K.J.</given-names>
          </name>
          <name>
            <surname>Van Der Walt</surname>
            <given-names>S.J.</given-names>
          </name>
          <name>
            <surname>Gommers</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Virtanen</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Cournapeau</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Wieser</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Berg</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>N.J.</given-names>
          </name>
          <name>
            <surname>Kern</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Array programming with NumPy</article-title>
        <source>Nature</source>
        <year>2020</year>
        <fpage>357</fpage>
        <lpage>362</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <element-citation publication-type="journal" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Hunter</surname>
            <given-names>J.D.</given-names>
          </name>
        </person-group>
        <article-title>Matplotlib: a 2D graphics environment</article-title>
        <source>Comput. Sci. Eng.</source>
        <volume>9</volume>
        <year>2007</year>
        <fpage>90</fpage>
        <lpage>95</lpage>
      </element-citation>
    </ref>
    <ref id="bib6">
      <element-citation publication-type="book" id="sref6">
        <person-group person-group-type="author">
          <name>
            <surname>Ke</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Finley</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>T.Y.</given-names>
          </name>
        </person-group>
        <part-title>Lightgbm: a highly efficient gradient boosting decision tree</part-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Guyon</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Von Luxburg</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wallach</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Fergus</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Vishwanathan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Garnett</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <series>Advances in Neural Information Processing Systems</series>
        <volume>30</volume>
        <year>2017</year>
        <publisher-name>CurranAssociates, Inc.</publisher-name>
        <fpage>3146</fpage>
        <lpage>3154</lpage>
      </element-citation>
    </ref>
    <ref id="bib7">
      <element-citation publication-type="book" id="sref7">
        <person-group person-group-type="author">
          <name>
            <surname>Lundberg</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.-I.</given-names>
          </name>
        </person-group>
        <part-title>A unified approach to interpreting model predictions</part-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Guyon</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Von Luxburg</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wallach</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Fergus</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Vishwanathan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Garnett</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <series>Advances in Neural Information Processing Systems</series>
        <volume>30</volume>
        <year>2017</year>
        <publisher-name>Curran Associates, Inc.)</publisher-name>
        <fpage>4765</fpage>
        <lpage>4774</lpage>
      </element-citation>
    </ref>
    <ref id="bib8">
      <element-citation publication-type="book" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>McKinney</surname>
            <given-names>W.</given-names>
          </name>
        </person-group>
        <part-title>Data structures for statistical computing in Python</part-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Van der Walt</surname>
            <given-names>Stéfan</given-names>
          </name>
          <name>
            <surname>Millman</surname>
            <given-names>Jarrod</given-names>
          </name>
        </person-group>
        <source>In proceedings of the 9th Python in Science Conference</source>
        <year>2010</year>
        <publisher-name>Presented at the Python in Science Conference, SciPy</publisher-name>
        <publisher-loc>Austin, Texas</publisher-loc>
        <fpage>56</fpage>
        <lpage>61</lpage>
        <pub-id pub-id-type="doi">10.25080/majora-92bf1922-00a</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <element-citation publication-type="journal" id="sref9">
        <person-group person-group-type="author">
          <name>
            <surname>Mok</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Ashley</surname>
            <given-names>E.A.</given-names>
          </name>
          <name>
            <surname>Ferreira</surname>
            <given-names>P.E.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Yeo</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chotivanich</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Imwong</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Pukrittayakamee</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Dhorda</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drug resistance. Population transcriptomics of human malaria parasites reveals the mechanism of artemisinin resistance</article-title>
        <source>Science</source>
        <volume>347</volume>
        <year>2015</year>
        <fpage>431</fpage>
        <lpage>435</lpage>
        <pub-id pub-id-type="pmid">25502316</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <element-citation publication-type="journal" id="sref10">
        <person-group person-group-type="author">
          <name>
            <surname>Mok</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Stokes</surname>
            <given-names>B.H.</given-names>
          </name>
          <name>
            <surname>Gnädig</surname>
            <given-names>N.F.</given-names>
          </name>
          <name>
            <surname>Ross</surname>
            <given-names>L.S.</given-names>
          </name>
          <name>
            <surname>Yeo</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Amaratunga</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Allman</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Solyakov</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Bottrill</surname>
            <given-names>A.R.</given-names>
          </name>
          <name>
            <surname>Tripathi</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Artemisinin-resistant K13 mutations rewire Plasmodium falciparum’s intra-erythrocytic metabolic program to enhance survival</article-title>
        <source>Nat. Commun.</source>
        <volume>12</volume>
        <year>2021</year>
        <fpage>530</fpage>
        <pub-id pub-id-type="pmid">33483501</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <element-citation publication-type="journal" id="sref11">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Thirion</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Grisel</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Blondel</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Prettenhofer</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Dubourg</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Vanderplas</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Scikit-learn: machine learning in Python</article-title>
        <source>J. Machine Learn. Res.</source>
        <volume>12</volume>
        <year>2011</year>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="bib12">
      <element-citation publication-type="other" id="sref12">
        <person-group person-group-type="author">
          <name>
            <surname>Sage</surname>
            <given-names>Bionetworks.</given-names>
          </name>
        </person-group>
        <article-title>Malaria DREAM Challenge</article-title>
        <ext-link ext-link-type="uri" xlink:href="https://www.synapse.org/#!Synapse:syn16924919/wiki/583955" id="intref5710">https://www.synapse.org/#!Synapse:syn16924919/wiki/583955</ext-link>
      </element-citation>
    </ref>
    <ref id="bib14">
      <element-citation publication-type="journal" id="sref14">
        <person-group person-group-type="author">
          <name>
            <surname>Virtanen</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Gommers</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Oliphant</surname>
            <given-names>T.E.</given-names>
          </name>
          <name>
            <surname>Haberland</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Reddy</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Cournapeau</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Burovski</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Peterson</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Weckesser</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Bright</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title>
        <source>Nat. Methods</source>
        <volume>17</volume>
        <year>2020</year>
        <fpage>261</fpage>
        <lpage>272</lpage>
        <pub-id pub-id-type="pmid">32015543</pub-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <element-citation publication-type="journal" id="sref15">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Guan</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Machine learning for artemisinin resistance in malaria treatment across in vivo-in vitro platforms</article-title>
        <source>iScience</source>
        <volume>25</volume>
        <year>2022</year>
        <fpage>103910</fpage>
        <pub-id pub-id-type="pmid">35243261</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec sec-type="data-availability" id="da0010">
    <title>Data and code availability</title>
    <p id="p0030">The script to obtain the example datasets from GEO and the code generated in this study are publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/ciclops" id="intref0010">https://github.com/GuanLab/ciclops</ext-link>. All original code has been deposited at Zenodo and is publicly available as of the date of publication. The DOI is listed in the <xref rid="sec10" ref-type="sec">key resources table</xref>. Any additional information required to reanalyze the data reported in this paper is available from the <xref rid="sec8.1" ref-type="sec">lead contact</xref> upon request.</p>
  </sec>
  <ack id="ack0010">
    <title>Acknowledgments</title>
    <p id="p0580">This work is supported by <funding-source id="gs1"><institution-wrap><institution-id institution-id-type="doi">10.13039/100000002</institution-id><institution>NIH</institution></institution-wrap></funding-source> R35GM133346, <funding-source id="gs2"><institution-wrap><institution-id institution-id-type="doi">10.13039/100000001</institution-id><institution>NSF</institution></institution-wrap></funding-source>#1452656, and T32GM141746. Two of the datasets used in our original analyses and adapted here as example data were obtained from GEO (GEO: GSE151189 and GEO: GSE59098).</p>
    <sec id="sec11">
      <title>Author contributions</title>
      <p id="p0585">E.C. packaged the code and wrote the manuscript. H.Z. edited the manuscript and wrote the code for the analyses. Y.G. designed and implemented the algorithm that was the basis for this package. All authors read and agreed with this final manuscript.</p>
    </sec>
    <sec sec-type="COI-statement" id="sec12">
      <title>Declaration of interests</title>
      <p id="p0590">Y.G. serves as scientific advisor and receives payment from Genentech Inc, Eli Lilly and Company, Merck &amp; Co; serves as chief scientist at Ann Arbor Algorithms Inc.; and serves as editor and receives payment from Elsevier (iScience).</p>
    </sec>
  </ack>
</back>
