<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7178942</article-id>
    <article-id pub-id-type="publisher-id">3342</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-020-3342-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepSuccinylSite: a deep learning based approach for protein succinylation site prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Thapa</surname>
          <given-names>Niraj</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chaudhari</surname>
          <given-names>Meenal</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>McManus</surname>
          <given-names>Sean</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Roy</surname>
          <given-names>Kaushik</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Newman</surname>
          <given-names>Robert H.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Saigo</surname>
          <given-names>Hiroto</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>KC</surname>
          <given-names>Dukka B.</given-names>
        </name>
        <address>
          <email>dukka.kc@wichita.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0287 4439</institution-id><institution-id institution-id-type="GRID">grid.261037.1</institution-id><institution>Department of Computational Science and Engineering, </institution><institution>North Carolina A&amp;T State University, </institution></institution-wrap>Greensboro, NC USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0287 4439</institution-id><institution-id institution-id-type="GRID">grid.261037.1</institution-id><institution>Department of Computer Science, </institution><institution>North Carolina A&amp;T State University, </institution></institution-wrap>Greensboro, NC USA </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0287 4439</institution-id><institution-id institution-id-type="GRID">grid.261037.1</institution-id><institution>Department of Biology, </institution><institution>North Carolina A&amp;T State University, </institution></institution-wrap>Greensboro, NC USA </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2242 4849</institution-id><institution-id institution-id-type="GRID">grid.177174.3</institution-id><institution>Faculty of Information Science and Electrical Engineering, </institution><institution>Kyushu University, </institution></institution-wrap>Fukuoka, Japan </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0000 9263 262X</institution-id><institution-id institution-id-type="GRID">grid.268246.c</institution-id><institution>Electrical Engineering and Computer Science Department, </institution><institution>Wichita State University, </institution></institution-wrap>Wichita, KS USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>23</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>21</volume>
    <issue>Suppl 3</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. Supplement Editors were not responsible for the review of papers they had authored. No other competing interests were declared.</issue-sponsor>
    <elocation-id>63</elocation-id>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>11</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>8</day>
        <month>1</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s). 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Protein succinylation has recently emerged as an important and common post-translation modification (PTM) that occurs on lysine residues. Succinylation is notable both in its size (e.g., at 100 Da, it is one of the larger chemical PTMs) and in its ability to modify the net charge of the modified lysine residue from + 1 to − 1 at physiological pH. The gross local changes that occur in proteins upon succinylation have been shown to correspond with changes in gene activity and to be perturbed by defects in the citric acid cycle. These observations, together with the fact that succinate is generated as a metabolic intermediate during cellular respiration, have led to suggestions that protein succinylation may play a role in the interaction between cellular metabolism and important cellular functions. For instance, succinylation likely represents an important aspect of genomic regulation and repair and may have important consequences in the etiology of a number of disease states. In this study, we developed DeepSuccinylSite, a novel prediction tool that uses deep learning methodology along with embedding to identify succinylation sites in proteins based on their primary structure.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Using an independent test set of experimentally identified succinylation sites, our method achieved efficiency scores of 79%, 68.7% and 0.48 for sensitivity, specificity and MCC respectively, with an area under the receiver operator characteristic (ROC) curve of 0.8. In side-by-side comparisons with previously described succinylation predictors, DeepSuccinylSite represents a significant improvement in overall accuracy for prediction of succinylation sites.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">Together, these results suggest that our method represents a robust and complementary technique for advanced exploration of protein succinylation.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Succinylation</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Convolutional neural network</kwd>
      <kwd>Recurrent neural network</kwd>
      <kwd>Long short-term memory</kwd>
      <kwd>Embedding</kwd>
    </kwd-group>
    <conference xlink:href="https://www.abacbs.org/conference2019/about">
      <conf-name>Joint 30th International Conference on Genome Informatics (GIW) &amp; Australian Bioinformatics and Computational Biology Society (ABACBS) Annual Conference</conf-name>
      <conf-loc>Sydney, Australia</conf-loc>
      <conf-date>9-11 December 2019</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par13">Protein post-translational modifications (PTM) are important cellular regulatory processes that occur after protein synthesis. PTMs increase the functional diversity of the proteome by the covalent addition of functional moieties to proteins, proteolytic cleavage of regulatory subunits and play important roles in signaling for degradation of entire proteins. PTMs include phosphorylation, glycosylation, ubiquitination and relatively recently described modifications, such as succinylation. Succinylation is a PTM that occurs through the addition of a succinyl group (−CO-CH<sub>2</sub>-CH<sub>2</sub>-CO<sub>2</sub>H) to the ε-amino of target lysine residues.</p>
    <p id="Par14">Protein PTMs have been detected by a variety of experimental techniques [<xref ref-type="bibr" rid="CR1">1</xref>], including mass spectrometry (MS) [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>], liquid chromatography [<xref ref-type="bibr" rid="CR4">4</xref>], radioactive chemical labeling [<xref ref-type="bibr" rid="CR5">5</xref>] and immunological detection, such as chromatin immunoprecipitation [<xref ref-type="bibr" rid="CR6">6</xref>] and western blotting [<xref ref-type="bibr" rid="CR7">7</xref>]. Generally, the experimental analysis of PTMs requires time-consuming, labor- and capital-intensive techniques and the use of hazardous/expensive chemical reagents. Due to importance of PTMs in both disease states and normal biological functions, it is imperative to invest in developing options that can screen proteins for potential PTM sites in a rapid, cost-effective manner.</p>
    <p id="Par15">In recent years, machine learning has become a cost-effective method for prediction of different PTM sites. Some of the machine learning based succinylation site prediction approaches are iSuc-PseAAC [<xref ref-type="bibr" rid="CR8">8</xref>], iSuc-PseOpt [<xref ref-type="bibr" rid="CR9">9</xref>], pSuc-Lys [<xref ref-type="bibr" rid="CR10">10</xref>], SuccineSite [<xref ref-type="bibr" rid="CR11">11</xref>], SuccineSite2.0 [<xref ref-type="bibr" rid="CR12">12</xref>], GPSuc [<xref ref-type="bibr" rid="CR13">13</xref>] and PSuccE [<xref ref-type="bibr" rid="CR14">14</xref>] . Although results have been promising, the potential for bias is present due to manual selection of features along with the possible absence of unknown features that contribute to succinylation. Moreover, the prediction performance of these methods is not yet satisfactory enough to be used in high throughput studies.</p>
    <p id="Par16">Recently, deep learning (DL) approaches have been developed to elucidate putative PTM sites in cellular proteins. For instance, MusiteDeep [<xref ref-type="bibr" rid="CR15">15</xref>] and DeepPhos [<xref ref-type="bibr" rid="CR16">16</xref>] have been developed to predict phosphorylation sites while Fu et al. [<xref ref-type="bibr" rid="CR17">17</xref>] and Wu et al. [<xref ref-type="bibr" rid="CR18">18</xref>] used DL-based methods to identify putative ubiquitination and acetylation sites, respectively. These DL methods have achieved relative improvement in aggregate measures of method performance, such as the area under curve (AUC) and Matthews Correlation Coefficient (MCC). Typically, these models utilize some combination of one-hot encoding and extracted features as an input, largely trying to avoid reliance on manual feature extraction. To the best of our knowledge, DL models have not been applied previously for prediction of succinylation sites. In this study, we developed a succinylation site predictor, termed DeepSuccinylSite, based on a convolutional neural network (CNN) deep learning framework [<xref ref-type="bibr" rid="CR19">19</xref>] using Keras library [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Benchmark dataset</title>
      <p id="Par17">In this study, we used the same training and independent dataset collected from experimentally derived lysine succinylation sites as in Hasan et al. [<xref ref-type="bibr" rid="CR13">13</xref>] and Ning et al. [<xref ref-type="bibr" rid="CR14">14</xref>]. Ning et al. used UniProtKB/Swiss-Prot database and NCBI protein sequence database as Hasan et al. to create the succinylation dataset. After removing proteins that have more than 30% sequence identity using CD-HIT, 5009 succinylation sites and 53,542 sites not known to be succinylated remained. Of these, 4755 succinylation sites and 50,565 non-succinylation sites were used for the training set and 254 succinylation sites and 2977 non-succinylation sites were used for the independent test. Moreover, for our approach the optimal window size came out to be 33 and some of the sequences had other characters, we lost 5 (out of 4755) positive sites in the training set.</p>
      <p id="Par18">For the training and test sets, data were balanced using under-sampling. The final training dataset contained 4750 positive and 4750 negative sites whereas the independent test dataset contained 254 positive and 254 negative sites after balancing. Table <xref rid="Tab1" ref-type="table">1</xref> shows the final dataset for training and independent test after balancing. In order to generate a local representation of the protein and to optimize the model, a window parameter was set around each lysine (K) of interest. If the left or right side of K was less than half the size of the window, then pseudo residue “-” was used in order to retain all the positive sites.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Number of positive and negative sites for training and testing dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Positive</th><th>Negative</th></tr></thead><tbody><tr><td>Training</td><td align="center">4750</td><td align="center">4750</td></tr><tr><td>Independent Test</td><td align="center">254</td><td align="center">254</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec4">
      <title>Encoding</title>
      <p id="Par19">In contrast to traditional machine learning methods, our DL-based method takes sequence data in the form of windows directly as an input, reducing the need for hand-crafted feature extraction. A pre-requisite for this approach is that the sequence data must be encoded in a form that is readable by our DL model. Accordingly, we have utilized two types of encoding: (i) one-hot encoding and (ii) embedding layer. Compared to other DL approaches for other types of post-translational modification site prediction, one of the major differences is our embedding encoding.</p>
      <sec id="Sec5">
        <title>One-hot encoding</title>
        <p id="Par20">One hot encoding converts categorical variables to respective binary variables. We implemented one-hot encoding in a manner similar to that used during the development of MusiteDeep [<xref ref-type="bibr" rid="CR15">15</xref>]. In order to convert the 20 common amino acids and our pseudo residue “-” into numerical values, these 21 characters are converted into integers ranging from 0 to 20. Every amino acid was represented by a binary code consisting of a sequence of zeros and a singular one, the location of which encodes the identity of the amino acid. In our study, the binary representation was done based on alphabetical order. For example, Alanine (A) is represented as 100000000000000000000 and Arginine (R) is represented as 010000000000000000000 and so on. Accordingly, in our model, a window of size, N, corresponded to an input vector size of N × 21.</p>
        <p id="Par21">One of the primary drawbacks of one-hot encoding is that the mapping is completely uniform. Therefore, amino acids with similar properties are not placed together in vector space.</p>
      </sec>
      <sec id="Sec6">
        <title>Embedding layer</title>
        <p id="Par22">One of the highlights of our approach is the embedding layer. The second type of encoding that we utilize is the embedding encoding [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>]. Embedding finds the best representation for the amino acid sequence, as in DeepGO [<xref ref-type="bibr" rid="CR22">22</xref>], to overcome the shortcomings of one-hot encoding. Briefly, the 20 amino acids residue and 1 pseudo residue were first converted into integers ranging from 0 to 20. This is provided as an input to the embedding layer, which lies at the beginning of our DL architecture. The embedding layer is initialized with random weights. The layer then learns better vector-based representations with subsequent epochs during training. Each vectorization is an orthogonal representation in another dimension, thus preserving its identity. Hence, making it more dynamic than the static one-hot encoding. In our study, embedding encoding (word to vec) for K is: [− 0.03372079, 0.01156038, − 0.00370798, 0.00726882, − 0.00323456, − 0.00622324, 0.01516087, 0.02321764, 0.00389882, − 0.01039953, − 0.02650939, 0.01174229, − 0.0204078, − 0.06951248, − 0.01470334, − 0.03336572, 0.01336034, − 0.00045607, 0.01492316, 0.02321628, − 0.02551141] in 21-dimensional vector space after training. Embedding groups commonly co-occurring items together in the vector space. Two key arguments must be specified in the embedding layer. These are:
<list list-type="bullet"><list-item><p id="Par23">output_dim: Size of vector space.</p></list-item><list-item><p id="Par24">input_length: Size of input, which is window size.</p></list-item></list></p>
      </sec>
    </sec>
    <sec id="Sec7">
      <title>Training and testing datasets</title>
      <p id="Par25">The training dataset was further sub-divided into 80% training and 20% validation sets. The model was trained on 80% of the training data with validation done in every epoch using the remaining 20% of the training dataset. This validation approach was performed in order to track the training progress and to identify overfitting. Overfitting was identified when validation accuracy started decreasing while training accuracy continued to increase. Checkpointer was utilized to select the optimal model from the epochs based on validation accuracy; this approach also helped to minimize any potential overfitting. The model generated was then used for independent testing with the independent testing dataset.</p>
    </sec>
    <sec id="Sec8">
      <title>Input</title>
      <p id="Par26">The main advantage of using DL over traditional machine learning approaches is the exclusion of manual feature extraction. The input for our DL approach is the sequence windows in FASTA format. For example, for a window size of 33, the input dimension would be 33 × 21 for one-hot encoding. For embedding for the same window size, the input dimension would be 33 × 21 for embedding output dimension of 21.</p>
    </sec>
    <sec id="Sec9">
      <title>DeepSuccinylSite architecture</title>
      <p id="Par27">The overall architecture of DeepSuccinylSite is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.
<fig id="Fig1"><label>Fig. 1</label><caption><p><bold>a</bold> Window size of 33 in FASTA format is the input. It is converted into integers which is then encoded either using one-hot encoding or embedding layer. This will be the input for CNN layers. <bold>b</bold> The output from either of the encoding is then fed as input into the deep learning architecture. Finally, after the flattening and fully connected layers we get the final output which contains two nodes with outputs [0 1] for positive and [1 0] for negative sites</p></caption><graphic xlink:href="12859_2020_3342_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par28">After encoding the input data, the encoded data was fed into the network. The same architecture was utilized for both encoding methods, except for the inclusion of an embedding layer and a lambda layer in the case of the embedding encoding.</p>
      <p id="Par29">The next layer is the convolutional layer. Previous DL-based models for Phosphorylation sites (DeepPhos, MusiteDeep) [19, 20] have used 1-D (dimensional) convolutional layer, whereas we have used 2-D (dimensional) convolutional layer, thus increasing our flexibility with choosing 2-D size. If we use 1D convolutional layer and do the same, then we will not be able to deduce many feature information, as the x-axis is fixed (it will stay at 21) and will only stride vertically. Thereafter, other layers were also chosen with 2D. We used a 2D convolutional layer to prioritize the inclusion of filter size 17 × 3 (for window size 33, the PTM site lies at the 17th position), which will include the PTM site in every stride. The use of this filter size, along with the disabling of padding, allowed the model to be optimized for training time without compromising performance. Higher dropout of 0.6 was used to avoid overfitting. Moreover, a rectified linear unit (ReLU) was used as an activation function for all layers. ReLU was deemed an optimal activation function due to its sparse activation, which minimized the possibility for overfitting and maximized the predictive power of the model. We used two convolutional layers, one maxpooling layer, a fully connected layer with two dense layers, and an output layer. The parameters used in the model are given in Table <xref rid="Tab2" ref-type="table">2</xref>.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Parameters in DeepSuccinylSite</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Parameters</th><th>Settings</th></tr></thead><tbody><tr><td>Embedding Output Dimension</td><td>21</td></tr><tr><td>Learning Rate</td><td>0.001</td></tr><tr><td>Batch Size</td><td>256</td></tr><tr><td>Epochs</td><td>80</td></tr><tr><td>Conv2d_1 number of filters</td><td>64</td></tr><tr><td>Conv2d_1 filter size</td><td>17 × 3 (For window size 33)</td></tr><tr><td>Conv2d_1 padding</td><td>Disabled</td></tr><tr><td>Dropout</td><td>0.6</td></tr><tr><td>Conv2d_1 number of filters</td><td>128</td></tr><tr><td>Conv2d_1 filter size</td><td>3 × 3</td></tr><tr><td>Conv2d_1 padding</td><td>Enabled</td></tr><tr><td>Dropout</td><td>0.6</td></tr><tr><td>MaxPooling2d</td><td>2 × 2</td></tr><tr><td>Dense 1</td><td>768</td></tr><tr><td>Dropout</td><td>0.5</td></tr><tr><td>Dense_2</td><td>256</td></tr><tr><td>Dropout</td><td>0.5</td></tr><tr><td>Checkpointer</td><td>Best validation accuracy</td></tr></tbody></table></table-wrap></p>
      <p id="Par30">Adam optimization was used as the optimizer for our architecture, as described previously by Kingma et al. [<xref ref-type="bibr" rid="CR23">23</xref>]. Adam uses an adaptive learning rates methodology to calculate individual learning rates for each parameter. Adam is different from classical stochastic gradient descent in that stochastic gradient descent maintains a single, constant learning rate for all weight updates during training [<xref ref-type="bibr" rid="CR24">24</xref>]. Specifically, Adam combines benefits of both adaptive gradient algorithm and root mean square propagation, allowing for efficient training of the model. Since this study is a binary classification problem, binary cross-entropy (measure of uncertainty associated with given distribution) or log loss was used as the loss function. The binary cross-entropy is given by:
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ -\frac{1}{N}\sum \limits_{i=1}^N\left[{y}_i\mathit{\log}\left({\hat{y}}_i\right)+\left(1-{y}_i\right)\mathit{\log}\left(1-{\hat{y}}_i\right)\right] $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo mathvariant="italic">log</mml:mo><mml:mfenced close=")" open="("><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo mathvariant="italic">log</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mspace width="0.25em"/></mml:math><graphic xlink:href="12859_2020_3342_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par31">where y is the label <bold>(</bold>1 for positive and 0 for negative) and <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\hat{y}}_i $$\end{document}</tex-math><mml:math id="M4" display="inline"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2020_3342_Article_IEq1.gif"/></alternatives></inline-formula> is the predicted probability of the site being positive for all N points. For each positive site (<italic>y = 1</italic>), it adds <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \log \left({\hat{y}}_i\right) $$\end{document}</tex-math><mml:math id="M6" display="inline"><mml:mo>log</mml:mo><mml:mfenced close=")" open="("><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mspace width="0.25em"/></mml:math><inline-graphic xlink:href="12859_2020_3342_Article_IEq2.gif"/></alternatives></inline-formula> to the loss, that is, the log probability of it being positive<bold>.</bold> Conversely, for each negative site (<italic>y = 0</italic>), it adds <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \log \left(1-{\hat{y}}_i\right) $$\end{document}</tex-math><mml:math id="M8" display="inline"><mml:mo>log</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2020_3342_Article_IEq3.gif"/></alternatives></inline-formula>, that is, the log probability of it being negative.</p>
      <p id="Par32">The fully connected layers contained two dense layers with 768 and 256 nodes, respectively, with the final output layer containing 2 nodes.</p>
    </sec>
    <sec id="Sec10">
      <title>Model evaluation and performance metrics</title>
      <p id="Par33">In this study, 10-fold cross validation was used to evaluate the performance of the model. In 10-fold cross validation, the data are partitioned into 10 equal parts. Then, one-part is left out for validation and training is performed on remaining 9 parts. This process is repeated until all parts are used for validation.</p>
      <p id="Par34">Confusion Matrix (CM), Matthew’s Correlation Coefficient (MCC) and Receiver Operating Characteristics (ROC) curve were used as performance metrics. The ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier whereas area under curve (AUC) represents the degree or measure of separability. Since identification of succinylation sites is a binary classification problem, the confusion matrix size is 2 × 2 composed of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN). Other metrics calculated using these variables were accuracy, sensitivity (i.e., the true positive rate) and specificity (i.e., the true negative rate).
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Accuracy=\frac{TP+ TN}{TP+ TN+ FP+ FN}\times 100 $$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mtext mathvariant="italic">Accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mspace width="0.25em"/></mml:math><graphic xlink:href="12859_2020_3342_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Sensitivity=\frac{TP}{TP+ FN}\times 100 $$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mtext mathvariant="italic">Sensitivity</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="italic">TP</mml:mi><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mspace width="0.25em"/></mml:math><graphic xlink:href="12859_2020_3342_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Specificity=\frac{TN}{TN+ FP}\times 100 $$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mtext mathvariant="italic">Specificity</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="italic">TN</mml:mi><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mspace width="0.25em"/></mml:math><graphic xlink:href="12859_2020_3342_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ MCC=\frac{(TP)(TN)-(FP)(FN)}{\sqrt{\left( TP+ FP\right)\left( TP+ FN\right)\left( TN+ FP\right)\left( TN+ FN\right)}} $$\end{document}</tex-math><mml:math id="M16" display="block"><mml:mi mathvariant="italic">MCC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">TP</mml:mi></mml:mfenced><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">TN</mml:mi></mml:mfenced><mml:mo>−</mml:mo><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">FP</mml:mi></mml:mfenced><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">FN</mml:mi></mml:mfenced></mml:mrow><mml:msqrt><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msqrt></mml:mfrac><mml:mspace width="0.25em"/></mml:math><graphic xlink:href="12859_2020_3342_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
  </sec>
  <sec id="Sec11">
    <title>Results</title>
    <sec id="Sec12">
      <title>Optimal window size and encoding</title>
      <p id="Par35">Initially, window sizes from 9 to 45 were tested with both one-hot encoding and embedding. For example, for a window size of 9, the lysine (K) residue was set in the middle of the window with 4 amino acid residues upstream and 4 amino acid residues downstream. A window size of 33 yielded the highest MCC for both one-hot encoding and embedding, with further increases in window size resulting in reductions in MCC (Table <xref rid="Tab3" ref-type="table">3</xref>). Likewise, the highest specificity and AUC were achieved using a window size of 33, with only a marginal reduction in sensitivity when using embedding (Table <xref rid="Tab3" ref-type="table">3</xref> and Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Hence, a window size of 33 was considered as the optimal window size for this study. Interestingly, a window size of 33 was also utilized by Wang et al. for phosphorylation site prediction using one-hot encoding [<xref ref-type="bibr" rid="CR15">15</xref>]. It is worth noting that the consistency in window size between this study and the previous study by Wang et al. correlates with the known range for many inter-protein amino acid interactions. Importantly, with only a few exceptions, embedding performed better than one-hot encoding for every window size tested. Therefore, for this study, embedding was chosen for encoding.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Performance metrics for different window sizes. The highest values in each category are highlighted in boldface. MCC: Matthew’s Correlation Coefficient</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Window Size</th><th colspan="3">One-Hot Encoding</th><th colspan="3">Embedding (Dimension = 21)</th></tr><tr><th>Sensitivity</th><th>Specificity</th><th>MCC</th><th>Sensitivity</th><th>Specificity</th><th>MCC</th></tr></thead><tbody><tr><td>9</td><td align="center">0.70</td><td align="center">0.55</td><td align="center">0.25</td><td align="center">0.80</td><td align="center">0.57</td><td align="center">0.39</td></tr><tr><td>15</td><td align="center">0.73</td><td align="center"><bold>0.60</bold></td><td align="center">0.33</td><td align="center"><bold>0.82</bold></td><td align="center">0.58</td><td align="center">0.42</td></tr><tr><td>21</td><td align="center">0.79</td><td align="center">0.55</td><td align="center">0.34</td><td align="center">0.76</td><td align="center">0.67</td><td align="center">0.43</td></tr><tr><td>27</td><td align="center">0.79</td><td align="center">0.59</td><td align="center">0.38</td><td align="center">0.81</td><td align="center">0.63</td><td align="center">0.45</td></tr><tr><td>33</td><td align="center"><bold>0.84</bold></td><td align="center">0.55</td><td align="center"><bold>0.41</bold></td><td align="center">0.79</td><td align="center"><bold>0.69</bold></td><td align="center"><bold>0.48</bold></td></tr><tr><td>39</td><td align="center">0.81</td><td align="center">0.53</td><td align="center">0.36</td><td align="center">0.75</td><td align="center">0.63</td><td align="center">0.40</td></tr><tr><td>45</td><td align="center">0.81</td><td align="center">0.55</td><td align="center">0.38</td><td align="center">0.76</td><td align="center">0.67</td><td align="center">0.43</td></tr></tbody></table></table-wrap>
<fig id="Fig2"><label>Fig. 2</label><caption><p>ROC curve for different window sizes for embedding</p></caption><graphic xlink:href="12859_2020_3342_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec13">
      <title>Identification of optimal embedding dimension</title>
      <p id="Par36">Next, we sought to identify the optimal embedding dimension. To this end, dimensions ranging from 9 to 33 were tested for embedding. It is important to note that increasing the dimension of embedding will result in higher computational cost. Therefore, we aimed to identify the smallest dimension that struck a balance across all metrics. Because MCC is often used as a surrogate of overall model performance, it was prioritized slightly over the other parameters. While both dimension sizes of 15 and 21 struck such a balance, the performance metrics were generally better using a dimension size of 21. Indeed, a dimension size of 21 achieved the highest MCC, with sensitivity and specificity scores that were within 7% of the maximum scores achieved in these areas (Table <xref rid="Tab4" ref-type="table">4</xref>). Consistently, dimension size of 15 and 21 achieved the highest AUC score (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Taken together, these data suggest that a dimension size of 21 is optimal using our architecture. Therefore, a dimension size of 21 was selected for model development. The dimension size is consistent with the fact that 20 amino acid residues and 1 pseudo residue were present in each vector.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Performance metrics for different embedding dimensions. The highest values in each category are shown in bold. MCC: Matthew’s Correlation Coefficient</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dimension</th><th>Sensitivity</th><th>Specificity</th><th>MCC</th></tr></thead><tbody><tr><td>9</td><td align="center"><bold>0.85</bold></td><td align="center">0.58</td><td align="center">0.45</td></tr><tr><td>15</td><td align="center">0.73</td><td align="center"><bold>0.71</bold></td><td align="center">0.44</td></tr><tr><td>21</td><td align="center">0.79</td><td align="center">0.67</td><td align="center"><bold>0.48</bold></td></tr><tr><td>27</td><td align="center">0.75</td><td align="center">0.66</td><td align="center">0.41</td></tr><tr><td>33</td><td align="center">0.77</td><td align="center">0.68</td><td align="center">0.45</td></tr></tbody></table></table-wrap>
<fig id="Fig3"><label>Fig. 3</label><caption><p>ROC curves for different embedding dimensions</p></caption><graphic xlink:href="12859_2020_3342_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
    <sec id="Sec14">
      <title>Cross-validation and alternative classifiers</title>
      <p id="Par37">Our final model, which we termed DeepSuccinylSite, utilizes embedding with window and dimension sizes of 33 and 21, respectively. Based on five rounds of 10-fold cross-validation, DeepSuccinylSite exhibited robustness with consistent performance metrics with an average MCC of 0.519 +/− 0.023 and an AUC of 0.823 (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3). We also implemented additional Deep Learning architectures and different machine learning models where the input was hand-crafted ‘physico-chemical’ based features rather than the protein sequence alone. Essentially, this implementation takes various physiochemical features combined with XGBoost to extract prominent features. We excluded any sequences with ‘-‘, while calculating the features. We then used XGBoost to extract prominent features, which provided better accuracy and obtained a total of 160 features at threshold of 0.00145. Interestingly, the performance of the methods using these approaches were not as good as DeepSuccinylSite, whose input is protein sequence alone (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2). Further information on performance of our model are included in Additional file <xref rid="MOESM1" ref-type="media">1</xref>. Additionally, the results of feature-based Deep Learning architecture is shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1.</p>
    </sec>
    <sec id="Sec15">
      <title>Comparison with other deep learning architectures</title>
      <p id="Par38">Other DL architectures, such as Recurrent Neural Network (RNN) [<xref ref-type="bibr" rid="CR25">25</xref>] and Long Short-Term Memory (LSTM) [<xref ref-type="bibr" rid="CR26">26</xref>], as well as the combined model, LSTM-RNN, were also implemented for one-hot encoding (DeepSuccinylSite-one_hot) and compared with the independent test result of DeepSuccinylSite (Table <xref rid="Tab5" ref-type="table">5</xref>). Additionally, we implemented an additional DL architecture, where the input includes other features beyond the primary amino acid sequence. Specifically, this implementation utilizes a combination of 1) physiochemical features, such as Pseudo Amino acid Composition (PAAC), ‘k-Spaced Amino Acid Pairs’ (AAP); 2) Autocorrelation features, such as Moreau-Broto autocorrelation and Composition, Transition and Distribution (CTD) features, and 3) Entropy Features, such as Shannon entropy, Relative entropy, and Information gain. We excluded any sequences with ‘-‘, while calculating the features. We then used XGBoost to extract prominent features which provided better accuracy and obtained a total of 160 features at threshold 0.00145. The version of the algorithm using features is termed as DeepSuccinylSite-feature based.
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Comparison of DeepSuccinylSite with other deep learning architectures for window size 33. The highest value in each category is shown in bold. MCC: Matthew’s Correlation Coefficient; RNN: Recurrent neural network; LSTM: Long short-term memory model</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Models</th><th>Sensitivity</th><th>Specificity</th><th>MCC</th></tr></thead><tbody><tr><td>RNN</td><td align="center">0.70</td><td align="center">0.49</td><td align="center">0.20</td></tr><tr><td>LSTM-RNN</td><td align="center">0.66</td><td align="center">0.57</td><td align="center">0.23</td></tr><tr><td>LSTM</td><td align="center">0.74</td><td align="center">0.66</td><td align="center">0.36</td></tr><tr><td><italic>DeepSuccinylSite-feature based</italic></td><td align="center"><italic>0.80</italic></td><td align="center"><italic>0.44</italic></td><td align="center"><italic>0.27</italic></td></tr><tr><td>DeepSuccinylSite-one_hot</td><td align="center"><bold>0.84</bold></td><td align="center">0.55</td><td align="center">0.41</td></tr><tr><td>DeepSuccinylSite-Embedding</td><td align="center">0.79</td><td align="center"><bold>0.69</bold></td><td align="center"><bold>0.48</bold></td></tr></tbody></table></table-wrap></p>
      <p id="Par39">For fair comparison, we used the same balanced training and testing dataset for window size of 33 and one-hot encoding for these three DL architectures. The results are shown in Table <xref rid="Tab5" ref-type="table">5</xref> and ROC curve is shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. The results for our DL model with embedding (DeepSuccinylSite) is also shown. The detailed architecture of these models, including results for other window sizes are discussed in Additional file <xref rid="MOESM1" ref-type="media">1</xref> and the performance of these methods is presended in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1. For one-hot encoding, DeepSuccinylSite achieved better MCC and AUC score than the other DL architectures. Likewise, our final model using embedding achieved the highest MCC and AUC scores of any model (Table <xref rid="Tab5" ref-type="table">5</xref>).
<fig id="Fig4"><label>Fig. 4</label><caption><p>ROC curve for different deep learning architectures</p></caption><graphic xlink:href="12859_2020_3342_Fig4_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec16">
      <title>Independent test comparisons with existing models</title>
      <p id="Par40">Next, the performance of DeepSuccinylSite was compared with other succinylation site predictors using an independent test set as mentioned in the benchmark dataset earlier. During these analyses, some of the most widely used tools for succinylation site prediction, such as iSuc-PseAAC [<xref ref-type="bibr" rid="CR8">8</xref>], iSuc-PseOpt [<xref ref-type="bibr" rid="CR9">9</xref>], pSuc-Lys [<xref ref-type="bibr" rid="CR10">10</xref>], SuccineSite [<xref ref-type="bibr" rid="CR11">11</xref>], SuccineSite2.0 [<xref ref-type="bibr" rid="CR12">12</xref>], GPSuc [<xref ref-type="bibr" rid="CR13">13</xref>] and PSuccE [<xref ref-type="bibr" rid="CR14">14</xref>], were considered. All these methods use the same training and independent test data sets as in Table <xref rid="Tab6" ref-type="table">6</xref>. The performance metrics for these previously published methods were taken from their respective manuscripts mainly based on comparison done in PSuccE [<xref ref-type="bibr" rid="CR14">14</xref>].
<table-wrap id="Tab6"><label>Table 6</label><caption><p>Comparison of DeepSuccinylSite with existing predictors using an independent test dataset. The highest value in each category is shown in bold</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Prediction Schemes</th><th>Sensitivity</th><th>Specificity</th><th>MCC</th></tr></thead><tbody><tr><td>iSuc-PseAAC</td><td align="center">0.12</td><td align="center"><bold>0.89</bold></td><td align="center">0.01</td></tr><tr><td>iSuc-PseOpt</td><td align="center">0.30</td><td align="center">0.76</td><td align="center">0.04</td></tr><tr><td>pSuc-Lys</td><td align="center">0.22</td><td align="center">0.83</td><td align="center">0.04</td></tr><tr><td>SuccineSite</td><td align="center">0.37</td><td align="center">0.88</td><td align="center">0.20</td></tr><tr><td>SuccineSite2.0</td><td align="center">0.45</td><td align="center">0.88</td><td align="center">0.26</td></tr><tr><td>GPSuc</td><td align="center">0.50</td><td align="center">0.88</td><td align="center">0.30</td></tr><tr><td>PSuccE</td><td align="center">0.38</td><td align="center"><bold>0.89</bold></td><td align="center">0.20</td></tr><tr><td>DeepSuccinylSite</td><td align="center"><bold>0.79</bold></td><td align="center">0.69</td><td align="center"><bold>0.48</bold></td></tr></tbody></table></table-wrap></p>
      <p id="Par41">DeepSuccinylSite achieved a 58.3% higher sensitivity score than the next highest performing model (Table <xref rid="Tab6" ref-type="table">6</xref>). In contrast, our model exhibited the lowest specificity score of all of models tested. However, the specificity score achieved by DeepSuccinylSite was only 22.2% lower than that of the top-ranked methods. Consequently, DeepSuccinylSite achieved a significantly higher performance as measured by MCC. Indeed, DeepSuccinylSite exhibited an ~ 62% increase in MCC when compared to the next highest method, GPSuc. Taken together, the novel architecture we have described, termed DeepSuccinylSite, shows significantly improved performance for precise and accurate prediction of succinylation sites.</p>
    </sec>
  </sec>
  <sec id="Sec17">
    <title>Discussion</title>
    <p id="Par42">Succinylation is relatively newly discovered PTM that is garnering interest due to the biological implications of introducing a large (100 Da) chemical moiety that changes the charge of the modified residue. Experimental detection of succinylation is labor intensive and expensive. Due to the availability of a relatively large dataset containing 4750 positive sites for training, it was possible for us to implement different DL architectures. The model optimization process described in this paper led to a significant improvement in precise prediction of succinylation sites when compared to models previously described in the literature. Two types of encoding were considered for this study, one-hot encoding and embedding. Our results suggest that embedding is an optimal approach, as it allows the model to learn representations similar to the amino acid features, which results in further improvements in the ability to identify putative sites of modification.</p>
    <p id="Par43">Furthermore, DeepSuccinylSite corroborates previous indications in the literature that have suggested a window size of 33 optimally reflects local chemical interactions in proteins that predict sites of PTM due to its performance in metrics like MCC. One of the important parameters was embedding dimension. DeepSuccinylSite was trained with different dimensions ranging from 9 to 33. With increase in dimension, training time also increased. Though there was not a significant difference between dimension sizes 15 and 21, considering the number of amino acid residues and slightly better result, 21 was chosen as the embedding dimension for this study. Finally, for window size 33 with embedding dimension 21, DeepSuccinylSite achieved efficiency scores of 0.79, 0.69 and 0.48 for sensitivity, specificity and MCC, respectively.</p>
    <p id="Par44">For further improvements, instead of current protein sequence-based window sequence, we can extract structure-based window sequence centered around the site of interest and use that window as the input. When the structure of the protein is not available, protein structure prediction pipelines like I-TASSER [<xref ref-type="bibr" rid="CR27">27</xref>] or ROSETTA [<xref ref-type="bibr" rid="CR28">28</xref>], can first be used to predict the structure. Since the structure of the proteins are more conserved than sequence, we hope to capture evolutionary information better and thus obtain better prediction accuracy. Moreover, we could also improve the performance of the approach by creating multiple models using sequence-based windows, structure-based windows, physiochemical properties and then utilize voting approaches. Lastly, multi-window input, as done in DeepPhos [<xref ref-type="bibr" rid="CR16">16</xref>], using our encoding technique can improve the performance. However, more datasets are required for these schemes and once more experimental data becomes available, we could explore this in more detail. We also explored the effects of data size on prediction performance (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4 and Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S2). These studies suggest that, initially, the performance of our model increases with the increasing data size before reaching a plateau. This is somewhat contrary to the general consensus in deep learning that performance keeps increasing with the data size according to a power law. However, with more experimental data likely to be available in the future, we could perform a more comprehensive study on how performance scales with increasing data size. Perhaps, this might also suggest that with increasing data we might have to develop more complex deep learning models.</p>
    <p id="Par45">Utilizing the unique architecture described in this paper, the DeepSuccinylSite model shows a substantial improvement in predictive quality over existing models. The utility of this model is in its ability to predict lysine residues that are likely to be succinylated. Accordingly, this model could be utilized to optimize workflows for experimental verification of succinylation sites. Specifically, use of this model could significantly reduce the time and cost of identification of these sites. This model may also have some utility in hypothesis generation when PTM presents itself as likely explanation for observed biological phenomenon.</p>
  </sec>
  <sec id="Sec18">
    <title>Conclusion</title>
    <p id="Par46">In this study, we describe the development of DeepSuccinylSite, a novel and effective deep learning architecture for the prediction of succinylation sites. The primary advantage of using this model over other machine learning architectures is the elimination of feature extraction. As a consequence, other PTM sites could be easily applied in this model. Since this model only utilizes two convolutional layer and one max-pooling layer to avoid overfitting for the current data, provision of new data sources may allow for further modification of this model in the future. In conclusion, DeepSuccinylSite is an effective deep learning architecture with best-in-class results for prediction of succinylation sites and potential for use in general PTM prediction problems.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec19">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2020_3342_MOESM1_ESM.docx">
            <caption>
              <p><bold>Additional file 1: </bold>Contains supplementary tables and figures referred to in the text. We describe various other deep learning architectures, other machine learning architectures, cross-validation results and independent test results for different sample sizes. <bold>Table S1.</bold> Independent Test Results. <bold>Table S2.</bold> Independent test result for different machine learning architectures. <bold>Figure S1.</bold> ROC curve for feature based DL-model. <bold>Table S3.</bold> Cross-validation (CV) results for different run. <bold>Table S4.</bold> Independent test results for different sample sizes. <bold>Figure S2.</bold> MCC and AUC for independent test for different sample sizes.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>AUC</term>
        <def>
          <p id="Par4">Area under ROC curve</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par5">Convolutional Neural Network</p>
        </def>
      </def-item>
      <def-item>
        <term>DL</term>
        <def>
          <p id="Par6">Deep learning</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p id="Par7">Long short-term memory</p>
        </def>
      </def-item>
      <def-item>
        <term>MCC</term>
        <def>
          <p id="Par8">Mathew correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>PTM</term>
        <def>
          <p id="Par9">Post translational modification</p>
        </def>
      </def-item>
      <def-item>
        <term>ReLU</term>
        <def>
          <p id="Par10">Rectified linear unit</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par11">Recurrent neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>ROC</term>
        <def>
          <p id="Par12">Receiver operator characteristics</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12859-020-3342-z.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>Not Applicable.</p>
    <sec id="FPar01">
      <title>About this supplement</title>
      <p id="Par045">This article has been published as part of <italic>BMC Bioinformatics Volume 21 Supplement 3, 2020: Proceedings of the Joint International GIW &amp; ABACBS-2019 Conference: bioinformatics (part 2).</italic> The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-21-supplement-3">https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-21-supplement-3</ext-link>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>DK, SH, RN, KR conceived of and designed the experiments. NT and MC performed the experiments and data analysis. NT, DK, SMM and MC wrote the paper. RN, SH, DK, KR and SMM revised the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by National Science Foundation (NSF) grant nos. 1901793, 1564606 and 1901086 (to DK). RHN is supported by an HBCU-UP Excellence in Research Award from NSF (1901793) and an SC1 Award from the National Institutes of Health National Institute of General Medical Science (5SC1GM130545). HS was supported by JSPS KAKENHI Grant Numbers JP18H01762 and JP19H04176.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets and models analyzed during the current study along with the supplementary materials are available in <ext-link ext-link-type="uri" xlink:href="https://github.com/dukkakc/DeepSuccinylSite">https://github.com/dukkakc/DeepSuccinylSite</ext-link>.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p id="Par47">Not Applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p id="Par48">Not Applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par49">The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Hasan MM, Khatun MS. Prediction of protein Post-Translational Modification sites: An overview. Ann Proteom Bioinform. 2018;2:049-57. 10.29328/journal.apb.1001005.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Medzihradszky</surname>
            <given-names>KF</given-names>
          </name>
        </person-group>
        <article-title>Peptide sequence analysis</article-title>
        <source>Methods Enzymol</source>
        <year>2005</year>
        <volume>402</volume>
        <fpage>209</fpage>
        <lpage>244</lpage>
        <pub-id pub-id-type="doi">10.1016/S0076-6879(05)02007-0</pub-id>
        <pub-id pub-id-type="pmid">16401511</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Agarwal</surname>
            <given-names>KL</given-names>
          </name>
          <name>
            <surname>Kenner</surname>
            <given-names>GW</given-names>
          </name>
          <name>
            <surname>Sheppard</surname>
            <given-names>RC</given-names>
          </name>
        </person-group>
        <article-title>Feline gastrin. An example of peptide sequence analysis by mass spectrometry</article-title>
        <source>J Am Chem Soc</source>
        <year>1969</year>
        <volume>91</volume>
        <issue>11</issue>
        <fpage>3096</fpage>
        <lpage>3097</lpage>
        <pub-id pub-id-type="doi">10.1021/ja01039a051</pub-id>
        <pub-id pub-id-type="pmid">5784957</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Welsch</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Nelsestuen</surname>
            <given-names>GL</given-names>
          </name>
        </person-group>
        <article-title>Amino-terminal alanine functions in a calcium-specific process essential for membrane binding by prothrombin fragment 1</article-title>
        <source>Biochemistry</source>
        <year>1988</year>
        <volume>27</volume>
        <issue>13</issue>
        <fpage>4939</fpage>
        <lpage>4945</lpage>
        <pub-id pub-id-type="doi">10.1021/bi00413a052</pub-id>
        <pub-id pub-id-type="pmid">3167022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Slade</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Subramanian</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Fuhrmann</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Thompson</surname>
            <given-names>PR</given-names>
          </name>
        </person-group>
        <article-title>Chemical and biological methods to detect post-translational modifications of arginine</article-title>
        <source>Biopolymers</source>
        <year>2014</year>
        <volume>101</volume>
        <issue>2</issue>
        <fpage>133</fpage>
        <lpage>143</lpage>
        <pub-id pub-id-type="doi">10.1002/bip.22256</pub-id>
        <pub-id pub-id-type="pmid">23576281</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Umlauf</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Feil</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Site-specific analysis of histone methylation and acetylation</article-title>
        <source>Methods Mol Biol</source>
        <year>2004</year>
        <volume>287</volume>
        <fpage>99</fpage>
        <lpage>120</lpage>
        <?supplied-pmid 15273407?>
        <pub-id pub-id-type="pmid">15273407</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaffrey</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Erdjument-Bromage</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ferris</surname>
            <given-names>CD</given-names>
          </name>
          <name>
            <surname>Tempst</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Snyder</surname>
            <given-names>SH</given-names>
          </name>
        </person-group>
        <article-title>Protein S-nitrosylation: a physiological signal for neuronal nitric oxide</article-title>
        <source>Nat Cell Biol</source>
        <year>2001</year>
        <volume>3</volume>
        <issue>2</issue>
        <fpage>193</fpage>
        <lpage>197</lpage>
        <pub-id pub-id-type="doi">10.1038/35055104</pub-id>
        <pub-id pub-id-type="pmid">11175752</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>YX</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lei</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>LY</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>NY</given-names>
          </name>
        </person-group>
        <article-title>iSuc-PseAAC: predicting lysine succinylation in proteins by incorporating peptide position-specific propensity</article-title>
        <source>Sci Rep</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>10184</fpage>
        <pub-id pub-id-type="doi">10.1038/srep10184</pub-id>
        <pub-id pub-id-type="pmid">26084794</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>iSuc-PseOpt: identifying lysine succinylation sites in proteins by incorporating sequence-coupling effects into pseudo components and optimizing imbalanced training dataset</article-title>
        <source>Anal Biochem</source>
        <year>2016</year>
        <volume>497</volume>
        <fpage>48</fpage>
        <lpage>56</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2015.12.009</pub-id>
        <pub-id pub-id-type="pmid">26723495</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>pSuc-Lys: predict lysine succinylation sites in proteins with PseAAC and ensemble random forest approach</article-title>
        <source>J Theor Biol</source>
        <year>2016</year>
        <volume>394</volume>
        <fpage>223</fpage>
        <lpage>230</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2016.01.020</pub-id>
        <pub-id pub-id-type="pmid">26807806</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hasan</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Mollah</surname>
            <given-names>MNH</given-names>
          </name>
        </person-group>
        <article-title>SuccinSite: a computational tool for the prediction of protein succinylation sites by exploiting the amino acid patterns and properties</article-title>
        <source>Mol BioSyst</source>
        <year>2016</year>
        <volume>12</volume>
        <issue>3</issue>
        <fpage>786</fpage>
        <lpage>795</lpage>
        <pub-id pub-id-type="doi">10.1039/C5MB00853K</pub-id>
        <pub-id pub-id-type="pmid">26739209</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hasan</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Khatun</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Mollah</surname>
            <given-names>MNH</given-names>
          </name>
          <name>
            <surname>Yong</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>A systematic identification of species-specific protein succinylation sites using joint element features information</article-title>
        <source>Int J Nanomedicine</source>
        <year>2017</year>
        <volume>12</volume>
        <fpage>6303</fpage>
        <lpage>6315</lpage>
        <pub-id pub-id-type="doi">10.2147/IJN.S140875</pub-id>
        <pub-id pub-id-type="pmid">28894368</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hasan</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Kurata</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>GPSuc: global prediction of generic and species-specific Succinylation sites by aggregating multiple sequence features</article-title>
        <source>PLoS One</source>
        <year>2018</year>
        <volume>13</volume>
        <issue>10</issue>
        <fpage>e0200283</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0200283</pub-id>
        <pub-id pub-id-type="pmid">30312302</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ning</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Bao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Detecting Succinylation sites from protein sequences using ensemble support vector machine</article-title>
        <source>BMC Bioinformatics</source>
        <year>2018</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>237</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-018-2249-4</pub-id>
        <pub-id pub-id-type="pmid">29940836</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Joshi</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MusiteDeep: a deep-learning framework for general and kinase-specific phosphorylation site prediction</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>24</issue>
        <fpage>3909</fpage>
        <lpage>3916</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx496</pub-id>
        <pub-id pub-id-type="pmid">29036382</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Fenglin Luo, Minghui Wang, Yu Liu, Xing-Ming Zhao, Ao Li. DeepPhos: prediction of protein phosphorylation sites with deep learning, Bioinformatics. 2019;35(16):2766–73.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>DeepUbi: a deep learning framework for prediction of ubiquitination sites in proteins</article-title>
        <source>BMC Bioinformatics</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>86</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-2677-9</pub-id>
        <pub-id pub-id-type="pmid">30777029</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A deep learning method to more accurately recall known lysine acetylation sites</article-title>
        <source>BMC Bioinformatics</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>49</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-2632-9</pub-id>
        <pub-id pub-id-type="pmid">30674277</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Deep learning</article-title>
        <source>Nature</source>
        <year>2015</year>
        <volume>521</volume>
        <fpage>436</fpage>
        <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
        <pub-id pub-id-type="pmid">26017442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Chollet F, et al. Keras; 2015. <ext-link ext-link-type="uri" xlink:href="https://keras.io">https://keras.io</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <collab>D’Informatique Et Recherche Operationnelle D</collab>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ejean Ducharme</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Vincent</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>De Recherche Mathematiques</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <source>A Neural Probabilistic Language Model</source>
        <year>2001</year>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kulmanov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Hoehndorf</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>34</volume>
        <issue>4</issue>
        <fpage>660</fpage>
        <lpage>668</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx624</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kingma</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Adam</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>A Method for Stochastic Optimization</article-title>
        <source>arXiv e-prints [Internet]</source>
        <year>2014</year>
        <volume>01</volume>
        <fpage>2014</fpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kiefer</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wolfowitz</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Stochastic estimation of the maximum of a regression function</article-title>
        <source>Ann Math Stat</source>
        <year>1952</year>
        <volume>23</volume>
        <issue>3</issue>
        <fpage>462</fpage>
        <lpage>466</lpage>
        <pub-id pub-id-type="doi">10.1214/aoms/1177729392</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Jain LC, Medsker LR. Recurrent neural networks: design and applications: CRC press, Inc.; 1999. 416 p.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>#252, Schmidhuber r. long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roy</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kucukural</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>I-TASSER: a unified platform for automated protein structure and function prediction</article-title>
        <source>Nat Protoc</source>
        <year>2010</year>
        <volume>5</volume>
        <issue>4</issue>
        <fpage>725</fpage>
        <lpage>738</lpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2010.5</pub-id>
        <pub-id pub-id-type="pmid">20360767</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>DiMaio</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Leaver-Fay</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bradley</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Andre</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Modeling symmetric macromolecular structures in Rosetta3</article-title>
        <source>PLoS One</source>
        <year>2011</year>
        <volume>6</volume>
        <issue>6</issue>
        <fpage>e20450</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0020450</pub-id>
        <pub-id pub-id-type="pmid">21731614</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
