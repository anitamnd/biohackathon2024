<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName archivearticle.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroscience</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1662-4548</issn>
    <issn pub-type="epub">1662-453X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8603828</article-id>
    <article-id pub-id-type="doi">10.3389/fnins.2021.756876</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Methods</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SSTDP: Supervised Spike Timing Dependent Plasticity for Efficient Spiking Neural Network Training</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Fangxin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn002" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1403320/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhao</surname>
          <given-names>Wenbo</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="fn002" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Yongbiao</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Zongwu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Tao</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Li</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">
          <sup>*</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1341020/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Shanghai Qi Zhi Institute</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>School of Engineering and Applied Science, Columbia Univeristy</institution>, <addr-line>New York, NY</addr-line>, <country>United States</country></aff>
    <aff id="aff4"><sup>4</sup><institution>MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Xing Hu, Institute of Computing Technology, Chinese Academy of Sciences (CAS), China</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Lei Deng, Tsinghua University, China; Timothe Masquelier, Centre National de la Recherche Scientifique (CNRS), France</p>
      </fn>
      <corresp id="c001">*Correspondence: Li Jiang <email>ljiang_cs@sjtu.edu.cn</email></corresp>
      <fn fn-type="other" id="fn001">
        <p>This article was submitted to Neuromorphic Engineering, a section of the journal Frontiers in Neuroscience</p>
      </fn>
      <fn fn-type="equal" id="fn002">
        <p>†These authors have contributed equally to this work</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>04</day>
      <month>11</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>15</volume>
    <elocation-id>756876</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>01</day>
        <month>10</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2021 Liu, Zhao, Chen, Wang, Yang and Jiang.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Liu, Zhao, Chen, Wang, Yang and Jiang</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Spiking Neural Networks (SNNs) are a pathway that could potentially empower low-power event-driven neuromorphic hardware due to their spatio-temporal information processing capability and high biological plausibility. Although SNNs are currently more efficient than artificial neural networks (ANNs), they are not as accurate as ANNs. Error backpropagation is the most common method for directly training neural networks, promoting the prosperity of ANNs in various deep learning fields. However, since the signals transmitted in the SNN are non-differentiable discrete binary spike events, the activation function in the form of spikes presents difficulties for the gradient-based optimization algorithms to be directly applied in SNNs, leading to a performance gap (i.e., accuracy and latency) between SNNs and ANNs. This paper introduces a new learning algorithm, called SSTDP, which bridges the gap between backpropagation (BP)-based learning and spike-time-dependent plasticity (STDP)-based learning to train SNNs efficiently. The scheme incorporates the global optimization process from BP and the efficient weight update derived from STDP. It not only avoids the non-differentiable derivation in the BP process but also utilizes the local feature extraction property of STDP. Consequently, our method can lower the possibility of vanishing spikes in BP training and reduce the number of time steps to reduce network latency. In SSTDP, we employ temporal-based coding and use Integrate-and-Fire (IF) neuron as the neuron model to provide considerable computational benefits. Our experiments show the effectiveness of the proposed SSTDP learning algorithm on the SNN by achieving the best classification accuracy 99.3% on the Caltech 101 dataset, 98.1% on the MNIST dataset, and 91.3% on the CIFAR-10 dataset compared to other SNNs trained with other learning methods. It also surpasses the best inference accuracy of the directly trained SNN with 25~32× less inference latency. Moreover, we analyze event-based computations to demonstrate the efficacy of the SNN for inference operation in the spiking domain, and SSTDP methods can achieve 1.3~37.7× fewer addition operations per inference. The code is available at: <ext-link xlink:href="https://github.com/MXHX7199/SNN-SSTDP" ext-link-type="uri">https://github.com/MXHX7199/SNN-SSTDP</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>spiking neural network</kwd>
      <kwd>gradient descent backpropagation</kwd>
      <kwd>neuromorphic computing</kwd>
      <kwd>spike-time-dependent plasticity</kwd>
      <kwd>deep learning</kwd>
      <kwd>efficient training</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="doi">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn001">61834006</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="10"/>
      <table-count count="4"/>
      <equation-count count="12"/>
      <ref-count count="50"/>
      <page-count count="15"/>
      <word-count count="8520"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>1. Introduction</title>
    <p>Deep neural networks have made tremendous progress and become a prevalent tool for performing various cognitive tasks such as object recognition (Simonyan and Zisserman, <xref rid="B41" ref-type="bibr">2015</xref>; Sandler et al., <xref rid="B39" ref-type="bibr">2018</xref>), natural language processing (Devlin et al., <xref rid="B8" ref-type="bibr">2018</xref>; Radford et al., <xref rid="B36" ref-type="bibr">2019</xref>), and self-driving (Nedevschi et al., <xref rid="B30" ref-type="bibr">2012</xref>; Liu et al., <xref rid="B26" ref-type="bibr">2017</xref>), etc. To leverage the capability of deep neural networks in ubiquitous environments requires deployment not only on large-scale computers but also on portable edge devices (Han and Roy, <xref rid="B13" ref-type="bibr">2020</xref>; Deng et al., <xref rid="B6" ref-type="bibr">2021</xref>). However, the increasing complexity of deep neural networks, coupled with data flooding with distributed sensors continuously generates real-time content and places tremendous energy demands on current computing platforms. Spiking Neural Networks (SNNs) are often regarded as third-generation brain-inspired neural networks, and represent one of the leading candidates for overcoming computational constraints and efficiently exploiting deep learning algorithms in real (or mobile) applications whilst also being highly power-efficient (Deng et al., <xref rid="B7" ref-type="bibr">2020</xref>; Rathi et al., <xref rid="B37" ref-type="bibr">2020</xref>; Taherkhani et al., <xref rid="B43" ref-type="bibr">2020</xref>).</p>
    <p>SNNs consist of spiking neurons that transmit information in the form of electric event spikes via plastic synapses (Taherkhani et al., <xref rid="B43" ref-type="bibr">2020</xref>). Event-driven computing capability is the fundamental characteristic of SNNs, supporting sparse and irregular input spike train, thereby reducing latency and power consumption of computation and communication (Lee et al., <xref rid="B23" ref-type="bibr">2018</xref>). With the development of neuromorphic hardware supporting the SNN, such as Intel Loihi (Davies et al., <xref rid="B5" ref-type="bibr">2018</xref>) and IBM TrueNorth (Akopyan et al., <xref rid="B1" ref-type="bibr">2015</xref>), SNNs have gained increasing attention in both academia and industry. To date, shallow SNN structures (i.e., two fully connected layers) have been widely used for classification. However, training high-performance SNNs with competitive classification accuracy and less latency is a nontrivial problem, limiting their scalability in complex applications (Benjamin et al., <xref rid="B3" ref-type="bibr">2014</xref>; Roy et al., <xref rid="B38" ref-type="bibr">2019</xref>; Sengupta et al., <xref rid="B40" ref-type="bibr">2019</xref>; Comsa et al., <xref rid="B4" ref-type="bibr">2020</xref>; Han et al., <xref rid="B14" ref-type="bibr">2020</xref>; Deng et al., <xref rid="B6" ref-type="bibr">2021</xref>).</p>
    <p>The existing training strategy for SNNs can be broadly divided into two categories, unsupervised learning and supervised learning (Roy et al., <xref rid="B38" ref-type="bibr">2019</xref>). Unsupervised learning discovers the underlying features and structure of input data without using the corresponding labels. Spike-time-dependent plasticity (STDP) is a bio-plausible unsupervised learning mechanism that exploits the temporal difference between pre-and post-synaptic neuronal spikes to modulate the weights of neural synapses instantaneously (Pfister and Gerstner, <xref rid="B35" ref-type="bibr">2006</xref>; Diehl and Cook, <xref rid="B9" ref-type="bibr">2015</xref>; Bellec et al., <xref rid="B2" ref-type="bibr">2018</xref>). It is a simple and fast training method that reflects the temporal correlations of pre-and post-synaptic spikes between neighboring (local) layers. However, the classification accuracy of SNNs trained based on the unsupervised learning represented by STDP is still lower than the results presented by state-of-the-art Artificial Neural Networks (ANNs). When it comes to supervised learning, it extracts internal features and structure given the training examples and target labels. The standard backpropagation (BP) is normally used for achieving state-of-art classification performance in ANNs by updating the network parameters to minimize the final output error of the network (He et al., <xref rid="B16" ref-type="bibr">2016</xref>). The corresponding loss function is defined as the difference between the predicted output of the network and the expected target output (label). Meanwhile, the SNNs trained by supervised learning can achieve much better performance than the unsupervised ones, triggering recent works to use the BP-based learning algorithm to train SNNs by input binary spike events. However, training such SNNs is quite difficult. Since the spiking neurons communicate through discrete, non-differentiable spike events, which is fundamentally different from the continuous activations of non-spiking neurons such as the ReLU function in ANNs, it is impossible to transfer the BP-based learning mechanism to SNNs directly (Wu et al., <xref rid="B45" ref-type="bibr">2021</xref>).</p>
    <p>There have been some successful attempts to introduce the BP-based learning mechanisms into SNNs (Lee et al., <xref rid="B24" ref-type="bibr">2016</xref>; Tavanaei et al., <xref rid="B44" ref-type="bibr">2019</xref>; Zhou et al., <xref rid="B50" ref-type="bibr">2019</xref>; Kheradpisheh et al., <xref rid="B18" ref-type="bibr">2020</xref>; Fang et al., <xref rid="B10" ref-type="bibr">2021</xref>; Mirsadeghi et al., <xref rid="B28" ref-type="bibr">2021</xref>). The first approach is the spike-based BP, which treats the membrane potentials as differentiable activations of spiking neurons and trains the synaptics of SNNs in a layer-wise fashion (Tavanaei et al., <xref rid="B44" ref-type="bibr">2019</xref>). The second approach is to use spike rates (frequency) to substitute the non-differentiable spike events (Liu et al., <xref rid="B25" ref-type="bibr">2015</xref>). Although these two types of methods are suitable for gradient descent learning, it requires complicated procedures for computing the derivative of the loss function in spatial and temporal domains. The third approach is approximate methods, which estimate the surrogate gradient of the spike generation function (Mirsadeghi et al., <xref rid="B28" ref-type="bibr">2021</xref>). However, this kind of approach incurs the strong assumption in backpropagating the error through the network using the chain rule. For instance, recent work proposes S4NN (Kheradpisheh et al., <xref rid="B18" ref-type="bibr">2020</xref>), where they use a temporal version of the traditional BP-based learning to train a multi-layer SNN consisting of IF neurons. This method approximates the derivative of time with respect to the potential as −1 in the backpropagation process. Meanwhile, none of these methods take into account the temporal dynamics between pre-and post-synaptic spike timings and are efficient for hardware implementation with rate coding.</p>
    <p>It is unclear which learning algorithm (i.e., unsupervised learning algorithm or supervised learning algorithm) is suitable for training the SNN (Roy et al., <xref rid="B38" ref-type="bibr">2019</xref>; Deng et al., <xref rid="B7" ref-type="bibr">2020</xref>, <xref rid="B6" ref-type="bibr">2021</xref>; Lobo et al., <xref rid="B27" ref-type="bibr">2020</xref>). Both STDP and spike-based BP learning have been demonstrated they can effectively capture the hierarchical features in SNN. On the one hand, the spiking neural networks trained solely on STDP-based methods lack competitive classification performance. On the other, BP-based SNN training methods usually lead to unstable convergence, and a slight variance on the hyper-parameters will have a great impact on the result. For these reasons, this study proposes utilizing STDP-based unsupervised learning to encourage the hidden layer to discover the local features and structures of the input patterns. In combination with the gradient-based supervised algorithm, it will guide the optimization in a global manner. The multi-layer spiking neural network consists of convolutional layers and pooling layers, followed by successive fully connected layers. Bio-plausible integrate-and-fire spiking neurons populate the layers in the SNN to process sparse spike trains that encode pixel intensities as the precise timing of spikes (temporal coding).</p>
    <p>The first main contribution of this work is that it uses a time-based supervised learning method that employs the weight update mechanism derived from STDP to bypass the non-differentiable nature of the spike generation function in the BP process. In addition, we efficiently construct SNN architectures for different tasks, such as convolutional SNN for the large dataset (i.e., CIFAR-10), fully-connected SNN for the small dataset (i.e., Caltech 101 and MNIST). Next, we demonstrate the effectiveness of this methodology for visual recognition tasks on standard datasets (Caltech 101, MNIST, CIFAR-10). Finally, this study quantifies and analyzes the advantages of the proposed learning method compared to prior techniques in terms of latency and energy consumption. To the best of our knowledge, this work achieves the best performance SNN with the shortest latency (i.e., the number of time steps) in Caltech 101, MNIST, and CIFAR-10 datasets, among other learning methods.</p>
    <p>Section 2 reviews related works and introduces the motivation of our work. Section 3 elaborates the proposed SSTDP learning algorithm. Section 4 then presents the experimental results, including experimental setups and evaluation metrics. It also discusses the comparison results with the recent works in terms of network performance, latency, and energy efficiency. Section 5 concludes the paper.</p>
  </sec>
  <sec id="s2">
    <title>2. Related Work</title>
    <sec>
      <title>2.1. STDP Methods</title>
      <p>The STDP-based learning algorithm is a bio-plausible learning mechanism for SNNs. It is a promising approach that could improve the information processing capability of neurons by specifying different synapses for various types of input data and providing dynamic control over plasticity (Ferré et al., <xref rid="B12" ref-type="bibr">2018</xref>; Kheradpisheh et al., <xref rid="B17" ref-type="bibr">2018</xref>; Taherkhani et al., <xref rid="B43" ref-type="bibr">2020</xref>).</p>
      <p>As shown in <xref rid="F1" ref-type="fig">Figure 1B</xref>, the STDP-based learning algorithm is based on the temporal correlation (Δ<italic toggle="yes">t</italic> = <italic toggle="yes">t</italic><sub><italic toggle="yes">post</italic></sub> − <italic toggle="yes">t</italic><sub><italic toggle="yes">pre</italic></sub>) between spike-time <italic toggle="yes">t</italic><sub><italic toggle="yes">pre</italic></sub> of the pre-synaptic neuron and spike-time <italic toggle="yes">t</italic><sub><italic toggle="yes">post</italic></sub> of the post-synaptic neuron to adjust the synapse weight as described in previous research tasks. Specifically, if the spike arrives at the pre-synaptic neuron <italic toggle="yes">t</italic><sub><italic toggle="yes">pre</italic></sub> earlier than the post-synaptic neuron fires the spike <italic toggle="yes">t</italic><sub><italic toggle="yes">post</italic></sub> within a given time window, the synapse weight is increased, which is called synaptic potentiation. The synaptic depression behavior is similar to potentiation. If the post-synaptic neuron fires the spike <italic toggle="yes">t</italic><sub><italic toggle="yes">post</italic></sub> later than the spike arrives at the pre-synaptic neuron <italic toggle="yes">t</italic><sub><italic toggle="yes">pre</italic></sub>, the synapse weight is reduced and is referred to as a synaptic depression.</p>
      <fig position="float" id="F1">
        <label>Figure 1</label>
        <caption>
          <p>An example of BP-based learning and STDP-based learning. <bold>(A)</bold> Forward and backward propagation of the SNN. <bold>(B)</bold> If the post-synaptic neuron fires after the pre-synaptic spike arrives, the synaptic weight between pre- and post-synaptic neuron increases. The magnitude of change increases in proportion to Δ<italic toggle="yes">t</italic><sub><italic toggle="yes">pot</italic></sub>. The reverse order leads to a decrease in synaptic weight in proportion to Δ<italic toggle="yes">t</italic><sub><italic toggle="yes">dep</italic></sub>.</p>
        </caption>
        <graphic xlink:href="fnins-15-756876-g0001" position="float"/>
      </fig>
      <p>The STDP-based unsupervised feature learning using convolution-over-time in SNNs is proposed to encode representative input features (Srinivasan et al., <xref rid="B42" ref-type="bibr">2018</xref>). The triplet STDP uses local variables called traces, as proposed in Pfister and Gerstner (<xref rid="B35" ref-type="bibr">2006</xref>). The traces associated with pre-synaptic neurons and post-synaptic neurons corresponding to two traces with fast and slow dynamics, respectively, to better extract the spiking dynamic features. A notable semi-supervised learning method based on STDP is outlined in the work of Lee et al. (<xref rid="B23" ref-type="bibr">2018</xref>), which uses STDP-based unsupervised learning to better initialize the parameters in pre-trained SNN and follows gradient-based supervised optimization. Tavanaei et al. (<xref rid="B44" ref-type="bibr">2019</xref>) proposed a learning rule that updates the synaptic weights using a teacher signal to switch between STDP and anti-STDP. However, it updates weights that only use local update rules and do not involve the gradient update mechanism of STDP. For all the methods mentioned above, all of which are based on STDP, the classification accuracy obtained from training is still lower than state-of-the-art results. Meanwhile, they all use rate-based coding to encode the information (i.e., multi-spikes in the spike train) and do not deal with time-based information directly (i.e., a single spike).</p>
    </sec>
    <sec>
      <title>2.2. BP Methods</title>
      <p>As illustrated in <xref rid="F1" ref-type="fig">Figure 1A</xref>, the backpropagation algorithm is one successful method for training deep SNNs (Deng et al., <xref rid="B7" ref-type="bibr">2020</xref>; Taherkhani et al., <xref rid="B43" ref-type="bibr">2020</xref>). Although the spike-based BP algorithm can achieve better accuracy than the STDP-based learning algorithm (Kheradpisheh et al., <xref rid="B18" ref-type="bibr">2020</xref>; Rathi et al., <xref rid="B37" ref-type="bibr">2020</xref>; Mirsadeghi et al., <xref rid="B28" ref-type="bibr">2021</xref>), it suffers from the same fundamental disadvantage: the computation of neurons theoretically occurs at the spike neuron and requires massive data and effort. Therefore, exploring the BP algorithm for temporal encoding is more efficient for hardware implementation. Meanwhile, considering that existing neuromorphic systems are time-driven execution mechanisms, for such systems, the computation of neurons occurs at each time step, and reducing the number of time steps while improving accuracy, should also be considered.</p>
    </sec>
  </sec>
  <sec id="s3">
    <title>3. Approach</title>
    <p>This paper proposes a novel learning method for the SNN with an accurate gradient descent mechanism and an efficient temporal local update mechanism by incorporating BP and STDP training methods. Thus, our method can effectively balance global and local information during training and can address some open questions regarding accurate and efficient computations.</p>
    <sec>
      <title>3.1. Spiking Neural Network Components</title>
      <sec>
        <title>3.1.1. Network Architecture</title>
        <p>In <xref rid="F2" ref-type="fig">Figure 2</xref> describes the typical network architecture of ANN and SNN, which was used for the classification task. In the first layer, inputs that feed to the neuron are pixels of the input image in the ANN, while in the SNN, these pixels are converted into spike trains. In the hidden layer, non-spiking neurons in the ANN perform Multiply Accumulate (MAC) operations and then pass the result through the activation function (e.g., ReLU function) to generate the input for the next layer. In contrast, in SNN, each spiking neuron integrates weighted spikes and fires the output spike when the membrane potential exceeds the threshold potential. In the final output layer, each category corresponds to one neuron. The loss function of the output layer is defined as the difference between the predicted value and the expected value.</p>
        <fig position="float" id="F2">
          <label>Figure 2</label>
          <caption>
            <p>A multi-layer neural network is composed of an input layer, one or more hidden layers, and an output layer. The workload of natural ANN training with real-valued activation <bold>(A)</bold>; and SNN training with spatio-temporal spike trains <bold>(B)</bold>.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0002" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.1.2. Information Encoding</title>
        <p>During the inference, the real-valued pixel intensities of the input image are converted to the sparse spiking events over a certain time window. The time step is used to record the spike timing, and the number of time steps (also known as network latency) required is determined by the expected inference accuracy. Thus, inference in SNNs is performed on multiple feed-forward processes equal to the number of time steps, where each process requires computations based on sparse spikes. As shown in <xref rid="F3" ref-type="fig">Figure 3</xref>, the two dominant coding methods are rate-based coding (<xref rid="F3" ref-type="fig">Figure 3A</xref>) and time-based coding (<xref rid="F3" ref-type="fig">Figure 3B</xref>) for SNNs. The rate-based coding scheme encodes the intensity of a pixel into the number of spikes, while the time-based coding scheme encodes the information as the latency to the first spike of the corresponding spike train. In the SNN with the rate-based coding scheme, massive spikes are fired to achieve accuracy comparable to the ANN, which leads to high computational costs. Therefore, the memory access and computational costs remain lower than the rate-based coding since time-based coding has only a single spike in the spike train.</p>
        <fig position="float" id="F3">
          <label>Figure 3</label>
          <caption>
            <p>An example about the input image is converted into the input spike train by the <bold>(A)</bold> rate-based coding scheme (Han et al., <xref rid="B14" ref-type="bibr">2020</xref>) and <bold>(B)</bold> Time-To-First-Spike time-based coding scheme (Rathi et al., <xref rid="B37" ref-type="bibr">2020</xref>). The time window represents the length of the spike train, which is equal to the number of time steps.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0003" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.1.3. Neuron Dynamics</title>
        <p>We use the biologically plausible Integrate-and-Fire (IF) neuron to simulate the dynamics of a spiking neuron that is driven by the input spike train via plastic synapses. The IF neuron <italic toggle="yes">i</italic> integrates the input spikes <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> into the current <italic toggle="yes">I</italic>(<italic toggle="yes">t</italic>) by the transmitted inter-connecting synaptic weights <italic toggle="yes">w</italic><sub><italic toggle="yes">i</italic></sub> of the corresponding spike and then accumulates it into the membrane potential <italic toggle="yes">V</italic><sub><italic toggle="yes">m</italic></sub>, leading to a change in its membrane potential (<italic toggle="yes">V</italic><sub><italic toggle="yes">m</italic></sub>). The temporal dynamics are formulated below.</p>
        <disp-formula id="E1">
          <label>(1)</label>
          <mml:math id="M1" overflow="scroll">
            <mml:mrow>
              <mml:mo>{</mml:mo>
              <mml:mrow>
                <mml:mtable columnalign="left">
                  <mml:mtr columnalign="left">
                    <mml:mtd columnalign="left">
                      <mml:mrow>
                        <mml:mtext>   </mml:mtext>
                        <mml:mi>I</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mi>t</mml:mi>
                        <mml:mo stretchy="false">)</mml:mo>
                        <mml:mo>=</mml:mo>
                        <mml:mstyle displaystyle="true">
                          <mml:munder>
                            <mml:mo>∑</mml:mo>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mo>∈</mml:mo>
                              <mml:mo>{</mml:mo>
                              <mml:mi>i</mml:mi>
                              <mml:mo>|</mml:mo>
                              <mml:msub>
                                <mml:mi>X</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:msub>
                              <mml:mo stretchy="false">(</mml:mo>
                              <mml:mi>t</mml:mi>
                              <mml:mo stretchy="false">)</mml:mo>
                              <mml:mo>=</mml:mo>
                              <mml:mn>1</mml:mn>
                              <mml:mo>}</mml:mo>
                            </mml:mrow>
                          </mml:munder>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mi>w</mml:mi>
                              <mml:mi>i</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                        </mml:mstyle>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                  <mml:mtr columnalign="left">
                    <mml:mtd columnalign="left">
                      <mml:mrow>
                        <mml:mfrac>
                          <mml:mrow>
                            <mml:mtext>d</mml:mtext>
                            <mml:msub>
                              <mml:mi>V</mml:mi>
                              <mml:mi>m</mml:mi>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mtext>d</mml:mtext>
                            <mml:mi>t</mml:mi>
                          </mml:mrow>
                        </mml:mfrac>
                        <mml:mo>=</mml:mo>
                        <mml:mi>I</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mi>t</mml:mi>
                        <mml:mo stretchy="false">)</mml:mo>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>Since the input values in SNN are binary spikes (i.e., “1” or “0”), the mathematical dot product operation in ANNs can be replaced by the addition in SNNs. When the accumulated membrane potential reaches a certain firing threshold, the neuron fires an output spike and then resets membrane potential. The reset mechanisms help regulate the spiking activities of the post-neurons.</p>
      </sec>
    </sec>
    <sec>
      <title>3.2. Proposed SNN Training Methodology</title>
      <sec>
        <title>3.2.1. Forward Propagation</title>
        <p><xref rid="F4" ref-type="fig">Figure 4</xref> provides an overview of the SSTDP algorithm. SSTDP consists of multiple layers since the number and type of neurons (i.e., IF and LIF neurons) and layers (i.e., fully connected and convolutional layers) are not limited. Hence, one can implement SSTDP with any arbitrary number and type of hidden layers. According to Equation 1, the membrane potential <italic toggle="yes">V</italic><sub><italic toggle="yes">j</italic></sub>(<italic toggle="yes">t</italic>) of the <italic toggle="yes">j</italic>-th neuron at time step <italic toggle="yes">t</italic><sub><italic toggle="yes">s</italic></sub> is computed as follows:</p>
        <disp-formula id="E2">
          <label>(2)</label>
          <mml:math id="M2" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mi>V</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:msub>
                <mml:mi>t</mml:mi>
                <mml:mi>s</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">)</mml:mo>
              <mml:mo>=</mml:mo>
              <mml:msub>
                <mml:mi>V</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:msub>
                <mml:mi>t</mml:mi>
                <mml:mi>s</mml:mi>
              </mml:msub>
              <mml:mo>−</mml:mo>
              <mml:mn>1</mml:mn>
              <mml:mo stretchy="false">)</mml:mo>
              <mml:mo>+</mml:mo>
              <mml:mstyle displaystyle="true">
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mi>i</mml:mi>
                </mml:munder>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>w</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mstyle>
              <mml:msub>
                <mml:mi>X</mml:mi>
                <mml:mi>i</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:msub>
                <mml:mi>t</mml:mi>
                <mml:mi>s</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">)</mml:mo>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">t</italic><sub><italic toggle="yes">s</italic></sub>) is the input spike train from the <italic toggle="yes">i</italic>-th pre-synaptic neuron, <italic toggle="yes">w</italic><sub><italic toggle="yes">ij</italic></sub> is the synaptic weight between the <italic toggle="yes">i</italic>-th pre-synaptic neuron and <italic toggle="yes">j</italic>-th post-synaptic neuron. The IF neuron fires a output spike with the time-based coding when its membrane potential exceeds the firing threshold θ<sub><italic toggle="yes">j</italic></sub> (&gt; 0):</p>
        <disp-formula id="E3">
          <label>(3)</label>
          <mml:math id="M3" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mi>X</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:msub>
                <mml:mi>t</mml:mi>
                <mml:mi>s</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">)</mml:mo>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mo>{</mml:mo>
                <mml:mrow>
                  <mml:mtable columnalign="left">
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mtext>if </mml:mtext>
                          <mml:msub>
                            <mml:mi>V</mml:mi>
                            <mml:mi>j</mml:mi>
                          </mml:msub>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:msub>
                            <mml:mi>t</mml:mi>
                            <mml:mi>s</mml:mi>
                          </mml:msub>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo>≤</mml:mo>
                          <mml:msub>
                            <mml:mi>θ</mml:mi>
                            <mml:mi>j</mml:mi>
                          </mml:msub>
                          <mml:mtext> and </mml:mtext>
                          <mml:msub>
                            <mml:mi>X</mml:mi>
                            <mml:mi>j</mml:mi>
                          </mml:msub>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mo>&lt;</mml:mo>
                          <mml:msub>
                            <mml:mi>t</mml:mi>
                            <mml:mi>s</mml:mi>
                          </mml:msub>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo>≠</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mtext>otherwise </mml:mtext>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <italic toggle="yes">X</italic><sub><italic toggle="yes">j</italic></sub>(&lt; <italic toggle="yes">t</italic>) ≠ 1 denotes to check whether the <italic toggle="yes">j</italic>-th neuron was not fired at any previous time step (&lt; <italic toggle="yes">t</italic><sub><italic toggle="yes">s</italic></sub>). In time-based coding, information is encoded using the spike time <italic toggle="yes">t</italic><sub><italic toggle="yes">s</italic></sub> of a single spike. Generally, the larger integration current is due to input spikes with larger corresponding weights. In such a scenario, a larger integration current corresponds to the possibility of the earlier fire spike, which in event-driven neuromorphic hardware can terminate the computation of the neuron earlier. Note that in the last layer (fully connected layer) in the network, the number of neurons corresponds to the number of task categories, where each neuron may fire a single spike at a different time step. After completing the forward process over the entire forward propagation time (i.e., several time-steps in the spiking domain), the category of an input image is predicted by the SNN as the category corresponding to the winner output neuron that fires the earliest spike. Since the network decision is based on the first fired spike in the last layer, earlier fired spikes carry more information in the spike train.</p>
        <fig position="float" id="F4">
          <label>Figure 4</label>
          <caption>
            <p>The illustration of the forward process and error backpropagation in the SSTDP method. The blue frame arrows represent forward propagation, and the red frame arrows represent backward propagation. In the forward phase, the neurons in the SNN integrate the received spikes with corresponding weights into the membrane potential and calculate the error based on the prediction results of the network. In the backward phase, the final error is backward past through the hidden layers based on the chain rule to obtain the partial derivative of the final error with respect to the time. The synaptic weights are modified with spatial (local weight updates from STDP) and temporal information (globally rectified from BP) to reduce the network error.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0004" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.2.2. Backward Propagation</title>
        <p>To utilize backward propagation to update the weights in the neural network, we need to obtain the derivative of the loss function with respect to each weight, <italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., <inline-formula><mml:math id="M4" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></inline-formula>, where <italic toggle="yes">E</italic> is the loss function, and <italic toggle="yes">w</italic><sup><italic toggle="yes">l</italic></sup> is a weight at the <italic toggle="yes">l</italic><sup><italic toggle="yes">th</italic></sup> layer.</p>
        <p>In our method, the output neuron that spikes first carries the most significant signal and thus corresponds to the output label. To separate the firing time of the target neuron and others, we set a minimum gap <italic toggle="yes">g</italic> between their expected firing times. Taking the average firing time of each sample into consideration, we set the expected firing time as the following equations:</p>
        <disp-formula id="E4">
          <label>(4)</label>
          <mml:math id="M5" overflow="scroll">
            <mml:mrow>
              <mml:msub>
                <mml:mi>T</mml:mi>
                <mml:mrow>
                  <mml:mtext>mean</mml:mtext>
                </mml:mrow>
              </mml:msub>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mn>1</mml:mn>
                <mml:mi>n</mml:mi>
              </mml:mfrac>
              <mml:mstyle displaystyle="true">
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>n</mml:mi>
                </mml:munderover>
                <mml:mrow>
                  <mml:msubsup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>L</mml:mi>
                  </mml:msubsup>
                </mml:mrow>
              </mml:mstyle>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="E5">
          <label>(5)</label>
          <mml:math id="M6" overflow="scroll">
            <mml:mrow>
              <mml:msubsup>
                <mml:mi>T</mml:mi>
                <mml:mi>j</mml:mi>
                <mml:mi>L</mml:mi>
              </mml:msubsup>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mo>{</mml:mo>
                <mml:mrow>
                  <mml:mtable columnalign="left">
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mi>min</mml:mi>
                          <mml:mo>{</mml:mo>
                          <mml:msubsup>
                            <mml:mi>t</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mi>L</mml:mi>
                          </mml:msubsup>
                          <mml:mo>,</mml:mo>
                          <mml:mtext> </mml:mtext>
                          <mml:msub>
                            <mml:mi>T</mml:mi>
                            <mml:mrow>
                              <mml:mtext>mean</mml:mtext>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>−</mml:mo>
                          <mml:mfrac>
                            <mml:mrow>
                              <mml:mi>n</mml:mi>
                              <mml:mo>−</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                            <mml:mi>n</mml:mi>
                          </mml:mfrac>
                          <mml:mi>g</mml:mi>
                          <mml:mo>}</mml:mo>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mi>j</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mi>y</mml:mi>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mi>max</mml:mi>
                          <mml:mo>{</mml:mo>
                          <mml:msubsup>
                            <mml:mi>t</mml:mi>
                            <mml:mi>j</mml:mi>
                            <mml:mi>L</mml:mi>
                          </mml:msubsup>
                          <mml:mo>,</mml:mo>
                          <mml:mtext> </mml:mtext>
                          <mml:msub>
                            <mml:mi>T</mml:mi>
                            <mml:mrow>
                              <mml:mtext>mean</mml:mtext>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>+</mml:mo>
                          <mml:mfrac>
                            <mml:mn>1</mml:mn>
                            <mml:mi>n</mml:mi>
                          </mml:mfrac>
                          <mml:mi>g</mml:mi>
                          <mml:mo>}</mml:mo>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mi>j</mml:mi>
                          <mml:menclose notation="updiagonalstrike">
                            <mml:mo>=</mml:mo>
                          </mml:menclose>
                          <mml:mi>y</mml:mi>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <italic toggle="yes">n</italic> is the number of output spikes, <italic toggle="yes">y</italic> is the correct label, <inline-formula><mml:math id="M7" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the actual firing time, and <inline-formula><mml:math id="M8" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the expected firing time. Such settings maintain the average expected firing time near the actual one to fit the firing time of each input sample and achieve better adaptation. The expected firing time of the target label is the smallest one among all output neurons with a minimum gap <italic toggle="yes">g</italic> with others to distinguish it well.</p>
        <p>Then, the loss function can be defined as the squared error of the bias between actual firing time and expected firing time:</p>
        <disp-formula id="E6">
          <label>(6)</label>
          <mml:math id="M9" overflow="scroll">
            <mml:mrow>
              <mml:mi>E</mml:mi>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mn>1</mml:mn>
                <mml:mn>2</mml:mn>
              </mml:mfrac>
              <mml:mstyle displaystyle="true">
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mi>j</mml:mi>
                </mml:munder>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>e</mml:mi>
                    <mml:mi>j</mml:mi>
                  </mml:msub>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mtext> </mml:mtext>
                    </mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:msup>
                </mml:mrow>
              </mml:mstyle>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <inline-formula><mml:math id="M10" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p>
        <p>Then, the gradient to the loss function can be estimated at the output layer, <inline-formula><mml:math id="M11" overflow="scroll"><mml:mi>∂</mml:mi><mml:mi>E</mml:mi><mml:mo>/</mml:mo><mml:mi>∂</mml:mi><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and the gradient is backward propagated to the hidden layers using the chain rule, as shown in the following equation:</p>
        <disp-formula id="E7">
          <label>(7)</label>
          <mml:math id="M12" overflow="scroll">
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>E</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>w</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
              </mml:mfrac>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>E</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
              </mml:mfrac>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>V</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
              </mml:mfrac>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>V</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>w</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where <italic toggle="yes">V</italic><sup><italic toggle="yes">l</italic></sup> and <italic toggle="yes">t</italic><sup><italic toggle="yes">l</italic></sup> is the membrane potential and the fired spike-time of a neuron in the <italic toggle="yes">l</italic>-th layer.</p>
        <p>As mentioned above, the term <inline-formula><mml:math id="M13" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></inline-formula> in Equation 7, i.e., the derivative of the post-synaptic fired spike-time with respect to its membrane potential, is not differentiable. In previous works, the derivative was estimated with various assumptions and approximations. However, estimating both ∂<italic toggle="yes">t</italic><sup><italic toggle="yes">l</italic></sup>/∂<italic toggle="yes">V</italic><sup><italic toggle="yes">l</italic></sup> and ∂<italic toggle="yes">V</italic><sup><italic toggle="yes">l</italic></sup>/∂<italic toggle="yes">w</italic><sup><italic toggle="yes">l</italic></sup> makes the result biased and unreliable. Therefore, our method circumvents these two non-derivable terms and merges the latter two terms into a single one:</p>
        <disp-formula id="E8">
          <label>(8)</label>
          <mml:math id="M14" overflow="scroll">
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:mi>E</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>w</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
              </mml:mfrac>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:mi>E</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
              </mml:mfrac>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msup>
                    <mml:mi>w</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>According to the definition of spike-time-dependent plasticity, if the pre-synaptic spike happens before the post-synaptic one, the connection will be strengthened, making the post-synaptic spike easier to fire, and if the pre-synaptic spike occurs after the post-synaptic one, the connection is useless, and thus the weight will be reduced. Such a proposal will always make the post-synaptic spike fire earlier, neglecting the actual update direction of the post-synaptic neuron. Therefore, we only calculate the derivative between post-synaptic firing time and the weight <inline-formula><mml:math id="M15" overflow="scroll"><mml:mi>∂</mml:mi><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>/</mml:mo><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> using STDP:</p>
        <disp-formula id="E9">
          <label>(9)</label>
          <mml:math id="M16" overflow="scroll">
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msubsup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msubsup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msub>
                    <mml:mi>w</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mfrac>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mo>{</mml:mo>
                <mml:mrow>
                  <mml:mtable columnalign="left">
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>ϵ</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:msub>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:msup>
                            <mml:mi>e</mml:mi>
                            <mml:mrow>
                              <mml:mo>−</mml:mo>
                              <mml:mfrac>
                                <mml:mrow>
                                  <mml:msub>
                                    <mml:mi>t</mml:mi>
                                    <mml:mrow>
                                      <mml:mi>p</mml:mi>
                                      <mml:mi>o</mml:mi>
                                      <mml:mi>s</mml:mi>
                                      <mml:mi>t</mml:mi>
                                    </mml:mrow>
                                  </mml:msub>
                                  <mml:mo>−</mml:mo>
                                  <mml:msub>
                                    <mml:mi>t</mml:mi>
                                    <mml:mrow>
                                      <mml:mi>p</mml:mi>
                                      <mml:mi>r</mml:mi>
                                      <mml:mi>e</mml:mi>
                                    </mml:mrow>
                                  </mml:msub>
                                </mml:mrow>
                                <mml:mi>τ</mml:mi>
                              </mml:mfrac>
                            </mml:mrow>
                          </mml:msup>
                          <mml:mo>−</mml:mo>
                          <mml:mi>δ</mml:mi>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo>×</mml:mo>
                          <mml:msup>
                            <mml:mrow>
                              <mml:mo stretchy="false">(</mml:mo>
                              <mml:msub>
                                <mml:mi>w</mml:mi>
                                <mml:mrow>
                                  <mml:mi>m</mml:mi>
                                  <mml:mi>a</mml:mi>
                                  <mml:mi>x</mml:mi>
                                </mml:mrow>
                              </mml:msub>
                              <mml:mo>−</mml:mo>
                              <mml:mi>w</mml:mi>
                              <mml:mo stretchy="false">)</mml:mo>
                            </mml:mrow>
                            <mml:mi>μ</mml:mi>
                          </mml:msup>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>t</mml:mi>
                            <mml:mrow>
                              <mml:mi>p</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>s</mml:mi>
                              <mml:mi>t</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>&gt;</mml:mo>
                          <mml:msub>
                            <mml:mi>t</mml:mi>
                            <mml:mrow>
                              <mml:mi>p</mml:mi>
                              <mml:mi>r</mml:mi>
                              <mml:mi>e</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>ϵ</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:msup>
                            <mml:mi>e</mml:mi>
                            <mml:mrow>
                              <mml:mo>−</mml:mo>
                              <mml:mfrac>
                                <mml:mrow>
                                  <mml:msub>
                                    <mml:mi>t</mml:mi>
                                    <mml:mrow>
                                      <mml:mi>p</mml:mi>
                                      <mml:mi>r</mml:mi>
                                      <mml:mi>e</mml:mi>
                                    </mml:mrow>
                                  </mml:msub>
                                  <mml:mo>−</mml:mo>
                                  <mml:msub>
                                    <mml:mi>t</mml:mi>
                                    <mml:mrow>
                                      <mml:mi>p</mml:mi>
                                      <mml:mi>o</mml:mi>
                                      <mml:mi>s</mml:mi>
                                      <mml:mi>t</mml:mi>
                                    </mml:mrow>
                                  </mml:msub>
                                </mml:mrow>
                                <mml:mi>τ</mml:mi>
                              </mml:mfrac>
                            </mml:mrow>
                          </mml:msup>
                          <mml:mo>−</mml:mo>
                          <mml:mi>δ</mml:mi>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mo>×</mml:mo>
                          <mml:msup>
                            <mml:mrow>
                              <mml:mo stretchy="false">(</mml:mo>
                              <mml:msub>
                                <mml:mi>w</mml:mi>
                                <mml:mrow>
                                  <mml:mi>m</mml:mi>
                                  <mml:mi>a</mml:mi>
                                  <mml:mi>x</mml:mi>
                                </mml:mrow>
                              </mml:msub>
                              <mml:mo>−</mml:mo>
                              <mml:mi>w</mml:mi>
                              <mml:mo stretchy="false">)</mml:mo>
                            </mml:mrow>
                            <mml:mi>μ</mml:mi>
                          </mml:msup>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>t</mml:mi>
                            <mml:mrow>
                              <mml:mi>p</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>s</mml:mi>
                              <mml:mi>t</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>&lt;</mml:mo>
                          <mml:msub>
                            <mml:mi>t</mml:mi>
                            <mml:mrow>
                              <mml:mi>p</mml:mi>
                              <mml:mi>r</mml:mi>
                              <mml:mi>e</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where ϵ<sub>1,2</sub> is the scaling factor of strengthening and restraining STDP, τ is the time constant, <italic toggle="yes">t</italic><sub><italic toggle="yes">pre</italic></sub> and <italic toggle="yes">t</italic><sub><italic toggle="yes">post</italic></sub> are the fired spike-time of a pair of pre- and post-neuron, respectively. δ represents the time interval for updating the weights in STDP, which means the spikes that occurred within this period, making a strong causal relationship between the corresponding pair of pre- and post-neuron. <italic toggle="yes">w</italic><sub><italic toggle="yes">max</italic></sub> and <italic toggle="yes">w</italic> are the maximum constraint on synaptic weight and the current synaptic weight, respectively. In addition, the weight update has dependence and is subject to μ. The update direction of the weight depends on both STDP and the derivative of the post-synaptic neuron, enabling STDP to learn global knowledge and lead to better performance.</p>
        <p>To propagate the gradient to deeper layers, we further need to calculate <inline-formula><mml:math id="M17" overflow="scroll"><mml:mi>∂</mml:mi><mml:mi>E</mml:mi><mml:mo>/</mml:mo><mml:mi>∂</mml:mi><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula>, which can be presented as</p>
        <disp-formula id="E10">
          <label>(10)</label>
          <mml:math id="M18" overflow="scroll">
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:mi>E</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msubsup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mrow>
                      <mml:mi>l</mml:mi>
                      <mml:mo>−</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                  </mml:msubsup>
                </mml:mrow>
              </mml:mfrac>
              <mml:mo>=</mml:mo>
              <mml:mstyle displaystyle="true">
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mi>i</mml:mi>
                </mml:munder>
                <mml:mrow>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mo>∂</mml:mo>
                      <mml:mi>E</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>∂</mml:mo>
                      <mml:msubsup>
                        <mml:mi>t</mml:mi>
                        <mml:mi>i</mml:mi>
                        <mml:mi>l</mml:mi>
                      </mml:msubsup>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:mstyle>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msubsup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msubsup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msubsup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mrow>
                      <mml:mi>l</mml:mi>
                      <mml:mo>−</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                  </mml:msubsup>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>The gradient of the firing time of a neuron in hidden layers is the weighted sum of all the gradients of firing time of those who receive spikes from it, and the coefficient is the derivative between them. Since the pre-synaptic spike only has an effect on the post-synaptic one when the former is earlier, we define the firing time derivative as</p>
        <disp-formula id="E11">
          <label>(11)</label>
          <mml:math id="M19" overflow="scroll">
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msubsup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>j</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msubsup>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>∂</mml:mo>
                  <mml:msubsup>
                    <mml:mi>t</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mrow>
                      <mml:mi>l</mml:mi>
                      <mml:mo>−</mml:mo>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                  </mml:msubsup>
                </mml:mrow>
              </mml:mfrac>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mo>{</mml:mo>
                <mml:mrow>
                  <mml:mtable columnalign="left">
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:msup>
                            <mml:mi>t</mml:mi>
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mo>−</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msup>
                          <mml:mo>&gt;</mml:mo>
                          <mml:msup>
                            <mml:mi>t</mml:mi>
                            <mml:mi>l</mml:mi>
                          </mml:msup>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr columnalign="left">
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:msubsup>
                            <mml:mi>w</mml:mi>
                            <mml:mrow>
                              <mml:mi>i</mml:mi>
                              <mml:mi>j</mml:mi>
                            </mml:mrow>
                            <mml:mi>l</mml:mi>
                          </mml:msubsup>
                          <mml:mo>,</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                      <mml:mtd columnalign="left">
                        <mml:mrow>
                          <mml:msup>
                            <mml:mi>t</mml:mi>
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mo>−</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msup>
                          <mml:mo>⩽</mml:mo>
                          <mml:msup>
                            <mml:mi>t</mml:mi>
                            <mml:mi>l</mml:mi>
                          </mml:msup>
                          <mml:mo>.</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>In conclusion, the full propagation process, including both the forward and the backward pass, can be described in the following pseudo-code (<xref rid="T4" ref-type="table">Algorithm 1</xref>).</p>
        <table-wrap position="float" id="T4">
          <label>Algorithm 1:</label>
          <caption>
            <p>Time-based backpropagation with STDP.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-i0001" position="float"/>
        </table-wrap>
      </sec>
    </sec>
  </sec>
  <sec id="s4">
    <title>4. Experiment</title>
    <sec>
      <title>4.1. Experimental Setup</title>
      <sec>
        <title>4.1.1. Datasets</title>
        <p>We take three visual datasets: Caltech 101 (Fei-Fei et al., <xref rid="B11" ref-type="bibr">2004</xref>), MNIST (LeCun et al., <xref rid="B21" ref-type="bibr">1998</xref>) and CIFAR-10 (Krizhevsky et al., <xref rid="B20" ref-type="bibr">2009</xref>) for object classification tasks. Caltech 101 dataset contains 101 categories of object images. Each category has approximately 40–800 images, each of which consists of 300 × 200 pixels. Here, all the images we use are grayscaled and rescaled to 160 pixels of height. MNIST is a benchmark dataset of handwritten digits containing 60,000 training images and 10,000 testing images that have been widely used in SNN literature. Each sample of MNIST is a 28 × 28 image and contains one of the digits 0 ~ 9. CIFAR-10 is a challenging dataset for the SNN, which contains 60K RGB images in the size of 32 × 32. Following the standard practice, 50K examples are used for training and the remaining 10K for testing. The images are drawn evenly from 10 classes. There are no data augmentation tricks utilized for the MNIST dataset.</p>
      </sec>
      <sec>
        <title>4.1.2. Network Structure</title>
        <p>To evaluate the classification performance of the proposed learning algorithm on the Caltech 101 and MNIST datasets, we consider SNN fully connected, having 784 inputs, from 300 to 700 neurons in the hidden layer, and 10 output neurons for the classification. Meanwhile, we randomly initialize the weights of hidden layers in the range [1, 10] and weights of the classification layer in the range [20, 50]. Note that the hidden layers in the network structure with spike-based classification can also be replaced by convolutional layers, which will be reported in the following experiments. To further demonstrate the effectiveness of the scheme on a large-scale dataset, we evaluated our method on CIFAR-10 using the VGG-7 network structure.</p>
      </sec>
      <sec>
        <title>4.1.3. Evaluation Metrics</title>
        <p>To measure the estimation performance of SNNs, we employ the following metrics in terms of accuracy, speed, and energy, which are widely used in the SNN.</p>
        <p>1) Test Accuracy. Percentage of test samples correctly classified by the SNN model.</p>
        <p>2) Training Epoch. Passing the full training examples once through the SNN denotes an epoch. Start training models from scratch with random initialization weights, and a lower training epoch indicates the model convergence faster.</p>
        <p>3) Time Steps. Since the real-valued inputs are encoded as the spike events over a certain time, inference in ANNS must be divided into multiple forward passes in SNNs, which are equal to the number of time steps. Thus, the number of time steps affects both the latency and the energy consumption (the number of performed operations per inference is equal to that of the sum of multiple forward processes).</p>
        <p>4) Fired Spike Rate (FSR). The average percentage of neuron fire spikes per time step, which are used to quantify the spiking activity.</p>
        <disp-formula id="E12">
          <label>(12)</label>
          <mml:math id="M20" overflow="scroll">
            <mml:mrow>
              <mml:mi>F</mml:mi>
              <mml:mi>S</mml:mi>
              <mml:mi>R</mml:mi>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>#</mml:mo>
                  <mml:mtext>fired spikes</mml:mtext>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>#</mml:mo>
                  <mml:mtext>total neurons</mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mo>#</mml:mo>
                  <mml:mtext>time steps</mml:mtext>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>A higher SR score means a larger number of spikes fired by the neuron, theoretically resulting in higher energy consumption in the neuromorphic hardware.</p>
      </sec>
      <sec>
        <title>4.1.4. Implementation Details</title>
        <p>To valid our SSTDP algorithm, we implemented it on the PyTorch framework (Paszke et al., <xref rid="B34" ref-type="bibr">2019</xref>). The weights of SNNs are initialized according to He et al. (<xref rid="B15" ref-type="bibr">2015</xref>). The batch size is set to 32 for the Caltech 101, MNIST, and CIFAR10 datasets to reduce memory consumption. We use the Adam optimizer (Kingma and Ba, <xref rid="B19" ref-type="bibr">2014</xref>) to adjust the learning rate with the initial learning rate 5 × 10<sup>−3</sup>. The threshold of neurons is adjusted for different types of networks and datasets, which are typically set between 0.7 and 10. The time constant τ and constant μ in Equation 9 are set to 5 and 0.0005, respectively. For our trained SNN, we employ the IF model as the neuron model. The GPU used in training was NVIDIA RTX 2080.</p>
      </sec>
    </sec>
    <sec>
      <title>4.2. Experimental Results</title>
      <sec>
        <title>4.2.1. Effect of Accuracy</title>
        <p>First, we evaluated the test accuracy of our SSTDP method on the Caltech 101 dataset, as described in <xref rid="T1" ref-type="table">Table 1</xref>. The network performance (99.3% top-1 accuracy) of our SSTDP method outperforms other existing learning methods. Then, to further evaluate the effectiveness of our proposed SSTDP learning algorithm, as shown in <xref rid="T2" ref-type="table">Table 2</xref>, we compared the top-1 accuracy of SSTDP with recent works that directly train the SNNs from scratch based on BP on the MNIST datasets. We found that our proposed SSTDP achieves better network performance than others in terms of accuracy and latency. Specifically, SSTDP achieved the same accuracy 98.1% as the SNN trained from scratch, whereas the ANN with 400 hidden neurons and ReLU activation function achieved 98.1%. The accuracy of the SNNs trained with our SSTDP method is larger than the LeNet with 11 network depths.</p>
        <table-wrap position="float" id="T1">
          <label>Table 1</label>
          <caption>
            <p>Test accuracy of SNNs trained with different learning methods on Caltech face/motorcycle dataset.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Method</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Type</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Coding</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Neuron model</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Acc.</bold>
                  <break/>
                  <bold>(Top-1 %)</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">R-STDP Mozafari et al., <xref rid="B29" ref-type="bibr">2018</xref></td>
                <td valign="top" align="center" rowspan="1" colspan="1">Unsupervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rectified linear</td>
                <td valign="top" align="center" rowspan="1" colspan="1">98.2</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">SDNN Kheradpisheh et al., <xref rid="B17" ref-type="bibr">2018</xref></td>
                <td valign="top" align="center" rowspan="1" colspan="1">Unsupervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">LIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">99.1</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">S4NN Kheradpisheh et al., <xref rid="B18" ref-type="bibr">2020</xref></td>
                <td valign="top" align="center" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">99.2</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">STiDi-BP Mirsadeghi et al., <xref rid="B28" ref-type="bibr">2021</xref></td>
                <td valign="top" align="center" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Linear SRM</td>
                <td valign="top" align="center" rowspan="1" colspan="1">99.2</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">This work</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">99.3</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T2">
          <label>Table 2</label>
          <caption>
            <p>Comparsion of our work and other SNN models with direct training on the MNIST dataset.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Method</bold>
                </th>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Structure</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Coding</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Neuron model</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Time</bold>
                  <break/>
                  <bold>steps</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Acc.</bold>
                  <break/>
                  <bold>(Top-1 %)</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">baseline (ANN)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-400FC-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">ReLU</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">98.1</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">S4NN Kheradpisheh et al., <xref rid="B18" ref-type="bibr">2020</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-400FC-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">512</td>
                <td valign="top" align="center" rowspan="1" colspan="1">97.4</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">STiDi-BP Mirsadeghi et al., <xref rid="B28" ref-type="bibr">2021</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-400FC-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Linear SRM</td>
                <td valign="top" align="center" rowspan="1" colspan="1">512</td>
                <td valign="top" align="center" rowspan="1" colspan="1">97.4</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Tempcoding Comsa et al., <xref rid="B4" ref-type="bibr">2020</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-340FC-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">SRM</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">97.9</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">STDBP Zhang et al., <xref rid="B49" ref-type="bibr">2020</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-384FC-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rectified linear</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">97.9</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">BP-STDP Tavanaei et al., <xref rid="B44" ref-type="bibr">2019</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-1000FC-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">96.6</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">TDSNN Zhang et al., <xref rid="B48" ref-type="bibr">2019</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">LeNet</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">-</td>
                <td valign="top" align="center" rowspan="1" colspan="1">92.0</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">SNN+DT Zhou et al., <xref rid="B50" ref-type="bibr">2019</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-Conv-Conv-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">99.33</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">PLIF Fang et al., <xref rid="B10" ref-type="bibr">2021</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-Conv-Pool-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">PLIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">8</td>
                <td valign="top" align="center" rowspan="1" colspan="1">99.72</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">T2FSNN Park et al., <xref rid="B32" ref-type="bibr">2021</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">VGG-16</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">LIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">40</td>
                <td valign="top" align="center" rowspan="1" colspan="1">99.33</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">This work</td>
                <td valign="top" align="left" rowspan="1" colspan="1">784FC-300FC-10FC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">16</td>
                <td valign="top" align="center" rowspan="1" colspan="1">98.1</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>As the number of time steps increases, more information can be represented in the spike train and can achieve higher classification accuracy. Since inference in SNNs is performed through multiple feedforward processes equal to the number of time steps (also called inference latencies), each requires computation based on sparse spikes (Deng et al., <xref rid="B7" ref-type="bibr">2020</xref>; Han and Roy, <xref rid="B13" ref-type="bibr">2020</xref>; Han et al., <xref rid="B14" ref-type="bibr">2020</xref>; Kheradpisheh et al., <xref rid="B18" ref-type="bibr">2020</xref>; Taherkhani et al., <xref rid="B43" ref-type="bibr">2020</xref>). Therefore, it was noted that in other SNNs directly trained by BP, it is likely that spike signals vanish, similar to the vanishing of the gradient in ANNs. SNN thereby requires enough time steps (e.g., 512 time steps) to avoid information loss. In contrast, our method allows accuracy to be maintained even if the time steps are small (i.e., 16 time steps) and can also achieve an accuracy that equals that of the ANN because we use STDP to realize the weight gradient update and extract information. Our SSTDP has a 25.0× ~32.0× acceleration on the MNIST over others. T2FSNN (Park et al., <xref rid="B32" ref-type="bibr">2021</xref>) adopt the VGG-16 as the network structure, SNN+DT (Zhou et al., <xref rid="B50" ref-type="bibr">2019</xref>) and PLIF (Fang et al., <xref rid="B10" ref-type="bibr">2021</xref>) use multiple convolutional layers to construct the network structure of the SNN for better accuracy.</p>
        <p><xref rid="T3" ref-type="table">Table 3</xref> lists the classification performance of all recent works on the SNN as well as our work. As can be seen on the large-scale dataset CIFAR-10 for SNNs, we also achieved an accuracy (91.31%) comparable to that of the ANN-SNN conversion network (91.46%), which out-performed other learning algorithms. Notably, previous efforts usually required 100 or even 1,000 steps to reach good accuracy (Roy et al., <xref rid="B38" ref-type="bibr">2019</xref>; Wu et al., <xref rid="B47" ref-type="bibr">2019b</xref>, <xref rid="B45" ref-type="bibr">2021</xref>). For instance, the ANN-SNN conversion method (Sengupta et al., <xref rid="B40" ref-type="bibr">2019</xref>) requires up to 2,500 time steps to maintain accuracy, the BP-based method (e.g., AFP Wu et al., <xref rid="B45" ref-type="bibr">2021</xref>) requires hundreds of time steps to maintain accuracy, while we only need 16 time steps here on the CIFAR-10 dataset. Note that the inference accuracy of PLIF (Fang et al., <xref rid="B10" ref-type="bibr">2021</xref>), SNN+DT (Zhou et al., <xref rid="B50" ref-type="bibr">2019</xref>), SM+SR (Park and Yoon, <xref rid="B33" ref-type="bibr">2021</xref>), and T2FSNN (Park et al., <xref rid="B32" ref-type="bibr">2021</xref>) adopt the VGG-16 as the network structure on the CIFAR-10, while other training SNNs in <xref rid="T3" ref-type="table">Table 3</xref> adopt the VGG-7. We found that the classification accuracy of our proposed SSTDP performs best in the time-based encoded SNN and is slightly inferior to the rate-based encoded SNN proposed in another study [1]. It is worth noting that this paper focuses on training time-based SNNs, enabling such SNNs to match or even exceed rate-based SNNs. In this way, we can ensure the prediction accuracy of SNNs and take full advantage of sparse spikes in terms of energy consumption. <xref rid="F5" ref-type="fig">Figure 5</xref> shows an example of the image from the CIFAR-10 dataset that is encoded by the time-based coding and processed by the first neuron. After processing the received spikes, every neuron, in combination with its passing synaptic weights, accumulates membrane potential. Initially, spikes in the spike trains of background pixels are fired at later time steps. After being processed by the neuron for feature extraction, the time of firing spikes is advanced. We can display the spike train as shown in <xref rid="F5" ref-type="fig">Figure 5B</xref>.</p>
        <table-wrap position="float" id="T3">
          <label>Table 3</label>
          <caption>
            <p>Test accuracy of different SNNs models on CIFAR-10.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Method</bold>
                </th>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Type</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Coding</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Neuron model</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Time</bold>
                  <break/>
                  <bold>steps</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Acc.</bold>
                  <break/>
                  <bold>(Top-1 %)</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">DeepSNN Sengupta et al., <xref rid="B40" ref-type="bibr">2019</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">ANN-converted</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">2500</td>
                <td valign="top" align="center" rowspan="1" colspan="1">91.46</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">SpikeCNN Panda and Roy, <xref rid="B31" ref-type="bibr">2016</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Unsupervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">LIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">-</td>
                <td valign="top" align="center" rowspan="1" colspan="1">70.16</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">spike-based training Rathi et al., <xref rid="B37" ref-type="bibr">2020</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">LIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">250</td>
                <td valign="top" align="center" rowspan="1" colspan="1">90.95</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">direct training Wu et al., <xref rid="B47" ref-type="bibr">2019b</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">LIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">90.53</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">ASF-BP Wu et al., <xref rid="B45" ref-type="bibr">2021</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">LIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">150</td>
                <td valign="top" align="center" rowspan="1" colspan="1">90.11</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Tandem learning Wu et al., <xref rid="B46" ref-type="bibr">2019a</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">90.98</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">PLIF Fang et al., <xref rid="B10" ref-type="bibr">2021</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Rate-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">PLIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">8</td>
                <td valign="top" align="center" rowspan="1" colspan="1">93.50</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">SNN+DT Zhou et al., <xref rid="B50" ref-type="bibr">2019</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">92.68</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">SM+SR Park and Yoon, <xref rid="B33" ref-type="bibr">2021</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">544</td>
                <td valign="top" align="center" rowspan="1" colspan="1">91.05</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">T2FSNN Park et al., <xref rid="B32" ref-type="bibr">2021</xref></td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">LIF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">1,280</td>
                <td valign="top" align="center" rowspan="1" colspan="1">91.36</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">This work</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Supervised</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Time-based</td>
                <td valign="top" align="center" rowspan="1" colspan="1">IF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">16</td>
                <td valign="top" align="center" rowspan="1" colspan="1">91.31</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <fig position="float" id="F5">
          <label>Figure 5</label>
          <caption>
            <p><bold>(A)</bold> The original image input to the SNN. <bold>(B)</bold> The orignial spike train input to the neurons and the processed version generated by neurons. <bold>(C)</bold> The reconstructed image at the first 33 time steps after time-based coding.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0005" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>4.2.2. Effect of Training Epoch</title>
        <p>In this experiment, we trained the SNN for weight updating by our proposed method while using an ANN optimized by SGD (LeCun et al., <xref rid="B22" ref-type="bibr">2012</xref>) for the weights as a baseline for comparison. The results in <xref rid="F6" ref-type="fig">Figure 6</xref> indicate that the SNN trained by our learning method achieves higher accuracy than the ANN with the same network structure on the MNIST dataset. It is worth mentioning that we reached the best accuracy in less than 90 epochs.</p>
        <fig position="float" id="F6">
          <label>Figure 6</label>
          <caption>
            <p>The accuracy evolution curve for training with our method on the MNIST dataset.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0006" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>4.2.3. Effect of Learning Rate Schedule</title>
        <p>The experiments analyzed the impact of the choice of learning rate schedule on training time and accuracy that are available in most training frameworks (Paszke et al., <xref rid="B34" ref-type="bibr">2019</xref>), including fixed, exponential, step-based, multi-step-based, cosine annealing, and cosine annealing warm restart learning rate decay, as shown in <xref rid="F7" ref-type="fig">Figure 7</xref>. For example, we trained an SNN model (three layers) with SSTDP for 100 epochs, using 0.003 as an initial learning rate and a step-based learning rate decay schedule (i.e., multiplied by 0.1 every 20 epochs). This model reached a top-1 accuracy of 98.1%, which is 0.14% lower than the equivalent model trained with cosine warm restarts learning rate decay.</p>
        <fig position="float" id="F7">
          <label>Figure 7</label>
          <caption>
            <p>The accuracy evolution curve for training with our method on the MNIST dataset varies as the learning rate schedule.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0007" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>4.2.4. Effect of Time Steps</title>
        <p><xref rid="F8" ref-type="fig">Figure 8</xref> describes the test accuracy curve of the SNN trained with the SSTDP method, which varies as the time steps. We observed that the number of time steps affects the model accuracy and is also crucial for training convergence. Although the larger time steps lead to higher model accuracy, the SNN with smaller time steps converges much faster than the SNN with larger time steps. Specifically, the figure shows six curves that vary as the number of time steps increases from 16 to 160, where the model accuracy increases as the number of time steps increases. However, SNNs with smaller time steps can achieve faster convergence. This is because the SNN with smaller time steps contains more intensive information and it is easier to extract features using the local update mechanism of STDP.</p>
        <fig position="float" id="F8">
          <label>Figure 8</label>
          <caption>
            <p>The Inference test accuracy curve of the SNN trained with SSTDP method varies as the time steps.</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0008" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>4.2.5. Effect of Computation Cost</title>
        <p>The inference computation cost of the SSTDP method, STiDi-BP and BP-STDP, are shown in <xref rid="F9" ref-type="fig">Figure 9</xref>, respectively. In each figure, the x-axis is the time steps used to encode information, also considered as the SNN inference latency; the y-axis is the fired spike rate (FSR), which represents the number of operations performed theoretically for computing in SNN inference. As described in <xref rid="F9" ref-type="fig">Figure 9</xref>, the proposed SSTDP method reduces the computation by orders of magnitude over the SNN with rate-based coding in Tavanaei et al. (<xref rid="B44" ref-type="bibr">2019</xref>) and will have an advantage over time-based SNN. Unlike our SSTDP method, other time-based approaches (Kheradpisheh et al., <xref rid="B18" ref-type="bibr">2020</xref>; Mirsadeghi et al., <xref rid="B28" ref-type="bibr">2021</xref>) force all neurons to fire spikes, even those that have not fired, to improve the network performance, and such an approach increases the computation effort. In addition, the network scale used in the two compared baselines is also larger than ours but with less accuracy than our method, as illustrated in the table. Specifically, our network size is only 784 × 300 × 10, while STiDi-BP and BP-STDP are 784 × 400 × 10 and 784 × 1, 000 × 10, respectively. The increase in neurons may also lead to the potential for an increase in FSR, especially for SNNs with rate-based coding. To reflect the computation more intuitively in SNNs, we also provide the number of additional operations performed in SNNs inference in <xref rid="F10" ref-type="fig">Figure 10</xref>. In each figure, the x-axis indicates the SNN inference latency (i.e., time steps), and the y-axis measures the number of addition operations to compute the accumulated membrane potential in the SNN inference. We found that the proposed SSTDP reduces the number of additional operations by orders of magnitude compared to STiDi-BP and BP-STDP.</p>
        <fig position="float" id="F9">
          <label>Figure 9</label>
          <caption>
            <p>The Inference computational cost (FSR) evolution curve comparisons between SSTDP and the two baseline SNNs (STiDi-BP and BP-STDP).</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0009" position="float"/>
        </fig>
        <fig position="float" id="F10">
          <label>Figure 10</label>
          <caption>
            <p>The Inference computational cost (addition operation) evolution curve comparisons between SSTDP and the two baseline SNNs (STiDi-BP and BP-STDP).</p>
          </caption>
          <graphic xlink:href="fnins-15-756876-g0010" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="s5">
    <title>5. Conclusion</title>
    <p>This paper proposes a novel supervised learning algorithm for SNNs, enabling SNNs to be implemented more efficiently by low-power neuromorphic hardware. This work establishes the bridge between the backpropagation algorithm and the STDP update mechanism, bypassing the non-differentiability part in the backward process of SNNs, using the local update mechanism of the STDP to implement it. This takes advantage of the local update property of STDP and the global signals from the BP. It enables the SNN to avoid spike signal disappearance during the execution, thus reducing the network latency. It makes the synaptic weight update receive guidance from the global signal, which guarantees the network performance. The experimental results demonstrate the advantages of our method in terms of network performance, latency, and energy consumption.</p>
  </sec>
  <sec sec-type="data-availability" id="s6">
    <title>Data Availability Statement</title>
    <p>Publicly available datasets were analyzed in this study. This data can be found here: <ext-link xlink:href="http://www.vision.caltech.edu/Image_Datasets/Caltech101" ext-link-type="uri">http://www.vision.caltech.edu/Image_Datasets/Caltech101</ext-link>; <ext-link xlink:href="http://yann.lecun.com/exdb/mnist" ext-link-type="uri">http://yann.lecun.com/exdb/mnist</ext-link>; <ext-link xlink:href="https://www.cs.toronto.edu/~kriz/cifar.html" ext-link-type="uri">https://www.cs.toronto.edu/~kriz/cifar.html</ext-link>.</p>
  </sec>
  <sec id="s7">
    <title>Author Contributions</title>
    <p>FL and WZ designed the study, contributed to the source code, conducted the experiments, and evaluated the results. YC, ZW, TY, and LJ provided feedback and scientific advice throughout the process. All authors contributed to the final manuscript.</p>
  </sec>
  <sec sec-type="funding-information" id="s8">
    <title>Funding</title>
    <p>This work was partially supported by the National Natural Science Foundation of China (grant no. 61834006 and U19B2035) and the National Key Research and Development Program of China (2018YFB1403400).</p>
  </sec>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s9">
    <title>Publisher's Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akopyan</surname><given-names>F.</given-names></name><name><surname>Sawada</surname><given-names>J.</given-names></name><name><surname>Cassidy</surname><given-names>A.</given-names></name><name><surname>Alvarez-Icaza</surname><given-names>R.</given-names></name><name><surname>Arthur</surname><given-names>J.</given-names></name><name><surname>Merolla</surname><given-names>P.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>Truenorth: Design and tool flow of a 65 mw 1 million neuron programmable neurosynaptic chip</article-title>. <source>IEEE Trans. Comput. Aided Design Integr. Circ. Syst</source>. <volume>34</volume>, <fpage>1537</fpage>–<lpage>1557</lpage>. <pub-id pub-id-type="doi">10.1109/TCAD.2015.2474396</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bellec</surname><given-names>G.</given-names></name><name><surname>Salaj</surname><given-names>D.</given-names></name><name><surname>Subramoney</surname><given-names>A.</given-names></name><name><surname>Legenstein</surname><given-names>R.</given-names></name><name><surname>Maass</surname><given-names>W.</given-names></name></person-group> (<year>2018</year>). <article-title>Long short-term memory and learning-to-learn in networks of spiking neurons</article-title>, in <source>Neural Information Processing Systems</source>, <publisher-loc>Montréal, Canada</publisher-loc>. <fpage>787</fpage>–<lpage>797</lpage>.</mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamin</surname><given-names>B. V.</given-names></name><name><surname>Gao</surname><given-names>P.</given-names></name><name><surname>McQuinn</surname><given-names>E.</given-names></name><name><surname>Choudhary</surname><given-names>S.</given-names></name><name><surname>Chandrasekaran</surname><given-names>A. R.</given-names></name><name><surname>Bussat</surname><given-names>J.-M.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Neurogrid: a mixed-analog-digital multichip system for large-scale neural simulations</article-title>. <source>Proc. IEEE</source><volume>102</volume>, <fpage>699</fpage>–<lpage>716</lpage>. <pub-id pub-id-type="doi">10.1109/JPROC.2014.2313565</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Comsa</surname><given-names>I. M.</given-names></name><name><surname>Fischbacher</surname><given-names>T.</given-names></name><name><surname>Potempa</surname><given-names>K.</given-names></name><name><surname>Gesmundo</surname><given-names>A.</given-names></name><name><surname>Versari</surname><given-names>L.</given-names></name><name><surname>Alakuijala</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Temporal coding in spiking neural networks with alpha synaptic function</article-title>, in <source>ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</source> (<publisher-loc>Barcelona</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>8529</fpage>–<lpage>8533</lpage>. <?supplied-pmid 33900924?></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davies</surname><given-names>M.</given-names></name><name><surname>Srinivasa</surname><given-names>N.</given-names></name><name><surname>Lin</surname><given-names>T.-H.</given-names></name><name><surname>Chinya</surname><given-names>G.</given-names></name><name><surname>Cao</surname><given-names>Y.</given-names></name><name><surname>Choday</surname><given-names>S. H.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Loihi: a neuromorphic manycore processor with on-chip learning</article-title>. <source>IEEE Micro</source><volume>38</volume>, <fpage>82</fpage>–<lpage>99</lpage>. <pub-id pub-id-type="doi">10.1109/MM.2018.112130359</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>L.</given-names></name><name><surname>Tang</surname><given-names>H.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2021</year>). <article-title>Understanding and bridging the gap between neuromorphic computing and machine learning</article-title>. <source>Front. Comput. Neurosci</source>. <volume>15</volume>:<fpage>665662</fpage>. <pub-id pub-id-type="doi">10.3389/fncom.2021.665662</pub-id><?supplied-pmid 33815083?><pub-id pub-id-type="pmid">33815083</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>L.</given-names></name><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Hu</surname><given-names>X.</given-names></name><name><surname>Liang</surname><given-names>L.</given-names></name><name><surname>Ding</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Rethinking the performance comparison between snns and anns</article-title>. <source>Neural Netw</source>. <volume>121</volume>, <fpage>294</fpage>–<lpage>307</lpage>. <pub-id pub-id-type="doi">10.1016/j.neunet.2019.09.005</pub-id><?supplied-pmid 31586857?><pub-id pub-id-type="pmid">31586857</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>J.</given-names></name><name><surname>Chang</surname><given-names>M.-W.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Toutanova</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <article-title>Bert: pre-training of deep bidirectional transformers for language understanding</article-title>. <source>arXiv [Preprint]. arXiv:1810.04805</source>. <pub-id pub-id-type="doi">10.18653/v1/n19-1423</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diehl</surname><given-names>P. U.</given-names></name><name><surname>Cook</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>). <article-title>Unsupervised learning of digit recognition using spike-timing-dependent plasticity</article-title>. <source>Front. Comput. Neurosci</source>. <volume>9</volume>:<fpage>99</fpage>. <pub-id pub-id-type="doi">10.3389/fncom.2015.00099</pub-id><?supplied-pmid 26941637?><pub-id pub-id-type="pmid">26941637</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>W.</given-names></name><name><surname>Yu</surname><given-names>Z.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Masquelier</surname><given-names>T.</given-names></name><name><surname>Huang</surname><given-names>T.</given-names></name><name><surname>Tian</surname><given-names>Y.</given-names></name></person-group> (<year>2021</year>). <article-title>Incorporating learnable membrane time constant to enhance learning of spiking neural networks</article-title>, in <source>ICCV</source>. Virtual Event.</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fei-Fei</surname><given-names>L.</given-names></name><name><surname>Fergus</surname><given-names>R.</given-names></name><name><surname>Perona</surname><given-names>P.</given-names></name></person-group> (<year>2004</year>). <article-title>Learning generative visual models from few training examples: an incremental bayesian approach tested on object categories</article-title>, in <source>2004 Conference on Computer Vision and Pattern Recognition Workshop</source> (<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>178</fpage>–<lpage>178</lpage>.</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferré</surname><given-names>P.</given-names></name><name><surname>Mamalet</surname><given-names>F.</given-names></name><name><surname>Thorpe</surname><given-names>S. J.</given-names></name></person-group> (<year>2018</year>). <article-title>Unsupervised feature learning with winner-takes-all based stdp</article-title>. <source>Front. Comput. Neurosci</source>. <volume>12</volume>:<fpage>24</fpage>. <pub-id pub-id-type="doi">10.3389/fncom.2018.00024</pub-id><?supplied-pmid 29674961?><pub-id pub-id-type="pmid">29674961</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Han</surname><given-names>B.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2020</year>). <article-title>Deep spiking neural network: Energy efficiency through time based coding</article-title>, in <source>Proceedings of IEEE Eurupen Conference on Computer Vision(ECCV)</source>, <publisher-loc>Glasgow, UK</publisher-loc>. <fpage>388</fpage>–<lpage>404</lpage>.</mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Han</surname><given-names>B.</given-names></name><name><surname>Srinivasan</surname><given-names>G.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2020</year>). <article-title>RMP-SNN: residual membrane potential neuron for enabling deeper high-accuracy and low-latency spiking neural network</article-title>, in <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source> (<publisher-loc>Seattle, WA</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>13558</fpage>–<lpage>13567</lpage>.</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>He</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Ren</surname><given-names>S.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</article-title>, in <source>Proceedings of the IEEE International Conference on Computer Vision</source> (<publisher-loc>Santiago</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>1026</fpage>–<lpage>1034</lpage>.</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>He</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Ren</surname><given-names>S.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Deep residual learning for image recognition</article-title>, in <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source> (<publisher-loc>Las Vegas, NV</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>770</fpage>–<lpage>778</lpage>. <?supplied-pmid 32166560?></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kheradpisheh</surname><given-names>S. R.</given-names></name><name><surname>Ganjtabesh</surname><given-names>M.</given-names></name><name><surname>Thorpe</surname><given-names>S. J.</given-names></name><name><surname>Masquelier</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). <article-title>Stdp-based spiking deep convolutional neural networks for object recognition</article-title>. <source>Neural Netw</source>. <volume>99</volume>, <fpage>56</fpage>–<lpage>67</lpage>. <pub-id pub-id-type="doi">10.1016/j.neunet.2017.12.005</pub-id><?supplied-pmid 29328958?><pub-id pub-id-type="pmid">29328958</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kheradpisheh</surname><given-names>S. R.</given-names></name><name><surname>Masquelier</surname><given-names>T.</given-names></name></person-group> (<year>2020</year>). <article-title>Temporal backpropagation for spiking neural networks with one spike per neuron</article-title>. <source>Int. J. Neural Syst</source>. <volume>30</volume>, <fpage>2050027</fpage>. <pub-id pub-id-type="doi">10.1142/S0129065720500276</pub-id><?supplied-pmid 32466691?><pub-id pub-id-type="pmid">32466691</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>D. P.</given-names></name><name><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <article-title>Adam: a method for stochastic optimization</article-title>, in <source>3rd International Conference on Learning Representations, ICLR</source>, eds <person-group person-group-type="editor"><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>LeCun</surname><given-names>Y.</given-names></name></person-group> (<publisher-loc>San Diego, CA</publisher-loc>). Available online at: <ext-link xlink:href="https://dblp.org/rec/journals/corr/KingmaB14" ext-link-type="uri">https://dblp.org/rec/journals/corr/KingmaB14</ext-link></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>Learning multiple layers of features from tiny images</article-title>. <publisher-name>Citeseer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y.</given-names></name><name><surname>Bottou</surname><given-names>L.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Haffner</surname><given-names>P.</given-names></name></person-group> (<year>1998</year>). <article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proc. IEEE</source>
<volume>86</volume>, <fpage>2278</fpage>–<lpage>2324</lpage>. <pub-id pub-id-type="doi">10.1109/5.726791</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y. A.</given-names></name><name><surname>Bottou</surname><given-names>L.</given-names></name><name><surname>Orr</surname><given-names>G. B.</given-names></name><name><surname>Müller</surname><given-names>K.-R.</given-names></name></person-group> (<year>2012</year>). <article-title>Efficient backprop</article-title>, in <source>Neural Networks: Tricks of the Trade</source> (<publisher-name>Springer</publisher-name>), <fpage>9</fpage>–<lpage>48</lpage>.</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>C.</given-names></name><name><surname>Panda</surname><given-names>P.</given-names></name><name><surname>Srinivasan</surname><given-names>G.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <article-title>Training deep spiking convolutional neural networks with stdp-based unsupervised pre-training followed by supervised fine-tuning</article-title>. <source>Front. Neurosci</source>. <volume>12</volume>:<fpage>435</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2018.00435</pub-id><?supplied-pmid 30123103?><pub-id pub-id-type="pmid">30123103</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J. H.</given-names></name><name><surname>Delbruck</surname><given-names>T.</given-names></name><name><surname>Pfeiffer</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>). <article-title>Training deep spiking neural networks using backpropagation</article-title>. <source>Front. Neurosci</source>. <volume>10</volume>:<fpage>508</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2016.00508</pub-id><?supplied-pmid 27877107?><pub-id pub-id-type="pmid">27877107</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Yan</surname><given-names>B.</given-names></name><name><surname>Yang</surname><given-names>C.</given-names></name><name><surname>Song</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>B.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>A spiking neuromorphic design with resistive crossbar</article-title>, in <source>2015 52nd ACM/EDAC/IEEE Design Automation Conference (DAC)</source> (<publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Li</surname><given-names>L.</given-names></name><name><surname>Tang</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>S.</given-names></name><name><surname>Gaudiot</surname><given-names>J.-L.</given-names></name></person-group> (<year>2017</year>). <article-title>Creating autonomous vehicle systems</article-title>. <source>Synth. Lect. Comput. Sci</source>. <volume>6</volume>, <fpage>I</fpage>-<lpage>186</lpage>. <pub-id pub-id-type="doi">10.2200/S00787ED1V01Y201707CSL009</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lobo</surname><given-names>J. L.</given-names></name><name><surname>Del Ser</surname><given-names>J.</given-names></name><name><surname>Bifet</surname><given-names>A.</given-names></name><name><surname>Kasabov</surname><given-names>N.</given-names></name></person-group> (<year>2020</year>). <article-title>Spiking neural networks and online learning: an overview and perspectives</article-title>. <source>Neural Netw</source>. <volume>121</volume>, <fpage>88</fpage>–<lpage>100</lpage>. <pub-id pub-id-type="doi">10.1016/j.neunet.2019.09.004</pub-id><?supplied-pmid 31536902?><pub-id pub-id-type="pmid">31536902</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirsadeghi</surname><given-names>M.</given-names></name><name><surname>Shalchian</surname><given-names>M.</given-names></name><name><surname>Kheradpisheh</surname><given-names>S. R.</given-names></name><name><surname>Masquelier</surname><given-names>T.</given-names></name></person-group> (<year>2021</year>). <article-title>Stidi-bp: spike time displacement based error backpropagation in multilayer spiking neural networks</article-title>. <source>Neurocomputing</source>
<volume>427</volume>, <fpage>131</fpage>–<lpage>140</lpage>. <pub-id pub-id-type="doi">10.1016/j.neucom.2020.11.052</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mozafari</surname><given-names>M.</given-names></name><name><surname>Kheradpisheh</surname><given-names>S. R.</given-names></name><name><surname>Masquelier</surname><given-names>T.</given-names></name><name><surname>Nowzari-Dalini</surname><given-names>A.</given-names></name><name><surname>Ganjtabesh</surname><given-names>M.</given-names></name></person-group> (<year>2018</year>). <article-title>First-spike-based visual categorization using reward-modulated stdp</article-title>. <source>IEEE Trans. Neural Netw. Learn. Syst</source>. <volume>29</volume>, <fpage>6178</fpage>–<lpage>6190</lpage>. <pub-id pub-id-type="doi">10.1109/TNNLS.2018.2826721</pub-id><?supplied-pmid 29993898?><pub-id pub-id-type="pmid">29993898</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nedevschi</surname><given-names>S.</given-names></name><name><surname>Popescu</surname><given-names>V.</given-names></name><name><surname>Danescu</surname><given-names>R.</given-names></name><name><surname>Marita</surname><given-names>T.</given-names></name><name><surname>Oniga</surname><given-names>F.</given-names></name></person-group> (<year>2012</year>). <article-title>Accurate ego-vehicle global localization at intersections through alignment of visual data with digital map</article-title>. <source>IEEE Trans. Intell. Transport. Syst</source>. <volume>14</volume>, <fpage>673</fpage>–<lpage>687</lpage>. <pub-id pub-id-type="doi">10.1109/TITS.2012.2228191</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Panda</surname><given-names>P.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2016</year>). <article-title>Unsupervised regenerative learning of hierarchical features in spiking deep networks for object recognition</article-title>, in <source>2016 International Joint Conference on Neural Networks (IJCNN)</source> (<publisher-loc>Vancouver, BC</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>299</fpage>–<lpage>306</lpage>.</mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Park</surname><given-names>S.</given-names></name><name><surname>Kim</surname><given-names>S.</given-names></name><name><surname>Na</surname><given-names>B.</given-names></name><name><surname>Yoon</surname><given-names>S.</given-names></name></person-group> (<year>2021</year>). <article-title>T2fsnn: deep spiking neural networks with time-to-first-spike coding</article-title>, in <source>2021 58th ACM/IEEE Design Automation Conference (DAC)</source> (<publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Park</surname><given-names>S.</given-names></name><name><surname>Yoon</surname><given-names>S.</given-names></name></person-group> (<year>2021</year>). <article-title>Training energy-efficient deep spiking neural networks with time-to-first-spike coding</article-title>. <source>arXiv [Preprint]. arXiv:2106.02568</source>. <pub-id pub-id-type="doi">10.1109/DAC18072.2020.9218689</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A.</given-names></name><name><surname>Gross</surname><given-names>S.</given-names></name><name><surname>Massa</surname><given-names>F.</given-names></name><name><surname>Lerer</surname><given-names>A.</given-names></name><name><surname>Bradbury</surname><given-names>J.</given-names></name><name><surname>Chanan</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Pytorch: an imperative style, high-performance deep learning library</article-title>, in <source>Advances in Neural Information Processing Systems, Vol. 32</source>, eds <person-group person-group-type="editor"><name><surname>Wallach</surname><given-names>H.</given-names></name><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Beygelzimer</surname><given-names>A.</given-names></name><name><surname>d'Alché-Buc</surname><given-names>F.</given-names></name><name><surname>Fox</surname><given-names>E.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Vancouver, BC</publisher-loc>: <publisher-name>Curran Associates, Inc.</publisher-name>). Vancouver, BC, Canada.</mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfister</surname><given-names>J.-P.</given-names></name><name><surname>Gerstner</surname><given-names>W.</given-names></name></person-group> (<year>2006</year>). <article-title>Triplets of spikes in a model of spike timing-dependent plasticity</article-title>. <source>J. Neurosci</source>. <volume>26</volume>, <fpage>9673</fpage>–<lpage>9682</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1425-06.2006</pub-id><?supplied-pmid 22851353?><pub-id pub-id-type="pmid">16988038</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radford</surname><given-names>A.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Child</surname><given-names>R.</given-names></name><name><surname>Luan</surname><given-names>D.</given-names></name><name><surname>Amodei</surname><given-names>D.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name></person-group> (<year>2019</year>). <article-title>Language models are unsupervised multitask learners</article-title>. <source>Open AI Blog</source>
<volume>1</volume>:<fpage>9</fpage>.</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rathi</surname><given-names>N.</given-names></name><name><surname>Srinivasan</surname><given-names>G.</given-names></name><name><surname>Panda</surname><given-names>P.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2020</year>). <article-title>Enabling deep spiking neural networks with hybrid conversion and spike timing dependent backpropagation</article-title>, in <source>8th International Conference on Learning Representations (ICLR)</source> (<publisher-loc>Addis Ababa</publisher-loc>).</mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>K.</given-names></name><name><surname>Jaiswal</surname><given-names>A.</given-names></name><name><surname>Panda</surname><given-names>P.</given-names></name></person-group> (<year>2019</year>). <article-title>Towards spike-based machine intelligence with neuromorphic computing</article-title>. <source>Nature</source>
<volume>575</volume>, <fpage>607</fpage>–<lpage>617</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-019-1677-2</pub-id><?supplied-pmid 31776490?><pub-id pub-id-type="pmid">31776490</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sandler</surname><given-names>M.</given-names></name><name><surname>Howard</surname><given-names>A.</given-names></name><name><surname>Zhu</surname><given-names>M.</given-names></name><name><surname>Zhmoginov</surname><given-names>A.</given-names></name><name><surname>Chen</surname><given-names>L.-C.</given-names></name></person-group> (<year>2018</year>). <article-title>Mobilenetv2: inverted residuals and linear bottlenecks</article-title>, in <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source> (<publisher-loc>Salt Lake City, UT</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>4510</fpage>–<lpage>4520</lpage>.</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengupta</surname><given-names>A.</given-names></name><name><surname>Ye</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>R.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2019</year>). <article-title>Going deeper in spiking neural networks: vgg and residual architectures</article-title>. <source>Front. Neurosci</source>. <volume>13</volume>:<fpage>95</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2019.00095</pub-id><?supplied-pmid 30899212?><pub-id pub-id-type="pmid">30899212</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Simonyan</surname><given-names>K.</given-names></name><name><surname>Zisserman</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>Very deep convolutional networks for large-scale image recognition</article-title>, in <source>International Conference on Learning Representations (ICLR)</source> (<publisher-loc>San Diego, CA</publisher-loc>).</mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>G.</given-names></name><name><surname>Panda</surname><given-names>P.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <article-title>Stdp-based unsupervised feature learning using convolution-over-time in spiking neural networks for energy-efficient neuromorphic computing</article-title>. <source>ACM J. Emerg. Technol. Comput. Syst</source>. <volume>14</volume>, <fpage>1</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1145/3266229</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taherkhani</surname><given-names>A.</given-names></name><name><surname>Belatreche</surname><given-names>A.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Cosma</surname><given-names>G.</given-names></name><name><surname>Maguire</surname><given-names>L. P.</given-names></name><name><surname>McGinnity</surname><given-names>T. M.</given-names></name></person-group> (<year>2020</year>). <article-title>A review of learning in biologically plausible spiking neural networks</article-title>. <source>Neural Netw</source>. <volume>122</volume>:<fpage>253</fpage>–<lpage>272</lpage>. <pub-id pub-id-type="doi">10.1016/j.neunet.2019.09.036</pub-id><?supplied-pmid 31726331?><pub-id pub-id-type="pmid">31726331</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavanaei</surname><given-names>A.</given-names></name><name><surname>Maida</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Bp-stdp: approximating backpropagation using spike timing dependent plasticity</article-title>. <source>Neurocomputing</source>
<volume>330</volume>, <fpage>39</fpage>–<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1016/j.neucom.2018.11.014</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Weng</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Xiong</surname><given-names>Z.</given-names></name><name><surname>Zha</surname><given-names>Z.-J.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Training spiking neural networks with accumulated spiking flow</article-title>, in <source>Proceedings of the AAAI Conference on Artificial Intelligence</source>. Virtual Event.</mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Chua</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Tan</surname><given-names>K. C.</given-names></name></person-group> (<year>2019a</year>). <article-title>A tandem learning rule for effective training and rapid inference of deep spiking neural networks</article-title>. <source>arXiv [Preprint]. arXiv:1907.01167</source>. <?supplied-pmid 34288879?></mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Deng</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Zhu</surname><given-names>J.</given-names></name><name><surname>Xie</surname><given-names>Y.</given-names></name><name><surname>Shi</surname><given-names>L.</given-names></name></person-group> (<year>2019b</year>). <article-title>Direct training for spiking neural networks: faster, larger, better</article-title>. <source>Proc. AAAI Conf. Art. Intell</source>. <volume>33</volume>, <fpage>1311</fpage>–<lpage>1318</lpage>. <pub-id pub-id-type="doi">10.1609/aaai.v33i01.33011311</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Zhou</surname><given-names>S.</given-names></name><name><surname>Zhi</surname><given-names>T.</given-names></name><name><surname>Du</surname><given-names>Z.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name></person-group> (<year>2019</year>). <article-title>Tdsnn: from deep neural networks to deep spike neural networks with temporal-coding</article-title>, in <source>Proc. AAAI Conf. Art. Intell</source>. <volume>33</volume>, <fpage>1319</fpage>–<lpage>1326</lpage>. <pub-id pub-id-type="doi">10.1609/aaai.v33i01.33011319</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Belatreche</surname><given-names>A.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Chua</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Spike-timing-dependent back propagation in deep spiking neural networks</article-title>. <source>CoRR</source>.</mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>S.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Chandrasekaran</surname><given-names>S. T.</given-names></name><name><surname>Sanyal</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Temporal coded deep spiking neural network with easy training and robust performance</article-title>, in <source>Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</source> (<publisher-name>AAAI Press</publisher-name>).</mixed-citation>
    </ref>
  </ref-list>
</back>
