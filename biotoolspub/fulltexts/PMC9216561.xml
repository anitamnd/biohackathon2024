<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Database (Oxford)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Database (Oxford)</journal-id>
    <journal-id journal-id-type="publisher-id">databa</journal-id>
    <journal-title-group>
      <journal-title>Database: The Journal of Biological Databases and Curation</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-0463</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
      <publisher-loc>UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9216561</article-id>
    <article-id pub-id-type="pmid">35657113</article-id>
    <article-id pub-id-type="doi">10.1093/database/baac036</article-id>
    <article-id pub-id-type="publisher-id">baac036</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>GeMI: interactive interface for transformer-based Genomic Metadata Integration</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5465-6182</contrib-id>
        <name>
          <surname>Serna Garcia</surname>
          <given-names>Giuseppe</given-names>
        </name>
        <aff><institution content-type="department">Department of Electronics, Information, and Bioengineering, Politecnico di Milano</institution>, Via Ponzio 34/5, Milano 20133, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2618-5985</contrib-id>
        <name>
          <surname>Leone</surname>
          <given-names>Michele</given-names>
        </name>
        <aff><institution content-type="department">Department of Electronics, Information, and Bioengineering, Politecnico di Milano</institution>, Via Ponzio 34/5, Milano 20133, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8016-5750</contrib-id>
        <name>
          <surname>Bernasconi</surname>
          <given-names>Anna</given-names>
        </name>
        <!--anna.bernasconi@polimi.it-->
        <xref rid="COR0001" ref-type="corresp"/>
        <aff><institution content-type="department">Department of Electronics, Information, and Bioengineering, Politecnico di Milano</institution>, Via Ponzio 34/5, Milano 20133, <country country="IT">Italy</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6575-9737</contrib-id>
        <name>
          <surname>Carman</surname>
          <given-names>Mark J</given-names>
        </name>
        <aff><institution content-type="department">Department of Electronics, Information, and Bioengineering, Politecnico di Milano</institution>, Via Ponzio 34/5, Milano 20133, <country country="IT">Italy</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR0001">*Corresponding author: Tel: +39 02 2399 3655; Fax: +39 02 2399 3411; Email: <email xlink:href="anna.bernasconi@polimi.it">anna.bernasconi@polimi.it</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-06-03">
      <day>03</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>03</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <volume>2022</volume>
    <elocation-id>baac036</elocation-id>
    <history>
      <date date-type="received">
        <day>05</day>
        <month>1</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>18</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>03</day>
        <month>6</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="baac036.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The Gene Expression Omnibus (GEO) is a public archive containing &gt;4 million digital samples from functional genomics experiments collected over almost two decades. The accompanying metadata describing the experiments suffer from redundancy, inconsistency and incompleteness due to the prevalence of free text and the lack of well-defined data formats and their validation. To remedy this situation, we created Genomic Metadata Integration (GeMI; <ext-link xlink:href="http://gmql.eu/gemi/" ext-link-type="uri">http://gmql.eu/gemi/</ext-link>), a web application that learns to automatically extract structured metadata (in the form of key-value pairs) from the plain text descriptions of GEO experiments. The extracted information can then be indexed for structured search and used for various downstream data mining activities. GeMI works in continuous interaction with its users. The natural language processing transformer-based model at the core of our system is a fine-tuned version of the Generative Pre-trained Transformer 2 (GPT2) model that is able to learn continuously from the feedback of the users thanks to an active learning framework designed for the purpose. As a part of such a framework, a machine learning interpretation mechanism (that exploits saliency maps) allows the users to understand easily and quickly whether the predictions of the model are correct and improves the overall usability. GeMI’s ability to extract attributes not explicitly mentioned (such as sex, tissue type, cell type, ethnicity and disease) allows researchers to perform specific queries and classification of experiments, which was previously possible only after spending time and resources with tedious manual annotation. The usefulness of GeMI is demonstrated on practical research use cases.</p>
      <p>
Database URL
</p>
      <p>
        <ext-link xlink:href="http://gmql.eu/gemi/" ext-link-type="uri">http://gmql.eu/gemi/</ext-link>
      </p>
    </abstract>
    <counts>
      <page-count count="12"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s2">
    <title>Introduction</title>
    <p>Public repositories of genomic datasets such as Gene Expression Omnibus (GEO, (<xref rid="R1" ref-type="bibr">1</xref>)), Sequence Read Archive (SRA, (<xref rid="R2" ref-type="bibr">2</xref>)) and ArrayExpress (<xref rid="R3" ref-type="bibr">3</xref>) have become a fundamental source of knowledge that helps the scientific community to accelerate biological investigations. The analysis of its rich data corpus (including gene expression, mutation profiles and chromatin configuration) is useful to provide new insights into understanding disease and protein evolution (<xref rid="R4" ref-type="bibr">4</xref>). In particular, GEO is one of the largest public repositories of genomic data with &gt;4 million experimental samples that are growing at an exponential rate in recent years (see <xref rid="F1" ref-type="fig">Figure 1</xref>). This happened also thanks to next-generation sequencing technologies (<xref rid="R5" ref-type="bibr">5</xref>), which have greatly reduced the cost of genome sequencing. Each experimental sample contained in GEO is composed of two parts: the region data and its associated metadata. In order to classify, compare and find relevant information at scale from such a large amount of genomic data, it is essential to have a well-structured metadata content that uniquely specifies attributes such as tissue type, cell type, sex, age, disease and species.</p>
    <fig position="float" id="F1" fig-type="figure">
      <label>Figure 1.</label>
      <caption>
        <p>Number of samples (GSM, left <italic toggle="yes">y</italic>-axis) and experiments (GSE, right <italic toggle="yes">y</italic>-axis) made available by the GEO portal; raw data were extracted from <ext-link xlink:href="https://www.ncbi.nlm.nih.gov/geo/browse/?view=samples" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/geo/browse/?view=samples</ext-link> and <ext-link xlink:href="https://www.ncbi.nlm.nih.gov/geo/browse/?view=series" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/geo/browse/?view=series</ext-link>).</p>
      </caption>
      <graphic xlink:href="baac036f1" position="float"/>
    </fig>
    <p>Unfortunately, GEO metadata lack structure because they are provided in the form of a textual description of the experiment. Such text cannot be easily processed, because each information piece contained in the description may be missing, misspelled or expressed using synonyms. This issue prevents researchers from completely exploiting the knowledge contained in GEO, as the meta-analysis and the integration of multiple genomic datasets are infeasible due to the lack of machine-readable standardized metadata. For this reason, annotating genomic datasets at scale is a challenging problem for bioinformaticians (<xref rid="R6" ref-type="bibr">6</xref>). Three approaches are usually employed to address this problem: manual curation, metadata inference directly from gene expression profiles (or other genomic signals) and automated natural language processing (NLP). In this work, we investigated the latter, focusing on applying the last developments of deep learning transformer-based NLP. In particular, we combined Generative Pre-trained Transformer 2 (GPT2) models for attribute extraction from metadata (Cannizzaro <italic toggle="yes">et al.</italic> (<xref rid="R7" ref-type="bibr">7</xref>)), with the implementation of an Active Learning (AL) Framework (Cohn <italic toggle="yes">et al.</italic> (<xref rid="R8" ref-type="bibr">8</xref>)) and gradient-based deep learning interpretation technique (Atanasova <italic toggle="yes">et al.</italic> (<xref rid="R9" ref-type="bibr">9</xref>)). Recent breakthroughs in NLP with pretrained generative models as GPT2 (Radford <italic toggle="yes">et al.</italic> (<xref rid="R10" ref-type="bibr">10</xref>)) allowed to build multitask learners using fewer data than classic supervised Machine Learning (ML) techniques. In our work, we used GPT2 to integrate the sets of attributes provided by the datasets generated from two important genomic data sources, namely Cistrome (<xref rid="R11" ref-type="bibr">11</xref>) and the Encyclopedia of DNA Elements (ENCODE, (<xref rid="R12" ref-type="bibr">12</xref>)). However, the huge number and diversity of unlabeled samples in GEO still make it necessary to manually annotate new samples, as such data can be used to make a model able to learn dynamically over time and improve its accuracy.</p>
    <p>AL is a meta-algorithm for ML that aims to minimize the number of samples needed to improve an ML model over time. By using an AL framework, users can verify and modify (as needed) a few specific predicted samples achieving the effect of manually annotating a multitude of samples. We designed an AL framework that learns from user feedback in real time, further reducing the number of samples to be annotated. In the last years, modern deep learning models such as Transformers (<xref rid="R13" ref-type="bibr">13</xref>), naturally considered as black-box techniques (i.e. not explainable), have shown an exponential growth in model parameters and computational times. This contributes highlighting the problem of user trust in the results, as—although deep learning models are able to predict correct values—these may be generated using incorrect or unethical patterns. The field of ML that addresses this issue is eXplainable AI (XAI) (<xref rid="R14" ref-type="bibr">14</xref>); XAI aims to make the results of complex black-box models understandable by human experts. In this work, we implemented a gradient-based technique (Kindermans <italic toggle="yes">et al.</italic> (<xref rid="R15" ref-type="bibr">15</xref>)) to make our model predictions interpretable by the users; we then integrated the interpretation mechanism into the AL framework; this not only improves the user experience, but also makes it easier and faster for the users to search for errors in the predictions.</p>
    <p>The result of our work is the Genomic Metadata Integration (GeMI) web tool, which is able to extract a table composed of 15 different attributes from each selected experiment metadata of GEO. The set of attributes has been selected according to the Biological and Technological views of the Genomic Conceptual Model (Bernasconi <italic toggle="yes">et al.</italic> (<xref rid="R16" ref-type="bibr">16</xref>)), which recognizes a set of concepts that are supported by most genomic data sources in order to provide a common language for genomic dataset integration pipelines. The work is in line with the principles of the GeCo project (<xref rid="R17" ref-type="bibr">17</xref>) and sets the bases for inclusion of a relevant fraction of GEO within the META-BASE repository (<xref rid="R18" ref-type="bibr">18</xref>) and its search tools (<xref rid="R19" ref-type="bibr">19</xref>). Compared to a state-of-the-art tool for metadata annotation (Ontology Annotations and Semantic Similarity Software, OnASSiS (<xref rid="R20" ref-type="bibr">20</xref>)), GeMI demonstrates a considerable improvement, especially when put in the context of downstream analysis pipelines (e.g. CombSAFE (<xref rid="R21" ref-type="bibr">21</xref>)).</p>
  </sec>
  <sec id="s3">
    <title>Related work</title>
    <p>In the last years, many works have proposed solutions for extracting structured tables from GEO data and metadata (Wang <italic toggle="yes">et al.</italic> (<xref rid="R6" ref-type="bibr">6</xref>)). The most straightforward approach is to manually annotate each experiment. This approach later evolved into crowd curation (Hadley <italic toggle="yes">et al.</italic> (<xref rid="R22" ref-type="bibr">22</xref>)), but since the amount of data is growing too fast, this approach still requires too many resources. Regarding automated techniques, we consider the work of Cannizzaro <italic toggle="yes">et al.</italic> (<xref rid="R7" ref-type="bibr">7</xref>), where deep learning transformer-based techniques for NLP are used to infer attributes from experiment metadata, formulating the problem as a translation task. This approach has many advantages over other classical NLP approaches such as regular expressions and classification techniques (Giles <italic toggle="yes">et al.</italic> (<xref rid="R23" ref-type="bibr">23</xref>), Chen <italic toggle="yes">et al.</italic> (<xref rid="R24" ref-type="bibr">24</xref>)); indeed, the GPT2 model does not require that the values of the attributes are known a priori (as opposed to the classification task)—it is able to handle synonyms/abbreviations and can also infer attributes from patterns (e.g. prostate implies the male sex of the donor). However, the continued growth of GEO requires a model that dynamically and efficiently learns to handle new types of experiment samples over time. This means that there is the need to collect annotations of new samples and retrain the model over time to keep it usable with new data. For this reason, the major difference of our work with respect to the available literature is the design and implementation of an AL framework that allows combining manual curation with automatic attribute extraction. In this hybrid approach, the data required to the deep learning transformer-based model are provided in an efficient way by the users during its usage. This method strategically selects a subset of the data that needs labeling to maximally improve the model performance with minimal labeling requirement. Although our model is based on a previously proposed model (<xref rid="R7" ref-type="bibr">7</xref>), our work differs from it because we defined the attribute extraction problem as a multitask problem where each task corresponds to a different attribute. This new formulation brings a number of advantages, the most important being that the new deep learning transformer-based model can learn to infer the union of the attributes of a multitude of heterogeneous datasets (each dataset can contain different experiment samples and different annotated attributes) and in this way it can integrate data from different data sources. Moreover, our work differs from manual curation tools (Hadley <italic toggle="yes">et al.</italic> (<xref rid="R22" ref-type="bibr">22</xref>)) since we implemented an interpretation mechanism for our model. This mechanism helps the user to spend less energy and time annotating samples. Finally, as other works in literature, we developed a web graphic interface that allows users to use our system to extract structured tables from GEO and annotate them without the need for programming knowledge.</p>
    <p>Previously proposed systems (<xref rid="R7" ref-type="bibr">7</xref>, <xref rid="R25" ref-type="bibr">25</xref>) provide scarce if not no interpretability at all. Instead, with GeMI we have made a first step toward achieving interpretability, which is paired with a functioning and effective system. On the contrary, simpler techniques (<xref rid="R6" ref-type="bibr">6</xref>, <xref rid="R23" ref-type="bibr">23</xref>, <xref rid="R24" ref-type="bibr">24</xref>) (e.g. regex-based) can easily provide interpretability by construction but suffer instead severe limitations in terms of performance.</p>
    <sec id="s3-s1">
      <title>Use of transformers NLP-based models in bioinformatics</title>
      <p>Several NLP techniques have been used and adapted to bioinformatics-relevant problems (<xref rid="R26" ref-type="bibr">26</xref>); in particular, transformer-based NLP techniques have focused on the study of protein structures (<xref rid="R27" ref-type="bibr">27</xref>, <xref rid="R28" ref-type="bibr">28</xref>), with several approaches trying to predict other relevant genomic elements such as DNA (<xref rid="R29" ref-type="bibr">29</xref>), DNA enhancers (<xref rid="R30" ref-type="bibr">30</xref>), DNA N6-methyladenine sites (<xref rid="R31" ref-type="bibr">31</xref>), microRNA sequences (<xref rid="R32" ref-type="bibr">32</xref>) and peptides (<xref rid="R33" ref-type="bibr">33</xref>, <xref rid="R34" ref-type="bibr">34</xref>). Few studies have addressed the problem of making the results explainable (<xref rid="R35" ref-type="bibr">35</xref>). In comparison, less approaches have employed transformed-based techniques for biomedical text extraction tasks (<xref rid="R25" ref-type="bibr">25</xref>), mainly focusing on entity relations (<xref rid="R36" ref-type="bibr">36</xref>, <xref rid="R37" ref-type="bibr">37</xref>). To the best of our knowledge, transformed-based approaches applied to biomedical tasks have not yet been combined with explainability approaches, as proposed in this article.</p>
    </sec>
  </sec>
  <sec id="s4">
    <title>Materials and methods</title>
    <sec id="s4-s1">
      <title>Datasets</title>
      <p>In order to investigate the effectiveness of the aforementioned techniques in the GeMI tool, we created a new dataset that joins two heterogeneous datasets, i.e. from Cistrome (<xref rid="R11" ref-type="bibr">11</xref>) and ENCODE (<xref rid="R12" ref-type="bibr">12</xref>). The Cistrome Data Browser (<xref rid="R11" ref-type="bibr">11</xref>) provides a collection of 44 843 experiments data and metadata. Each sample’s metadata have been manually curated and annotated in order to provide the following attributes: Cell Line, Cell Type, Tissue Type and Factor Name. The original dataset was downloaded from <ext-link xlink:href="http://cistrome.org/db/#/bdown" ext-link-type="uri">http://cistrome.org/db/#/bdown</ext-link>. ENCODE (<xref rid="R12" ref-type="bibr">12</xref>) contains a collection of 20 734 experiments about DNA sequences. It provides for each experiment a set of 15 attributes. The dataset was extracted from <ext-link xlink:href="https://www.encodeproject.org/help/batch-download/" ext-link-type="uri">https://www.encodeproject.org/help/batch-download/</ext-link>. Only a minor fraction of the samples of the two datasets (3103 out of 58 235 about 0.05%) overlap; moreover, their annotated attributes are different. The model proposed in this work is able to learn to predict the union of the attributes of the two datasets, even if they are heterogeneous. To create the new dataset, we split each sample of the original datasets into as many samples as the number of its attributes. Thus, each sample of Cistrome was split into four samples, where each new sample has the same experiment metadata (data point) but a different attribute (label). Then, we merged all the samples thus obtained from the two original datasets. The attributes of the resulting dataset are extracted as indicated in <xref rid="T1" ref-type="table">Table 1</xref>. The Cell Line, Cell Type and Tissue information is retrieved from the corresponding attributes of Cistrome (when this is available) or from a combination of the Classification and Biosample term name from ENCODE, as an alternative. In the latter case: i) the attribute Classification specifies if the Biosample term name refers to a ‘cell line’ or a ‘tissue’. ii) Biosample term name’s content must be interpreted in the context of the classification scope. The combination of these two ENCODE attributes defines either a Cell Line or a Tissue; Cell Type is set to null. All the other attributes are mapped directly from ENCODE, with minimal renaming to better adhere to the terminology of the Genomic Conceptual Model (<xref rid="R16" ref-type="bibr">16</xref>).</p>
      <table-wrap position="float" id="T1">
        <label>Table 1.</label>
        <caption>
          <p>List of attributes considered from the Cistrome and ENCODE datasets and how they are mapped into GeMI’s output</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Cistrome</th>
              <th valign="bottom" align="left" rowspan="1" colspan="1">ENCODE</th>
              <th valign="bottom" align="left" rowspan="1" colspan="1">GeMI</th>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Cell Line
</td>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Cell Line
</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
Cell Type
</td>
              <td align="left" rowspan="1" colspan="1">Classification
</td>
              <td align="left" rowspan="1" colspan="1">
Cell Type
</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
Tissue Type</td>
              <td align="left" rowspan="1" colspan="1">Biosample term name</td>
              <td align="left" rowspan="1" colspan="1">
Tissue</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Assay Name</td>
              <td align="left" rowspan="1" colspan="1">Technique</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Assay Type</td>
              <td align="left" rowspan="1" colspan="1">Technique Type</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Target of Assay</td>
              <td align="left" rowspan="1" colspan="1">Target</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Organism</td>
              <td align="left" rowspan="1" colspan="1">Species</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Life stage</td>
              <td align="left" rowspan="1" colspan="1">Life stage</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Age</td>
              <td align="left" rowspan="1" colspan="1">Age</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Age units</td>
              <td align="left" rowspan="1" colspan="1">Age units</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Sex</td>
              <td align="left" rowspan="1" colspan="1">Sex</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Ethnicity</td>
              <td align="left" rowspan="1" colspan="1">Ethnicity</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Health status</td>
              <td align="left" rowspan="1" colspan="1">Disease</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Classification</td>
              <td align="left" rowspan="1" colspan="1">Classification</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Investigated as</td>
              <td align="left" rowspan="1" colspan="1">Feature</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>GEO database structure. GEO data model (<ext-link xlink:href="https://www.ncbi.nlm.nih.gov/geo/info/overview.html" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/geo/info/overview.html</ext-link>) is composed of Samples, Series and Platforms records. In our work, we considered only Samples and Series. Any GEO series (GSE) represents an experiment that contains a collection of Samples (GSMs). We made the GEO repository searchable alternatively by GSE or GSM ids; specifically, we analyzed Samples’ metadata.</p>
      <p>Text Metadata Structure. Input descriptions are as shown on the upper area of <xref rid="F2" ref-type="fig">Figure 2</xref> and they correspond to the GEO metadata of the experimental Samples. For a bulk extraction of all the GEO samples’ metadata, we employed GEOparse Python library (<ext-link xlink:href="https://github.com/guma44/GEOparse" ext-link-type="uri">https://github.com/guma44/GEOparse</ext-link>), searching by the GSM identifiers available in Cistrome and ENCODE experiments. As in Cannizzaro <italic toggle="yes">et al.</italic> (<xref rid="R7" ref-type="bibr">7</xref>), we transformed the semi-structured metadata table of each GEO Sample into a plain text string built as follows: keys (i.e. column definitions) are enclosed in squared parentheses and values (i.e. cell contents) are reported unchanged, in the form [name of the field]: metadata-free-text. The model can thus understand and exploit the patterns given by the structure of the table. The sample shown in <xref rid="F2" ref-type="fig">Figure 2</xref> results as follows:</p>
      <fig position="float" id="F2" fig-type="figure">
        <label>Figure 2.</label>
        <caption>
          <p>Example input document and possible output format.</p>
        </caption>
        <graphic xlink:href="baac036f2" position="float"/>
      </fig>
      <p>[gsm]: gsm1565792 [title]: DC_MTB_H3K9me3_rep1 (ChIP-Seq) [sample type]: sra [source name]: Monocyte-derived dendritic cells [organism]: homo sapiens [characteristics]: condition: MTB-infected chip antibody: H3K9me3 (MABI, 0318, 13 001) [description]: …</p>
      <p>For a limited number of ENCODE’s experiments, the corresponding GSM identifier was not available. For such cases, we filled the [characteristic]: and [description]: metadata fields of the input text by concatenating the content of ENCODE attributes Description, Biosample summary and replicates.library.biosample.description.</p>
      <p>As part of the pre-processing, we changed the text into lowercase and we removed special characters such as ‘*’ and ‘_’. For complying with technological constraints of the GPT2 model, we removed all words that are &gt;30 characters (the limit in this work corresponds to 400 tokens) and because—by empirical evaluation—most long words do not contain relevant information for the task.</p>
    </sec>
    <sec id="s4-s2">
      <title>Model</title>
      <p>The model has been fine-tuned according to two requirements:</p>
      <list list-type="bullet">
        <list-item>
          <p>need to handle heterogeneous datasets by generating the union of all their attributes and</p>
        </list-item>
        <list-item>
          <p>need to predict each field independently from the others (for achieving better confidence of the predictions).</p>
        </list-item>
      </list>
      <p>To this end, our resulting model differs from the fine-tuned GPT2 in Cannizzaro <italic toggle="yes">et al.</italic> (<xref rid="R7" ref-type="bibr">7</xref>), which needed two different versions of the models and generated all attributes at the same time, taking the previously generated attributes as input to generate the next attribute.</p>
      <p>Here, instead, we propose a single fine-tuned model that can extract all the attributes provided from ENCODE and Cistrome; each attribute is extracted independently from the others. The output table generated one attribute at a time, exploiting the ‘task conditioning’ (<xref rid="R10" ref-type="bibr">10</xref>) meta-learning approach, which allows a model to perform as a multitask learner. In the case of GPT2, a multitask learning can be expressed as a conditional distribution P(output|input, task), where the task to be performed by the model is expressed in the form of text. In our context, we consider every attribute as a different task, so that a GPT2 model can extract a specific attribute when given the keyword ‘attribute_name’: as a task. An example formulation of fine-tuning training sample is given in <xref rid="T2" ref-type="table">Table 2</xref>.</p>
      <table-wrap position="float" id="T2">
        <label>Table 2.</label>
        <caption>
          <p>&lt;BOS&gt; &lt;SEP&gt; and &lt;EOS&gt; are special keywords that mean respectively ‘beginning of sentence’, ‘separated sentence’ and ‘end of the sentence’</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Input</th>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Task</th>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Output</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">&lt;BOS&gt; [Input sentence] &lt;SEP&gt;</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Cell line:</td>
              <td valign="top" align="left" rowspan="1" colspan="1">HeLa-S3 &lt;EOS &gt;</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s4-s3">
      <title>Model interpretability</title>
      <p>Deep learning models are able to find patterns and feature representation automatically. In our case, this allows to extract attributes that do not appear explicitly in the metadata of the experiment. For example, our model is able to infer the pair ‘Sex = Male’, just by knowing that the donor has prostate cancer. However, even when the model correctly extracts attributes, we cannot know if the result was achieved by exploiting wrong patterns. The AL framework offers support for such cases: the user must check prediction results and can potentially correct them. During this phase, it is critical that the user understands whether a given result is not only predicted correctly, but also whether it is predicted by exploiting a correct pattern/information. For such purpose, we resort to XAI techniques that allow the user to interpret the predictions of our model. Here, we focused on the generation of saliency maps, originally proposed for evaluating image classification (<xref rid="R38" ref-type="bibr">38</xref>), but recently applied to NLP (<xref rid="R39" ref-type="bibr">39</xref>). These are maps over the input that highlight the words that contributed the most to the extraction of given attributes. For predictions’ interpretation we have experimented three different approaches based on saliency maps, namely: LIME (Ribeiro <italic toggle="yes">et al.</italic> (<xref rid="R39" ref-type="bibr">39</xref>)), Attention (Bahdanau <italic toggle="yes">et al.</italic> (<xref rid="R40" ref-type="bibr">40</xref>)) and Gradient (Atanasova <italic toggle="yes">et al.</italic> (<xref rid="R9" ref-type="bibr">9</xref>)).</p>
      <p>LIME (<ext-link xlink:href="https://github.com/marcotcr/lime" ext-link-type="uri">https://github.com/marcotcr/lime</ext-link>) showed to be impractical in real-time systems like ours. The Attention mechanism, typical of all transformer-based models (Vaswani <italic toggle="yes">et al.</italic> (<xref rid="R13" ref-type="bibr">13</xref>)), made it hard to find which combination of attentions was the best to interpret the model. Empirical evaluation of this approach led to disappointing results but present high efficiency in terms of compute time as during inference time of the model generates both the interpretations and the prediction.</p>
      <p>We finally implemented a saliency map using the gradient-based technique InputXGrad (introduced by Kindermans <italic toggle="yes">et al.</italic> (<xref rid="R15" ref-type="bibr">15</xref>) and evaluated by Atanasova <italic toggle="yes">et al.</italic> (<xref rid="R9" ref-type="bibr">9</xref>)), exploiting the Ecco library (<xref rid="R41" ref-type="bibr">41</xref>) (<ext-link xlink:href="https://github.com/jalammar/ecco" ext-link-type="uri">https://github.com/jalammar/ecco</ext-link>) for our implementation with PyTorch (<ext-link xlink:href="https://pytorch.org/" ext-link-type="uri">https://pytorch.org/</ext-link>). Differently from the Attention approach, generating saliency maps considering only the attentions layers of the model, the gradient-based technique considers the whole model. Empirically, we verified that the results of this method are similar or better than our implemented attention approach. Our assessment was also confirmed by the results provided in (<xref rid="R9" ref-type="bibr">9</xref>), where the InputXGrad approach is compared with LIME. This interpretation technique was selected for inclusion in the GeMI tool. One example application (related to the GSM1348947 sample) can be appreciated in <xref rid="F3" ref-type="fig">Figure 3</xref>, where the ‘Sex = male’ was inferred from the information highlighted in blue, including the presence of benign prostate tissue.</p>
      <fig position="float" id="F3" fig-type="figure">
        <label>Figure 3.</label>
        <caption>
          <p>The gradient-based saliency map implemented in the GeMI tool. The words referring to the prediction of the ‘Sex’ attribute for the GSM1348947, ‘ms’, ‘benign tissue’, ‘benign prostate’ and ‘ms 36c7’ are highlighted because they are used by the model to predict the necessary fields.</p>
        </caption>
        <graphic xlink:href="baac036f3" position="float"/>
      </fig>
    </sec>
    <sec id="s4-s4">
      <title>Active learning framework</title>
      <p>Our AL framework adopts the model confidence as a metric to understand which data points are more informative for the model. For classification tasks, confidence is computed as the probability of the prediction. However, for text generation tasks, the definition is less trivial. In our scenario, a prediction is composed of a few words. Each token (i.e. a word or part of a word) of a text generated by a language model holds a probability that is conditioned by all the previous tokens. For computing the confidence of a single prediction, we thus combine a number of conditioned probabilities, with three possible approaches:</p>
      <list list-type="order">
        <list-item>
          <p>Multiply the probabilities of all the tokens. Note that GPT2 is a language model that uses sub-word tokens: for multi-token words, tokens after the first one exhibit a very high probability. In this way, when multiplying probabilities, second-to-last tokens do not lower the overall result.</p>
        </list-item>
        <list-item>
          <p>Select the lowest probability among the tokens (characterizing the most critical part of the text).</p>
        </list-item>
        <list-item>
          <p>Select the probability of the first token (considered the most informative part the text).</p>
        </list-item>
      </list>
      <p>Surprisingly, Options 1 and 2 generate too many low values, even when the model predicts values correctly. On the contrary, the third (naive) option is more calibrated with the correctness of the prediction of the model and performs reasonably well; it was thus adopted in our AL framework.</p>
      <p>Online Learning. Online learning is based on the idea of training a model as soon as new data become available. Implementing this mechanism in our framework has several advantages. First of all, it motivates the user by means of an instant visualization of the benefits of her work. Then, it diversifies the effort requested to the user, as explained next. In the considered scenario, new samples can be very similar to previously input data (especially when they belong to the same series). For this reason, a user could find that most errors of the predictor are repeated many times, leading to annoying interactions (labeling similar points does not give more information to the model). Online learning can mitigate this problem by prompting users to label similar samples only two times at most. As a drawback, after a while the model starts to forget the training data. To alleviate this drawback, every time a user labels a data point, this is added into a new dataset, which is used to augment our dataset when re-training the model.</p>
      <p>Active Learning Framework Design. The GeMI AL framework is designed to be as much user-friendly as possible; our aim is to provide genomic researchers with a fun, interesting and useful tool, which keeps them motivated to a continued use. This will prospectively allow us to keep collecting the data that are needed to improve the performance of the model. The four iterative phases of the AL framework are shown in <xref rid="F4" ref-type="fig">Figure 4</xref>:</p>
      <fig position="float" id="F4" fig-type="figure">
        <label>Figure 4.</label>
        <caption>
          <p>The four iterative phases of the AL framework.</p>
        </caption>
        <graphic xlink:href="baac036f4" position="float"/>
      </fig>
      <list list-type="order">
        <list-item>
          <p>The user provides a list of GSMs or GSEs identifiers. The model generates a table with the fields of the indicated GSM samples or of the GSM samples contained in the indicated GSE series.</p>
        </list-item>
        <list-item>
          <p>The samples with predicted fields are sorted by ascending order of low confidence fields, i.e. the sample with the highest number of low confidence fields is shown first, as it the one that needs user editing the most.</p>
        </list-item>
        <list-item>
          <p>The user edits the samples helped by the gradient saliency map (visualizing highlighted metadata text).</p>
        </list-item>
        <list-item>
          <p>Once the editing session is over, the model is trained with the new data; the sample is removed from the table. At the end of the training, the table is generated again, showing a new first sample in the table.</p>
        </list-item>
      </list>
      <p>The iteration is repeated: the user continues until the table ends or all the predictions show high confidence. We consider as highly confident each prediction with a confidence value above the green threshold value, which was set to 0.8. In the interface, we also use a yellow threshold value, set to 0.6, to signal lower confidence predictions. These threshold values were manually selected to provide for an intuitive interface. We leave to future work an investigation of i) the possible decoupling of the training threshold from the ones used in the interface and ii) the use of validation datasets and/or user feedback to tune these thresholds.</p>
    </sec>
  </sec>
  <sec id="s5">
    <title>Results</title>
    <sec id="s5-s1">
      <title>Experiments</title>
      <p><xref rid="F5" ref-type="fig">Figure 5</xref> summarizes the approach of our experiment. In order to evaluate the performance of our novel model we used the model of Cannizzaro <italic toggle="yes">et al.</italic> (<xref rid="R7" ref-type="bibr">7</xref>) for building two baselines, trained respectively with the dataset of Cistrome and ENCODE. We evaluated our model separately against the two baselines, both in terms of accuracy and of inference time.</p>
      <fig position="float" id="F5" fig-type="figure">
        <label>Figure 5.</label>
        <caption>
          <p>Schematic representation of the comparative experimental setting. On the right, separate models were trained on the ENCODE and Cistrome datasets (as presented in (<xref rid="R7" ref-type="bibr">7</xref>)). On the left, the task conditional setting presented in this work, employing the two training datasets together.</p>
        </caption>
        <graphic xlink:href="baac036f5" position="float"/>
      </fig>
      <p>Setup. For the training phase, on the Google Colab platform <ext-link xlink:href="https://colab.research.google.com" ext-link-type="uri">https://colab.research.google.com</ext-link>, we used the Tensor Processing Units (TPU) v2 with 8 cores and 16-bit precision; for evaluation of the accuracy and the inference time we used the NVIDIA Tesla T4 with 16GB ram. The model was developed using the PyTorch <ext-link xlink:href="https://pytorch.org" ext-link-type="uri">https://pytorch.org</ext-link> library. The Transformer library from HuggingFace <ext-link xlink:href="https://github.com/huggingface/transformers" ext-link-type="uri">https://github.com/huggingface/transformers</ext-link> was exploited for the tokenizer and for downloading the pretrained GPT2. To setup the training with the TPU, we used the PyTorch Lightning library <ext-link xlink:href="https://www.pytorchlightning.ai/" ext-link-type="uri">https://www.pytorchlightning.ai/</ext-link>. For training of our model and the baselines we used: i) for hyperparameters, CrossEntropy Loss Function; ii) an early-stop condition to avoid overfitting, with patient equal to 2 and min delta set to 0; iii) the Adam optimizer with a learning rate of 1e−4. In this work we used a batch size of 12. Note that, since we used a TPU with 8 cores in parallel and each core contains a replica of the model with a batch size of 12, the real batch size corresponds to 12 × 8 = 96. Finally, the used model is a fine-tuned GPT2 small architecture composed by 12 decoder layers, 12 head attentions and an embedding size of 768.</p>
      <p>We initially set the learning rate according to previous work on data extraction (<xref rid="R7" ref-type="bibr">7</xref>) to be 0.001; then we reduced it by a factor of 10 (while also increasing the batch size from 5 right up to 96), based on manual inspection of the produced learning curves. We did not perform sweep over hyper-parameter settings, as our focus is not to optimize performance on a fixed training set, but rather to develop a system and interface capable of soliciting feedback from users to improve performance of the system as rapidly as possible.</p>
      <p>Evaluation. The results of the accuracy comparison are shown in <xref rid="F6" ref-type="fig">Figure 6</xref>. Accuracy is computed considering the perfect match of the predicted strings; slight differences and synonyms are considered incorrect. Here we can appreciate that no relevant differences are measured in terms of accuracy. We can derive that the power of the GPT2 architectures depends on the quality of the dataset (which in this case is the same) and on the complexity of the architecture (in terms of number of layers, number of heads and dimension of the embeddings), as reported in literature. Moreover, we derive that the task conditioning mechanism does not affect the performance of the model in terms of accuracy. <xref rid="T3" ref-type="table">Table 3</xref> reports the results of the comparison of the inference times required by the baseline models and the GeMI model. In the first experiment, we evaluated the Cistrome baseline against the GeMI model only considering the Cell Line, Cell Type and Tissue Type attributes. In the second experiment, we evaluated the ENCODE baseline against all other attributes. In total, we considered 1000 samples; GeMI required a significantly shorter time.</p>
      <fig position="float" id="F6" fig-type="figure">
        <label>Figure 6.</label>
        <caption>
          <p>Bar plot representing the accuracy of experiments on the two separate baselines (trained on ENCODE or Cistrome data) and on our new model. On the <italic toggle="yes">x</italic>-axis we report all the attributes considered for prediction.</p>
        </caption>
        <graphic xlink:href="baac036f6" position="float"/>
      </fig>
      <table-wrap position="float" id="T3">
        <label>Table 3.</label>
        <caption>
          <p>Comparisons of inference time between (i) GeMI (with ENCODE-derived attributes) and the ENCODE baseline and (ii) GeMI (with Cistrome-derived attributes) and the Cistrome baseline</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Model</th>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Training time</th>
              <th valign="bottom" colspan="1" align="left" rowspan="1">Inference time per sample</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">GeMI (Cistrome attr. only)</td>
              <td align="left" rowspan="1" colspan="1">10 h</td>
              <td align="left" rowspan="1" colspan="1">0.27 s</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Baseline Cistrome</td>
              <td align="left" rowspan="1" colspan="1">2.49 h</td>
              <td align="left" rowspan="1" colspan="1">0.38 s</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GeMI (ENCODE attr. only)</td>
              <td align="left" rowspan="1" colspan="1">10 h</td>
              <td align="left" rowspan="1" colspan="1">0.49 s</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Baseline ENCODE</td>
              <td align="left" rowspan="1" colspan="1">0.58 h</td>
              <td align="left" rowspan="1" colspan="1">0.81 s</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s5-s2">
      <title>GeMI web application</title>
      <p><xref rid="F7" ref-type="fig">Figure 7</xref> provides an overview of the main front-end elements provided in GeMI. Panel A shows the list of loaded samples; for each of them, we show the Sample (GSM) and Experiment (GSE) under analysis and the unstructured text that describes the sample on GEO. Then, several columns represent the attributes recognized by the tool, e.g. Feature, Technique and Sex. The system tries to fill all such attributes based on the input text. Predictions are marked as accurate when accuracy is &gt; 0.8 (color code: green), to be verified when accuracy is between 0.8 and 0.6 (yellow), and probably wrong when accuracy is below 0.6 (red). From the top bar menu, users can access the samples loader, where samples are input as lists of GSMs or of enclosing GSEs either typed within a text box or uploaded by means of a text file. Additionally, they can export the results table in JSON or CSV format, delete the current uploaded samples and optionally save/resort to previously approved samples.</p>
      <fig position="float" id="F7" fig-type="figure">
        <label>Figure 7.</label>
        <caption>
          <p>Overview of the GeMI interface, divided in four panels. Panel A represents loaded samples with original and predicted information. Panel B provides the gradient-based saliency map related to the sample selected in the table above. Panel C shows the predicted values for the selected sample, also reporting the for accuracy of the prediction. Panel D allows users to actively modify the prediction of the model and save the suggestions.</p>
        </caption>
        <graphic xlink:href="baac036f7" position="float"/>
      </fig>
      <p>When a single row in Panel A is selected, Panel C (Extracted Fields) shows the detailed results obtained by the prediction for each attribute. When a specific field is selected here, Panel B shows the saliency map related to the model prediction of that specific attribute; blue highlight is used to inform users on which input text parts were used by the model to elaborate the prediction. Different shades, from lighter to darker, indicate how much (from weakly to strongly) the model exploited the highlighted information for the prediction. After inspection of this saliency map, users are invited to use the Edit Form in Panel D, where guidance (description and common values with external links) is provided to help make a decision. Here users can either (i) confirm the predicted value; (ii) set it as unknown (when the information should not be retrieved for the sample under scrutiny) or (iii) insert a new value manually. Once all the Extracted fields have been processed (i.e. they all turned green), the sample can be saved, thereby triggering a re-training session of the model and inserting the just processed sample within a list of annotated samples ready to be exported. Samples that have already been processed by users (i.e. for which the ‘Save Sample’ button has been pressed in the Panel C), can be recovered in the table of Panel A by using the switch button on the upper right corner of the panel.</p>
      <p>We note that in GeMI we make the implicit assumption that the users are well-intentioned domain experts. Indeed, users who offer to spend their valuable time providing annotations are expected to be subject matter experts who see the value in doing so (to train an automated system to obviate the need for manual data extraction). Moreover, given sufficient training labels we expect the error rate for the system to approach that of the manual annotators.</p>
    </sec>
    <sec id="s5-s3">
      <title>Basic use case</title>
      <p>Suppose a user is interested in acquiring the metadata of GEO experiments studying the K562 cell line. Tools such as GEOmetadb (<xref rid="R42" ref-type="bibr">42</xref>) and the GEO Datasets Browser (<ext-link xlink:href="https://www.ncbi.nlm.nih.gov/sites/GDSbrowser/" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/sites/GDSbrowser/</ext-link>) allow to select a list of GSMs (samples) or/and GSEs (series) that are related to the cell line of interest. This list can be loaded into GeMI; in this example, we suppose load the GSE11670 series. Once the GSE’s samples are loaded, the tool extracts the attributes for each of them and visualizes them in table of Panel A sorted by number of red attributes (i.e. with low confidence). Since the first considered sample (see GSM296608 as selected in <xref rid="F7" ref-type="fig">Figure 7</xref>) requires user supervision, it is automatically loaded in Panels B, C and D of <xref rid="F7" ref-type="fig">Figure 7</xref>. In Panel C, the user can select an extracted attribute (e.g. ‘Technique = rna-seq’ with 72% confidence), so that it is displayed in Panel B. Here, we show the words of the input text on which the model focused in order to predict the output attribute. Note, for instance, that the technique was inferred by using the information that i) the sample belongs to a particular experiment (GSE), as usually samples from the same experiment are also processed using a same assay; ii) the sample is of RNA type (thus, the assay is most likely an RNA sequencing); ii) the cell line was ‘untreated’ (from the title) or that the experiment was aimed at understanding the ‘effect’ of a specific medication (ICL670) on the cell line (from the description) and iii) the disease is leukemia (possibly because most of experiments on this kind of cancer in the training set were associated with this kind of assay).</p>
      <p>By selecting the various attributes, we can observe that for some of them (e.g. species) the model has predicted a word exactly as it appears in the input text; in other cases, instead, the attribute has been inferred from other words contained in the text. Moreover, we observe that the attributes related to the characteristics of the donor (i.e. Life stage, Age, Age units, Sex and Ethnicity) are deduced from the cell line K562. When these attributes are selected, within the ‘Field Description’ of the Edit Form (Panel D), links to relevant external databases of cell lines are provided; these may be of help when assessing the accuracy of the extracted information. Specifically, we link back to the American Type Culture Collection (<ext-link xlink:href="https://www.atcc.org/search" ext-link-type="uri">https://www.atcc.org/search</ext-link>) and to the Expasy Cellosaurus (<xref rid="R43" ref-type="bibr">43</xref>). This allows users to confirm that all the characteristics of the donor have been correctly deduced and that the model is confident with them. In this example, we observe that the model is not confident with the Tissue; a user check confirms that this is not the correct prediction. For correcting this field, users can use Panel D, ‘Insert new value’ option. For example, we insert ‘haematopoietic and lymphoid tissue’. By confirming our choices, the model is retrained. Once the new input is processed, the tool generates a new table of samples updated with this information. When there are no more errors in the table, users are invited to export the generated table with the dedicated button, for further inclusion in downstream pipelines or analyses.</p>
      <p>This use case is also shown in the video provided to users within our evaluation form (described next). Please mind that the results reported in this description refer to the very first test of the use case on the system, before it went through several re-training cycles following different use sessions with the evaluators and other testers.</p>
    </sec>
    <sec id="s5-s4">
      <title>Extended use case and tool comparison</title>
      <p>In this section we describe an extended example of how GeMI can be used to annotate relevant datasets by providing standardized metadata information, which is then exploited for downstream biological analysis. For comparison, the same task is performed with an alternative state-of-the-art tool, i.e. OnASSiS (<xref rid="R20" ref-type="bibr">20</xref>, <xref rid="R44" ref-type="bibr">44</xref>).</p>
      <p>We selected a relevant dataset from GEO, corresponding to all Chip-seq data of <italic toggle="yes">Homo s</italic><italic toggle="yes">apiens</italic>; in total, 6627 samples were extracted. For each sample, we pursue the computation of semantic annotations using the general format 〈information about cell type〉, 〈information about disease〉. Annotations performed with GeMI (proposed in this article) and the benchmark tool OnASSiS were compared. In GeMI, annotations were built by concatenating the ‘cell type’ and ‘health status’ attributes produced in output. In OnASSiS, the tool builds the desired annotations by selecting the ontological terms with minimum distance from the sample description; for this purpose, we used the Cell Ontology (<xref rid="R45" ref-type="bibr">45</xref>) for cell information and the Disease Ontology (<xref rid="R46" ref-type="bibr">46</xref>, <xref rid="R47" ref-type="bibr">47</xref>) for disease information,</p>
      <p>For the purpose of the comparison, we focused on samples dedicated to a small set of relevant factors, including both transcription factors (TFs) and histone modifications (HMs). Note that ‘factor’ field is automatically extracted by GeMI. For extracting comparable information from OnASSiS we instead resorted to Cistrome (<xref rid="R11" ref-type="bibr">11</xref>), by querying samples using GSM identifiers. Results were produced in the format 〈GSM, factor_list, semantic_annotation〉. Further numerical analysis was conducted to identify the sets of four TFs and HMs with the highest frequency in the dataset. <xref rid="T4" ref-type="table">Table 4</xref> reports the results obtained for sets of four factors that include POL2RA (i.e. the gene that encodes for DNA-directed RNA polymerase II subunit RPB1) and CTCF (i.e. a transcriptional repressor involved in many cellular processes). The left part of the table shows the factor lists for which OnASSiS produced the richest sets of annotations (max 13), whereas the right part reports the top scores achieved by GeMI. As a relevant example, we focus on the list ‘POLR2A, CTCF, H3K4me1, H3K4me3’ (highlighted in bold in the table), which has 8 annotations in OnASSiS and 16 in GeMI, listed in <xref rid="T5" ref-type="table">Table 5</xref>. Note that annotations provided by OnASSiS can be multiple (without measures to indicate priority), e.g. the third annotation has both ‘colorectal cancer’ and ‘cancer’ values. They are less specific than the ones found by GeMI; for instance, in the second semantic annotation predicted by OnASSiS, the attribute ‘cell’ is very generic and does not provide meaningful information about the cell type. The coupling of this term with the ‘unknown’ attribute referring to the disease condition makes the semantic annotation unusable for any subsequent biological analysis.</p>
      <table-wrap position="float" id="T4">
        <label>Table 4.</label>
        <caption>
          <p>Attributes describing SARS-CoV-2 sequences in four data sources</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>Factor list</bold>
              </td>
              <td valign="bottom" colspan="1" align="left" rowspan="1">
                <bold>#sem. annot</bold>
              </td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th valign="bottom" colspan="2" align="left" rowspan="1">Semantic annotations predicted by GeMI</th>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me3, H3K27ac</td>
              <td align="left" rowspan="1" colspan="1">16</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>POLR2A, CTCF, H3K4me1, H3K4me3</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <bold>16</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me1, H3K27ac</td>
              <td align="left" rowspan="1" colspan="1">15</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me3, H3K27me3</td>
              <td align="left" rowspan="1" colspan="1">15</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me3, unknown</td>
              <td align="left" rowspan="1" colspan="1">15</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me1, H3K36me3</td>
              <td align="left" rowspan="1" colspan="1">14</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me3, H3K36me3</td>
              <td align="left" rowspan="1" colspan="1">14</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me1, unknown</td>
              <td align="left" rowspan="1" colspan="1">14</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me1, H3K27me3</td>
              <td align="left" rowspan="1" colspan="1">14</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K27ac, H3K27me3</td>
              <td align="left" rowspan="1" colspan="1">14</td>
            </tr>
            <tr>
              <td colspan="2" align="left" rowspan="1">
                <bold>Semantic annotations predicted by OnASSiS</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K27me3, H3K4me3</td>
              <td align="left" rowspan="1" colspan="1">13</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K27ac, H3K4me3</td>
              <td align="left" rowspan="1" colspan="1">11</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K27me3, H3K27ac</td>
              <td align="left" rowspan="1" colspan="1">10</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K36me3, H3K4me3</td>
              <td align="left" rowspan="1" colspan="1">8</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K27me3, H3K36me3</td>
              <td align="left" rowspan="1" colspan="1">8</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, MYC, H3K4me3</td>
              <td align="left" rowspan="1" colspan="1">8</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>POLR2A, CTCF, H3K4me1, H3K4me3</bold>
              </td>
              <td align="left" rowspan="1" colspan="1">
                <bold>8</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me1, H3K27me3</td>
              <td align="left" rowspan="1" colspan="1">7</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K4me1, H3K27ac</td>
              <td align="left" rowspan="1" colspan="1">7</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">POLR2A, CTCF, H3K27ac, H3K36me3</td>
              <td align="left" rowspan="1" colspan="1">6</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap position="float" id="T5">
        <label>Table 5.</label>
        <caption>
          <p>List of semantic annotations for the set {POLR2A, CTCF, H3K4me1, H3K4me3}, using OnASSiS or GeMI</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Source</th>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Cell type</th>
              <th valign="bottom" align="left" rowspan="1" colspan="1">Disease</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">OnASSiS</td>
              <td align="left" rowspan="1" colspan="1">Cell, erythroblast</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Cell</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Endodermal cell</td>
              <td align="left" rowspan="1" colspan="1">Colorectal cancer, cancer</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Fibroblast</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Lining cell, mesodermal cell</td>
              <td align="left" rowspan="1" colspan="1">Cancer, chronic myeloid leukemia</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Lining cell</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Lining cell</td>
              <td align="left" rowspan="1" colspan="1">Neuroblastoma</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Progenitor cell</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GeMI</td>
              <td align="left" rowspan="1" colspan="1">B lymphocyte</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Embryonic stem cell</td>
              <td align="left" rowspan="1" colspan="1">Healthy</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Embryonic stem cell</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Epithelium</td>
              <td align="left" rowspan="1" colspan="1">Breast cancer (adenocarcinoma)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Epithelium</td>
              <td align="left" rowspan="1" colspan="1">Cervical adenocarcinoma</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Epithelium</td>
              <td align="left" rowspan="1" colspan="1">Hepatocellular carcinoma</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Epithelium</td>
              <td align="left" rowspan="1" colspan="1">Mammary ductal carcinoma</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Epithelium</td>
              <td align="left" rowspan="1" colspan="1">Prostate adenocarcinoma</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Epithelium</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Erythroblast</td>
              <td align="left" rowspan="1" colspan="1">Chronic myelogenous leukemia</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Erythroblast</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Fibroblast</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Keratinocyte</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="left" rowspan="1" colspan="1">Lymphoblastoid</td>
              <td align="left" rowspan="1" colspan="1">Unknown</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Finally, the described annotations can be used as input in a more complex pipeline that aims, for example, to compare combinations of functional elements in multiple biological conditions (<xref rid="R21" ref-type="bibr">21</xref>). For conducting such analysis we can use a library for genomic data querying such as pyGMQL (<xref rid="R48" ref-type="bibr">48</xref>, <xref rid="R49" ref-type="bibr">49</xref>) that allows to (i) extract the region data corresponding to the previously 6627 mentioned samples and (ii) verify which genomic regions are confirmed by at least one sample (i.e. a COVER(1,ANY) operation (<xref rid="R50" ref-type="bibr">50</xref>)), while grouping regions according to their factor and semantic annotation. Then, we identify functional states using ChromeHMM (<xref rid="R51" ref-type="bibr">51</xref>). Results for this analysis are shown in the <xref rid="sup1" ref-type="supplementary-material">Supplementary material (Figure S1)</xref>, where the use of more accurate and richer semantic annotation such as the ones obtained through GeMI allows identifying a larger spectrum of functional states of chromatin, unless lost with OnASSiS annotations.</p>
    </sec>
    <sec id="s5-s5">
      <title>User evaluation</title>
      <p>Study Rationale. In line with other tools’ empirical evaluations (<xref rid="R52" ref-type="bibr">52</xref>), we asked 30 users (15 with a Biology background and 15 with a computer science background), to complete the survey available at <ext-link xlink:href="https://forms.gle/VrAT5tiwHv7xZY299" ext-link-type="uri">https://forms.gle/VrAT5tiwHv7xZY299</ext-link>. After providing a brief introduction of GEO, GenoSurf (<xref rid="R19" ref-type="bibr">19</xref>) and the related metadata-integration problem, we described our proposed GeMI tool and provided a video tutorial (available at <ext-link xlink:href="https://youtu.be/HLcDDIQ69YA" ext-link-type="uri">https://youtu.be/HLcDDIQ69YA</ext-link>) with more detailed explanations about the system. Subsequently, we asked users to solve six operational tasks using the GeMI interface and to evaluate their overall experience through four additional questions. As previously mentioned, GeMI is based on an AL framework; this introduces a bias in the evaluation because training data are continually updated and improved as a result of progressive user corrections. To mitigate such bias, we assigned different samples to each user who evaluated the system. Specifically, we manually selected a set of samples that covered different types of experiments and tissues/cell lines so as to minimize the semantic overlap between the task proposed to one evaluator and the task proposed to the previous evaluators.</p>
      <p>Study Results. Users were asked to evaluate the intuitiveness of the GeMI interface to solve various tasks. As reported in <xref rid="F8" ref-type="fig">Figure 8</xref>, most users (<xref rid="R18" ref-type="bibr">18</xref>) rated this aspect with the maximum score 5/5; among these, 13 had a biological background and 5 a computer science background. Other 9 participants evaluated positively the intuitiveness of the tool (4/5 score), 6 being computer scientists and 3 biologists. Finally, three users evaluated the intuitiveness of the GeMI interface as low: two of them with a score of 2/5 and one with a score of 1/5 (all with a computer science background).</p>
      <fig position="float" id="F8" fig-type="figure">
        <label>Figure 8.</label>
        <caption>
          <p>Bar plot of the answers to the question about the intuitiveness of GeMI according to the survey participant.</p>
        </caption>
        <graphic xlink:href="baac036f8" position="float"/>
      </fig>
      <p>Users were also asked if they deemed GeMI useful in their research. As shown in <xref rid="F9" ref-type="fig">Figure 9</xref>, 12 users rated the tool with the maximum score 5/5; out of these, 9 had a biological background and 3 a computer science background. Then, 7 users rated GeMI’s usefulness with a 4/5 score; also in this case, the majority (<xref rid="R5" ref-type="bibr">5</xref>) was biologists, while the rest was computer scientists (<xref rid="R2" ref-type="bibr">2</xref>). Moreover, six people rated the tool’s usefulness with a score of 3/5 (four computer scientists and two biologists). Finally, six people rated GeMI’s usefulness as low (three with 2/5 and three with 1/5); all members of this group had a computer science background. No participant considered the interface useless. Results on the specific operational tasks confirmed that a considerable number of users found GeMI engaging, i.e. no user left the evaluation process before its end.</p>
      <fig position="float" id="F9" fig-type="figure">
        <label>Figure 9.</label>
        <caption>
          <p>Bar plot of the answers to the question about the usefulness of GeMI for user’s future researches according to the survey participants.</p>
        </caption>
        <graphic xlink:href="baac036f9" position="float"/>
      </fig>
      <p>User Feedback. At the end of the survey, we asked participants to provide answers to an open-ended question: Do you have any suggestions for improving the GeMI tool? The collected indications were clustered into four main areas of improvement: (i) additions to the data model; (ii) changes to the user interface; (iii) management of user corrections and (iv) improvement of training and re-training phases. The most relevant ideas expressed in participants’ comments are summarized in <xref rid="T6" ref-type="table">Table 6</xref>; they have been fundamental to apply improvements to the framework and inspired several future work developments, discussed in the next{} section.</p>
      <table-wrap position="float" id="T6">
        <label>Table 6.</label>
        <caption>
          <p>Taxonomy of user-provided suggestions for improvement of GeMI</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
          </colgroup>
          <tbody>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>Data model</bold>
                <break/>
                <list list-type="bullet">
                  <list-item>
                    <p>Consider additional fields provided by GEO (e.g. platform)</p>
                  </list-item>
                  <list-item>
                    <p>Allow a free schema, to include user-defined attributes (possibly, information about genotype or treatment)</p>
                  </list-item>
                  <list-item>
                    <p>Add more possibilities to denote unknown attribute values: non specified, not applicable, none User interface</p>
                  </list-item>
                  <list-item>
                    <p>Add information regarding the GSM in Panel B for user reference</p>
                  </list-item>
                  <list-item>
                    <p>Reshape screen to provide a more comprehensive initial view of panels</p>
                  </list-item>
                </list>
                <break/>
                <bold>User corrections</bold>
                <break/>
                <list list-type="bullet">
                  <list-item>
                    <p>Aim to user corrections’ normalization by providing guidelines and value references (e.g. for life stage values)</p>
                  </list-item>
                  <list-item>
                    <p>Provide feedback to the user when the sample to be annotated changes</p>
                  </list-item>
                </list>
                <break/>
                <bold>Training and re-training phases</bold>
                <break/>
                <list list-type="bullet">
                  <list-item>
                    <p>Return number and type of updated values after re-training</p>
                  </list-item>
                  <list-item>
                    <p>Perform a stronger training of the model with gene expression-related datasets (now skewed toward ChIP-seq)</p>
                  </list-item>
                  <list-item>
                    <p>Integrate the possibility of using parts of sentences suggested by users as ‘relevant for prediction’</p>
                  </list-item>
                </list>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
  </sec>
  <sec id="s6">
    <title>Toward GeMI version 2.0</title>
    <p>Threats to the robustness of GeMI can arise from the degradation of its model; this can happen because of model overfitting or noisy input from user (malicious or sub-standard users). The first aspect has been discussed in the Setup section. As to the latter, we cannot measure how reliable a user who annotates the data is in general. However, in a future version of the system, we propose to (i) retain a validation dataset (which has not been used for training) and monitor the prediction performances on that dataset, verifying that the model does not collapse and (ii) use checkpoints, where the original model is retained while the new suggestions from users are only applied to a new instance of the model. In the latter case, different instances are compared to measure the trend of performances, checking that—based on the contribution of a specific user—the performances do not drop essentially. Optimization of this strategy will also be addressed.</p>
    <p>We also plan to address several points from the feedback received from the study participants who left free-text comments. For example, a future version of GeMI will allow users to introduce new attributes to be extracted from the GEO description. It will also differentiate between different types of ‘unknown’ values, such as not present, not applicable, etc. We will also improve the guidance provided to users, supporting their annotation work with further tips, links to specialized ontologies (<xref rid="R53" ref-type="bibr">53</xref>) and reference tables and defining the set of valid values that a particular attribute can take. Finally, we will investigate whether it is possible to provide feedback to the domain expert on the extent to which their annotations improve the predictive performance of the model.</p>
  </sec>
  <sec id="s7">
    <title>Conclusions</title>
    <p>We built a GeMI tool where the model can handle many heterogeneous datasets and predict each field independently. The inference process is faster than the baseline (<xref rid="R7" ref-type="bibr">7</xref>), while accuracy, recall and precision are comparable to the ones of the baseline. As to the proposed gradient-based interpretation mechanism, it is effective in interpreting the predictions of the model and allows a faster and easier identification of errors in the predictions. The employed AL framework requires few user annotations, while offering an intuitive and simple interface. In the future we aim to use domain-specific ontologies support, in order to simplify the management of synonyms and increase the same real-world concepts matching. In addition, we will evaluate alternative pretrained models, e.g., Bidirectional and Auto-Regressive Transformers (BART), which has been shown to achieve good results on summarization tasks (<xref rid="R54" ref-type="bibr">54</xref>).</p>
    <p>Overall, the proposed approach and tool are a solid advancement in the user-aided metadata curation of genomic datasets. The simple output provided by GeMI backend suggests a straightforward embedding of our pipeline within more complicated data integration infrastructures, such as the one proposed by Bernasconi <italic toggle="yes">et al.</italic> (<xref rid="R18" ref-type="bibr">18</xref>) for extension of open data repositories (<xref rid="R19" ref-type="bibr">19</xref>). The prediction framework and the active learning-based interface are already being experimented within the context of new data types (e.g. extraction of mutation effects of SARS-CoV-2, the virus responsible for COVID-19) and we plan to generalize its use even further. With more extensive use of our tools, we will also conduct empirical studies aimed at quantifying the users’ gain when using them, e.g. by timing tasks performed by users.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>baac036_Supp</label>
      <media xlink:href="baac036_supp.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors would like to thank Giuseppe Cannizzaro for providing the basis and the initial implementation repository for this work and Arif Canakoglu for the support in the deep learning framework implementation.</p>
  </ack>
  <sec id="s8">
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Database</italic> Online.</p>
  </sec>
  <sec id="s9">
    <title>Funding</title>
    <p>None declared.</p>
  </sec>
  <sec id="s10">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec sec-type="data-availability" id="s11">
    <title>Data availability</title>
    <p>The GeMI tool is openly available at <ext-link xlink:href="http://gmql.eu/gemi/" ext-link-type="uri">http://gmql.eu/gemi/</ext-link>. The code is on GitHub at <ext-link xlink:href="https://github.com/armando2603/GeMI" ext-link-type="uri">https://github.com/armando2603/GeMI</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="R1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barrett</surname><given-names>T.</given-names></string-name>, <string-name><surname>Wilhite</surname><given-names>S.E.</given-names></string-name>, <string-name><surname>Ledoux</surname><given-names>P.</given-names></string-name></person-group><etal>et al.</etal> (<year>2012</year>) <article-title>NCBI GEO: archive for functional genomics data sets–update</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>41</volume>, <fpage>D991</fpage>–<lpage>D995</lpage>.<pub-id pub-id-type="pmid">23193258</pub-id></mixed-citation>
    </ref>
    <ref id="R2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kodama</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Shumway</surname><given-names>M.</given-names></string-name> and <string-name><surname>Leinonen</surname><given-names>R.</given-names></string-name></person-group> (<year>2011</year>) <article-title>The Sequence Read Archive: explosive growth of sequencing data</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>40</volume>, <fpage>D54</fpage>–<lpage>D56</lpage>.<pub-id pub-id-type="pmid">22009675</pub-id></mixed-citation>
    </ref>
    <ref id="R3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rustici</surname><given-names>G.</given-names></string-name>, <string-name><surname>Kolesnikov</surname><given-names>N.</given-names></string-name>, <string-name><surname>Brandizi</surname><given-names>M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2013</year>) <article-title>ArrayExpress update–trends in database growth and links to data analysis tools</article-title>. <source><italic toggle="yes">Sarkans U Nucleic Acids Res.</italic></source>, <volume>41</volume>, <fpage>987</fpage>–<lpage>990</lpage>.</mixed-citation>
    </ref>
    <ref id="R4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name>, <string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name>, <string-name><surname>Masseroli</surname><given-names>M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>The road towards data integration in human genomics: players, steps and interactions</article-title>. <source><italic toggle="yes">Brief. Bioinform.</italic></source>, <volume>22</volume>, <fpage>30</fpage>–<lpage>44</lpage>.<pub-id pub-id-type="pmid">32496509</pub-id></mixed-citation>
    </ref>
    <ref id="R5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schuster</surname><given-names>S.C.</given-names></string-name></person-group> (<year>2008</year>) <article-title>Next-generation sequencing transforms today’s biology</article-title>. <source><italic toggle="yes">Nat. Methods</italic></source>, <volume>5</volume>, <fpage>16</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">18165802</pub-id></mixed-citation>
    </ref>
    <ref id="R6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Lachmann</surname><given-names>A.</given-names></string-name> and <string-name><surname>Ma’ayan</surname><given-names>A.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Mining data and metadata from the gene expression omnibus</article-title>. <source><italic toggle="yes">Biophys. Rev.</italic></source>, <volume>11</volume>, <fpage>103</fpage>–<lpage>110</lpage>.<pub-id pub-id-type="pmid">30594974</pub-id></mixed-citation>
    </ref>
    <ref id="R7">
      <label>7.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cannizzaro</surname><given-names>G.</given-names></string-name>, <string-name><surname>Leone</surname><given-names>M.</given-names></string-name>, <string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>Automated integration of genomic metadata with sequence-to-sequence models</article-title>. In: <italic toggle="yes">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</italic>. <publisher-name>Springer</publisher-name>, Ghent, Belgium, pp. <fpage>187</fpage>–<lpage>203</lpage>.</mixed-citation>
    </ref>
    <ref id="R8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohn</surname><given-names>D.</given-names></string-name>, <string-name><surname>Atlas</surname><given-names>L.</given-names></string-name> and <string-name><surname>Ladner</surname><given-names>R.</given-names></string-name></person-group> (<year>1994</year>) <article-title>Improving generalization with active learning</article-title>. <source><italic toggle="yes">Mach. Learn.</italic></source>, <volume>15</volume>, <fpage>201</fpage>–<lpage>221</lpage>.</mixed-citation>
    </ref>
    <ref id="R9">
      <label>9.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Atanasova</surname><given-names>P.</given-names></string-name>, <string-name><surname>Simonsen</surname><given-names>J.G.</given-names></string-name>, <string-name><surname>Lioma</surname><given-names>C.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>A diagnostic study of explainability techniques for text classification</article-title>. <source>arXiv preprint arXiv:200913295</source>.</mixed-citation>
    </ref>
    <ref id="R10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radford</surname><given-names>A.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Child</surname><given-names>R.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>Language models are unsupervised multitask learners</article-title>. <source><italic toggle="yes">OpenAI Blog</italic></source>, <volume>1</volume>, <page-range>9</page-range>.</mixed-citation>
    </ref>
    <ref id="R11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zheng</surname><given-names>R.</given-names></string-name>, <string-name><surname>Wan</surname><given-names>C.</given-names></string-name>, <string-name><surname>Mei</surname><given-names>S.</given-names></string-name></person-group><etal>et al.</etal> (<year>2018</year>) <article-title>Cistrome Data Browser: expanded datasets and new tools for gene regulatory analysis</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>47</volume>, <fpage>D729</fpage>–<lpage>D735</lpage>.</mixed-citation>
    </ref>
    <ref id="R12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>Consortium ENCODE</collab></person-group>. (<year>2012</year>) <article-title>An integrated encyclopedia of DNA elements in the human genome</article-title>. <source><italic toggle="yes">Nature</italic></source>, <volume>489</volume>, <fpage>57</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">22955616</pub-id></mixed-citation>
    </ref>
    <ref id="R13">
      <label>13.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name>, <string-name><surname>Shazeer</surname><given-names>N.</given-names></string-name>, <string-name><surname>Parmar</surname><given-names>N.</given-names></string-name></person-group><etal>et al.</etal> (<year>2017</year>) <article-title>Attention is all you need</article-title>. In: <italic toggle="yes">Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS 2017)</italic>. Long Beach, CA, USA, pp. <fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="R14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Adadi</surname><given-names>A.</given-names></string-name> and <string-name><surname>Berrada</surname><given-names>M.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Peeking inside the black-box: a survey on explainable artificial intelligence (XAI)</article-title>. <source><italic toggle="yes">IEEE Access</italic></source>, <volume>6</volume>, <fpage>52138</fpage>–<lpage>52160</lpage>.</mixed-citation>
    </ref>
    <ref id="R15">
      <label>15.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kindermans</surname><given-names>P.J.</given-names></string-name>, <string-name><surname>Schütt</surname><given-names>K.</given-names></string-name>, <string-name><surname>Müller</surname><given-names>K.R.</given-names></string-name></person-group><etal>et al.</etal> (<year>2016</year>) <article-title>Investigating the influence of noise and distractors on the interpretation of neural networks</article-title>. <source>arXiv preprint arXiv:161107270</source>.</mixed-citation>
    </ref>
    <ref id="R16">
      <label>16.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name><string-name><surname>Ceri</surname><given-names>S.</given-names></string-name><string-name><surname>Campi</surname><given-names>A.</given-names></string-name></person-group><etal>et al.</etal> (<year>2017</year>) <part-title>conceptual modeling for genomics: building an integrated repository of open data</part-title>. In: <person-group person-group-type="editor"><string-name><surname>Mayr</surname><given-names>HC</given-names></string-name>, <string-name><surname>Guizzardi</surname><given-names>G</given-names></string-name>, <string-name><surname>Ma</surname><given-names>H</given-names></string-name>, <string-name><surname>Pastor</surname><given-names>O</given-names></string-name></person-group> (eds). <source><italic toggle="yes">Conceptual Modeling</italic></source>. <publisher-name>Springer International Publishing</publisher-name>, <publisher-loc>Cham</publisher-loc>, pp. <fpage>325</fpage>–<lpage>39</lpage>.</mixed-citation>
    </ref>
    <ref id="R17">
      <label>17.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ceri</surname><given-names>S.</given-names></string-name>, <string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name>, <string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name></person-group><etal>et al.</etal> (<year>2017</year>) <article-title>Overview of GeCo: a project for exploring and integrating signals from the genome</article-title>. In: <italic toggle="yes">International Conference on Data Analytics and Management in Data Intensive Domains</italic>. <publisher-name>Springer</publisher-name>, Moscow, Russia, pp. <fpage>46</fpage>–<lpage>57</lpage>.</mixed-citation>
    </ref>
    <ref id="R18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name>, <string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name>, <string-name><surname>Masseroli</surname><given-names>M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2020</year>) <article-title>META-BASE: a novel architecture for large-scale genomic metadata integration</article-title>. <source><italic toggle="yes">IEEE/ACM Trans. Comput. Biol. Bioinform.</italic></source>, <volume>19</volume>, <fpage>543</fpage>–<lpage>557</lpage>.</mixed-citation>
    </ref>
    <ref id="R19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name>, <string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name>, <string-name><surname>Colombo</surname><given-names>A.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>GenoSurf: metadata driven semantic search system for integrated genomic datasets</article-title>. <source><italic toggle="yes">Database</italic></source>, <page-range>2019</page-range>, baz132. doi: <pub-id pub-id-type="doi">10.1093/database/baz132</pub-id>.</mixed-citation>
    </ref>
    <ref id="R20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Galeota</surname><given-names>E.</given-names></string-name> and <string-name><surname>Pelizzola</surname><given-names>M.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Ontology-based annotations and semantic relations in large-scale (epi) genomics data</article-title>. <source><italic toggle="yes">Brief. Bioinformatics</italic></source>, <volume>18</volume>, <page-range>40312</page-range>.</mixed-citation>
    </ref>
    <ref id="R21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leone</surname><given-names>M.</given-names></string-name>, <string-name><surname>Galeota</surname><given-names>E.</given-names></string-name>, <string-name><surname>Masseroli</surname><given-names>M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>Identification, semantic annotation and comparison of combinations of functional elements in multiple biological conditions</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>38</volume>, <fpage>1183</fpage>–<lpage>1190</lpage>.</mixed-citation>
    </ref>
    <ref id="R22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hadley</surname><given-names>D.</given-names></string-name>, <string-name><surname>Pan</surname><given-names>J.</given-names></string-name>, <string-name><surname>El-Sayed</surname><given-names>O.</given-names></string-name></person-group><etal>et al.</etal> (<year>2017</year>) <article-title>Precision annotation of digital samples in NCBI’s gene expression omnibus</article-title>. <source><italic toggle="yes">Sci. Data.</italic></source>, <volume>4</volume>, <page-range>170125</page-range>.</mixed-citation>
    </ref>
    <ref id="R23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giles</surname><given-names>C.B.</given-names></string-name>, <string-name><surname>Brown</surname><given-names>C.A.</given-names></string-name>, <string-name><surname>Ripperger</surname><given-names>M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2017</year>) <article-title>ALE: automated label extraction from GEO metadata</article-title>. <source><italic toggle="yes">BMC Bioinform.</italic></source>, <volume>18</volume>, <page-range>509</page-range>.</mixed-citation>
    </ref>
    <ref id="R24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>G.</given-names></string-name>, <string-name><surname>Ramírez</surname><given-names>J.C.</given-names></string-name>, <string-name><surname>Deng</surname><given-names>N.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>Restructured GEO: restructuring Gene Expression Omnibus metadata for genome dynamics analysis</article-title>. <source><italic toggle="yes">Database</italic></source>, <volume>2019</volume>, bay145. doi: <pub-id pub-id-type="doi">10.1093/database/bay145</pub-id>.</mixed-citation>
    </ref>
    <ref id="R25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kalyan</surname><given-names>K.S.</given-names></string-name>, <string-name><surname>Rajasekharan</surname><given-names>A.</given-names></string-name> and <string-name><surname>Sangeetha</surname><given-names>S.</given-names></string-name></person-group> (<year>2021</year>) <article-title>AMMU: a survey of transformer-based biomedical pretrained language models</article-title>. <source><italic toggle="yes">J. Biomed. Inform.</italic></source>, <volume>126</volume>, <page-range>103982</page-range>.</mixed-citation>
    </ref>
    <ref id="R26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lan</surname><given-names>K.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>D.</given-names></string-name>, <string-name><surname>Fong</surname><given-names>S.</given-names></string-name></person-group><etal>et al.</etal> (<year>2018</year>) <article-title>A survey of data mining and deep learning in bioinformatics</article-title>. <source><italic toggle="yes">J. Med. Syst.</italic></source>, <volume>42</volume>, <page-range>120</page-range>.</mixed-citation>
    </ref>
    <ref id="R27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ofer</surname><given-names>D.</given-names></string-name>, <string-name><surname>Brandes</surname><given-names>N.</given-names></string-name> and <string-name><surname>Linial</surname><given-names>M.</given-names></string-name></person-group> (<year>2021</year>) <article-title>The language of proteins: NLP, machine learning &amp; protein sequences</article-title>. <source><italic toggle="yes">Comput Struct Biotechnol J</italic></source>, <volume>19</volume>, <fpage>1750</fpage>–<lpage>1758</lpage>.<pub-id pub-id-type="pmid">33897979</pub-id></mixed-citation>
    </ref>
    <ref id="R28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marquet</surname><given-names>C.</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Olenyi</surname><given-names>T.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>Embeddings from protein language models predict conservation and variant effects</article-title>. <source><italic toggle="yes">Hum. Genet.</italic></source>. <ext-link xlink:href="http://10.1007/s00439-021-02411-y" ext-link-type="uri">10.1007/s00439-021-02411-y</ext-link>.</mixed-citation>
    </ref>
    <ref id="R29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ji</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>H.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>37</volume>, <fpage>2112</fpage>–<lpage>2120</lpage>.</mixed-citation>
    </ref>
    <ref id="R30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>N.Q.K.</given-names></string-name>, <string-name><surname>Ho</surname><given-names>Q.T.</given-names></string-name>, <string-name><surname>Nguyen</surname><given-names>T.T.D.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>A transformer architecture based on BERT and 2D convolutional neural network to identify DNA enhancers from sequence information</article-title>. <source><italic toggle="yes">Brief. Bioinformatics</italic></source>, <volume>22</volume>, <page-range>bbab005</page-range>.</mixed-citation>
    </ref>
    <ref id="R31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Le</surname><given-names>N.Q.K.</given-names></string-name> and <string-name><surname>Ho</surname><given-names>Q.T.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Deep transformers and convolutional neural network in identifying DNA N6-methyladenine sites in cross-species genomes</article-title>. <source><italic toggle="yes">Methods</italic></source>.</mixed-citation>
    </ref>
    <ref id="R32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Raad</surname><given-names>J.</given-names></string-name>, <string-name><surname>Bugnon</surname><given-names>L.A.</given-names></string-name>, <string-name><surname>Milone</surname><given-names>D.H.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>miRe2e: a full end-to-end deep model based on transformers for prediction of pre-miRNAs</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>38</volume>, <fpage>1191</fpage>–<lpage>1197</lpage>.</mixed-citation>
    </ref>
    <ref id="R33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>J.</given-names></string-name>, <string-name><surname>Zhao</surname><given-names>L.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>A novel antibacterial peptide recognition algorithm based on BERT</article-title>. <source><italic toggle="yes">Brief. Bioinformatics</italic></source>, <volume>22</volume>, <page-range>Bbab200</page-range>.</mixed-citation>
    </ref>
    <ref id="R34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charoenkwan</surname><given-names>P.</given-names></string-name>, <string-name><surname>Nantasenamat</surname><given-names>C.</given-names></string-name>, <string-name><surname>Hasan</surname><given-names>M.M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2021</year>) <article-title>BERT4Bitter: a bidirectional encoder representations from transformers (BERT)-based model for improving the prediction of bitter peptides</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>37</volume>, <fpage>2556</fpage>–<lpage>2562</lpage>.</mixed-citation>
    </ref>
    <ref id="R35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clauwaert</surname><given-names>J.</given-names></string-name>, <string-name><surname>Menschaert</surname><given-names>G.</given-names></string-name> and <string-name><surname>Waegeman</surname><given-names>W.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Explainability in transformer models for functional genomics</article-title>. <source><italic toggle="yes">Brief. Bioinformatics</italic></source>, <volume>22</volume>, <page-range>Bbab060</page-range>.</mixed-citation>
    </ref>
    <ref id="R36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Warikoo</surname><given-names>N.</given-names></string-name>, <string-name><surname>Chang</surname><given-names>Y.C.</given-names></string-name> and <string-name><surname>Hsu</surname><given-names>W.L.</given-names></string-name></person-group> (<year>2021</year>) <article-title>LBERT: lexically aware transformer-based bidirectional encoder representation model for learning universal bio-entity relations</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>37</volume>, <fpage>404</fpage>–<lpage>412</lpage>.<pub-id pub-id-type="pmid">32810217</pub-id></mixed-citation>
    </ref>
    <ref id="R37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lai</surname><given-names>P.T.</given-names></string-name> and <string-name><surname>Lu</surname><given-names>Z.</given-names></string-name></person-group> (<year>2020</year>) <article-title>BERT-GT: cross-sentence n-ary relation extraction with BERT and Graph Transformer</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>36</volume>, <fpage>5678</fpage>–<lpage>5685</lpage>.</mixed-citation>
    </ref>
    <ref id="R38">
      <label>38.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Simonyan</surname><given-names>K.</given-names></string-name>, <string-name><surname>Vedaldi</surname><given-names>A.</given-names></string-name> and <string-name><surname>Zisserman</surname><given-names>A.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Deep inside convolutional networks: visualising image classification models and saliency maps</article-title>. <source>arXiv preprint arXiv:13126034</source>.</mixed-citation>
    </ref>
    <ref id="R39">
      <label>39.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ribeiro</surname><given-names>M.T.</given-names></string-name>, <string-name><surname>Singh</surname><given-names>S.</given-names></string-name> and <string-name><surname>Guestrin</surname><given-names>C.</given-names></string-name></person-group> (<year>2016</year>) <article-title>‘Why should i trust you?’ Explaining the predictions of any classifier</article-title>. In: <italic toggle="yes">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>, San Francisco, CA, USA, pp. <fpage>1135</fpage>–<lpage>1144</lpage>.</mixed-citation>
    </ref>
    <ref id="R40">
      <label>40.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bahdanau</surname><given-names>D.</given-names></string-name>, <string-name><surname>Cho</surname><given-names>K.</given-names></string-name> and <string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name></person-group> (<year>2014</year>) <article-title>Neural machine translation by jointly learning to align and translate</article-title>.</mixed-citation>
    </ref>
    <ref id="R41">
      <label>41.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Alammar</surname><given-names>J.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Ecco: an open source library for the explainability of transformer language models</article-title>. In: <italic toggle="yes">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</italic>, <publisher-name>Association for Computational Linguistics</publisher-name>.</mixed-citation>
    </ref>
    <ref id="R42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Davis</surname><given-names>S.</given-names></string-name>, <string-name><surname>Stephens</surname><given-names>R.</given-names></string-name></person-group><etal>et al.</etal> (<year>2008</year>) <article-title>GEOmetadb: powerful alternative search engine for the Gene Expression Omnibus</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>24</volume>, <fpage>2798</fpage>–<lpage>2800</lpage>.<pub-id pub-id-type="pmid">18842599</pub-id></mixed-citation>
    </ref>
    <ref id="R43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bairoch</surname><given-names>A.</given-names></string-name></person-group> (<year>2018</year>) <article-title>The Cellosaurus, a cell-line knowledge resource</article-title>. <source><italic toggle="yes">J. Biomol. Tech.</italic></source>, <volume>29</volume>, <page-range>25</page-range>.</mixed-citation>
    </ref>
    <ref id="R44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Galeota</surname><given-names>E.</given-names></string-name>, <string-name><surname>Kishore</surname><given-names>K.</given-names></string-name> and <string-name><surname>Pelizzola</surname><given-names>M.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Ontology-driven integrative analysis of omics data through OnASSiS</article-title>. <source><italic toggle="yes">Sci Rep</italic></source>, <volume>10</volume>, <fpage>1</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">31913322</pub-id></mixed-citation>
    </ref>
    <ref id="R45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diehl</surname><given-names>A.D.</given-names></string-name>, <string-name><surname>Meehan</surname><given-names>T.F.</given-names></string-name>, <string-name><surname>Bradford</surname><given-names>Y.M.</given-names></string-name></person-group><etal>et al.</etal> (<year>2016</year>) <article-title>The Cell Ontology 2016: enhanced content, modularization, and ontology interoperability</article-title>. <source><italic toggle="yes">J. Biomed. Semantics</italic></source>, <volume>7</volume>, <fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">26759709</pub-id></mixed-citation>
    </ref>
    <ref id="R46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schriml</surname><given-names>L.M.</given-names></string-name>, <string-name><surname>Mitraka</surname><given-names>E.</given-names></string-name>, <string-name><surname>Munro</surname><given-names>J.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>Human Disease Ontology 2018 update: classification, content and workflow expansion</article-title>. <source><italic toggle="yes">Nucleic Acids Res.</italic></source>, <volume>47</volume>, <fpage>D955</fpage>–<lpage>D962</lpage>.<pub-id pub-id-type="pmid">30407550</pub-id></mixed-citation>
    </ref>
    <ref id="R47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name>, and <string-name><surname>Masseroli</surname><given-names>M.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Biological and Medical Ontologies: Disease Ontology (DO)</article-title>. <source><italic toggle="yes">Reference Module in Life Sciences, Encyclopedia of Bioinformatics and Computational Biology</italic></source>, <volume>1</volume>, <fpage>838</fpage>–<lpage>847</lpage>.</mixed-citation>
    </ref>
    <ref id="R48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nanni</surname><given-names>L.</given-names></string-name>, <string-name><surname>Pinoli</surname><given-names>P.</given-names></string-name>, <string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>PyGMQL: scalable data extraction and analysis for heterogeneous genomic datasets</article-title>. <source><italic toggle="yes">BMC Bioinform.</italic></source>, <volume>20</volume>, <page-range>560</page-range>.</mixed-citation>
    </ref>
    <ref id="R49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masseroli</surname><given-names>M.</given-names></string-name>, <string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name>, <string-name><surname>Pinoli</surname><given-names>P.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>Processing of big heterogeneous genomic datasets for tertiary analysis of Next Generation Sequencing data</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>35</volume>, <fpage>729</fpage>–<lpage>736</lpage>.<pub-id pub-id-type="pmid">30101316</pub-id></mixed-citation>
    </ref>
    <ref id="R50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masseroli</surname><given-names>M.</given-names></string-name>, <string-name><surname>Pinoli</surname><given-names>P.</given-names></string-name>, <string-name><surname>Venco</surname><given-names>F.</given-names></string-name></person-group><etal>et al.</etal> (<year>2015</year>) <article-title>GenoMetric Query Language: a novel approach to large-scale genomic data management</article-title>. <source><italic toggle="yes">Bioinformatics</italic></source>, <volume>31</volume>, <fpage>1881</fpage>–<lpage>1888</lpage>.<pub-id pub-id-type="pmid">25649616</pub-id></mixed-citation>
    </ref>
    <ref id="R51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ernst</surname><given-names>J.</given-names></string-name> and <string-name><surname>Kellis</surname><given-names>M.</given-names></string-name></person-group> (<year>2012</year>) <article-title>ChromHMM: automating chromatin-state discovery and characterization</article-title>. <source><italic toggle="yes">Nat. Methods</italic></source>, <volume>9</volume>, <fpage>215</fpage>–<lpage>216</lpage>.<pub-id pub-id-type="pmid">22373907</pub-id></mixed-citation>
    </ref>
    <ref id="R52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name><string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name> and <string-name><surname>Ceri</surname><given-names>S.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Exploiting conceptual modeling for searching genomic metadata: A quantitative and qualitative empirical study</article-title>. In: <source><italic toggle="yes">International Conference on Conceptual Modeling</italic></source>. Springer, Cham, pp. <fpage>83</fpage>–<lpage>94</lpage>.</mixed-citation>
    </ref>
    <ref id="R53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernasconi</surname><given-names>A.</given-names></string-name><string-name><surname>Canakoglu</surname><given-names>A.</given-names></string-name><string-name><surname>Colombo</surname><given-names>A.</given-names></string-name></person-group><etal>et al.</etal> (<year>2018</year>) <article-title>Ontology-driven metadata enrichment for genomic datasets</article-title>. In: <source><italic toggle="yes">11th International Conference Semantic Web Applications and Tools for Life Sciences, SWAT4LS 2018</italic></source>, Vol. 2275. CEUR-WS. pp. <fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation>
    </ref>
    <ref id="R54">
      <label>54.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lewis</surname><given-names>M.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Goyal</surname><given-names>N.</given-names></string-name></person-group><etal>et al.</etal> (<year>2019</year>) <article-title>BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</article-title>. <ext-link xlink:href="https://arxiv.org/abs/1910.13461" ext-link-type="uri">https://arxiv.org/abs/1910.13461</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
