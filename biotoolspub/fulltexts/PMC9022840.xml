<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9022840</article-id>
    <article-id pub-id-type="pmid">35404958</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-21-01000</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1010050</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Physiology</subject>
          <subj-group>
            <subject>Physiological Parameters</subject>
            <subj-group>
              <subject>Body Weight</subject>
              <subj-group>
                <subject>Obesity</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Medical Microbiology</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Microbial Genomics</subject>
              <subj-group>
                <subject>Microbiome</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Microbial Genomics</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Metagenomics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Optimization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Molecular biology</subject>
          <subj-group>
            <subject>Molecular biology techniques</subject>
            <subj-group>
              <subject>Cloning</subject>
              <subj-group>
                <subject>DNA cloning</subject>
                <subj-group>
                  <subject>Shotgun Sequencing</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and analysis methods</subject>
        <subj-group>
          <subject>Molecular biology techniques</subject>
          <subj-group>
            <subject>Cloning</subject>
            <subj-group>
              <subject>DNA cloning</subject>
              <subj-group>
                <subject>Shotgun Sequencing</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Molecular Biology Techniques</subject>
            <subj-group>
              <subject>Sequencing Techniques</subject>
              <subj-group>
                <subject>Shotgun Sequencing</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Molecular Biology Techniques</subject>
          <subj-group>
            <subject>Sequencing Techniques</subject>
            <subj-group>
              <subject>Shotgun Sequencing</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Metabolism</subject>
            <subj-group>
              <subject>Metabolites</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Metabolism</subject>
            <subj-group>
              <subject>Metabolomics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Microbiome-based disease prediction with multimodal variational information bottlenecks</article-title>
      <alt-title alt-title-type="running-head">Microbiome-based disease prediction with multimodal variational information bottlenecks</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8888-133X</contrib-id>
        <name>
          <surname>Grazioli</surname>
          <given-names>Filippo</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Siarheyeu</surname>
          <given-names>Raman</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Alqassem</surname>
          <given-names>Israa</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1386-5372</contrib-id>
        <name>
          <surname>Henschel</surname>
          <given-names>Andreas</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pileggi</surname>
          <given-names>Giampaolo</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9666-8456</contrib-id>
        <name>
          <surname>Meiser</surname>
          <given-names>Andrea</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>NEC Laboratories Europe, Heidelberg, Germany</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Research and Data Intelligence Support Center, Khalifa University, Abu Dhabi, UAE</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Zhang</surname>
          <given-names>Zhaolei</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>University of Toronto, CANADA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>filippo.grazioli@neclab.eu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <volume>18</volume>
    <issue>4</issue>
    <elocation-id>e1010050</elocation-id>
    <history>
      <date date-type="received">
        <day>2</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Grazioli et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Grazioli et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1010050.pdf"/>
    <abstract>
      <p>Scientific research is shedding light on the interaction of the gut microbiome with the human host and on its role in human health. Existing machine learning methods have shown great potential in discriminating healthy from diseased microbiome states. Most of them leverage shotgun metagenomic sequencing to extract gut microbial species-relative abundances or strain-level markers. Each of these gut microbial profiling modalities showed diagnostic potential when tested separately; however, no existing approach combines them in a single predictive framework. Here, we propose the Multimodal Variational Information Bottleneck (MVIB), a novel deep learning model capable of learning a joint representation of multiple heterogeneous data modalities. MVIB achieves competitive classification performance while being faster than existing methods. Additionally, MVIB offers interpretable results. Our model adopts an information theoretic interpretation of deep neural networks and computes a joint stochastic encoding of different input data modalities. We use MVIB to predict whether human hosts are affected by a certain disease by jointly analysing gut microbial species-relative abundances and strain-level markers. MVIB is evaluated on human gut metagenomic samples from 11 publicly available disease cohorts covering 6 different diseases. We achieve high performance (0.80 &lt; ROC AUC &lt; 0.95) on 5 cohorts and at least medium performance on the remaining ones. We adopt a saliency technique to interpret the output of MVIB and identify the most relevant microbial species and strain-level markers to the model’s predictions. We also perform cross-study generalisation experiments, where we train and test MVIB on different cohorts of the same disease, and overall we achieve comparable results to the baseline approach, i.e. the Random Forest. Further, we evaluate our model by adding metabolomic data derived from mass spectrometry as a third input modality. Our method is scalable with respect to input data modalities and has an average training time of &lt; 1.4 seconds. The source code and the datasets used in this work are publicly available.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>The gut microbiome can be an indicator of various diseases due to its interaction with the human system. Our main objective is to improve on the current state of the art in microbiome classification for diagnostic purposes. A rich body of literature evidences the clinical value of microbiome predictive models. Here, we propose the Multimodal Variational Information Bottleneck (MVIB), a novel deep learning model for microbiome-based disease prediction. MVIB learns a joint stochastic encoding of different input data modalities to predict the output class. We use MVIB to predict whether human hosts are affected by a certain disease by jointly analysing gut microbial species-relative abundance and strain-level marker profiles. Both of these gut microbial features showed diagnostic potential when tested separately in previous studies; however, no research has combined them in a single predictive tool. We evaluate MVIB on various human gut metagenomic samples from 11 publicly available disease cohorts. MVIB achieves competitive performance compared to state-of-the-art methods. Additionally, we evaluate our model by adding metabolomic data as a third input modality and we show that MVIB is scalable with respect to input feature modalities. Further, we adopt a saliency technique to interpret the output of MVIB and identify the most relevant microbial species and strain-level markers to our model predictions.</p>
    </abstract>
    <funding-group>
      <funding-statement>The author(s) received no specific funding for this work.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="2"/>
      <page-count count="27"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2022-04-21</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The code and the datasets used in this work are publicly available at <ext-link xlink:href="https://zenodo.org/record/6433860" ext-link-type="uri">https://zenodo.org/record/6433860</ext-link>, as well as in the following GitHub repository <ext-link xlink:href="https://github.com/nec-research/microbiome-mvib" ext-link-type="uri">https://github.com/nec-research/microbiome-mvib</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The code and the datasets used in this work are publicly available at <ext-link xlink:href="https://zenodo.org/record/6433860" ext-link-type="uri">https://zenodo.org/record/6433860</ext-link>, as well as in the following GitHub repository <ext-link xlink:href="https://github.com/nec-research/microbiome-mvib" ext-link-type="uri">https://github.com/nec-research/microbiome-mvib</ext-link>.</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic toggle="yes">PLOS Computational Biology</italic> Methods paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>The human microbiota consist of various microbial communities that live in and on our bodies. These communities are composed of different species of bacteria, archaea, protists, fungi and viruses [<xref rid="pcbi.1010050.ref001" ref-type="bibr">1</xref>]. Together, they constitute complex and diverse ecosystems that interact with the human host. When we refer to microbiota together with their genomic information, we use the term <italic toggle="yes">microbiome</italic>. Previous research estimated that the genes in the gut microbiome alone outnumber the human genes by two orders of magnitude [<xref rid="pcbi.1010050.ref002" ref-type="bibr">2</xref>]. Recent studies showed that the human microbiota play key roles in human health state [<xref rid="pcbi.1010050.ref003" ref-type="bibr">3</xref>]. The presence of microbiota benefits the host as they enable important chemical processes, e.g., they maintain homeostasis, develop the immune system and help in harvesting various nutrients that are otherwise inaccessible [<xref rid="pcbi.1010050.ref003" ref-type="bibr">3</xref>, <xref rid="pcbi.1010050.ref004" ref-type="bibr">4</xref>]. Previous research reported that altered states of microbiota can contribute to carcinogenesis and affect therapeutic response in cancer patients [<xref rid="pcbi.1010050.ref005" ref-type="bibr">5</xref>]. [<xref rid="pcbi.1010050.ref006" ref-type="bibr">6</xref>] reviewed the role of microbiota in human health and disease and anticipated a potential use of microbiota analysis for disease diagnosis and prediction.</p>
    <p>Over the past two decades, several large-scale microbial profiling projects were established, such as the Human Microbiome Project [<xref rid="pcbi.1010050.ref007" ref-type="bibr">7</xref>] and the MetaHIT (Metagenomics of the Human Intestinal Tract) project [<xref rid="pcbi.1010050.ref008" ref-type="bibr">8</xref>]. These projects aimed at investigating the nature of the microbial components of the human genetic and metabolic landscape and their link to various diseases. However, despite various attempts to develop unified best practices, truly standardised approaches in microbiome research have not yet been established [<xref rid="pcbi.1010050.ref009" ref-type="bibr">9</xref>–<xref rid="pcbi.1010050.ref011" ref-type="bibr">11</xref>]. Therefore, we are in need for various statistical and machine learning models that leverage high throughput metagenomic data with supervised and unsupervised learning techniques.</p>
    <p>Shotgun metagenomic sequencing allows comprehensive sampling of all genes in all microorganisms that are present in a given sample. This technology enables researchers to examine microbial diversity and to detect their abundances in different environments. In comparison to 16S rRNA gene sequencing technology, shotgun metagenomic sequencing provides higher resolution profiles at species and strain levels. Existing machine learning methods leverage shotgun metagenomics to extract gut microbial species abundance or strain-level marker profiles to differentiate healthy from diseased human hosts. Both of these gut microbial features showed diagnostic potential [<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>, <xref rid="pcbi.1010050.ref013" ref-type="bibr">13</xref>] and have been used separately in previous research for microbiome-based disease prediction.</p>
    <p>Current microbiome-based disease prediction approaches either use species-relative abundance or strain-level marker profiles. [<xref rid="pcbi.1010050.ref014" ref-type="bibr">14</xref>, <xref rid="pcbi.1010050.ref015" ref-type="bibr">15</xref>] solve the disease prediction task by applying deep learning to abundance profiles from human gut microbiome. MetAML [<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>] solves the disease prediction task by applying classical machine learning algorithms to either abundance or marker profiles. MicroPheno [<xref rid="pcbi.1010050.ref016" ref-type="bibr">16</xref>] sub-samples 16S rRNA sequences via bootstrapping, then computes k-mer representations of the sub-sampled sequences, after that it uses the produced k-mer representations for disease prediction. DeepMicro [<xref rid="pcbi.1010050.ref017" ref-type="bibr">17</xref>] leverages deep representation learning with autoencoders to compute encodings of either microbiome species abundance or marker profiles, i.e., it transforms high-dimensional microbiome data into a low-dimensional representation, then it applies classical machine learning classification models on the generated representations for disease prediction. [<xref rid="pcbi.1010050.ref018" ref-type="bibr">18</xref>] solves the prediction of cardiovascular disease by using supervised learning on taxonomic features, i.e., microbial taxa. PopPhy-CNN [<xref rid="pcbi.1010050.ref019" ref-type="bibr">19</xref>] represents microbial phylogenetic tree and relative abundances of microbial taxa in a single matrix and solves disease prediction via a convolutional neural network (CNN). The SIAMCAT R package [<xref rid="pcbi.1010050.ref020" ref-type="bibr">20</xref>] provides a toolbox for statistical inference of associations between microbial communities and host phenotypes. Its feature matrix consists of abundances of microbial taxa, genes, or pathways across all samples, in addition to optional meta-variables, such as demographics, lifestyles, donor clinical records.</p>
    <p>Also related to our work is [<xref rid="pcbi.1010050.ref021" ref-type="bibr">21</xref>], which explores various statistical methodologies for the analysis of multi-table heterogeneous data for microbiome research. This work combines the analysis of body mass composition information and 16S rRNA abundances in a single computational framework, but does not specifically address disease prediction.</p>
    <p>A rich body of literature evidences the clinical value of microbiome predictive models, e.g., [<xref rid="pcbi.1010050.ref022" ref-type="bibr">22</xref>]. Hence, our main objective is to improve the current state of the art in microbiome-based disease classification for diagnostic purposes by combining multimodal data sources. To the best of our knowledge, none of the existing approaches is capable of solving this task by efficiently combining features from heterogeneous data modalities. Here, we present the Multimodal Variational Information Bottleneck (MVIB), a novel multimodal generalisation of the Deep Variational Information Bottleneck (Deep VIB) [<xref rid="pcbi.1010050.ref023" ref-type="bibr">23</xref>]. MVIB is a microbiome-disease classification method. It leverages the theory of the Information Bottleneck (IB) [<xref rid="pcbi.1010050.ref024" ref-type="bibr">24</xref>] to learn a meaningful joint encoding from different input data modalities, e.g. species-relative abundance, strain-level marker profiles and metabolomic data. The joint encoding learned by MVIB is maximally compressive of the heterogeneous input data modalities and at the same time is maximally expressive of the target class, i.e. diseased or healthy human host. By design, MVIB is scalable with respect to input data modalities.</p>
    <p>We evaluate MVIB on 11 different metagenomic datasets from human gut microbiome. In this paper, we show how MVIB performs when combining species-relative abundances and strain-level markers. Additionally, we demonstrate how MVIB works in a trimodal setting by adding metabolomic data as a third modality. We benchmark MVIB against state-of-the-art methods, i.e. DeepMicro, PopPhy-CNN and Random Forest. Additionally, we adopt a saliency technique derived from computer vision literature [<xref rid="pcbi.1010050.ref025" ref-type="bibr">25</xref>] to interpret the output of MVIB and identify most discriminative microbial species and strain-level markers with respect to various human diseases. Furthermore, we perform various transfer learning [<xref rid="pcbi.1010050.ref026" ref-type="bibr">26</xref>, <xref rid="pcbi.1010050.ref027" ref-type="bibr">27</xref>] experiments, as well as cross-study generalisation experiments where we train and test MVIB on different cohorts of the same disease.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Materials and methods</title>
    <sec id="sec003">
      <title>Datasets</title>
      <p>For evaluation and comparative benchmark analysis, we consider publicly available human gut metagenomic samples from 11 different cohorts that cover 6 different diseases. These diseases are inflammatory bowel disease (<italic toggle="yes">IBD</italic>), type 2 diabetes in Europe (women) (<italic toggle="yes">EW-T2D</italic>) and in China (women and men) (<italic toggle="yes">C-T2D</italic>), obesity (<italic toggle="yes">Obesity</italic>, <italic toggle="yes">Obesity-Joint</italic>), liver cirrhosis (<italic toggle="yes">Cirrhosis</italic>), colorectal cancer (<italic toggle="yes">Colorectal</italic>, <italic toggle="yes">Colorectal-EMBL</italic>, <italic toggle="yes">Early-Colorectal-EMBL</italic>, <italic toggle="yes">Colorectal-Metabolic</italic>) and chronic high blood pressure (<italic toggle="yes">Hypertension</italic>). The names in parentheses indicate the cohort identifiers that we used in this work. The number of affected and control subjects in each cohort are listed in <xref rid="pcbi.1010050.t001" ref-type="table">Table 1</xref>.</p>
      <table-wrap position="float" id="pcbi.1010050.t001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Datasets overview.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1010050.t001" id="pcbi.1010050.t001g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Dataset name</th>
                <th align="center" rowspan="1" colspan="1">Samples</th>
                <th align="center" rowspan="1" colspan="1">Controls</th>
                <th align="center" rowspan="1" colspan="1">Affected</th>
                <th align="left" rowspan="1" colspan="1">Data source</th>
                <th align="center" rowspan="1" colspan="1">Modalities</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">IBD</td>
                <td align="center" rowspan="1" colspan="1">110</td>
                <td align="center" rowspan="1" colspan="1">85</td>
                <td align="center" rowspan="1" colspan="1">25</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>], [<xref rid="pcbi.1010050.ref008" ref-type="bibr">8</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EW-T2D</td>
                <td align="center" rowspan="1" colspan="1">96</td>
                <td align="center" rowspan="1" colspan="1">43</td>
                <td align="center" rowspan="1" colspan="1">53</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>], [<xref rid="pcbi.1010050.ref029" ref-type="bibr">29</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">C-T2D</td>
                <td align="center" rowspan="1" colspan="1">344</td>
                <td align="center" rowspan="1" colspan="1">174</td>
                <td align="center" rowspan="1" colspan="1">170</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>], [<xref rid="pcbi.1010050.ref030" ref-type="bibr">30</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Obesity</td>
                <td align="center" rowspan="1" colspan="1">253</td>
                <td align="center" rowspan="1" colspan="1">89</td>
                <td align="center" rowspan="1" colspan="1">164</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>], [<xref rid="pcbi.1010050.ref031" ref-type="bibr">31</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Obesity-Joint</td>
                <td align="center" rowspan="1" colspan="1">331</td>
                <td align="center" rowspan="1" colspan="1">117</td>
                <td align="center" rowspan="1" colspan="1">214</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>], [<xref rid="pcbi.1010050.ref031" ref-type="bibr">31</xref>], [<xref rid="pcbi.1010050.ref032" ref-type="bibr">32</xref>], [<xref rid="pcbi.1010050.ref033" ref-type="bibr">33</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ΔObesity</td>
                <td align="center" rowspan="1" colspan="1">78</td>
                <td align="center" rowspan="1" colspan="1">28</td>
                <td align="center" rowspan="1" colspan="1">50</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref032" ref-type="bibr">32</xref>], [<xref rid="pcbi.1010050.ref033" ref-type="bibr">33</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Cirrhosis</td>
                <td align="center" rowspan="1" colspan="1">232</td>
                <td align="center" rowspan="1" colspan="1">114</td>
                <td align="center" rowspan="1" colspan="1">118</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>], [<xref rid="pcbi.1010050.ref034" ref-type="bibr">34</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Colorectal</td>
                <td align="center" rowspan="1" colspan="1">121</td>
                <td align="center" rowspan="1" colspan="1">73</td>
                <td align="center" rowspan="1" colspan="1">48</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>], [<xref rid="pcbi.1010050.ref035" ref-type="bibr">35</xref>] (cohort F)</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Colorectal-EMBL</td>
                <td align="center" rowspan="1" colspan="1">199</td>
                <td align="center" rowspan="1" colspan="1">103</td>
                <td align="center" rowspan="1" colspan="1">96</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref035" ref-type="bibr">35</xref>] (cohorts F/G)</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ΔColorectal</td>
                <td align="center" rowspan="1" colspan="1">78</td>
                <td align="center" rowspan="1" colspan="1">30</td>
                <td align="center" rowspan="1" colspan="1">48</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref035" ref-type="bibr">35</xref>] (cohorts F/G)</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Early-Colorectal-EMBL</td>
                <td align="center" rowspan="1" colspan="1">96</td>
                <td align="center" rowspan="1" colspan="1">52</td>
                <td align="center" rowspan="1" colspan="1">44</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref035" ref-type="bibr">35</xref>] (cohorts F/G)</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Hypertension</td>
                <td align="center" rowspan="1" colspan="1">196</td>
                <td align="center" rowspan="1" colspan="1">40</td>
                <td align="center" rowspan="1" colspan="1">156</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref036" ref-type="bibr">36</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Colorectal-Metabolic</td>
                <td align="center" rowspan="1" colspan="1">347</td>
                <td align="center" rowspan="1" colspan="1">127</td>
                <td align="center" rowspan="1" colspan="1">220</td>
                <td align="left" rowspan="1" colspan="1">[<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>]</td>
                <td align="center" rowspan="1" colspan="1">Abundance, Markers, Metabolites</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>We obtained pre-processed human gut metagenomic data for the IBD, EW-T2D, C-T2D, Obesity, Cirrhosis and Colorectal cohorts from the MetAML repository [<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>]. We also considered five additional disease cohorts, i.e. Obesity-Joint [<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>, <xref rid="pcbi.1010050.ref031" ref-type="bibr">31</xref>–<xref rid="pcbi.1010050.ref033" ref-type="bibr">33</xref>], Colorectal-EMBL [<xref rid="pcbi.1010050.ref035" ref-type="bibr">35</xref>] (cohorts F and G), Early-Colorectal-EMBL [<xref rid="pcbi.1010050.ref035" ref-type="bibr">35</xref>], Colorectal-Metabolic [<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>] and Hypertension [<xref rid="pcbi.1010050.ref036" ref-type="bibr">36</xref>]. For the latter cohorts, we performed the data pre-processing steps highlighted in <xref rid="pcbi.1010050.g001" ref-type="fig">Fig 1A and 1B</xref> and described later in detail in Section Pre-processing.</p>
      <fig position="float" id="pcbi.1010050.g001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Full workflow.</title>
          <p>(A) The raw data, i.e., shotgun metagenomic sequencing data of the human gut microbiome. (B) For pre-processing, we leverage MetaPhlAn2 and MetAML to extract species-relative abundances and strain-level markers. We consider two pre-processing schemes to produce two different dataset collections, <italic toggle="yes">default</italic> (D) and <italic toggle="yes">joint</italic> (J). (C) A high-level representation of the probabilistic encoders of the MVIB model. (D) The Product of Experts computes a single joint posterior i.e. <bold><italic toggle="yes">z</italic></bold>; the joint posterior <bold><italic toggle="yes">z</italic></bold> is sampled with the reparametrisation trick [<xref rid="pcbi.1010050.ref028" ref-type="bibr">28</xref>]. (E) A logistic regression decoder estimates the probability of whether a subject is affected by a certain disease. (F, G) The gradients of the output class are computed with respect to (w.r.t) the input vectors and used to compute saliency maps.</p>
        </caption>
        <graphic xlink:href="pcbi.1010050.g001" position="float"/>
      </fig>
      <p>Early-Colorectal-EMBL presents 96 affected samples from the Colorectal-EMBL dataset, where 52 subjects are labelled as “early stage” (colorectal cancer stages 0, I and II) and 44 are labelled as “late stage” (stages III and IV). The Hypertension cohort presents samples from Chinese individuals with pre-hypertension (pHTN) or primary hypertension (HTN), as well as healthy control samples [<xref rid="pcbi.1010050.ref036" ref-type="bibr">36</xref>]; we consider both pHTN and HTN subjects (156 in total) as affected. The Colorectal dataset from MetAML repository is a subset of Colorectal-EMBL, therefore we create Δ<italic toggle="yes">Colorectal</italic> = <italic toggle="yes">Colorectal-EMBL</italic> − <italic toggle="yes">Colorectal</italic> to address the samples which only belong to the larger dataset. Similarly, Obesity is a subset of Obesity-Joint, hence we create Δ<italic toggle="yes">Obesity</italic> = <italic toggle="yes">Obesity-Joint</italic> − <italic toggle="yes">Obesity</italic>.</p>
      <p>In addition to the datasets discussed so far, which present two data modalities, we performed experiments on a trimodal dataset. To this end, we included metabolite profiles in addition to species-relative abundance and strain-level marker profiles. We extracted 347 samples with both metabolomic and metagenomic data from [<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>], which proposes a large cohort of participants who underwent colonoscopy to assess taxonomic and functional characteristics of the gut microbiota and metabolites. The metabolomic data was extracted by means of capillary electrophoresis time-of-flight mass spectrometry (CE-TOFMS). In this dataset, 220 samples belong to subjects affected by colorectal cancer, polypoid adenomas or intramucosal carcinomas, in addition to more advanced lesions. The remaining 127 samples belong to healthy individuals. We refer to this trimodal dataset as <italic toggle="yes">Colorectal-Metabolic</italic>.</p>
      <p>All datasets include ground truth labels (i.e., healthy or affected) which refer to the time the microbiome samples were collected. Hence, in this work, we do not predict a future health status.</p>
    </sec>
    <sec id="sec004">
      <title>Pre-processing</title>
      <p>We run all metagenomic samples that were not taken from [<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>] (i.e. Colorectal-EMBL, Early-Colorectal-EMBL, Obesity-Joint, Hypertension and Colorectal-Metabolic datasets) through a quality control and MetaPhlAn2-based annotation pipeline. This allowed us to get species-relative abundance and strain-level marker profiles in the same format as the datasets taken from the MetAML repository [<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>].</p>
      <p>We downloaded whole-genome shotgun metagenomic sequencing data from the bioproject repositories of the National Center for Biotechnology Information (NCBI). Raw read data for each sequencing run were converted into FASTQ format using fastq-dump version 2.8.0 (NCBI SRA Toolkit [<xref rid="pcbi.1010050.ref038" ref-type="bibr">38</xref>]) and aggregated by sample identifiers. Afterwards, we used Kneaddata version 0.7.4 [<xref rid="pcbi.1010050.ref039" ref-type="bibr">39</xref>] with default parameters to perform quality control of the sequencing reads and remove reads of length &lt; 60 base pairs (bp). Finally, we run MetaPhlAn2 (Metagenomic Phylogenetic Analysis) [<xref rid="pcbi.1010050.ref040" ref-type="bibr">40</xref>] for profiling the compositions of microbial communities from the quality-controlled data. MetAML <monospace>dataset_selection.py</monospace> [<xref rid="pcbi.1010050.ref012" ref-type="bibr">12</xref>] was used to leave only species-level information in the abundance profiles. Obtained species-relative abundances and strain-level markers make up the feature vectors of our machine learning model.</p>
      <p>We created two collections of cohort datasets, i.e. <italic toggle="yes">default</italic> and <italic toggle="yes">joint</italic>. Each collection includes all the cohorts. The datasets in the <italic toggle="yes">default</italic> (D) collection are obtained with the MetaPhlAn2+MetAML pre-processing described above. In the <italic toggle="yes">joint</italic> (J) collection, species abundances and strain-level markers are homogeneous across all datasets. We achieved this by taking the union of all features from the various datasets. This guarantees that species abundance and strain-level marker profiles have the same dimensionality across cohorts. We created the <italic toggle="yes">joint</italic> collection for transfer learning (Section Transfer learning) and cross-study generalisation (Section Cross-study generalisation) experiments. We applied feature normalisation to the final sets of species abundances in both collections to obtain species-relative abundances <inline-formula id="pcbi.1010050.e001"><alternatives><graphic xlink:href="pcbi.1010050.e001.jpg" id="pcbi.1010050.e001g" position="anchor"/><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. The dimensionality of the species abundance feature vectors is &lt; 10<sup>3</sup>.</p>
      <p>The strain-level marker profiles are represented by a vector of binary variables, where 0 indicates the absence of a certain strain and 1 indicates its presence. The dimensionality of the strain-level markers feature vectors is &lt; 10<sup>5</sup>.</p>
    </sec>
    <sec id="sec005">
      <title>The multimodal variational information bottleneck</title>
      <p>Let <italic toggle="yes">Y</italic> be a random variable representing a ground truth label associated with a set of multimodal input random variables <italic toggle="yes">X</italic><sup>1</sup>, …, <italic toggle="yes">X</italic><sup><italic toggle="yes">M</italic></sup>. In order to provide a more compact notation, let us represent the collection of the available data modalities as a data point <italic toggle="yes">X</italic> = {<italic toggle="yes">X</italic><sup><italic toggle="yes">i</italic></sup>|<italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup>
<italic toggle="yes">modality present</italic>}. Let <italic toggle="yes">Z</italic> be a stochastic encoding of <italic toggle="yes">X</italic> coming from an intermediate layer of a deep neural network and defined by a parametric encoder <italic toggle="yes">p</italic>(<bold><italic toggle="yes">z</italic></bold>|<bold><italic toggle="yes">x</italic></bold>; <bold><italic toggle="yes">θ</italic></bold>) representing the upstream part of such neural model. For the rest of this manuscript, we adopt the following notation: <italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>, <italic toggle="yes">Z</italic> are random variables; <bold><italic toggle="yes">x</italic></bold>, <bold><italic toggle="yes">y</italic></bold>, <bold><italic toggle="yes">z</italic></bold> are multidimensional instances of random variables; <italic toggle="yes">f</italic>(⋅; <bold><italic toggle="yes">θ</italic></bold>) are functions parametrised by a vector of parameters <bold><italic toggle="yes">θ</italic></bold>; <inline-formula id="pcbi.1010050.e002"><alternatives><graphic xlink:href="pcbi.1010050.e002.jpg" id="pcbi.1010050.e002g" position="anchor"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mi mathvariant="script">S</mml:mi></mml:math></alternatives></inline-formula> represents a set.</p>
      <p>Following the information bottleneck approach [<xref rid="pcbi.1010050.ref024" ref-type="bibr">24</xref>], our goal consists in learning an encoding <italic toggle="yes">Z</italic> which is (a) maximally informative about <italic toggle="yes">Y</italic> and (b) maximally compressive about <italic toggle="yes">X</italic>. Following an information theoretic approach, objective (a) implies maximising the mutual information <italic toggle="yes">I</italic>(<italic toggle="yes">Z</italic>, <italic toggle="yes">Y</italic>; <bold><italic toggle="yes">θ</italic></bold>) between the encoding <italic toggle="yes">Z</italic> and the target <italic toggle="yes">Y</italic>, where:
<disp-formula id="pcbi.1010050.e003"><alternatives><graphic xlink:href="pcbi.1010050.e003.jpg" id="pcbi.1010050.e003g" position="anchor"/><mml:math id="M3" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>log</mml:mtext><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mspace width="0.222222em"/><mml:mi>d</mml:mi><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mspace width="0.222222em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula></p>
      <p>A trivial solution for maximising <xref rid="pcbi.1010050.e003" ref-type="disp-formula">Eq 1</xref> would be the identity <italic toggle="yes">Z</italic> = <italic toggle="yes">X</italic>. This would ensure a maximally informative representation, but (b) places a constraint on <italic toggle="yes">Z</italic>. In fact, due to (b), we want to “forget” as much information as possible about <italic toggle="yes">X</italic>. This leads to the objective:
<disp-formula id="pcbi.1010050.e004"><alternatives><graphic xlink:href="pcbi.1010050.e004.jpg" id="pcbi.1010050.e004g" position="anchor"/><mml:math id="M4" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:munder><mml:mspace width="0.222222em"/><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>β</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
where <italic toggle="yes">β</italic> ≥ 0 is a Lagrange multiplier. The first term on the right hand side of <xref rid="pcbi.1010050.e004" ref-type="disp-formula">Eq 2</xref> causes <italic toggle="yes">Z</italic> to be predictive of <italic toggle="yes">Y</italic>, while the second term constraints <italic toggle="yes">Z</italic> to be a minimal sufficient statistics of <italic toggle="yes">X</italic>. <italic toggle="yes">β</italic> controls the trade-off.</p>
      <p>As derived in [<xref rid="pcbi.1010050.ref023" ref-type="bibr">23</xref>] for the Deep Variational Information Bottleneck (Deep VIB), assuming <italic toggle="yes">q</italic>(<bold><italic toggle="yes">y</italic></bold>|<bold><italic toggle="yes">z</italic></bold>) and <italic toggle="yes">r</italic>(<bold><italic toggle="yes">z</italic></bold>) are variational approximations of the true <italic toggle="yes">p</italic>(<bold><italic toggle="yes">y</italic></bold>|<bold><italic toggle="yes">z</italic></bold>) and <italic toggle="yes">p</italic>(<bold><italic toggle="yes">z</italic></bold>), respectively, <xref rid="pcbi.1010050.e004" ref-type="disp-formula">Eq 2</xref> can be rewritten as:
<disp-formula id="pcbi.1010050.e005"><alternatives><graphic xlink:href="pcbi.1010050.e005.jpg" id="pcbi.1010050.e005g" position="anchor"/><mml:math id="M5" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:munder><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mtext>log</mml:mtext><mml:mspace width="2pt"/><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
where <inline-formula id="pcbi.1010050.e006"><alternatives><graphic xlink:href="pcbi.1010050.e006.jpg" id="pcbi.1010050.e006g" position="anchor"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is an auxiliary Gaussian noise variable, <italic toggle="yes">KL</italic> is the Kullback-Leibler divergence and <italic toggle="yes">f</italic> is a vector-valued parametric deterministic encoding function (in this work, a neural network). The introduction of <bold><italic toggle="yes">ϵ</italic></bold> consists in the reparameterisation trick [<xref rid="pcbi.1010050.ref028" ref-type="bibr">28</xref>], which allows to write <italic toggle="yes">p</italic>(<bold><italic toggle="yes">z</italic></bold>|<bold><italic toggle="yes">x</italic></bold>; <bold><italic toggle="yes">θ</italic></bold>)<italic toggle="yes">d<bold>x</bold></italic> = <italic toggle="yes">p</italic>(<bold><italic toggle="yes">ϵ</italic></bold>)<italic toggle="yes">d</italic><bold><italic toggle="yes">ϵ</italic></bold>, where <bold><italic toggle="yes">z</italic></bold> = <italic toggle="yes">f</italic>(<bold><italic toggle="yes">x</italic></bold>, <bold><italic toggle="yes">ϵ</italic></bold>) is now treated as a deterministic variable. This formulation allows the noise variable to be independent of the model parameters. This way, it is easy to compute gradients of the objective in <xref rid="pcbi.1010050.e005" ref-type="disp-formula">Eq 3</xref> and optimise via backpropagation. In this work, we let the variational approximate posteriors be multivariate Gaussians with a diagonal covariance structure <inline-formula id="pcbi.1010050.e007"><alternatives><graphic xlink:href="pcbi.1010050.e007.jpg" id="pcbi.1010050.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; a valid reparameterisation is <bold><italic toggle="yes">z</italic></bold> = <bold><italic toggle="yes">μ</italic></bold> + <bold><italic toggle="yes">σϵ</italic></bold>.</p>
      <p>We generalise the formulation of the Deep VIB objective of <xref rid="pcbi.1010050.e005" ref-type="disp-formula">Eq 3</xref> by considering that <italic toggle="yes">X</italic> is a collection of multimodal random input variables s.t. <italic toggle="yes">X</italic> = {<italic toggle="yes">X</italic><sup><italic toggle="yes">i</italic></sup>|<italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup>
<italic toggle="yes">modality present</italic>}. In light of this, the posterior <italic toggle="yes">p</italic>(<italic toggle="yes">Z</italic>|<bold><italic toggle="yes">x</italic></bold>) of <xref rid="pcbi.1010050.e005" ref-type="disp-formula">Eq 3</xref> consists actually in the joint posterior <italic toggle="yes">p</italic>(<italic toggle="yes">Z</italic>|<bold><italic toggle="yes">x</italic></bold><sup>1</sup>, …, <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">M</italic></sup>), conditioned by the joint <italic toggle="yes">M</italic> available data modalities. Following the approach proposed for the Multimodal Variational Autoencoder [<xref rid="pcbi.1010050.ref041" ref-type="bibr">41</xref>], assuming conditional independence between the various modalities conditioned on <italic toggle="yes">Z</italic> and approximating <italic toggle="yes">p</italic>(<italic toggle="yes">Z</italic>|<bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">i</italic></sup>) with <inline-formula id="pcbi.1010050.e008"><alternatives><graphic xlink:href="pcbi.1010050.e008.jpg" id="pcbi.1010050.e008g" position="anchor"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1010050.e009"><alternatives><graphic xlink:href="pcbi.1010050.e009.jpg" id="pcbi.1010050.e009g" position="anchor"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the stochastic encoder of the <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> data modality and <italic toggle="yes">p</italic>(<italic toggle="yes">Z</italic>) is a prior, the joint posterior can be expressed as a product of single-modality posteriors:
<disp-formula id="pcbi.1010050.e010"><alternatives><graphic xlink:href="pcbi.1010050.e010.jpg" id="pcbi.1010050.e010g" position="anchor"/><mml:math id="M10" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula></p>
      <p>The formulation derived from <xref rid="pcbi.1010050.e010" ref-type="disp-formula">Eq 4</xref> is addressed as a product of experts (PoE) (see <xref rid="pcbi.1010050.g001" ref-type="fig">Fig 1D</xref>). When the involved probability distributions are Gaussian, the PoE acquires a simple analytical solution, as the product of Gaussian experts is itself a Gaussian [<xref rid="pcbi.1010050.ref042" ref-type="bibr">42</xref>]. We can now formulate the objective of the Multimodal Variational Information Bottleneck:
<disp-formula id="pcbi.1010050.e011"><alternatives><graphic xlink:href="pcbi.1010050.e011.jpg" id="pcbi.1010050.e011g" position="anchor"/><mml:math id="M11" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:munder><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mtext>log</mml:mtext><mml:mspace width="2pt"/><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula></p>
    </sec>
    <sec id="sec006">
      <title>Implementation details</title>
      <p>In this work, there are two main data modalities: the species-relative abundance profiles and the strain-level marker profiles. For each modality, the dedicated stochastic encoder has the form <inline-formula id="pcbi.1010050.e012"><alternatives><graphic xlink:href="pcbi.1010050.e012.jpg" id="pcbi.1010050.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> (see <xref rid="pcbi.1010050.g001" ref-type="fig">Fig 1C</xref>). <italic toggle="yes">f</italic><sub><italic toggle="yes">e</italic></sub> is a multi-layer perceptron (MLP). For abundance profiles, the MLP has 2 layers of the form <italic toggle="yes">input dimension</italic>—<italic toggle="yes">input dimension</italic>/2—<italic toggle="yes">input dimension</italic>/2, followed by two parallel layers which output 2 vectors of size <italic toggle="yes">K</italic> for <bold><italic toggle="yes">μ</italic></bold> and <bold><italic toggle="yes">σ</italic></bold>. <italic toggle="yes">K</italic> is the size of the bottleneck, i.e. the dimension of <italic toggle="yes">Z</italic>. For a more stable computation, we let <inline-formula id="pcbi.1010050.e013"><alternatives><graphic xlink:href="pcbi.1010050.e013.jpg" id="pcbi.1010050.e013g" position="anchor"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> model the logarithm of the variance log <bold><italic toggle="yes">σ</italic></bold><sup>2</sup>. For marker profiles, the MLP has 2 layers of the form <italic toggle="yes">input dimension</italic>/2—1024—1024, followed by two parallel layers which output 2 vectors of size <italic toggle="yes">K</italic> for <bold><italic toggle="yes">μ</italic></bold> and <bold><italic toggle="yes">σ</italic></bold>. SiLU [<xref rid="pcbi.1010050.ref043" ref-type="bibr">43</xref>] activation functions are used. 0.4 drop-out is used at training time.</p>
      <p>As described later, experiments on the Colorectal-Metabolic dataset demand a third additional stochastic encoder for the metabolite profiles. For this data modality, the same encoder architecture adopted for the abundance profiles is used.</p>
      <p>The decoder consists in a logistic regression model <italic toggle="yes">q</italic>(<bold><italic toggle="yes">y</italic></bold>|<bold><italic toggle="yes">z</italic></bold>) = <italic toggle="yes">σ</italic>(<italic toggle="yes">f</italic><sub><italic toggle="yes">d</italic></sub>(<bold><italic toggle="yes">z</italic></bold>)), where <italic toggle="yes">σ</italic>(⋅) is the logistic sigmoid function and <italic toggle="yes">f</italic><sub><italic toggle="yes">d</italic></sub>(<bold><italic toggle="yes">z</italic></bold>) = <bold><italic toggle="yes">w</italic></bold><sup><italic toggle="yes">T</italic></sup>
<bold><italic toggle="yes">z</italic></bold> + <bold><italic toggle="yes">b</italic></bold> (see <xref rid="pcbi.1010050.g001" ref-type="fig">Fig 1E</xref>). This implements the binary classification. <bold><italic toggle="yes">y</italic></bold> models the diagnosis label for a given disease: sick or healthy.</p>
      <p>In <xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>, <italic toggle="yes">r</italic>(<italic toggle="yes">Z</italic>) and <italic toggle="yes">p</italic>(<italic toggle="yes">Z</italic>) are treated as K-dimensional spherical Gaussian distributions, <inline-formula id="pcbi.1010050.e014"><alternatives><graphic xlink:href="pcbi.1010050.e014.jpg" id="pcbi.1010050.e014g" position="anchor"/><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. The latent dimension <italic toggle="yes">K</italic> of the encoding is set to 256. <italic toggle="yes">β</italic> is set to 10<sup>−5</sup>.</p>
      <p>The networks are trained using the Adam optimiser, with a learning rate of 10<sup>−4</sup> and a <italic toggle="yes">L</italic><sub>2</sub> weight decay with λ = 10<sup>−5</sup>. The batch size is set to 256. The training is performed for 200 epochs and, in order to avoid overfitting, the best model is selected by saving the weights corresponding to the epoch where the area under the curve (AUC) of the receiver operating characteristic (ROC) is maximum on the validation set (see Section Validation framework and performance evaluation).</p>
      <p>All experiments were performed on a CentOS Linux 8 machine with NVIDIA GeForce RTX 2080 Ti GPUs and CUDA 10.2 installed, with the exception of the transfer learning experiments (see Section Transfer learning), which were performed with an NVIDIA TITAN RTX GPU. Algorithms are implemented in Python 3.6 using PyTorch [<xref rid="pcbi.1010050.ref044" ref-type="bibr">44</xref>] version 1.7; code is publicly available at <ext-link xlink:href="https://github.com/nec-research/microbiome-mvib" ext-link-type="uri">https://github.com/nec-research/microbiome-mvib</ext-link>.</p>
    </sec>
    <sec id="sec007">
      <title>Extending the MVIB objective with the triplet margin loss</title>
      <p>The MVIB objective function proposed in <xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref> consists of two terms: a supervised negative log-likelihood loss and a KL divergence which acts as a regulariser. As presented in Section Results, it was empirically observed that extending the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> of <xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref> with an additional triplet margin loss [<xref rid="pcbi.1010050.ref045" ref-type="bibr">45</xref>] term can lead to a more accurate predictor on various disease datasets.</p>
      <p>The triplet margin loss was first introduced in the field of computer vision [<xref rid="pcbi.1010050.ref045" ref-type="bibr">45</xref>]. The underlying idea consists in explicitly enforcing the latent representation of an input sample (e.g. an image, or a vector) to be close to the latent representations of the samples that belong to the same class, and distant from the latent representations of samples that belong to a different class. The concept of closeness depends on the nature of the latent space. In a Euclidean space, the Euclidean distance can be used as distance metric.</p>
      <p>Given a certain batch size <italic toggle="yes">B</italic> of samples on which the loss is meant to be computed, let <italic toggle="yes">B</italic><sub>+</sub> be the number of sick samples and <italic toggle="yes">B</italic><sub>−</sub> the number of healthy control samples. Let <italic toggle="yes">B</italic><sub><italic toggle="yes">T</italic></sub> = <italic toggle="yes">min</italic>{<italic toggle="yes">B</italic><sub>+</sub>, <italic toggle="yes">B</italic><sub>−</sub>}. From a batch of size <italic toggle="yes">B</italic>, we randomly sample <italic toggle="yes">B</italic><sub><italic toggle="yes">T</italic></sub> sick samples and <italic toggle="yes">B</italic><sub><italic toggle="yes">T</italic></sub> control samples without repetitions (this implies that the smaller set of samples, either sick or control, will be fully considered). These 2<italic toggle="yes">B</italic><sub><italic toggle="yes">T</italic></sub> samples constitute the <italic toggle="yes">anchors</italic> of the triplet margin loss. We represent the anchors with two sets: <inline-formula id="pcbi.1010050.e015"><alternatives><graphic xlink:href="pcbi.1010050.e015.jpg" id="pcbi.1010050.e015g" position="anchor"/><mml:math id="M15" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula> (which contains <italic toggle="yes">B</italic><sub><italic toggle="yes">T</italic></sub> sick anchors) and <inline-formula id="pcbi.1010050.e016"><alternatives><graphic xlink:href="pcbi.1010050.e016.jpg" id="pcbi.1010050.e016g" position="anchor"/><mml:math id="M16" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula> (which contains <italic toggle="yes">B</italic><sub><italic toggle="yes">T</italic></sub> control anchors). For each anchor sample in <inline-formula id="pcbi.1010050.e017"><alternatives><graphic xlink:href="pcbi.1010050.e017.jpg" id="pcbi.1010050.e017g" position="anchor"/><mml:math id="M17" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1010050.e018"><alternatives><graphic xlink:href="pcbi.1010050.e018.jpg" id="pcbi.1010050.e018g" position="anchor"/><mml:math id="M18" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula>, we sample: (a) a subject of the same class (addressed in this context as <italic toggle="yes">positive</italic>) and (b) a sample of the opposite class (addressed as <italic toggle="yes">negative</italic>). In our implementation, this is obtained by shuffling the samples in the opposite-class anchor set. This allows to constitute a set of positive samples <inline-formula id="pcbi.1010050.e019"><alternatives><graphic xlink:href="pcbi.1010050.e019.jpg" id="pcbi.1010050.e019g" position="anchor"/><mml:math id="M19" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula> (i.e. of the same class) and a set of negative samples <inline-formula id="pcbi.1010050.e020"><alternatives><graphic xlink:href="pcbi.1010050.e020.jpg" id="pcbi.1010050.e020g" position="anchor"/><mml:math id="M20" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula> (i.e. of the opposite class) for the sick anchors <inline-formula id="pcbi.1010050.e021"><alternatives><graphic xlink:href="pcbi.1010050.e021.jpg" id="pcbi.1010050.e021g" position="anchor"/><mml:math id="M21" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula>. Analogously, a set of positive samples <inline-formula id="pcbi.1010050.e022"><alternatives><graphic xlink:href="pcbi.1010050.e022.jpg" id="pcbi.1010050.e022g" position="anchor"/><mml:math id="M22" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula> and a set of negative samples <inline-formula id="pcbi.1010050.e023"><alternatives><graphic xlink:href="pcbi.1010050.e023.jpg" id="pcbi.1010050.e023g" position="anchor"/><mml:math id="M23" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula> are obtained for the control anchors <inline-formula id="pcbi.1010050.e024"><alternatives><graphic xlink:href="pcbi.1010050.e024.jpg" id="pcbi.1010050.e024g" position="anchor"/><mml:math id="M24" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula>.</p>
      <p>Samples contained in the <inline-formula id="pcbi.1010050.e025"><alternatives><graphic xlink:href="pcbi.1010050.e025.jpg" id="pcbi.1010050.e025g" position="anchor"/><mml:math id="M25" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula> set are healthy control subjects, while samples contained in <inline-formula id="pcbi.1010050.e026"><alternatives><graphic xlink:href="pcbi.1010050.e026.jpg" id="pcbi.1010050.e026g" position="anchor"/><mml:math id="M26" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula> belong to sick ones. Analogously, samples contained in the <inline-formula id="pcbi.1010050.e027"><alternatives><graphic xlink:href="pcbi.1010050.e027.jpg" id="pcbi.1010050.e027g" position="anchor"/><mml:math id="M27" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula> set belong to sick subjects, while samples contained in <inline-formula id="pcbi.1010050.e028"><alternatives><graphic xlink:href="pcbi.1010050.e028.jpg" id="pcbi.1010050.e028g" position="anchor"/><mml:math id="M28" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula> come from heathy control ones. This is because, in the context of the triplet margin loss, <italic toggle="yes">positive</italic> and <italic toggle="yes">negative</italic> mean of the <italic toggle="yes">same</italic> and of <italic toggle="yes">opposite</italic> ground truth class, respectively.</p>
      <p>We define the triplet margin loss as:
<disp-formula id="pcbi.1010050.e029"><alternatives><graphic xlink:href="pcbi.1010050.e029.jpg" id="pcbi.1010050.e029g" position="anchor"/><mml:math id="M29" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">A</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">A</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:munder><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mo>‖</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mo>‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>-</mml:mo><mml:mo>‖</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mo>‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula>
where <italic toggle="yes">α</italic> is a tunable margin which we set to 1 and <inline-formula id="pcbi.1010050.e030"><alternatives><graphic xlink:href="pcbi.1010050.e030.jpg" id="pcbi.1010050.e030g" position="anchor"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the MLP that computes the mean of <inline-formula id="pcbi.1010050.e031"><alternatives><graphic xlink:href="pcbi.1010050.e031.jpg" id="pcbi.1010050.e031g" position="anchor"/><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>μ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> (see Section Implementation details). It follows that, for our <inline-formula id="pcbi.1010050.e032"><alternatives><graphic xlink:href="pcbi.1010050.e032.jpg" id="pcbi.1010050.e032g" position="anchor"/><mml:math id="M32" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1010050.e033"><alternatives><graphic xlink:href="pcbi.1010050.e033.jpg" id="pcbi.1010050.e033g" position="anchor"/><mml:math id="M33" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></alternatives></inline-formula> anchors sets, the triplet loss objective can be written as:
<disp-formula id="pcbi.1010050.e034"><alternatives><graphic xlink:href="pcbi.1010050.e034.jpg" id="pcbi.1010050.e034g" position="anchor"/><mml:math id="M34" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">A</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">P</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">N</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula></p>
      <p>Intuitively, the first term of the right hand side of <xref rid="pcbi.1010050.e034" ref-type="disp-formula">Eq 7</xref> encourages the encodings of sick samples to be closer to each other in their K-dimensional Euclidean space and far away from the encodings of healthy control samples. In the same fashion, the second term of the equation encourages the encodings of healthy samples to be clustered in the same region of the latent space and to be distant from the encodings of sick samples.</p>
      <p>With the definition of the triplet margin loss objective of <xref rid="pcbi.1010050.e034" ref-type="disp-formula">Eq 7</xref>, we can extend the MVIB objective presented in <xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref> and introduce the MVIB-T objective:
<disp-formula id="pcbi.1010050.e035"><alternatives><graphic xlink:href="pcbi.1010050.e035.jpg" id="pcbi.1010050.e035g" position="anchor"/><mml:math id="M35" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi><mml:mo>-</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>λ</mml:mo><mml:mi>T</mml:mi></mml:msub><mml:msub><mml:mi>J</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mspace width="0.222222em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(8)</label></disp-formula></p>
      <p>λ<sub><italic toggle="yes">T</italic></sub> is a multiplying constant which we set to 1 for all experiments.</p>
    </sec>
    <sec id="sec008">
      <title>Full multimodal objective</title>
      <p>For the training of MVIB, we adopt the same training paradigm proposed for the Multimodal Variational Autoencoder [<xref rid="pcbi.1010050.ref041" ref-type="bibr">41</xref>]. The MVIB objective presented in <xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref> assumes that all <italic toggle="yes">M</italic> data modalities are present. This has the unfortunate consequence of not training the single-modality encoders <inline-formula id="pcbi.1010050.e036"><alternatives><graphic xlink:href="pcbi.1010050.e036.jpg" id="pcbi.1010050.e036g" position="anchor"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> individually. This implies that the model cannot be used if certain data modalities are not available at test time. In order to circumvent this limitation and allow the MVIB to work at test time with missing data modalities, we need to compute the MVIB objective for the combined data modalities, as well as for the individual modalities.</p>
      <p><xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref> can be reformulated as a full multimodal objective, which allows the model to be optimal in all multimodal and single-modality settings:
<disp-formula id="pcbi.1010050.e037"><alternatives><graphic xlink:href="pcbi.1010050.e037.jpg" id="pcbi.1010050.e037g" position="anchor"/><mml:math id="M37" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>A</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>A</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(9)</label></disp-formula>
where <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">A</italic></sup> represents the species-relative abundance profiles and <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">M</italic></sup> the strain-level marker profiles. This extension holds also for the MVIB-T objective of <xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>. For all experiments performed in this work, the objective functions are computed in their full multimodal form, as described in this section.</p>
    </sec>
    <sec id="sec009">
      <title>Validation framework and performance evaluation</title>
      <p>With the goal of providing a non-biased estimate of the model’s classification performance, we implemented a performance evaluation scheme inspired by DeepMicro [<xref rid="pcbi.1010050.ref017" ref-type="bibr">17</xref>]. We split each dataset into training and test sets with a 8:2 ratio. In particular, for the IBD, EW-T2D, C-T2D, Obesity, Cirrhosis and Colorectal datasets, we implemented the random training-test split using the same random partition seeds used by DeepMicro; this ensures that our test samples are the same ones considered by DeepMicro and allows a fair benchmark of the models’ performances. The same procedure was adopted for Obesity-Joint, Colorectal-EMBL, Early-Colorectal-EMBL, Hypertension and Colorectal-Metabolic too.</p>
      <p>Considering only the training set, we performed a stratified 5-fold cross-validation and used the validation sets to compute a validation ROC AUC score for selecting the epoch with the best model parameters. The five best models obtained via the 5-fold cross-validation were then tested on the left-out test set and their predictions were ensembled via a majority vote. This procedure was repeated five times, each time with a different random partition seed, in order to ensure that the five experiments were conducted with independent random training-test splits. The resulting test performance metrics coming from the five independent experiments were then averaged and their mean was used for comparing model performance.</p>
    </sec>
    <sec id="sec010">
      <title>Transfer learning</title>
      <p>Motivated by the hypothesis that altered microbiome states caused by two different diseases might in fact share some common patterns, we performed experiments following a transfer learning paradigm [<xref rid="pcbi.1010050.ref026" ref-type="bibr">26</xref>, <xref rid="pcbi.1010050.ref027" ref-type="bibr">27</xref>]. Iteratively, we first select a target disease from the set of considered datasets. This allows to define a target domain <inline-formula id="pcbi.1010050.e038"><alternatives><graphic xlink:href="pcbi.1010050.e038.jpg" id="pcbi.1010050.e038g" position="anchor"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1010050.e039"><alternatives><graphic xlink:href="pcbi.1010050.e039.jpg" id="pcbi.1010050.e039g" position="anchor"/><mml:math id="M39" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is the target feature space and <italic toggle="yes">p</italic>(<bold><italic toggle="yes">X</italic></bold><sub><italic toggle="yes">T</italic></sub>) is the marginal distribution of the set of samples of the target dataset <inline-formula id="pcbi.1010050.e040"><alternatives><graphic xlink:href="pcbi.1010050.e040.jpg" id="pcbi.1010050.e040g" position="anchor"/><mml:math id="M40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. A target task <inline-formula id="pcbi.1010050.e041"><alternatives><graphic xlink:href="pcbi.1010050.e041.jpg" id="pcbi.1010050.e041g" position="anchor"/><mml:math id="M41" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">T</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi mathvariant="script">Y</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is also defined, where <inline-formula id="pcbi.1010050.e042"><alternatives><graphic xlink:href="pcbi.1010050.e042.jpg" id="pcbi.1010050.e042g" position="anchor"/><mml:math id="M42" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">Y</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is the label space of the target dataset and <italic toggle="yes">f</italic> the decision function which is expected to be learned. The target task shall therefore be interpreted as the prediction of the disease which we mostly care about.</p>
      <p>Merging the non-target datasets, we constitute a source domain and task <inline-formula id="pcbi.1010050.e043"><alternatives><graphic xlink:href="pcbi.1010050.e043.jpg" id="pcbi.1010050.e043g" position="anchor"/><mml:math id="M43" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">T</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. For the source task, all sick subjects are treated equally and they are assigned a positive ground truth label, independently on what pathology they actually have. We first train MVIB on the source domain and task <inline-formula id="pcbi.1010050.e044"><alternatives><graphic xlink:href="pcbi.1010050.e044.jpg" id="pcbi.1010050.e044g" position="anchor"/><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">T</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and fine-tune it on the target domain and task <inline-formula id="pcbi.1010050.e045"><alternatives><graphic xlink:href="pcbi.1010050.e045.jpg" id="pcbi.1010050.e045g" position="anchor"/><mml:math id="M45" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">D</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">T</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
      <p>For the transfer learning experiments, we adopted the <italic toggle="yes">joint</italic> datasets collection, as the microbial species and strain markers share the same positional indexes across the various datasets and present the same dimensionality.</p>
      <p>As Colorectal-EMBL is an extension of the Colorectal dataset, and Obesity-Joint is an extension of Obesity, applying the procedure described above would allow the model to observe the samples shared by more than one dataset during both the source and the target task. This would lead to biased results. Therefore, in the transfer learning experiments, ΔObesity and ΔColorectal are considered during the source task instead of Obesity-Joint and Colorectal-EMBL, respectively.</p>
    </sec>
    <sec id="sec011">
      <title>Cross-study generalisation</title>
      <p>In order to further evaluate the generalisation capabilities of MVIB across different studies, and motivated by the fact of having various datasets for the same disease, we performed cross-study generalisation experiments. First, we identified the following ordered pairs of datasets: (EW-T2D, C-T2D), (C-T2D, EW-T2D), (ΔObesity, Obesity), (ΔColorectal, Colorectal), (Obesity, ΔObesity), (Colorectal, ΔColorectal). Then, for each pair, we trained MVIB on the first source dataset, and tested it on the second target one. No fine-tuning was performed on the test dataset.</p>
    </sec>
    <sec id="sec012">
      <title>Explaining predictions with saliency</title>
      <p>Following the same approach proposed by [<xref rid="pcbi.1010050.ref025" ref-type="bibr">25</xref>], given a multimodal pair of feature vectors <inline-formula id="pcbi.1010050.e046"><alternatives><graphic xlink:href="pcbi.1010050.e046.jpg" id="pcbi.1010050.e046g" position="anchor"/><mml:math id="M46" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, where <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">A</italic></sup> represents the species-relative abundance profile and <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">M</italic></sup> the strain-level marker profile, we would like to rank the strain-level markers of <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">M</italic></sup> and the microbial species of <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">A</italic></sup> based on their influence on the MVIB prediction. More formally, we compute the derivate of the MVIB class prediction with respect to both input vectors <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">A</italic></sup> and <bold><italic toggle="yes">x</italic></bold><sup><italic toggle="yes">M</italic></sup>:
<disp-formula id="pcbi.1010050.e047"><alternatives><graphic xlink:href="pcbi.1010050.e047.jpg" id="pcbi.1010050.e047g" position="anchor"/><mml:math id="M47" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mi>A</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>q</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>|</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>A</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>A</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>A</mml:mi></mml:msubsup></mml:msub><mml:mspace width="0.222222em"/><mml:mspace width="0.222222em"/><mml:mo>,</mml:mo><mml:mspace width="0.222222em"/><mml:mspace width="0.222222em"/><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>q</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>|</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>A</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup></mml:msub><mml:mspace width="0.222222em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(10)</label></disp-formula>
where <italic toggle="yes">q</italic>(⋅) is the parametric probabilistic decoder of MVIB and <italic toggle="yes">f</italic>(⋅) represents its whole multimodal encoding block, following the same notation of <xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>.</p>
      <p>The magnitude of the derivatives presented in <xref rid="pcbi.1010050.e047" ref-type="disp-formula">Eq 10</xref> indicates which strain-level markers and species-relative abundances need to be changed the least to affect the class score the most. For each disease dataset, we compute the saliency maps for all samples correctly classified as positive (i.e. sick) and compute their average. This allows to discover a ranking of the most influential strain-level markers and microbial species for each disease dataset (see <xref rid="pcbi.1010050.g001" ref-type="fig">Fig 1F and 1G</xref>). The computation of saliency maps is extremely quick and it only requires a single backpropagation pass.</p>
    </sec>
    <sec id="sec013">
      <title>Trimodal MVIB: Combining metabolomics and metagenomics</title>
      <p>In order to further investigate the multimodal learning capabilities of MVIB, we performed trimodal experiments on the Colorectal-Metabolic dataset [<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>]. This dataset includes three data modalities for all samples: species-relative abundance, strain-level marker and metabolite profiles. For training the model in the trimodal setting, the same full multimodal training paradigm presented in Section Full multimodal objective was adopted. This allows to compute the MVIB objective for all possible data modalities combinations, as well as for the individual modalities.</p>
      <p>In this trimodal setting, the objective function is computed in the following fashion:
<disp-formula id="pcbi.1010050.e048"><alternatives><graphic xlink:href="pcbi.1010050.e048.jpg" id="pcbi.1010050.e048g" position="anchor"/><mml:math id="M48" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">M</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>}</mml:mo><mml:mo>∈</mml:mo><mml:mi mathvariant="script">M</mml:mi><mml:mi mathvariant="script">M</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>V</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">M</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.222222em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(11)</label></disp-formula>
where <inline-formula id="pcbi.1010050.e049"><alternatives><graphic xlink:href="pcbi.1010050.e049.jpg" id="pcbi.1010050.e049g" position="anchor"/><mml:math id="M49" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">M</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the set of the three considered data modalities and <inline-formula id="pcbi.1010050.e050"><alternatives><graphic xlink:href="pcbi.1010050.e050.jpg" id="pcbi.1010050.e050g" position="anchor"/><mml:math id="M50" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">M</mml:mi><mml:mi mathvariant="script">M</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mo>{</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>}</mml:mo><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">M</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the set of all possible (unordered) modality pairs. <xref rid="pcbi.1010050.s001" ref-type="supplementary-material">S1 Fig</xref> depicts the trimodal architecture of MVIB used for the experiments on the Colorectal-Metabolic dataset.</p>
      <p>For the trimodal experiments, the learning rate has been set to 10<sup>−5</sup> and the bottleneck dimension <italic toggle="yes">K</italic> to 128, as we observed that this slightly improves learning.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec014">
    <title>Results</title>
    <sec id="sec015">
      <title>MVIB achieves competitive results on the multimodal microbiome-based disease prediction task</title>
      <p>We assess the performance of MVIB in comparison to existing state-of-the-art methods for microbiome-based disease prediction, i.e. Random Forest, DeepMicro [<xref rid="pcbi.1010050.ref017" ref-type="bibr">17</xref>] and PopPhy-CNN [<xref rid="pcbi.1010050.ref019" ref-type="bibr">19</xref>]. In <xref rid="pcbi.1010050.t002" ref-type="table">Table 2</xref>, we report the AUC ROC values for our benchmark analysis on various disease cohorts. The results of MVIB are shown for both dataset collections <italic toggle="yes">default</italic> and <italic toggle="yes">joint</italic> (which we describe previously in Section Pre-processing). MVIB results are derived from the two input feature modalities, species abundances and strain-level markers (A+M). A complete summary of MVIB results for all bimodal dataset collections is available in <xref rid="pcbi.1010050.s002" ref-type="supplementary-material">S1 Table</xref>.</p>
      <table-wrap position="float" id="pcbi.1010050.t002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Classification performance of MVIB and competing methods.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1010050.t002" id="pcbi.1010050.t002g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="2" colspan="1">Dataset</th>
                <th align="center" colspan="3" rowspan="1">Random Forest</th>
                <th align="center" colspan="3" rowspan="1">DeepMicro<sub>VAE</sub>
<xref rid="t002fn003" ref-type="table-fn">‡</xref> [<xref rid="pcbi.1010050.ref017" ref-type="bibr">17</xref>]</th>
                <th align="center" rowspan="1" colspan="1">PopPhy-CNN [<xref rid="pcbi.1010050.ref019" ref-type="bibr">19</xref>]</th>
                <th align="center" colspan="2" rowspan="1">MVIB (A+M)</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">A</th>
                <th align="center" rowspan="1" colspan="1">M</th>
                <th align="center" rowspan="1" colspan="1">A+M</th>
                <th align="center" rowspan="1" colspan="1">A</th>
                <th align="center" rowspan="1" colspan="1">M</th>
                <th align="center" rowspan="1" colspan="1">A+M</th>
                <th align="center" rowspan="1" colspan="1">A</th>
                <th align="center" rowspan="1" colspan="1">D</th>
                <th align="center" rowspan="1" colspan="1">J</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">IBD</td>
                <td align="center" rowspan="1" colspan="1">0.899<break/>(0.037)</td>
                <td align="center" rowspan="1" colspan="1">0.932<break/>(0.025)</td>
                <td align="center" rowspan="1" colspan="1">0.936<break/>(0.017)</td>
                <td align="center" rowspan="1" colspan="1">0.779<break/>(0.032)</td>
                <td align="center" rowspan="1" colspan="1">0.899<break/>(0.039)</td>
                <td align="center" rowspan="1" colspan="1">0.833<break/>(0.034)</td>
                <td align="center" rowspan="1" colspan="1">0.799<break/>(0.052)</td>
                <td align="center" rowspan="1" colspan="1">0.922<break/>(0.020)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.936</bold>
                  <break/>
                  <bold>(0.014)</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">EW-T2D</td>
                <td align="center" rowspan="1" colspan="1">0.825<break/>(0.020)</td>
                <td align="center" rowspan="1" colspan="1">0.812<break/>(0.017)</td>
                <td align="center" rowspan="1" colspan="1">0.789<break/>(0.024)</td>
                <td align="center" rowspan="1" colspan="1">0.640<break/>(0.051)</td>
                <td align="center" rowspan="1" colspan="1">0.853<break/>(0.041)</td>
                <td align="center" rowspan="1" colspan="1">0.741<break/>(0.080)</td>
                <td align="center" rowspan="1" colspan="1">0.591<break/>(0.037)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.859</bold>
                  <break/>
                  <bold>(0.023)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.853<break/>(0.025)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">C-T2D</td>
                <td align="center" rowspan="1" colspan="1">0.717<break/>(0.018)</td>
                <td align="center" rowspan="1" colspan="1">0.736<break/>(0.023)</td>
                <td align="center" rowspan="1" colspan="1">0.734<break/>(0.017)</td>
                <td align="center" rowspan="1" colspan="1">0.715<break/>(0.031)</td>
                <td align="center" rowspan="1" colspan="1">0.719<break/>(0.019)</td>
                <td align="center" rowspan="1" colspan="1">0.714<break/>(0.030)</td>
                <td align="center" rowspan="1" colspan="1">0.641<break/>(0.019)</td>
                <td align="center" rowspan="1" colspan="1">0.750<break/>(0.009)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.758</bold>
                  <break/>
                  <bold>(0.012)</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Obesity</td>
                <td align="center" rowspan="1" colspan="1">0.662<break/>(0.022)</td>
                <td align="center" rowspan="1" colspan="1">0.634<break/>(0.019)</td>
                <td align="center" rowspan="1" colspan="1">0.619<break/>(0.017)</td>
                <td align="center" rowspan="1" colspan="1">0.600<break/>(0.030)</td>
                <td align="center" rowspan="1" colspan="1">0.599<break/>(0.014)</td>
                <td align="center" rowspan="1" colspan="1">0.576<break/>(0.040)</td>
                <td align="center" rowspan="1" colspan="1">0.630<break/>(0.018)</td>
                <td align="center" rowspan="1" colspan="1">0.662<break/>(0.024)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.666</bold>
                  <break/>
                  <bold>(0.027)</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Cirrhosis</td>
                <td align="center" rowspan="1" colspan="1">0.897<break/>(0.013)</td>
                <td align="center" rowspan="1" colspan="1">0.896<break/>(0.007)</td>
                <td align="center" rowspan="1" colspan="1">0.905<break/>(0.009)</td>
                <td align="center" rowspan="1" colspan="1">0.781<break/>(0.021)</td>
                <td align="center" rowspan="1" colspan="1">0.891<break/>(0.016)</td>
                <td align="center" rowspan="1" colspan="1">0.867<break/>(0.018)</td>
                <td align="center" rowspan="1" colspan="1">0.893<break/>(0.008)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.925</bold>
                  <break/>
                  <bold>(0.005)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.924<break/>(0.005)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Colorectal</td>
                <td align="center" rowspan="1" colspan="1">0.803<break/>(0.048)</td>
                <td align="center" rowspan="1" colspan="1">0.771<break/>(0.053)</td>
                <td align="center" rowspan="1" colspan="1">0.764<break/>(0.053)</td>
                <td align="center" rowspan="1" colspan="1">0.739<break/>(0.070)</td>
                <td align="center" rowspan="1" colspan="1">0.737<break/>(0.068)</td>
                <td align="center" rowspan="1" colspan="1">0.548<break/>(0.040)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.803</bold>
                  <break/>
                  <bold>(0.023)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.780<break/>(0.071)</td>
                <td align="center" rowspan="1" colspan="1">0.777<break/>(0.069)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Obesity-Joint</td>
                <td align="center" rowspan="1" colspan="1">0.806<break/>(0.026)</td>
                <td align="center" rowspan="1" colspan="1">0.795<break/>(0.024)</td>
                <td align="center" rowspan="1" colspan="1">0.799<break/>(0.025)</td>
                <td align="center" rowspan="1" colspan="1">0.662<break/>(0.015)</td>
                <td align="center" rowspan="1" colspan="1">0.637<break/>(0.021)</td>
                <td align="center" rowspan="1" colspan="1">0.600<break/>(0.017)</td>
                <td align="center" rowspan="1" colspan="1">0.697<break/>(0.026)</td>
                <td align="center" rowspan="1" colspan="1">0.815<break/>(0.019)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.818</bold>
                  <break/>
                  <bold>(0.018)</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Colorectal-EMBL</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.890</bold>
                  <break/>
                  <bold>(0.015)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.866<break/>(0.024)</td>
                <td align="center" rowspan="1" colspan="1">0.860<break/>(0.016)</td>
                <td align="center" rowspan="1" colspan="1">0.662<break/>(0.027)</td>
                <td align="center" rowspan="1" colspan="1">0.725<break/>(0.049)</td>
                <td align="center" rowspan="1" colspan="1">0.693<break/>(0.034)</td>
                <td align="center" rowspan="1" colspan="1">
                  <xref rid="t002fn002" ref-type="table-fn">†</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">0.811<break/>(0.010)</td>
                <td align="center" rowspan="1" colspan="1">0.814<break/>(0.013)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Early-Colorectal-EMBL</td>
                <td align="center" rowspan="1" colspan="1">0.577<break/>(0.046)</td>
                <td align="center" rowspan="1" colspan="1">0.533<break/>(0.039)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.582</bold>
                  <break/>
                  <bold>(0.024)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.562<break/>(0.070)</td>
                <td align="center" rowspan="1" colspan="1">0.557<break/>(0.048)</td>
                <td align="center" rowspan="1" colspan="1">0.5616<break/>(0.048)</td>
                <td align="center" rowspan="1" colspan="1">
                  <xref rid="t002fn002" ref-type="table-fn">†</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">0.535<break/>(0.050)</td>
                <td align="center" rowspan="1" colspan="1">0.543<break/>(0.048)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Hypertension</td>
                <td align="center" rowspan="1" colspan="1">0.662<break/>(0.035)</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.677</bold>
                  <break/>
                  <bold>(0.023)</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.631<break/>(0.031)</td>
                <td align="center" rowspan="1" colspan="1">0.523<break/>(0.030)</td>
                <td align="center" rowspan="1" colspan="1">0.561<break/>(0.028)</td>
                <td align="center" rowspan="1" colspan="1">0.658<break/>(0.054)</td>
                <td align="center" rowspan="1" colspan="1">
                  <xref rid="t002fn002" ref-type="table-fn">†</xref>
                </td>
                <td align="center" rowspan="1" colspan="1">0.603<break/>(0.045)</td>
                <td align="center" rowspan="1" colspan="1">0.591<break/>(0.041)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>The performance of all methods is measured by ROC AUC computed on the test sets. Values in brackets refer to the standard error over five repeated experiments. The first set of columns presents the results of the Random Forest classifier after leveraging cross-validated grid-search for hyperparameter optimisation. We adopted Random Forest implementation from the Scikit-learn Python library [<xref rid="pcbi.1010050.ref046" ref-type="bibr">46</xref>] version 0.23.2. The second set of columns presents the results of DeepMicro with variational autoencoder (VAE). The third set of columns presents the results of PopPhy-CNN. The last set of columns presents MVIB results. A, M, A+M refer to the results that are obtained from processing abundances, markers or both, respectively. D and J refer to the two different pre-processing schemes, i.e. <italic toggle="yes">default</italic> (D) and <italic toggle="yes">joint</italic> (J). The MVIB implementation follows the model description in Section Implementation details where we set the bottleneck dimension to 256 and we use the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>).</p>
          </fn>
          <fn id="t002fn002">
            <p><sup>†</sup>: for the last three datasets, we could not produce PopPhy-CNN results, as the original implementation generates an infinite loop while pruning the phylogenetic tree.</p>
          </fn>
          <fn id="t002fn003">
            <p><sup>‡</sup>: For DeepMicro, we selected the best test ROC AUC values from three different downstream classifiers, i.e. Support Vector Machine (SVM), MLP and Random Forest.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For Random Forest and DeepMicro, we report the results on various feature combinations, i.e. only species abundance (A), only strain-level markers (M) and the concatenation of abundances and markers (A+M). Benchmark methods do not explicitly model multiple input data modalities, hence we adopted a simple feature concatenation in the (A+M) setting. The results of Random Forest shown in <xref rid="pcbi.1010050.t002" ref-type="table">Table 2</xref> are derived after fine-tuning the model through cross-validated grid-search over the hyperparameter space summarised in <xref rid="pcbi.1010050.s006" ref-type="supplementary-material">S1 File</xref>. For PopPhy-CNN, we only report the results using the species abundances (A) modality, since the current implementation of the method does not scale to include strain-level markers.</p>
      <p>The DeepMicro method consists of a two-steps mechanism: (1) train an autoencoder to generate input embeddings, (2) train a downstream classifier on the embeddings computed in the first step. Various autoencoder architectures and downstream classifiers are introduced in [<xref rid="pcbi.1010050.ref017" ref-type="bibr">17</xref>] and there is no clear criteria on which combination has an optimal performance. For our benchmark analysis, we trained DeepMicro with the Variational Autoencoder (VAE) [<xref rid="pcbi.1010050.ref028" ref-type="bibr">28</xref>]. We believe this choice offers fair comparisons, since MVIB is also based on variational inference. Choosing VAE for DeepMicro allows us to highlight the key improvements of our end-to-end multimodal architecture when compared to the demanding two-steps mechanism offered by DeepMicro. For the classification step of DeepMicro, we trained multiple downstream classifiers, i.e. SVM, MLP and Random Forest, then we report the best test ROC AUC values.</p>
      <p>We modified the source code of PopPhy-CNN to make the model validation and testing consistent with our validation framework. The original PopPhy-CNN implementation offers a slightly different validation procedure, hence we made the necessary changes to ensure that all of the evaluation results (see <xref rid="pcbi.1010050.t002" ref-type="table">Table 2</xref>) are computed in the same manner.</p>
      <p>From the results of <xref rid="pcbi.1010050.t002" ref-type="table">Table 2</xref>, we see that MVIB outperforms Random Forest on all datasets except Colorectal-EMBL, Early-Colorectal-EMBL and Hypertension. MVIB consistently outperforms DeepMicro on all datasets in both settings, i.e. single-modality (A or B) and multimodality (A+M). In comparison to PopPhy-CNN, MVIB achieves better results on all datasets, except for Colorectal, where PopPhy-CNN achieves 2% higher ROC AUC. For the Colorectal-EMBL, Early-Colorectal-EMBL and Hypertension datasets, we could not produce PopPhy-CNN results, as the original implementation seems to generate an infinite loop when the phylogenetic tree is pruned.</p>
      <p>Early-Colorectal and Hypertension present the hardest diseases to predict for all classifiers including MVIB. MVIB achieves approximately 55% and 60% ROC AUC on each of the aforementioned datasets, respectively. However, these values are still above random baseline. In summary, the discrimination capabilities of various classifiers including MVIB vary among different datasets which may indicate less measurable microbial changes in subjects with certain diseases.</p>
    </sec>
    <sec id="sec016">
      <title>Multimodal ablation study</title>
      <p>To further evaluate the multimodal learning capabilities of MVIB, we perform an ablation study to compare classification performance of single-modality and bimodal settings. To this end, we train MVIB by optimising the full multimodal objective (see Section Full multimodal objective), which ensures that all encoders are trained individually as well as jointly. At test time, for the single-modality setting, we tested the model by considering either species abundances (MVIB-A) or strain-level markers (MVIB-M) as inputs. While for the bimodal setting, we passed both data modalities simultaneously as inputs to our model (MVIB-A+M). <xref rid="pcbi.1010050.g002" ref-type="fig">Fig 2</xref> summarises our results.</p>
      <fig position="float" id="pcbi.1010050.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Ablation study results. Comparisons between single-modality and bimodal MVIB.</title>
          <p>The shown values are ROC AUC on test sets, error bars represents standard error computed by repeating each experiment five times on different random train/test splits. We leveraged the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>) for optimisation. MVIB-A indicates the model performance only on species-relative abundances at test time. MVIB-M indicates the model performance only on strain-level markers at test time. MVIB-A+M indicates the model performance on both species-relative abundances and strain-level markers at test time.</p>
        </caption>
        <graphic xlink:href="pcbi.1010050.g002" position="float"/>
      </fig>
      <p><xref rid="pcbi.1010050.g002" ref-type="fig">Fig 2</xref> shows that MVIB-M results are consistently better than those obtained from MVIB-A. In the bimodal setting, MVIB-A+M, the performance remains comparable to MVIB-M results (i.e. the best performance). One can notice that on the datasets of IBD, Cirrhosis, Colorectal and Hypertension, the results of MVIB-A+M are (slightly) better than the results reported by MVIB-A or MVIB-M.</p>
      <p>MVIB can efficiently combine heterogeneous input data modalities. Although ROC AUC results from MVIB-A are consistently lower than the ROC AUC values from MVIB-M, the combination of the two modalities does not lead to a performance drop that may occur in other methods due to an increased feature space, i.e. the curse of dimensionality. In summary, MVIB can guarantee classification performance which is at least as good as the best single-modality performance.</p>
    </sec>
    <sec id="sec017">
      <title>The triplet margin loss can improve classification</title>
      <p>The first term of the original MVIB objective <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>) is a negative log-likelihood, which acquires the shape of a binary cross-entropy in the binary classification setting. We explored an extension of this objective, namely <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub>, by adding a triplet margin loss term (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>).</p>
      <p>The triplet margin loss aims to encourage the latent distribution of samples which belong to the same class to cluster in a dedicated region of the latent Euclidean space. At the same time, the triplet margin loss encourages the distributions of samples of different classes to depart from each other in the latent space. This aims at increasing the separability of different classes and facilitating the classification task.</p>
      <p><xref rid="pcbi.1010050.s003" ref-type="supplementary-material">S2 Table</xref> presents a comparison of the effects of the triplet margin loss on the MVIB classification performance. For the IBD, EW-T2D, C-T2D and Early-Colorectal-EMBL datasets, the highest ROC AUC is achieved by optimising the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective, which includes the triplet margin loss. The <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective leads to best results on the remaining datasets.</p>
      <p><xref rid="pcbi.1010050.g003" ref-type="fig">Fig 3A</xref> depicts the 95% confidence interval of the subjects’ stochastic encodings <inline-formula id="pcbi.1010050.e051"><alternatives><graphic xlink:href="pcbi.1010050.e051.jpg" id="pcbi.1010050.e051g" position="anchor"/><mml:math id="M51" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> deriving from the optimisation of the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>). Such Gaussian distributions are the output of the PoE (<xref rid="pcbi.1010050.e010" ref-type="disp-formula">Eq 4</xref>) and consist in fact in the joint posterior distribution of the latent encoding, conditioned on all input data modalities. In comparison with the curves of <xref rid="pcbi.1010050.g003" ref-type="fig">Fig 3C</xref>, obtained with the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>), we observe that the triplet margin loss leads to Gaussian distributions which present a higher variance. Conversely, stochastic encodings deriving from <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>) present smaller variance (see <xref rid="pcbi.1010050.g003" ref-type="fig">Fig 3A</xref>).</p>
      <fig position="float" id="pcbi.1010050.g003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Effect of the triplet margin loss on the stochastic encodings of the microbiome samples.</title>
          <p>The depicted curves are the 95% confidence intervals of the samples’ stochastic encodings <inline-formula id="pcbi.1010050.e052"><alternatives><graphic xlink:href="pcbi.1010050.e052" id="pcbi.1010050.e052g" position="anchor"/><mml:math id="M52" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; the points are their means <bold><italic toggle="yes">μ</italic></bold>. The displayed encodings consist in a set of 22 test samples obtained from a random training-test split of the IBD dataset (i.e. the 20% of the dataset not used for training). The <italic toggle="yes">K</italic> dimension of the latent space has been set to 2 in order to allow a 2D visualisation. (A, B) optimisation of the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>). (C, D) optimisation of the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>).</p>
        </caption>
        <graphic xlink:href="pcbi.1010050.g003" position="float"/>
      </fig>
      <p>Methods such as simple autoencoders, or the PCA, which are commonly used for dimensionality reduction, provide deterministic encodings, i.e. compressed representations of the input without a rigorous estimate of the uncertainty. Our method allows to compute <italic toggle="yes">stochastic</italic> encodings, i.e. to represent the input not only as a point in a latent space, but as a probability distribution. Computing probability distributions allows to estimate the confidence of the stochastic encodings.</p>
      <p>Intuitively, it is preferable to obtain stochastic encodings which present a small variance, as this allows for a better separability and classification. <xref rid="pcbi.1010050.g003" ref-type="fig">Fig 3</xref> allows to visually interpret the effect of including the triplet margin loss (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>) in the objective function and to visualise the results of the different losses on the samples’ stochastic encodings. We conclude that, although adding the triplet margin loss can lead to better classification results on some datasets (see <xref rid="pcbi.1010050.s003" ref-type="supplementary-material">S2 Table</xref>), the stochastic encodings derived from the optimisation of the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>) present higher variance with respect to those obtained from the optimisation of the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>).</p>
      <p>In addition to the plots of <xref rid="pcbi.1010050.g003" ref-type="fig">Fig 3</xref>, which only refer to the IBD dataset, <xref rid="pcbi.1010050.s007" ref-type="supplementary-material">S2 File</xref> contains the plots of the MVIB stochastic encodings for all the datasets considered in this work. The stochastic encodings depicted in <xref rid="pcbi.1010050.s007" ref-type="supplementary-material">S2 File</xref> are obtained from the <italic toggle="yes">joint</italic> datasets collection. They are available for models trained by optimising the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective, as well as models trained by optimising the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective, in order to allow comparison.</p>
      <p><xref rid="pcbi.1010050.s008" ref-type="supplementary-material">S3 File</xref> presents for each dataset a comparison between the PCA 2D projections and the mean of the MVIB 2D stochastic encodings. For both the PCA and the MVIB plots presented in <xref rid="pcbi.1010050.s008" ref-type="supplementary-material">S3 File</xref>, the <italic toggle="yes">default</italic> datasets collection has been adopted. It is possible to observe that the PCA projections completely fail at clustering the two samples classes (healthy and sick) in dedicated areas of the 2D plane. Conversely, MVIB encodes sick and healthy samples in two clearly separated areas of the 2D plane, creating two distinct clusters.</p>
    </sec>
    <sec id="sec018">
      <title>Transfer learning across different diseases can improve disease prediction</title>
      <p>Driven by the hypothesis that different diseases might lead to some common altered patterns in the subjects’ microbiome, we performed various transfer learning experiments. As described in Section Transfer learning, we first pre-trained MVIB on all non-target diseases, then we fine-tuned the model on target diseases. For these experiments, we only consider the <italic toggle="yes">joint</italic> datasets collection, as it presents feature vectors with the same dimensions across all disease cohorts for both the species-relative abundance and strain-level marker profiles. <xref rid="pcbi.1010050.s004" ref-type="supplementary-material">S3 Table</xref> presents the MVIB classification performance achieved by performing a pre-training on the source task followed by a fine-tuning on the target diseases. The ROC AUC slightly decreases on the Cirrhosis and Colorectal target datasets. A consistent performance drop is observed on the IBD and EW-T2D target datasets. Improvements on randomly initialised models can be observed on the remaining datasets, i.e. C-T2D, Obesity and Hypertension.</p>
      <p>We did not consider Colorectal-EMBL or Obesity-Joint datasets here, since the former is just an extension to Colorectal dataset, and the latter is an extension to Obesity dataset. Thus, we ensured that the samples that are present in more than a single dataset will not observed twice, i.e. during both source and target tasks. Moreover, ΔObesity and ΔColorectal are only used during the source task (i.e. pre-training).</p>
    </sec>
    <sec id="sec019">
      <title>Cross-study generalisation results and benchmark</title>
      <p>Generalisation is a fundamental requirement for machine learning models. It consists in the capacity to make correct predictions on samples which were not observed at training time. In order to further investigate how well MVIB can generalise, we performed cross-study experiments as described in Section Cross-study generalisation. First, six ordered pairs of datasets were identified: (EW-T2D, C-T2D), (C-T2D, EW-T2D), (ΔObesity, Obesity), (ΔColorectal, Colorectal), (Obesity, ΔObesity), (Colorectal, ΔColorectal). The first dataset of each pair was exclusively used for training, while the second one for testing without fine-tuning. In order to guarantee that abundance and marker features share the same positional indexes across the source and target datasets, the <italic toggle="yes">joint</italic> dataset collection was employed for all cross-study experiments (see Section Pre-processing).</p>
      <p>In order to compare the generalisation capabilities of MVIB with a state-of-the-art machine learning model used in microbiome research, we performed benchmark experiments with Random Forest. The Random Forest was trained on the concatenation of the abundance and marker profiles (multimodal setting). For the Random Forest, a cross-validated grid-search over a defined hyperparameter space was adopted for fine tuning (see <xref rid="pcbi.1010050.s006" ref-type="supplementary-material">S1 File</xref>). MVIB did not undergo hyperparameter tuning, but employed the default implementation described in Section Implementation details, with the exception of a lower learning rate, which was set to 10<sup>−5</sup>, as we observed this improves convergence.</p>
      <p><xref rid="pcbi.1010050.g004" ref-type="fig">Fig 4</xref> shows the cross-study results. MVIB performed better than the Random Forest on the (EW-T2D, C-T2D) and (ΔColorectal, Colorectal) experiments. Conversely, the Random Forest achieved better generalisation on (C-T2D, EW-T2D), (ΔObesity, Obesity) and (Obesity, ΔObesity). The two methods obtained the same results on (Colorectal, ΔColorectal).</p>
      <fig position="float" id="pcbi.1010050.g004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>MVIB cross-study generalisation and benchmark.</title>
          <p>Values are test ROC AUC computed by first training the models on a source dataset and then testing it on a target dataset. RF: Random Forest. All datasets used for cross-study experiments belong to the <italic toggle="yes">joint</italic> collection. For MVIB, the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective has been adopted for the optimisation (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>). The datasets reported on the x-axis shall be interpreted as: <italic toggle="yes">train</italic> →<italic toggle="yes">test</italic>. For the Random Forest, the error bars represent the standard error over five repeated experiments and account for the stochasticity of the Scikit-learn implementation. The standard error is missing for the MVIB results, as our PyTorch implementation has been made deterministic.</p>
        </caption>
        <graphic xlink:href="pcbi.1010050.g004" position="float"/>
      </fig>
      <p>Based on the empirical results which we obtained, it is possible to conclude that MVIB offers competitive cross-study generalisation when benchmarked with a fine-tuned Random Forest.</p>
    </sec>
    <sec id="sec020">
      <title>Discovering the most salient microbial species and strain-level markers</title>
      <p>In order to achieve interpretability, we implemented a method which allows to compute saliency, i.e. detecting the areas of the input vectors which are most discriminative with respect to the predicted class (see Section Explaining predictions with saliency). For each disease dataset in the <italic toggle="yes">default</italic> dataset collection, we obtained saliency maps of both abundance and marker profiles. Such saliency maps were obtained by computing the derivative of the model’s positive predictions with respect to the inputs (<xref rid="pcbi.1010050.e047" ref-type="disp-formula">Eq 10</xref>). Since we were mostly interested in the magnitude of such gradients, rather than the sign, the absolute value was considered.</p>
      <p>The aim of this analysis is the discovery of the most salient microbial species and strain-level markers for each considered dataset, i.e. the features which mostly affect the outcome of positive disease predictions. In order to discover true biological insights about the relationships between the microbiome and the analysed diseases, we considered saliency maps derived from true positive predictions. After having trained MVIB, each dataset was passed through the model to compute predictions for all samples. Saliency maps were then computed (<xref rid="pcbi.1010050.e047" ref-type="disp-formula">Eq 10</xref>). Saliency vectors coming from true positive predictions where then extracted from the dataset batch. As described in Section Validation framework and performance evaluation, experiments were repeated five times with different independent training-test splits. Furthermore, for each of the five training-test splits, the five different best models derived from a 5-fold cross-validation were ensembled. This leads to 25 different models, and therefore 25 saliency maps, which were then averaged.</p>
      <p><xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5</xref> depicts the microbial species sorted by mean saliency for the Colorectal-EMBL dataset. <xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5A</xref> only depicts the top 25 species, while <xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5B</xref> depicts the full distribution.</p>
      <fig position="float" id="pcbi.1010050.g005">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Microbial species sorted by saliency for the Colorectal-EMBL dataset.</title>
          <p>Saliency maps computed for the Colorectal-EMBL dataset using <xref rid="pcbi.1010050.e047" ref-type="disp-formula">Eq 10</xref>. (A) Top 25 microbial species sorted by mean saliency. Species abundance significance in healthy (red) and affected (blue) individuals was calculated using a Wilcoxon test for each microbial species for two unpaired samples: healthy and affected individuals. Error bars represent the standard error over the five repeated experiments and the five ensembled MVIB models for each experiment. (B) Full distribution of the mean saliency across the microbial species of the Colorectal-EMBL dataset.</p>
        </caption>
        <graphic xlink:href="pcbi.1010050.g005" position="float"/>
      </fig>
      <p>For the microbial species, the abundance significance in healthy and affected individuals was calculated by means of a Wilcoxon test. For each microbial species, two samples were constructed from the abundance values: (1) healthy individuals, (2) affected individuals.</p>
      <p>False discovery rate (FDR) correction was applied to adjust for multiple hypotheses testing. Species abundance supported by adjusted p-values &lt; 0.1 was reported as significant. In <xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5</xref>, species which are significantly more abundant in healthy individuals are marked in red. Species which are significantly more abundant in positive individual are marked in blue.</p>
      <p><xref rid="pcbi.1010050.s009" ref-type="supplementary-material">S4 File</xref> contains the plots with the top 25 microbial species and strain markers sorted by mean saliency for all datasets considered in this work, analogous to what <xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5A</xref> depicts for the Colorectal-EMBL dataset.</p>
      <p>As depicted in <xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5</xref> and <xref rid="pcbi.1010050.s009" ref-type="supplementary-material">S4 File</xref>, many species which are significantly more abundant in either healthy (red) or affected individuals (blue) appear among the most salient ones. However, in multiple instances, non-significant species (grey) are also listed among the most salient ones. We believe this has the following explanation. On one hand, the Wilcoxon test used to compute the significance of species abundance considers one single species at a time. Hence, the Wilcoxon test is not capable to capture complex multi-dimensional patterns in the abundance distribution. On the other hand, MVIB can learn complex non-linear dependencies between the input and a given label. As non-significant microbial species appear to be salient for the model, this seems to point out the existence of inter-dependencies among microbial species, which MVIB could capture. Additionally, in the Wilcoxon test, p-values &lt; 0.1 were reported as significant. The selection of this threshold for the p-values intrinsically affects what species are labelled as significantly more abundant.</p>
      <p><xref rid="pcbi.1010050.s010" ref-type="supplementary-material">S5 File</xref> contains the histogram plots of the full saliency distributions over species (analogous to what <xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5B</xref> depicts for the Colorectal-EMBL dataset), as well as the violin plots of the saliency distributions grouped by significance. The species in the histograms are sorted by mean saliency. As it is possible to observe in the histograms plots, saliency maps are not sparse. This is possibly due to how they are computed: as described above, the final saliency maps are obtained by averaging the saliency computed from 25 models. Additionally, as displayed in the plots, values are very low. Saliency maps are in fact the gradients of the model output with respect to the input. In deep learning, gradients are in general very low to allow computational stability, but also for theoretical reasons (e.g. regularization). Although we cannot escape these drawbacks which accompany gradients, we still observe that the average saliency maps let species emerge, which are under-/over-represented in the affected and healthy individuals. We can conclude that, although models e.g. RF or penalised linear regression could allow for simpler and more intuitive feature selection, deep-learning-based methods like MVIB can also allow for explainable predictions.</p>
    </sec>
    <sec id="sec021">
      <title>Metabolomics can improve colorectal cancer prediction when combined with metagenomics</title>
      <p>With the aim of further investigating the multimodal learning capabilities of MVIB, we performed experiments on the Colorectal-Metabolic dataset extracted from [<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>]. For each sample, this dataset presents three modalities: species-relative abundance, strain-level marker and metabolite profiles.</p>
      <p>First, we trained MVIB following the full multimodal training paradigm presented in Section Trimodal MVIB: Combining metabolomics and metagenomics. This ensures that all encoders are individually and jointly trained and that MVIB can perform single-modality and multimodal predictions at test time. We then tested the model in various multimodal and single-modality fashions: abundance profiles only (A), marker profiles only (M), abundance + marker profiles (A+M), abundance + marker + metabolite profiles (A+M+Metabolic).</p>
      <p>We compared MVIB with a fine-tuned Random Forest. For fine-tuning the Random Forest, a cross-validated grid-search over a defined hyperparameter space was used (see <xref rid="pcbi.1010050.s006" ref-type="supplementary-material">S1 File</xref>). In the A+M and A+M+Metabolic multimodal settings, the various input modalities have been concatenated and then fed into the Random Forest.</p>
      <p><xref rid="pcbi.1010050.g006" ref-type="fig">Fig 6</xref> shows the obtained experimental results. It is possible to observe that the multimodal settings A+M and A+M+Metabolic allow MVIB to reach higher test ROC AUC with respect to Random Forest. Furthermore, adding metabolomic data (A+M+Metabolic) allows to achieve the best classification results. Results obtained in the single-modality M setting are comparable to those obtained in the trimodal setting.</p>
      <fig position="float" id="pcbi.1010050.g006">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>Comparison of different multimodal and single-modality models for colorectal cancer prediction.</title>
          <p>Values are test ROC AUC, error bars are standard error obtained by repeating the experiment five times on different random train/test splits. RF: Random Forest. A: species-relative abundance profiles. M: strain-level marker profiles. Metabolic: metabolite profiles. For MVIB, the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective has been adopted for the optimisation (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>). Experiments are executed on the Colorectal-Metabolic dataset extracted from [<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>].</p>
        </caption>
        <graphic xlink:href="pcbi.1010050.g006" position="float"/>
      </fig>
      <p>The Random Forest performs better than MVIB only in the abundance-only single-modality setting (A). Most notably, the Random Forest performance tends to degrade when further data modalities are added. This shows the superiority of MVIB in combining multiple heterogeneous data modalities.</p>
    </sec>
    <sec id="sec022">
      <title>Empirical analysis of the training time</title>
      <p>In this section, we report the analysis of the training time of various machine learning models trained on the trimodal Colorectal-Metabolic dataset from [<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>]. We choose this dataset since it has three data modalities, and the highest number of samples compared with the other datasets considered in this work.</p>
      <p>For benchmarking, we compared the training time of MVIB with the training time of Random Forest (RF-DEF in <xref rid="pcbi.1010050.g007" ref-type="fig">Fig 7</xref>), Support Vector Machine (SVM-DEF in <xref rid="pcbi.1010050.g007" ref-type="fig">Fig 7</xref>) and Random Forest with hyperparameter optimisation (RF-HPO in <xref rid="pcbi.1010050.g007" ref-type="fig">Fig 7</xref>). For both RF-DEF and SVM-DEF, we considered the default implementation from Scikit-learn [<xref rid="pcbi.1010050.ref046" ref-type="bibr">46</xref>] library version 0.23.2, which runs on CPU. We labelled the two methods with <italic toggle="yes">-DEF</italic> suffix in order to highlight that the default Scikit-learn implementation was used without any hyperparameter optimisation.</p>
      <fig position="float" id="pcbi.1010050.g007">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010050.g007</object-id>
        <label>Fig 7</label>
        <caption>
          <title>Training time comparison across different machine learning models and various feature space dimensions.</title>
          <p>The values reported in this graph consist in the training time measured in seconds. The Colorectal-Metabolic dataset extracted from [<xref rid="pcbi.1010050.ref037" ref-type="bibr">37</xref>] has been used for training all models. The depicted training times are obtained by averaging the run times of five experiments with different random train/test splits. A: species-relative abundance profiles. M: strain-level marker profiles. Metabolic: metabolite profiles. RF-DEF: Random Forest with default Scikit-learn implementation. SVM-DEF: Support Vector Machine with default Scikit-learn implementation. RF-HPO: Random Forest with hyperparameter optimisation (see <xref rid="pcbi.1010050.s006" ref-type="supplementary-material">S1 File</xref>). For MVIB, the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective has been adopted for the optimisation (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>). On the x-axis, next to the modality name, the feature space dimension is reported in square brackets.</p>
        </caption>
        <graphic xlink:href="pcbi.1010050.g007" position="float"/>
      </fig>
      <p>For RF-HPO, we implement a cross-validated grid-search over a defined hyperparameter space (see <xref rid="pcbi.1010050.s006" ref-type="supplementary-material">S1 File</xref>). We used 16 CPU cores to parallelise the grid-search. The hyperparameter optimisation adopted for RF-HPO is the same one which we used to obtain the results in <xref rid="pcbi.1010050.t002" ref-type="table">Table 2</xref>.</p>
      <p>For MVIB, we set the learning rate to 10<sup>−4</sup> and the latent dimension <italic toggle="yes">K</italic> to 256. We trained MVIB with a batch size of 256 for up to 50 epochs, as convergence (i.e. best validation ROC AUC) is normally observed within the first 20 epochs. We considered the training complete at the epoch in which the model achieves the highest ROC AUC on the validation set. No ensembling was performed, i.e. a single model was trained in this set of experiments. MVIB experiments were executed on a single NVIDIA GeForce RTX 2080 Ti GPU.</p>
      <p>We performed experiments in various multimodal and single-modality fashions: abundance profiles only (A), marker profiles only (M), abundance + marker profiles (A+M), abundance + marker + metabolite profiles (A+M+Metabolic). For RF-DEF, SVM-DEF and RF-HPO, in the multimodal settings, the input feature vectors of the various modalities were concatenated. <xref rid="pcbi.1010050.g007" ref-type="fig">Fig 7</xref> depicts the empirical results of the training time analysis.</p>
      <p>Although the SVM-DEF is the fastest model to complete training in the abundance-only setting (A), its training time dramatically increases in the markers-only setting (M), as well as in the the two multimodal settings (A+M and A+M+Metabolic), reaching an average training time of more than 7 seconds. The feature space dimensions in the various settings are reported in <xref rid="pcbi.1010050.g007" ref-type="fig">Fig 7</xref>. The RF-DEF exhibits the same trend: it achieves the fastest training in the A setting, but requires a slightly longer time in all other settings. Compared with the SVM-DEF, the RF-DEF is always much faster and never requires more than 1 second to complete training. The training of RF-HPO requires consistently more time due to the cross-validated grid-search: around 30 seconds in the A setting, and more than 70 seconds for all other settings.</p>
      <p>For MVIB we observe a different behaviour. The training time does not appear to correlate with the feature space dimension. In fact the shortest training time is achieved in the M setting, which presents a much higher feature space dimension with respect to A. In all other settings, MVIB converges in around 1 second.</p>
      <p>In the A setting, despite the smaller feature space dimension, MVIB requires a longer training time with respect to the M setting. This is because the training duration of MVIB is mainly determined by the number of epochs needed to reach the highest validation ROC AUC. The number of required epochs is mainly a function of the learning rate and the batch size. The single forward pass and backpropagation steps are extremely quick and highly parallelised, hence the feature space dimension plays a less relevant role in the training time of MVIB w.r.t. RF-DEF, SVM-DEF and RF-HPO.</p>
      <p>It is additionally worth mentioning that RF-DEF is consistently worse than MVIB when it comes to classification results (see <xref rid="pcbi.1010050.s005" ref-type="supplementary-material">S4 Table</xref> and <xref rid="pcbi.1010050.t002" ref-type="table">Table 2</xref>, respectively). RF-HPO provides competitive classification performance with respect to MVIB (see Random Forest results in <xref rid="pcbi.1010050.t002" ref-type="table">Table 2</xref>), but its training time is consistently higher (see <xref rid="pcbi.1010050.g007" ref-type="fig">Fig 7</xref>). Hence, we can conclude that the Random Forest only competes with MVIB when it undergoes an extensive hyperparameter optimisation. Our implementation of MVIB requires very short training time and provides high classification performance without fine-tuning.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec023">
    <title>Discussion</title>
    <p>Microbiome-based disease prediction is a challenging task due to several reasons. First, microbial communities present high complexity in their composition. Second, microbial features (e.g. species abundance, strain-level markers and metabolites) are heterogeneous data modalities and sometimes they are generated using different technologies (e.g. shotgun metagenomic sequencing and mass spectrometry, respectively). Third, human gut microbiome is in a state of constant change, not only when a host is affected by a certain disease, but also as a function of lifestyle, e.g. diet [<xref rid="pcbi.1010050.ref002" ref-type="bibr">2</xref>], stress [<xref rid="pcbi.1010050.ref047" ref-type="bibr">47</xref>] and sleep [<xref rid="pcbi.1010050.ref048" ref-type="bibr">48</xref>]. Therefore, it is not surprising that a “healthy” microbiome can not be determined by simple rules of thumb, e.g., high or low count of individual taxa [<xref rid="pcbi.1010050.ref049" ref-type="bibr">49</xref>, <xref rid="pcbi.1010050.ref050" ref-type="bibr">50</xref>].</p>
    <p>In this work, we have introduced MVIB, a novel multimodal deep learning approach for microbiome-based disease prediction. MVIB computes a joint stochastic encoding of species-relative abundance and strain-level marker profiles. Both of these microbial features were obtained from shotgun metagenomic sequencing. MVIB stochastic encodings are maximally compressive of the various input data modalities and are simultaneously maximally informative about the output labels. We demonstrate that MVIB scales well in the trimodal setting where the learned encoding combines information from the species-relative abundances, the strain-level markers and the metabolites (from mass spectrometry). When the various input data modalities are considered jointly, MVIB computes a more complete representation of the host microbiome.</p>
    <p>Our results show that MVIB competes with state-of-the-art methods for microbiome-based disease prediction, e.g. Random Forest, DeepMicro and PopPhy-CNN. MVIB achieves the highest ROC AUC on eight out of the eleven cohorts, although the improvement in performance can be marginal in certain cases. We also noticed that the discrimination capabilities of various classifiers including MVIB vary among different datasets, which may indicate less measurable microbial changes in subjects with certain diseases. Compared to DeepMicro, MVIB has the advantage of being an end-to-end approach, i.e. it learns a mapping from inputs to outputs and it does not require hyperparameter tuning. Conversely, DeepMicro requires a two-steps training approach, and it demands a complex fine-tuning process due to a lack of well-defined criteria about which autoencoder architecture and downstream classifier shall be used with a given dataset. Similarly, Random Forest requires a time-consuming hyperparameter optimisation step to achieve a good performance. Therefore, the training time of MVIB is ∼70 times faster than Random Forest training time (including the hyperparameter optimisation).</p>
    <p>Furthermore, we adopted a saliency technique derived from computer vision literature to interpret the output of MVIB and we identified the most relevant microbial species and strain-level markers to MVIB predictions. We performed cross-study generalisation experiments, where we trained and tested MVIB on different cohorts of the same disease. Our results show that MVIB is able to generalise in some cases like colorectal cancer, however, the results were not always satisfactory. Poor generalisation performance may be due to other environmental factors that are specific to each cohort which we do not consider in our model. For example, nutritional differences between Europe and China could play an important role in shaping the gut microbiome in the two different type 2 diabetes cohorts, i.e. EW-T2D and C-T2D.</p>
    <p>Finally, one possible area for future work is to extend MVIB from microbiome-based disease prediction to microbiome-based disease prevention, i.e. to predict the presence of a certain disease in its early stages, e.g. by identifying specific microbiome patterns that indicate the potential for developing that disease. We will also consider extending the current implementation to accommodate temporal longitudinal multimodal microbiome data; the current architecture can support such an extension using for example Long Short-Term Memory networks (LSTMs) [<xref rid="pcbi.1010050.ref051" ref-type="bibr">51</xref>] as encoders to capture temporal dynamics.</p>
  </sec>
  <sec id="sec024" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1010050.s001" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Trimodal MVIB architecture.</title>
        <p>This figure depicts the trimodal architecture of MVIB used for combining species-relative abundance, strain-level marker and metabolite profiles for colorectal cancer prediction.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s001.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s002" position="float" content-type="local-data">
      <label>S1 Table</label>
      <caption>
        <title>Complete experimental results for the multimodal microbiome-based disease prediction task with MVIB.</title>
        <p>Results obtained optimising the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>). Experiments are executed five times with random independent training-test splits. Values in brackets refer to the standard error over the repeated experiments. All values in the table refer to metrics computed on the test sets. ROC AUC: area under the receiver operating characteristic curve. AC: classification accuracy. F1: F1 score. P: precision. R: recall. D and J refer to the two pre-processing techniques adopted and the two collections of datasets obtained: <italic toggle="yes">default</italic> (D) and <italic toggle="yes">joint</italic> (J).</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s003" position="float" content-type="local-data">
      <label>S2 Table</label>
      <caption>
        <title>Comparison of different objective functions and pre-processing techniques.</title>
        <p>All values are ROC AUC computed on the test sets. Values in brackets refer to the standard error over five repeated experiments. The first group of columns presents the results obtained optimising the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>), which includes the triplet margin loss. The second group of columns presents the results obtained optimising the original objective function <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>). D and J refer to the two pre-processing techniques adopted and the two collections of datasets obtained: <italic toggle="yes">default</italic> (D) and <italic toggle="yes">joint</italic> (J).</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s004" position="float" content-type="local-data">
      <label>S3 Table</label>
      <caption>
        <title>Comparison of pre-trained models against randomly initialised models.</title>
        <p>The first column presents the results obtained with randomly initialised models. The second column displays classification results obtained by first pre-training the models on all source datasets, and then fine-tuning them on the target disease (see Section Transfer learning). The <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective was adopted for both columns (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>). J refers to the adopted pre-processing technique: <italic toggle="yes">joint</italic>. Reported values are ROC AUC computed on the test sets. In brackets, the standard error over five repeated experiments is reported.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s005" position="float" content-type="local-data">
      <label>S4 Table</label>
      <caption>
        <title>Experimental results for the Random Forest with default Scikit-learn implementation.</title>
        <p>Experiments are executed five times with random independent training-test splits. Values in brackets refer to the standard error over the repeated experiments. Reported values are test ROC AUC.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s006" position="float" content-type="local-data">
      <label>S1 File</label>
      <caption>
        <title>Random Forest hyperparameter space for cross-validated grid-search.</title>
        <p>The file contains the hyperparameter space considered for Random Forest in cross-validated grid-search.</p>
        <p>(TXT)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s006.txt">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s007" position="float" content-type="local-data">
      <label>S2 File</label>
      <caption>
        <title>Effect of the triplet margin loss on the stochastic encodings of the microbiome samples.</title>
        <p>For all datasets considered in this work, this file presents plots of the 2D MVIB stochastic encodings analogous to <xref rid="pcbi.1010050.g003" ref-type="fig">Fig 3</xref>. The depicted curves are the 95% confidence intervals of the samples’ stochastic encodings <inline-formula id="pcbi.1010050.e053"><alternatives><graphic xlink:href="pcbi.1010050.e053.jpg" id="pcbi.1010050.e053g" position="anchor"/><mml:math id="M53" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; the points are their means <bold><italic toggle="yes">μ</italic></bold>. The displayed encodings consist only in the test samples obtained from random training-test splits (i.e. the 20% of the dataset not used for training). The <italic toggle="yes">K</italic> dimension of the latent space has been set to 2 in order to allow a 2D visualisation. Plots derived from both the optimisation of the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>) and the optimisation of the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic></sub> objective (<xref rid="pcbi.1010050.e011" ref-type="disp-formula">Eq 5</xref>) are included. Five copies of all plots are available, as they are obtained by training the model with five different independent training-test random splits.</p>
        <p>(ZIP)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s007.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s008" position="float" content-type="local-data">
      <label>S3 File</label>
      <caption>
        <title>PCA 2D projections and MVIB 2D stochastic encoding.</title>
        <p>This file presents, for each dataset, the plots of the PCA 2D projections, as well as the plots of the mean of the MVIB 2D stochastic encodings. For the MVIB stochastic encodings <inline-formula id="pcbi.1010050.e054"><alternatives><graphic xlink:href="pcbi.1010050.e054.jpg" id="pcbi.1010050.e054g" position="anchor"/><mml:math id="M54" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, the depicted points represent the mean <bold><italic toggle="yes">μ</italic></bold>. The <italic toggle="yes">K</italic> dimension of the latent space has been set to 2 in order to allow a 2D visualisation of the encodings. For training MVIB, the <italic toggle="yes">J</italic><sub><italic toggle="yes">MVIB</italic>−<italic toggle="yes">T</italic></sub> objective (<xref rid="pcbi.1010050.e035" ref-type="disp-formula">Eq 8</xref>) has been optimised. For MVIB, five copies of the means plots are available, as they are obtained by training the model with five different independent training-test random splits. Both the PCA and the MVIB plots have been created starting from the <italic toggle="yes">default</italic> datasets collection.</p>
        <p>(ZIP)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s008.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s009" position="float" content-type="local-data">
      <label>S4 File</label>
      <caption>
        <title>Top microbial species and strain markers sorted by saliency for all datasets.</title>
        <p>These files present the plots of the top 25 microbial species and strain markers for all datasets considered in this work, analogous to what <xref rid="pcbi.1010050.g005" ref-type="fig">Fig 5A</xref> depicts for the species from the Colorectal-EMBL dataset. Additionally, the scripts used to create the plots are included.</p>
        <p>(ZIP)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s009.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010050.s010" position="float" content-type="local-data">
      <label>S5 File</label>
      <caption>
        <title>Saliency distributions over microbial species for all datasets.</title>
        <p>For each dataset, two different kinds of plots are available. (A) the histogram of the average saliency distribution over microbial species. Species are sorted from left to right by decreasing saliency. Species abundance significance in healthy (red) and affected (blue) individuals was calculated using a Wilcoxon test for each microbial species for two unpaired samples: healthy and affected individuals. (B) violin plots of the saliency distributions for microbial species grouped by significance: significantly more abundant in affected (blue), significantly more abundant in healthy (red), no significance (grey).</p>
        <p>(ZIP)</p>
      </caption>
      <media xlink:href="pcbi.1010050.s010.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to acknowledge Giacomo Maria Cremonesi and Panagiota Vasileiadou for supporting us in the successful completion of this research project. We would like to acknowledge Dr. Carolin Lawrence and Dr. Francesco Alesiani for valuable discussion.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1010050.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>De Sordi</surname><given-names>L</given-names></name>, <name><surname>Lourenço</surname><given-names>M</given-names></name>, <name><surname>Debarbieux</surname><given-names>L</given-names></name>. <article-title>The battle within: interactions of bacteriophages and bacteria in the gastrointestinal tract</article-title>. <source>Cell host and microbe</source>. <year>2019</year>. <volume>25</volume>(<issue>2</issue>):<fpage>210</fpage>–<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.chom.2019.01.018</pub-id><?supplied-pmid 30763535?><pub-id pub-id-type="pmid">30763535</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Gilbert</surname><given-names>JA</given-names></name>, <name><surname>Blaser</surname><given-names>MJ</given-names></name>, <name><surname>Caporaso</surname><given-names>JG</given-names></name>, <name><surname>Jansson</surname><given-names>JK</given-names></name>, <name><surname>Lynch</surname><given-names>SV</given-names></name>, <name><surname>Knight</surname><given-names>R</given-names></name>. <article-title>Current understanding of the human microbiome</article-title>. <source>Nature medicine</source>. <year>2018</year>. <volume>24</volume>(<issue>4</issue>):<fpage>392</fpage>–<lpage>400</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nm.4517</pub-id><?supplied-pmid 29634682?><pub-id pub-id-type="pmid">29634682</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Cho</surname><given-names>I</given-names></name>, <name><surname>Blaser</surname><given-names>MJ</given-names></name>. <article-title>The human microbiome: at the interface of health and disease</article-title>. <source>Nature Reviews Genetics</source>. <year>2012</year>. <volume>13</volume>(<issue>4</issue>):<fpage>260</fpage>–<lpage>270</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nrg3182</pub-id><?supplied-pmid 22411464?><pub-id pub-id-type="pmid">22411464</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Huttenhower</surname><given-names>C</given-names></name>, <name><surname>Gevers</surname><given-names>D</given-names></name>, <name><surname>Knight</surname><given-names>R</given-names></name>, <name><surname>Abubucker</surname><given-names>S</given-names></name>, <name><surname>Badger</surname><given-names>JH</given-names></name>, <name><surname>Chinwalla</surname><given-names>AT</given-names></name>, <etal>et al</etal>. <article-title>Structure, function and diversity of the healthy human microbiome</article-title>. <source>Nature</source>. <year>2012</year>. <volume>486</volume>(<issue>7402</issue>):<fpage>207</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature11234</pub-id><pub-id pub-id-type="pmid">22699609</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>McQuade</surname><given-names>JL</given-names></name>, <name><surname>Daniel</surname><given-names>CR</given-names></name>, <name><surname>Helmink</surname><given-names>BA</given-names></name>, <name><surname>Wargo</surname><given-names>JA</given-names></name>. <article-title>Modulating the microbiome to improve therapeutic response in cancer</article-title>. <source>The Lancet Oncology</source>. <year>2019</year>. <volume>20</volume>(<issue>2</issue>):<fpage>e77</fpage>–<lpage>e91</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S1470-2045(18)30952-5</pub-id><?supplied-pmid 30712808?><pub-id pub-id-type="pmid">30712808</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Eloe-Fadrosh</surname><given-names>EA</given-names></name>, <name><surname>Rasko</surname><given-names>DA</given-names></name>. <article-title>The human microbiome: from symbiosis to pathogenesis</article-title>. <source>Annual review of medicine</source>. <year>2013</year>. <volume>64</volume>:<fpage>145</fpage>–<lpage>163</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1146/annurev-med-010312-133513</pub-id><?supplied-pmid 23327521?><pub-id pub-id-type="pmid">23327521</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Turnbaugh</surname><given-names>PJ</given-names></name>, <name><surname>Ley</surname><given-names>RE</given-names></name>, <name><surname>Hamady</surname><given-names>M</given-names></name>, <name><surname>Fraser-Liggett</surname><given-names>CM</given-names></name>, <name><surname>Knight</surname><given-names>R</given-names></name>, <name><surname>Gordon</surname><given-names>JI</given-names></name>. <article-title>The human microbiome project</article-title>. <source>Nature</source>. <year>2007</year>. <volume>449</volume>(<issue>7164</issue>):<fpage>804</fpage>–<lpage>810</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature06244</pub-id><?supplied-pmid 17943116?><pub-id pub-id-type="pmid">17943116</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Qin</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>R</given-names></name>, <name><surname>Raes</surname><given-names>J</given-names></name>, <name><surname>Arumugam</surname><given-names>M</given-names></name>, <name><surname>Burgdorf</surname><given-names>KS</given-names></name>, <name><surname>Manichanh</surname><given-names>C</given-names></name>, <etal>et al</etal>. <article-title>A human gut microbial gene catalogue established by metagenomic sequencing</article-title>. <source>Nature</source>. <year>2010</year>. <volume>464</volume>(<issue>7285</issue>):<fpage>59</fpage>–<lpage>65</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature08821</pub-id><?supplied-pmid 20203603?><pub-id pub-id-type="pmid">20203603</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Moreno-Indias</surname><given-names>I</given-names></name>, <name><surname>Lahti</surname><given-names>L</given-names></name>, <name><surname>Nedyalkova</surname><given-names>M</given-names></name>, <name><surname>Elbere</surname><given-names>I</given-names></name>, <name><surname>Roshchupkin</surname><given-names>G</given-names></name>, <name><surname>Adilovic</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Statistical and machine learning techniques in human microbiome studies: contemporary challenges and solutions</article-title>. <source>Frontiers in Microbiology</source>. <year>2021</year>. <volume>12</volume>:<fpage>277</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fmicb.2021.635781</pub-id><?supplied-pmid 33692771?><pub-id pub-id-type="pmid">33692771</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Quince</surname><given-names>C</given-names></name>, <name><surname>Walker</surname><given-names>AW</given-names></name>, <name><surname>Simpson</surname><given-names>JT</given-names></name>, <name><surname>Loman</surname><given-names>NJ</given-names></name>, <name><surname>Segata</surname><given-names>N</given-names></name>. <article-title>Shotgun metagenomics, from sampling to analysis</article-title>. <source>Nature biotechnology</source>. <year>2017</year>. <volume>35</volume>(<issue>9</issue>):<fpage>833</fpage>–<lpage>844</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt.3935</pub-id><?supplied-pmid 28898207?><pub-id pub-id-type="pmid">28898207</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Knight</surname><given-names>R</given-names></name>, <name><surname>Vrbanac</surname><given-names>A</given-names></name>, <name><surname>Taylor</surname><given-names>BC</given-names></name>, <name><surname>Aksenov</surname><given-names>A</given-names></name>, <name><surname>Callewaert</surname><given-names>C</given-names></name>, <name><surname>Debelius</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Best practices for analysing microbiomes</article-title>. <source>Nature Reviews Microbiology</source>. <year>2018</year>. <volume>16</volume>(<issue>7</issue>):<fpage>410</fpage>–<lpage>422</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41579-018-0029-9</pub-id><?supplied-pmid 29795328?><pub-id pub-id-type="pmid">29795328</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Pasolli</surname><given-names>E</given-names></name>, <name><surname>Truong</surname><given-names>DT</given-names></name>, <name><surname>Malik</surname><given-names>F</given-names></name>, <name><surname>Waldron</surname><given-names>L</given-names></name>, <name><surname>Segata</surname><given-names>N</given-names></name>. <article-title>Machine learning meta-analysis of large metagenomic datasets: tools and biological insights</article-title>. <source>PLoS computational biology</source>. <year>2016</year>. <volume>12</volume>(<issue>7</issue>):<fpage>e1004977</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004977</pub-id><?supplied-pmid 27400279?><pub-id pub-id-type="pmid">27400279</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Truong</surname><given-names>DT</given-names></name>, <name><surname>Tett</surname><given-names>A</given-names></name>, <name><surname>Pasolli</surname><given-names>E</given-names></name>, <name><surname>Huttenhower</surname><given-names>C</given-names></name>, <name><surname>Segata</surname><given-names>N</given-names></name>. <article-title>Microbial strain-level population structure and genetic diversity from metagenomes</article-title>. <source>Genome research</source>. <year>2017</year>. <volume>27</volume>(<issue>4</issue>):<fpage>626</fpage>–<lpage>38</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1101/gr.216242.116</pub-id><?supplied-pmid 28167665?><pub-id pub-id-type="pmid">28167665</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref014">
      <label>14</label>
      <mixed-citation publication-type="other">Nguyen TH, Chevaleyre Y, Prifti E, Sokolovska N, Zucker JD. Deep learning for metagenomic data: using 2d embeddings and convolutional neural networks. arXiv:171200244 [Preprint]. 2017 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1712.00244" ext-link-type="uri">https://arxiv.org/abs/1712.00244</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref015">
      <label>15</label>
      <mixed-citation publication-type="other">Nguyen TH, Prifti E, Chevaleyre Y, Sokolovska N, Zucker JD. Disease classification in metagenomics with 2d embeddings and deep learning. arXiv:180609046 [Preprint]. 2018 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1806.09046" ext-link-type="uri">https://arxiv.org/abs/1806.09046</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Asgari</surname><given-names>E</given-names></name>, <name><surname>Garakani</surname><given-names>K</given-names></name>, <name><surname>McHardy</surname><given-names>AC</given-names></name>, <name><surname>Mofrad</surname><given-names>MR</given-names></name>. <article-title>MicroPheno: predicting environments and host phenotypes from 16S rRNA gene sequencing using a k-mer based representation of shallow sub-samples</article-title>. <source>Bioinformatics</source>. <year>2018</year>. <volume>34</volume>(<issue>13</issue>):<fpage>i32</fpage>–<lpage>i42</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bty296</pub-id><?supplied-pmid 29950008?><pub-id pub-id-type="pmid">29950008</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Oh</surname><given-names>M</given-names></name>, <name><surname>Zhang</surname><given-names>L</given-names></name>. <article-title>DeepMicro: deep representation learning for disease prediction based on microbiome data</article-title>. <source>Scientific reports</source>. <year>2020</year>. <volume>10</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-020-63159-5</pub-id><?supplied-pmid 32265477?><pub-id pub-id-type="pmid">31913322</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Aryal</surname><given-names>S</given-names></name>, <name><surname>Alimadadi</surname><given-names>A</given-names></name>, <name><surname>Manandhar</surname><given-names>I</given-names></name>, <name><surname>Joe</surname><given-names>B</given-names></name>, <name><surname>Cheng</surname><given-names>X</given-names></name>. <article-title>Machine Learning Strategy for Gut Microbiome-Based Diagnostic Screening of Cardiovascular Disease</article-title>. <source>Hypertension</source>. <year>2020</year>. <volume>76</volume>(<issue>5</issue>):<fpage>1555</fpage>–<lpage>1562</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1161/HYPERTENSIONAHA.120.15885</pub-id><?supplied-pmid 32909848?><pub-id pub-id-type="pmid">32909848</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Reiman</surname><given-names>D</given-names></name>, <name><surname>Metwally</surname><given-names>AA</given-names></name>, <name><surname>Sun</surname><given-names>J</given-names></name>, <name><surname>Dai</surname><given-names>Y</given-names></name>. <article-title>PopPhy-CNN: a phylogenetic tree embedded architecture for convolutional neural networks to predict host phenotype from metagenomic data</article-title>. <source>IEEE journal of biomedical and health informatics</source>. <year>2020</year>. <volume>24</volume>(<issue>10</issue>):<fpage>2993</fpage>–<lpage>3001</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/JBHI.2020.2993761</pub-id><?supplied-pmid 32396115?><pub-id pub-id-type="pmid">32396115</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Wirbel</surname><given-names>J</given-names></name>, <name><surname>Zych</surname><given-names>K</given-names></name>, <name><surname>Essex</surname><given-names>M</given-names></name>, <name><surname>Karcher</surname><given-names>N</given-names></name>, <name><surname>Kartal</surname><given-names>E</given-names></name>, <etal>et al</etal>. <article-title>Microbiome meta-analysis and cross-disease comparison enabled by the SIAMCAT machine learning toolbox</article-title><source>Genome Biology</source>. <year>2021</year>. <volume>22</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>27</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13059-021-02306-1</pub-id><?supplied-pmid 33785070?><pub-id pub-id-type="pmid">33397451</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Sankaran</surname><given-names>K</given-names></name>, <name><surname>Holmes</surname><given-names>SP</given-names></name><article-title>Multitable Methods for Microbiome Data Integration</article-title><source>Frontiers in Genetics</source>. <year>2019</year>. <volume>10</volume>:<fpage>627</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fgene.2019.00627</pub-id><?supplied-pmid 31555316?><pub-id pub-id-type="pmid">31555316</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Zackular</surname><given-names>JP</given-names></name>, <name><surname>Rogers</surname><given-names>MA</given-names></name>, <name><surname>Ruffin</surname><given-names>MT</given-names></name>, <name><surname>Schloss</surname><given-names>PD</given-names></name>. <article-title>The human gut microbiome as a screening tool for colorectal cancer</article-title>. <source>Cancer prevention research</source>. <year>2014</year>. <volume>7</volume>(<issue>11</issue>):<fpage>1112</fpage>–<lpage>21</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1158/1940-6207.CAPR-14-0129</pub-id><?supplied-pmid 25104642?><pub-id pub-id-type="pmid">25104642</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref023">
      <label>23</label>
      <mixed-citation publication-type="other">Alemi AA, Fischer I, Dillon JV, Murphy K. Deep variational information bottleneck. arXiv:161200410 [Preprint]. 2016 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1612.00410" ext-link-type="uri">https://arxiv.org/abs/1612.00410</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Tishby N, Pereira FC, Bialek W. The information bottleneck method. arXiv:0004057 [Preprint]. 2000 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/physics/0004057" ext-link-type="uri">https://arxiv.org/abs/physics/0004057</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">Simonyan K, Vedaldi A, Zisserman A. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv:13126034 [Preprint]. 2013 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1312.6034" ext-link-type="uri">https://arxiv.org/abs/1312.6034</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Pan</surname><given-names>SJ</given-names></name>, <name><surname>Yang</surname><given-names>Q</given-names></name>. <article-title>A survey on transfer learning</article-title>. <source>IEEE Transactions on knowledge and data engineering</source>. <year>2009</year>. <volume>22</volume>(<issue>10</issue>):<fpage>1345</fpage>–<lpage>1359</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TKDE.2009.191</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Zhuang</surname><given-names>F</given-names></name>, <name><surname>Qi</surname><given-names>Z</given-names></name>, <name><surname>Duan</surname><given-names>K</given-names></name>, <name><surname>Xi</surname><given-names>D</given-names></name>, <name><surname>Zhu</surname><given-names>Y</given-names></name>, <name><surname>Zhu</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>A comprehensive survey on transfer learning</article-title>. <source>Proceedings of the IEEE</source>. <year>2020</year>. <volume>109</volume>(<issue>1</issue>):<fpage>43</fpage>–<lpage>76</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/JPROC.2020.3004555</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref028">
      <label>28</label>
      <mixed-citation publication-type="other">Kingma DP, Welling M. Auto-encoding variational bayes. arXiv:13126114 [Preprint]. 2013 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1312.6114" ext-link-type="uri">https://arxiv.org/abs/1312.6114</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Karlsson</surname><given-names>FH</given-names></name>, <name><surname>Tremaroli</surname><given-names>V</given-names></name>, <name><surname>Nookaew</surname><given-names>I</given-names></name>, <name><surname>Bergström</surname><given-names>G</given-names></name>, <name><surname>Behre</surname><given-names>CJ</given-names></name>, <name><surname>Fagerberg</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Gut metagenome in European women with normal, impaired and diabetic glucose control</article-title>. <source>Nature</source>. <year>2013</year>. <volume>498</volume>(<issue>7452</issue>):<fpage>99</fpage>–<lpage>103</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature12198</pub-id><?supplied-pmid 23719380?><pub-id pub-id-type="pmid">23719380</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Qin</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Cai</surname><given-names>Z</given-names></name>, <name><surname>Li</surname><given-names>S</given-names></name>, <name><surname>Zhu</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>A metagenome-wide association study of gut microbiota in type 2 diabetes</article-title>. <source>Nature</source>. <year>2012</year>. <volume>490</volume>(<issue>7418</issue>):<fpage>55</fpage>–<lpage>60</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature11450</pub-id><?supplied-pmid 23023125?><pub-id pub-id-type="pmid">23023125</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Le Chatelier</surname><given-names>E</given-names></name>, <name><surname>Nielsen</surname><given-names>T</given-names></name>, <name><surname>Qin</surname><given-names>J</given-names></name>, <name><surname>Prifti</surname><given-names>E</given-names></name>, <name><surname>Hildebrand</surname><given-names>F</given-names></name>, <name><surname>Falony</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Richness of human gut microbiome correlates with metabolic markers</article-title>. <source>Nature</source>. <year>2013</year>. <volume>500</volume>(<issue>7464</issue>):<fpage>541</fpage>–<lpage>546</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature12506</pub-id><?supplied-pmid 23985870?><pub-id pub-id-type="pmid">23985870</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>S</given-names></name>, <name><surname>Zhu</surname><given-names>A</given-names></name>, <name><surname>Benes</surname><given-names>V</given-names></name><etal>et al</etal>. <article-title>Durable coexistence of donor and recipient strains after fecal microbiota transplantation</article-title>. <source>Science</source>. <year>2016</year>. <volume>352</volume>(<issue>6285</issue>):<fpage>586</fpage>–<lpage>589</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/science.aad8852</pub-id><?supplied-pmid 27126044?><pub-id pub-id-type="pmid">27126044</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Voigt</surname><given-names>A</given-names></name>, <name><surname>Costea</surname><given-names>P</given-names></name>, <name><surname>Kultima</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Temporal and technical variability of human gut metagenomes</article-title>. <source>Genome Biology</source>. <year>2015</year>. <volume>16</volume>(<issue>73</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13059-015-0639-8</pub-id><?supplied-pmid 25888008?><pub-id pub-id-type="pmid">25888008</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Qin</surname><given-names>N</given-names></name>, <name><surname>Yang</surname><given-names>F</given-names></name>, <name><surname>Li</surname><given-names>A</given-names></name>, <name><surname>Prifti</surname><given-names>E</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Shao</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Alterations of the human gut microbiome in liver cirrhosis</article-title>. <source>Nature</source>. <year>2014</year>. <volume>513</volume>(<issue>7516</issue>):<fpage>59</fpage>–<lpage>64</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature13568</pub-id><?supplied-pmid 25079328?><pub-id pub-id-type="pmid">25079328</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Zeller</surname><given-names>G</given-names></name>, <name><surname>Tap</surname><given-names>J</given-names></name>, <name><surname>Voigt</surname><given-names>AY</given-names></name>, <name><surname>Sunagawa</surname><given-names>S</given-names></name>, <name><surname>Kultima</surname><given-names>JR</given-names></name>, <name><surname>Costea</surname><given-names>PI</given-names></name>, <etal>et al</etal>. <article-title>Potential of fecal microbiota for early-stage detection of colorectal cancer</article-title>. <source>Molecular systems biology</source>. <year>2014</year>. <volume>10</volume>(<issue>11</issue>):<fpage>766</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.15252/msb.20145645</pub-id><?supplied-pmid 25432777?><pub-id pub-id-type="pmid">25432777</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>J</given-names></name>, <name><surname>Zhao</surname><given-names>F</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>Gut microbiota dysbiosis contributes to the development of hypertension</article-title>. <source>Microbiome</source>. <year>2017</year>. <volume>5</volume>(<issue>14</issue>).</mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Yachida</surname><given-names>S</given-names></name>, <name><surname>Mizutani</surname><given-names>S</given-names></name>, <name><surname>Shiroma</surname><given-names>H</given-names></name>, <name><surname>Shiba</surname><given-names>S</given-names></name>, <name><surname>Nakajima</surname><given-names>T</given-names></name>, <etal>et al</etal><article-title>Metagenomic and metabolomic analyses reveal distinct stage-specific phenotypes of the gut microbiota in colorectal cancer</article-title><source>Nature Medicine</source>. <year>2019</year>. <volume>25</volume>(<issue>6</issue>):<fpage>968</fpage>–<lpage>976</lpage><comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-019-0458-7</pub-id><?supplied-pmid 31171880?><pub-id pub-id-type="pmid">31171880</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">NCBI. SRA-Tools. Last visited 2021 May 21. Available from: <ext-link xlink:href="http://ncbi.github.io/sra-tools/" ext-link-type="uri">http://ncbi.github.io/sra-tools/</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref039">
      <label>39</label>
      <mixed-citation publication-type="other">Biobakery. KneadData. Last visited 2021 May 21. Available from: <ext-link xlink:href="https://github.com/biobakery/kneaddata" ext-link-type="uri">https://github.com/biobakery/kneaddata</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Truong</surname><given-names>DT</given-names></name>, <name><surname>Franzosa</surname><given-names>EA</given-names></name>, <name><surname>Tickle</surname><given-names>TL</given-names></name>, <name><surname>Scholz</surname><given-names>M</given-names></name>, <name><surname>Weingart</surname><given-names>G</given-names></name>, <name><surname>Pasolli</surname><given-names>E</given-names></name>, <etal>et al</etal>. <article-title>MetaPhlAn2 for enhanced metagenomic taxonomic profiling</article-title>. <source>Nature methods</source>. <year>2015</year>. <volume>12</volume>(<issue>10</issue>):<fpage>902</fpage>–<lpage>903</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nmeth.3589</pub-id><?supplied-pmid 26418763?><pub-id pub-id-type="pmid">26418763</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref041">
      <label>41</label>
      <mixed-citation publication-type="other">Wu M, Goodman N. Multimodal generative models for scalable weakly-supervised learning. arXiv:180205335 [Preprint]. 2018 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1802.05335" ext-link-type="uri">https://arxiv.org/abs/1802.05335</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref042">
      <label>42</label>
      <mixed-citation publication-type="other">Cao Y, Fleet DJ. Generalized product of experts for automatic and principled fusion of Gaussian process predictions. arXiv:14107827 [Preprint]. 2014 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1410.7827" ext-link-type="uri">https://arxiv.org/abs/1410.7827</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref043">
      <label>43</label>
      <mixed-citation publication-type="other">Hendrycks D, Gimpel K. Gaussian error linear units (gelus). arXiv:160608415 [Preprint]. 2016 [cited 2021 May 21]. Available from: <ext-link xlink:href="https://arxiv.org/abs/1606.08415" ext-link-type="uri">https://arxiv.org/abs/1606.08415</ext-link></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref044">
      <label>44</label>
      <mixed-citation publication-type="other">Paszke A, Gross S, Massa F, Lerer A, Bradbury J, et al. PyTorch: An Imperative Style, High-Performance Deep Learning Library Advances in Neural Information Processing Systems. 2019. 8024–8035</mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Balntas</surname><given-names>V</given-names></name>, <name><surname>Riba</surname><given-names>E</given-names></name>, <name><surname>Ponsa</surname><given-names>D</given-names></name>, <name><surname>Mikolajczyk</surname><given-names>K</given-names></name>. <article-title>Learning local feature descriptors with triplets and shallow convolutional neural networks</article-title>. <source>BMVC</source>. <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python</article-title><source>Journal of Machine Learning Research</source>. <year>2011</year>. <volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref047">
      <label>47</label>
      <mixed-citation publication-type="journal"><name><surname>Stothart</surname><given-names>MR</given-names></name>, <name><surname>Palme</surname><given-names>R</given-names></name>, <name><surname>Newman</surname><given-names>AE</given-names></name>. <article-title>It’s what’s on the inside that counts: stress physiology and the bacterial microbiome of a wild urban mammal</article-title>. <source>Proceedings of the Royal Society B</source>. <year>2019</year>. <volume>286</volume>(<issue>1913</issue>):<fpage>2019</fpage>–<lpage>2111</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1098/rspb.2019.2111</pub-id><?supplied-pmid 31640519?><pub-id pub-id-type="pmid">31640519</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>RP</given-names></name>, <name><surname>Easson</surname><given-names>C</given-names></name>, <name><surname>Lyle</surname><given-names>SM</given-names></name>, <name><surname>Kapoor</surname><given-names>R</given-names></name>, <name><surname>Donnelly</surname><given-names>CP</given-names></name>, <name><surname>Davidson</surname><given-names>EJ</given-names></name>, <etal>et al</etal>. <article-title>Gut microbiome diversity is associated with sleep physiology in humans</article-title>. <source>PLoS One</source>. <year>2019</year>. <volume>14</volume>(<issue>10</issue>):<fpage>e0222394</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0222394</pub-id><?supplied-pmid 31589627?><pub-id pub-id-type="pmid">31589627</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref049">
      <label>49</label>
      <mixed-citation publication-type="journal"><name><surname>Ravel</surname><given-names>J</given-names></name>, <name><surname>Gajer</surname><given-names>P</given-names></name>, <name><surname>Abdo</surname><given-names>Z</given-names></name>, <name><surname>Schneider</surname><given-names>GM</given-names></name>, <name><surname>Koenig</surname><given-names>SS</given-names></name>, <name><surname>McCulle</surname><given-names>SL</given-names></name>, <name><surname>Karlebach</surname><given-names>S</given-names></name>, <name><surname>Gorle</surname><given-names>R</given-names></name>, <name><surname>Russell</surname><given-names>J</given-names></name>, <name><surname>Tacket</surname><given-names>CO</given-names></name>, <name><surname>Brotman</surname><given-names>RM</given-names></name>. <article-title>Vaginal microbiome of reproductive-age women</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2011</year>, <volume>108</volume>(<issue>Supplement 1</issue>):<fpage>4680</fpage>–<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.1002611107</pub-id><?supplied-pmid 20534435?><pub-id pub-id-type="pmid">20534435</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Schnorr</surname><given-names>SL</given-names></name>, <name><surname>Candela</surname><given-names>M</given-names></name>, <name><surname>Rampelli</surname><given-names>S</given-names></name>, <name><surname>Centanni</surname><given-names>M</given-names></name>, <name><surname>Consolandi</surname><given-names>C</given-names></name>, <name><surname>Basaglia</surname><given-names>G</given-names></name>, <name><surname>Turroni</surname><given-names>S</given-names></name>, <name><surname>Biagi</surname><given-names>E</given-names></name>, <name><surname>Peano</surname><given-names>C</given-names></name>, <name><surname>Severgnini</surname><given-names>M</given-names></name>, <name><surname>Fiori</surname><given-names>J</given-names></name>. <article-title>Gut microbiome of the Hadza hunter-gatherers</article-title>. <source>Nature communications</source>. <year>2014</year>, <volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>2</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/ncomms4654</pub-id><?supplied-pmid 24736369?><pub-id pub-id-type="pmid">24736369</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010050.ref051">
      <label>51</label>
      <mixed-citation publication-type="journal"><name><surname>Hochreiter</surname><given-names>S</given-names></name>, <name><surname>Schmidhuber</surname><given-names>J</given-names></name>. <article-title>Long short-term memory</article-title><source>Neural computation</source>. <year>1997</year>. <volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>–<lpage>1780</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><?supplied-pmid 9377276?><pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
