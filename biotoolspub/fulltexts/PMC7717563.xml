<?properties open_access?>
<?subarticle pcbi.1008277.r001?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">ploscomp</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7717563</article-id>
    <article-id pub-id-type="pmid">33216746</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-19-01790</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008277</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Public and Occupational Health</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Epidemiology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Natural Language Processing</subject>
            <subj-group>
              <subject>Word Embedding</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Machine Learning Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Support Vector Machines</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Applications</subject>
          <subj-group>
            <subject>Web-Based Applications</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Natural Language Processing</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic>EventEpi</italic>—A natural language processing framework for event-based surveillance</article-title>
      <alt-title alt-title-type="running-head"><italic>EventEpi</italic>–A natural language processing framework for event-based surveillance</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4428-168X</contrib-id>
        <name>
          <surname>Abbood</surname>
          <given-names>Auss</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Investigation</role>
        <role content-type="https://casrai.org/credit/">Methodology</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Visualization</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4894-6124</contrib-id>
        <name>
          <surname>Ullrich</surname>
          <given-names>Alexander</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Project administration</role>
        <role content-type="https://casrai.org/credit/">Supervision</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9593-8696</contrib-id>
        <name>
          <surname>Busche</surname>
          <given-names>Rüdiger</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Methodology</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Visualization</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3911-9573</contrib-id>
        <name>
          <surname>Ghozzi</surname>
          <given-names>Stéphane</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Project administration</role>
        <role content-type="https://casrai.org/credit/">Supervision</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Visualization</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff004">
          <sup>4</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Robert Koch Institute (RKI), Berlin, Germany</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Osnabrück University, Osnabrück, Lower Saxony, Germany</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>inserve GmbH, Hannover, Lower Saxony, Germany</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Helmholtz Centre for Infection Research (HZI), Brunswick, Lower Saxony, Germany</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Althouse</surname>
          <given-names>Benjamin Muir</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Institute for Disease Modeling, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>abbooda@rki.de</email> (AA); <email>ullricha@rki.de</email> (AU); <email>rbusche@uos.de</email> (RB); <email>stephane.ghozzi@helmholtz-hzi.de</email> (SG)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>20</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <volume>16</volume>
    <issue>11</issue>
    <elocation-id>e1008277</elocation-id>
    <history>
      <date date-type="received">
        <day>28</day>
        <month>10</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>8</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2020 Abbood et al</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Abbood et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1008277.pdf"/>
    <abstract>
      <p>According to the World Health Organization (WHO), around 60% of all outbreaks are detected using informal sources. In many public health institutes, including the WHO and the Robert Koch Institute (RKI), dedicated groups of public health agents sift through numerous articles and newsletters to detect relevant events. This media screening is one important part of event-based surveillance (EBS). Reading the articles, discussing their relevance, and putting key information into a database is a time-consuming process. To support EBS, but also to gain insights into what makes an article and the event it describes relevant, we developed a natural language processing framework for automated information extraction and relevance scoring. First, we scraped relevant sources for EBS as done at the RKI (WHO Disease Outbreak News and ProMED) and automatically extracted the articles’ key data: <italic>disease</italic>, <italic>country</italic>, <italic>date</italic>, and <italic>confirmed-case count</italic>. For this, we performed named entity recognition in two steps: EpiTator, an open-source epidemiological annotation tool, suggested many different possibilities for each. We extracted the key country and disease using a heuristic with good results. We trained a naive Bayes classifier to find the key date and confirmed-case count, using the RKI’s EBS database as labels which performed modestly. Then, for relevance scoring, we defined two classes to which any article might belong: The article is <italic>relevant</italic> if it is in the EBS database and <italic>irrelevant</italic> otherwise. We compared the performance of different classifiers, using bag-of-words, document and word embeddings. The best classifier, a logistic regression, achieved a sensitivity of 0.82 and an index balanced accuracy of 0.61. Finally, we integrated these functionalities into a web application called <italic>EventEpi</italic> where relevant sources are automatically analyzed and put into a database. The user can also provide any URL or text, that will be analyzed in the same way and added to the database. Each of these steps could be improved, in particular with larger labeled datasets and fine-tuning of the learning algorithms. The overall framework, however, works already well and can be used in production, promising improvements in EBS. The source code and data are publicly available under open licenses.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Public health surveillance that uses official sources to detect important disease outbreaks suffers from a time delay. Using unofficial sources, like websites, to detect rumors of disease outbreaks can offer a decisive temporal advantage. Due to the vast amount of information on the web, public health agents are only capable to process a fraction of the available information. Recent advances in natural language processing and deep learning offer new opportunities to process large amounts of text with human-like understanding. However, to the best of our knowledge, no open-source solutions using natural language processing for public health surveillance exist. We extracted expert labels from a public health unit that screens online resources every day to train various machine learning models and perform key information extraction as well as relevance scoring on epidemiological texts. With the help of those expert labels, we scraped and annotated news articles to create inputs for the machine learning models. The scraped texts were transformed into word embeddings that were trained on 61,320 epidemiological articles and the Wikipedia corpus (May 2020). We were able to extract key information from epidemiological texts such as disease, outbreak country, cases counts, and the date of these counts. While disease and country could be extracted with high accuracy, date and count could still be extracted with medium accuracy with the help of machine learning models. Furthermore, our model could detect 82% of all relevant articles in an unseen test dataset. Both of these functionalities were embedded into a web application. We present an open-source framework that public health agents can use to include online sources into their screening routine. This can be of great help to existing and emerging public health institutions. Although parts of the information extraction function robustly and the relevance scoring could already save public health agent’s time, methods to explain deep and machine learning models showed that the learned patterns are sometimes implausible. This could be improved with more labeled data and optimization of the learning algorithms.</p>
    </abstract>
    <funding-group>
      <funding-statement>The project was funded by the German Federal Ministry of Health through the Signale 2.0 project (<ext-link ext-link-type="uri" xlink:href="http://www.rki.de./signale-project">www.rki.de./signale-project</ext-link>) with the following funding code: ZMVI1-2517FSB418. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="3"/>
      <table-count count="3"/>
      <page-count count="16"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2020-12-04</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>Code and CSVs for figures in the manuscript are placed in <ext-link ext-link-type="uri" xlink:href="https://github.com/aauss/EventEpi">https://github.com/aauss/EventEpi</ext-link>. The incident data base can be found at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.12575978">https://doi.org/10.6084/m9.figshare.12575978</ext-link>. The word embeddings trained for this manuscript can be found at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.12575966">https://doi.org/10.6084/m9.figshare.12575966</ext-link>. This information can be found in the manuscript aswell.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>Code and CSVs for figures in the manuscript are placed in <ext-link ext-link-type="uri" xlink:href="https://github.com/aauss/EventEpi">https://github.com/aauss/EventEpi</ext-link>. The incident data base can be found at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.12575978">https://doi.org/10.6084/m9.figshare.12575978</ext-link>. The word embeddings trained for this manuscript can be found at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.12575966">https://doi.org/10.6084/m9.figshare.12575966</ext-link>. This information can be found in the manuscript aswell.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <sec id="sec002">
      <title>Event-based surveillance</title>
      <p>One of the major goals of <italic>public health surveillance</italic> is the timely detection and subsequent containment of infectious disease outbreaks to minimize health consequences and the burden to the public health apparatus. Surveillance systems are an essential part of efficient early-warning mechanisms [<xref rid="pcbi.1008277.ref001" ref-type="bibr">1</xref>, <xref rid="pcbi.1008277.ref002" ref-type="bibr">2</xref>].</p>
      <p>In traditional reporting systems the acquisition of this data is mostly a passive process and follows routines established by the legislator and the public health institutes [<xref rid="pcbi.1008277.ref002" ref-type="bibr">2</xref>]. This process is called <italic>indicator-based surveillance</italic>.</p>
      <p>Hints of an outbreak, however, can also be detected through changed circumstances that are known to favor outbreaks, e.g., warm weather might contribute to more salmonellosis outbreaks [<xref rid="pcbi.1008277.ref003" ref-type="bibr">3</xref>] or a loss of proper sanitation might lead to cholera outbreaks [<xref rid="pcbi.1008277.ref004" ref-type="bibr">4</xref>]. Therefore, besides traditional surveillance that typically relies on routine reporting from healthcare facilities, secondary data such as weather, attendance monitoring at schools and workplaces, social media, and the web are also significant sources of information [<xref rid="pcbi.1008277.ref002" ref-type="bibr">2</xref>].</p>
      <p>The monitoring of information generated outside the traditional reporting system and its analysis is called <italic>event-based surveillance</italic> (EBS). EBS can greatly reduce the delay between the occurrence and the detection of an event compared to IBS. It enables public health agents to detect and report events before the recognition of human cases in the routine reporting system of the public health system [<xref rid="pcbi.1008277.ref002" ref-type="bibr">2</xref>]. Especially on the web, the topicality and quantity of data can be useful to detect even rumors of suspected outbreaks [<xref rid="pcbi.1008277.ref005" ref-type="bibr">5</xref>]. As a result, more than 60% of the initial outbreak reports refer to such informal sources [<xref rid="pcbi.1008277.ref006" ref-type="bibr">6</xref>].</p>
      <p>Filtering this massive amount of data poses the difficulty of finding the right criteria for which information to consider and which to discard. This task is particularly difficult because it is important that the filter does not miss any important events (sensitivity) while being confident what to exclude (specificity). Without such a filter process, it is infeasible to perform EBS on larger data sources. Algorithms in the field of natural language processing are well suited to tap these informal resources and help to structure and filter this information automatically and systematically [<xref rid="pcbi.1008277.ref007" ref-type="bibr">7</xref>].</p>
    </sec>
    <sec id="sec003">
      <title>Motivation and contribution</title>
      <p>At the RKI, the <italic>The Information Centre for International Health Protection</italic> (<italic>Informationsstelle für Internationalen Gesundheitsschutz</italic>, INIG), among other units, performs EBS to identify events relevant to public health in Germany. Their routine tasks are defined in standard operating procedures (SOPs) and include reading online articles from a defined set of sources, evaluating them for their relevance, and then manually filling a spreadsheet with information from the relevant articles. This spreadsheet is INIG’s EBS database, called <italic>Incident Database</italic> (<italic>Ereignisdatenbank</italic>, <italic>IDB</italic>). The existence of SOPs and the amount of time spent with manual information extraction and especially data entry lead to the idea to automate parts of the process.</p>
      <p>Applying methods of natural language processing and machine learning to the IDB, we developed a pipeline that:</p>
      <list list-type="bullet">
        <list-item>
          <p>automatically extracts key entities (disease, country, confirmed-case count, and date of the case count which are the mandatory entries of the IDB and thus are complete) from an epidemiological article and puts them in a database, making tedious data entry unnecessary;</p>
        </list-item>
        <list-item>
          <p>scores articles for relevance to allow the most important ones to be shown first;</p>
        </list-item>
        <list-item>
          <p>provides the results in a web service named <italic>EventEpi</italic> that can be integrated in EBS workflows.</p>
        </list-item>
      </list>
      <p>We did not formally define what a “disease” was but rather followed the conventions at INIG. Although considering symptoms or syndromes might lead to earlier event detection, those were rarely entered in the IDB.</p>
      <p>All code and data necessary to reproduce this work are freely available under open licenses: The source code can be found on GitHub under a GNU license [<xref rid="pcbi.1008277.ref008" ref-type="bibr">8</xref>], the IDB and word embeddings (see Training of the classifiers) on Figshare under a CC BY 4.0 license, [<xref rid="pcbi.1008277.ref009" ref-type="bibr">9</xref>] and [<xref rid="pcbi.1008277.ref010" ref-type="bibr">10</xref>] respectively.</p>
    </sec>
    <sec id="sec004">
      <title>Related work</title>
      <p>The Global Rapid Identification Tool System (GRITS) [<xref rid="pcbi.1008277.ref011" ref-type="bibr">11</xref>] by the EcoHealth Alliance is a web service that provides automatic analyses of epidemiological texts. It uses EpiTator [<xref rid="pcbi.1008277.ref012" ref-type="bibr">12</xref>] to extract crucial information about a text, such as dates or countries, and suggests the most likely disease the text is about. However GRITS cannot be automated and is not customizable. To use it in EBS, one would need to manually copy-paste both URLs and output of the analysis. Furthermore, GRITS does not filter texts for relevance but only extracts entities from provided texts.</p>
      <p>The <italic>recent disease incidents page</italic> of MEDISYS [<xref rid="pcbi.1008277.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1008277.ref014" ref-type="bibr">14</xref>], which channels PULS [<xref rid="pcbi.1008277.ref015" ref-type="bibr">15</xref>, <xref rid="pcbi.1008277.ref016" ref-type="bibr">16</xref>], tabularly presents automatically-extracted outbreak information from a vast amount of news sources. However, it is not clear how articles are filtered, how information is extracted, or how uncertain the output is. Therefore, it cannot be used as such and as it is a closed software we could not develop it further.</p>
    </sec>
  </sec>
  <sec sec-type="materials|methods" id="sec005">
    <title>Materials and methods</title>
    <p>The approach presented here consists of two largely independent, but complementary parts: key information extraction and relevance scoring. Both approaches are integrated in a web application called <italic>EventEpi</italic>. After preprocessing the IDB, texts of articles from the RKI’s main online sources have to be extracted. The full pipeline is shown in <xref ref-type="fig" rid="pcbi.1008277.g001">Fig 1</xref>. With the exception of the convolutional neural network (CNN) for which we used Keras [<xref rid="pcbi.1008277.ref017" ref-type="bibr">17</xref>], we used the Python package scikit-learn to implement the machine learning algorithms [<xref rid="pcbi.1008277.ref018" ref-type="bibr">18</xref>]. The exact configurations of all algorithms can be found in <xref ref-type="supplementary-material" rid="pcbi.1008277.s002">S1 Table</xref>.</p>
    <fig id="pcbi.1008277.g001" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pcbi.1008277.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>An illustration of the <italic>EventEpi</italic> architecture.</title>
        <p>The orange part of the plot describes the relevance scoring of epidemiological texts vectorized with word embeddings (created with word2vec), document embeddings (mean over word embeddings), and bag-of-words, and fed to different classification algorithms (support vector machine (SVM), k-nearest neighbor (kNN) and logistic regression (LR) among others). The part of <italic>EventEpi</italic> that extracts the key information is colored in blue. Key information extraction is trained on sentences containing named entities using a naive Bayes classifier or the most-frequent approach applied to the output of EpiTator, a epidemiological annotation software. The workflow ends with the results being saved into the <italic>EventEpi</italic> database that is embedded into <italic>EventEpi</italic>’s web application.</p>
      </caption>
      <graphic xlink:href="pcbi.1008277.g001"/>
    </fig>
    <sec id="sec006">
      <title>Key information extraction</title>
      <p>Key information extraction from epidemiological articles was in part already solved by EpiTator. EpiTator is a Python library to extract named entities that are particularly relevant in the field of epidemiology, namely: disease, location, date, and count entities. EpiTator uses spaCy [<xref rid="pcbi.1008277.ref019" ref-type="bibr">19</xref>] in the background to preprocess text. One function of EpiTator is to return all entities of an entity class (e.g., disease) found in a text. However INIG, as other EBS groups, is mostly interested in the <italic>key</italic> entities of each class. Accordingly, the IDB contains a single value for each type of information. Thus, we needed to be able to filter the output of EpiTator to a single entity per class that best describes the corresponding event. In the case of the IDB these are <italic>source</italic>, <italic>disease</italic>, <italic>country</italic>, <italic>confirmed-case count</italic>, and the <italic>date</italic> of the number of confirmed cases of an outbreak article.</p>
      <p>Before we could explore methods to find the aforementioned key entities, we applied standard cleaning and preprocessing to the IDB such that it could be fed into machine learning algorithms (see <xref ref-type="supplementary-material" rid="pcbi.1008277.s001">S1 Text</xref>). To find the key entities among those found by EpiTator, we explored two methods, a heuristic and classification-based approach which we refer to as key entity filtering (see Sec. Key entity filtering). If the filtered output of EpiTator for a given article matched the respective key information of the IDB, we then knew that the filter selected the correct key entities.</p>
      <sec id="sec007">
        <title>Key entity filtering</title>
        <p>A naive approach to finding the key entity out of all the entities returned by EpiTator is to pick the most frequent one (the mode). We call this the <italic>most-frequent approach</italic>. To find the key country, we focused only on the first three geographic entities mentioned in the text, since articles tend to contain mentions of other geographic entities different from the key country. To improve performance, we developed a learning-based approach for key date and confirmed-case count. This is shown in the <italic>supervised learning</italic> block in <xref ref-type="fig" rid="pcbi.1008277.g001">Fig 1</xref>.</p>
        <p>For the learning approach, we took the texts of the articles published in 2018 from the two most relevant sources, WHO DONs [<xref rid="pcbi.1008277.ref020" ref-type="bibr">20</xref>] and ProMED [<xref rid="pcbi.1008277.ref021" ref-type="bibr">21</xref>, <xref rid="pcbi.1008277.ref022" ref-type="bibr">22</xref>] (a list of the RKI’s frequently used sources and the reason for selecting those two are described in <xref ref-type="supplementary-material" rid="pcbi.1008277.s001">S1 Text</xref>) and applied a sentence tokenizer using the Python library NLTK [<xref rid="pcbi.1008277.ref023" ref-type="bibr">23</xref>]. Tokenization is the process of splitting text into atomic units, typically sentences, words, or phrases.</p>
        <p>We filtered all sentences to only keep those that contained some entity <italic>e</italic><sub><italic>c</italic>,<italic>j</italic></sub> recognized by EpiTator, with <italic>c</italic> being the class of the entity (date or confirmed-case count) and <italic>j</italic> being the <italic>j</italic><sup><italic>th</italic></sup> entity in a text. If an entity <italic>e</italic><sub><italic>c</italic>,<italic>j</italic></sub> in a sentence matched the entry of class <italic>c</italic> in the IDB, then we labeled this sentence as <italic>key</italic>. Every other sentence was labeled <italic>not key</italic>. The distribution of samples in the datasets obtained is summarized in <xref ref-type="supplementary-material" rid="pcbi.1008277.s004">S1 Fig</xref>.</p>
        <p>Then we trained a Bernoulli naive Bayes classifier (Bernoulli NBC) [<xref rid="pcbi.1008277.ref024" ref-type="bibr">24</xref>] with these labeled sentences to learn the relevant properties of sentences that led to the inclusion of their information into the IDB. Before applying a classifier, a text needs to be represented as a vector of numbers (vectorization). During training, a Bernoulli NBC classifier receives for each input sentence a binary vector <italic>b</italic> of the whole vocabulary (all the words seen during training) where the <italic>i</italic><sup><italic>th</italic></sup> position of the vector indicates the <italic>i</italic><sup><italic>th</italic></sup> term of the vocabulary. If the <italic>i</italic><sup><italic>th</italic></sup> term <italic>t</italic><sub><italic>i</italic></sub> is present in the input sentence, then <italic>b</italic><sub><italic>i</italic></sub> = 1 and 0 otherwise.</p>
        <p>Based on the binary vectors and the corresponding labels, the Bernoulli NBC assigns probabilities to individual sentences of being <italic>key</italic> and <italic>not key</italic>. The key information for class <italic>c</italic> was set to the entity recognized in the sentence that has the highest probability of being <italic>key</italic> and contains a recognized entity of class <italic>c</italic>. This method ensures that some entity is still chosen even if no sentence is being classified as <italic>key</italic>, i.e., if all sentences in a text have less than 50% probability of being <italic>key</italic>.</p>
        <p>Additionally, we applied the multinomial NBC for comparison. The only difference to the Bernoulli NBC is that the multinomial NBC takes an occurrence vector <italic>o</italic>, with <italic>o</italic><sub><italic>i</italic></sub> being the frequency of term <italic>t</italic><sub><italic>i</italic></sub> in the text, as an input instead of a binary vector <italic>b</italic>. This approach is called bag-of-words. We combined bag-of-words with tf-idf (term frequency-inverse document frequency) where each term frequency is scaled so as to correct for overly frequent terms within and across documents. Formally, tf-idf is defined as
<disp-formula id="pcbi.1008277.e001"><alternatives><graphic xlink:href="pcbi.1008277.e001.jpg" id="pcbi.1008277.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>tfidf</mml:mtext><mml:mo>(</mml:mo><mml:mtext>t</mml:mtext><mml:mo>,</mml:mo><mml:mtext>d</mml:mtext><mml:mo>,</mml:mo><mml:mtext>D</mml:mtext><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mtext>max</mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>·</mml:mo><mml:mtext>log</mml:mtext><mml:mfrac><mml:mi>N</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mo>{</mml:mo><mml:mi>d</mml:mi><mml:mo>∈</mml:mo><mml:mi>D</mml:mi><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>d</mml:mi><mml:mo>}</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>t</italic> is a term from the bag-of-words, <italic>d</italic> is a document, <italic>D</italic> is the corpus of all epidemiological articles seen during training (containing <italic>N</italic> documents) and <italic>f</italic><sub><italic>t</italic>,<italic>d</italic></sub> is the frequency of term <italic>t</italic> occurring in document <italic>d</italic>. The Bernoulli NBC might perform better on a small vocabulary, while the multinomial NBC usually performs equally well or even better on a large vocabulary [<xref rid="pcbi.1008277.ref024" ref-type="bibr">24</xref>]. We also applied further standard methods of text preprocessing (see <xref ref-type="supplementary-material" rid="pcbi.1008277.s001">S1 Text</xref>).</p>
      </sec>
    </sec>
    <sec id="sec008">
      <title>Relevance scoring</title>
      <p>The second part of developing a framework to support EBS was to estimate the relevance of epidemiological articles. We framed the relevance evaluation as a classification problem, where articles that were present in the IDB were labeled <italic>relevant</italic>. We had access to all assessments of the IDB of the year 2018 and therefore scraped all WHO DON and ProMED articles of the year 2018. This resulted in a dataset of 3236 articles, 164 of them labeled <italic>relevant</italic> and 3072 <italic>irrelevant</italic>. The exact statistics of the dataset are summarized in <xref ref-type="supplementary-material" rid="pcbi.1008277.s005">S2 Fig</xref>.</p>
      <sec id="sec009">
        <title>Training of the classifiers</title>
        <p>Modern text classifiers tend to use word embeddings [<xref rid="pcbi.1008277.ref025" ref-type="bibr">25</xref>, <xref rid="pcbi.1008277.ref026" ref-type="bibr">26</xref>] for vectorization rather than the tf-idf and bag-of-words approach. Word embeddings are vector representations of words that are learned on large amounts of texts in an unsupervised manner. Proximity in the word embedding space tends to correspond to semantic similarity. This is accomplished by assigning similar embeddings to words appearing in similar contexts. First, we used standard pre-trained embeddings, trained on the Wikipedia 2014 and Gigaword 5th Edition corpora [<xref rid="pcbi.1008277.ref027" ref-type="bibr">27</xref>]. However, many terms specific to epidemiology were not represented. Thus, we produced custom 300-dimensional embeddings, training the word2vec algorithm [<xref rid="pcbi.1008277.ref028" ref-type="bibr">28</xref>] on the Wikipedia corpus of 2020 [<xref rid="pcbi.1008277.ref029" ref-type="bibr">29</xref>] and all available WHO DONs and ProMED Mail articles (61,320 articles). We applied the skip-gram approach and hierarchical softmax [<xref rid="pcbi.1008277.ref028" ref-type="bibr">28</xref>]. Those settings helped incorporating infrequent terms [<xref rid="pcbi.1008277.ref030" ref-type="bibr">30</xref>]. The embeddings were trained for five epochs. See <xref ref-type="supplementary-material" rid="pcbi.1008277.s001">S1 Text</xref> for information on computational resources and elapsed time.</p>
        <p>Since we ultimately wanted to classify whether a whole document was <italic>relevant</italic>, we needed <italic>document</italic> embeddings. Although dedicated algorithms for document embeddings exist [<xref rid="pcbi.1008277.ref031" ref-type="bibr">31</xref>], we had not enough data to apply them meaningfully. However, taking the mean over all word embeddings of a document is a valid alternative [<xref rid="pcbi.1008277.ref032" ref-type="bibr">32</xref>] and suffices to show if learning the relevance of an article is possible.</p>
        <p>A further issue was imbalance. Only a small fraction (5.0%) of the articles in the dataset was labeled <italic>relevant</italic>. Instead of discarding data from the majority class, we chose to up-sample the dataset using the ADASYN algorithm [<xref rid="pcbi.1008277.ref033" ref-type="bibr">33</xref>]. It generates new data points of the minority class by repeating the following steps until the proportion of minority and majority classes reaches the desired proportion (1:1):</p>
        <list list-type="order">
          <list-item>
            <p>choose a random data point <italic>x</italic><sub><italic>i</italic></sub> (the document embedding of article <italic>i</italic>) of the minority class;</p>
          </list-item>
          <list-item>
            <p>randomly choose another minority-class data point <italic>x</italic><sub><italic>zi</italic></sub> among the 5-nearest neighbors of <italic>x</italic><sub><italic>i</italic></sub>;</p>
          </list-item>
          <list-item>
            <p>generate a new data point <italic>y</italic><sub><italic>j</italic></sub> at a random position between <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>zi</italic></sub> such that <italic>y</italic><sub><italic>j</italic></sub> = <italic>ax</italic><sub><italic>i</italic></sub> + (1 − <italic>a</italic>)<italic>x</italic><sub><italic>zi</italic></sub> with <italic>a</italic> drawn uniformly at random between 0 and 1.</p>
          </list-item>
        </list>
        <p>One problem of up-sampling data is that it still uses the minority class to create new examples and this might hinder the generalizability of the classifier [<xref rid="pcbi.1008277.ref034" ref-type="bibr">34</xref>]. We used the imbalanced-learn package [<xref rid="pcbi.1008277.ref035" ref-type="bibr">35</xref>] to implement ADASYN. We compared different classifiers for the relevance scoring task using embeddings or the bag-of-words approach. Support vector machine (SVM), k-nearest-neighbors (kNN), logistic regression (LR) and multilayer perceptron (MLP) used document embeddings as features. The CNN operated on the word embeddings instead of the document embeddings. That way the striding filters of the CNN–if large enough–could learn relationships between adjacent words. We capped the input documents to a maximum of 400 words for the CNN. 597 documents contained less than 400 words which we filled up with zero embeddings such that each document has the same shape. For multinomial and complement NBCs, we used the bag-of-words approach since this feature representation coincides with the assumption of the NBC to predict a class given the occurrence (probability) of a feature. See <xref ref-type="supplementary-material" rid="pcbi.1008277.s002">S1 Table</xref> for a tabular, detailed view of the vectorizations and parameters used.</p>
        <p>Finally, we used layer-wise relevance propagation [<xref rid="pcbi.1008277.ref036" ref-type="bibr">36</xref>] to make decisions of the CNN explainable. This is done by assessing which word embeddings passed through the CNN led to the final classification. We used iNNvestigate to implement this step [<xref rid="pcbi.1008277.ref037" ref-type="bibr">37</xref>].</p>
      </sec>
    </sec>
    <sec id="sec010">
      <title>Evaluation</title>
      <p>The output of the key entity filtering of texts (see Section Key entity filtering) was compared with the IDB entries of the respective texts. If a found key entity matched the IDB entry exactly we counted the filtered output as correctly classified. Less stringently, the extracted date was counted as correctly classified if it was within three days of the IDB entry. This is due to EpiTator’s API which returns date ranges instead of single dates if parsing a text. A range of three days allows us to rightly overlay with EpiTator’s date ranges. The performances of all classifiers are evaluated on a test set which consists of 25% of the whole dataset. We applied stratification to ensure that both classes are evenly distributed on the train and test set. The data for the CNN was split into a training (60%), validation (20%), and testing (20%) set with slightly different class composition due to different sampling strategies (see <xref ref-type="supplementary-material" rid="pcbi.1008277.s001">S1 Text</xref> for details). We consider a number of scores defined as functions of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN): precision = TP/(TP + FP); sensitivity = TP/(TP + FN); specificity = TN/(TN + FP) and F1 = 2 ⋅ TP/(2 ⋅ TP + FP + FN) [<xref rid="pcbi.1008277.ref038" ref-type="bibr">38</xref>]. Since public health agents are interested in not missing any positives by classifying them incorrectly as negatives, we considered the sensitivity as a good indicator for the performance of the classifiers. As a measure for the overall accuracy, we preferred the index-balanced accuracy (IBA) [<xref rid="pcbi.1008277.ref039" ref-type="bibr">39</xref>], which has been developed to gauge classification performance on imbalanced datasets. It is based on sensitivity, i.e., the fraction of correctly classified relevant articles or key entities, and specificity, i.e., the fraction of correctly classified irrelevant articles or non key entities. It is defined as
<disp-formula id="pcbi.1008277.e002"><alternatives><graphic xlink:href="pcbi.1008277.e002.jpg" id="pcbi.1008277.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>I</mml:mi><mml:mi>B</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo>·</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtext>sensitivity</mml:mtext><mml:mo>-</mml:mo><mml:mtext>specificity</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>·</mml:mo><mml:mtext>sensitivity</mml:mtext><mml:mo>·</mml:mo><mml:mtext>specificity</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
where sensitivity − specificity is called the dominance and 0 ≤ <italic>α</italic> ≤ 1 is a weighting factor that can be fine-tuned based on how significant the dominating class is supposed to be. IBA measures the trade-off between global performance and a signed index that accounts for imbalanced predictions. It favors classifiers with better true positive rates, assuming that correct predictions on the positive class are more important than true negative predictions. As in the original publication [<xref rid="pcbi.1008277.ref034" ref-type="bibr">34</xref>], we use <italic>α</italic> = 0.1.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec011">
    <title>Results</title>
    <p>In this section we present the performance of a series of key information extraction and relevance-scoring algorithms, and describe how the findings were embedded into the web application <italic>EventEpi</italic>.</p>
    <sec id="sec012">
      <title>Performance of key date and count extraction</title>
      <p>We identified the most probable true entity among the many proposed by EpiTator using the most-frequent approach and two NBCs. The most frequent approach worked well for detecting the key country (85% correctly classified) and disease (88% correctly classified). Note that EpiTator systematically failed to detect Nipah virus infection and anthrax. However, performing key information extraction of date and case-count entities using the most-frequent approach did not work and no entity was correctly classified (0% correctly classified in both cases).</p>
      <p>The performance of both NBC algorithms applied to extract key date and key confirmed-case count are shown in Tables <xref rid="pcbi.1008277.t001" ref-type="table">1</xref> and <xref rid="pcbi.1008277.t002" ref-type="table">2</xref> respectively. Confusion matrices and ROC curves present the performances in greater detail (see <xref ref-type="supplementary-material" rid="pcbi.1008277.s008">S5</xref> and <xref ref-type="supplementary-material" rid="pcbi.1008277.s010">S7</xref> Figs respectively).</p>
      <table-wrap id="pcbi.1008277.t001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008277.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Evaluation of the key <italic>date</italic> extraction.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008277.t001g" xlink:href="pcbi.1008277.t001"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="right" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">Pre.</th>
                <th align="center" rowspan="1" colspan="1">Sen.</th>
                <th align="center" rowspan="1" colspan="1">Spec.</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">IBA</th>
                <th align="center" rowspan="1" colspan="1"><italic>key</italic> sample size</th>
                <th align="center" rowspan="1" colspan="1"><italic>not key</italic> sample size</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Multinomial naive Bayes</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.55</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.78</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.69</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.65</td>
                <td align="char" char="." rowspan="1" colspan="1">0.54</td>
                <td align="center" rowspan="1" colspan="1">27</td>
                <td align="center" rowspan="1" colspan="1">54</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Bernoulli naive Bayes</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.55</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.81</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.67</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.66</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.55</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">27</td>
                <td align="center" rowspan="1" colspan="1">54</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p>For each classifier and label, the precision (Pre.), sensitivity (Sen.), specificity (Spec.), F1, index balanced accuracy (IBA) with <italic>α</italic> = 0.1, and sample size for both classes, <italic>key</italic> and <italic>not key</italic>, of the test set is given. The best values for each score highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="pcbi.1008277.t002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008277.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Evaluation of the key <italic>confirmed-case count</italic> extraction.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008277.t002g" xlink:href="pcbi.1008277.t002"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="right" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">Pre.</th>
                <th align="center" rowspan="1" colspan="1">Sen.</th>
                <th align="center" rowspan="1" colspan="1">Spec.</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">IBA</th>
                <th align="center" rowspan="1" colspan="1"><italic>key</italic> sample size</th>
                <th align="center" rowspan="1" colspan="1"><italic>not key</italic> sample size</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Multinomial naive Bayes</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.39</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.45</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.93</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.42</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.40</td>
                <td align="center" rowspan="1" colspan="1">89</td>
                <td align="center" rowspan="1" colspan="1">874</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Bernoulli naive Bayes</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.20</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.81</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.67</td>
                <td align="char" char="." rowspan="1" colspan="1">0.32</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.55</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">89</td>
                <td align="center" rowspan="1" colspan="1">874</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>Definitions and parameters are the same as in <xref rid="pcbi.1008277.t001" ref-type="table">Table 1</xref>. The best values for each score highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For both date and count information extraction, the Bernoulli NBC had the highest IBA and sensitivity. Thus, without offering perfect results, applying classification to the output of EpiTator enables key entity extraction for <italic>date</italic> and <italic>confirmed-case count</italic>. We might be able to improve the performance by hyperparameter tuning, or better feature extraction (e.g., looking for key words such as “confirmed”). Increasing the amount of training data however would probably not lead to much improvement (see <xref ref-type="supplementary-material" rid="pcbi.1008277.s006">S3 Fig</xref>).</p>
    </sec>
    <sec id="sec013">
      <title>Performance of relevance scoring</title>
      <p>The results of the relevance scoring are shown in <xref rid="pcbi.1008277.t003" ref-type="table">Table 3</xref>. The confusion matrices for these results are displayed in <xref ref-type="supplementary-material" rid="pcbi.1008277.s009">S6 Fig</xref> and the respective ROC curves in <xref ref-type="supplementary-material" rid="pcbi.1008277.s011">S8 Fig</xref>. A comparison on classifier trained on non up-sampled data showed no better performance than sensitivity of 0.03 and IBA of 0.02 (see <xref ref-type="supplementary-material" rid="pcbi.1008277.s003">S2 Table</xref>). While the logistic regression has the highest sensitivity (0.82) and IBA (0.61), no model has a higher precision than 0.22 which suggests that all classifier overfit the positive class.</p>
      <table-wrap id="pcbi.1008277.t003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008277.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>The performance evaluation of the relevance classification.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi.1008277.t003g" xlink:href="pcbi.1008277.t003"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="right" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">Pre.</th>
                <th align="center" rowspan="1" colspan="1">Sen.</th>
                <th align="center" rowspan="1" colspan="1">Spec.</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">IBA</th>
                <th align="center" rowspan="1" colspan="1"><italic>relevant</italic> sample size</th>
                <th align="center" rowspan="1" colspan="1"><italic>irrelevant</italic> sample size</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Multinomial naive Bayes</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.22</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.42</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.93</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.29</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.37</td>
                <td align="center" rowspan="1" colspan="1">38</td>
                <td align="center" rowspan="1" colspan="1">771</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Complement naive Bayes</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.19</td>
                <td align="char" char="." rowspan="1" colspan="1">0.61</td>
                <td align="char" char="." rowspan="1" colspan="1">0.87</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.29</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.51</td>
                <td align="center" rowspan="1" colspan="1">38</td>
                <td align="center" rowspan="1" colspan="1">771</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Logistic regression</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.14</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.82</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.75</td>
                <td align="char" char="." rowspan="1" colspan="1">0.24</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.61</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">38</td>
                <td align="center" rowspan="1" colspan="1">771</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>k-nearest neighbor classifier</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.12</td>
                <td align="char" char="." rowspan="1" colspan="1">0.63</td>
                <td align="char" char="." rowspan="1" colspan="1">0.77</td>
                <td align="char" char="." rowspan="1" colspan="1">0.20</td>
                <td align="char" char="." rowspan="1" colspan="1">0.48</td>
                <td align="center" rowspan="1" colspan="1">38</td>
                <td align="center" rowspan="1" colspan="1">771</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Support vector machine</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.13</td>
                <td align="char" char="." rowspan="1" colspan="1">0.79</td>
                <td align="char" char="." rowspan="1" colspan="1">0.74</td>
                <td align="char" char="." rowspan="1" colspan="1">0.22</td>
                <td align="char" char="." rowspan="1" colspan="1">0.59</td>
                <td align="center" rowspan="1" colspan="1">38</td>
                <td align="center" rowspan="1" colspan="1">771</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Multilayer perceptron</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.22</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.42</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.93</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>0.29</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.37</td>
                <td align="center" rowspan="1" colspan="1">38</td>
                <td align="center" rowspan="1" colspan="1">771</td>
              </tr>
              <tr>
                <td align="right" rowspan="1" colspan="1">
                  <bold>Convolutional neural network</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.14</td>
                <td align="char" char="." rowspan="1" colspan="1">0.55</td>
                <td align="char" char="." rowspan="1" colspan="1">0.78</td>
                <td align="char" char="." rowspan="1" colspan="1">0.23</td>
                <td align="char" char="." rowspan="1" colspan="1">0.42</td>
                <td align="center" rowspan="1" colspan="1">42</td>
                <td align="center" rowspan="1" colspan="1">606</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t003fn001">
            <p>For each classifier and label, the precision (Pre.), sensitivity (Sen.), specificity (Spec.), F1, index balanced accuracy (IBA) with <italic>α</italic> = 0.1, and sample size of both classes, <italic>relevant</italic> and <italic>irrelevant</italic> articles, of the test set is given. The best values for each score are highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The multinomial NBCs had a better performance (sensitivity and IBA) than the complement NBC, possibly because of the dataset imbalance [<xref rid="pcbi.1008277.ref040" ref-type="bibr">40</xref>]. Although the scores are relatively high in general, all classifier overfit the positive class. Overfitting usually can be avoided for some models. E.g, for the CNN, we can apply further dropout (random removal of nodes in the network during training time to minimize highly specified nodes), regularization (e.g., L2 to punish strong weighting of nodes), and early stopping (to minimize the difference of losses between the test and validation set). Most models can incorporate a class weight variable adjusted to control overfitting. Also, we did not optimize the decision boundary of the tested classifiers which, however, might improve the balance between both classes. All these points which fall in the task of hyperparameter optimization can be tackled in a separate step.</p>
      <p>It is nevertheless interesting to use the CNN as an example for explaining what contributed to the classification. A plot of a layer-wise relevance propagation shows one example where a relevant article was correctly classified (<xref ref-type="fig" rid="pcbi.1008277.g002">Fig 2</xref>). We see that words like <italic>500</italic> in the beginning of the text are highlighted as strongly important for the classification of the text as being <italic>relevant</italic>. Also, the word <italic>schistosomiasis</italic>–an infectious disease caused by flatworms–is labeled as strongly relevant for the classification. Interestingly, it is also relevant for the classifier that this disease is treated with antiparasitic drugs (<italic>anthelmintic</italic>). Both make sense, since a very high number of cases of a dangerous infectious disease are of interest for public health agents. All other case numbers are labeled as slightly irrelevant which does not necessarily make sense. An event might be less relevant when out of 500 confirmed cases of some infectious disease half of the patients are in treatment.</p>
      <fig id="pcbi.1008277.g002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008277.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>A layer-wise relevance propagation of the CNN for relevance classification.</title>
          <p>This text was correctly classified as relevant. Words that are highlighted in red contributed to the classification of the article being <italic>relevant</italic> and blue words contradicted this classification. The saturation of the color indicates the strength of which the single words contributed to the classification. <monospace>&lt;UNK&gt;</monospace> indicates a token for which no word embedding is available.</p>
        </caption>
        <graphic xlink:href="pcbi.1008277.g002"/>
      </fig>
      <p>The focus of this work was to show a proof of concept that classification methods can serve in determining the relevance of an article. We did not try to fine-tune all of the compared classifiers. Since training of the algorithms was only a matter of minutes, it might be cheap to perform hyperparameter optimization. Computational time and resources to train all models are described in <xref ref-type="supplementary-material" rid="pcbi.1008277.s001">S1 Text</xref>. For now, logistic regression (LR), although having a low precision, is preferred due to its good sensitivity and IBA. Although the relevance classification has not a very strong performance, it could already aid public health agents. The algorithms could be retrained every time articles are entered into the IDB to increase performance continuously. Indeed, testing the classifiers on fractions of the data shows a positive trend of performance (IBA) with increasing data size (see <xref ref-type="supplementary-material" rid="pcbi.1008277.s007">S4 Fig</xref>). Until very high performance can be achieved, relevance scores could be displayed and used to sort articles, but not to filter content.</p>
    </sec>
    <sec id="sec014">
      <title>Web service</title>
      <p>To showcase the analyses presented above and show how key information and relevance scoring can be used simultaneously to aid EBS, we developed the web application <italic>EventEpi</italic>. <xref ref-type="fig" rid="pcbi.1008277.g003">Fig 3</xref> shows a screenshot of its user interface. <italic>EventEpi</italic> is a Flask [<xref rid="pcbi.1008277.ref041" ref-type="bibr">41</xref>] app that uses DataTables [<xref rid="pcbi.1008277.ref042" ref-type="bibr">42</xref>] as an interface to its database. <italic>EventEpi</italic> lets users paste URLs and automatically analyze texts from sources they trust or are interested in. The last step in <xref ref-type="fig" rid="pcbi.1008277.g001">Fig 1</xref> shows how the <italic>EventEpi</italic> database is filled with the output of the key information extraction and relevance scoring algorithms. With our colleagues at INIG in mind, we integrated a mechanism that would automatically download and analyze the newest unseen articles from WHO DONs and ProMED. Currently, this process is slow and depends on pre-analyses for a good user experience. To allow for the integration of the functionality into another application, we also wrote an ASP.NET Core application to analyze texts via API calls.</p>
      <fig id="pcbi.1008277.g003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1008277.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>A screenshot of the <italic>EventEpi</italic> web application.</title>
          <p>The top input text field receives an URL. This URL is summarized if the <monospace>SUMMARIZE</monospace> button is pushed. The result of this summary is entered into the datatable, which is displayed as a table. The buttons <monospace>Get WHO DONs</monospace> and <monospace>Get Promed Articles</monospace> automatically scrape the last articles form both platforms that are not yet in the datatable. Furthermore, the user can search for words in the search text field and download the datatable as CSV, Excel or PDF.</p>
        </caption>
        <graphic xlink:href="pcbi.1008277.g003"/>
      </fig>
    </sec>
    <sec id="sec015">
      <title>Conclusion</title>
      <p>We have shown that novel natural language processing methodology can be applied in combination with available resources, in this case the IDB of the RKI, to improve public health surveillance. Even with limited datasets, EBS can be supported by automatic processes, such as pre-screening large amounts of news articles to forward a condensed batch of articles for manual review.</p>
      <p>More work is needed to bring <italic>EventEpi</italic> into production. While key disease and country can satisfactorily be extracted, the performance of key date and confirmed-case count extractions needs to be improved.</p>
      <p>Relevance scoring shows promising results. We believe it could already be helpful to public health agents, and could greatly be improved with fine-tuning and larger datasets.</p>
      <p>The web application <italic>EventEpi</italic> is a scalable tool. Thus, the scope of EBS might be increased without comparable increase in effort. This is particularly relevant with the availability of automatic translation (for example DeepL [<xref rid="pcbi.1008277.ref043" ref-type="bibr">43</xref>]). It could allow an EBS team to access much more sources than those in the few languages its members typically speak without being overwhelmed. It is possible to provide better classifications that work for different languages using multilingual word embeddings [<xref rid="pcbi.1008277.ref044" ref-type="bibr">44</xref>], or a better key information extraction using contextual embeddings [<xref rid="pcbi.1008277.ref045" ref-type="bibr">45</xref>, <xref rid="pcbi.1008277.ref046" ref-type="bibr">46</xref>] which adjust the embedding based on the textual context. Contrary to the relevance of a document, key information is mostly defined by its nearby words.</p>
      <p>The same fundamental issues encountered in using machine learning in general apply here as well, in particular bias and explainability. Tackling individual biases and personal preferences during labeling by experts is essential to continue this project and make it safe to use. It will also be important to show <italic>why EventEpi</italic> extracted certain information or computed a relevance for it to be adopted but also critically assessed by public health agents. For artificial neural networks, we showed that layer-wise relevance propagation can be used in the domain of epidemiological texts to make a classifier explainable. For other models, model agnostic methods [<xref rid="pcbi.1008277.ref047" ref-type="bibr">47</xref>, <xref rid="pcbi.1008277.ref048" ref-type="bibr">48</xref>] could be applied analogously.</p>
      <p>At the moment <italic>EventEpi</italic> only presents results to the user. However it could be expanded to be a general interface to an event database and allow public health agents to note which articles were indeed relevant as well as correct key information. This process would allow more people to label articles and thus expand the datasets, as well as help better train the relevance-scoring algorithms, an approach called active-learning [<xref rid="pcbi.1008277.ref049" ref-type="bibr">49</xref>].</p>
      <p>With a large labeled dataset, a neural network could be (re)trained for the relevance classification. Later, transfer learning (tuning of the last layer of the network) could be used to adapt the relevance classification to single user preferences.</p>
      <p>This work demonstrates how machine learning methods can be applied meaningfully in public health using data readily available: As experts evaluate and document events as part of their daily work, valuable labeled datasets are routinely produced. If systematically gathered and cataloged, these offer immense potential for the development of artificial intelligence in public health.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="sec016">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s001">
      <label>S1 Text</label>
      <caption>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s002">
      <label>S1 Table</label>
      <caption>
        <title>Hyperparameter settings of the classifaction algorithms.</title>
        <p>This tables lists the parameters and the vectorization methods stratified for the task and used models (naive Bayes classifier (NBC), support vector machine (SVM), k-nearest neighbors (kNN), logistic regression (LR), multi layer perceptron (MLP), and convolutional neural network (CNN)). More information on the used parameters can be found at <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org">https://scikit-learn.org</ext-link>.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s003">
      <label>S2 Table</label>
      <caption>
        <title>Performance evaluation of the relevance classification without up-sampling using ADASYN.</title>
        <p>For each classifier and label, the precision (Pre.), sensitivity (Sen.), specificity (Spec.), F1, index balanced accuracy (IBA) with <italic>α</italic> = 0.1, and sample size for both classes, <italic>relevant</italic> and <italic>irrelevant</italic> articles, of the test set is given. The best values for each score are highlighted in bold.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s004">
      <label>S1 Fig</label>
      <caption>
        <title>Sample distribution for key information extraction.</title>
        <p>The number of articles used for each class (positive/negative, i.e. key/not key) for the partions of the dataset (train, test) are shown for each task.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s005">
      <label>S2 Fig</label>
      <caption>
        <title>Sample distribution for relevance scoring.</title>
        <p>The number of articles used for each class (positive/negative, i.e. relevant/irrelevant) for the partions of the dataset (train, test, and for CNN validation) are shown for each task.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s006">
      <label>S3 Fig</label>
      <caption>
        <title>Learning curves for key count and date entity extraction.</title>
        <p>Dependency of <italic>key</italic> (date and count) classifcation performance on training data size as measured using 5-fold cross validation for the multinomial and Bernoulli naive Bayes classifiers. The performance is measured by the IBA score. The points show mean scores, the shaded regions show the mean plus and minus one standard deviation on the cross validation folds.</p>
        <p>(PNG)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s006.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s007">
      <label>S4 Fig</label>
      <caption>
        <title>Learning curves for relevance scoring.</title>
        <p>Dependency of <italic>relevance</italic> classifcation performance on training data size as measured using 5-fold cross validation for different classifiers. The performance is measured by the IBA score. The points show mean scores, the shaded regions show the mean plus and minus one standard deviation on the cross validation folds.</p>
        <p>(PNG)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s007.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s008">
      <label>S5 Fig</label>
      <caption>
        <title>Confusion matrices of the key count and date entity extraction.</title>
        <p>The plot shows the true and predicted labels of the test test in the key entitiy extraction task. The plots are stratified by algorithm (multinomial and Bernoulli naive Bayes classifier (NBC)) and task (key count and date extraction). Furthermore, the proportion of missclassified is shown below.</p>
        <p>(PNG)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s008.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s009">
      <label>S6 Fig</label>
      <caption>
        <title>Confusion matrices of the relevance scoring.</title>
        <p>The plot shows the true and predicted labels of the relevance scoring task. The plots are stratified by algorithm. Furthermore, the proportion of missclassified is shown below.</p>
        <p>(PNG)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s009.png">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s010">
      <label>S7 Fig</label>
      <caption>
        <title>Receiver operating characteristics of the key count and date entity extraction.</title>
        <p>The plot shows the true positive rate against the false positive rate stratified by algorithm (multinomial and Bernoulli naive Bayes classifier (NBC)) and task (key count and date extraction) and the area under the curve (AUC). The black, dotted middle shows the expected curve for random classifcation.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s010.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s011">
      <label>S8 Fig</label>
      <caption>
        <title>Receiver operating characteristics of the relevance scoring.</title>
        <p>The plot shows the true positive rate against the false positive rate stratified by algorithm (complement naive Bayes classifier (compl. NBC), k-nearest neighbors (kNN), logistic regression (LR), multi layer perceptron (MLP), multi. NBC (multinomial naive Bayes classifier), support vecotor machine (SVM), and convolution neural network (CNN)) and the area under the curve (AUC). The black, dotted middle line shows the expected curve for random classifcation.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1008277.s011.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to thank Maria an der Heiden, Sandra Beermann, Sarah Esquevin, Raskit Lachmann and Nadine Zeitlmann for helping us on questions regarding epidemic intelligence, for providing us with data and for critical comments on the manuscript. We also thank Katarina Birghan for helping us using Wikidata and Fabian Eckelmann for his support in developing the <italic>EventEpi</italic> web application.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1008277.ref001">
      <label>1</label>
      <mixed-citation publication-type="other">WHO. Epidemiology; 2014. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/topics/epidemiology/en/">https://www.who.int/topics/epidemiology/en/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref002">
      <label>2</label>
      <mixed-citation publication-type="other">WHO. Early detection, assessment and response to acute public health events. WHO. 2014.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Stephen</surname><given-names>DM</given-names></name>, <name><surname>Barnett</surname><given-names>AG</given-names></name>. <article-title>Effect of temperature and precipitation on salmonellosis cases in South-East Queensland, Australia: an observational study</article-title>. <source>BMJ Open</source>. <year>2016</year>;<volume>6</volume>(<issue>2</issue>). <pub-id pub-id-type="doi">10.1136/bmjopen-2015-010204</pub-id><?supplied-pmid 26916693?><pub-id pub-id-type="pmid">26916693</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Taylor</surname><given-names>DL</given-names></name>, <name><surname>Kahawita</surname><given-names>TM</given-names></name>, <name><surname>Cairncross</surname><given-names>S</given-names></name>, <name><surname>Ensink</surname><given-names>JHJ</given-names></name>. <article-title>The Impact of Water, Sanitation and Hygiene Interventions to Control Cholera: A Systematic Review</article-title>. <source>PLOS ONE</source>. <year>2015</year>;<volume>10</volume>(<issue>8</issue>):<fpage>e0135676</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0135676</pub-id><?supplied-pmid 26284367?><pub-id pub-id-type="pmid">26284367</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Kaiser</surname><given-names>R</given-names></name>, <name><surname>Coulombier</surname><given-names>D</given-names></name>, <name><surname>Baldari</surname><given-names>M</given-names></name>, <name><surname>Morgan</surname><given-names>D</given-names></name>, <name><surname>Paquet</surname><given-names>C</given-names></name>. <article-title>What is epidemic intelligence, and how is it being improved in Europe?</article-title><source>Euro Surveillance</source>. <year>2006</year>;<volume>11</volume>(<issue>5</issue>). <pub-id pub-id-type="doi">10.2807/esw.11.05.02892-en</pub-id>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">WHO. Epidemic intelligence—systematic event detection; 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/csr/alertresponse/epidemicintelligence/en/">https://www.who.int/csr/alertresponse/epidemicintelligence/en/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Linge</surname><given-names>JP</given-names></name>, <name><surname>Steinberger</surname><given-names>R</given-names></name>, <name><surname>Weber</surname><given-names>TP</given-names></name>, <name><surname>Yangarber</surname><given-names>R</given-names></name>, <name><surname>van der Goot</surname><given-names>E</given-names></name>, <name><surname>Khudhairy</surname><given-names>DHA</given-names></name>, <etal>et al</etal><article-title>Internet surveillance systems for early alerting of health threats</article-title>. <source>Eurosurveillance</source>. <year>2009</year>;<volume>14</volume>(<issue>13</issue>):<fpage>19162</fpage><?supplied-pmid 19341610?><pub-id pub-id-type="pmid">19341610</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref008">
      <label>8</label>
      <mixed-citation publication-type="other">Source code for EventEpi;. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/aauss/EventEpi">https://github.com/aauss/EventEpi</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref009">
      <label>9</label>
      <mixed-citation publication-type="other">Incidence database (IDB);. Available from: <pub-id pub-id-type="doi">10.6084/m9.figshare.12575978</pub-id>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">EventEpi word embeddings;. Available from: <pub-id pub-id-type="doi">10.6084/m9.figshare.12575966</pub-id>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref011">
      <label>11</label>
      <mixed-citation publication-type="other">Global Rapid Identification Tool System (GRITS);. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/ecohealthalliance/diagnostic-dashboard">https://github.com/ecohealthalliance/diagnostic-dashboard</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref012">
      <label>12</label>
      <mixed-citation publication-type="other">EpiTator;. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/ecohealthalliance/EpiTator">https://github.com/ecohealthalliance/EpiTator</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref013">
      <label>13</label>
      <mixed-citation publication-type="other">MediSys;. Available from: <ext-link ext-link-type="uri" xlink:href="http://medisys.newsbrief.eu/medisys/helsinkiedition/en/home.html">http://medisys.newsbrief.eu/medisys/helsinkiedition/en/home.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref014">
      <label>14</label>
      <mixed-citation publication-type="other">Disease incidents—MEDISYS;. Available from: <ext-link ext-link-type="uri" xlink:href="http://medisys.newsbrief.eu/medisys/helsinkiedition/en/home.html">http://medisys.newsbrief.eu/medisys/helsinkiedition/en/home.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref015">
      <label>15</label>
      <mixed-citation publication-type="other">PULS Project: Surveillance of Global News Media;. Available from: <ext-link ext-link-type="uri" xlink:href="http://puls.cs.helsinki.fi/static/index.html">http://puls.cs.helsinki.fi/static/index.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref016">
      <label>16</label>
      <mixed-citation publication-type="other">PULS;. Available from: <ext-link ext-link-type="uri" xlink:href="http://puls.cs.helsinki.fi/static/index.html">http://puls.cs.helsinki.fi/static/index.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref017">
      <label>17</label>
      <mixed-citation publication-type="other">Chollet F, Others. Keras; 2015. \url{<ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link>}.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal><article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>(<issue>Oct</issue>):<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref019">
      <label>19</label>
      <mixed-citation publication-type="other">spaCy · Industrial-strength Natural Language Processing in Python;. Available from: <ext-link ext-link-type="uri" xlink:href="https://spacy.io/">https://spacy.io/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref020">
      <label>20</label>
      <mixed-citation publication-type="other">WHO—Disease Outbreak News (DONs);. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/csr/don/en/">https://www.who.int/csr/don/en/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Carrion</surname><given-names>M</given-names></name>, <name><surname>Madoff</surname><given-names>LC</given-names></name>. <article-title>ProMED-mail: 22 years of digital surveillance of emerging infectious diseases</article-title>. <source>International health</source>. <year>2017</year>;<volume>9</volume>(<issue>3</issue>):<fpage>177</fpage>–<lpage>183</lpage>. <pub-id pub-id-type="doi">10.1093/inthealth/ihx014</pub-id><?supplied-pmid 28582558?><pub-id pub-id-type="pmid">28582558</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref022">
      <label>22</label>
      <mixed-citation publication-type="other">ProMED-mail;. Available from: <ext-link ext-link-type="uri" xlink:href="https://promedmail.org/">https://promedmail.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref023">
      <label>23</label>
      <mixed-citation publication-type="book"><name><surname>Bird</surname><given-names>S</given-names></name>, <name><surname>Klein</surname><given-names>E</given-names></name>, <name><surname>Loper</surname><given-names>E</given-names></name>. <source>Natural Language Processing with Python</source>. <edition>1st ed</edition><publisher-name>O’Reilly Media, Inc.</publisher-name>; <year>2009</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>McCallum</surname><given-names>A</given-names></name>, <name><surname>Nigam</surname><given-names>K</given-names></name>. <article-title>A Comparison of Event Models for Naive Bayes Text Classification</article-title>. <source>AAAI-98 workshop on learning for text categorization</source>. <year>1998</year>;<volume>752</volume>(<issue>1</issue>):<fpage>41</fpage>–<lpage>48</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">Johnson R, Zhang T. Supervised and semi-supervised text categorization using LSTM for region embeddings. In: Proceedings of the 33rd International Conference on International Conference on Machine Learning—Volume 48. New York, USA: JMLR.org; 2016. p. 526–534. Available from: <ext-link ext-link-type="uri" xlink:href="https://dl.acm.org/citation.cfm?id=3045447">https://dl.acm.org/citation.cfm?id=3045447</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref026">
      <label>26</label>
      <mixed-citation publication-type="other">Conneau A, Schwenk H, Barrault L, Lecun Y. Very Deep Convolutional Networks for Text Classification. In: Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers. Valencia, Spain: Association for Computational Linguistics; 2017. p. 1107–1116. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/papers/E/E17/E17-1104/">https://www.aclweb.org/anthology/papers/E/E17/E17-1104/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">GloVe: Global Vectors for Wor Representation—Kaggle;. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/rtatman/glove-global-vectors-for-word-representation">https://www.kaggle.com/rtatman/glove-global-vectors-for-word-representation</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref028">
      <label>28</label>
      <mixed-citation publication-type="other">Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J. Distributed Representations of Words and Phrases and their Compositionality. In: Burges CJC, Bottou L, Welling M, Ghahramani Z, Weinberger KQ, editors. Advances in Neural Information Processing Systems 26. Curran Associates, Inc.; 2013. p. 3111–3119. Available from: <ext-link ext-link-type="uri" xlink:href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref029">
      <label>29</label>
      <mixed-citation publication-type="other">Wikimedia Downloads;. Available from: <ext-link ext-link-type="uri" xlink:href="https://dumps.wikimedia.org/">https://dumps.wikimedia.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref030">
      <label>30</label>
      <mixed-citation publication-type="other">Code Google. Google Code Archive—Long-term storage for Google Code Project Hosting.; 2013. Available from: <ext-link ext-link-type="uri" xlink:href="https://code.google.com/archive/p/word2vec/">https://code.google.com/archive/p/word2vec/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref031">
      <label>31</label>
      <mixed-citation publication-type="other">Lau JH, Baldwin T. An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation. In: Proceedings of the 1st Workshop on Representation Learning for NLP. Berlin, Germany: Association for Computational Linguistics; 2016. p. 78–86. Available from: <ext-link ext-link-type="uri" xlink:href="http://aclweb.org/anthology/W16-1609">http://aclweb.org/anthology/W16-1609</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>De Boom</surname><given-names>C</given-names></name>, <name><surname>Van Canneyt</surname><given-names>S</given-names></name>, <name><surname>Demeester</surname><given-names>T</given-names></name>, <name><surname>Dhoedt</surname><given-names>B</given-names></name>. <article-title>Representation learning for very short texts using weighted word embedding aggregation</article-title>. <source>Pattern Recognition Letters</source>. <year>2016</year>;<volume>80</volume>(<issue>C</issue>):<fpage>150</fpage>–<lpage>156</lpage>. <pub-id pub-id-type="doi">10.1016/j.patrec.2016.06.012</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref033">
      <label>33</label>
      <mixed-citation publication-type="other">He H, Bai Y, Edwardo A G, Li S. ADASYN: Adaptive synthetic sampling approach for imbalanced learning. In: 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence). IEEE; 2008. p. 1322–1328. Available from: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/4633969/">http://ieeexplore.ieee.org/document/4633969/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>López</surname><given-names>V</given-names></name>, <name><surname>Fernández</surname><given-names>A</given-names></name>, <name><surname>García</surname><given-names>S</given-names></name>, <name><surname>Palade</surname><given-names>V</given-names></name>, <name><surname>Herrera</surname><given-names>F</given-names></name>. <article-title>An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics</article-title>. <source>Information Sciences</source>. <year>2013</year>;<volume>250</volume>:<fpage>113</fpage>–<lpage>141</lpage>. <pub-id pub-id-type="doi">10.1016/j.ins.2013.07.007</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Lemaitre</surname><given-names>G</given-names></name>, <name><surname>Nogueira</surname><given-names>F</given-names></name>, <name><surname>Aridas</surname><given-names>CK</given-names></name>. <article-title>Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning</article-title>. <source>Journal of Machine Learning Research</source>. <year>2017</year>;<volume>18</volume>(<issue>17</issue>):<fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Arras</surname><given-names>L</given-names></name>, <name><surname>Horn</surname><given-names>F</given-names></name>, <name><surname>Montavon</surname><given-names>G</given-names></name>, <name><surname>Müller</surname><given-names>KR</given-names></name>, <name><surname>Samek</surname><given-names>W</given-names></name>. <article-title>“What is relevant in a text document?”: An interpretable machine learning approach</article-title>. <source>PLOS ONE</source>. <year>2017</year>;<volume>12</volume>(<issue>8</issue>):<fpage>1</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0181142</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Alber</surname><given-names>M</given-names></name>, <name><surname>Lapuschkin</surname><given-names>S</given-names></name>, <name><surname>Seegerer</surname><given-names>P</given-names></name>, <name><surname>Hägele</surname><given-names>M</given-names></name>, <name><surname>Schütt</surname><given-names>KT</given-names></name>, <name><surname>Montavon</surname><given-names>G</given-names></name>, <etal>et al</etal><article-title>iNNvestigate Neural Networks!</article-title><source>Journal of Machine Learning Research</source>. <year>2019</year>;<volume>20</volume>(<issue>93</issue>):<fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">Chinchor N. MUC-4 Evaluation Metrics. In: Proceedings of the 4th Conference on Message Understanding. MUC4’92. USA: Association for Computational Linguistics; 1992. p. 22–29. Available from: <pub-id pub-id-type="doi">10.3115/1072064.1072067</pub-id>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref039">
      <label>39</label>
      <mixed-citation publication-type="other">García V, A Mollineda R, Sánchez J. Index of Balanced Accuracy: A Performance Measure for Skewed Class Distributions. In: 4th Iberian Conference. vol. 5524; 2009. p. 441–448.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref040">
      <label>40</label>
      <mixed-citation publication-type="other">Rennie JDM, Shih L, Teevan J, Karger DR. Tackling the Poor Assumptions of Naive Bayes Text Classifiers. In: In Proceedings of the Twentieth International Conference on Machine Learning. Washington, DC, USA: AAAI Press; 2003. p. 616–623. Available from: <ext-link ext-link-type="uri" xlink:href="http://citeseerx.ist.psu.edu/viewdoc/citations?doi=10.1.1.13.8572">http://citeseerx.ist.psu.edu/viewdoc/citations?doi=10.1.1.13.8572</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref041">
      <label>41</label>
      <mixed-citation publication-type="other">Flask;. Available from: <ext-link ext-link-type="uri" xlink:href="http://flask.pocoo.org/">http://flask.pocoo.org/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref042">
      <label>42</label>
      <mixed-citation publication-type="other">DataTables;. Available from: <ext-link ext-link-type="uri" xlink:href="https://datatables.net/">https://datatables.net/</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref043">
      <label>43</label>
      <mixed-citation publication-type="other">DeepL Translator;. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.deepl.com/translator">https://www.deepl.com/translator</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref044">
      <label>44</label>
      <mixed-citation publication-type="other">Chen X, Cardie C. Unsupervised Multilingual Word Embeddings. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics; 2018. p. 261–270. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/D18-1024">https://www.aclweb.org/anthology/D18-1024</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref045">
      <label>45</label>
      <mixed-citation publication-type="other">Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In: Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics; 2019. p. 4171–4186. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/N19-1423">https://www.aclweb.org/anthology/N19-1423</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref046">
      <label>46</label>
      <mixed-citation publication-type="other">Peters ME, Neumann M, Iyyer M, Gardner M, Clark C, Lee K, et al. Deep contextualized word representations. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). New Orleans, Louisiana: Association for Computational Linguistics; 2018. p. 2227–2237. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/N18-1202">https://www.aclweb.org/anthology/N18-1202</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref047">
      <label>47</label>
      <mixed-citation publication-type="other">Ribeiro MT, Singh S, Guestrin C. “Why Should {I} Trust You?”: Explaining the Predictions of Any Classifier. In: Proceedings of the 22nd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016; 2016. p. 1135–1144.</mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Štrumbelj</surname><given-names>E</given-names></name>, <name><surname>Kononenko</surname><given-names>I</given-names></name>. <article-title>Explaining prediction models and individual predictions with feature contributions</article-title>. <source>Knowledge and Information Systems</source>. <year>2014</year>;<volume>41</volume>(<issue>3</issue>):<fpage>647</fpage>–<lpage>665</lpage>. <pub-id pub-id-type="doi">10.1007/s10115-013-0679-x</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1008277.ref049">
      <label>49</label>
      <mixed-citation publication-type="other">Kakas AC, Cohn D, Dasgupta S, Barto AG, Carpenter GA, Grossberg S, et al. Active Learning. In: Encyclopedia of Machine Learning. Boston, MA: Springer US; 2011. p. 10–14. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.springerlink.com/index/10.1007/978-0-387-30164-8{_}6">http://www.springerlink.com/index/10.1007/978-0-387-30164-8{_}6</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="pcbi.1008277.r001" article-type="aggregated-review-documents">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008277.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Pitzer</surname>
          <given-names>Virginia E.</given-names>
        </name>
        <role>Deputy Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Althouse</surname>
          <given-names>Benjamin Muir</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2020 Pitzer, Althouse</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Pitzer, Althouse</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj001" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008277" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">29 Apr 2020</named-content>
    </p>
    <p>Dear Mr. Abbood,</p>
    <p>Thank you very much for submitting your manuscript "EventEpi–A Natural Language Processing Framework for Event-Based Surveillance" for consideration at PLOS Computational Biology.</p>
    <p>As with all papers reviewed by the journal, your manuscript was reviewed by members of the editorial board and by several independent reviewers. In light of the reviews (below this email), we would like to invite the resubmission of a significantly-revised version that takes into account the reviewers' comments.</p>
    <p>We cannot make any decision about publication until we have seen the revised manuscript and your response to the reviewers' comments. Your revised manuscript is also likely to be sent to reviewers for further evaluation.</p>
    <p>When you are ready to resubmit, please upload the following:</p>
    <p>[1] A letter containing a detailed list of your responses to the review comments and a description of the changes you have made in the manuscript. Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out.</p>
    <p>[2] Two versions of the revised manuscript: one with either highlights or tracked changes denoting where the text has been changed; the other a clean version (uploaded as the manuscript file).</p>
    <p>Important additional instructions are given below your reviewer comments.</p>
    <p>Please prepare and submit your revised manuscript within 60 days. If you anticipate any delay, please let us know the expected resubmission date by replying to this email. Please note that revised manuscripts received after the 60-day due date may require evaluation and peer review similar to newly submitted manuscripts.</p>
    <p>Thank you again for your submission. We hope that our editorial process has been constructive so far, and we welcome your feedback at any time. Please don't hesitate to contact us if you have any questions or comments.</p>
    <p>Sincerely,</p>
    <p>Benjamin Althouse</p>
    <p>Associate Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Virginia Pitzer</p>
    <p>Deputy Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: See attached.</p>
    <p>Reviewer #2: Dear Authors,</p>
    <p>Congratulations for your hard work.</p>
    <p>It is well written. Additional information should be provided to help public health experts not familiar with natural processing language algorithms be able to judge the presented results.</p>
    <p>From a public health point of view I have the following comments, questions and proposed modifications to the text:</p>
    <p>General:</p>
    <p>• Please use “Public health surveillance” instead of “Infectious disease epidemiology” or “epidemiological surveillance” in the context of this paper.</p>
    <p>• Avoid the use of NLP acronym, consider using the full term “natural language processing” across the text?</p>
    <p>• Please define each acronym at least once (for example TPR: true predictive ratio).</p>
    <p>• Specify what you mean by “disease”. Is this limited to laboratory specific diseases such as measles, cholera or yellow fever; or it also includes syndromes such as cutaneous rash, watery diarrhoea, jaundice? This is especially important for EBS, as its purpose is mainly to detect unknown or unexpected diseases that cannot be well captured by the routine data reporting performed by healthcare facilities.</p>
    <p>Author summary:</p>
    <p>• What did this research do and find: 4th point (last): misleading sentence, as mentioned in the results only countries and diseases were correctly detected, not dates or counts.</p>
    <p>Introduction</p>
    <p>• Line 3 – 4: One of the most important goals of "Public health surveillance" is the "timely" detection and response to an acute public health event; the other being to monitor the health status of the population to drive health policy. In this paper, early detection and response is the topic of interest, yet public health surveillance cannot be reduced to that.</p>
    <p>• Lines 14-15: “traditional surveillance” relies on “routine reporting from healthcare facilities” and not from “laboratory confirmation” (most cases are not laboratory confirmed in many settings and for many diseases).</p>
    <p>• Lines 20-22: add “routine” in the sentence: “It enables public health agents […] recognition of human cases in the **routine** reporting system”.</p>
    <p>• Line 29: why the use of the word “precision” instead of “specificity”?</p>
    <p>• Lines 45-46: why only “confirmed-case count”? And not counts of suspect cases, for example?</p>
    <p>Figure 1</p>
    <p>• Don't use the light "pink-orange" background for boxes as it is confusing with the orange part of the figure describing the relevance scoring.</p>
    <p>• Define briefly "word2vec", "EpiTator", "SVM", "kNN", "LR" either in the figure or in its description.</p>
    <p>• To facilitate understanding, maybe consider splitting the "supervised learning" row in two: the classification phase (relevance scoring), and the identification of the appropriate data (key information extraction). And use the terms "relevance scoring" and "key information extraction" in the figure.</p>
    <p>Material and methods:</p>
    <p>• Add a section to detail how you assessed the performance of the key information extraction and of the classifiers, this would encompass among other lines 85-89, 267-273 in the methods, and some paragraphs from the results, for example lines 288 to 295.</p>
    <p>• In the above proposed section, please add a quick description of all indicators used to assess each extraction and classification method (i.e. indicators described in the results and in tables 2 to 4).</p>
    <p>• For epidemiologists the term “sensitivity” will be clearer than “recall”.</p>
    <p>• Lines 79-80: if correct, add “in each class” in the following sentence: “However INIG, as other […] in the keys entitities *in each class*”.</p>
    <p>• Lines 120-121: you mention the problem of events/incidents involving several countries but you don’t specify how you solved it (for example to have an accurate number of cases for each country). Please specify how many events/incidents it concerned and how you solved this problem. Why didn’t you remove these events for training the algorithm?</p>
    <p>• Table 1: please specify what a “sample” is; and what is considered “positive” or “negative” samples.</p>
    <p>• Lines 159-161: if I understood well, the key information for a single class is the recognized entity from the sentence with the highest probability. How did you deal with sentences having more than one recognized entity for a single class?</p>
    <p>• Please make clear the number of articles used in your samples:</p>
    <p>◦ As I understand, you had 3232 articles, 160 relevant (included in the IDB) and 3072 irrelevant.</p>
    <p>◦ And then you tested your classifiers with 20% of your sample, please provide figures of relevant and irrelevant articles used to test your classifiers.</p>
    <p>◦ As I understand, you had two classes: relevant or irrelevant article. If I am correct, please make it clear, including in the sections related to the test of the classifiers.</p>
    <p>Results:</p>
    <p>• When you say all countries and diseases (except one) were correctly recognized, please provide the figures; i.e. for how many articles presents in the IDB country and disease were correctly extracted. Same for dates and counts.</p>
    <p>• Lines 299-302: not clear what the results related to EpiTator and the ones related to the most frequent approach are.</p>
    <p>• Please also provide figures for table 4. For example, for each classification modality, how many documents were classified as relevant and not relevant, how many were truly relevant and how many truly not relevant?</p>
    <p>• Similarly, it would be good to know if other incidents not logged in the IDB but still of interest were identified using the automatized screening approach, i.e. documents identified as “relevant” by the classifier, that were not in the IDB, but that should have been after a review by a public health expert.</p>
    <p>Conclusion:</p>
    <p>• The most important added value of the tool would be to pre-screen large amounts of data to identify a sample that would be then manually screened by public health experts.</p>
    <p>**********</p>
    <p>
      <bold>Have all data underlying the figures and results presented in the manuscript been provided?</bold>
    </p>
    <p>Large-scale datasets should be made available via a public repository as described in the <italic>PLOS Computational Biology</italic>
<ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/ploscompbiol/s/data-availability">data availability policy</ext-link>, and numerical data that underlies graphs or summary statistics should be provided in spreadsheet form as supporting information.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: None</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" xlink:href="https://www.plos.org/privacy-policy">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: Yes: Jose Guerra</p>
    <p>
      <underline>Figure Files:</underline>
    </p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <underline><ext-link ext-link-type="uri" xlink:href="https://pacev2.apexcovantage.com/" xlink:type="simple">https://pacev2.apexcovantage.com</ext-link></underline>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <underline><email xlink:type="simple">figures@plos.org</email></underline>.</p>
    <p>
      <underline>Data Requirements:</underline>
    </p>
    <p>Please note that, as a condition of publication, PLOS' data policy requires that you make available all data used to draw the conclusions outlined in your manuscript. Data must be deposited in an appropriate repository, included within the body of the manuscript, or uploaded as supporting information. This includes all numerical values that were used to generate graphs, histograms etc.. For an example in PLOS Biology see here: <ext-link ext-link-type="uri" xlink:href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5">http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5</ext-link>.</p>
    <p>
      <underline>Reproducibility:</underline>
    </p>
    <p>To enhance the reproducibility of your results, PLOS recommends that you deposit laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. For instructions, please see <underline><ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/plospathogens/s/submission-guidelines" xlink:type="simple">http://journals.plos.org/compbiol/s/submission-guidelines#loc-materials-and-methods</ext-link></underline></p>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s012">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Review for PCOMPBIOL-D-19-01790.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1008277.s012.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1008277.r002" article-type="author-comment">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008277.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article id="rel-obj002" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008277" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">28 Jun 2020</named-content>
    </p>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s013">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">response.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1008277.s013.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1008277.r003" article-type="aggregated-review-documents">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008277.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Pitzer</surname>
          <given-names>Virginia E.</given-names>
        </name>
        <role>Deputy Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Althouse</surname>
          <given-names>Benjamin Muir</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2020 Pitzer, Althouse</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Pitzer, Althouse</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj003" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008277" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">21 Jul 2020</named-content>
    </p>
    <p>Dear Mr. Abbood,</p>
    <p>Thank you very much for submitting your manuscript "EventEpi–A Natural Language Processing Framework for Event-Based Surveillance" for consideration at PLOS Computational Biology. As with all papers reviewed by the journal, your manuscript was reviewed by members of the editorial board and by several independent reviewers. The reviewers appreciated the attention to an important topic. Based on the reviews, we are likely to accept this manuscript for publication, providing that you modify the manuscript according to the review recommendations.</p>
    <p>Please address reviewer 2's very minor points.</p>
    <p>Please prepare and submit your revised manuscript within 30 days. If you anticipate any delay, please let us know the expected resubmission date by replying to this email. </p>
    <p>When you are ready to resubmit, please upload the following:</p>
    <p>[1] A letter containing a detailed list of your responses to all review comments, and a description of the changes you have made in the manuscript. Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out</p>
    <p>[2] Two versions of the revised manuscript: one with either highlights or tracked changes denoting where the text has been changed; the other a clean version (uploaded as the manuscript file).</p>
    <p>Important additional instructions are given below your reviewer comments.</p>
    <p>Thank you again for your submission to our journal. We hope that our editorial process has been constructive so far, and we welcome your feedback at any time. Please don't hesitate to contact us if you have any questions or comments.</p>
    <p>Sincerely,</p>
    <p>Benjamin Althouse</p>
    <p>Associate Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Virginia Pitzer</p>
    <p>Deputy Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************</p>
    <p>A link appears below if there are any accompanying review attachments. If you believe any reviews to be missing, please contact <email>ploscompbiol@plos.org</email> immediately:</p>
    <p>[LINK]</p>
    <p>Please address reviewer 2's very minor points.</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: I am satisfied that the authors have addressed the concerns highlighted in the review. I also congratulate them on making the data accessible for future research.</p>
    <p>Reviewer #2: Dear Authors,</p>
    <p>Thank you for your impressive work in the improvement of the paper, it looks very good now.</p>
    <p>I am fully satisfied with your explanations to my questions and the modifications performed to the manuscript.</p>
    <p>Please find below some very minor comments and proposed modifications, feel free to consider them or not.</p>
    <p>Introduction:</p>
    <p>* Line 40: typo, "spent" instead of "spend".</p>
    <p>Results:</p>
    <p>* Tables 1 and 2: the term "support" is still not very clear, even with the added explanation, maybe you could consider the use of another term such as "sample used".</p>
    <p>* The confusion matrices are very good and self-explanatory, I strongly believe they should be part of the main manuscript instead of being in the supplementary material.</p>
    <p>S1 Appendix:</p>
    <p>* line 554: typo "classification" instead of "classifcation"</p>
    <p>Best regards</p>
    <p>**********</p>
    <p>
      <bold>Have all data underlying the figures and results presented in the manuscript been provided?</bold>
    </p>
    <p>Large-scale datasets should be made available via a public repository as described in the <italic>PLOS Computational Biology</italic>
<ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/ploscompbiol/s/data-availability">data availability policy</ext-link>, and numerical data that underlies graphs or summary statistics should be provided in spreadsheet form as supporting information.</p>
    <p>Reviewer #1: None</p>
    <p>Reviewer #2: None</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" xlink:href="https://www.plos.org/privacy-policy">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: <bold>Yes: </bold>José Guerra</p>
    <p>
      <underline>Figure Files:</underline>
    </p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <underline><ext-link ext-link-type="uri" xlink:href="https://pacev2.apexcovantage.com/" xlink:type="simple">https://pacev2.apexcovantage.com</ext-link></underline>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <underline><email xlink:type="simple">figures@plos.org</email></underline>.</p>
    <p>
      <underline>Data Requirements:</underline>
    </p>
    <p>Please note that, as a condition of publication, PLOS' data policy requires that you make available all data used to draw the conclusions outlined in your manuscript. Data must be deposited in an appropriate repository, included within the body of the manuscript, or uploaded as supporting information. This includes all numerical values that were used to generate graphs, histograms etc.. For an example in PLOS Biology see here: <ext-link ext-link-type="uri" xlink:href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5">http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5</ext-link>.</p>
    <p>
      <underline>Reproducibility:</underline>
    </p>
    <p>To enhance the reproducibility of your results, PLOS recommends that you deposit laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. For instructions see <underline><ext-link ext-link-type="uri" xlink:href="http://journals.plos.org/plospathogens/s/submission-guidelines" xlink:type="simple">http://journals.plos.org/ploscompbiol/s/submission-guidelines#loc-materials-and-methods</ext-link></underline></p>
  </body>
</sub-article>
<sub-article id="pcbi.1008277.r004" article-type="author-comment">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008277.r004</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 1</article-title>
    </title-group>
    <related-article id="rel-obj004" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008277" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">10 Aug 2020</named-content>
    </p>
    <supplementary-material content-type="local-data" id="pcbi.1008277.s014">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">response_2.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1008277.s014.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article id="pcbi.1008277.r005" article-type="editor-report">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008277.r005</article-id>
    <title-group>
      <article-title>Decision Letter 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Pitzer</surname>
          <given-names>Virginia E.</given-names>
        </name>
        <role>Deputy Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Althouse</surname>
          <given-names>Benjamin Muir</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2020 Pitzer, Althouse</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Pitzer, Althouse</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj005" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008277" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">20 Aug 2020</named-content>
    </p>
    <p>Dear Mr. Abbood,</p>
    <p>We are pleased to inform you that your manuscript 'EventEpi–A Natural Language Processing Framework for Event-Based Surveillance' has been provisionally accepted for publication in PLOS Computational Biology.</p>
    <p>Before your manuscript can be formally accepted you will need to complete some formatting changes, which you will receive in a follow up email. A member of our team will be in touch with a set of requests.</p>
    <p>Please note that your manuscript will not be scheduled for publication until you have made the required changes, so a swift response is appreciated.</p>
    <p>IMPORTANT: The editorial review process is now complete. PLOS will only permit corrections to spelling, formatting or significant scientific errors from this point onwards. Requests for major changes, or any which affect the scientific understanding of your work, will cause delays to the publication date of your manuscript.</p>
    <p>Should you, your institution's press office or the journal office choose to press release your paper, you will automatically be opted out of early publication. We ask that you notify us now if you or your institution is planning to press release the article. All press must be co-ordinated with PLOS.</p>
    <p>Thank you again for supporting Open Access publishing; we are looking forward to publishing your work in PLOS Computational Biology. </p>
    <p>Best regards,</p>
    <p>Benjamin Althouse</p>
    <p>Associate Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Virginia Pitzer</p>
    <p>Deputy Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************************************************</p>
  </body>
</sub-article>
<sub-article id="pcbi.1008277.r006" article-type="editor-report">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1008277.r006</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Pitzer</surname>
          <given-names>Virginia E.</given-names>
        </name>
        <role>Deputy Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Althouse</surname>
          <given-names>Benjamin Muir</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2020 Pitzer, Althouse</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Pitzer, Althouse</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article id="rel-obj006" ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1008277" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">27 Oct 2020</named-content>
    </p>
    <p>PCOMPBIOL-D-19-01790R2 </p>
    <p>EventEpi–A Natural Language Processing Framework for Event-Based Surveillance</p>
    <p>Dear Dr Abbood,</p>
    <p>I am pleased to inform you that your manuscript has been formally accepted for publication in PLOS Computational Biology. Your manuscript is now with our production department and you will be notified of the publication date in due course.</p>
    <p>The corresponding author will soon be receiving a typeset proof for review, to ensure errors have not been introduced during production. Please review the PDF proof of your manuscript carefully, as this is the last chance to correct any errors. Please note that major changes, or those which affect the scientific understanding of the work, will likely cause delays to the publication date of your manuscript. </p>
    <p>Soon after your final files are uploaded, unless you have opted out, the early version of your manuscript will be published online. The date of the early version will be your article's publication date. The final article will be published to the same URL, and all versions of the paper will be accessible to readers.</p>
    <p>Thank you again for supporting PLOS Computational Biology and open-access publishing. We are looking forward to publishing your work! </p>
    <p>With kind regards,</p>
    <p>Matt Lyles</p>
    <p>PLOS Computational Biology | Carlyle House, Carlyle Road, Cambridge CB4 3DN | United Kingdom <email>ploscompbiol@plos.org</email> | Phone +44 (0) 1223-442824 | <ext-link ext-link-type="uri" xlink:href="http://ploscompbiol.org">ploscompbiol.org</ext-link> | @PLOSCompBiol</p>
  </body>
</sub-article>
