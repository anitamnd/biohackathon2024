<?properties open_access?>
<?subarticle report58116?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">F1000Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">F1000Res</journal-id>
    <journal-id journal-id-type="pmc">F1000Research</journal-id>
    <journal-title-group>
      <journal-title>F1000Research</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2046-1402</issn>
    <publisher>
      <publisher-name>F1000 Research Limited</publisher-name>
      <publisher-loc>London, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6966772</article-id>
    <article-id pub-id-type="doi">10.12688/f1000research.21782.4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group>
        <subject>Articles</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Benchmarking of long-read assemblers for prokaryote whole genome sequencing</article-title>
      <fn-group content-type="pub-status">
        <fn>
          <p>[version 4; peer review: 4 approved]</p>
        </fn>
      </fn-group>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wick</surname>
          <given-names>Ryan R.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Data Curation</role>
        <role content-type="http://credit.casrai.org/">Formal Analysis</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8349-0778</contrib-id>
        <xref ref-type="corresp" rid="c1">a</xref>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Holt</surname>
          <given-names>Kathryn E.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <xref ref-type="aff" rid="a1">1</xref>
        <xref ref-type="aff" rid="a2">2</xref>
      </contrib>
      <aff id="a1"><label>1</label>Department of Infectious Diseases, Central Clinical School, Monash University, Melbourne, VIC, 3004, Australia</aff>
      <aff id="a2"><label>2</label>Department of Infection Biology, London School of Hygiene &amp; Tropical Medicine, London, WC1E 7HT, UK</aff>
    </contrib-group>
    <author-notes>
      <corresp id="c1">
        <label>a</label>
        <email xlink:href="mailto:rrwick@gmail.com">rrwick@gmail.com</email>
      </corresp>
      <fn fn-type="COI-statement">
        <p>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>1</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>8</volume>
    <elocation-id>2138</elocation-id>
    <history>
      <date date-type="accepted">
        <day>25</day>
        <month>1</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright: © 2021 Wick RR and Holt KE</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="f1000research-8-54213.pdf"/>
    <abstract>
      <p><bold>Background: </bold>Data sets from long-read sequencing platforms (Oxford Nanopore Technologies and Pacific Biosciences) allow for most prokaryote genomes to be completely assembled – one contig per chromosome or plasmid. However, the high per-read error rate of long-read sequencing necessitates different approaches to assembly than those used for short-read sequencing. Multiple assembly tools (assemblers) exist, which use a variety of algorithms for long-read assembly.</p>
      <p><bold>Methods: </bold>We used 500 simulated read sets and 120 real read sets to assess the performance of eight long-read assemblers (Canu, Flye, Miniasm/Minipolish, NECAT, NextDenovo/NextPolish, Raven, Redbean and Shasta) across a wide variety of genomes and read parameters. Assemblies were assessed on their structural accuracy/completeness, sequence identity, contig circularisation and computational resources used.</p>
      <p><bold>Results: </bold>Canu v2.1 produced reliable assemblies and was good with plasmids, but it performed poorly with circularisation and had the longest runtimes of all assemblers tested. Flye v2.8 was also reliable and made the smallest sequence errors, though it used the most RAM. Miniasm/Minipolish v0.3/v0.1.3 was the most likely to produce clean contig circularisation. NECAT v20200803 was reliable and good at circularisation but tended to make larger sequence errors. NextDenovo/NextPolish v2.3.1/v1.3.1 was reliable with chromosome assembly but bad with plasmid assembly. Raven v1.3.0 was reliable for chromosome assembly, though it did not perform well on small plasmids and had circularisation issues. Redbean v2.5 and Shasta v0.7.0 were computationally efficient but more likely to produce incomplete assemblies.</p>
      <p><bold>Conclusions: </bold>Of the assemblers tested, Flye, Miniasm/Minipolish, NextDenovo/NextPolish and Raven performed best overall. However, no single tool performed well on all metrics, highlighting the need for continued development on long-read assembly algorithms.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>Assembly</kwd>
      <kwd>long-read sequencing</kwd>
      <kwd>Oxford Nanopore Technologies</kwd>
      <kwd>Pacific Biosciences</kwd>
      <kwd>microbial genomics</kwd>
      <kwd>benchmarking</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1" xlink:href="http://dx.doi.org/10.13039/100008717">
        <funding-source>Sylvia and Charles Viertel Charitable Foundation</funding-source>
      </award-group>
      <award-group id="fund-2" xlink:href="http://dx.doi.org/10.13039/100000865">
        <funding-source>Bill and Melinda Gates Foundation</funding-source>
        <award-id>OPP1175797</award-id>
      </award-group>
      <award-group id="fund-3" xlink:href="http://dx.doi.org/10.13039/501100000937">
        <funding-source>Department of Education, Employment and Workplace Relations, Australian Government</funding-source>
      </award-group>
      <funding-statement>This work was supported by the Bill &amp; Melinda Gates Foundation, Seattle (grant number OPP1175797) and an Australian Government Research Training Program Scholarship. KEH is supported by a Senior Medical Research Fellowship from the Viertel Foundation of Victoria.</funding-statement>
      <funding-statement>
        <italic>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</italic>
      </funding-statement>
    </funding-group>
  </article-meta>
  <notes notes-type="version-changes">
    <sec sec-type="version-changes">
      <label>Updated</label>
      <title>Changes from Version 3</title>
      <p>This version contains updated results for new versions of Canu (v2.1), NECAT (v20200803), NextDenovo/NextPolish (v2.3.1/v1.3.1), Raven (v1.3.0) and Shasta (v0.7.0). Most notably, the current versions of NECAT and NextDenovo/NextPolish were more reliable and robust than their previous versions, and the current version of Raven used much less RAM than its previous version.</p>
    </sec>
  </notes>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>Genome assembly is the computational process of using shotgun whole-genome sequencing data (reads) to reconstruct an organism’s true genomic sequence to the greatest extent possible
<sup><xref rid="ref-1" ref-type="bibr">1</xref></sup>. Software tools which carry out assembly (assemblers) take sequencing reads as input and produce reconstructed contiguous pieces of the genome (contigs) as output.</p>
    <p>If a genome contains repetitive sequences (repeats) which are longer than the sequencing reads, then the underlying genome cannot be fully reconstructed without additional information; i.e. if no read spans a repeat in the genome, then that repeat cannot be resolved, limiting contig length
<sup><xref rid="ref-2" ref-type="bibr">2</xref></sup>. Short-read sequencing platforms (e.g. those made by Illumina) produce reads hundreds of bases in length and tend to result in shorter contigs. In contrast, long-read platforms from Oxford Nanopore Technologies (ONT) and Pacific Biosciences (PacBio) can generate reads tens of thousands of bases in length which span more repeats and thus result in longer contigs
<sup><xref rid="ref-3" ref-type="bibr">3</xref></sup>.</p>
    <p>Prokaryote genomes are simpler than eukaryote genomes in a few aspects relevant to assembly. First, they are smaller, most being less than 10 Mbp in size
<sup><xref rid="ref-4" ref-type="bibr">4</xref></sup>. Second, they contain less repetitive content and their longest repeat sequences are often less than 10 kbp in length
<sup><xref rid="ref-5" ref-type="bibr">5</xref></sup>. Third, prokaryote genomes are haploid and thus avoid assembly-related complications from diploidy/polyploidy
<sup><xref rid="ref-6" ref-type="bibr">6</xref></sup>. These facts make prokaryote genome assembly a more tractable problem than eukaryote genome assembly, and in most cases a long-read set of sufficient depth should contain enough information to generate a complete assembly – each replicon in the genome being fully assembled into a single contig
<sup><xref rid="ref-7" ref-type="bibr">7</xref></sup>. Prokaryote genomes also have two other features relevant to assembly: they may contain plasmids that differ from the chromosome in copy number and therefore read depth, and most prokaryote replicons are circular with no defined start/end point.</p>
    <p>In this study, we examine the performance of various long-read assemblers in the context of prokaryote whole genomes. We assessed each tool on its ability to generate complete assemblies using both simulated and real read sets. We also investigated prokaryote-specific aspects of assembly, such as performance on plasmids and the circularisation of contigs.</p>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>Simulated read sets</title>
      <p>Simulated read sets (read sequences generated
<italic>in silico</italic> from reference genomes) offer some advantages over real read sets when assessing assemblers. They allow for a confident ground truth – i.e. the true underlying genome is known with certainty. They allow for large sample sizes, in practice limited only by computational resources. Also, a variety of genomes and read set parameters can be used to examine assembler performance over a wide range of scenarios. For this study, we simulated 500 read sets to test the assemblers, each using different parameters and a different prokaryote genome.</p>
      <p>To select reference genomes for the simulated read sets, we first downloaded all bacterial and archaeal RefSeq genomes using
<ext-link ext-link-type="uri" xlink:href="https://github.com/kblin/ncbi-genome-download">ncbi-genome-download</ext-link> v0.2.10 (14333 genomes at the time of download)
<sup><xref rid="ref-8" ref-type="bibr">8</xref></sup>. We then performed some quality control steps: excluding genomes with a &gt;10 Mbp chromosome, a &lt;500 kbp chromosome, any &gt;300 kbp plasmid, any plasmid &gt;25% of the chromosome size or more than 9 plasmids (
<italic>Extended data</italic>, Figure S1)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. We then ran
<ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/Assembly-Dereplicator">Assembly Dereplicator</ext-link> v0.1.0 with a threshold of 0.1, resulting in 3153 unique genomes
<sup><xref rid="ref-10" ref-type="bibr">10</xref></sup>.</p>
      <p>To produce a final set of 500 genomes with 500 plasmids, we randomly selected 250 genomes from those containing plasmids, repeating this selection until the genomes contained exactly 500 plasmids. We then added 250 genomes randomly selected from those without plasmids. Any ambiguous bases in the assemblies were replaced with ‘A’ to ensure that sequences contained only the four canonical DNA bases.</p>
      <p>We then used
<ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/Badread">Badread</ext-link> v0.1.5 to generate one read set for each input genome
<sup><xref rid="ref-11" ref-type="bibr">11</xref></sup>. The parameters for each set (controlling read depth, length, identity and errors) were randomly chosen to ensure a large amount of variability (
<italic>Extended data</italic>, Figure S2)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Note that not all of these read sets were sufficient to reconstruct the original genome (due to low depth or short read length), so even an ideal assembler would be incapable of completing an assembly for all 500 test sets.</p>
      <p>For genomes containing plasmids, the read depth of plasmids relative to the chromosome was also set randomly, with limits based on the plasmid size (
<italic>Extended data</italic>, Figure S3)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Large plasmids were simulated at depths close to that of the chromosome while small plasmids spanned a wider range of depth. This was done to model the observed pattern that small plasmids often have a high per-cell copy number (i.e. may be high read depth) but can be biased against in library preparations (i.e. may be low read depth)
<sup><xref rid="ref-12" ref-type="bibr">12</xref></sup>. All replicons (chromosomes and plasmids) were treated as circular sequences in Badread, so the simulated read sets do not test assembler performance on linear sequences.</p>
    </sec>
    <sec>
      <title>Real read sets</title>
      <p>Despite the advantages of simulated read sets, they can be unrealistic because read simulation tools (such as Badread) may not accurately model all relevant features: error profiles, read lengths, quality scores, etc. Real read sets are therefore also valuable when assessing assemblers. The challenge with real read sets is obtaining a ground truth genome against which assemblies can be checked. Since many reference genome sequences are produced using long-read assemblies, there is the risk of circular reasoning – if we use an assembly as our ground truth reference, our results will be biased in favour of whichever assembler produced the reference.</p>
      <p>To avoid this issue, we used the datasets produced in a recent study comparing ONT (MinION R9.4) and PacBio (RSII CLR) data which also included Illumina reads for each isolate
<sup><xref rid="ref-13" ref-type="bibr">13</xref></sup>. For each of the 20 bacterial isolates in that study, we conducted two hybrid assemblies using
<ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/Unicycler">Unicycler</ext-link> v0.4.7: Illumina+ONT and Illumina+PacBio
<sup><xref rid="ref-14" ref-type="bibr">14</xref></sup>. Unicycler works by first generating an assembly graph using the Illumina reads, then using long-read alignments to scaffold the graph’s contigs into a completed genome – a distinct approach from any of the long-read assemblers tested in this study. We ran the assemblies using Unicycler’s
<monospace>--no_miniasm</monospace> option so it skipped its Miniasm-based step which could bias the results in favour of Miniasm/Minipolish. We then excluded any isolate where either hybrid assembly failed to reach completion or where there were &gt;50 nucleotide differences between the two assemblies as determined by a Minimap2 alignment
<sup><xref rid="ref-15" ref-type="bibr">15</xref></sup>. I.e. the Illumina+ONT and Illumina+PacBio hybrid assemblies needed to be in near-perfect agreement with each other. This left six isolates for inclusion. The above process may have biased these isolates in favour of easier-to-assemble genomes, as more complex genomes would be more likely to encounter inconsistencies between the two Unicycler assemblies.</p>
      <p>The ONT and PacBio read sets for these isolates were quite deep (156× to 535×) so to increase the number of assembly tests, we produced ten random read subsets of each, ranging from 40× to 100× read depth. This resulted in 120 total read sets for testing the assemblers (6 genomes × 2 platforms × 10 read subsets). The Illumina+ONT hybrid assembly was used as ground truth for each isolate.</p>
      <p>All real and simulated read sets
<sup><xref rid="ref-16" ref-type="bibr">16</xref></sup> and reference genomes
<sup><xref rid="ref-17" ref-type="bibr">17</xref></sup> are available as
<italic>Underlying data</italic>.</p>
    </sec>
    <sec>
      <title>Assemblers tested</title>
      <p>We assembled each of the read sets using the current versions of eight long-read assemblers:
<ext-link ext-link-type="uri" xlink:href="https://github.com/marbl/canu">Canu</ext-link> v2.1,
<ext-link ext-link-type="uri" xlink:href="https://github.com/fenderglass/Flye">Flye</ext-link> v2.8,
<ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/Minipolish">Miniasm/Minipolish</ext-link> v0.3/v0.1.3,
<ext-link ext-link-type="uri" xlink:href="https://github.com/xiaochuanle/NECAT">NECAT</ext-link> v20200803,
<ext-link ext-link-type="uri" xlink:href="https://github.com/Nextomics/NextDenovo">NextDenovo</ext-link>/
<ext-link ext-link-type="uri" xlink:href="https://github.com/Nextomics/NextPolish">NextPolish</ext-link> v2.3.1/v1.3.1,
<ext-link ext-link-type="uri" xlink:href="https://github.com/lbcb-sci/raven">Raven</ext-link> v1.3.0,
<ext-link ext-link-type="uri" xlink:href="https://github.com/ruanjue/wtdbg2">Redbean</ext-link> v2.5 and
<ext-link ext-link-type="uri" xlink:href="https://github.com/chanzuckerberg/shasta">Shasta</ext-link> v0.7.0. Default parameters were used except where stated, and exact commands for each tool are given in the
<italic>Extended data</italic>, Figure S4
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Assemblers that only work on PacBio reads (i.e. not on ONT reads) were excluded (HGAP
<sup><xref rid="ref-18" ref-type="bibr">18</xref></sup>, FALCON
<sup><xref rid="ref-19" ref-type="bibr">19</xref></sup>, HINGE
<sup><xref rid="ref-20" ref-type="bibr">20</xref></sup> and Dazzler
<sup><xref rid="ref-21" ref-type="bibr">21</xref></sup>), as were hybrid assemblers which also require short read input (Unicycler
<sup><xref rid="ref-14" ref-type="bibr">14</xref></sup> and MaSuRCA
<sup><xref rid="ref-22" ref-type="bibr">22</xref></sup>).</p>
      <p>Canu has the longest history of all the assemblers tested, with its first release dating back to 2015. It performs assembly by first correcting reads, then trimming reads (removing adapters and breaking chimeras) and finally assembling reads into contigs
<sup><xref rid="ref-23" ref-type="bibr">23</xref></sup>. Its assembly strategy uses a modified version of the string graph algorithm
<sup><xref rid="ref-24" ref-type="bibr">24</xref></sup>, sometimes referred to as the overlap-layout-consensus (OLC) approach.</p>
      <p>Flye takes a different approach to assembly: first combining reads into error-prone disjointigs, then collapsing repetitive sequences to make a repeat graph and finally resolving the graph’s repeats to make the final contigs
<sup><xref rid="ref-25" ref-type="bibr">25</xref></sup>. Of particular note to prokaryote assemblies, Flye has options for recovery of small plasmids (
<monospace>--plasmids</monospace>) and uneven depth of coverage (
<monospace>--meta</monospace>), both of which we used in this analysis.</p>
      <p>Miniasm builds a string graph from a set of read overlaps – i.e. it performs only the layout step of OLC. It does not perform read overlapping which must be done separately with Minimap2, and it does not have a consensus step, so its assembly error rates are comparable to raw read error rates. A separate polishing tool such as Racon is therefore required to achieve high sequence identity
<sup><xref rid="ref-26" ref-type="bibr">26</xref></sup>. For this study, we developed a tool called Minipolish to simplify this process by conducting Racon polishing (two rounds by default) on a Miniasm assembly graph
<sup><xref rid="ref-27" ref-type="bibr">27</xref></sup>. To ensure clean circularisation of prokaryote replicons, circular contigs are ‘rotated’ (have their starting position adjusted) between polishing rounds. Minipolish also comes with a script (
<monospace>miniasm_and_minipolish.sh</monospace>) which carries out all assembly steps (Minimap2 overlapping, Miniasm assembly and Minipolish consensus) in a single command, and subsequent references to ‘Miniasm/Minipolish’ refer to this entire pipeline.</p>
      <p>NECAT follows an approach similar to Canu: first correcting the input reads, then building an assembly from the corrected reads
<sup><xref rid="ref-28" ref-type="bibr">28</xref></sup>. Both the correction and assembly steps are progressive, using multiple processing steps to achieve better accuracy/completeness.</p>
      <p>NextDenovo is a performance-oriented assembler, which like Canu and NECAT performs read-correction at the start of its pipeline. It performs the first two steps of OLC (overlap and layout), leaving the final step (consensus) to a separate tool: NextPolish
<sup><xref rid="ref-29" ref-type="bibr">29</xref></sup>. We used both tools in conjunction in this study, referred to as ‘NextDenovo/NextPolish’.</p>
      <p>Raven (previously known as Ra) is another tool which takes an OLC approach to assembly
<sup><xref rid="ref-30" ref-type="bibr">30</xref></sup>. Its overlapping step shares algorithms with Minimap2, and its consensus step is based on Racon, making it similar to Miniasm/Minipolish. It differs in its layout step which includes novel approaches to remove spurious overlaps from the graph, helping to improve assembly contiguity.</p>
      <p>Redbean (previously known as Wtdbg2) uses an approach to long-read assembly called a fuzzy Bruijn graph
<sup><xref rid="ref-31" ref-type="bibr">31</xref></sup>. This is modelled on the De Bruijn graph concept widely used for short-read assembly
<sup><xref rid="ref-32" ref-type="bibr">32</xref></sup> but modified to work with the inexact sequence matches present in noisy long reads.</p>
      <p>Shasta is an assembler designed for computational efficiency
<sup><xref rid="ref-33" ref-type="bibr">33</xref></sup>. To achieve this, much of its assembly pipeline is performed not directly on read sequences but rather on a reduced representation of marker
<italic>k</italic>-mers. These markers are used to find overlaps and build an assembly graph from which a consensus sequence is derived.</p>
    </sec>
    <sec>
      <title>Computational environment</title>
      <p>All assemblies were run on Ubuntu 18.04 instances of Australia’s Nectar Research Cloud which contained 32 vCPUs and 128 GB of RAM (r3.xxlarge flavour). To guard against performance variation caused by vCPU overcommit, the assemblers were limited to 16 threads (half the number of available vCPUs) in their options. Any assembly which exceeded 24 hours of runtime or 128 GB of memory usage was terminated.</p>
    </sec>
    <sec>
      <title>Assembly assessment</title>
      <p>Our primary metric of assembly quality was contiguity, defined here as the longest single Minimap2 alignment between the assembly and the reference replicon, relative to the reference replicon length. This provides a simpler picture of assembly quality than is created by QUAST (which quantifies misassemblies and other metrics such as NG50) but is appropriate for cases where complete assembly is likely
<sup><xref rid="ref-2" ref-type="bibr">2</xref></sup>. Contiguity of exactly 100% indicates that the replicon was assembled completely with no missing or extra sequence (
<italic>Extended data</italic>, Figure S5A)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Contiguity of slightly less than 100% (e.g. 99.9%) indicates that the assembly was complete, but some bases were lost at the start/end of the contig (
<italic>Extended data</italic>, Figure S5B)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Contiguity of more than 100% (e.g. 101%) indicates that the contig contains duplicated sequence via start-end overlap (
<italic>Extended data</italic>, Figure S5C)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Much lower contiguity (e.g. 70%) indicates that the assembly was not complete due to fragmentation (
<italic>Extended data</italic>, Figure S5D)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>, missing sequence (
<italic>Extended data</italic>, Figure S5E)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup> or misassembly (
<italic>Extended data</italic>, Figure S5F)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Contiguity values were determined by aligning the contigs to a tripled version of the reference replicon, necessary to ensure that contigs can fully align even with start-end overlap and regardless of their starting position relative to that of the linearised reference sequence (
<italic>Extended data</italic>, Figure S6)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. To encourage longer alignments, Minimap2 was run with the asm20 preset, chain elongation threshold of 10 kbp, banding threshold of 10 kbp, Z-drop score of 1000 and inversion Z-drop score of 500. The script for conducting this analysis (assess_assembly.py) is available in
<italic>Extended data</italic>.</p>
      <p>Contiguity values were determined for each replicon in the assemblies – e.g. if a genome contained two plasmids, then the assemblies of that genome have three contiguity values: one for the chromosome and one for each plasmid. A status of ‘fully complete’ was assigned to assemblies where all replicons (the chromosome and any plasmids if present) achieved a contiguity of
<italic>≥</italic>99%. If an assembly had a chromosome with a contiguity of
<italic>≥</italic>99% but incomplete plasmids, it was given a status of ‘complete chromosome’. If the chromosome had a contiguity of &lt;99%, the assembly was deemed ‘incomplete’. If the assembly was empty or missing (possibly due to the assembler prematurely terminating with an error), it was given a status of ‘empty’. Computational metrics were also observed for each assembly: time to complete and maximum RAM usage.</p>
    </sec>
  </sec>
  <sec sec-type="results | discussion">
    <title>Results and discussion</title>
    <p><xref ref-type="fig" rid="f1">Figure 1</xref> and
<xref ref-type="fig" rid="f2">Figure 2</xref> summarise the assembly results for the simulated and real read sets, respectively. Full tabulated results can be found in the
<italic>Extended data</italic>
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. The assemblies, times and terminal outputs generated by each assembler are available as
<italic>Underlying data</italic>
<sup><xref rid="ref-34" ref-type="bibr">34</xref></sup>. </p>
    <fig fig-type="figure" id="f1" orientation="portrait" position="anchor">
      <label>Figure 1. </label>
      <caption>
        <title>Assembly results for the simulated read sets, which cover a wide variety of parameters for length, depth and quality.</title>
        <p>‘Miniasm+’ here refers to the entire Miniasm/Minipolish assembly pipeline. (
<bold>A</bold>) Proportion of each possible assembly outcome. (
<bold>B</bold>) Relative contiguity of the chromosome for each assembly, showing cleanliness of circularisation. (
<bold>C</bold>) Relative contiguity of all plasmids in the assemblies, showing cleanliness of circularisation. (
<bold>D</bold>) Sequence identity of each assembly’s longest alignment to the chromosome. (
<bold>E</bold>) The maximum indel error size in each assembly’s longest alignment to the chromosome. (
<bold>F</bold>) Total time taken (wall time) for each assembly. (
<bold>G</bold>) Maximum RAM usage for each assembly.</p>
      </caption>
      <graphic xlink:href="f1000research-8-54213-g0000"/>
    </fig>
    <fig fig-type="figure" id="f2" orientation="portrait" position="anchor">
      <label>Figure 2. </label>
      <caption>
        <title>Assembly results for the real read sets, half containing ONT MinION reads (circles) and half PacBio RSII reads (X shapes).</title>
        <p> ‘Miniasm+’ here refers to the entire Miniasm/Minipolish assembly pipeline. (
<bold>A</bold>) Proportion of each possible assembly outcome. (
<bold>B</bold>) Relative contiguity of the chromosome for each assembly, showing cleanliness of circularisation. (
<bold>C</bold>) Relative contiguity of all plasmids in the assemblies, showing cleanliness of circularisation. (
<bold>D</bold>) Sequence identity of each assembly’s longest alignment to the chromosome. (
<bold>E</bold>) The maximum indel error size in each assembly’s longest alignment to the chromosome. (
<bold>F</bold>) Total time taken (wall time) for each assembly. (
<bold>G</bold>) Maximum RAM usage for each assembly.</p>
      </caption>
      <graphic xlink:href="f1000research-8-54213-g0001"/>
    </fig>
    <p><xref ref-type="fig" rid="f1">Figure 1A</xref>/
<xref ref-type="fig" rid="f2">Figure 2A</xref> show the proportion of read sets with each assembly status. For the real read sets, a higher proportion of completed assemblies indicates a more reliable assembler – one which is likely to make a completed assembly given a typical set of input reads. For the simulated read sets, a higher proportion of completed assemblies indicates a more robust assembler – one which is able to tolerate a wide range of input read parameters, including adverse conditions such as low read accuracy and low read depth (conditions present in some of the simulated read sets but not in the real read sets).
<italic>Extended data</italic>, Figure S7
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup> plots assembly contiguity against specific read set parameters to give a more detailed assessment of robustness. Plasmid assembly status, plotted with plasmid length and read depth, is shown in
<italic>Extended data</italic>, Figure S8 and Figure S9
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup> for the simulated and real read sets, respectively.</p>
    <p><xref ref-type="fig" rid="f1">Figure 1B</xref>/
<xref ref-type="fig" rid="f2">Figure 2B</xref> show the chromosome contiguity values for each assembly, focusing on the range near 100%. These plots show how well assemblers can circularise contigs – i.e. whether sequence is duplicated or missing at the contig start/end (
<italic>Extended data</italic>, Figure S5)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. The closer contiguity is to 100% the better, with exactly 100% indicating perfect circularisation. Plasmid contiguity values are shown in
<xref ref-type="fig" rid="f1">Figure 1C</xref>/
<xref ref-type="fig" rid="f2">Figure 2C</xref>
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>.</p>
    <p>Assembly identity (consensus identity) is a measure of the base-level accuracy of an assembled contig relative to the reference sequence (how few substitution and small indel errors are present) and is shown in
<xref ref-type="fig" rid="f1">Figure 1D</xref>/
<xref ref-type="fig" rid="f2">Figure 2D</xref>. The identity of assembled sequences is almost always higher than the identity of individual reads because errors can be ‘averaged out’ using read depth, producing more accurate consensus base calls. However, systematic read errors (e.g. mistakes in homopolymer length) can make perfect sequence identity difficult to achieve, regardless of assembly strategy
<sup><xref rid="ref-35" ref-type="bibr">35</xref></sup>. While most of the sequence inaccuracies are small (e.g. a single base indel), some can be much larger.
<xref ref-type="fig" rid="f1">Figure 1E</xref>/
<xref ref-type="fig" rid="f2">Figure 2E</xref> show the size of the largest indel error found in each assembly’s chromosome, with smaller values being better. E.g. a maximum indel error size of 10 indicates that no indel errors larger than 10 bp were found in the chromosome.</p>
    <p>Assembler resource usage is shown in terms of total runtime (
<xref ref-type="fig" rid="f1">Figure 1F</xref>/
<xref ref-type="fig" rid="f2">Figure 2F</xref>) and the maximum RAM usage during assembly (
<xref ref-type="fig" rid="f1">Figure 1G</xref>/
<xref ref-type="fig" rid="f2">Figure 2G</xref>).</p>
    <sec>
      <title>Reliability</title>
      <p>Reliability was assessed using each assembler’s performance on the real read sets (
<xref ref-type="fig" rid="f2">Figure 2A</xref>). When considering only the chromosome, NextDenovo/NextPolish was the most reliable assembler, followed by Raven, NECAT, Canu and Flye – all were able to complete the chromosome in over three-quarters of their assemblies. If plasmids are also considered, then Canu was the most reliable assembler followed by Flye. Miniasm/Minipolish and Shasta were moderately reliable, completing over half of the chromosomes. Redbean was the least reliable and completed less than half of the chromosomes.</p>
    </sec>
    <sec>
      <title>Robustness</title>
      <p>Robustness was assessed using each assembler’s performance on the simulated read sets (
<xref ref-type="fig" rid="f1">Figure 1A</xref>) which contained a large amount of variation on many metrics (
<italic>Extended data</italic>, Figure S7). NextDenovo/NextPolish and Raven were the most robust assemblers, able to complete the chromosome in over three-quarters of their assemblies. Flye, Redbean and Canu performed best in cases of low read depth, able to complete assemblies down to
<italic>~</italic>10× depth (
<italic>Extended data</italic>, Figure S7A)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Raven, NextDenovo/NextPolish and NECAT performed best with low-identity read sets (
<italic>Extended data</italic>, Figure S7B)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. The assemblers performed similarly with regards to read length, except for Shasta which required longer reads (
<italic>Extended data</italic>, Figure S7C)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. The assemblers were similarly unaffected by random reads, junk reads, chimeric reads or adapter sequences (
<italic>Extended data</italic>, Figure S7D–F)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Read glitches (local breaks in continuity) were more likely to cause assembly problems for Canu, NECAT and Shasta (
<italic>Extended data</italic>, Figure S7G)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>.</p>
    </sec>
    <sec>
      <title>Identity</title>
      <p>In our real read tests, Flye achieved the highest overall assembled sequence identity (
<xref ref-type="fig" rid="f2">Figure 2D</xref>). Canu achieved high sequence identity on PacBio reads. Miniasm/Minipolish, NextDenovo/NextPolish and Raven did well on ONT reads. For each assembler, real PacBio reads resulted in higher identities than real ONT reads. For the simulated reads (which contain artificial error profiles), results were more erratic, with Canu and Flye performing best (
<xref ref-type="fig" rid="f1">Figure 1D</xref>).</p>
      <p>Regarding the maximum indel error size in the assemblies, Flye performed best, usually producing assemblies with errors no larger than 10 bp (
<xref ref-type="fig" rid="f1">Figure 1E</xref>/
<xref ref-type="fig" rid="f2">Figure 2E</xref>). NECAT and Shasta performed poorly, usually producing errors larger than 10 bp. The other assemblers had a large variance in this metric, sometimes producing assemblies with small errors and sometimes with large errors.</p>
      <p>The nature of read errors depends on the sequencing platform and basecalling software used, so these results may not hold true for all read sets. Platform-specific post-assembly polishing tools (including Nanopolish
<sup><xref rid="ref-7" ref-type="bibr">7</xref></sup>, Medaka
<sup><xref rid="ref-36" ref-type="bibr">36</xref></sup> and Arrow
<sup><xref rid="ref-37" ref-type="bibr">37</xref></sup>) are routinely used to improve the accuracy of long-read assemblies
<sup><xref rid="ref-38" ref-type="bibr">38</xref></sup>, and these can often achieve assembly identities of &gt;99.9% for ONT read sets and &gt;99.999% for PacBio read sets (i.e. better than any of the assemblers were able to achieve on their own). Identity can be further increased by polishing with Illumina reads where available (e.g. with Pilon
<sup><xref rid="ref-39" ref-type="bibr">39</xref></sup>). Therefore, the sequence identity produced by the assembler itself is potentially unimportant for many users. However, large-scale indel errors may be less easily fixed using polishing tools and therefore could be of greater relevance.</p>
    </sec>
    <sec>
      <title>Resource usage</title>
      <p>Canu was the slowest assembler tested on both real (
<xref ref-type="fig" rid="f2">Figure 2F</xref>) and simulated (
<xref ref-type="fig" rid="f1">Figure 1F</xref>) read sets, sometimes taking hours to complete. Its runtime was correlated with read accuracy and read set size, with low-accuracy and large read sets being more likely to result in a long runtime.</p>
      <p>Flye was typically faster than Canu, taking less than 15 minutes for the real read sets and usually less than an hour for the simulated read sets. It sometimes took multiple hours to assemble simulated read sets, and this was correlated with the amount of junk (low-complexity) reads, suggesting that removal of such reads via pre-assembly QC may be beneficial. Flye had the highest RAM usage of the tested assemblers and its RAM usage was correlated with read N50 and read set size, with long and large read sets being more likely to result in high RAM usage.</p>
      <p>Shasta, Redbean and Raven were the fastest assemblers, typically completing assemblies in less than 5 minutes. While not tested in this study, Racon (which is used in Minipolish) and Raven can be run with GPU acceleration to further improve speed performance. Raven and Shasta had the lowest memory usage, typically requiring less than 4 GB of RAM.</p>
    </sec>
    <sec>
      <title>Circularisation</title>
      <p>Of all assemblers tested, Miniasm/Minipolish and NECAT most regularly achieved exact circularisation (contiguity=100%) (
<xref ref-type="fig" rid="f1">Figure 1B</xref>/
<xref ref-type="fig" rid="f2">Figure 2B</xref>). Flye often excluded a small amount of sequence (tens of bases) from the start/end of circular contigs (contiguity &lt;100%), and Raven typically excluded moderate amounts of sequence (hundreds of bases). Contiguities for Canu and NextDenovo/NextPolish usually exceeded 100%, indicating a large amount (thousands of bases) of start/end overlap. The amount of overlap in a Canu or NextDenovo/NextPolish assembly was correlated with the read N50 length (
<italic>Extended data</italic>, Figure S7C)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Redbean and Shasta were both erratic in their circularisation, often producing some sequence duplication (contiguity &gt;100%) but occasionally dropping sequence (contiguity &lt;100%).</p>
      <p>In addition to cleanly circularising contig sequences, it is valuable for a prokaryote genome assembler to clearly distinguish between circular and linear contigs. This can provide users with a clue as to whether or not the genome was assembled to completion. Flye, Miniasm/Minipolish, Raven and Shasta produce graph files of their final assembly which can indicate circularity. Canu indicates circularity via the ‘suggestCircular’ text in its contig headers. NECAT, NextDenovo/NextPolish and Redbean do not signal to users whether a contig is circular.</p>
    </sec>
    <sec>
      <title>Plasmids</title>
      <p>Canu and Flye were the two assemblers most able to assemble plasmids at a broad range of size and depth (
<italic>Extended data</italic>, Figures S8, S9)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. Miniasm/Minipolish also performed well, though it failed to assemble plasmids if they were very small or had a very high read depth. Raven was able to assemble most large plasmids but not small plasmids. NECAT, NextDenovo/NextPolish, Redbean and Shasta were least successful at plasmid assembly.</p>
      <p>Circularisation of plasmids followed the same pattern as for chromosomes, with Miniasm/Minipolish, Flye and NECAT most consistently achieving clean circularisation (
<xref ref-type="fig" rid="f1">Figure 1C</xref>/
<xref ref-type="fig" rid="f2">Figure 2C</xref>)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. For smaller plasmids, start/end overlap could sometimes result in contiguities of
<italic>∼</italic>200% – i.e. the plasmid sequence was duplicated in a single contig. This was most common with Canu and NextDenovo/NextPolish, though it occurred with other assemblers as well.</p>
    </sec>
    <sec>
      <title>Ease of use</title>
      <p>Most assemblers tested were relatively easy to use, either running with a single command (Canu, Flye, Raven and Shasta) or providing a convenience script to bundle the commands together (Miniasm/Minipolish and Redbean). NECAT requires a configuration file be prepared, making it somewhat cumbersome to run. NextDenovo/NextPolish was the most difficult to run, requiring multiple commands and multiple configuration files. All were able to take long reads in FASTQ format as input (
<italic>Extended data</italic>, Figure S4)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>. We encountered no difficulty installing any of the tools by following the instructions provided.</p>
      <p>Some of the assemblers needed a predicted genome size as input (Canu, NECAT, NextDenovo/NextPolish and Redbean) while others (Flye, Miniasm/Minipolish, Raven and Shasta) did not. This requirement could be a nuisance when assembling unknown isolates, as it may be hard to specify a genome size before the species is known.</p>
    </sec>
    <sec>
      <title>Configurability</title>
      <p>While we ran our assemblies using default and/or recommended commands (
<italic>Extended data</italic>, Figure S4)
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>, some of the assemblers have parameters which can be used to alter their behaviour. Raven was the least configurable assembler tested, with few options available to users. Flye offers some parameters, including overlap and coverage thresholds. Miniasm/Minipolish, NECAT, NextDenovo/NextPolish, Redbean and Shasta all offer more options, and Canu is the most configurable with hundreds of adjustable parameters. Many of the available parameters are arcane (e.g. Miniasm’s ‘max and min overlap drop ratio’ or Shasta’s ‘pruneIterationCount’), and only experienced power users are likely to adjust them – most will likely stick with default settings or only adjust easier-to-understand options. However, the presence of low-level parameters provides an opportunity to experiment and gain greater control over assemblies and are therefore appreciated even when unlikely to be used.</p>
      <p>Another aspect worth noting is whether an assembler produces useful files other than its final assembly. Canu and NECAT stand out in this respect, as they create corrected and trimmed reads in their pipelines which have low error rates and are mostly free of adapters and chimeric sequences. Canu and NECAT can therefore be considered not just assemblers but also long-read correction tools suitable for use in other analyses.</p>
    </sec>
    <sec>
      <title>Assembler summaries</title>
      <p>Canu v2.1 was the slowest assembler and suffered from large circularisation problems. However, it was quite reliable and did well with plasmids. Its main strength is in its configurability, so power users who are willing to learn Canu’s nuances may find that they can tune it to fit their needs. However, it is probably not the best choice for users wanting a quick and simple prokaryote genome assembly.</p>
      <p>Flye v2.8 was a strong and well-balanced performer in our tests: reliable, robust and good with plasmids. It also produced the fewest large-scale indel errors in its assemblies. However, it often deleted some sequence (usually on the order of tens of bases) when circularising contigs and had the highest RAM usage of assemblers tested.</p>
      <p>Miniasm/Minipolish v0.3/v0.1.3 was not the most reliable assembler but was fairly robust to read set parameters. Its main strength is that it was the most likely to consistently achieve perfect contig circularisation (as this is a specific goal of its polishing step). It was also one of the better assemblers for plasmids, especially regarding clean circularisation of plasmid sequences.</p>
      <p>NECAT v20200803 performed reliably with chromosome assembly in the real read sets and was second only to Miniasm/Minipolish for contig circularisation. However, it failed to assemble many plasmids and was cumbersome to run.</p>
      <p>NextDenovo/NextPolish v2.3.1/v1.3.1 was resource-efficient and very good at completing chromosomes in both simulated and real read sets, but it performed poorly on plasmid assembly. It was also the most cumbersome assembler to run, requiring multiple commands.</p>
      <p>Raven v1.3.0 was reliable and robust for chromosome assembly and used very little RAM. However, it suffered from worse circularisation problems than Flye (often deleting hundreds of bases) and wasn’t good with small plasmids.</p>
      <p>Redbean v2.5 assemblies tended to have glitches in the sequence which caused breaks in contiguity, making it perform poorly in both reliability and robustness. This makes it a less-than-ideal choice for long-read prokaryote read sets.</p>
      <p>Shasta v0.7.0 was the fastest assembler tested and had low RAM usage, but it had the worst robustness and second-worst reliability. It is therefore more suited to assembly of large genomes in resource-limited settings (the use case for which it was designed) than it is for prokaryote genome assembly.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions">
    <title>Conclusions</title>
    <p>Each of the different assemblers has pros and cons, and while no single assembler emerged as an ideal choice for prokaryote genome long-read assembly, the overall best performers were Flye, Miniasm/Minipolish, NextDenovo/NextPolish and Raven. Flye was reliable, especially for plasmid assembly, was the best performing assembler at low read depths and made the fewest large-scale sequence errors. Miniasm/Minipolish was the only assembler to consistently achieve clean contig circularisation. NextDenovo/NextPolish was best at generating complete chromosomal contigs. Raven was reliable for chromosome assembly, tolerant of low-identity read sets and computationally efficient.</p>
    <p>For users looking to achieve an optimal assembly, we recommend trying multiple different tools and comparing the results. This will provide the opportunity for validation – confidence in an assembly is greater when it is in agreement with other independent assemblies. It also offers a chance to detect and repair circularisation issues, as different assemblers are likely to give different contig start/end positions for a circular replicon.</p>
    <p>An ideal prokaryotic long-read assembler would reliably complete assemblies, be robust against read set problems, produce no large-scale errors, be easy to use, have low computational requirements, cleanly circularise contigs and assemble plasmids of any size. The importance of long-read assembly will continue to grow as long-read sequencing becomes more commonplace in microbial genomics, and so development of assemblers towards this ideal is crucial.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <sec>
      <title>Underlying data</title>
      <p>Figshare: Read sets.
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.26180/5df6f5d06cf04">https://doi.org/10.26180/5df6f5d06cf04</ext-link>
<sup><xref rid="ref-16" ref-type="bibr">16</xref></sup>. </p>
      <p>These files contain the input read sets (both simulated and real) for assembly.</p>
      <p>Figshare: Reference genomes.
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.26180/5df6e99ff3eed">https://doi.org/10.26180/5df6e99ff3eed</ext-link>
<sup><xref rid="ref-17" ref-type="bibr">17</xref></sup>. </p>
      <p>This file contains the reference genomes against which the long-read assemblies were compared. For the simulated read sets, these genomes were the source sequence from which the reads were generated.</p>
      <p>Figshare: Assemblies.
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.26180/5df6e2864a658">https://doi.org/10.26180/5df6e2864a658</ext-link>
<sup><xref rid="ref-34" ref-type="bibr">34</xref></sup>. </p>
      <p>These files contain assemblies (in FASTA format), times and terminal outputs for each of the assemblers.</p>
    </sec>
    <sec>
      <title>Extended data</title>
      <p>Zenodo: Long-read-assembler-comparison.
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2702442">https://doi.org/10.5281/zenodo.2702442</ext-link>
<sup><xref rid="ref-9" ref-type="bibr">9</xref></sup>.</p>
      <p>This project contains the following extended data:</p>
      <list list-type="bullet">
        <list-item>
          <p>Results (tables of results data, (including information on each reference genome, read set parameters and metrics foreach assembly).</p>
        </list-item>
        <list-item>
          <p>Scripts (scripts used to assess assemblies and generate plots).</p>
        </list-item>
        <list-item>
          <p>Figure S1. Distributions of chromosome sizes (A), plasmid sizes (B) and per-genome plasmid counts (C) for the reference genomes used to make the simulated read sets.</p>
        </list-item>
        <list-item>
          <p>Figure S2. Badread parameter histograms for the simulated read sets. (A) Mean read depths were sampled from a uniform distribution ranging from 5× to 200×. (B) mean read lengths were sampled from a uniform distribution ranging from 100 to 20000 bp. C: read length standard deviations were sampled from a uniform distribution ranging from 100 to twice that set’s mean length (up to 40000 bp). D: mean read identities were sampled from a uniform distribution ranging from 80% to 99%. (E) Max read identities were sampled from a uniform distribution ranging from that set’s mean identity plus 1% to 100%. (F) Read identity standard deviations were sampled from a uniform distribution ranging from 1% to the max identity minus the mean identity. (G, H and I) Junk, random and chimera rates were all sampled from an exponential distribution with a mean of 2%. (J) Glitch sizes/skips were sampled from a uniform distribution ranging from 0 to 100. (K) Glitch rates for each set were calculated from the size/skip according to this formula: 100000
<italic>/</italic>1.6986
<sup><italic>s/</italic>10</sup>. (L) Adapter lengths were sampled from an exponential distribution with a mean of 50.</p>
        </list-item>
        <list-item>
          <p>Figure S3. Top: the target simulated depth of each replicon relative to the chromosome. The smaller the plasmid, the wider the range of possible depths. Bottom: the absolute read set of each replicon after read simulation.</p>
        </list-item>
        <list-item>
          <p>Figure S4. Commands used for each of the eight assemblers tested.</p>
        </list-item>
        <list-item>
          <p>Figure S5. Possible states for the assembly of a circular replicon. Reference sequences are shown in the inner circles in black and aligned contig sequences are shown in the outer circles in colour (red at the contig start to violet at the contig end). (A) Complete assembly with perfect circularisation. (B) Complete assembly but with missing bases leading to a gapped circularisation. (C) Complete assembly but with duplicated bases leading to overlapping circularisation. (D) Incomplete assembly due to fragmentation (multiple contigs per replicon). (E) Incomplete assembly due to missing sequence. (F) Incomplete assembly due to misassembly (noncontiguous sequence in the contig).</p>
        </list-item>
        <list-item>
          <p>Figure S6. Reference triplication for assembly assessment. (A) Due to the ambiguous starting position of a circular replicon, a completely-assembled contig will typically not align to the reference in a single unbroken alignment. (B) Doubling the reference sequence will allow for a single alignment, regardless of starting position. (C) However, if the contig contains start/end overlap (i.e. contiguity &gt;100%) then even a doubled reference may not be sufficient to achieve a single alignment, depending on the starting position. (D) A tripled reference allows for an unbroken alignment, regardless of starting position, even in cases of &gt;100% contiguity.</p>
        </list-item>
        <list-item>
          <p>Figure S7. Contiguity of the simulated read set assemblies plotted against Badread parameters for each of the tested assemblers. These plots show how well the assemblers tolerate different problems in the read sets. (A) Mean read depth (higher is better). (B) Max read identity (higher is better). (C) N50 read length (higher is better). (D) The sum of random read rate and junk read rate (lower is better). (E) Chimeric read rate (lower is better). (F) Adapter sequence length (lower is better). (G) Glitch size/skip (lower is better).</p>
        </list-item>
        <list-item>
          <p>Figure S8. Plasmid completion for the simulated read set assemblies for each of the tested assemblers, plotted with plasmid length and read depth. Solid dots indicate completely assembled plasmids (contiguity
<italic>≥</italic>99%) while open dots indicate incomplete plasmids (contiguity &lt;99%). Percentages in the plot titles give the proportion of plasmids which were completely assembled.</p>
        </list-item>
        <list-item>
          <p>Figure S9. Plasmid completion for the real read set assemblies for each of the tested assemblers, plotted with plasmid length and read depth. Solid dots indicate completely assembled plasmids (contiguity
<italic>≥</italic>99%) while open dots indicate incomplete plasmids (contiguity &lt;99%). Percentages in the plot titles give the proportion of plasmids which were completely assembled.</p>
        </list-item>
      </list>
      <p>Extended data are also available on
<ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/Long-read-assembler-comparison">GitHub</ext-link>.</p>
      <p>Data are available under the terms of the
<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International license</ext-link> (CC-BY 4.0).</p>
    </sec>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>This research was supported by use of the Nectar Research Cloud, a collaborative Australian research platform supported by the National Collaborative Research Infrastructure Strategy (NCRIS).</p>
  </ack>
  <ref-list>
    <ref id="ref-1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname><given-names>EW</given-names></name></person-group>:
<article-title>A history of DNA sequence assembly.</article-title><source><italic toggle="yes">IT - Information Technology.</italic></source><year>2016</year>;<volume>58</volume>(<issue>3</issue>):<fpage>126</fpage>–<lpage>132</lpage>.
<pub-id pub-id-type="doi">10.1515/itit-2015-0047</pub-id></mixed-citation>
    </ref>
    <ref id="ref-2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gurevich</surname><given-names>A</given-names></name><name><surname>Saveliev</surname><given-names>V</given-names></name><name><surname>Vyahhi</surname><given-names>N</given-names></name><etal/></person-group>:
<article-title>QUAST: quality assessment tool for genome assemblies.</article-title><source><italic toggle="yes">Bioinformatics.</italic></source><year>2013</year>;<volume>29</volume>(<issue>8</issue>):<fpage>1072</fpage>–<lpage>1075</lpage>.
<pub-id pub-id-type="doi">10.1093/bioinformatics/btt086</pub-id><!--<pub-id pub-id-type="pmcid">3624806</pub-id>--><?supplied-pmid 23422339?><pub-id pub-id-type="pmid">23422339</pub-id></mixed-citation>
    </ref>
    <ref id="ref-3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodwin</surname><given-names>S</given-names></name><name><surname>McPherson</surname><given-names>JD</given-names></name><name><surname>McCombie</surname><given-names>WR</given-names></name></person-group>:
<article-title>Coming of age: ten years of next-generation sequencing technologies.</article-title><source><italic toggle="yes">Nat Rev Genet.</italic></source><year>2016</year>;<volume>17</volume>(<issue>6</issue>):<fpage>333</fpage>–<lpage>351</lpage>.
<pub-id pub-id-type="doi">10.1038/nrg.2016.49</pub-id><?supplied-pmid 27184599?><pub-id pub-id-type="pmid">27184599</pub-id></mixed-citation>
    </ref>
    <ref id="ref-4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Land</surname><given-names>M</given-names></name><name><surname>Hauser</surname><given-names>L</given-names></name><name><surname>Jun</surname><given-names>SR</given-names></name><etal/></person-group>:
<article-title>Insights from 20 years of bacterial genome sequencing.</article-title><source><italic toggle="yes">Funct Integr Genomics.</italic></source><year>2015</year>;<volume>15</volume>(<issue>2</issue>):<fpage>141</fpage>–<lpage>161</lpage>.
<pub-id pub-id-type="doi">10.1007/s10142-015-0433-4</pub-id><!--<pub-id pub-id-type="pmcid">4361730</pub-id>--><?supplied-pmid 25722247?><pub-id pub-id-type="pmid">25722247</pub-id></mixed-citation>
    </ref>
    <ref id="ref-5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haubold</surname><given-names>B</given-names></name><name><surname>Wiehe</surname><given-names>T</given-names></name></person-group>:
<article-title>How repetitive are genomes?</article-title><source><italic toggle="yes">BMC Bioinformatics.</italic></source><year>2006</year>;<volume>7</volume>:<fpage>541</fpage>.
<pub-id pub-id-type="doi">10.1186/1471-2105-7-541</pub-id><!--<pub-id pub-id-type="pmcid">1769404</pub-id>--><?supplied-pmid 17187668?><pub-id pub-id-type="pmid">17187668</pub-id></mixed-citation>
    </ref>
    <ref id="ref-6">
      <label>6</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kyriakidou</surname><given-names>M</given-names></name><name><surname>Tai</surname><given-names>HH</given-names></name><name><surname>Anglin</surname><given-names>NL</given-names></name><etal/></person-group>:
<article-title>Current Strategies of Polyploid Plant Genome Sequence Assembly.</article-title><source><italic toggle="yes">Front Plant Sci.</italic></source><year>2018</year>;<volume>9</volume>:<fpage>1660</fpage>.
<pub-id pub-id-type="doi">10.3389/fpls.2018.01660</pub-id><!--<pub-id pub-id-type="pmcid">6258962</pub-id>--><?supplied-pmid 30519250?><pub-id pub-id-type="pmid">30519250</pub-id></mixed-citation>
    </ref>
    <ref id="ref-7">
      <label>7</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loman</surname><given-names>NJ</given-names></name><name><surname>Quick</surname><given-names>J</given-names></name><name><surname>Simpson</surname><given-names>JT</given-names></name></person-group>:
<article-title>A complete bacterial genome assembled
<italic>de novo</italic> using only nanopore sequencing data.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2015</year>;<volume>12</volume>(<issue>8</issue>):<fpage>733</fpage>–<lpage>735</lpage>.
<pub-id pub-id-type="doi">10.1038/nmeth.3444</pub-id><?supplied-pmid 26076426?><pub-id pub-id-type="pmid">26076426</pub-id></mixed-citation>
    </ref>
    <ref id="ref-8">
      <label>8</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blin</surname><given-names>K</given-names></name></person-group>:
<article-title>Ncbi genome downloading scripts</article-title>.<year>2019</year><ext-link ext-link-type="uri" xlink:href="https://github.com/kblin/ncbi-genome-download">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-9">
      <label>9</label>
      <mixed-citation publication-type="data"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>R</given-names></name></person-group>:
<article-title>rrwick/Long-read-assembler-comparison: Add supplementary figures</article-title>.<year>2019</year><pub-id pub-id-type="doi">10.5281/zenodo.3581590</pub-id></mixed-citation>
    </ref>
    <ref id="ref-10">
      <label>10</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>RR</given-names></name><name><surname>Holt</surname><given-names>KE</given-names></name></person-group>:
<article-title>rrwick/Assembly-Dereplicator: Assembly Dereplicator v0.1.0</article-title>.<year>2019</year><pub-id pub-id-type="doi">10.5281/zenodo.3365572</pub-id></mixed-citation>
    </ref>
    <ref id="ref-11">
      <label>11</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>RR</given-names></name></person-group>:
<article-title>Badread: simulation of error-prone long reads.</article-title><source><italic toggle="yes">J Open Source Softw.</italic></source><year>2019</year>;<volume>4</volume>(<issue>36</issue>):<fpage>1316</fpage><pub-id pub-id-type="doi">10.21105/joss.01316</pub-id></mixed-citation>
    </ref>
    <ref id="ref-12">
      <label>12</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>RR</given-names></name><name><surname>Judd</surname><given-names>LM</given-names></name><name><surname>Gorrie</surname><given-names>CL</given-names></name><etal/></person-group>:
<article-title>Completing bacterial genome assemblies with multiplex MinION sequencing.</article-title><source><italic toggle="yes">Microb Genom.</italic></source><year>2017</year>;<volume>3</volume>(<issue>10</issue>):<fpage>e000132</fpage>.
<pub-id pub-id-type="doi">10.1099/mgen.0.000132</pub-id><!--<pub-id pub-id-type="pmcid">5695209</pub-id>--><?supplied-pmid 29177090?><pub-id pub-id-type="pmid">29177090</pub-id></mixed-citation>
    </ref>
    <ref id="ref-13">
      <label>13</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Maio</surname><given-names>N</given-names></name><name><surname>Shaw</surname><given-names>LP</given-names></name><name><surname>Hubbard</surname><given-names>A</given-names></name><etal/></person-group>:
<article-title>Comparison of long-read sequencing technologies in the hybrid assembly of complex bacterial genomes.</article-title><source><italic toggle="yes">Microb Genom.</italic></source><year>2019</year>;<volume>5</volume>(<issue>9</issue>):<fpage>e000294</fpage>.
<pub-id pub-id-type="doi">10.1099/mgen.0.000294</pub-id><!--<pub-id pub-id-type="pmcid">6807382</pub-id>--><?supplied-pmid 31483244?><pub-id pub-id-type="pmid">31483244</pub-id></mixed-citation>
    </ref>
    <ref id="ref-14">
      <label>14</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>RR</given-names></name><name><surname>Judd</surname><given-names>LM</given-names></name><name><surname>Gorrie</surname><given-names>CL</given-names></name><etal/></person-group>:
<article-title>Unicycler: Resolving bacterial genome assemblies from short and long sequencing reads.</article-title><source><italic toggle="yes">PLoS Comput Biol.</italic></source><year>2017</year>;<volume>13</volume>(<issue>6</issue>):<fpage>e1005595</fpage>.
<pub-id pub-id-type="doi">10.1371/journal.pcbi.1005595</pub-id><!--<pub-id pub-id-type="pmcid">5481147</pub-id>--><?supplied-pmid 28594827?><pub-id pub-id-type="pmid">28594827</pub-id></mixed-citation>
    </ref>
    <ref id="ref-15">
      <label>15</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name></person-group>:
<article-title>Minimap2: pairwise alignment for nucleotide sequences.</article-title><source><italic toggle="yes">Bioinformatics.</italic></source><year>2018</year>;<volume>34</volume>(<issue>18</issue>):<fpage>3094</fpage>–<lpage>3100</lpage>.
<pub-id pub-id-type="doi">10.1093/bioinformatics/bty191</pub-id><!--<pub-id pub-id-type="pmcid">6137996</pub-id>--><?supplied-pmid 29750242?><pub-id pub-id-type="pmid">29750242</pub-id></mixed-citation>
    </ref>
    <ref id="ref-16">
      <label>16</label>
      <mixed-citation publication-type="data"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>R</given-names></name></person-group>:
<article-title>Read sets</article-title>.<year>2019</year><pub-id pub-id-type="doi">10.26180/5df6f5d06cf04</pub-id></mixed-citation>
    </ref>
    <ref id="ref-17">
      <label>17</label>
      <mixed-citation publication-type="data"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>R</given-names></name></person-group>:
<article-title>Reference genomes</article-title>.<year>2019</year><pub-id pub-id-type="doi">10.26180/5df6e99ff3eed</pub-id></mixed-citation>
    </ref>
    <ref id="ref-18">
      <label>18</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chin</surname><given-names>CS</given-names></name><name><surname>Alexander</surname><given-names>DH</given-names></name><name><surname>Marks</surname><given-names>P</given-names></name><etal/></person-group>:
<article-title>Nonhybrid, finished microbial genome assemblies from long-read SMRT sequencing data.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2013</year>;<volume>10</volume>(<issue>6</issue>):<fpage>563</fpage>–<lpage>569</lpage>.
<pub-id pub-id-type="doi">10.1038/nmeth.2474</pub-id><?supplied-pmid 23644548?><pub-id pub-id-type="pmid">23644548</pub-id></mixed-citation>
    </ref>
    <ref id="ref-19">
      <label>19</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chin</surname><given-names>CS</given-names></name><name><surname>Peluso</surname><given-names>P</given-names></name><name><surname>Sedlazeck</surname><given-names>FJ</given-names></name><etal/></person-group>:
<article-title>Phased diploid genome assembly with single-molecule real-time sequencing.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2016</year>;<volume>13</volume>(<issue>12</issue>):<fpage>1050</fpage>–<lpage>1054</lpage>.
<pub-id pub-id-type="doi">10.1038/nmeth.4035</pub-id><!--<pub-id pub-id-type="pmcid">5503144</pub-id>--><?supplied-pmid 27749838?><pub-id pub-id-type="pmid">27749838</pub-id></mixed-citation>
    </ref>
    <ref id="ref-20">
      <label>20</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamath</surname><given-names>GM</given-names></name><name><surname>Shomorony</surname><given-names>I</given-names></name><name><surname>Xia</surname><given-names>F</given-names></name><etal/></person-group>:
<article-title>HINGE: long-read assembly achieves optimal repeat resolution.</article-title><source><italic toggle="yes">Genome Res.</italic></source><year>2017</year>;<volume>27</volume>(<issue>5</issue>):<fpage>747</fpage>–<lpage>756</lpage>.
<pub-id pub-id-type="doi">10.1101/gr.216465.116</pub-id><!--<pub-id pub-id-type="pmcid">5411769</pub-id>--><?supplied-pmid 28320918?><pub-id pub-id-type="pmid">28320918</pub-id></mixed-citation>
    </ref>
    <ref id="ref-21">
      <label>21</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname><given-names>EW</given-names></name></person-group>:
<article-title>Efficient local alignment discovery amongst noisy long reads.</article-title><source><italic toggle="yes">Lecture Notes in Computer Science.</italic></source>LNBI,<year>2014</year>;<volume>8701</volume>:<fpage>52</fpage>–<lpage>67</lpage>.
<pub-id pub-id-type="doi">10.1007/978-3-662-44753-6_5</pub-id></mixed-citation>
    </ref>
    <ref id="ref-22">
      <label>22</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimin</surname><given-names>AV</given-names></name><name><surname>Marçais</surname><given-names>G</given-names></name><name><surname>Puiu</surname><given-names>D</given-names></name><etal/></person-group>:
<article-title>The MaSuRCA genome assembler.</article-title><source><italic toggle="yes">Bioinformatics.</italic></source><year>2013</year>;<volume>29</volume>(<issue>21</issue>):<fpage>2669</fpage>–<lpage>2677</lpage>.
<pub-id pub-id-type="doi">10.1093/bioinformatics/btt476</pub-id><!--<pub-id pub-id-type="pmcid">3799473</pub-id>--><?supplied-pmid 23990416?><pub-id pub-id-type="pmid">23990416</pub-id></mixed-citation>
    </ref>
    <ref id="ref-23">
      <label>23</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koren</surname><given-names>S</given-names></name><name><surname>Walenz</surname><given-names>BP</given-names></name><name><surname>Berlin</surname><given-names>K</given-names></name><etal/></person-group>:
<article-title>Canu: scalable and accurate long-read assembly via adaptive
<italic>k</italic>-mer weighting and repeat separation.</article-title><source><italic toggle="yes">Genome Res.</italic></source><year>2017</year>;<volume>27</volume>(<issue>5</issue>):<fpage>722</fpage>–<lpage>736</lpage>.
<pub-id pub-id-type="doi">10.1101/gr.215087.116</pub-id><!--<pub-id pub-id-type="pmcid">5411767</pub-id>--><?supplied-pmid 28298431?><pub-id pub-id-type="pmid">28298431</pub-id></mixed-citation>
    </ref>
    <ref id="ref-24">
      <label>24</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname><given-names>EW</given-names></name></person-group>:
<article-title>The fragment assembly string graph.</article-title><source><italic toggle="yes">Bioinformatics.</italic></source><year>2005</year>;<volume>21 Suppl 2</volume>:<fpage>ii79</fpage>–<lpage>85</lpage>.
<pub-id pub-id-type="doi">10.1093/bioinformatics/bti1114</pub-id><?supplied-pmid 16204131?><pub-id pub-id-type="pmid">16204131</pub-id></mixed-citation>
    </ref>
    <ref id="ref-25">
      <label>25</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolmogorov</surname><given-names>M</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name><etal/></person-group>:
<article-title>Assembly of long, error-prone reads using repeat graphs.</article-title><source><italic toggle="yes">Nat Biotechnol.</italic></source><year>2019</year>;<volume>37</volume>(<issue>5</issue>):<fpage>540</fpage>–<lpage>546</lpage>.
<pub-id pub-id-type="doi">10.1038/s41587-019-0072-8</pub-id><?supplied-pmid 30936562?><pub-id pub-id-type="pmid">30936562</pub-id></mixed-citation>
    </ref>
    <ref id="ref-26">
      <label>26</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaser</surname><given-names>R</given-names></name><name><surname>Sović</surname><given-names>I</given-names></name><name><surname>Nagarajan</surname><given-names>N</given-names></name><etal/></person-group>:
<article-title>Fast and accurate
<italic>de novo</italic> genome assembly from long uncorrected reads.</article-title><source><italic toggle="yes">Genome Res.</italic></source><year>2017</year>;<volume>27</volume>(<issue>5</issue>):<fpage>737</fpage>–<lpage>746</lpage>.
<pub-id pub-id-type="doi">10.1101/gr.214270.116</pub-id><!--<pub-id pub-id-type="pmcid">5411768</pub-id>--><?supplied-pmid 28100585?><pub-id pub-id-type="pmid">28100585</pub-id></mixed-citation>
    </ref>
    <ref id="ref-27">
      <label>27</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>RR</given-names></name><name><surname>Holt</surname><given-names>Ke</given-names></name></person-group>:
<article-title>rrwick/Minipolish: Minipolish v0.1.3</article-title>.<year>2020</year><pub-id pub-id-type="doi">10.5281/zenodo.3752203</pub-id></mixed-citation>
    </ref>
    <ref id="ref-28">
      <label>28</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ying</surname><given-names>C</given-names></name><name><surname>Fan</surname><given-names>N</given-names></name><name><surname>Shang-Qian</surname><given-names>X</given-names></name><etal/></person-group>:
<article-title>Fast and accurate assembly of Nanopore reads via progressive error correction and adaptive read selection.</article-title><source><italic toggle="yes">bioRxiv.</italic></source><year>2020</year><pub-id pub-id-type="doi">10.1101/2020.02.01.930107</pub-id></mixed-citation>
    </ref>
    <ref id="ref-29">
      <label>29</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name><name><surname>Sun</surname><given-names>Z</given-names></name><etal/></person-group>:
<article-title>NextPolish: A fast and efficient genome polishing tool for long-read assembly.</article-title><source><italic toggle="yes">Bioinformatics.</italic></source><year>2020</year>;<volume>36</volume>(<issue>7</issue>):<fpage>2253</fpage>–<lpage>2255</lpage>.
<pub-id pub-id-type="doi">10.1093/bioinformatics/btz891</pub-id><!--<pub-id pub-id-type="pmcid">7004874</pub-id>--><?supplied-pmid 31778144?><pub-id pub-id-type="pmid">31778144</pub-id></mixed-citation>
    </ref>
    <ref id="ref-30">
      <label>30</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaser</surname><given-names>R</given-names></name><name><surname>Šikić</surname><given-names>M</given-names></name></person-group>:
<article-title>Yet another
<italic>de novo</italic> genome assembler.</article-title><source><italic toggle="yes">11th International Symposium on Image and Signal Processing and Analysis (ISPA).</italic></source><year>2019</year><pub-id pub-id-type="doi">10.1109/ISPA.2019.8868909</pub-id></mixed-citation>
    </ref>
    <ref id="ref-31">
      <label>31</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruan</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>H</given-names></name></person-group>:
<article-title>Fast and accurate long-read assembly with wtdbg2.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2019</year>.<year>2020</year>;<volume>17</volume>(<issue>2</issue>):<fpage>155</fpage>–<lpage>158</lpage>.
<pub-id pub-id-type="doi">10.1038/s41592-019-0669-3</pub-id><!--<pub-id pub-id-type="pmcid">7004874</pub-id>--><?supplied-pmid 31819265?><pub-id pub-id-type="pmid">31819265</pub-id></mixed-citation>
    </ref>
    <ref id="ref-32">
      <label>32</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zerbino</surname><given-names>DR</given-names></name><name><surname>Birney</surname><given-names>E</given-names></name></person-group>:
<article-title>Velvet: algorithms for
<italic>de novo</italic> short read assembly using de Bruijn graphs.</article-title><source><italic toggle="yes">Genome Res.</italic></source><year>2008</year>;<volume>18</volume>(<issue>5</issue>):<fpage>821</fpage>–<lpage>829</lpage>.
<pub-id pub-id-type="doi">10.1101/gr.074492.107</pub-id><!--<pub-id pub-id-type="pmcid">2336801</pub-id>--><?supplied-pmid 18349386?><pub-id pub-id-type="pmid">18349386</pub-id></mixed-citation>
    </ref>
    <ref id="ref-33">
      <label>33</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafin</surname><given-names>K</given-names></name><name><surname>Pesout</surname><given-names>T</given-names></name><name><surname>Lorig-Roach</surname><given-names>R</given-names></name><etal/></person-group>:
<article-title>Efficient
<italic>de novo</italic> assembly of eleven human genomes using PromethION sequencing and a novel nanopore toolkit.</article-title><source><italic toggle="yes">bioRxiv.</italic></source><year>2019</year><pub-id pub-id-type="doi">10.1101/715722</pub-id></mixed-citation>
    </ref>
    <ref id="ref-34">
      <label>34</label>
      <mixed-citation publication-type="data"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>R</given-names></name></person-group>:
<article-title>Assemblies</article-title>.<year>2019</year><pub-id pub-id-type="doi">10.26180/5df6e2864a658</pub-id></mixed-citation>
    </ref>
    <ref id="ref-35">
      <label>35</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>RR</given-names></name><name><surname>Judd</surname><given-names>LM</given-names></name><name><surname>Holt</surname><given-names>KE</given-names></name></person-group>:
<article-title>Performance of neural network basecalling tools for Oxford Nanopore sequencing.</article-title><source><italic toggle="yes">Genome Biol.</italic></source><year>2019</year>;<volume>20</volume>(<issue>1</issue>):<fpage>129</fpage>.
<pub-id pub-id-type="doi">10.1186/s13059-019-1727-y</pub-id><!--<pub-id pub-id-type="pmcid">6591954</pub-id>--><?supplied-pmid 31234903?><pub-id pub-id-type="pmid">31234903</pub-id></mixed-citation>
    </ref>
    <ref id="ref-36">
      <label>36</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>CJ</given-names></name></person-group>:
<article-title>Medaka</article-title>.<year>2019</year><ext-link ext-link-type="uri" xlink:href="https://github.com/nanoporetech/medaka">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-37">
      <label>37</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>DH</given-names></name></person-group>:
<article-title>GenomicConsensus</article-title>.<year>2019</year><ext-link ext-link-type="uri" xlink:href="https://github.com/PacificBiosciences/GenomicConsensus">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-38">
      <label>38</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wick</surname><given-names>RR</given-names></name><name><surname>Judd</surname><given-names>LM</given-names></name><name><surname>Holt</surname><given-names>KE</given-names></name></person-group>:
<article-title>August 2019 consensus accuracy update</article-title>.<year>2019</year><ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/August-2019-consensus-accuracy-update">Reference Source</ext-link></mixed-citation>
    </ref>
    <ref id="ref-39">
      <label>39</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>BJ</given-names></name><name><surname>Abeel</surname><given-names>T</given-names></name><name><surname>Shea</surname><given-names>T</given-names></name><etal/></person-group>:
<article-title>Pilon: an integrated tool for comprehensive microbial variant detection and genome assembly improvement.</article-title><source><italic toggle="yes">PLoS One.</italic></source><year>2014</year>;<volume>9</volume>(<issue>11</issue>):<fpage>e112963</fpage>.
<pub-id pub-id-type="doi">10.1371/journal.pone.0112963</pub-id><!--<pub-id pub-id-type="pmcid">4237348</pub-id>--><?supplied-pmid 25409509?><pub-id pub-id-type="pmid">25409509</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="report58116" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.24010.r58116</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Silander</surname>
          <given-names>Olin</given-names>
        </name>
        <xref ref-type="aff" rid="r58116a1">1</xref>
        <role>Referee</role>
      </contrib>
      <aff id="r58116a1"><label>1</label>School of Natural and Computational Sciences, Massey University Auckland, North Shore, New Zealand</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Silander O</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e2738" ext-link-type="doi" xlink:href="10.12688/f1000research.21782.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The authors compare six long read genome assemblers using simulated and real data (PacBio and Nanopore). They find that there is no single best method, and that each offers distinct advantages and disadvantages.</p>
    <p> I enjoyed reading this paper. It was well written and clearly presented. As I understand, the authors plan to continually update the benchmarking is a fantastic step forward and considerably improves the utility of such a publication. This should be noted more explicitly in the manuscript.</p>
    <p>
      <bold>Major comments:</bold>
      <list list-type="bullet">
        <list-item>
          <p>P.3 “Real Read Sets”. Could the authors note which fraction of the PacBio reads were CCS / HiFi reads?</p>
        </list-item>
        <list-item>
          <p>p.4 para.1: We then excluded any isolate where either hybrid assembly failed to reach completion or where there were structural differences between the two assemblies as determined by a Minimap2 alignment.</p>
          <p> I wonder if this biases the genomes that were used such that they were easier to assemble than the genomes that were left out. I do not have a big problem with this, but it could be mentioned. It would also be good to provide slightly more detail on what precisely “structural differences between the two assemblies” means - e.g. does this include large indels (size range), inversions, etc.</p>
        </list-item>
        <list-item>
          <p>P.5 para.4: Figure 1B/Figure 2B shows the chromosome contiguity values for each assembly.</p>
          <p> There are some interesting patterns in 1B and 2B. First is the large number of Shasta assemblies have precisely 100.005% contiguity (looks to be mostly ONT assemblies). I am also surprised by the sort of bimodality in 1C/2C flye assemblies (and somewhat the miniasm assemblies). I would expect an even spread, but instead it looks like some assemblies have similar to 99% identity, whereas others have ~ 2-fold lower error rate (99.5% identity, my guesstimate). Is there an explanation for either of these patterns?</p>
        </list-item>
        <list-item>
          <p>P.5 Discussion of Identity. The authors could note the level generally achieved by polishing, which for ONT I think is around 99.98% (I am sure the authors are more aware than I am).</p>
        </list-item>
      </list>
    </p>
    <p>Is the work clearly and accurately presented and does it cite the current literature?</p>
    <p>Yes</p>
    <p>If applicable, is the statistical analysis and its interpretation appropriate?</p>
    <p>Yes</p>
    <p>Are all the source data underlying the results available to ensure full reproducibility?</p>
    <p>Yes</p>
    <p>Is the study design appropriate and is the work technically sound?</p>
    <p>Yes</p>
    <p>Are the conclusions drawn adequately supported by the results?</p>
    <p>Yes</p>
    <p>Are sufficient details of methods and analysis provided to allow replication by others?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Microbial genomics and evolution, transcription, metagenomics</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
  <sub-article id="comment5428-58116" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Wick</surname>
            <given-names>Ryan</given-names>
          </name>
          <aff>Monash University, Australia</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>15</day>
        <month>4</month>
        <year>2020</year>
      </pub-date>
    </front-stub>
    <body>
      <p>We thank the reviewer for their feedback, and changes to the article will be incorporated in its next version (along with updated results for newer assemblers/versions).</p>
      <p>
        <bold>Regarding point number 1:</bold>
      </p>
      <p> None of the PacBio read sets were CCS – all were CLR. We have clarified this in the main text of the paper, noting that they are CLR reads when first introduced.</p>
      <p>
        <bold>Regarding point number 2:</bold>
      </p>
      <p> We have clarified both of these points in the text. The relevant section now reads: ‘We then excluded any isolate where either hybrid assembly failed to reach completion or where there were &gt;50 nucleotide differences between the two assemblies as determined by a Minimap2 alignment. I.e. the Illumina+ONT and Illumina+PacBio hybrid assemblies needed to be in near-perfect agreement with each other. This left six isolates for inclusion. The above process may have biased these isolates in favour of easier-to-assemble genomes, as more complex genomes would be more likely to encounter inconsistencies between the two Unicycler assemblies.’</p>
      <p>
        <bold>Regarding point number 3:</bold>
      </p>
      <p> These are indeed interesting patterns, but I can only speculate as to what the explanations are. Shasta is prone to producing ~10-15 bp of overlap in its assemblies. This may be related to the fact that Shasta operates on a reduced representation of the read sequences that is based on 10-mers. The bimodality of the Flye ONT assembly identity distribution is not as pronounced for the newer version of Flye (v2.7) but it is still there. The identity is relatively consistent within each genome (e.g. two read sets for a given genome tend to yield similar assembly identity), so I would speculate that the cause has something to do with the genome itself. E.g. perhaps the lower identity genomes have some type of DNA modification motif that is more likely to cause errors in the consensus sequence.</p>
      <p>
        <bold>Regarding point number 4:</bold>
      </p>
      <p> We have added to the text to elaborate on polished assembly identity: ‘Platform-specific post-assembly polishing tools (including Nanopolish, Medaka and Arrow) are routinely used to improve the accuracy of long-read assemblies, and these can often achieve assembly identities of &gt;99.9% for ONT read sets and &gt;99.999% for PacBio read sets (i.e. better than any of the assemblers were able to achieve on their own).’</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report58301" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.24010.r58301</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Kolmogorov</surname>
          <given-names>Mikhail</given-names>
        </name>
        <xref ref-type="aff" rid="r58301a1">1</xref>
        <role>Referee</role>
      </contrib>
      <aff id="r58301a1"><label>1</label>Department of Computer Science and Engineering, University of California San Diego, La Jolla, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>M.K. is a developer of Flye, which is benchmarked in this study among the other assemblers.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Kolmogorov M</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e2916" ext-link-type="doi" xlink:href="10.12688/f1000research.21782.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The article presents the benchmarking of the current popular long-read assemblers (Canu, Flye, Miniasm/Minipolish, Raven, Redbean and Shasta) on various prokaryotic genomes. Wick &amp; Holt have simulated 500 long-read datasets to reflect various genomic features (such as repeat length and complexity) as well as different sequencing parameters (depth, read length, sequencing artifacts etc). In addition, the authors test the assemblers on 160 real PacBio and Oxford Nanopore datasets. For each benchmarked algorithm, Wick &amp; Holt summarize the important assembly metrics, such as contiguity or base-level accuracy (measured against the corresponding references), as well as overall user experience.</p>
    <p> The manuscript is well-written, and the study design is sound. The presented benchmarks will be a valuable resource for the long-read genomics community, both for developers and users. Importantly, the authors have made all data sets and benchmarking pipelines freely available. I only have the following minor suggestions:
<list list-type="order"><list-item><p>In my view, the evaluation pipeline designed by the authors could be highlighted more in the main text. E.g. how can a developer test a different assembler using the described benchmarks? Is it quick to reproduce? What would be the resource requirements?</p></list-item><list-item><p>It would be useful to compare the pros and cons of this work with the other assembly evaluation methods (such as QUAST) in a short discussion.</p></list-item><list-item><p>On Figure 2, triangles and circles are somewhat difficult to distinguish. Is there a way to better visually separate PacBio and ONT data points (maybe color tones or background pattern)?</p></list-item><list-item><p>For the sake of completeness, it is worth mentioning the minimap2 alignment identity threshold that is used for contiguity evaluation.</p></list-item><list-item><p>DOI links to read sets and generated assemblies seem to have an unneeded space that break the URLs.</p></list-item></list>
</p>
    <p>Is the work clearly and accurately presented and does it cite the current literature?</p>
    <p>Yes</p>
    <p>If applicable, is the statistical analysis and its interpretation appropriate?</p>
    <p>Not applicable</p>
    <p>Are all the source data underlying the results available to ensure full reproducibility?</p>
    <p>Yes</p>
    <p>Is the study design appropriate and is the work technically sound?</p>
    <p>Yes</p>
    <p>Are the conclusions drawn adequately supported by the results?</p>
    <p>Yes</p>
    <p>Are sufficient details of methods and analysis provided to allow replication by others?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Bioinformatics, genomics</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
  <sub-article id="comment5427-58301" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Wick</surname>
            <given-names>Ryan</given-names>
          </name>
          <aff>Monash University, Australia</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>15</day>
        <month>4</month>
        <year>2020</year>
      </pub-date>
    </front-stub>
    <body>
      <p>We thank the reviewer for their feedback, and changes to the article will be incorporated in its next version (along with updated results for newer assemblers/versions).</p>
      <p>
        <bold>Regarding point number 1:</bold>
      </p>
      <p>We have refined the
<ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/Long-read-assembler-comparison/blob/master/scripts/assess_assembly.py">script used to assess assemblies</ext-link> to make it more generalisable and usable: command line help text and usage information at the top of the script. We have also added a mention of the script and where it can be found to the main text of the paper: ‘The script for conducting this analysis (assess_assembly.py) is available in
<italic>Extended data</italic>.’</p>
      <p>
        <bold>Regarding point number 2:</bold>
      </p>
      <p>We have added a brief comparison between our evaluation metric (contiguity) and QUAST to the main text: ‘This provides a simpler picture of assembly quality than is created by QUAST (which quantifies misassemblies and other metrics such as NG50) but is appropriate for cases where complete assembly is likely.’</p>
      <p>
        <bold>Regarding point number 3:</bold>
      </p>
      <p>We have changed the triangles for PacBio data points to X shapes, which are easier to distinguish from the circles used for ONT data points.</p>
      <p>
        <bold>Regarding point number 4:</bold>
      </p>
      <p>We have added the exact minimap2 options used to the main text of the article: ‘To encourage longer alignments, Minimap2 was run with the asm20 preset and chain elongation and banding thresholds of 10 kbp.’</p>
      <p>
        <bold>Regarding point number 5:</bold>
      </p>
      <p>We have removed the space to fix the links for these URLs.​​​​​​​</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report58113" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.24010.r58113</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Šikić</surname>
          <given-names>Mile</given-names>
        </name>
        <xref ref-type="aff" rid="r58113a2">2</xref>
        <xref ref-type="aff" rid="r58113a3">3</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8370-0891</contrib-id>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vaser</surname>
          <given-names>Robert</given-names>
        </name>
        <xref ref-type="aff" rid="r58113a1">1</xref>
        <role>Co-referee</role>
      </contrib>
      <aff id="r58113a1"><label>1</label>Department of Electronic Systems and Information Processing, Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia</aff>
      <aff id="r58113a2"><label>2</label>Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia</aff>
      <aff id="r58113a3"><label>3</label>Genome Institute of Singapore, A*STAR, Singapore</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Vaser R and Šikić M</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e3116" ext-link-type="doi" xlink:href="10.12688/f1000research.21782.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The authors present a benchmark regarding prokaryotic organisms for several state-of-the-art long-read assemblers. The comparison includes both third generation sequencing technologies with real and simulated data, assessing various assembly traits with the conclusion that no assembler is perfect. The manuscript is well written, the figures look neat and all the data is freely available online.</p>
    <p> Minor comments:
<list list-type="order"><list-item><p>Generating the assembly with a hybrid approach which is different from all benchmarked assemblers is a good approach, but is there a possibility to analyse in details datasets which have reference genomes assembled with Sanger sequencing (such as CFT073 and MGH78578 datasets used in
<bold>De Maio N, Shaw LP, Hubbard A,
<italic>et al.</italic></bold>
<sup><xref rid="rep-ref-58113-1" ref-type="bibr">1</xref></sup>)?</p></list-item><list-item><p>As minipolish is a new pipeline introduced in this paper, I would suggest describing it a bit more in detail.</p></list-item><list-item><p>Ra assembler has been published as a conference proceedings
<ext-link ext-link-type="uri" xlink:href="https://ieeexplore.ieee.org/document/8868909">here</ext-link>.</p></list-item></list>
</p>
    <p>Is the work clearly and accurately presented and does it cite the current literature?</p>
    <p>Yes</p>
    <p>If applicable, is the statistical analysis and its interpretation appropriate?</p>
    <p>Not applicable</p>
    <p>Are all the source data underlying the results available to ensure full reproducibility?</p>
    <p>Yes</p>
    <p>Is the study design appropriate and is the work technically sound?</p>
    <p>Yes</p>
    <p>Are the conclusions drawn adequately supported by the results?</p>
    <p>Yes</p>
    <p>Are sufficient details of methods and analysis provided to allow replication by others?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Sequence alignment, de novo assembly, algorithms, machine learning</p>
    <p>We confirm that we have read this submission and believe that we have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="rep-ref-58113-1">
        <label>1</label>
        <mixed-citation publication-type="journal">
:
<article-title>Comparison of long-read sequencing technologies in the hybrid assembly of complex bacterial genomes.</article-title>
<source><italic toggle="yes">Microb Genom</italic></source>.<year>2019</year>;<volume>5</volume>(<issue>9</issue>) :
<elocation-id>10.1099/mgen.0.000294</elocation-id>
<pub-id pub-id-type="doi">10.1099/mgen.0.000294</pub-id>
<?supplied-pmid 31483244?><pub-id pub-id-type="pmid">31483244</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <sub-article id="comment5426-58113" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Wick</surname>
            <given-names>Ryan</given-names>
          </name>
          <aff>Monash University, Australia</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>15</day>
        <month>4</month>
        <year>2020</year>
      </pub-date>
    </front-stub>
    <body>
      <p>We thank the reviewer for their feedback, and changes to the article will be incorporated in its next version (along with updated results for newer assemblers/versions).</p>
      <p>
        <bold>Regarding point number 1:</bold>
      </p>
      <p> We were reluctant to use Sanger-finished genomes as references for this study due to the dynamic nature of bacterial genomes. I.e. when a strain is sequenced multiple times from separate colonies and DNA extractions, there can be discrepancies between the underlying genomes. We encountered this problem when benchmarking Unicycler using public datasets for the
<italic>E. coli</italic> K-12 MG1655 genome (
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005595">10.1371/journal.pcbi.1005595</ext-link>). In that case, an insertion sequence had shifted in the genome relative to the Sanger-finished reference, causing false positive misassemblies. Scenarios such as this would be detrimental in our current study where even a single such discrepancy could seriously impact the contiguity metric we used (which requires zero misassemblies to achieve a contiguity of 100%). Instead, we opted to produce our own reference sequences (as described in the article) using De Maio et al’s single DNA extraction per isolate.</p>
      <p>
        <bold>Regarding point number 2:</bold>
      </p>
      <p> Further information on the Minipolish process is available on its GitHub page. We have now created a DOI for this repository to make a permanent digital record (
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3752203">10.5281/zenodo.3752203</ext-link>) and added it to the article’s references.</p>
      <p>
        <bold>Regarding point number 3:</bold>
      </p>
      <p> We have updated the article’s reference for Ra to the provided conference proceedings.</p>
    </body>
  </sub-article>
</sub-article>
<sub-article id="report58115" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.24010.r58115</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Salzberg</surname>
          <given-names>Steven L</given-names>
        </name>
        <xref ref-type="aff" rid="r58115a2">2</xref>
        <xref ref-type="aff" rid="r58115a3">3</xref>
        <xref ref-type="aff" rid="r58115a4">4</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8859-7432</contrib-id>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zimin</surname>
          <given-names>Aleksey</given-names>
        </name>
        <xref ref-type="aff" rid="r58115a1">1</xref>
        <role>Co-referee</role>
      </contrib>
      <aff id="r58115a1"><label>1</label>Department of Biomedical Engineering, Johns Hopkins University, Baltimore, Maryland, USA</aff>
      <aff id="r58115a2"><label>2</label>Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, Maryland, USA</aff>
      <aff id="r58115a3"><label>3</label>Department of Computer Science, Whiting School of Engineering, Johns Hopkins University, Baltimore, Maryland, USA</aff>
      <aff id="r58115a4"><label>4</label>Department of Biostatistics, Bloomberg School of Public Health, Johns Hopkins University, Baltimore, Maryland, USA</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>9</day>
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Zimin A and Salzberg SL</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e3361" ext-link-type="doi" xlink:href="10.12688/f1000research.21782.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The report is clear and concise, easy to read, and the authors' conclusions are well supported by their experimental results. The authors are to be commended for their unusual attention to reproducibility, and for making all data easily available.</p>
    <p> We just have a couple of minor suggestions:
<list list-type="order"><list-item><p>Reliability vs. robustness: the authors summarized their findings using the terms "reliability" for performance on real data sets, and "robustness" on simulated data sets. These terms might be a bit misleading to some readers. Reliability can be defined as consistent performance with good results, and robustness (in contrast) might be the ability to perform well under adverse conditions. The real data sets do vary in quality and coverage, although not as much as the simulated data. But it seems that both reliability and robustness can be evaluated on both types of data. If they want to use the term "robustness," perhaps they could also plot the number of successful assemblies (or contiguity) vs the read error rate for each assembler. In this respect, a high error rate might be considered an adverse condition.</p></list-item><list-item><p>Figure 1 is excellent, and provides a really nice summary of the performance on simulated data. However, only 1 of the programs, Flye, failed due to running out of memory, which was limited to 64 GB of RAM. Flye was otherwise one of the best performers. RAM is fairly inexpensive today, and it's not hard to find a server with &gt;64 GB. The Figure doesn't show how much more memory Flye would need, and it would be really helpful to know that. Would 128GB allow it to complete in all cases? We suggest they run those failed assemblies on a larger-memory server and report what was needed.</p><p> Another consideration here, though, is that depending on overcommit ratio and swap parameters, processes may be killed or slowed down long before they reach the 64GB physical memory limit. The impact of swap space on performance is an unknown here as well. For a clean evaluation, they should be sure (and maybe they did this, we can't tell) that swap was disabled and that the overcommit ratio was set to 97% to allow a process to use essentially all avaliable RAM.  (There's more information about memory overcommit settings
<ext-link ext-link-type="uri" xlink:href="http://engineering.pivotal.io/post/virtual_memory_settings_in_linux_-_the_problem_with_overcommit/">here</ext-link>) If swapping came into play on any of these jobs, then it would drastically increase runtime.</p></list-item></list>
</p>
    <p>Is the work clearly and accurately presented and does it cite the current literature?</p>
    <p>Yes</p>
    <p>If applicable, is the statistical analysis and its interpretation appropriate?</p>
    <p>Not applicable</p>
    <p>Are all the source data underlying the results available to ensure full reproducibility?</p>
    <p>Yes</p>
    <p>Is the study design appropriate and is the work technically sound?</p>
    <p>Yes</p>
    <p>Are the conclusions drawn adequately supported by the results?</p>
    <p>Yes</p>
    <p>Are sufficient details of methods and analysis provided to allow replication by others?</p>
    <p>Yes</p>
    <p>Reviewer Expertise:</p>
    <p>Genomics, computational biology</p>
    <p>We confirm that we have read this submission and believe that we have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
  <sub-article id="comment5425-58115" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Wick</surname>
            <given-names>Ryan</given-names>
          </name>
          <aff>Monash University, Australia</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>15</day>
        <month>4</month>
        <year>2020</year>
      </pub-date>
    </front-stub>
    <body>
      <p>We thank the reviewer for their feedback, and changes to the article will be incorporated in its next version (along with updated results for newer assemblers/versions).</p>
      <p>
        <bold>Regarding point number 1:</bold>
      </p>
      <p> Supplementary figure S7 (available
<ext-link ext-link-type="uri" xlink:href="https://github.com/rrwick/Long-read-assembler-comparison">here</ext-link>) plots assembly contiguity against many different parameters used to generate the simulated reads, including maximum read identity. This gives a more detailed look at assembler ‘robustness’ towards a number of adverse conditions. Also, in the main text where the terms ‘reliability’ and ‘robustness’ are introduced, we have clarified that the simulated read sets contain adverse conditions which are not present in the real read sets.</p>
      <p>
        <bold>Regarding point number 2:</bold>
      </p>
      <p> We have created a new virtual machine on the Nectar Research Cloud with 128 GB of RAM (the most available in that service) and all new results (including those for Flye v2.7) were run on this VM. This has prevented assemblies from failing due to lack of memory. Since the larger VM allowed all assemblies to complete, we have opted to not alter the Linux memory settings and instead use the defaults. We checked memory statistics (as reported by /usr/bin/env time -v) and saw that major page fault counts were low (usually zero, sometimes in the tens and occasionally a few hundred for Canu), so we don’t believe that memory swapping has significantly impacted performance.</p>
    </body>
  </sub-article>
</sub-article>
