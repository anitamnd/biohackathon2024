<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Genet</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Genet.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-8021</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9557156</article-id>
    <article-id pub-id-type="publisher-id">1007618</article-id>
    <article-id pub-id-type="doi">10.3389/fgene.2022.1007618</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Genetics</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep_KsuccSite: A novel deep learning method for the identification of lysine succinylation sites</article-title>
      <alt-title alt-title-type="left-running-head">Liu et al.</alt-title>
      <alt-title alt-title-type="right-running-head">
        <ext-link xlink:href="https://doi.org/10.3389/fgene.2022.1007618" ext-link-type="uri">10.3389/fgene.2022.1007618</ext-link>
      </alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Liu</surname>
          <given-names>Xin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1194521/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Lin-Lin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lu</surname>
          <given-names>Ya-Ping</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Ting</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gu</surname>
          <given-names>Xin-Yu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Liang</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/456094/overview"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Liu</surname>
          <given-names>Yong</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/717681/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Medical Informatics and Engineering</institution>, <institution>Xuzhou Medical University</institution>, <addr-line>Xuzhou</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>College of Computer Science and Technology</institution>, <institution>China University of Mining and Technology</institution>, <addr-line>Xuzhou</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Laboratory Medicine</institution>, <institution>Guangdong Provincial People’s Hospital</institution>, <institution>Guangdong Academy of Medical Sciences</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Jiangsu Center for the Collaboration and Innovation of Cancer Biotherapy</institution>, <institution>Cancer Institute</institution>, <institution>Xuzhou Medical University</institution>, <addr-line>Xuzhou</addr-line>, <addr-line>Jiangsu</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/778029/overview" ext-link-type="uri">Zhibin Lv</ext-link>, Sichuan University, China</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1027418/overview" ext-link-type="uri">Hao Lv</ext-link>, University of Electronic Science and Technology of China, China Wenzheng Bao, </p>
        <p>Xuzhou University of Technology, China</p>
      </fn>
      <corresp id="c001">*Correspondence: Xin Liu, <email>liuxin@xzhmu.edu.cn</email>; Liang Wang, <email>healthscience@foxmail.com</email>; Yong Liu, <email>liuymito@xzhmu.edu.cn</email>
</corresp>
      <fn fn-type="other">
        <p>This article was submitted to Computational Genomics, a section of the journal Frontiers in Genetics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>1007618</elocation-id>
    <history>
      <date date-type="received">
        <day>01</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>08</day>
        <month>9</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Liu, Xu, Lu, Yang, Gu, Wang and Liu.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Liu, Xu, Lu, Yang, Gu, Wang and Liu</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Identification of lysine (symbol Lys or K) succinylation (Ksucc) sites centralizes the basis for disclosing the mechanism and function of lysine succinylation modifications. Traditional experimental methods for Ksucc site ientification are often costly and time-consuming. Therefore, it is necessary to construct an efficient computational method to prediction the presence of Ksucc sites in protein sequences. In this study, we proposed a novel and effective predictor for the identification of Ksucc sites based on deep learning algorithms that was termed as Deep_KsuccSite. The predictor adopted Composition, Transition, and Distribution (CTD) Composition (CTDC), Enhanced Grouped Amino Acid Composition (EGAAC), Amphiphilic Pseudo-Amino Acid Composition (APAAC), and Embedding Encoding methods to encode peptides, then constructed three base classifiers using one-dimensional (1D) convolutional neural network (CNN) and 2D-CNN, and finally utilized voting method to get the final results. K-fold cross-validation and independent testing showed that Deep_KsuccSite could serve as an effective tool to identify Ksucc sites in protein sequences. In addition, the ablation experiment results based on voting, feature combination, and model architecture showed that Deep_KsuccSite could make full use of the information of different features to construct an effective classifier. Taken together, we developed Deep_KsuccSite in this study, which was based on deep learning algorithm and could achieved better prediction accuracy than current methods for lysine succinylation sites. The code and dataset involved in this methodological study are permanently available at the URL <ext-link xlink:href="https://github.com/flyinsky6/Deep_KsuccSite" ext-link-type="uri">https://github.com/flyinsky6/Deep_KsuccSite</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>post-translational modification</kwd>
      <kwd>lysine succinylation</kwd>
      <kwd>deep learning</kwd>
      <kwd>CNN</kwd>
      <kwd>protein</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">
          <institution-wrap>
            <institution>Jiangsu Postdoctoral Research Foundation
</institution>
            <institution-id institution-id-type="doi">10.13039/501100010011</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn001">1701062B 2017107011</award-id>
      </award-group>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1 Introduction</title>
    <p>Protein post-translational modification (PTM) is ubiquitous in various prokaryotes and eukaryotes, which also plays important roles in many biological processes involving diseases such as such as cancer, Alzheimer’s Disease (AD), and cardiovascular disease (<xref rid="B45" ref-type="bibr">Wu et al., 2019</xref>; <xref rid="B1" ref-type="bibr">Aggarwal et al., 2020</xref>; <xref rid="B38" ref-type="bibr">Ramesh et al., 2020</xref>). There currently have more than 450 known PTMs (<xref rid="B14" ref-type="bibr">Gao et al., 2020</xref>), among which phosphorylation, methylation, acetylation, succinylation, and ubiquitination have been extensively investigated. Lysine succinylation (Ksucc) is a type of newly discovered PTM, which was found to occur naturally on protein lysine residues <italic>in vivo</italic> (<xref rid="B51" ref-type="bibr">Zhang et al., 2011</xref>). Ksucc is the process in which a succinyl moiety covalently binds to lysine residues through enzymatic or nonenzymatic-dependent mechanisms. This modification adds negatively charged carboxyl groups to the modified site and neutralizes its positive charge, thus reconstructing the intra- and inter-molecule interactions, which may further affect the spatial structure of the protein and eventually lead to changes in the physicochemical properties of the modified protein (<xref rid="B51" ref-type="bibr">Zhang et al., 2011</xref>). Relevant studies have shown that Ksucc modification is widely involved in important physiological activities such as cell differentiation and cell metabolism (<xref rid="B2" ref-type="bibr">Alleyn et al., 2018</xref>), whose abnormalities are closely related to a variety of diseases, including cancer, metabolic diseases, neurological diseases. Therefore, identification of Ksucc sites is crucial to reveal its mechanisms, providing theoretical supports for the drug design and development of relevant diseases (<xref rid="B51" ref-type="bibr">Zhang et al., 2011</xref>; <xref rid="B37" ref-type="bibr">Park et al., 2013</xref>; <xref rid="B39" ref-type="bibr">Rardin et al., 2013</xref>).</p>
    <p>Both experimental and computational methods have made significant contributions to the identification of Ksucc sites. In particular, experimental methods provide a large number of first-hand data for the study of Ksucc. However, the disadvantages are that these methods are time-consuming and expensive, which no longer meet the increasing needs of the fast-pacing research (<xref rid="B10" ref-type="bibr">Doll and Burlingame, 2015</xref>). Therefore, with the development of machine learning (ML) methods and the accumulation of Ksucc experimental data, more and more attentions have been put on computational methods with a focus on deep learning (DL) algorithms (<xref rid="B17" ref-type="bibr">Hasan et al., 2019</xref>). ML based method generally includes feature representation, feature selection, and algorithm application. SuccFind is the first Ksucc predictor that incorporated amino acid composition (AAC), the composition of k-spaced amino acid pairs (CKSAAP), and evolutionary-derived information to represent each peptide segment, after which F-score as feature reduction and SVM as a classifier were used to predict Ksucc sites (<xref rid="B46" ref-type="bibr">Xu et al., 2015</xref>). Then, pSuc-Lys (<xref rid="B25" ref-type="bibr">Jia et al., 2016</xref>), succiSite (<xref rid="B20" ref-type="bibr">Hasan et al., 2016</xref>), succiSite2.0 (<xref rid="B18" ref-type="bibr">Hasan et al., 2017</xref>), and GPSuc (<xref rid="B19" ref-type="bibr">Hasan and Kurata, 2018</xref>) were indepenenlty developed to predict Ksucc sites. Both pSuc-Lys and succiSite used random forest (RF) as the classifier but they differed in feature representation. That is, pSuc-Lys used general PseAAC to formulate peptide samples, while succiSite utilized the compositions k-spaced amino acid pairs (CKSAAP), binary, and amino acid index property as feature representation. In addition, succiSite2.0 took the composition of profile-based amino acid and orthogonal binary as features. GPsuc method adopted five features to encode sequence peptides. For each feature, the Wilcoxon rank was used as feature selection and RF was utilized as a base classifier, and finally logistic regression was used to integrate the results (<xref rid="B19" ref-type="bibr">Hasan and Kurata, 2018</xref>). There are also many other feature selection algorithms such as the minimum redundancy–maximum relevance (mRMR) and sequential forward selection (SFS) that were used for the prediction of lysine succinylation sites (<xref rid="B28" ref-type="bibr">Kao et al., 2020</xref>). In terms of feature representation, in addition to the physical and chemical properties, evolutionary information and structural information were also used in PSSM-Suc (<xref rid="B8" ref-type="bibr">Dehzangi et al., 2017</xref>), SSEvol-Suc (<xref rid="B9" ref-type="bibr">Dehzangi et al., 2018</xref>) and Success (<xref rid="B33" ref-type="bibr">López et al., 2018</xref>). SSKM_Succ was developed to solve the reliability of negative samples by using K-means (<xref rid="B34" ref-type="bibr">Ning, 2020</xref>). In 2022, Jia et al. (<xref rid="B26" ref-type="bibr">Jia et al., 2022</xref>) proposed the pSuc-FFSEA model, which not only used EBGW, one-hot, AAF_ DWT also adopted CBOW and CGR to encode amino acids, and then LASSO and two-layer stacked ensemble classifiers were utilized to construct the model. Although classical machine learning methods have contributed significantly to the prediction of Ksucc sites with good interpretability, it is difficult to obtain higher-level features by simple feature engineering, which limits the performance of the models to some extent.</p>
    <p>Many deep learning-based Ksucc predictors have been proposed to further improve model performance by using their unique feature learning capabilities. Ning et al. (<xref rid="B35" ref-type="bibr">Ning et al., 2020</xref>) constructed a new tool named HybridSucc, which combined 10 types of informative features and implemented a hybrid-learning architecture by integrating deep-learning and conventional machine-learning algorithms into a single framework. <xref rid="B42" ref-type="bibr">Thapa et al. (2020</xref>) developed DeepSuccinylSite based on a convolutional neural network (CNN). <xref rid="B23" ref-type="bibr">Huang et al. (2021</xref>) proposed the LSTMCNNsucc model by combining long short-term memory (LSTM) and CNN. MDCAN_lys (<xref rid="B44" ref-type="bibr">Wang et al., 2021</xref>), which is a multilane dense convolutional attention network used the cascading model of dense convolutional block and convolutional block attention module to capture feature information at different levels. Zhang et al. (<xref rid="B49" ref-type="bibr">Zhang and Wang, 2022</xref>) constructed a mixed prediction model using ensemble learning strateg which established four basic classifiers LSTM-CNN, CNN-LSTM, LSTM, and CNN for five features of CKSAAP, ACF, BLOSUM62, AAindex, and one-hot, and then selected the classifier with the best performance for each feature, and finally integrated them. The biggest contribution of deep learning in Ksucc site prediction is that it can automatically extract high-dimensional features based on existing feature representations, and even directly extract features from amino acid sequences. Meanwhile, although the existing models have contributed much to the prediction of Ksucc sites, there is still more room for the method to be improved. In this study, we proposed a new Ksucc site predictor termed as Deep_KsuccSite, which is based on 1D-CNN, 2D-CNN, and voting methods. In this study, four representations including Enhanced Grouped Amino Acid Composition (EGAAC), the Composition of CTD (CTDC), Amphiphilic Pseudo-Amino Acid Composition (APAAC), and Embedding encoding were used to encode protein peptides. 1D-CNN and 2D-CNN were then used to construct base classifiers for 1D features and 2D features, respectively. Finally, output was obtained by voting on the results of each base classifier. In sum, we developed Deep_KsuccSite in this study, which was based on deep learning algorithm and could achieved better prediction accuracy than current methods for lysine succinylation sites. The code and dataset involved in this methodological study are permanently available at the URL <ext-link xlink:href="https://github.com/flyinsky6/Deep_KsuccSite" ext-link-type="uri">https://github.com/flyinsky6/Deep_KsuccSite</ext-link>.</p>
  </sec>
  <sec id="s2">
    <title>2 Materials and methods</title>
    <p>The direct fusion of feature information may cause mutual interference and weaken the quality of features, which in turn affects the effect of feature extraction. Therefore, in this paper, CNN was used as the base classifier of Deep_KsuccSite, that is, 2D-CNN for embedding features, and 1D-CNN for one-dimensional features such as CTDC and the combination of EGAAC and APAAC. Finally, the outputs of these three base models were voted to obtain the model output. The schematic illustration of the structure of Deep_KsuccSite method was shown in <xref rid="F1" ref-type="fig">Figure 1</xref>. The major procedures for the development of Deep_KsuccSite could be summarized as following: 1) Data collection and preprocessing that were illustrated in <xref rid="s2-1" ref-type="sec">Section 2.1</xref>; 2) Information encoding which were described in detail in <xref rid="s2-2" ref-type="sec">Section 2.2</xref>; 3) classifiers module based on deep learning described in <xref rid="s2-3" ref-type="sec">Section 2.3</xref>; 4) Performance evaluation and validation in <xref rid="s2-4" ref-type="sec">Section 2.4</xref>.</p>
    <fig position="float" id="F1">
      <label>FIGURE 1</label>
      <caption>
        <p>The overall framework of Deep_KsuccSite. The blue dashed line with arrows indicates the flow of the independent test dataset.</p>
      </caption>
      <graphic xlink:href="fgene-13-1007618-g001" position="float"/>
    </fig>
    <sec id="s2-1">
      <title>2.1 Data collection and preprocessing</title>
      <p>The Ksucc site data were downloaded from Protein Lysine Modification Database (PLMD,<ext-link xlink:href="http://plmd.biocuckoo.org/" ext-link-type="uri">http://plmd.biocuckoo.org/</ext-link>) that was dedicated to protein lysine modifications (<xref rid="B47" ref-type="bibr">Xu et al., 2017</xref>). The PLMD database contains 18,593 Ksucc sites sourced from 6,378 protein sequences across 14 different species. In this study, the <italic>Mus musculus</italic> data were used to construct our model because it had the most Ksucc sites. Then, redundant protein sequences with high similarities for each species were strictly removed using CD-HIT with a threshold value of 0.4 to ensure squence quality and reduce sequence biases (<xref rid="B24" ref-type="bibr">Huang et al., 2010</xref>). Finally, a total of 932 protein sequences including 3,342 experimentally validated Ksucc sites were obtained as positive samples, and an equal amount of data from protein sequences without Ksucc site modification was obtained as negative samples by down-sampling technique (<xref rid="s10" ref-type="sec">Supplementary Table S1</xref>). The length of each sample is L = 2N + 1, which was centered on lysine taking N amino acids to the left and right sides. For some peptides with lengths shorter than L, we filled them with pseudo-amino acids (denoted by the symbol <italic>X</italic>). The determination of the length L was described in <xref rid="s3-1" ref-type="sec">Section 3.1</xref>. We randomly select 75% of the data set as the training set and the rest adata as an independent test set, which were used to train the model and evaluate the generalization ability of the model, respectively. Finally, 5,013 training datasets and 1,671 independent test datasets were obtained.</p>
    </sec>
    <sec id="s2-2">
      <title>2.2 Information encoding</title>
      <p>In order to construct a predictive model, peptides need to be transformed into feature vectors that can be recognized by machine learning algorithms. There are many methods for the vectorization of peptides used in the field of PTM, including physicochemical properties, evolutionary information, structural information and so on. In specificity, four encoding methods are considered in this paper, namely EGAAC, CTDC, APAAC, and Embedding Encoding. The first three methods were obtained by iLearn_plus (<xref rid="B5" ref-type="bibr">Chen et al., 2020</xref>), and all of four methods were briefly described as follows.</p>
      <p>EGAAC calculates the enhanced grouped amino acid composition in a fixed-length window, sliding continuously from the N- to C-terminal of each peptide. Specifically, the 20 amino acids were classified into five categories based on different physicochemical properties (<xref rid="B31" ref-type="bibr">Lee et al., 2011</xref>): aliphatic group (g1:GAVLMI), aromatic group (g2:FYW), positive charge group (g3:KRH), negative charged group (g4:DE), uncharged group (g5:STCPNQ). The calculation formula is as follows:<disp-formula id="e1"><mml:math id="m1" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mn>5</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math><label>(1)</label></disp-formula>Where <inline-formula id="inf1"><mml:math id="m2" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of amino acids in group g within the window n, <inline-formula id="inf2"><mml:math id="m3" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the length of the window n. The fixed-length sequence window size defaults to 5 (<xref rid="B4" ref-type="bibr">Chen et al., 2018</xref>).</p>
      <p><bold>CTDC</bold> features represent the distribution patterns of amino acids for specific structural or physicochemical properties in a protein or peptide sequence. CTDC refers to the composition of CTD descriptors that are computed by the following procedures: 1) transforming amino acid sequences into sequences for structural or physicochemical properties; 2) according to Tomii and Kanehisa’s major amino acid index clustering, 20 amino acids were divided into three groups for each of the seven different physicochemical properties, detailed calculation of which could be seen in previous studies (<xref rid="B5" ref-type="bibr">Chen et al., 2020</xref>; <xref rid="B16" ref-type="bibr">Gu et al., 2020</xref>). In fact, CTDC has been successfully applied to the prediction of G protein-coupled receptors (<xref rid="B16" ref-type="bibr">Gu et al., 2020</xref>).</p>
      <p><bold>APAAC</bold> descriptor has the same form as the amino acid composition but contains more information related to the sequence order of the protein and the distribution of hydrophobic and hydrophilic amino acids along its chain.</p>
      <p><bold>Embedding Encoding</bold> method. The essence of the embedding encoding is word embedding, which is very important in the field of natural language processing (<xref rid="B15" ref-type="bibr">Grohe, 2020</xref>). It can help us find the relationship between words that are difficult to detect, and this idea is currently getting more and more attention in the protein field, because There are many analogies between amino acid sequences and natural languages. For example, sequences are regarded as sentences, and amino acids are regarded as words. Therefore, each amino acid can be vectorized by embedding representation, and finally the representation of the entire sequence can be obtained by integration. In particular, the 20 amino acid residues and one pseudo residue are first converted into integers from 0 to 20, and then a vector representation of each integer (length 21) is obtained by training through the embedding layer in Keras. Finally, each peptide is represented as a 33*21 two-dimensional matrix.</p>
    </sec>
    <sec id="s2-3">
      <title>2.3 Base classifier</title>
      <p>CNN, one of the representative algorithms of deep learning, is a feed-forward neural network with deep structure and convolution computation. Its powerful representation learning capability has led to successful applications in image processing, natural language processing, biological information, and other fields (<xref rid="B3" ref-type="bibr">Alom et al., 2019</xref>; <xref rid="B22" ref-type="bibr">Hesamian et al., 2019</xref>). According to the format of input data, CNN can be classified into 1D-CNN and 2D-CNN (<xref rid="B29" ref-type="bibr">Kiranyaz et al., 2021</xref>). In this study, two base classifiers based on 1D-CNN and 2D-CNN were constructed for different features.</p>
      <sec id="s2-3-1">
        <title>2.3.1 1D-CNN classifier</title>
        <p>Traditional 2D-CNN are specialized for processing 2D data, such as images and videos. As an alternative, 1D-CNN has been recently developed (<xref rid="B29" ref-type="bibr">Kiranyaz et al., 2021</xref>). It has been shown that 1D-CNNs outperform 2D-CNNs in processing 1D signals in certain applications, e.g., patient EEG (<xref rid="B48" ref-type="bibr">Yildirim et al., 2018</xref>), high-power circuit, power engine fault detection (<xref rid="B11" ref-type="bibr">Eren et al., 2018</xref>), etc. In this study, CTDC, EGAAC and APAAC were 1D features with dimensions of 39, 24 and 145, respectively. Taking CTDC features as an example (<xref rid="F2" ref-type="fig">Figure 2</xref>), it could be see that the positions of the 23rd, 27th, 29th, 32nd, and 34th features show obvious maximum values, and the positions of 20, 26, 28, 33, and 39 all show obvious minimum values. This suggests that they have they have good timing sequential characteristic and could thus be classified with 1D-CNN.</p>
        <fig position="float" id="F2">
          <label>FIGURE 2</label>
          <caption>
            <p>Schematic illustration of the sequence diagram of CTDC that showed the time sequence feature of the data type.</p>
          </caption>
          <graphic xlink:href="fgene-13-1007618-g002" position="float"/>
        </fig>
        <p>The structure of the 1D-CNN used in this paper mainly consisted of a Convolution Layer, a Dropout Layer, and a Fully-Connected Layer. Among them, there were 64 Convolution Layers with a step size of 2. In order to avoid overfitting, the Dropout Layer retained 40% of the connections, whilethe Fully-Connected Layer contained 32 units. Finally, the final output was calculated using the <italic>SoftMax</italic> activation function. Both convolutional and fully connected layers used rectified linear units (<italic>ReLu</italic>) as the activation function, and the optimizer was Stochastic Gradient Descent (SGD). The detailed structure and parameter settings were shown in <xref rid="T1" ref-type="table">Table 1</xref>, while the parameter range and settings of 1D-CNN were shown in <xref rid="s10" ref-type="sec">Supplementary Table S2</xref>.</p>
        <table-wrap position="float" id="T1">
          <label>TABLE 1</label>
          <caption>
            <p>Architecture and hyperparameter settings for 1D-CNN. The size column describes the kernel size of the convolutional layer, the size of the largest pooling layer, and the fully connected layer.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Layer no.</th>
                <th align="left" rowspan="1" colspan="1">Layer type</th>
                <th align="left" rowspan="1" colspan="1">Size</th>
                <th align="left" rowspan="1" colspan="1">Activation</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">0</td>
                <td align="left" rowspan="1" colspan="1">Input</td>
                <td align="left" rowspan="1" colspan="1">L</td>
                <td align="left" rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">1</td>
                <td align="left" rowspan="1" colspan="1">CONV</td>
                <td align="left" rowspan="1" colspan="1">64*2</td>
                <td align="left" rowspan="1" colspan="1">Relu</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">6</td>
                <td align="left" rowspan="1" colspan="1">Flatten</td>
                <td align="left" rowspan="1" colspan="1">—</td>
                <td align="left" rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Dropout</td>
                <td align="left" rowspan="1" colspan="1">0.4</td>
                <td align="left" rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">7</td>
                <td align="left" rowspan="1" colspan="1">Fc1</td>
                <td align="left" rowspan="1" colspan="1">32</td>
                <td align="left" rowspan="1" colspan="1">Relu</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">8</td>
                <td align="left" rowspan="1" colspan="1">Output</td>
                <td align="left" rowspan="1" colspan="1">2</td>
                <td align="left" rowspan="1" colspan="1">SoftMax</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">9</td>
                <td align="left" rowspan="1" colspan="1">Optimizer</td>
                <td align="left" rowspan="1" colspan="1">SGD</td>
                <td align="left" rowspan="1" colspan="1"/>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="s2-3-2">
        <title>2.3.2 2D-CNN classifier</title>
        <p>In this section, considering the advantages of CNN for feature extraction of 2D data such as images, 2D-CNN is used to construct a classifier for embedding encoding to reduce information loss during feature propagation, which was first proposed in previous study (<xref rid="B42" ref-type="bibr">Thapa et al., 2020</xref>). The framework of 2D-CNN was shown in <xref rid="F3" ref-type="fig">Figure 3</xref>, which included an Input Layer, a Convolution Layer, a Pooling Layer, a Dropout Layer, a Flatten Layer, a Fully-Connected Layer, and an Output Layer. In this paper, we used 17*3 and 3*3 matrices with sliding windows for convolutional operations and used <italic>ReLu</italic> as the activation function for the normalized results.</p>
        <fig position="float" id="F3">
          <label>FIGURE 3</label>
          <caption>
            <p>Schematic illustration of the architecture of the 2D-CNN, which contains an Input Layer, a Convolution Layer, a Pooling Layer, a Dropout Layer, a Flatten Layer, a Fully-Connected Layer, and an Output Llayer.</p>
          </caption>
          <graphic xlink:href="fgene-13-1007618-g003" position="float"/>
        </fig>
        <p>To improve the operation efficiency and reduce the risk of overfitting, the Maxpooling Layer and Dropout Layer were embedded in the convolution module. Since the probability distribution of all classes needs to output, the Flatten Layer achieves the transition from the Convolutional Layer to fully-connected Layer by converting the matrices generated by Convolutional Layers into a vector. If the operations of the convolution, pooling, and activation function layers are understood as mapping the original data to the feature space of the hidden layer, then the fully-connected layer plays the role of mapping the learned “distributed feature representation” to the sample marker space. Here, two fully-connected layers in our DL model, denoted as Fc1 and Fc2, had 768 and 256 neurons, respectively. <italic>ReLu</italic> was also used as the activation function. Finally, the <italic>SoftMax</italic> activation function was used in the output layer to calculate the final output. The hyperparameter settings used for each layer were shown in <xref rid="T2" ref-type="table">Table 2</xref>.</p>
        <table-wrap position="float" id="T2">
          <label>TABLE 2</label>
          <caption>
            <p>The hyperparameter settings of each 2D-CNN layer.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Layer no.</th>
                <th align="left" rowspan="1" colspan="1">Layer type</th>
                <th align="left" rowspan="1" colspan="1">Size</th>
                <th align="left" rowspan="1" colspan="1">Activation</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">0</td>
                <td align="left" rowspan="1" colspan="1">INPUT</td>
                <td align="left" rowspan="1" colspan="1">33*21</td>
                <td align="left" rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">1</td>
                <td align="left" rowspan="1" colspan="1">CONV</td>
                <td align="left" rowspan="1" colspan="1">64*17*3</td>
                <td align="left" rowspan="1" colspan="1">Relu</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">2</td>
                <td align="left" rowspan="1" colspan="1">MaxPooling</td>
                <td align="left" rowspan="1" colspan="1">2*2</td>
                <td align="left" rowspan="1" colspan="1">-</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">3</td>
                <td align="left" rowspan="1" colspan="1">CONV</td>
                <td align="left" rowspan="1" colspan="1">128*3*3</td>
                <td align="left" rowspan="1" colspan="1">Relu</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">4</td>
                <td align="left" rowspan="1" colspan="1">MaxPooling</td>
                <td align="left" rowspan="1" colspan="1">2*2</td>
                <td align="left" rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">5</td>
                <td align="left" rowspan="1" colspan="1">Dropout</td>
                <td align="left" rowspan="1" colspan="1">0.5</td>
                <td align="left" rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">6</td>
                <td align="left" rowspan="1" colspan="1">Flatten</td>
                <td align="left" rowspan="1" colspan="1">—</td>
                <td align="left" rowspan="1" colspan="1">—</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">7</td>
                <td align="left" rowspan="1" colspan="1">Fc1</td>
                <td align="left" rowspan="1" colspan="1">768</td>
                <td align="left" rowspan="1" colspan="1">Relu</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Dropout</td>
                <td align="left" rowspan="1" colspan="1">0.5</td>
                <td align="left" rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">8</td>
                <td align="left" rowspan="1" colspan="1">Fc2</td>
                <td align="left" rowspan="1" colspan="1">256</td>
                <td align="left" rowspan="1" colspan="1">Relu</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Dropout</td>
                <td align="left" rowspan="1" colspan="1">0.5</td>
                <td align="left" rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">Output</td>
                <td align="left" rowspan="1" colspan="1">2</td>
                <td align="left" rowspan="1" colspan="1">Softmax</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">9</td>
                <td align="left" rowspan="1" colspan="1">Optimizer</td>
                <td align="left" rowspan="1" colspan="1">Adam</td>
                <td align="left" rowspan="1" colspan="1"/>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
    <sec id="s2-4">
      <title>2.4 Performance evaluation</title>
      <p>To evaluate the performance of Deep_KsuccSite, we adopted several common statistical methods in this paper, including accuracy (Acc), sensitivity (Sen), precision (Pre), Matthew’s correlation coefficient (MCC) and F1 score. Detailed definitions were given below:<disp-formula id="e7"><mml:math id="m4" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><label>(2)</label></disp-formula>
<disp-formula id="e8"><mml:math id="m5" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><label>(3)</label></disp-formula>
<disp-formula id="e9"><mml:math id="m6" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><label>(4)</label></disp-formula>
<disp-formula id="e10"><mml:math id="m7" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>×</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><label>(5)</label></disp-formula>
<disp-formula id="e11"><mml:math id="m8" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><label>(6)</label></disp-formula>
</p>
      <p>Here, TP means the number of correctly predicted positive samples. TN means the number of correctly predicted negative samples. FP means the number of incorrectly predicted positive samples. FN means the number of incorrectly predicted negative samples (<xref rid="B7" ref-type="bibr">Crooks et al., 2004</xref>).</p>
      <p>When the data set is balanced, accuracy indicates the percentage of the correctly predicted outcomes in the total sample. Sen refers to the percentage of true positive samples correctly classified, Pre refers to the probability of actually being positive among all predicted positive samples, F1 is the harmonic mean of Pre and Sen, MCC is essentially a correlation coefficient describing the correlation between the actual category and the predicted category, and it takes values in the range [-1,1] (<xref rid="B13" ref-type="bibr">Forbes, 1995</xref>). In addition, the receiver operating characteristic curve (ROC) and the area under ROC curves (AUC) were also used to assess the performance. OC calculates the range of sensitivities and specificities by setting different thresholds for continuous variables, which is a composite indicator of sensitivity and specificity (<xref rid="B12" ref-type="bibr">Fawcett, 2006</xref>). The average AUC value shows the overall performance, with larger values being better (<xref rid="B32" ref-type="bibr">Lobo et al., 2008</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="results|discussion" id="s3">
    <title>3 Results and discussion</title>
    <sec id="s3-1">
      <title>3.1 Selection of window size</title>
      <p>The choice of window size has a direct impact on the performance of Deep_KsuccSite. If the window is too small, it is easy to ignore the global nature. Considering that the window with lengths greater than 40 may form structural domains and lead to model bias (<xref rid="B41" ref-type="bibr">Taylor, 1999</xref>), existing studies use windows in the range of 21–51 (<xref rid="B35" ref-type="bibr">Ning et al., 2020</xref>; <xref rid="B50" ref-type="bibr">Zhang et al., 2020</xref>; <xref rid="B53" ref-type="bibr">Zhu et al., 2020</xref>; <xref rid="B23" ref-type="bibr">Huang et al., 2021</xref>; <xref rid="B40" ref-type="bibr">Tasmia et al., 2021</xref>; <xref rid="B44" ref-type="bibr">Wang et al., 2021</xref>). Therefore, we analyzed the model performance when the length was between 21 and 39. The Acc and AUC values corresponding to the different windows of the Deep_KsuccSite on the training data set were shown in <xref rid="F4" ref-type="fig">Figure 4</xref>. It could be seen that the highest values were obtained when the window reached 33 for both AUC (81.5%) and Acc (73.8%), respectively.</p>
      <fig position="float" id="F4">
        <label>FIGURE 4</label>
        <caption>
          <p>The Acc and AUC values corresponding to different window sizes of Deep_KsuccSite on the training data set. <bold>(A)</bold> AUC corresponding to window size. <bold>(B)</bold> ACC corresponding to window size. For both of the two parameters, highest values were achieved when the window size reached to 33.</p>
        </caption>
        <graphic xlink:href="fgene-13-1007618-g004" position="float"/>
      </fig>
    </sec>
    <sec id="s3-2">
      <title>3.2 Performance evaluation and comparison</title>
      <p>To evaluate the performance of Deep_KsuccSite, 5-, 8- and 10-fold cross-validations were performed on the training dataset. The ROC curves for n-fold cross-validations were shown in <xref rid="F5" ref-type="fig">Figure 5</xref>. The results showed that the AUC values were 0.8026, 0.8149, and 0.7973 for 5-,8-, and 10-fold cross-validations, respectively. The high consistency of different cross-validation results indicated the robustness of Deep_KsuccSite.</p>
      <fig position="float" id="F5">
        <label>FIGURE 5</label>
        <caption>
          <p>The comparision ROC curves of 5-,8-,10-fold cross-validation of the Deep_KsuccSite on the training data set. Blue, red and yellow curves indicated the ROC curves of 5-,8-,10-fold cross-validation, which had AUCs of 0.8026, 0.8149, and 0.7973, respectively.</p>
        </caption>
        <graphic xlink:href="fgene-13-1007618-g005" position="float"/>
      </fig>
      <p>To verify the generalization capability of Deep_KsuccSite, the performance of Deep_KsuccSite was compared with other reported and publicly available Ksucc predictors. Although many servers or source code were released along with previous studies, only a few were available. In this study, four models were used to compare with Deep_KsuccSite, namely pSuc-FFSEA (<xref rid="B26" ref-type="bibr">Jia et al., 2022</xref>), DeepSuccinyISite (<xref rid="B42" ref-type="bibr">Thapa et al., 2020</xref>), SuccinSite (<xref rid="B20" ref-type="bibr">Hasan et al., 2016</xref>), and GPSuc (<xref rid="B19" ref-type="bibr">Hasan and Kurata, 2018</xref>). Among them, Both GPSuc and SuccinSite used Random Forest, and GPsuc developed generic and 9 species-specific Ksucc site classifiers by aggregating multiple complementary features, while SuccinSite was developed by integrating three sequence encoding methods. DeepSuccinyIsite proposed a novel embedding encoding to represent peptide segments based on CNN. Since most of the methods only provided web servers, we evaluated them on the independent test set, and the comparison results were presented in <xref rid="T3" ref-type="table">Table 3</xref>, in which the Pre of Deep_KsuccSite was only slightly lower than the Pre of DeepSuccinyIsite by 0.36%. Except for that, Deep_KsuccSite outperformed all the other methods in terms of the evaluation indices including Acc, Sen, Pre, F1, MCC, and AUC values.</p>
      <table-wrap position="float" id="T3">
        <label>TABLE 3</label>
        <caption>
          <p>Comparison of Deep_KsuccSite with existing predictors of GPSuc, SuccinSite, and DeepSuccinyIsite on the independent test data.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="left" rowspan="1" colspan="1">Acc(%)</th>
              <th align="left" rowspan="1" colspan="1">Sen(%)</th>
              <th align="left" rowspan="1" colspan="1">Pre(%)</th>
              <th align="left" rowspan="1" colspan="1">F1 (%)</th>
              <th align="left" rowspan="1" colspan="1">MCC</th>
              <th align="left" rowspan="1" colspan="1">AUC(%)</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">GPSuc (<xref rid="B19" ref-type="bibr">Hasan and Kurata, 2018</xref>)</td>
              <td align="char" char="." rowspan="1" colspan="1">51.58</td>
              <td align="char" char="." rowspan="1" colspan="1">35.05</td>
              <td align="char" char="." rowspan="1" colspan="1">52.84</td>
              <td align="char" char="." rowspan="1" colspan="1">42.14</td>
              <td align="char" char="." rowspan="1" colspan="1">4.54</td>
              <td align="left" rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">SuccinSite (<xref rid="B20" ref-type="bibr">Hasan et al., 2016</xref>)</td>
              <td align="char" char="." rowspan="1" colspan="1">56.38</td>
              <td align="char" char="." rowspan="1" colspan="1">29.31</td>
              <td align="char" char="." rowspan="1" colspan="1">64.42</td>
              <td align="char" char="." rowspan="1" colspan="1">40.29</td>
              <td align="char" char="." rowspan="1" colspan="1">16.05</td>
              <td align="left" rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DeepSuccinyIsite (<xref rid="B42" ref-type="bibr">Thapa et al., 2020</xref>)</td>
              <td align="char" char="." rowspan="1" colspan="1">69.42</td>
              <td align="char" char="." rowspan="1" colspan="1">67.84</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>70.76</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">69.27</td>
              <td align="char" char="." rowspan="1" colspan="1">38.90</td>
              <td align="char" char="." rowspan="1" colspan="1">69.44</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">pSuc-FFSEA (<xref rid="B26" ref-type="bibr">Jia et al., 2022</xref>)</td>
              <td align="char" char="." rowspan="1" colspan="1">58.93</td>
              <td align="char" char="." rowspan="1" colspan="1">37.93</td>
              <td align="char" char="." rowspan="1" colspan="1">68.75</td>
              <td align="char" char="." rowspan="1" colspan="1">48.89</td>
              <td align="char" char="." rowspan="1" colspan="1">21.47</td>
              <td align="char" char="." rowspan="1" colspan="1">59.71</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Deep_KsuccSite</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>71.87</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>77.03</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">70.40</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>73.57</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>43.85</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>78.03</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>Note: Bold number means the best value achieved for a specific parameter when compared all the methods in the table.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="s3-3">
      <title>3.3 Ablation experiments</title>
      <p>Deep_KsuccSite is a model obtained by voting on different features or feature combinations corresponding to base classifiers, so the voting strategy, feature combination method, and base classifier are all factors that affect the performance of the model, and we conduct 3 types of ablation experiments on independent test data respectively.</p>
      <sec id="s3-3-1">
        <title>3.3.1 Voting ablation experiment</title>
        <p>The Deep_KsuccSite model was obtained by voting on the three base classifiers. To demonstrate the effectiveness of voting, we compared the model performance using different voting strategies for the base classifiers separately on independent test data, and the results were shown in <xref rid="F6" ref-type="fig">Figure 6</xref> and <xref rid="s10" ref-type="sec">Supplementary Table S3</xref>. As one can see in <xref rid="F6" ref-type="fig">Figure 6</xref>, the performance of the models obtained from different voting strategies varied slightly on the independent test data. Among them, the model voting on the three models achieved the best performance in almost all evaluation metrics with 71.87%, 70.40%, 73.57%, 43.85%, and 78.03% for Acc, Pre, F1, MCC, and AUC, respectively. It was noteworthy that CTDC-based Model 1 had the best Re with a value of 82.10%.</p>
        <fig position="float" id="F6">
          <label>FIGURE 6</label>
          <caption>
            <p>Line charts of voting results for different base models on independent test data. Model 1 denoted base classifier based on CTDC, Model 2 denoted base classifier based on the combination of APAAC and EGAAC, and Model 3 denotee based classifier based on embedding encoding. <bold>(A)</bold> Voting results for different combinations of models. <bold>(B)</bold> ROC curves and AUC values for different combinations of models.</p>
          </caption>
          <graphic xlink:href="fgene-13-1007618-g006" position="float"/>
        </fig>
      </sec>
      <sec id="s3-3-2">
        <title>3.3.2 Feature combination ablation experiment</title>
        <p>Many studies improved the model performance by combining multiple features, but we speculated that direct information fusion might cause mutual interference, weakening feature quality and affecting model performance. To verify this speculation, we compared the performance of different feature combinations on independent test data, and the results were shown in <xref rid="F7" ref-type="fig">Figure 7</xref> and <xref rid="s10" ref-type="sec">Supplementary Table S4</xref>.</p>
        <fig position="float" id="F7">
          <label>FIGURE 7</label>
          <caption>
            <p>The comparison of Acc and AUC of different feature combinations based on CNN. Feature a denoted APAAC, feature b denotes CTDC, feature c denoted EGAAC, and feature d denoted embedding encoding. According to the results, the combination of a, b and c (EGAAC, APAAC and CTDC) showed the best performance.</p>
          </caption>
          <graphic xlink:href="fgene-13-1007618-g007" position="float"/>
        </fig>
        <p>As seen in <xref rid="F7" ref-type="fig">Figure 7</xref>, there was no significant correlation between the number of features and the performance. Among these feature combinations, the combination of EGAAC, APAAC and CTDC (dark blue bars in <xref rid="F7" ref-type="fig">Figure 7</xref>) had the best performance, while the performance of the combination of all four features was not outstanding and lower than many other feature combinations. Deep_KsuccSite effectively avoided this problem by selecting the best model for each class of special and then integrating the results of each model. For this reason, we compared the above optimal feature combinations with Deep_KsuccSite on independent test data, the results of which were shown in <xref rid="F8" ref-type="fig">Figure 8</xref>.</p>
        <fig position="float" id="F8">
          <label>FIGURE 8</label>
          <caption>
            <p>The comparison of best feature combinations (EGAAC, APAAC and CTDC) and Deep_KsuccSite method on independent test data. According to the results, the Deep_KsuccSite method showed consistent better performance than the best feature combinations.</p>
          </caption>
          <graphic xlink:href="fgene-13-1007618-g008" position="float"/>
        </fig>
        <p>As shown in <xref rid="F8" ref-type="fig">Figure 8</xref>, Deep_KsuccSite outperformed the best combination found in <xref rid="F7" ref-type="fig">Figure 7</xref> on all evaluation metrics, especially on the MCC index. This further confirmed that simply integrating multiple features did not fully utilize the information of each feature. Choosing the appropriate model for each feature to integrate could improve the overall performance.</p>
      </sec>
      <sec id="s3-3-3">
        <title>3.3.3 Model architecture ablation experiment</title>
        <p>As mentioned above, Deep_KsuccSite used CNN as the base classifier. To verify the effectiveness of CNN, we replaced it with SVM and LSTM. Among them, SVM is a classical machine learning model, which is good at dealing with small sample high-dimensional data and successfully applied in many PTM prediction studies (<xref rid="B27" ref-type="bibr">Ju et al., 2016</xref>; <xref rid="B6" ref-type="bibr">Chou, 2019</xref>), and LSTM is a RNN model that is good at dealing with time-series data. For the four features studied in this paper, the embedding feature needed to be vectorized into 1D features before use. The SVM classifier used kernel function, the parameters c and g were determined by five-fold cross-validation and grid search. LSTM used <italic>SoftMax</italic> as the activation function, and the remaining parameters were obtained by training. For a fair comparison, we used the same training and independent test data for these three models. Their comparison on the independent test data was shown in <xref rid="T4" ref-type="table">Table 4</xref>.</p>
        <table-wrap position="float" id="T4">
          <label>TABLE 4</label>
          <caption>
            <p>Performance of different model architectures on the independent test data.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">Acc</th>
                <th align="left" rowspan="1" colspan="1">Re</th>
                <th align="left" rowspan="1" colspan="1">Pre</th>
                <th align="left" rowspan="1" colspan="1">F1</th>
                <th align="left" rowspan="1" colspan="1">MCC</th>
                <th align="left" rowspan="1" colspan="1">AUC</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">SVM</td>
                <td align="char" char="." rowspan="1" colspan="1">67.32</td>
                <td align="char" char="." rowspan="1" colspan="1">68.67</td>
                <td align="char" char="." rowspan="1" colspan="1">67.56</td>
                <td align="char" char="." rowspan="1" colspan="1">68.11</td>
                <td align="char" char="." rowspan="1" colspan="1">34.62</td>
                <td align="char" char="." rowspan="1" colspan="1">74.26</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">LSTM</td>
                <td align="char" char="." rowspan="1" colspan="1">64.71</td>
                <td align="char" char="." rowspan="1" colspan="1">63.10</td>
                <td align="char" char="." rowspan="1" colspan="1">64.95</td>
                <td align="char" char="." rowspan="1" colspan="1">64.01</td>
                <td align="char" char="." rowspan="1" colspan="1">29.22</td>
                <td align="char" char="." rowspan="1" colspan="1">70.81</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CNN</td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>71.87</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>77.03</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>70.40</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>73.57</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>43.85</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>78.03</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn>
              <p>Note: Bold number means the best value achieved for a specific parameter when compared all the methods in the table.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>As shown in <xref rid="T4" ref-type="table">Table 4</xref>, Deep_Ksucc outperformed the model based on SVM and LSTM in all evaluation metrics, with SVM coming second, and LSTM probably being the least suitable for those features. The main reason may be that large amount of information was lost when the embedding features were directly transformed into 1D data, and also many features did not have obvious temporal characteristics, so neither SVM nor LSTM could obtain better results.</p>
      </sec>
    </sec>
    <sec id="s3-4">
      <title>3.4 Biological insights into ksucc prediction</title>
      <p>To further observe the differences between Ksucc and non-Ksucc peptides, two Sample logos with <italic>t</italic>-test (<italic>p</italic>-value &lt; 0.05) was used to analyze the frequency of sequence occurrence at each position (<xref rid="B7" ref-type="bibr">Crooks et al., 2004</xref>). As seen in <xref rid="F9" ref-type="fig">Figure 9</xref>, there was a significant difference in sequence preferences between Ksucc and non-Ksucc peptides. Aspartic acid (D), phenylalanine (F), and alanine (A) were significantly more abundant in the Ksucc peptides. Non-Ksucc amino acids were abundant in arginine (R), leucine (L), and glutamate (E). Meanwhile, lysine (K) was enriched in different positions of Ksucc and non-Ksucc peptides. Therefore, we believed that the differences between these two peptides could be used as a way to distinguish them.</p>
      <fig position="float" id="F9">
        <label>FIGURE 9</label>
        <caption>
          <p>The statistical two-sample logo analysis with <italic>t</italic>-test on the samples (<italic>p</italic>-value &lt; 0.05).</p>
        </caption>
        <graphic xlink:href="fgene-13-1007618-g009" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="s4">
    <title>4 Conclusion</title>
    <p>In this study, Deep_KsuccSite, a novel and effective predictor for predicting Ksucc sites, was developed. Considering the EGAAC, APAAC, CTDC, and Embedding Encoding of proteins, Deep_KsuccSite constructed two base classifiers based on CTDC, the combination of EAGGC and APAAC using 1D-CNN, and a base classifier based on embedding encoding using 2D-CNN, and then voted on those three base classifiers. K-fold cross-validation and independent tests showed that Deep_KsuccSite could be used as a powerful tool to assist in identifying Ksucc sites. In addition, the ablation experiment results based on voting, feature combination, and model architecture showed that Deep_KsuccSite could leverage information from different features to build an effective classifier. The code involved in this study was freely available at <ext-link xlink:href="https://github.com/flyinsky6/Deep_KsuccSite" ext-link-type="uri">https://github.com/flyinsky6/Deep_KsuccSite</ext-link>. In the future, we will carry out further research in three aspects. First of all, the introduction of more protein feature representations to the PTM prediction field, such as protein structure information, evolution information, more physical and chemical properties, etc., will be conducted. For some protein structures that have not been identified yet, we can use the prediction results of SPIDER3 (<xref rid="B21" ref-type="bibr">Heffernan et al., 2017</xref>), PSRSM (<xref rid="B52" ref-type="bibr">Zhao et al., 2020</xref>), or Nnessy (<xref rid="B30" ref-type="bibr">Krieger and Kececioglu, 2020</xref>). Secondly, advanced techniques from natural language processing (NLP) can be introduced to extract protein features, such as Transformer and Bert (<xref rid="B43" ref-type="bibr">Vaswani;, 2017</xref>). Many feature embedding methods from the NLP domain have been proved to have good applications in the bioinformatics domain, especially in feature extraction (<xref rid="B36" ref-type="bibr">Ofer et al., 2021</xref>). Finally, more effective and interpretable models will be explored in both traditional machine learning and deep learning fields in order to facilitate the understanding of the biological meanings of the prediction results.</p>
  </sec>
</body>
<back>
  <sec sec-type="data-availability" id="s5">
    <title>Data availability statement</title>
    <p>The original contributions presented in the study are included in the article/<xref rid="s10" ref-type="sec">Supplementary Material</xref>, further inquiries can be directed to the corresponding authors.</p>
  </sec>
  <sec id="s6">
    <title>Author contributions</title>
    <p>YL and XL proposed the core ideas of the project. XL, YPL, and XYG collected and processed the data, performed the experiments, and contribute to the writing of the manuscript. YL, L-LX, and TY validated the results. LW contributed to manuscript writing, data analysis and visualization, and critical review of the manuscript. All authors read and approved the final manuscript and consent to the publication of this study.</p>
  </sec>
  <sec id="s7">
    <title>Funding</title>
    <p>This research was funded by Jiangsu Postdoctoral Science Foundation (Grant Nos. 1701062B and 2017107011), the Social development project of Jiangsu Province (Grant No. BE2019644), Young Science and Technology Innovation Team of Xuzhou Medical University (Grant No. TD202001), and Jiangsu Qinglan Project (2020), Natural Science Foundation of Jiangsu Universities (Grant No. 18KJD416002).</p>
  </sec>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s9">
    <title>Publisher’s note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <sec id="s10">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fgene.2022.1007618/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fgene.2022.1007618/full#supplementary-material</ext-link>
</p>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="Table2.XLSX">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM2" position="float" content-type="local-data">
      <media xlink:href="Table3.XLSX">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM3" position="float" content-type="local-data">
      <media xlink:href="Table4.XLSX">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM4" position="float" content-type="local-data">
      <media xlink:href="Table1.XLSX">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aggarwal</surname><given-names>S.</given-names></name><name><surname>Banerjee</surname><given-names>S. K.</given-names></name><name><surname>Talukdar</surname><given-names>N. C.</given-names></name><name><surname>Yadav</surname><given-names>A. K.</given-names></name></person-group> (<year>2020</year>). <article-title>Post-translational modification crosstalk and hotspots in sirtuin interactors implicated in cardiovascular diseases</article-title>. <source>Front. Genet.</source>
<volume>11</volume>, <fpage>356</fpage>. <pub-id pub-id-type="doi">10.3389/fgene.2020.00356</pub-id>
<pub-id pub-id-type="pmid">32425973</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alleyn</surname><given-names>M.</given-names></name><name><surname>Breitzig</surname><given-names>M.</given-names></name><name><surname>Lockey</surname><given-names>R.</given-names></name><name><surname>Kolliputi</surname><given-names>N.</given-names></name></person-group> (<year>2018</year>). <article-title>The dawn of succinylation: A posttranslational modification</article-title>. <source>Am. J. Physiology-Cell Physiology</source>
<volume>314</volume> (<issue>2</issue>), <fpage>C228</fpage>–<lpage>C232</lpage>. <pub-id pub-id-type="doi">10.1152/ajpcell.00148.2017</pub-id>
</mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alom</surname><given-names>M. Z.</given-names></name><name><surname>Taha</surname><given-names>T. M.</given-names></name><name><surname>Yakopcic</surname><given-names>C.</given-names></name><name><surname>Westberg</surname><given-names>S.</given-names></name><name><surname>Sidike</surname><given-names>P.</given-names></name><name><surname>Nasrin</surname><given-names>M. S.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>A state-of-the-art survey on deep learning theory and architectures</article-title>. <source>Electronics</source>
<volume>8</volume> (<issue>3</issue>), <fpage>292</fpage>. <pub-id pub-id-type="doi">10.3390/electronics8030292</pub-id>
</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Zhao</surname><given-names>P.</given-names></name><name><surname>Li</surname><given-names>F.</given-names></name><name><surname>Leier</surname><given-names>A.</given-names></name><name><surname>Marquez-Lago</surname><given-names>T. T.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>iFeature: a Python package and web server for features extraction and selection from protein and peptide sequences</article-title>. <source>Bioinformatics</source>
<volume>34</volume> (<issue>14</issue>), <fpage>2499</fpage>–<lpage>2502</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bty140</pub-id>
<pub-id pub-id-type="pmid">29528364</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Zhao</surname><given-names>P.</given-names></name><name><surname>Li</surname><given-names>F.</given-names></name><name><surname>Marquez-Lago</surname><given-names>T. T.</given-names></name><name><surname>Leier</surname><given-names>A.</given-names></name><name><surname>Revote</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>iLearn: an integrated platform and meta-learner for feature engineering, machine-learning analysis and modeling of DNA, RNA and protein sequence data</article-title>. <source>Brief. Bioinform.</source>
<volume>21</volume> (<issue>3</issue>), <fpage>1047</fpage>–<lpage>1057</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbz041</pub-id>
<pub-id pub-id-type="pmid">31067315</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chou</surname><given-names>K.-C.</given-names></name></person-group> (<year>2019</year>). <article-title>Progresses in predicting post-translational modification</article-title>. <source>Int. J. Pept. Res. Ther.</source>
<volume>26</volume> (<issue>2</issue>), <fpage>873</fpage>–<lpage>888</lpage>. <pub-id pub-id-type="doi">10.1007/s10989-019-09893-5</pub-id>
</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crooks</surname><given-names>G. E.</given-names></name><name><surname>Hon</surname><given-names>G.</given-names></name><name><surname>Chandonia</surname><given-names>J. M.</given-names></name><name><surname>Brenner</surname><given-names>S. E.</given-names></name></person-group> (<year>2004</year>). <article-title>WebLogo: A sequence logo generator</article-title>. <source>Genome Res.</source>
<volume>14</volume> (<issue>6</issue>), <fpage>1188</fpage>–<lpage>1190</lpage>. <pub-id pub-id-type="doi">10.1101/gr.849004</pub-id>
<pub-id pub-id-type="pmid">15173120</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehzangi</surname><given-names>A.</given-names></name><name><surname>López</surname><given-names>Y.</given-names></name><name><surname>Lal</surname><given-names>S. P.</given-names></name><name><surname>Taherzadeh</surname><given-names>G.</given-names></name><name><surname>Michaelson</surname><given-names>J.</given-names></name><name><surname>Sattar</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>PSSM-Suc: Accurately predicting succinylation using position specific scoring matrix into bigram for feature extraction</article-title>. <source>J. Theor. Biol.</source>
<volume>425</volume>, <fpage>97</fpage>–<lpage>102</lpage>. <pub-id pub-id-type="doi">10.1016/j.jtbi.2017.05.005</pub-id>
<pub-id pub-id-type="pmid">28483566</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehzangi</surname><given-names>A.</given-names></name><name><surname>López</surname><given-names>Y.</given-names></name><name><surname>Lal</surname><given-names>S. P.</given-names></name><name><surname>Taherzadeh</surname><given-names>G.</given-names></name><name><surname>Sattar</surname><given-names>A.</given-names></name><name><surname>Tsunoda</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Improving succinylation prediction accuracy by incorporating the secondary structure via helix, strand and coil, and evolutionary information from profile bigrams</article-title>. <source>PLoS One</source>
<volume>13</volume> (<issue>2</issue>), <fpage>e0191900</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0191900</pub-id>
<pub-id pub-id-type="pmid">29432431</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doll</surname><given-names>S.</given-names></name><name><surname>Burlingame</surname><given-names>A. L.</given-names></name></person-group> (<year>2015</year>). <article-title>Mass spectrometry-based detection and assignment of protein posttranslational modifications</article-title>. <source>ACS Chem. Biol.</source>
<volume>10</volume> (<issue>1</issue>), <fpage>63</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1021/cb500904b</pub-id>
<pub-id pub-id-type="pmid">25541750</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eren</surname><given-names>L.</given-names></name><name><surname>Ince</surname><given-names>T.</given-names></name><name><surname>Kiranyaz</surname><given-names>S.</given-names></name></person-group> (<year>2018</year>). <article-title>A generic intelligent bearing fault diagnosis system using compact adaptive 1D CNN classifier</article-title>. <source>J. Signal Process. Syst.</source>
<volume>91</volume> (<issue>2</issue>), <fpage>179</fpage>–<lpage>189</lpage>. <pub-id pub-id-type="doi">10.1007/s11265-018-1378-3</pub-id>
</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fawcett</surname><given-names>T.</given-names></name></person-group> (<year>2006</year>). <article-title>An introduction to ROC analysis</article-title>. <source>Pattern Recognit. Lett.</source>
<volume>27</volume> (<issue>8</issue>), <fpage>861</fpage>–<lpage>874</lpage>. <pub-id pub-id-type="doi">10.1016/j.patrec.2005.10.010</pub-id>
</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forbes</surname><given-names>A. D.</given-names></name></person-group> (<year>1995</year>). <article-title>Classification-algorithm evaluation: Five performance measures based onconfusion matrices</article-title>. <source>J. Clin. Monit.</source>
<volume>11</volume> (<issue>3</issue>), <fpage>189</fpage>–<lpage>206</lpage>. <pub-id pub-id-type="doi">10.1007/BF01617722</pub-id>
<pub-id pub-id-type="pmid">7623060</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J.</given-names></name><name><surname>Shao</surname><given-names>K.</given-names></name><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Yu</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>The involvement of post-translational modifications in cardiovascular pathologies: Focus on SUMOylation, neddylation, succinylation, and prenylation</article-title>. <source>J. Mol. Cell. Cardiol.</source>
<volume>138</volume>, <fpage>49</fpage>–<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1016/j.yjmcc.2019.11.146</pub-id>
<pub-id pub-id-type="pmid">31751566</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grohe</surname><given-names>M.</given-names></name></person-group> (<year>2020</year>). <article-title>word2vec, node2vec, graph2vec, X2vec: Towards a theory of vector embeddings of structured data</article-title>. <source>Proc. 39th ACM SIGMOD-SIGACT-SIGAI Symposium Princ. Database Syst.</source>, <fpage>1</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1145/3375395.3387641</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Prediction of G Protein-Coupled receptors with CTDC extraction and MRMD2.0 dimension-reduction methods</article-title>. <source>Front. Bioeng. Biotechnol.</source>
<volume>8</volume>, <fpage>635</fpage>. <pub-id pub-id-type="doi">10.3389/fbioe.2020.00635</pub-id>
<pub-id pub-id-type="pmid">32671038</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasan</surname><given-names>M. M.</given-names></name><name><surname>Khatun</surname><given-names>M. S.</given-names></name><name><surname>Kurata</surname><given-names>H.</given-names></name></person-group> (<year>2019</year>). <article-title>Large-scale Assessment of bioinformatics tools for lysine succinylation sites</article-title>. <source>Cells</source>
<volume>8</volume> (<issue>2</issue>), <fpage>95</fpage>. <pub-id pub-id-type="doi">10.3390/cells8020095</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasan</surname><given-names>M. M.</given-names></name><name><surname>Khatun</surname><given-names>M. S.</given-names></name><name><surname>Mollah</surname><given-names>M. N. H.</given-names></name><name><surname>Yong</surname><given-names>C.</given-names></name><name><surname>Guo</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>A systematic identification of species-specific protein succinylation sites using joint element features information</article-title>. <source>Ijn</source>
<volume>Vol. 12</volume>, <fpage>6303</fpage>–<lpage>6315</lpage>. <pub-id pub-id-type="doi">10.2147/IJN.S140875</pub-id>
</mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasan</surname><given-names>M. M.</given-names></name><name><surname>Kurata</surname><given-names>H.</given-names></name></person-group> (<year>2018</year>). <article-title>GPSuc: Global prediction of generic and species-specific succinylation sites by aggregating multiple sequence features</article-title>. <source>PLoS One</source>
<volume>13</volume> (<issue>10</issue>), <fpage>e0200283</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0200283</pub-id>
<pub-id pub-id-type="pmid">30312302</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasan</surname><given-names>M. M.</given-names></name><name><surname>Yang</surname><given-names>S.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name><name><surname>Mollah</surname><given-names>M. N. H.</given-names></name></person-group> (<year>2016</year>). <article-title>SuccinSite: A computational tool for the prediction of protein succinylation sites by exploiting the amino acid patterns and properties</article-title>. <source>Mol. Biosyst.</source>
<volume>12</volume> (<issue>3</issue>), <fpage>786</fpage>–<lpage>795</lpage>. <pub-id pub-id-type="doi">10.1039/c5mb00853k</pub-id>
<pub-id pub-id-type="pmid">26739209</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffernan</surname><given-names>R.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Paliwal</surname><given-names>K.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name></person-group> (<year>2017</year>). <article-title>Capturing non-local interactions by long short-term memory bidirectional recurrent neural networks for improving prediction of protein secondary structure, backbone angles, contact numbers and solvent accessibility</article-title>. <source>Bioinformatics</source>
<volume>33</volume> (<issue>18</issue>), <fpage>2842</fpage>–<lpage>2849</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btx218</pub-id>
<pub-id pub-id-type="pmid">28430949</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesamian</surname><given-names>M. H.</given-names></name><name><surname>Jia</surname><given-names>W.</given-names></name><name><surname>He</surname><given-names>X.</given-names></name><name><surname>Kennedy</surname><given-names>P.</given-names></name></person-group> (<year>2019</year>). <article-title>Deep learning techniques for medical image segmentation: Achievements and challenges</article-title>. <source>J. Digit. Imaging</source>
<volume>32</volume> (<issue>4</issue>), <fpage>582</fpage>–<lpage>596</lpage>. <pub-id pub-id-type="doi">10.1007/s10278-019-00227-x</pub-id>
<pub-id pub-id-type="pmid">31144149</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>G.</given-names></name><name><surname>Shen</surname><given-names>Q.</given-names></name><name><surname>Zhang</surname><given-names>G.</given-names></name><name><surname>Wang</surname><given-names>P.</given-names></name><name><surname>Yu</surname><given-names>Z. G.</given-names></name></person-group> (<year>2021</year>). <article-title>LSTMCNNsucc: A bidirectional LSTM and CNN-based deep learning method for predicting lysine succinylation sites</article-title>. <source>BioMed Res. Int.</source>
<volume>2021</volume>, <fpage>1</fpage>–<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1155/2021/9923112</pub-id>
<pub-id pub-id-type="pmid">35465048</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y.</given-names></name><name><surname>Niu</surname><given-names>B.</given-names></name><name><surname>Gao</surname><given-names>Y.</given-names></name><name><surname>Fu</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>CD-HIT suite: A web server for clustering and comparing biological sequences</article-title>. <source>Bioinformatics</source>
<volume>26</volume> (<issue>5</issue>), <fpage>680</fpage>–<lpage>682</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btq003</pub-id>
<pub-id pub-id-type="pmid">20053844</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jia</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>B.</given-names></name><name><surname>Chou</surname><given-names>K. C.</given-names></name></person-group> (<year>2016</year>). <article-title>pSuc-Lys: Predict lysine succinylation sites in proteins with PseAAC and ensemble random forest approach</article-title>. <source>J. Theor. Biol.</source>
<volume>394</volume>, <fpage>223</fpage>–<lpage>230</lpage>. <pub-id pub-id-type="doi">10.1016/j.jtbi.2016.01.020</pub-id>
<pub-id pub-id-type="pmid">26807806</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jia</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>G.</given-names></name><name><surname>Qiu</surname><given-names>W.</given-names></name></person-group> (<year>2022</year>). <article-title>pSuc-FFSEA: Predicting lysine succinylation sites in proteins based on feature fusion and stacking ensemble algorithm</article-title>. <source>Front. Cell Dev. Biol.</source>
<volume>10</volume>, <fpage>894874</fpage>. <pub-id pub-id-type="doi">10.3389/fcell.2022.894874</pub-id>
<pub-id pub-id-type="pmid">35686053</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ju</surname><given-names>Z.</given-names></name><name><surname>Cao</surname><given-names>J. Z.</given-names></name><name><surname>Gu</surname><given-names>H.</given-names></name></person-group> (<year>2016</year>). <article-title>Predicting lysine phosphoglycerylation with fuzzy SVM by incorporating k-spaced amino acid pairs into Chous general PseAAC</article-title>. <source>J. Theor. Biol.</source>
<volume>397</volume>, <fpage>145</fpage>–<lpage>150</lpage>. <pub-id pub-id-type="doi">10.1016/j.jtbi.2016.02.020</pub-id>
<pub-id pub-id-type="pmid">26908349</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>H. J.</given-names></name><name><surname>Nguyen</surname><given-names>V. N.</given-names></name><name><surname>Huang</surname><given-names>K. Y.</given-names></name><name><surname>Chang</surname><given-names>W. C.</given-names></name><name><surname>Lee</surname><given-names>T. Y.</given-names></name></person-group> (<year>2020</year>). <article-title>SuccSite: Incorporating amino acid composition and informative k-spaced amino acid pairs to identify protein succinylation sites</article-title>. <source>Genomics, Proteomics Bioinforma.</source>
<volume>18</volume> (<issue>2</issue>), <fpage>208</fpage>–<lpage>219</lpage>. <pub-id pub-id-type="doi">10.1016/j.gpb.2018.10.010</pub-id>
</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiranyaz</surname><given-names>S.</given-names></name><name><surname>Avci</surname><given-names>O.</given-names></name><name><surname>Abdeljaber</surname><given-names>O.</given-names></name><name><surname>Ince</surname><given-names>T.</given-names></name><name><surname>Gabbouj</surname><given-names>M.</given-names></name><name><surname>Inman</surname><given-names>D. J.</given-names></name></person-group> (<year>2021</year>). <article-title>1D convolutional neural networks and applications: A survey</article-title>. <source>Mech. Syst. Signal Process.</source>
<volume>151</volume>, <fpage>107398</fpage>. <pub-id pub-id-type="doi">10.1016/j.ymssp.2020.107398</pub-id>
</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krieger</surname><given-names>S.</given-names></name><name><surname>Kececioglu</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Boosting the accuracy of protein secondary structure prediction through nearest neighbor search and method hybridization</article-title>. <source>Bioinformatics</source>
<volume>36</volume>, <fpage>i317</fpage>–<lpage>i325</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa336</pub-id>
<pub-id pub-id-type="pmid">32657384</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>T. Y.</given-names></name><name><surname>Lin</surname><given-names>Z. Q.</given-names></name><name><surname>Hsieh</surname><given-names>S. J.</given-names></name><name><surname>Bretana</surname><given-names>N. A.</given-names></name><name><surname>Lu</surname><given-names>C. T.</given-names></name></person-group> (<year>2011</year>). <article-title>Exploiting maximal dependence decomposition to identify conserved motifs from a group of aligned signal sequences</article-title>. <source>Bioinformatics</source>
<volume>27</volume> (<issue>13</issue>), <fpage>1780</fpage>–<lpage>1787</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btr291</pub-id>
<pub-id pub-id-type="pmid">21551145</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lobo</surname><given-names>J. M.</given-names></name><name><surname>Jiménez-Valverde</surname><given-names>A.</given-names></name><name><surname>Real</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>Auc: A misleading measure of the performance of predictive distribution models</article-title>. <source>Glob. Ecol. Biogeogr.</source>
<volume>17</volume> (<issue>2</issue>), <fpage>145</fpage>–<lpage>151</lpage>. <pub-id pub-id-type="doi">10.1111/j.1466-8238.2007.00358.x</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>López</surname><given-names>Y.</given-names></name><name><surname>Sharma</surname><given-names>A.</given-names></name><name><surname>Dehzangi</surname><given-names>A.</given-names></name><name><surname>Lal</surname><given-names>S. P.</given-names></name><name><surname>Taherzadeh</surname><given-names>G.</given-names></name><name><surname>Sattar</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Success: Evolutionary and structural properties of amino acids prove effective for succinylation site prediction</article-title>. <source>BMC Genomics</source>
<volume>19</volume>, <fpage>923</fpage>. <pub-id pub-id-type="doi">10.1186/s12864-017-4336-8</pub-id>
<pub-id pub-id-type="pmid">29363424</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ning</surname><given-names>Q.</given-names></name></person-group> (<year>2020</year>). <source>SSKM_Succ: A novel succinylation sites prediction method incorprating K-means clustering with a new semi-supervised learning algorithm</source>. <publisher-name>IEEE/ACM Trans Comput Biol Bioinform</publisher-name>. </mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ning</surname><given-names>W.</given-names></name><name><surname>Xu</surname><given-names>H.</given-names></name><name><surname>Jiang</surname><given-names>P.</given-names></name><name><surname>Cheng</surname><given-names>H.</given-names></name><name><surname>Deng</surname><given-names>W.</given-names></name><name><surname>Guo</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>HybridSucc: A hybrid-learning architecture for general and species-specific succinylation site prediction</article-title>. <source>Genomics, Proteomics Bioinforma.</source>
<volume>18</volume> (<issue>2</issue>), <fpage>194</fpage>–<lpage>207</lpage>. <pub-id pub-id-type="doi">10.1016/j.gpb.2019.11.010</pub-id>
</mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ofer</surname><given-names>D.</given-names></name><name><surname>Brandes</surname><given-names>N.</given-names></name><name><surname>Linial</surname><given-names>M.</given-names></name></person-group> (<year>2021</year>). <article-title>The language of proteins: NLP, machine learning &amp; protein sequences</article-title>. <source>Comput. Struct. Biotechnol. J.</source>
<volume>19</volume>, <fpage>1750</fpage>–<lpage>1758</lpage>. <pub-id pub-id-type="doi">10.1016/j.csbj.2021.03.022</pub-id>
<pub-id pub-id-type="pmid">33897979</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Tishkoff</surname><given-names>D. X.</given-names></name><name><surname>Peng</surname><given-names>C.</given-names></name><name><surname>Tan</surname><given-names>M.</given-names></name><name><surname>Dai</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>SIRT5-mediated lysine desuccinylation impacts diverse metabolic pathways</article-title>. <source>Mol. Cell</source>
<volume>50</volume> (<issue>6</issue>), <fpage>919</fpage>–<lpage>930</lpage>. <pub-id pub-id-type="doi">10.1016/j.molcel.2013.06.001</pub-id>
<pub-id pub-id-type="pmid">23806337</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramesh</surname><given-names>M.</given-names></name><name><surname>Gopinath</surname><given-names>P.</given-names></name><name><surname>Govindaraju</surname><given-names>T.</given-names></name></person-group> (<year>2020</year>). <article-title>Role of post‐translational modifications in alzheimer's disease</article-title>. <source>Chembiochem</source>
<volume>21</volume> (<issue>8</issue>), <fpage>1052</fpage>–<lpage>1079</lpage>. <pub-id pub-id-type="doi">10.1002/cbic.201900573</pub-id>
<pub-id pub-id-type="pmid">31863723</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rardin</surname><given-names>M. J.</given-names></name><name><surname>He</surname><given-names>W.</given-names></name><name><surname>Nishida</surname><given-names>Y.</given-names></name><name><surname>Newman</surname><given-names>J. C.</given-names></name><name><surname>Carrico</surname><given-names>C.</given-names></name><name><surname>Danielson</surname><given-names>S. R.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>SIRT5 regulates the mitochondrial lysine succinylome and metabolic networks</article-title>. <source>Cell Metab.</source>
<volume>18</volume> (<issue>6</issue>), <fpage>920</fpage>–<lpage>933</lpage>. <pub-id pub-id-type="doi">10.1016/j.cmet.2013.11.013</pub-id>
<pub-id pub-id-type="pmid">24315375</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tasmia</surname><given-names>S. A.</given-names></name><name><surname>Ahmed</surname><given-names>F. F.</given-names></name><name><surname>Mosharaf</surname><given-names>P.</given-names></name><name><surname>Hasan</surname><given-names>M.</given-names></name><name><surname>Mollah</surname><given-names>N. H.</given-names></name></person-group> (<year>2021</year>). <article-title>An improved computational prediction model for lysine succinylation sites mapping on <italic>Homo sapiens</italic> by fusing three sequence encoding schemes with the random forest classifier</article-title>. <source>Curr. Genomics</source>
<volume>22</volume> (<issue>2</issue>), <fpage>122</fpage>–<lpage>136</lpage>. <pub-id pub-id-type="doi">10.2174/1389202922666210219114211</pub-id>
<pub-id pub-id-type="pmid">34220299</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>W.</given-names></name></person-group> (<year>1999</year>). <article-title>Protein structural domain identification</article-title>. <source>Protein Eng.</source>
<volume>12</volume> (<issue>3</issue>), <fpage>203</fpage>–<lpage>216</lpage>. <pub-id pub-id-type="doi">10.1093/protein/12.3.203</pub-id>
<pub-id pub-id-type="pmid">10235621</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thapa</surname><given-names>N.</given-names></name><name><surname>Chaudhari</surname><given-names>M.</given-names></name><name><surname>McManus</surname><given-names>S.</given-names></name><name><surname>Roy</surname><given-names>K.</given-names></name><name><surname>Newman</surname><given-names>R. H.</given-names></name><name><surname>Saigo</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>DeepSuccinylSite: A deep learning based approach for protein succinylation site prediction</article-title>. <source>BMC Bioinforma.</source>
<volume>21</volume>, <fpage>63</fpage>. <pub-id pub-id-type="doi">10.1186/s12859-020-3342-z</pub-id>
</mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani;</surname><given-names>A.</given-names></name></person-group>, <article-title>Attention is all you need</article-title>, in In <source>Adv. Neural Inf. Process. Syst.</source>,. <year>2017</year>. p. <fpage>10</fpage>. </mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Zhao</surname><given-names>H.</given-names></name><name><surname>Yan</surname><given-names>Z.</given-names></name><name><surname>Zhao</surname><given-names>J.</given-names></name><name><surname>Han</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). <article-title>MDCAN-lys: A model for predicting succinylation sites based on multilane dense convolutional attention network</article-title>. <source>Biomolecules</source>
<volume>11</volume> (<issue>6</issue>), <fpage>872</fpage>. <pub-id pub-id-type="doi">10.3390/biom11060872</pub-id>
<pub-id pub-id-type="pmid">34208298</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Huang</surname><given-names>R.</given-names></name><name><surname>Yuan</surname><given-names>L.</given-names></name></person-group> (<year>2019</year>). <article-title>Crosstalk of intracellular post-translational modifications in cancer</article-title>. <source>Archives Biochem. Biophysics</source>
<volume>676</volume>, <fpage>108138</fpage>. <pub-id pub-id-type="doi">10.1016/j.abb.2019.108138</pub-id>
</mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H. D.</given-names></name><name><surname>Shi</surname><given-names>S. P.</given-names></name><name><surname>Wen</surname><given-names>P. P.</given-names></name><name><surname>Qiu</surname><given-names>J. D.</given-names></name></person-group> (<year>2015</year>). <article-title>SuccFind: A novel succinylation sites online prediction tool via enhanced characteristic strategy</article-title>. <source>Bioinformatics</source>
<volume>31</volume> (<issue>23</issue>), <fpage>btv439</fpage>–<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btv439</pub-id>
</mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Lin</surname><given-names>S.</given-names></name><name><surname>Deng</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Xue</surname><given-names>Y.</given-names></name></person-group> (<year>2017</year>). <article-title>Plmd: An updated data resource of protein lysine modifications</article-title>. <source>J. Genet. Genomics</source>
<volume>44</volume> (<issue>5</issue>), <fpage>243</fpage>–<lpage>250</lpage>. <pub-id pub-id-type="doi">10.1016/j.jgg.2017.03.007</pub-id>
<pub-id pub-id-type="pmid">28529077</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yildirim</surname><given-names>O.</given-names></name><name><surname>Plawiak</surname><given-names>P.</given-names></name><name><surname>Tan</surname><given-names>R. S.</given-names></name><name><surname>Acharya</surname><given-names>U. R.</given-names></name></person-group> (<year>2018</year>). <article-title>Arrhythmia detection using deep convolutional neural network with long duration ECG signals</article-title>. <source>Comput. Biol. Med.</source>
<volume>102</volume>, <fpage>411</fpage>–<lpage>420</lpage>. <pub-id pub-id-type="doi">10.1016/j.compbiomed.2018.09.009</pub-id>
<pub-id pub-id-type="pmid">30245122</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name></person-group> (<year>2022</year>). <article-title>A protein succinylation sites prediction method based on the hybrid architecture of LSTM network and CNN</article-title>. <source>J. Bioinform. Comput. Biol.</source>
<volume>20</volume> (<issue>2</issue>), <fpage>2250003</fpage>. <pub-id pub-id-type="doi">10.1142/S0219720022500032</pub-id>
<pub-id pub-id-type="pmid">35191361</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Qin</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>G.</given-names></name></person-group> (<year>2020</year>). <article-title>Succinylation site prediction based on protein sequences using the IFS-LightGBM (BO) model</article-title>. <source>Comput. Math. Methods Med.</source>
<volume>2020</volume>, <fpage>8858489</fpage>. <pub-id pub-id-type="doi">10.1155/2020/8858489</pub-id>
<pub-id pub-id-type="pmid">33224267</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Tan</surname><given-names>M.</given-names></name><name><surname>Xie</surname><given-names>Z.</given-names></name><name><surname>Dai</surname><given-names>L.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Zhao</surname><given-names>Y.</given-names></name></person-group> (<year>2011</year>). <article-title>Identification of lysine succinylation as a new post-translational modification</article-title>. <source>Nat. Chem. Biol.</source>
<volume>7</volume> (<issue>1</issue>), <fpage>58</fpage>–<lpage>63</lpage>. <pub-id pub-id-type="doi">10.1038/nchembio.495</pub-id>
<pub-id pub-id-type="pmid">21151122</pub-id></mixed-citation>
    </ref>
    <ref id="B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name></person-group> (<year>2020</year>). <article-title>Protein secondary structure prediction based on generative confrontation and convolutional neural network</article-title>. <source>IEEE Access</source>
<volume>8</volume>, <fpage>199171</fpage>–<lpage>199178</lpage>. <pub-id pub-id-type="doi">10.1109/access.2020.3035208</pub-id>
</mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Jia</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>F.</given-names></name><name><surname>Song</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Inspector: A lysine succinylation predictor based on edited nearest-neighbor undersampling and adaptive synthetic oversampling</article-title>. <source>Anal. Biochem.</source>
<volume>593</volume>, <fpage>113592</fpage>. <pub-id pub-id-type="doi">10.1016/j.ab.2020.113592</pub-id>
<pub-id pub-id-type="pmid">31968210</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
