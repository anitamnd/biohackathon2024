<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6597584</article-id>
    <article-id pub-id-type="publisher-id">10668</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-019-10668-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title><italic>MorphoNet</italic>: an interactive online morphological browser to explore complex multi-scale data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Leggio</surname>
          <given-names>Bruno</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Laussu</surname>
          <given-names>Julien</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Carlier</surname>
          <given-names>Axel</given-names>
        </name>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Godin</surname>
          <given-names>Christophe</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4925-2009</contrib-id>
        <name>
          <surname>Lemaire</surname>
          <given-names>Patrick</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Faure</surname>
          <given-names>Emmanuel</given-names>
        </name>
        <address>
          <email>emmanuel.faure@lirmm.fr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 0141</institution-id><institution-id institution-id-type="GRID">grid.121334.6</institution-id><institution>Centre de Recherche de Biologie cellulaire de Montpellier (CRBM), </institution><institution>Univ Montpellier, CNRS, </institution></institution-wrap>Montpellier, 34293 France </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2175 9188</institution-id><institution-id institution-id-type="GRID">grid.15140.31</institution-id><institution>Laboratoire Reproduction et Développement des Plantes (LRDP), </institution><institution>Univ Lyon, ENS de Lyon, UCB Lyon 1, CNRS, INRA, Inria, </institution></institution-wrap>Lyon, 69342 France </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 0141</institution-id><institution-id institution-id-type="GRID">grid.121334.6</institution-id><institution>Institut de Biologie Computationnelle (IBC), </institution><institution>Univ Montpellier, </institution></institution-wrap>Montpellier, 34095 France </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0723 035X</institution-id><institution-id institution-id-type="GRID">grid.15781.3a</institution-id><institution>Informatics Research Institute of Toulouse (IRIT), </institution><institution>CNRS, INPT, ENSEEIHT, University of Toulouse I and III, </institution></institution-wrap>Toulouse, 31062 France </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 0141</institution-id><institution-id institution-id-type="GRID">grid.121334.6</institution-id><institution>Laboratoire d’Informatique de Robotique et de Microélectronique de Montpellier (LIRMM), </institution><institution>Univ Montpellier, CNRS, </institution></institution-wrap>Montpellier, 34095 France </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>6</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>6</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>2812</elocation-id>
    <history>
      <date date-type="received">
        <day>1</day>
        <month>8</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>5</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Powerful novel imaging and image-processing methods are revolutionizing many fields of biology, at scales ranging from the molecule to the functional organ. To support this big-data revolution, we develop a concept of generic web-based morphodynamic browser to interactively visualize complex image datasets, with applications in research and education. MorphoNet handles a broad range of natural or simulated morphological data, onto which quantitative geometric or genetic data can be projected.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Most morphological visualization platforms are not designed to share research data, or are limited to data visualization. Here the authors present MorphoNet, an open-source, web-based tool for interactive visualization and sharing of complex morphodynamic datasets, onto which users can project their own data.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Computational platforms and environments</kwd>
      <kwd>Software</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100001665</institution-id>
            <institution>Agence Nationale de la Recherche (French National Research Agency)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>ANR-11-BINF-0002</award-id>
        <award-id>ANR-14-CE11-0013</award-id>
        <principal-award-recipient>
          <name>
            <surname>Leggio</surname>
            <given-names>Bruno</given-names>
          </name>
          <name>
            <surname>Laussu</surname>
            <given-names>Julien</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">Over the past 20 years, the exploration of biological shapes across time, space, and scales has benefited from the emergence and refinement of novel imaging technologies<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, including IRM tomography, CT scans, cryoelectron microscopy and tomography, and light-sheet imaging<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. These technologies, coupled with the development of fluorescent markers for cell compartments and of biosensors<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, reveal both the geometry of imaged specimens and their function. High-resolution data from living<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, fixed<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> or fossilized<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> material can now be produced, collectively bridging scales from the entire organism to single cells or even molecules, and revolutionizing fields as diverse as functional brain imaging and neuronal connectivity<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, paleontology<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> or morphogenesis<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. In the field of developmental biology, the dynamics of the 3D shape, position, interaction and function of single cells, as well as cellular arrangements in different embryonic<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>, larval<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> and adult<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> tissues are now accessible, redefining the horizons of modern morphometrics.</p>
    <p id="Par4">This burst of massive complex data brings forward the need for multidisciplinary approaches, unified formats and sharing environments for their quantitative exploitation. This situation shares numerous analogies with the next-generation sequencing revolution. Enormous amounts of genetic data were produced, which required the development of novel intuitive and interactive visualization tools, the web-based genomic browsers<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, to share, integrate and facilitate the human interpretation of genomic data across large scientific communities. Genomic browsers use genome assemblies as the basic framework onto which a variety of qualitative or quantitative pieces of information, at scales ranging from the single base to multi-megabase-sized chromosomal domains, can be projected.</p>
    <p id="Par5">There is currently no generic tool in the imaging field matching the power, generality and intuitiveness of genomic browsers. Existing morphological visualization platforms, either academic (e.g., OpenWorm<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, BodyParts3D<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, FPBioimage<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, Fiji<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, Icy<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>, MorphoGraphX<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>, and EmbryoMiner<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>) or commercial (Amira, Imaris, etc…) allow users to interact with specific datasets, within the context of precise scientific questions. Compared to genomic browsers, these platforms have three major limitations. First, they are not designed to integrate the user’s data with external sources: none offers the possibility to project external quantitative/genetic information onto morphological datasets. Second, they are primarily designed as local analysis tools, and can hardly be used to share research data within and across scientific communities. Finally, the development of these tools requires the maintenance of a software which needs to be installed on different machines and with different operating systems who themselves evolve in time. This needs a long-term intensive plan of software maintenance, which may not be compatible with the limited resources available in the context of specific research projects, with the risk of rapid obsolescence.</p>
    <p id="Par6">Web-based morphological databases exist (MorphoSource, Phenome10k, MorphoMuseum, DataDryad), some of which come together with an online data visualization interface. However, the set of user interactions with the dataset is much more limited, and no additional information can be uploaded to and/or projected onto the dataset.</p>
    <p id="Par7">The open-source web-based tool presented here (<ext-link ext-link-type="uri" xlink:href="http://www.morphonet.org">http://www.morphonet.org</ext-link>) shows that the exploration and analysis of diverse large-scale imaging datasets can be used for a conceptually analogous philosophy to that which presided over the development of generic web-based genome browsers. MorphoNet allows the interactive visualization and sharing of complex morphodynamic datasets, onto which quantitative and qualitative information can be projected. Central to the concept is the definition of a unified, human-readable data format. In this sense, one could refer to MorphoNet as a morphodynamic browser.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>Conception of a morphodynamic web browser</title>
      <p id="Par8">The first challenge was to compress massive fixed or live imaging datasets sufficiently to allow their visualization and interaction through the web. While raw microscopy images and their volume segmentations are too voluminous to be visualized online, segmented images are objects-based structures that can be highly compressed into surface meshes<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, without significant loss of shape information. MorphoNet then renders such collection of meshes using the Unity3D gaming engine, which runs on standard internet browsers and exploits the recent power of the WebGL. An intuitive, user-friendly web browser-based graphical user interface was developed to control the interaction with any dataset uploaded and stored in a common database (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). To speed up rendering and visualization of cloud-stored datasets, including hundreds to thousands of objects, the level of details of the meshes can be set by the user. In such a way, complex 2D or 3D morphological datasets, at a single time point or across time series can easily be handled and shared. The whole open source code of MorphoNet and related documentation are available on a GitLab at <ext-link ext-link-type="uri" xlink:href="https://gitlab.inria.fr/efaure/morpholab">https://gitlab.inria.fr/efaure/morpholab</ext-link>.<fig id="Fig1"><label>Fig. 1</label><caption><p>MorphoNet framework and its online graphical user interface. The cloud-based structure and the use of unifying formats for both morphological datasets and related information are the key concepts of our online morphological browser</p></caption><graphic xlink:href="41467_2019_10668_Fig1_HTML" id="d29e419"/></fig></p>
      <p id="Par9">While the universal atomic unit in any genomic dataset is the DNA base pair, the atomic units vary between imaging datasets from complex organs, to cells or even subcellular structures or molecules. The choice of the scale of elementary building blocks for visualization, which depends on the scientific question, is thus left to the owner of the dataset. Figure <xref rid="Fig2" ref-type="fig">2</xref> and Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref> illustrate that MorphoNet can render and interact in exactly the same way with any object-based meshed data obtained through microscopy imaging (Fig. <xref rid="Fig2" ref-type="fig">2a, f</xref>), computer simulation (Fig. <xref rid="Fig2" ref-type="fig">2b</xref>), X-ray tomography (Fig. <xref rid="Fig2" ref-type="fig">2c</xref>) or 3D drawing (Fig. <xref rid="Fig2" ref-type="fig">2d, e</xref>) across a broad range of scales of complexity.<fig id="Fig2"><label>Fig. 2</label><caption><p>Morphological datasets and information. <bold>a</bold> Tracking of epidermal clones through several rounds of cell division in <italic>Phallusia mammillata</italic> embryo. Epidermal cells are color-coded at 64-cell stage and can hence be followed until 702-cell stage. Published data<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. <bold>b</bold> Simulation of an abstract lateral organ formation at an oryzalin-treated shoot apical meristem. Growth is simulated according to Boudon2015<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, with the wall elasticity model described in Oliveri2018<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. Strain anisotropy during growth is shown as heatmap for two time points on the left, and inner cell layers are highlighted in alternating red-yellow colors on the right. Data kindly provided by H. Oliveri. <bold>c</bold> 3D structure of a nest of termite <italic>Cubitermes</italic><sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, in which a heat map has been applied to each chamber showing the chambers’ volume distribution (red = high volume, blue = low volume). Data kindly provided by A. Perna. <bold>d</bold> Exploration of a human body atlas, in which color labels are applied corresponding to different classes of organs. Dataset can be cut to easily explore its inner structure. <bold>e</bold> Inner structure of <italic>C. elegans</italic> worm. To reveal inner organs, hypodermis layers were hidden from view. Color labeling identifies different organ groups. <bold>f</bold> Quantitative information visualization by heat map on Drosophila connectome<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, representing the distribution of number of synaptic connections for each axon. More information about these datasets can be found in the Supplementary Notes section of the <xref rid="MOESM1" ref-type="media">Supplementary Information</xref></p></caption><graphic xlink:href="41467_2019_10668_Fig2_HTML" id="d29e499"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>Genetic Information. <bold>a</bold> Gene expression profiles on ascidian embryos. The panel shows the genetic interface, with the list of ascidian genes taken directly from the online database ANISEED<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. Two expression profiles are shown in green and red at two different embryonic developmental stages, together with their overlap in blue. Data taken from ref. <sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. <bold>b</bold> Gene expression in <italic>Arabidopsis</italic> meristem. The panel shows expression domain overlaps of different genes, taken from a manually entered formatted file. Each color corresponds to a different set of genes expressed in the territory. Data kindly provided by J. Traas (unpublished)</p></caption><graphic xlink:href="41467_2019_10668_Fig3_HTML" id="d29e525"/></fig></p>
      <p id="Par10">In genomic browsers, bases are grouped into transcripts, genes or other genetic elements through the use of universally formatted files<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, that can be shared and compared within and between research networks. We likewise developed a strategy to describe biological structures as multiscale systems and to express this using hierarchies of topological and geometric objects, such as cellular complexes. First, in the case of multichannel image acquisition, MorphoNet can group and independently visualize the information present in the different channels, for example to visualize several organelles within each cell. Importantly, objects in different visualization channels can be linked and actions performed on one channels can be automatically reported on linked objects on other channels. Second, individual objects can also be grouped in space, for example to build higher-order structures, such as organs (Fig. <xref rid="Fig2" ref-type="fig">2d, e</xref>) or to identify all neighbors of an object of interest according to adjacency relationships (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>, Supplementary Movie <xref rid="MOESM4" ref-type="media">1</xref>). In the case of time series, objects can finally be grouped by their temporal ancestry, for example to track cell lineages (Fig. <xref rid="Fig2" ref-type="fig">2a</xref>).</p>
      <p id="Par11">Individual objects, as well as spatial or temporal groups, can be identified by the assignment of specific color labels, which can be propagated through time series. This offers flexibility in observing and interacting with shape changes of objects, and in exploring the processes characterizing their morphological history (Fig. <xref rid="Fig2" ref-type="fig">2a, b</xref>, Supplementary Movie <xref rid="MOESM5" ref-type="media">2</xref>). Objects and groups can be hidden or made partially transparent, either at a single time-point or throughout time series. As shown in Fig. <xref rid="Fig2" ref-type="fig">2d, e</xref>, this feature allows the exploration of internal structures within highly complex multilayered datasets such as a whole human body (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>, Supplementary Movies <xref rid="MOESM6" ref-type="media">3</xref>–<xref rid="MOESM9" ref-type="media">6</xref>).</p>
      <p id="Par12">To facilitate the interpretation of project-specific data in the context of publicly available information, genomic browsers support the upload by private users of custom datasets, such as RNA-seq or ChIP-seq, mapped onto the reference genome and which appear as individual genetic tracks. MorphoNet also supports the upload of formatted external quantitative and qualitative information, mapped onto individual objects, and which can be projected onto individual objects or groups in the form of color labels, text or heat maps (Fig. <xref rid="Fig2" ref-type="fig">2c, f</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>, Supplementary Movies <xref rid="MOESM5" ref-type="media">2</xref>–<xref rid="MOESM13" ref-type="media">10</xref>). Such morphological tracks can be saved in the cloud and shared with other users.</p>
      <p id="Par13">Among the possible morphological tracks, one of notable interest is gene expression patterns. MorphoNet offers the possibility to upload gene expression data from in situ hybridizations, cell- or tissue- specific RNAseq, Starr-seq, or chromatin signatures and to superimpose them onto a 2D or 3D scaffold as either boolean (color selections) or quantitative (heatmaps) information. This feature bridges cell-level genetic and 3D dynamic morphological information in one visualization tool, permitting the exploration of their spatio-temporal interplay (Fig. <xref rid="Fig3" ref-type="fig">3</xref>, Supplementary Movie <xref rid="MOESM12" ref-type="media">9</xref>). Genetic information can either be automatically synchronized from external databases (such as ANISEED<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>) connected to MorphoNet through their Application Programming Interfaces (APIs) (Fig. <xref rid="Fig3" ref-type="fig">3a</xref>) or uploaded manually by users in the dedicated genetic MorphoNet format, detailed in the section “Morphological information” in the Methods (Fig. <xref rid="Fig3" ref-type="fig">3b</xref>).</p>
      <p id="Par14">Finally, MorphoNet can also be used to explore population variabilities or evolutionary divergence. For instance, morphological or genetic variations within or between species or between wild-type and experimentally- or environmentally-manipulated samples can be explored in time and space through the upload of formatted comparative morphological or genetic information. Interspecies variability of relative tissue volume of developing embryos can, for instance, be pre-calculated and visualized as a heat map, to show whether it is localized on certain tissues and/or certain developmental stages. In addition averages, standard deviations, relative variations, and other relevant statistics can be calculated on quantitative properties.</p>
      <p id="Par15">A few simple calculations (average, standard deviations, normalizations) exist as built-in options in the MorphoNet interface. Due to the web-based structure of the tool, more costly calculations on the server would affect the user dynamic interaction with the dataset. However more complex calculations can be performed externally. The Morphonet Python API and ImageJ plugin provide an easy interface to upload any Python-based or ImageJ-performed calculations directly to the MorphoNet server. Otherwise, the user has always the possibility to create.txt files and upload them from the online interface.</p>
    </sec>
    <sec id="Sec4">
      <title>Potential use in research</title>
      <p id="Par16">To exemplify the use, richness, and generality of MorphoNet we provide three detailed tutorials explaining how MorphoNet can address specific needs. These tutorials can be found online at <ext-link ext-link-type="uri" xlink:href="http://www.morphonet.org/Tutorials/MorphoNet_Tutorials.php">http://www.morphonet.org/Tutorials/MorphoNet_Tutorials.php</ext-link>.</p>
      <p id="Par17">The first tutorial illustrates how to use MorphoNet to investigate dynamic biological properties of embryonic cells for the specific case of ascidian embryonic development. Thanks to its straightforward upload process, a 3D reconstruction is available on the MorphoNet server as a new dataset immediately after segmentation. MorphoNet is then used to visualize complex 3D dynamic shape changes and to select, on 3D data and though the timestack, a group of cells of interest to study (specifically, those cells whose shape changes the most during gastrulation, i.e., endodermal cells). A few lines in Python are then used to quantify the change in time of endodermal cells’ shape during gastrulation. These results are then uploaded to MorphoNet in the form of quantitative information. MorphoNet allows to project this dynamic information on the embryonic cellular scaffold and to visualize its evolution. In this way, by a simple and direct visual investigation, one can clearly see the onset of the two main shape changes involved in ascidian gastrulation, and confirm their sequentiality in time.</p>
      <p id="Par18">The second tutorial shows how to use the MorphoNet plugin for ImageJ/FiJi we have developed. It allows to use the many image analysis tools, including properties quantification, available in ImageJ and to upload the results directly to the MorphoNet cloud. Specifically, the tutorial shows how one can import a volumetric segmented image of one ascidian embryo in ImageJ, create a surface mesh with the Fiji built-in library and upload it as a new dataset to MorphoNet, together with the quantitative information about the volume of each cell in the embryo.</p>
      <p id="Par19">The third tutorial demonstrates the use of MorphoNet to help a 3D+t segmentation and cell tracking routine. It illustrates how MorphoNet and its functions can be used to correct some of the most common problems occurring during the segmentation of volumetric images, distributed in timestacks: over-segmentations of cells, under-segmentations of cells and missed temporal links between mother cells and daughter cells after cell divisions.</p>
    </sec>
  </sec>
  <sec id="Sec5" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par20">In summary, MorphoNet integrates, in one open-source online tool (<ext-link ext-link-type="uri" xlink:href="http://www.morphonet.org">http://www.morphonet.org</ext-link>), a comprehensive palette of interactions to explore the structure, dynamics and, variability of biological shapes and to confront these with genetic information. It largely profits from the most recent and well-developed web technologies and introduces a generic strategy for hierarchical representation of biological structures. We expect in the future, thanks to the contribution of large user communities, to develop the MorphoNet data and metadata formats towards standardization.</p>
    <p id="Par21">Due to the lack of unified formats for morphological data and metadata, uploading a dataset from an external database in Morphonet leads to the duplication of this dataset in a slightly different format. To reduce the impact of this reaccessionning issue, we invite Morphonet users to always provide the original dataset ID in the metadata of the uploaded copy, and to cite both MorphoNet and the original database and ID in scientific publications.</p>
    <p id="Par22">MorphoNet allows the efficient and controlled dissemination and sharing within scientific communities of public and private information, with large visibility for new discoveries. It fills a gap which has until now limited the quantitative understanding of morphodynamics and its genetic underpinnings by contributing to the creation of ever-growing atlases of morphogenesis. In addition to its research use, Morphonet is expected to give access to the public and educational professionals to the immense body of live imaging data that is increasingly made publicly available by academic institutions on open-access data repositories, thereby facilitating the dissemination of scientific knowledge across society.</p>
  </sec>
  <sec id="Sec6">
    <title>Methods</title>
    <sec id="Sec7">
      <title>MorphoNet features and functions</title>
      <p id="Par23">MorphoNet has a highly interactive interface through which users can visualize morphodynamic data and display quantitative and qualitative information.</p>
      <p id="Par24">The first public instantiation of MorphoNet is currently hosted on a secure server (<ext-link ext-link-type="uri" xlink:href="http://www.morphonet.org">http://www.morphonet.org</ext-link>). The system is portable and, as the bulk of the calculations is handled on the client side, it can be installed on any server with even modest computing power.</p>
      <p id="Par25">MorphoNet has two different types of access possibilities: registered users, whose access rights are detailed in Table <xref rid="Tab1" ref-type="table">1</xref>, and non-registered users, who can access public datasets and have visualization rights only.<table-wrap id="Tab1"><label>Table 1</label><caption><p>MorphoNet user rights</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Creator</th><th>Owner</th><th>Reader</th></tr></thead><tbody><tr><td>Can visualize meshes</td><td>X</td><td>X</td><td>X</td></tr><tr><td>Can see shared Information</td><td>X</td><td>X</td><td>X</td></tr><tr><td>Can see and delete private information</td><td>X</td><td/><td/></tr><tr><td>Can upload/download information</td><td>X</td><td>X</td><td/></tr><tr><td>Can download meshes</td><td>X</td><td>X</td><td/></tr><tr><td>Can share information</td><td>X</td><td>X</td><td/></tr><tr><td>Can grant access rights</td><td>X</td><td>X</td><td/></tr><tr><td>Can erase dataset</td><td>X</td><td/><td/></tr></tbody></table></table-wrap></p>
      <p id="Par26">A visual help web page is accessible at any time through the question mark button at the top of MorphoNet page. Supplementary Movies <xref rid="MOESM4" ref-type="media">1</xref>–<xref rid="MOESM13" ref-type="media">10</xref> provide several practical examples of use of the MorphoNet interface.</p>
      <p id="Par27">MorphoNet offers a large variety of interactive features to explore the structure and dynamics of morphological datasets. Basic dataset interactions include data rotation and translation by keyboard + mouse shortcuts, object selection by mouse clicks or keyboard + mouse shortcuts, zooming in/out through mouse actions and scrolling through timestacks by either a scrollbar or by keyboard shortcuts. All keyboard and mouse actions are explained in the navigation menu in the upper-left corner of the application screen.</p>
      <p id="Par28">In addition to these basic features, more advanced data interactions are available. These functions are grouped into 6 menus in the visual interface: Dataset, Infos, Objects, Groups, Genetic, Movie. Moreover, standard object-interaction functions are given at the bottom of the interface.</p>
      <p id="Par29">Standard object-interaction functions allow users to search specific objects or groups of objects, identified by their name or numerical ID. Once objects are picked, they can be hidden from view, either at specific time instants or throughout the timestack. User can also select all physical neighbors of any picked objects, which can be iteratively repeated to explore the structure of object adjacency.</p>
      <p id="Par30">In the Dataset menu, users can interact with the dataset as a whole. The dataset position and orientation in space can be reset to default values, and the default orientation can be set (only by dataset owner).</p>
      <p id="Par31">Dataset can be cropped along the three main axes, or along a custom direction. Users can also switch among different visualization channels, or download surface meshes or visualize adjacency and temporal lineage trees. In particular, nodes in the lineage tree are automatically linked to their corresponding objects in the dataset: any action performed on objects (such as color-labeling) is automatically reported on tree nodes.</p>
      <p id="Par32">Infos menu lists all information associated with the dataset. Information is categorized as: Selection, Quantitative, Qualitative and Genetic. Selections are color labels applied to objects (see later on about the Objects menu). Quantitative information, associated with all objects or to a selected subgroup, can be visualized as heat maps on the dataset, and its numerical value is shown for any picked object. In addition, users can manipulate quantitative information by, for instance, calculating time and space averages, mean values, standard deviations or time normalization. After such manipulation, a new entry in the Quantitative category is created, representing the outcome of the requested calculation.</p>
      <p id="Par33">Qualitative information associates a string of characters to all objects or a selected subgroup. Once one Qualitative entry is activated, the corresponding information is visualized as text superimposed on the dataset as the mouse pointer passes over the corresponding object.</p>
      <p id="Par34">Genetic information associates objects to an expression level of a specific gene. This information replaces or complements the equivalent information extracted from external genetic databases (if connected to MorphoNet). Expression level can be given as boolean (on/off) or as quantitative level. If one or more Genetic entries are activated, a Genetic menu is created and made accessible (see below).</p>
      <p id="Par35">From the Infos menu, users can also upload to the cloud text files (.txt extension) containing new information. Users also have the possibility to manually create and curate and upload new information tracks directly through the visual online interface. All the information provided can be downloaded as text files, shared with selected users, and manually curated.</p>
      <p id="Par36">Specific object interactions are possible in Objects menu. There users can apply color selections to picked objects, hide non-selected objects from view and propagate color-labeling through time along the lineage tree. This allows users to track the evolution of selected objects in time and/or to cluster groups of objects in space.</p>
      <p id="Par37">Groups gives a list of previously uploaded sets of objects of particular relevance (these can, for instance, be tissues in organs). The group structure is hierarchical, such that smaller groups can build up larger ones, highlighting the relevant morphological scales of the dataset. Users can select all objects (or subgroups) in one group and automatically apply color selections to each of them.</p>
      <p id="Par38">Genetic menu is present only if genetic expression data are provided, either by connecting MorphoNet to an external genetic database, or by uploading it through the specific genetic information format, or by a combination of the two.</p>
      <p id="Par39">The menu shows the full provided list of genes, with the gene name, the total number of objects expressing the specific gene and the possibility to color-label these objects. In addition to single gene expressions, users can also visualize using a color-code the overlap and the union of expression patterns of two or more genes. If quantitative expression levels are provided, users can also visualize them as heat maps. Users can in addition obtain the list of genes expressed by any picked object, or search specific genes by name.</p>
      <p id="Par40">Genetic expression patterns can also be manually curated directly from the Genetic menu.</p>
      <p id="Par41">Screenshots of visualized dataset, as well as movies of spatial and temporal dynamics, can be produced in the Movie menu.</p>
      <p id="Par42">When creating a movie (Scenario), users can create keyframes of specific views of the data (both in space and in time) and can tune the frame-rate between two subsequent keyframes. In addition, they can choose whether to interpolate dataset movements between two subsequent selected views. Once a movie has been edited, users can visualize it and download it as an.mp4 file. Movies can also be uploaded to the cloud and shared with other users.</p>
      <p id="Par43">For both screenshots and movies, all user interactions with objects (e.g., color selections) are taken into account.</p>
      <p id="Par44">Finally, depending on the user account level and on the user rights on each specific dataset, user account options may allow users to modify and erase dataset information, share the whole dataset and, eventually, its information with other specific users, change the default point of view or erase the whole dataset.</p>
      <p id="Par45">Users can always update their personal information and send feedback/comments to administrators.</p>
    </sec>
    <sec id="Sec8">
      <title>MorphoNet implementation</title>
      <p id="Par46">MorphoNet is a web-based application composed of a front-end application on the client (internet browser) and a back-end support on the server which communicate through classical http requests.</p>
      <p id="Par47">The structure of MorphoNet integrates a database for uploading and sharing, which is hosted on the back-end, and a 3D interactive interface for visualization and other advanced dataset interaction, which is hosted on the front-end.</p>
      <p id="Par48">The front-end application of MorphoNet is accessible through the url <ext-link ext-link-type="uri" xlink:href="http://www.morphonet.org">http://www.morphonet.org</ext-link> on any Internet browser, but we strongly recommend to use Firefox, which is free and accessible on any operating system. We also extensively tested MorphoNet on two versions of Chrome (72.0.3626.121 and 73.0.3683.75) on Windows 7, 8, 10, on MacOS Sierra 10.13, Mojave 10.14 and on Ubuntu 14, 16, 18. MorphoNet is fully compatible with the tested Chrome browser versions.</p>
      <p id="Par49">MorphoNet uses the browser internal library WebGL 2.0 to display complex morphological data, and thus needs a recent computer with enough memory and CPU power to support this library. The main technical limitation of MorphoNet, imposed by the very structure of WebGL, is the 2 GB limit of memory use, as is the case for many online mesh visualization platforms. However, for a better interactivity with the dataset during more advanced user interactions (information upload, computations, lineage tree exploration), we suggest to limit the total size of a dataset mesh to 500 MB. This can be achieved by decimating the dataset mesh, i.e., decreasing the number of polygons composing the mesh, for instance through MeshLab (<ext-link ext-link-type="uri" xlink:href="http://www.meshlab.net">http://www.meshlab.net</ext-link>).</p>
      <p id="Par50">In the same spirit, in order to optimize the interaction with the dataset, we recommend to limit the total number of elementary objects in each dataset to half a million. Also, for optimal loading, the dataset should not contain more than 1 thousand.obj files (each.obj file can contain more than one elementary object, see “Format specification” section).</p>
      <p id="Par51">The front-end application is developed in Unity 3D v2017 Personal Edition using C# language. During the building of the application, Unity converts all code to JavaScript, which makes it readable by any browser.</p>
      <p id="Par52">We provide, by application/request, the possibility to add new data on our own server. A database implemented in MySQL stores all necessary information of MorphoNet (datasets, users, quantitative data, curations, etc.). The server uses classical apache and PHP libraries to communicate with the browser. Any researcher/laboratory can also install MorphoNet on their own server to create their own private morpho-browser.</p>
      <p id="Par53">Researchers with little computer science knowledge can create a new dataset and upload their meshes directly through the web interface (as.obj files, see “Format specification” section). For a more controlled upload, however, we recommend to employ the MorphoNet API written in Python, which is provided at the url <ext-link ext-link-type="uri" xlink:href="http://www.morphonet.org/HELP/HelpAPI.php">http://www.morphonet.org/HELP/HelpAPI.php</ext-link>. The API allows uploading meshes distributed in multiples files, their associated information, and permits to perform common user functions (e.g., create, share or delete datasets).</p>
      <p id="Par54">Once data are uploaded to the server, users can directly visualize and interact with them on MorphoNet. For a smoother usage, a daemon, running on the server, converts the.obj format of each new mesh in AssetBundle, which is the optimized Unity format.</p>
    </sec>
    <sec id="Sec9">
      <title>User rights: creation of users and groups</title>
      <p id="Par55">Any registered user on MorphoNet has the right to create new users. Once created, a user can be erased only by him/herself or by MorphoNet administrators.</p>
      <p id="Par56">Any registered user on MorphoNet has the right to create a user group. Groups are used to easily share datasets/information with all group members.</p>
      <p id="Par57">These groups can be either private or public: in private groups, only group managers can add new members, while any users can freely decide to join a public group.</p>
      <p id="Par58">The group creator is automatically a manager. Other group members can be either managers or simple members. Both managers and members have access to group datasets and information, while only managers can add/remove users (for private groups), manage the group structure and allow manager rights to other members.</p>
      <p id="Par59">Once created, groups can be completely erased from the database of MorphoNet by MorphoNet administrators only.</p>
      <p id="Par60">Group managers can, however, decide at any time to make the group inactive by archiving it. The group then becomes hidden and its rights to dataset access are suspended. Managers can reactivate archived groups at any time.</p>
    </sec>
    <sec id="Sec10">
      <title>User rights: dataset and information access and sharing</title>
      <p id="Par61">Once a dataset is created by uploading surface meshes to the MorphoNet database, it will stay private until the creator of the dataset decides to give access to other selected users (or user groups).</p>
      <p id="Par62">As such, each dataset has a community of allowed users who can, with different access rights, read and/or upload information to it.</p>
      <p id="Par63">Allowed users for each dataset in MorphoNet can be granted three access-rights levels:</p>
      <p id="Par64">Creator, i.e., the user who uploaded the meshes to the cloud; there is one Creator only per dataset;</p>
      <p id="Par65">Owner, i.e., users having full-right access to meshes and information; each dataset can have several Owners;</p>
      <p id="Par66">Reader, i.e., users having read-only access to meshes and information; each dataset can have several Readers.</p>
      <p id="Par67">Users who have not been given access to a specific dataset will neither be able to see it nor to access it.</p>
      <p id="Par68">Both Creator and Owners can upload new information to the dataset. All uploaded information can either be kept private, or shared will all users with read access (Creator, Owners, and Readers).</p>
      <p id="Par69">Creator and Owners can also download both meshes and all information they have access to.</p>
      <p id="Par70">Private information can only be seen by the specific Owner who uploaded it and by the Creator of the dataset, who has full access to everything associated with his/her dataset.</p>
      <p id="Par71">Both the Creator and Owners can grant access rights to other users or user groups.</p>
      <p id="Par72">Readers have no upload/download/share right and can only visualize meshes and shared information.</p>
      <p id="Par73">A dataset can also be made public, in which case all registered users on MorphoNet automatically acquire Reader rights.</p>
      <p id="Par74">In addition, public datasets can be accessed by users from anywhere in the world without the need for a MorphoNet account: public access will be granted to unregistered users, with visualization rights only.</p>
    </sec>
    <sec id="Sec11">
      <title>Format specification</title>
      <p id="Par75">In order to fully exploit the interdisciplinary networking structure of the idea behind morphological browsers we have hereby introduced, we created a generic format for morphological information specification.</p>
      <p id="Par76">To this end, we take advantage of the object-based structure of morphological datasets by introducing morphodynamic information categories which can be projected on elementary blocks. Each of these objects can be uniquely identified by an object tuple (OTP) given by its context. For example, when both temporal information and several visualization channels are present in a dataset, at any given time point and for any given visualization channel, one is left with a collection of objects. Therefore, OTPs in such datasets correspond to three integer numbers separated by commas: t, id, ch, specifying the time point (t), the visualization channel (ch) and the ID of the specific object given in the obj file (id).</p>
      <p id="Par77">On the other hand, if only one time point and one channel is provided in the dataset, OTPs can be simplified to just the simple <italic>id</italic> specified in.obj files.</p>
    </sec>
    <sec id="Sec12">
      <title>Morphological datasets</title>
      <p id="Par78">Morphological datasets must be uploaded to MorphoNet in the form of surface meshes. More specifically, we employ one of the most used format to represent meshes, i.e., the OBJ format. Each.obj file contains a list of elementary objects present at a given time point, of its vertices and of its faces. Each elementary object is identified by the time index at which it exists and its specific <italic>id</italic> at each given time, followed by the list of coordinates of its vertices and the list of faces composed of three vertices (each vertex being numbered starting from 1, with a global numbering running over all vertices of all objects at any given time point).</p>
      <p id="Par79">This leaves dataset owners the freedom to choose the level of detail of their morphological unit, which will then be interpreted by MorphoNet as the elementary object with which users can interact.</p>
      <p id="Par80">Each elementary brick should be referenced in the.obj file by the letter g (standard in the obj format) followed by its OTP.</p>
      <p id="Par81">For an optimal experience when interacting with the dataset, the total number of objects should not be higher than half a million. This is due to the intrinsic limits to the WebGL memory as of today.</p>
    </sec>
    <sec id="Sec13">
      <title>Morphological information</title>
      <p id="Par82">Thanks to flexible OTPs, users can upload information to be visualized in the dataset. The general structure of information is a property associated with a specific object. The unique MorphoNet information format consists of a list of entries of the form OTP: property.</p>
      <p id="Par83">Properties can, in turn, represent several different kinds of morphological information, each identified by a specific information type.</p>
      <p id="Par84">The type of information must be mentioned at the beginning of the list as type: information type.</p>
      <p id="Par85">Each property must be given a name in order to uniquely identify it in the database.</p>
      <p id="Par86">Available information types and their format are listed in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Overview of morphological information formats</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Information type</th><th>Information format</th></tr></thead><tbody><tr><td>Temporal information</td><td>Time</td><td>OTP1: OTP2</td></tr><tr><td>Spatial information</td><td>Space</td><td>OTP1: OTP2</td></tr><tr><td>Group information</td><td>Group</td><td>OTP: group1 (: subgroup2…)</td></tr><tr><td>Quantitative information</td><td>Float</td><td>OTP: number (float)</td></tr><tr><td>Selection information</td><td>Selection</td><td>OTP: number (integer)</td></tr><tr><td>Color information</td><td>Color</td><td>OTP: R,G,B</td></tr><tr><td>Qualitative information</td><td>String</td><td>OTP: text</td></tr><tr><td>Genetic information</td><td>Genetic</td><td>OTP: number (float)</td></tr><tr><td>Dictionary information</td><td>Dict</td><td>OTP1: OTP2: number (float)</td></tr><tr><td>Sphere information</td><td>Sphere</td><td>OTP: x,y,z,r</td></tr><tr><td>Vector information</td><td>Vector</td><td>OTP: x1,y1,z1,s1: x2,y2,z2,s2</td></tr></tbody></table><table-wrap-foot><p>Further details are given in the text</p></table-wrap-foot></table-wrap></p>
      <p id="Par87">Specifically: Temporal information provides information on temporal relations between two objects OTP1 and OTP2 at different time points: OTP2 originates from OTP1 at a previous time point. This format can be used to identify the same object at two different time points and to characterize object divisions (for instance, if OTP1 divides and creates OTP2 and OTP3, the list will have both entries <italic>OTP1: OTP2</italic> and <italic>OTP1: OTP3</italic>) or objects fusion (if OTP1 and OTP2 merge to produce OTP3, the list will have both entries <italic>OTP1: OTP3</italic> and <italic>OTP2: OTP3</italic>).</p>
      <p id="Par88">Spatial Information provides information on spatial relations between two objects OTP1 and OTP2. It can be used to provide objects adjacency information or any other kind of connection existing between objects at the same time point. For instance, if one wants to provide the list of physical neighbors of object OTP1, the list will contain several entries <italic>OTP1: OTP2, OTP1: OTP3</italic>, etc…</p>
      <p id="Par89">Group Information provides group information on object OTP, used to identify several objects belonging to the same class (for instance, cells belonging to the same tissue). This information is given as text corresponding to the name of each group. Users can additionally provide subgroups information: their names must be given in a hierarchical order, from the largest to the smallest (i.e., subgroup2 is a part of group1 and so forth).</p>
      <p id="Par90">For instance, if OTP belongs to the group Epidermis and to subgroup Head Epidermis, the corresponding list entry will be <italic>OTP: Epidermis: Head Epidermis</italic>.</p>
      <p id="Par91">Quantitative Information provides quantitative information associated with object OTP. This information is a number, representing a certain property of OTP, such as for instance its volume. Such information will be displayed on MorphoNet as a heat map.</p>
      <p id="Par92">Selection information associates object OTP to standard MorphoNet selection, identified by an integer between 1 and 255 and corresponding to the selection number in the Objects menu of MorphoNet. Object OTP will then be color-labeled correspondingly.</p>
      <p id="Par93">Color information colors OTP according to given Red-Green-Blue values (integer in the range 0,255).</p>
      <p id="Par94">Qualitative Information provides qualitative information associated with object OTP. This information is in the form of text, representing a certain characteristic of OTP, such as for instance its name. Such information will be displayed on MorphoNet as text superimposed to OTP as the mouse pointer passes over it.</p>
      <p id="Par95">Genetic Information provides gene expression information associated with object OTP. The number characterizes the expression level (either given as boolean 0/1 or as more precise quantitative expression level). The gene name whose expression is given in the information must be specified as the name of the information file uploaded to the database.</p>
      <p id="Par96">Dictionary Information links object OTP1 to object OTP2 with a quantitative information on this link. Such a quantitative information is represented as heat map on the dataset. For instance, object OTP1 is associated with its direct physical neighbors, with additional quantitative information on their contact areas.</p>
      <p id="Par97">Sphere Information visualizes a sphere on the dataset, having the same color selection as object OTP, centered at coordinates x,y,z and with radius r.</p>
      <p id="Par98">Vector Information visualizes a line segment on the dataset, having the same color selection as OTP, starting at coordinates x1,y1,z1 with size s1 and ending at coordinates x2,y2,z2 with size s2.</p>
    </sec>
    <sec id="Sec14">
      <title>Reporting summary</title>
      <p id="Par99">Further information on research design is available in the <xref rid="MOESM14" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec15">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2019_10668_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2019_10668_MOESM2_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="41467_2019_10668_MOESM3_ESM.pdf">
            <caption>
              <p>Description of Additional Supplementary Files</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="41467_2019_10668_MOESM4_ESM.mov">
            <caption>
              <p>Supplementary Movie 1</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="41467_2019_10668_MOESM5_ESM.mov">
            <caption>
              <p>Supplementary Movie 2</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="41467_2019_10668_MOESM6_ESM.mov">
            <caption>
              <p>Supplementary Movie 3</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM7">
          <media xlink:href="41467_2019_10668_MOESM7_ESM.mov">
            <caption>
              <p>Supplementary Movie 4</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM8">
          <media xlink:href="41467_2019_10668_MOESM8_ESM.mov">
            <caption>
              <p>Supplementary Movie 5</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM9">
          <media xlink:href="41467_2019_10668_MOESM9_ESM.mov">
            <caption>
              <p>Supplementary Movie 6</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM10">
          <media xlink:href="41467_2019_10668_MOESM10_ESM.mov">
            <caption>
              <p>Supplementary Movie 7</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM11">
          <media xlink:href="41467_2019_10668_MOESM11_ESM.mov">
            <caption>
              <p>Supplementary Movie 8</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM12">
          <media xlink:href="41467_2019_10668_MOESM12_ESM.mov">
            <caption>
              <p>Supplementary Movie 9</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM13">
          <media xlink:href="41467_2019_10668_MOESM13_ESM.mov">
            <caption>
              <p>Supplementary Movie 10</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM14">
          <media xlink:href="41467_2019_10668_MOESM14_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Peer review information:</bold><italic>Nature Communications</italic> thanks Arno Klein and other anonymous reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.</p>
    </fn>
    <fn>
      <p><bold>Publisher’s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary Information</bold> accompanies this paper at 10.1038/s41467-019-10668-1.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank M. Brozovic for helping with the MorphoNet-ANISEED connection. We thank J. Dardaillon for her precious help in the MorphoNet-ANISEED connection and in the NCBI taxonomy API. We thank F. Boudon for generously providing the dataset of simulated Mango tree. We thank J. Traas for kindly providing the dataset of <italic>Arabidopsis</italic> meristem and gene expression patterns, and for discussions and feedbacks. We thank A. Perna for providing the dataset of <italic>Cubitermes</italic> nest structure. We thank G. Cerutti for his help with the creation of surface meshes on volume segmentation datasets. We thank H. Oliveri for providing the dataset of simulated meristem. We thank C. Dantec and the CRBM for helping with and hosting the MorphoNet website. B. L., J. L., C.G., and P.L. acknowledge financial support from the Agence Nationale de la Recherche (Dig-Em contract, ANR-14-CE11-0013; Equipex Morphoscope2, ANR-11-EQPX-0029; Institut de Biologie Computationnelle, IBC, ANR 11-BINF-0002) and from the Inria Project Lab Morphogenetics.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>E.F. conceived the concept of MorphoNet, developed the code, contributed to its features and to the preparation of datasets and contributed to writing the manuscript; B.L. contributed to the development of the concept, the features of MorphoNet, the preparation of datasets and wrote the manuscript; P.L. contributed to the inception of the main concept, the development of features and of datasets and contributed to writing the manuscript; C.G. contributed to the inception of the main concept, the development of features and of datasets; J.L. contributed to the features and the preparation of datasets; A.C. contributed to development of concepts and features. All authors contributed to discussions on the structure of the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>All public datasets shown in this work are accessible through the MorphoNet online interface and available for download upon request.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>The whole open source code of MorphoNet, its APIs, format converters, data analysis scripts in Python and related documentation are available on a GitLab at <ext-link ext-link-type="uri" xlink:href="https://gitlab.inria.fr/efaure/morpholab">https://gitlab.inria.fr/efaure/morpholab</ext-link>.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par100">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kherlopian</surname>
            <given-names>AR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A review of imaging techniques for systems biology</article-title>
        <source>Bmc. Syst. Biol.</source>
        <year>2008</year>
        <volume>2</volume>
        <fpage>74</fpage>
        <pub-id pub-id-type="doi">10.1186/1752-0509-2-74</pub-id>
        <pub-id pub-id-type="pmid">18700030</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keller</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>Imaging morphogenesis: technological advances and biological insights</article-title>
        <source>Science</source>
        <year>2013</year>
        <volume>340</volume>
        <fpage>1234168</fpage>
        <pub-id pub-id-type="doi">10.1126/science.1234168</pub-id>
        <pub-id pub-id-type="pmid">23744952</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stegmaier</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Real-time three-dimensional cell segmentation in large-scale microscopy data of developing embryos</article-title>
        <source>Dev. Cell.</source>
        <year>2016</year>
        <volume>36</volume>
        <fpage>225</fpage>
        <lpage>240</lpage>
        <pub-id pub-id-type="doi">10.1016/j.devcel.2015.12.028</pub-id>
        <pub-id pub-id-type="pmid">26812020</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tassy</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Daian</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Hudson</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bertrand</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Lemaire</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>A Quantitative approach to the study of cell shapes and interactions during early chordate embryogenesis</article-title>
        <source>Curr. Biol.</source>
        <year>2006</year>
        <volume>16</volume>
        <fpage>345</fpage>
        <lpage>358</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2005.12.044</pub-id>
        <pub-id pub-id-type="pmid">16488868</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cunningham</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Rahman</surname>
            <given-names>IA</given-names>
          </name>
          <name>
            <surname>Lautenschlager</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rayfield</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Donoghue</surname>
            <given-names>PCJ</given-names>
          </name>
        </person-group>
        <article-title>A virtual world of paleontology</article-title>
        <source>Trends Ecol. Evol.</source>
        <year>2014</year>
        <volume>29</volume>
        <fpage>347</fpage>
        <lpage>357</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tree.2014.04.004</pub-id>
        <pub-id pub-id-type="pmid">24821516</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Takemura</surname>
            <given-names>S-Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Synaptic circuits and their variations within different columns in the visual system of Drosophila</article-title>
        <source>Proc. Natl Acad. Sci. USA</source>
        <year>2015</year>
        <volume>112</volume>
        <fpage>13711</fpage>
        <lpage>13716</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1509820112</pub-id>
        <pub-id pub-id-type="pmid">26483464</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Guignard, L. et al. Contact-dependent cell communications drive morphological invariance during ascidian embryogenesis, 10.1101/238741 (2017).</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sherrard</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Robin</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Lemaire</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Munro</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Sequential activation of apical and basolateral contractility drives ascidian endoderm invagination</article-title>
        <source>Curr. Biol.</source>
        <year>2010</year>
        <volume>20</volume>
        <fpage>1499</fpage>
        <lpage>1510</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2010.06.075</pub-id>
        <pub-id pub-id-type="pmid">20691592</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lemon</surname>
            <given-names>WC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Whole-central nervous system functional imaging in larval Drosophila</article-title>
        <source>Nat. Commun.</source>
        <year>2015</year>
        <volume>6</volume>
        <fpage>7924</fpage>
        <pub-id pub-id-type="doi">10.1038/ncomms8924</pub-id>
        <pub-id pub-id-type="pmid">26263051</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tainaka</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Whole-body imaging with single-cell resolution by tissue decolorization</article-title>
        <source>Cell</source>
        <year>2014</year>
        <volume>159</volume>
        <fpage>911</fpage>
        <lpage>924</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2014.10.034</pub-id>
        <pub-id pub-id-type="pmid">25417165</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Exploring long-range genome interactions using the WashU Epigenome Browser</article-title>
        <source>Nat. Methods</source>
        <year>2013</year>
        <volume>10</volume>
        <fpage>375</fpage>
        <lpage>376</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2440</pub-id>
        <pub-id pub-id-type="pmid">23629413</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Szigeti, B. et al. OpenWorm: an open-science approach to modeling <italic>Caenorhabditis elegans</italic>. <italic>Front. Comput. Neurosci</italic>. <bold>8</bold>, 137 (2014).</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitsuhashi</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BodyParts3D: 3D structure database for anatomical concepts</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2009</year>
        <volume>37</volume>
        <fpage>D782</fpage>
        <lpage>D785</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkn613</pub-id>
        <pub-id pub-id-type="pmid">18835852</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fantham</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kaminski</surname>
            <given-names>CF</given-names>
          </name>
        </person-group>
        <article-title>A new online tool for visualization of volumetric data</article-title>
        <source>Nat. Photonics</source>
        <year>2017</year>
        <volume>11</volume>
        <fpage>69</fpage>
        <pub-id pub-id-type="doi">10.1038/nphoton.2016.273</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schindelin</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fiji: an open-source platform for biological-image analysis</article-title>
        <source>Nat. Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <fpage>676</fpage>
        <lpage>682</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id>
        <pub-id pub-id-type="pmid">22743772</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Chaumont</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Icy: an open bioimage informatics platform for extended reproducible research</article-title>
        <source>Nat. Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <fpage>690</fpage>
        <lpage>696</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2075</pub-id>
        <pub-id pub-id-type="pmid">22743774</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barbier de Reuille</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MorphoGraphX: A platform for quantifying morphogenesis in 4D</article-title>
        <source>eLife</source>
        <year>2015</year>
        <volume>4</volume>
        <fpage>05864</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.05864</pub-id>
        <pub-id pub-id-type="pmid">25946108</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schott</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>EmbryoMiner: A new framework for interactive knowledge discovery in large-scale cell tracking data of developing embryos</article-title>
        <source>PLoS Comput. Biol.</source>
        <year>2018</year>
        <volume>14</volume>
        <fpage>e1006128</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006128</pub-id>
        <pub-id pub-id-type="pmid">29672531</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boltcheva</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Yvinec</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Boissonnat</surname>
            <given-names>J-D</given-names>
          </name>
        </person-group>
        <article-title>Mesh generation from 3D multi-material images</article-title>
        <source>Med. Image Comput. Comput. Assist. Interv.</source>
        <year>2009</year>
        <volume>12</volume>
        <fpage>283</fpage>
        <lpage>290</lpage>
        <?supplied-pmid 20426123?>
        <pub-id pub-id-type="pmid">20426123</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brozovic</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ANISEED 2017: extending the integrated ascidian database to the exploration and evolutionary comparison of genome-scale datasets</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2018</year>
        <volume>46</volume>
        <fpage>D718</fpage>
        <lpage>D725</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx1108</pub-id>
        <pub-id pub-id-type="pmid">29149270</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boudon</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A computational framework for 3D mechanical modeling of plant morphogenesis with cellular resolution</article-title>
        <source>PLoS Comput. Biol.</source>
        <year>2015</year>
        <volume>11</volume>
        <fpage>e1003950</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003950</pub-id>
        <pub-id pub-id-type="pmid">25569615</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oliveri</surname>
            <given-names>Hadrien</given-names>
          </name>
          <name>
            <surname>Traas</surname>
            <given-names>Jan</given-names>
          </name>
          <name>
            <surname>Godin</surname>
            <given-names>Christophe</given-names>
          </name>
          <name>
            <surname>Ali</surname>
            <given-names>Olivier</given-names>
          </name>
        </person-group>
        <article-title>Regulation of plant cell wall stiffness by mechanical stress: a mesoscale physical model</article-title>
        <source>Journal of Mathematical Biology</source>
        <year>2018</year>
        <volume>78</volume>
        <issue>3</issue>
        <fpage>625</fpage>
        <lpage>653</lpage>
        <pub-id pub-id-type="doi">10.1007/s00285-018-1286-y</pub-id>
        <pub-id pub-id-type="pmid">30209574</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Perna</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The structure of gallery networks in the nests of termite Cubitermes spp. revealed by X-ray tomography</article-title>
        <source>Naturwissenschaften</source>
        <year>2008</year>
        <volume>95</volume>
        <fpage>877</fpage>
        <lpage>884</lpage>
        <pub-id pub-id-type="doi">10.1007/s00114-008-0388-6</pub-id>
        <pub-id pub-id-type="pmid">18493731</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
