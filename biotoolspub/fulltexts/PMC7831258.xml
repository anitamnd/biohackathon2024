<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7831258</article-id>
    <article-id pub-id-type="publisher-id">3960</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-021-03960-9</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepDist: real-value inter-residue distance prediction with deep residual convolutional network</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Wu</surname>
          <given-names>Tianqi</given-names>
        </name>
        <address>
          <email>tianqiwu@mail.missouri.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Guo</surname>
          <given-names>Zhiye</given-names>
        </name>
        <address>
          <email>zggc9@mail.missouri.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hou</surname>
          <given-names>Jie</given-names>
        </name>
        <address>
          <email>jie.hou@slu.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0305-2853</contrib-id>
        <name>
          <surname>Cheng</surname>
          <given-names>Jianlin</given-names>
        </name>
        <address>
          <email>chengji@missouri.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.134936.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 2162 3504</institution-id><institution>Electrical Engineering and Computer Science Department, </institution><institution>University of Missouri, </institution></institution-wrap>Columbia, MO 65211 USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.262962.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9342</institution-id><institution>Department of Computer Science, </institution><institution>Saint Louis University, </institution></institution-wrap>St. Louis, MO 63103 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>25</day>
      <month>1</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>25</day>
      <month>1</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>22</volume>
    <elocation-id>30</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>6</day>
        <month>1</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Driven by deep learning, inter-residue contact/distance prediction has been significantly improved and substantially enhanced ab initio protein structure prediction. Currently, most of the distance prediction methods classify inter-residue distances into multiple distance intervals instead of directly predicting real-value distances. The output of the former has to be converted into real-value distances to be used in tertiary structure prediction.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">To explore the potentials of predicting real-value inter-residue distances, we develop a multi-task deep learning distance predictor (DeepDist) based on new residual convolutional network architectures to simultaneously predict real-value inter-residue distances and classify them into multiple distance intervals. Tested on 43 CASP13 hard domains, DeepDist achieves comparable performance in real-value distance prediction and multi-class distance prediction. The average mean square error (MSE) of DeepDist’s real-value distance prediction is 0.896 Å<sup>2</sup> when filtering out the predicted distance ≥ 16 Å, which is lower than 1.003 Å<sup>2</sup> of DeepDist’s multi-class distance prediction. When distance predictions are converted into contact predictions at 8 Å threshold (the standard threshold in the field), the precision of top L/5 and L/2 contact predictions of DeepDist’s multi-class distance prediction is 79.3% and 66.1%, respectively, higher than 78.6% and 64.5% of its real-value distance prediction and the best results in the CASP13 experiment.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">DeepDist can predict inter-residue distances well and improve binary contact prediction over the existing state-of-the-art methods. Moreover, the predicted real-value distances can be directly used to reconstruct protein tertiary structures better than multi-class distance predictions due to the lower MSE. Finally, we demonstrate that predicting the real-value distance map and multi-class distance map at the same time performs better than predicting real-value distances alone.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Protein distance prediction</kwd>
      <kwd>Contact prediction</kwd>
      <kwd>Protein structure prediction</kwd>
      <kwd>Deep learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100008982</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>DBI1759934 &amp; IIS1763246</award-id>
        <principal-award-recipient>
          <name>
            <surname>Cheng</surname>
            <given-names>Jianlin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>DOE</institution>
        </funding-source>
        <award-id>AWD-001604-G1</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>GM093123</award-id>
        <principal-award-recipient>
          <name>
            <surname>Cheng</surname>
            <given-names>Jianlin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Department of Energy</institution>
        </funding-source>
        <award-id>DE-SC0020400</award-id>
        <principal-award-recipient>
          <name>
            <surname>Cheng</surname>
            <given-names>Jianlin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2021</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par9">Recently, the accuracy of protein inter-residue contact prediction has been substantially increased due to the development of residue-residue co-evolution analysis methods effectively detecting the directly correlated mutations of contacted residues in the sequences of a protein family, such as Direct Coupling Analysis (DCA) [<xref ref-type="bibr" rid="CR1">1</xref>], plmDCA [<xref ref-type="bibr" rid="CR2">2</xref>], GREMLIN [<xref ref-type="bibr" rid="CR3">3</xref>], CCMpred [<xref ref-type="bibr" rid="CR4">4</xref>], and PSICOV [<xref ref-type="bibr" rid="CR5">5</xref>]. The capability of these methods to extract the correlated mutation information for contact prediction largely depends on the number of effective sequences in multiple sequence alignment (MSA) of a target protein. Due to the advancement in the DNA/RNA sequencing technology [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>], many proteins have a lot of sufficiently diverse, homologous sequences that make their contact/distance prediction fairly accurate. However, for targets with a small number of effective homologous sequences (i.e. shallow sequence alignments), the co-evolutionary scores are noisy and not reliable for contact prediction. The problem can be largely addressed by using noisy co-evolutionary scores as input for advanced deep learning techniques that have strong pattern recognition power to predict inter-residue contacts and distances.</p>
    <p id="Par10">After deep learning was introduced for contact prediction in 2012 [<xref ref-type="bibr" rid="CR8">8</xref>], different deep learning architectures have been designed to integrate traditional sequence features with inter-residue coevolution scores to substantially improve contact/distance prediction [<xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR12">12</xref>], even for some targets with shallow MSAs.</p>
    <p id="Par11">The improved contact predictions can be converted into inter-residue distance information, which has been successfully used with distance-based modeling methods such as CONFOLD [<xref ref-type="bibr" rid="CR13">13</xref>], CONFOLD2 [<xref ref-type="bibr" rid="CR14">14</xref>], and EVFOLD [<xref ref-type="bibr" rid="CR15">15</xref>] to build accurate tertiary structures for ab initio protein targets [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>].</p>
    <p id="Par12">In the most recent CASP13 experiment, several groups (e.g., AlphaFold [<xref ref-type="bibr" rid="CR18">18</xref>] and RaptorX [<xref ref-type="bibr" rid="CR19">19</xref>]) applied deep learning techniques to classify inter-residue distances into multiple fine-grained distance intervals (i.e. predict the distance distribution) to further improve ab initio structure prediction substantially. However, the probabilities of a distance belonging to different intervals predicted by the multi-classification approach still need to be converted into a distance value to be used for tertiary structure modeling. There is lack of deep learning regression methods to directly predict the exact real value of inter-residue distances.</p>
    <p id="Par13">In this study, we develop a deep residual convolutional neural network method (DeepDist) to predict both the full-length real-value distance map and the multi-class distance map (i.e. distance distribution map) for a target protein. According to the test on 43 CASP13 hard domains (i.e. both FM and FM/TBM domains; FM: free modeling; TBM: template-based modeling), 37 CASP12 hard (FM) domains, and 268 CAMEO targets, the method can predict inter-residue distance effectively and perform better than existing state-of-the-art methods in terms of the precision of binary contact prediction. We further show that predicting both real-value distance map and multi-class distance map simultaneously is more accurate than only predicting real-value distance map, demonstrating the advantage of DeepDist multi-task learning framework to improve protein distance prediction.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>Comparing DeepDist with state-of-the-art methods on CASP12 and CASP13 datasets in terms of precision of binary contact predictions</title>
      <p id="Par14">As a multi-task predictor, our distance predictor DeepDist can not only classify each residue pair into distance intervals (multi-classification) but also predict its real-value distance (regression). We convert the predicted distances into contact maps in order to compare DeepDist with existing methods using the most widely used evaluation metrics—the precision of top L/5, L/2, L long-range contact predictions (long range: sequence separation of the residue pair ≥ 24). Figure <xref rid="Fig1" ref-type="fig">1</xref> reports the contact prediction precision of the multi-class distance prediction and the real-value distance prediction of DeepDist and several state-of-the-art methods on two CASP test datasets (43 CASP13 FM and FM/TBM domains and 37 CASP12 FM domains). To compare our distance prediction result on 43 CASP13 test sets strictly, we extract the contact precision results of RaptorX-Contact [<xref ref-type="bibr" rid="CR19">19</xref>], AlphaFold [<xref ref-type="bibr" rid="CR18">18</xref>], and TripletRes [<xref ref-type="bibr" rid="CR12">12</xref>] reported in their paper. For trRosetta [<xref ref-type="bibr" rid="CR20">20</xref>], we ran it with the same MSAs used with DeepDist to predict distance probability distribution map and converted it into a binary contact map within 8 Å threshold. On the CASP13 dataset (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a), the contact precision of DeepDist is higher than the contact precision of three top methods (RaptorX-Contact, AlphaFold, and TripletRes) in CASP13 as well as trRosetta in almost all cases. For instance, the precision of top L/5 long-range predicted contacts for DeepDist(multi-class) and DeepDist(real_dist) is 0.793 and 0.786 on the CASP13 dataset, respectively, higher than 0.751 of trRosetta. The precision of top L/2 long-range predicted contacts for DeepDist(multi-class) is 0.661, which is also similar to trRosetta’s precision—0.652. According to this metric, the multi-class distance prediction (DeepDist(multi-class)) works slightly better than the real-value distance prediction (DeepDist(real_dist)).<fig id="Fig1"><label>Fig. 1</label><caption><p>Contact prediction precision of DeepDist and several state-of-art methods on CASP12 and CASP13 test sets. <bold>a</bold> Long-range contact prediction precision of DeepDist, RaptorX-Contact, AlphaFold, TripletRes, and trRosetta on 43 CASP13 FM and FM/TBM domains. “Top L/5”, “Top L/2” and “Top L” stands for the top L/5, L/2 and L predicted contacts, where L is the length of the domain. <bold>b</bold> Long-range contact prediction precision of DeepDist and DeepMetaPSICOV on 37 CASP12 FM domains.</p></caption><graphic xlink:href="12859_2021_3960_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par15">We also compare DeepDist with DeepMetaPSICOV [<xref ref-type="bibr" rid="CR11">11</xref>] on 37 CASP12 FM domains. To rigorously evaluate them, we ran DeepMetaPSICOV with the same sequence-based features (sequence profile from PSI-BLAST [<xref ref-type="bibr" rid="CR21">21</xref>] and solvent accessibility from PSIPRED [<xref ref-type="bibr" rid="CR22">22</xref>]) and MSAs used with DeepDist. Both multi-class distance prediction and real-value distance prediction of DeepDist perform consistently better than DeepMetaPSICOV (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b).</p>
    </sec>
    <sec id="Sec4">
      <title>Comparison of predicting real-value distance map and multi-class distance map simultaneously with predicting real-value distance map alone</title>
      <p id="Par16">In order to evaluate if predicting real-value distance map and multi-class distance map together improves the performance over predicting real-value distance map only, we conducted two experiments. Experiment 1 trained real-value distance prediction and multi-class distance prediction simultaneously; Experiment 2 trained real-value distance prediction only. To ensure a fair comparison, two experiments used the same input features (PLM) and the same model architecture (PLM_Net mentioned in Method section).</p>
      <p id="Par17">We evaluated the real-value distance prediction performance of the two experiments based on several evaluation metrics—long-range (residue pair separation ≥ 24) contact precision, MSE, and Pearson coefficient. As the evaluation data shown in Table <xref rid="Tab1" ref-type="table">1</xref>, the real-value distance prediction trained simultaneously with multi-class distance prediction in Experiment 1 performed better than the real-value distance prediction trained alone in Experiment 2 according to all the metrics. The results demonstrate that DeepDist’s multi-task learning framework can improve the performance of real-value distance prediction.<table-wrap id="Tab1"><label>Table 1</label><caption><p>The results of predicting real-value distance map and multi-class distance map at the same time versus predicting real-value distance separately on 43 CASP13 hard domains</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">L/5 (Precision)</th><th align="left">L/2 (Precision)</th><th align="left">L (Precision)</th><th align="left">MSE</th><th align="left">Pearson coefficient</th></tr></thead><tbody><tr><td align="left">Experiment 1</td><td char="." align="char">0.699</td><td char="." align="char">0.580</td><td char="." align="char">0.446</td><td char="." align="char">1.151</td><td char="." align="char">0.979</td></tr><tr><td align="left">Experiment 2</td><td char="." align="char">0.687</td><td char="." align="char">0.558</td><td char="." align="char">0.430</td><td char="." align="char">1.282</td><td char="." align="char">0.978</td></tr></tbody></table><table-wrap-foot><p>MSE: average mean square error between predicted distances and true distances; Pearson coefficient: the Pearson’s correlation between predicted distance and true distance</p><p>Experiment 1: real-value distance prediction by training real-value distance prediction and multi-class distance prediction simultaneously</p><p>Experiment 2: real-value distance prediction by training real-value distance prediction alone. The two experiments used the same input features PLM and the same model architecture PLM_Net</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec5">
      <title>Comparison of the ensemble model based on four kinds of inputs and a single model based on one input</title>
      <p id="Par18">Table <xref rid="Tab2" ref-type="table">2</xref> reports the performance of DeepDist (an ensemble of multiple models trained on four kinds of inputs) on the CASP13 dataset. The accuracy of DeepDist’s real-value distance prediction (DeepDist(real-dist)) and multi-class distance prediction (DeepDist(multi-class)) in Table <xref rid="Tab2" ref-type="table">2</xref> is substantially higher than the accuracy of Experiment 1 in Table <xref rid="Tab1" ref-type="table">1</xref>, a single deep model trained on one kind of feature—PLM. For instance, the precision for top L/5 contact prediction and MSE of DeepDist (real-dist) are 0.786 and 0.896 Å<sup>2</sup>, better than 0.699 and 1.151 Å<sup>2</sup> of the single model PLM_Net. The same results are observed for other single models trained on COV, PRE, or OTHER features, separately. The results clearly demonstrate that the ensemble approach improves the accuracy of inter-residue distance prediction.<table-wrap id="Tab2"><label>Table 2</label><caption><p>The performance of DeepDist on 43 CASP13 hard domains</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">L/5 (Precision)</th><th align="left">L/2 (Precision)</th><th align="left">L (Precision)</th><th align="left">MSE</th><th align="left">Pearson coefficient</th></tr></thead><tbody><tr><td align="left">DeepDist (real-dist)</td><td char="." align="char">0.786</td><td char="." align="char">0.645</td><td char="." align="char">0.496</td><td char="." align="char">0.896</td><td char="." align="char">0.981</td></tr><tr><td align="left">DeepDist (multi-class)</td><td char="." align="char">0.793</td><td char="." align="char">0.661</td><td char="." align="char">0.517</td><td char="." align="char">1.003</td><td char="." align="char">0.981</td></tr></tbody></table><table-wrap-foot><p>DeepDist(real-dist): real-value distance prediction; DeepDist(multi-class): multi-class distance prediction</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec6">
      <title>Comparison between real-value distance prediction and multi-class distance distribution prediction in terms of 3D protein structure folding</title>
      <p id="Par19">To test the usefulness of two distance predictions for 3D structure folding, we use the real-value distance map and multi-class distance map predicted by DeepDist with DFOLD [<xref ref-type="bibr" rid="CR23">23</xref>] to construct the 3D models for the 43 CASP13 hard domains respectively. Table <xref rid="Tab3" ref-type="table">3</xref> shows the average TM-score of the top 1 model and the best model of the top 5 models of using real-value distances (DeepDist(real-dist)) and of using multi-class distances (DeepDist(multi-class)) on the 43 CASP13 FM and FM/TBM domains. The average TM-scores of top 1 and top 5 models generated from real-value distance predictions are 0.487 and 0.522, which demonstrates the feasibility of applying real-value distance predictions to build protein tertiary structures with moderate model quality.<table-wrap id="Tab3"><label>Table 3</label><caption><p>TM-scores of models on CASP13 43 FM and FM/TBM domains for four methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">Top 1</th><th align="left">Top 5</th><th align="left"># of TM-score ≥ 0.5 (Top 1)</th><th align="left"># of TM-score ≥ 0.5 (Top 5)</th></tr></thead><tbody><tr><td align="left">DeepDist (real-dist)</td><td char="." align="char">0.487</td><td char="." align="char">0.522</td><td align="left">21</td><td align="left">23</td></tr><tr><td align="left">DeepDist (multi-class)</td><td char="." align="char">0.463</td><td char="." align="char">0.506</td><td align="left">21</td><td align="left">22</td></tr><tr><td align="left">DMPfold</td><td char="." align="char">0.438</td><td char="." align="char">0.449</td><td align="left">16</td><td align="left">16</td></tr><tr><td align="left">CONFOLD2</td><td char="." align="char">0.382</td><td char="." align="char">0.466</td><td align="left">12</td><td align="left">19</td></tr></tbody></table></table-wrap></p>
      <p id="Par20">Figure <xref rid="Fig2" ref-type="fig">2</xref> illustrates the distribution of TM-score of the top1 models of 43 CASP13 domains for DeepDist (real-dist) and DeepDist(multi-class). The distribution of DeepDist (real-dist) shifts toward higher scores (TM-score &gt; 0.6). As shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1, the real-value distance prediction has 13 domains with TM-score &gt; 0.6 and the multi-class distance prediction has 12. From the target-by-target comparison, when the models of both methods have TM-score &gt; 0.6, models constructed from the real-value distance prediction tend to have higher scores. This is also consistent with what was observed in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, a tendency of the TM-score distribution curve of the real-value distance prediction sitting above the curve of the multi-class distance prediction when TM-score &gt; 0.6. The reduction of MSE of the predicted distances may be one of the factors contributing to the improvement of DeepDist (real-dist) over DeepDist(multi-class) for 3D modeling. The average MSE between the predicted real-value distance map and the true distance map is 0.8964 Å<sup>2</sup>, which is lower than the average MSE (1.0037 Å<sup>2</sup>) between the distance map converted from the predicted multi-class distance map and the true distance map. The way of converting multi-class distance predictions to real-value distance constraints and setting the upper and lower distance bounds for constructing 3D models can be another two factors that affect the final model quality.<fig id="Fig2"><label>Fig. 2</label><caption><p>Distribution of TM-scores of the top 1 models of 43 CASP13 FM and FM/TBM domains, built from the real-value distance predictions and the multi-class distance predictions</p></caption><graphic xlink:href="12859_2021_3960_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par21">On the 43 CASP13 FM and FM/TBM domains, we also compared the models generated from the predicted distance of DeepDist with two popular ab initio distance-based model folding methods: DMPfold [<xref ref-type="bibr" rid="CR24">24</xref>] and CONFOLD2 [<xref ref-type="bibr" rid="CR14">14</xref>] (Table <xref rid="Tab3" ref-type="table">3</xref>). For DMPfold, we applied the same sequence-based features and multiple sequence alignment used with DeepDist as input for DMPfold to build 3D models. For CONFOLD2, we converted the predicted distance map to the contact map as its input to build 3D models. As shown in Table <xref rid="Tab3" ref-type="table">3</xref>, Both DeepDist and DMPfold have a much better performance than the contact-based method CONFOLD2, clearly demonstrating that the distance-based 3D modeling is better than contact-based 3D modeling. The average TM-score of DeepDist (real-dist) is 0.487, higher than 0.438 of DMPfold, probably due to more accurate distance prediction made by DeepDist. Considering top 5 models, DeepDist(real_dist) folds 23 out of 43 domains (TM-score &gt; 0.5) correctly, higher than 16 of DMPfold. Figure <xref rid="Fig3" ref-type="fig">3</xref> illustrates the DeepDist distance map for the target T0997 and other four high-quality CASP13 tertiary structure models built from the predicted real-value distances that have the TM-scores ≥ 0.7.<fig id="Fig3"><label>Fig. 3</label><caption><p>DeepDist predicted distance maps for the target T0997 and the four high-quality tertiary structure models of CASP13 targets (T0968s2-D1, T0969-D1, T0992-D1, T1000-D2) (TM-score ≥ 0.7) generated from DeepDist real-value distance predictions versus their native structures. <bold>a</bold> Two types of distance outputs from DeepDist for the target T0997 are shown as “real-dist” (for real-value distance prediction) and “multi-class” (for multi-class distance prediction). The true distance map of T0997 is marked as “ground truth”. The brightness of each pixel represents the distance of each residue pair of T0997—the brighter the pixel, the shorter the distance. For comparing the two predicted distance maps, the difference of predicted distance maps between “multi-class” and “real-dist” is shown. The brightness of each pixel represents the distance difference between “multi-class” and “real-dist” in each residue pair, i.e., the brighter the pixel, the smaller the distance difference. 3D model comparison is also shown, with the model built from DeepDist real-value distance prediction in brown and the native structure in blue. <bold>b</bold> Model comparison of other four high-quality CASP13 models (TM-score ≥ 0.7) generated from DeepDist real-value distance predictions versus their native structures. Brown: model; Blue: native structure.</p></caption><graphic xlink:href="12859_2021_3960_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
    <sec id="Sec7">
      <title>The relationship between 3D models reconstructed from predicted real-value distances and multiple sequence alignments.</title>
      <p id="Par22">The main input features used with DeepDist are derived from MSAs. Figure <xref rid="Fig4" ref-type="fig">4</xref> plots the TM-scores of top 1 models of 43 CASP13 domains against the natural logarithm of the number of effective sequences in their MSAs. There is a moderate correlation (Pearson’s correlation = 0.66) between the two. Moreover, 3D models for 6 domains (T0957s2-D1, T0958-D1, T0986s2-D1, T0987-D1, T0989-D1, and T0990-D1) with shallow alignments (the number of effective sequences (Neff) in the alignment &lt; 55) have TM-score &gt; 0.5 (i.e. TM-score 0.568, 0.644, 0.658, 0.555, 0.545 and 0.593, respectively), indicating DeepDist works well on some targets with shallow alignments.<fig id="Fig4"><label>Fig. 4</label><caption><p>The quality of the top 1 models folded from DeepDist real-value distance predictions versus the logarithm of the number of effective sequences (Neff) on 43 CASP13 FM and FM/TBM domains. The six points in red denote domains with shallow alignments (Neff &lt; 55) but correctly predicted structural folds (TM-score &gt; 0.5)</p></caption><graphic xlink:href="12859_2021_3960_Fig4_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Evaluation of CAMEO targets</title>
      <p id="Par23">In order to further evaluate DeepDist on a large dataset, we test DeepDist on 268 CAMEO targets selected from 08/31/2018 to 08/24/2019. The average precision of the top L/5 or L/2 long-range inter-residue contact prediction converted from the real-value distance prediction is 0.691, and 0.598, respectively. 191 out of 268 targets have the long-range top L/5 contact prediction precision ≥ 0.7. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows 5 high-quality models constructed from DeepDist predicted real-value distances. For the 14 targets with the number of effective sequences less than or equal to 50, the average top L/5 and top L/2 long-range contact prediction precision is 0.696 and 0.515, which is reasonable. Using the predicted distance to build 3D structures for the 14 targets, five of them have models with TM-score &gt; 0.5. This further confirms that DeepDist’s predicted distances can fold some proteins with very shallow alignments correctly.<fig id="Fig5"><label>Fig. 5</label><caption><p>High-quality 3D models for five CAMEO targets constructed from DeepDist predicted real-value distances. The model is shown in brown and the native structure is shown in blue</p></caption><graphic xlink:href="12859_2021_3960_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Discussion</title>
    <p id="Par24">Although there are numerous deep learning methods to conduct distance prediction by classifying distance into multiple intervals, there are few deep learning methods to predict real-value distance via regression. Our results demonstrate that it is worthwhile to explore the potentials of real-value distance prediction, which can be directly used by 3D modeling methods to build protein tertiary structures. Evaluated by the precision of binary contact prediction, the accuracy of predicting real-value distance prediction alone is worse than predicting real-value distances and classifying distances into multiple intervals at the same time in a multi-task learning framework (Table <xref rid="Tab1" ref-type="table">1</xref>). This demonstrates that the strength of DeepDist predicting the two types of distances simultaneously to improve the accuracy of predicting real-value distance. Moreover, the two distance predictions in DeepDist achieve comparable results. The distance multi-classification prediction of DeepDist is slightly better than real-value distance prediction in terms of precision of contact prediction, but it is a little worse in terms of MSE of predicted distance. The p-value (shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Tables S2 and S3) calculated from the paired t-test of the corresponding MSE value pairs between DeepDist(real-dist) and DeepDist(multi-class) suggests the significant differences in their mean MSE values. All those results show that the real-value distance prediction can add some value on top of distance multi-classification prediction. Both the strengths and weaknesses of the two distance prediction methods in DeepDist have been demonstrated in this study. Which method should be chosen to use may depend on the specific needs of users and multiple factors such as how to convert multi-classification distances into real-value distances, how to estimate distance errors, and which distances can be used by a 3D modeling tool. Moreover, more experiments are still needed to investigate if and how real-value distance prediction can directly improve the performance of distance multi-classification prediction.</p>
  </sec>
  <sec id="Sec10">
    <title>Conclusion</title>
    <p id="Par25">We develop an inter-residue distance predictor DeepDist based on new deep residual convolutional neural networks to predict both real-value distance map and multi-class distance map simultaneously. We demonstrate that predicting the two at the same time yields higher accuracy in real-value distance prediction than predicting real-value distance alone. The overall performance of DeepDist’s real-value distance prediction and multi-class distance prediction is comparable according to multiple evaluation metrics. Both kinds of distance predictions of DeepDist are more accurate than several state-of-the-art methods on the CASP13 hard targets. Moreover, DeepDist can work well on some targets with shallow multiple sequence alignments. And the real-value distance predictions can be used to reconstruct 3D protein structures better than predicted multi-class distance predictions, showing that predicting real-value inter-residue distances can add the value on top of existing distance prediction approaches.</p>
  </sec>
  <sec id="Sec11">
    <title>Methods</title>
    <sec id="Sec12">
      <title>Overview</title>
      <p id="Par26">The overall workflow of DeepDist is shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. We use four sets of 2D co-evolutionary and sequence-based features to train four deep residual convolutional neural network architectures respectively to predict the Euclidean distance between residues in a protein target. Three of four feature sets are mostly coevolution-based features, i.e. covariance matrix (COV) [<xref ref-type="bibr" rid="CR25">25</xref>], precision matrix (PRE) [<xref ref-type="bibr" rid="CR26">26</xref>], and pseudolikelihood maximization matrix (PLM) [<xref ref-type="bibr" rid="CR4">4</xref>]) calculated from multiple sequence alignments. Considering that coevolution-based features sometimes cannot provide sufficient information, particularly when targets have shallow alignments, the fourth set of sequence-based features (OTHER), such as the sequence profile generated by PSI-BLAST [<xref ref-type="bibr" rid="CR21">21</xref>], and solvent accessibility from PSIPRED [<xref ref-type="bibr" rid="CR22">22</xref>] are used. The output of DeepDist is a real-value L × L distance map and a multi-class distance map (L: the length of the target protein). The two types of distance maps are generated by two prediction branches. For each branch, the final output is produced by the ensemble of four deep network models (COV_Net, PLM_Net, PRE_Net, and OTHER_Net) named after their input feature sets (COV, PLM, PRE, and OTHER). For the prediction of the multi-class distance map, we discretize the inter-residue distances into 25 bins: 1 bin for distance &lt; 4.5 Å, 23 bins from 4.5 to 16 Å at interval size of 0.5 Å and a final bin for all distances ≥ 16 Å. For the real-value distance map, we simply use the true distance map of the native structure as targets to train deep learning models without discretization. Because large distances are not useful and not predictable, we only predict inter-residue distances less than 16 Å by filtering out true distances ≥ 16 Å.<fig id="Fig6"><label>Fig. 6</label><caption><p>The overall workflow of DeepDist for both real-value distance map prediction and multi-class distance map prediction. Given a sequence, DeepAln and DeepMSA are called to search it against sequence databases to generate two kinds of multiple sequence alignments (MSAs), which are used to generate four sets of features (COV, PLM, PRE, OTHER), respectively. The four sets of features are used by four deep networks (COV Net, PLM Net, PRE Net, and OTHER Net) to predict both real-value distance (real-dist) map and multi-class distance (multi-class) map, respectively. The real-value distance maps (or multi-class distance maps) of the individual networks are averaged to produce the final real-value distance map (or multi-class distance map)</p></caption><graphic xlink:href="12859_2021_3960_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
    <sec id="Sec13">
      <title>Datasets</title>
      <p id="Par27">We select targets from the training list used in DMPfold [<xref ref-type="bibr" rid="CR24">24</xref>] and extract their true structures from the Protein Data Bank (PDB) to create a training dataset. After filtering out the redundancy with the validation dataset and test datasets according to 25% sequence identity threshold, 6463 targets are left in the training dataset. The validation set contains 144 targets used to validate DNCON2 [<xref ref-type="bibr" rid="CR10">10</xref>]. The three blind test datasets are 37 CASP12 FM domains, 43 CASP13 FM and FM/TBM domains, and 268 CAMEO targets collected from 08/31/2018 to 08/24/2019.</p>
    </sec>
    <sec id="Sec14">
      <title>Input feature generation</title>
      <p id="Par28">The sequence databases used to search for homologous sequences for feature generation include Uniclust30 (2017-10) [<xref ref-type="bibr" rid="CR27">27</xref>], Uniref90 (2018-04), Metaclust50 (2018-01) [<xref ref-type="bibr" rid="CR28">28</xref>], a customized database that combines Uniref100 (2018-04) and metagenomics sequence databases (2018-04), and NR90 database (2016). All the sequence databases were constructed before the CASP13 experiment.</p>
      <p id="Par29">Co-evolutionary features (i.e. COV, PRE, and PLM) are the main input features for DeepDist, where COV is the covariance matrix calculated from marginal and pair frequencies of each amino acid pair [<xref ref-type="bibr" rid="CR25">25</xref>], PRE [<xref ref-type="bibr" rid="CR26">26</xref>] is the inverse covariance matrix, and PLM is the inverse Potts model coupling matrix optimized by pseudolikelihoods [<xref ref-type="bibr" rid="CR4">4</xref>]. All the three coevolutionary features are generated from multiple sequence alignment (MSA). Two methods, DeepMSA [<xref ref-type="bibr" rid="CR29">29</xref>] and our in-house DeepAln, are used to generate MSA for a target. The outputs of both MSA generation methods are the combination of the iterative homologous sequence search of HHblits [<xref ref-type="bibr" rid="CR30">30</xref>] and Jackhmmer [<xref ref-type="bibr" rid="CR31">31</xref>] on several sequence databases. The two methods differ in sequence databases used and the strategy of combining the output of HHblits and Jackhmmer searches. DeepMSA trims the sequence hits from Jackhmmer and performs sequence clustering, which shortens the time for constructing the HHblits database for the next round of search. To leverage its fast speed, we apply DeepMSA to search against a large customized sequence database that is composed of UniRef100 and metagenomic sequences. In contrast, DeepAln directly uses the full-length Jackhmmer hits for building HHblits customized databases and is slower. It is applied to the Metaclust sequences database. The detailed comparison of two MSA generation methods is reported in the Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4. In addition to three kinds of co-evolutionary features, 2D features such as the coevolutionary contact scores generated by CCMpred, Shannon entropy sum, mean contact potential, normalized mutual information, and mutual information are also generated. Moreover, some other features used in DNCON2 including sequence profile, solvent accessibility, joint entropy, and Pearson correlation are also produced, which are collectively called OTHER feature.</p>
      <p id="Par30">The features above are generated for the MSAs of both DeepMSA and DeepAln. Each of them is used to train a deep model to predict both real-value distance map and multi-class distance map, resulting in 8 predicted real-value distance maps and 8 multi-class distance maps (Fig. <xref rid="Fig6" ref-type="fig">6</xref>).</p>
    </sec>
    <sec id="Sec15">
      <title>Deep network architectures for distance prediction</title>
      <p id="Par31">We started training the first network (COV_Net) with a simple feature set which consists of the covariance matrix described above, along with sequence profile (PSSM), contact scores (CCMpred), and Pearson correlation. Inspired by COV_Net, two networks—PLM_Net and PRE_Net that use two related coevolutionary matrices PLM and PRE generated from multiple sequence alignment were then added to use the coevolutionary relationship between amino acid pairs more effectively. Since all three networks highly depend on the quality of MSA, the fourth network OTHER_Net was constructed by adding only non-coevolutionary sequence-based features as input in case the MSA is shallow. To make sure every network works well, we tweaked the model architecture for each feature set. In total, there are four different networks in DeepDist, which are called COV_Net, PLM_Net, PRE_Net, and OTHER_Net (Fig. <xref rid="Fig7" ref-type="fig">7</xref>), respectively. PRE_Net and OTHER_Net share almost the same architecture with some minor differences. The detailed comparison of four networks is shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S5.<fig id="Fig7"><label>Fig. 7</label><caption><p>Deep network architectures for four deep residual network models. <bold>a</bold> COV_Net; <bold>b</bold> PLM_Net; <bold>c</bold> PRE_Net/OTHER_Net. RCIN: normalization layer; SE_block: squeeze-and-excitation block</p></caption><graphic xlink:href="12859_2021_3960_Fig7_HTML" id="MO7"/></fig></p>
      <p id="Par32">COV_Net (Fig. <xref rid="Fig7" ref-type="fig">7</xref>a) uses the COV matrix along with sequence profile (PSSM), contact scores (CCMpred), and Pearson correlation as input. It starts with a normalization block called RCIN that contains instance normalization (IN) [<xref ref-type="bibr" rid="CR32">32</xref>], row normalization (RN), column normalization (CN) [<xref ref-type="bibr" rid="CR33">33</xref>] and a ReLU [<xref ref-type="bibr" rid="CR34">34</xref>] activation function, followed by one convolutional layer with 128 kernels of size 1 × 1 and one Maxout [<xref ref-type="bibr" rid="CR35">35</xref>] layer to reduce the input channel from 483 to 64. The output of Maxout is then fed into 16 residual blocks. Each residual block is composed of two RCIN normalization blocks, two convolutional layers that consist of 64 kernels of size 3 × 3, and one squeeze-and-excitation block (SE_block) [<xref ref-type="bibr" rid="CR36">36</xref>]. The output feature maps from the block, together with the input of the block are added together as input for a ReLU activation function to generate the output of the residual block. The last residual block is followed by one convolutional instance normalization layer. The output of the layer is converted into two output maps simultaneously. One real-value distance map is obtained by a ReLU function through a convolution kernel of size 1 × 1, and one multi-class distance map with 25 output channels is obtained by a softmax function.</p>
      <p id="Par33">PLM_Net (Fig. <xref rid="Fig7" ref-type="fig">7</xref>b) uses as input the PLM matrix concatenated with the sequence profile (PSSM) and Pearson correlation. The input is first fed into an instance normalization layer, followed by one convolutional layer and one Maxout layer. The output of Maxout is then fed into 20 residual blocks. Each residual block contains three RCIN blocks, four convolutional layers with 64 kernels of size 3 × 3, one SE_block, and one dropout layer [<xref ref-type="bibr" rid="CR37">37</xref>] with a dropout rate of 0.2. The residual block is similar to the bottleneck residual block, except that the middle convolutional layer of kernel size 3 × 3 is replaced with three convolutional layers of kernel size 3 × 3, 7 × 1, 1 × 7, separately. The last residual block is followed by the same layers as in COV_Net to predict a real-value distance map and a multi-class distance map.</p>
      <p id="Par34">PRE_Net (Fig. <xref rid="Fig7" ref-type="fig">7</xref>c) uses as input the PRE matrix as well as entropy scores (joint entropy, Shannon entropy) and sequence profile (PSSM). An instance normalization layer is first applied to the input. Unlike COV_Net and PLM_Net, one convolutional layer with 64 kernels of size 1 × 1 and an RCIN block are applied after the instance normalization layer for dimensionality reduction. The output of the RCIN block is then fed through 16 residual blocks. Each residual block is made of two stacked sub-blocks (each containing one convolutional layer with 64 kernels of size 3 × 3, an RCIN block, a dropout layer with a dropout rate of 0.2, a SE_block, and the shortcut connection). The final output layers after the residual blocks are the same as in COV_Net.</p>
      <p id="Par35">OTHER_Net uses OTHER features as input. Its architecture is basically the same as PRE_Net, except that it has 22 residual blocks and there is no dropout layer in each residual block.</p>
      <p id="Par36">The final output of DeepDist is an average real-value distance map and an average multi-class distance map calculated from the output of the four individual network models, i.e. the output of the ensemble of the individual networks.</p>
    </sec>
    <sec id="Sec16">
      <title>Training</title>
      <p id="Par37">The dimension of the input of COV_Net, PLM_Net, and PRE_Net is L × L × 483, L × L × 482, and L × L × 484 respectively, which is very large and consumes a lot of memory. Therefore, we use data generators from Keras to load large feature data batch by batch. The batch size is set as 1. A normal initializer [<xref ref-type="bibr" rid="CR38">38</xref>] is used to initialize the network. For epochs ≤ 30, Adam optimizer [<xref ref-type="bibr" rid="CR39">39</xref>] is performed with an initial learning rate of 0.001. For epochs &gt; 30, stochastic gradient descent (SGD) with momentum [<xref ref-type="bibr" rid="CR40">40</xref>] is used instead, with the initial learning rate of 0.01 and the momentum of 0.9. The real-value distance prediction and multi-class distance classification are trained in two parallel branches. The mean squared error (MSE) and cross-entropy are used as their loss function, respectively. At each epoch, the precision of top L/2 long-range contact predictions derived from the average of the two contact maps converted from the real-value distance map and the multi-class distance map on the validation dataset is calculated. The inter-residue real-value distance map is converted to the contact map by inversing the predicted distance to obtain a relative contact probability (i.e. 1/dij: relative contact probability score; dij: predicted distance between residues i and j). The multi-class distance map is converted to the binary contact map by summing up the predicted probabilities of all the distance intervals ≤ 8 Å as contact probabilities.</p>
    </sec>
    <sec id="Sec17">
      <title>Ab initio protein folding by predicted distances</title>
      <p id="Par38">We use distances predicted by DeepDist with our in-house tool—DFOLD [<xref ref-type="bibr" rid="CR23">23</xref>] built on top of CNS [<xref ref-type="bibr" rid="CR41">41</xref>], a software package that implements distance geometry algorithm for NMR based structure determination, to convert the distance restraints into 3D structure models. For the predicted real-value distance map, we select the predicted distances ≤ 15 Å and with sequence separation ≥ 3 to generate the distance restraints between Cb-Cb atoms of residue pairs. 0.1 Å is added to or subtracted from the predicted distances to set the upper and lower distance bounds. For the predicted multi-class distance map, we first convert the distance probability distribution matrix to a real-value distance map by setting each distance as the probability-weighted mean distance of all intervals for a residue pair and using the standard deviation to calculate the upper and lower distance bounds. Given a final real-value distance map, we prepare five different subsets of input distance restraints by filtering out distances ≥ x respectively, where x = 11 Å, 12 Å, 13 Å, 14 Å, and 15 Å. For each subset of distance restraints, we run DFOLD for 3 iterations. For each iteration, we generate 50 models and select the top five models ranked by the CNS energy score, the sum of all violations of all distance restraints used to generate a model.
The top selected models generated from five subsets are further ranked by SBROD [<xref ref-type="bibr" rid="CR42">42</xref>]. The final top one model is the one with the highest SBROD score. PSIPRED is used to predict the secondary structure to generate hydrogen bonds and torsion angle constraints for DFOLD to use.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec131">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2021_3960_MOESM1_ESM.docx">
            <caption>
              <p><bold>Additional file 1.</bold> Supplemental results and data.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>MSE</term>
        <def>
          <p id="Par4">The average mean square error</p>
        </def>
      </def-item>
      <def-item>
        <term>DCA</term>
        <def>
          <p id="Par5">Direct coupling analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>MSA</term>
        <def>
          <p id="Par6">Multiple sequence alignment</p>
        </def>
      </def-item>
      <def-item>
        <term>FM</term>
        <def>
          <p id="Par7">Free modeling</p>
        </def>
      </def-item>
      <def-item>
        <term>TBM</term>
        <def>
          <p id="Par8">Template-based modeling</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>Tianqi Wu and Zhiye Guo have equal contributions to this work</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary Information</title>
    <p>The online version contains supplementary material available at 10.1186/s12859-021-03960-9.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We wish to thank CASP organizers and predictors for sharing the data used in this work.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>JC conceived the project. TW, ZG, JH, and JC designed the method. TW and ZG implemented the method and gathered the results. TW, ZG, and JC analyzed the results. TW, ZG, JH, and JC wrote the manuscript. All authors edited and approved the manuscript. TW and ZG contributed equally to this work. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Research reported in this publication was supported in part by two NSF Grants (DBI 1759934 and IIS1763246), a DOE grant (AWD-001604-G1) and an NIH Grant (R01GM093123) to JC. The funding agencies did not play a role in this research.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets used in this study and the source code of DeepDist are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/multicom-toolbox/deepdist">https://github.com/multicom-toolbox/deepdist</ext-link>.</p>
  </notes>
  <notes id="FPar1">
    <title>Ethics approval and consent to participate</title>
    <p id="Par39">Not applicable.</p>
  </notes>
  <notes id="FPar2">
    <title>Consent for publication</title>
    <p id="Par40">Not applicable.</p>
  </notes>
  <notes id="FPar3" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par41">The authors declare they have no conflict of interest.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weigt</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>White</surname>
            <given-names>RA</given-names>
          </name>
          <name>
            <surname>Szurmant</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hoch</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Hwa</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Identification of direct residue contacts in protein–protein interaction by message passing</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2009</year>
        <volume>106</volume>
        <issue>1</issue>
        <fpage>67</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0805923106</pub-id>
        <pub-id pub-id-type="pmid">19116270</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ekeberg</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lövkvist</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Weigt</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Aurell</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Improved contact prediction in proteins: using pseudolikelihoods to infer Potts models</article-title>
        <source>Phys Rev E</source>
        <year>2013</year>
        <volume>87</volume>
        <issue>1</issue>
        <fpage>012707</fpage>
        <pub-id pub-id-type="doi">10.1103/PhysRevE.87.012707</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kamisetty</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ovchinnikov</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Assessing the utility of coevolution-based residue–residue contact predictions in a sequence- and structure-rich era</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2013</year>
        <volume>110</volume>
        <issue>39</issue>
        <fpage>15674</fpage>
        <lpage>15679</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1314045110</pub-id>
        <pub-id pub-id-type="pmid">24009338</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Seemayer</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gruber</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CCMpred—fast and precise prediction of protein residue–residue contacts from correlated mutations</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>21</issue>
        <fpage>3128</fpage>
        <lpage>3130</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu500</pub-id>
        <pub-id pub-id-type="pmid">25064567</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Buchan</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Cozzetto</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Pontil</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>PSICOV: precise structural contact prediction using sparse inverse covariance estimation on large multiple sequence alignments</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>2</issue>
        <fpage>184</fpage>
        <lpage>190</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr638</pub-id>
        <pub-id pub-id-type="pmid">22101153</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meyer</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Paarmann</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>D'Souza</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Olson</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Glass</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Kubal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Paczian</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Rodriguez</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Stevens</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wilke</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The metagenomics RAST server—a public resource for the automatic phylogenetic and functional analysis of metagenomes</article-title>
        <source>BMC Bioinform</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>386</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-9-386</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wilke</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bischof</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gerlach</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Glass</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Harrison</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Keegan</surname>
            <given-names>KP</given-names>
          </name>
          <name>
            <surname>Paczian</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Trimble</surname>
            <given-names>WL</given-names>
          </name>
          <name>
            <surname>Bagchi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Grama</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The MG-RAST metagenomics database and portal in 2015</article-title>
        <source>Nucl Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <issue>D1</issue>
        <fpage>D590</fpage>
        <lpage>D594</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv1322</pub-id>
        <pub-id pub-id-type="pmid">26656948</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eickholt</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Predicting protein residue–residue contacts using deep networks and boosting</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>23</issue>
        <fpage>3066</fpage>
        <lpage>3072</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts598</pub-id>
        <pub-id pub-id-type="pmid">23047561</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Accurate de novo prediction of protein contact map by ultra-deep learning model</article-title>
        <source>PLoS Comput Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>e1005324</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005324</pub-id>
        <pub-id pub-id-type="pmid">28056090</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Adhikari</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>DNCON2: improved protein contact prediction using two-level deep convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>9</issue>
        <fpage>1466</fpage>
        <lpage>1472</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx781</pub-id>
        <pub-id pub-id-type="pmid">29228185</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kandathil</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Greener</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Prediction of interresidue contacts with DeepMetaPSICOV in CASP13</article-title>
        <source>Proteins Struct Funct Bioinform</source>
        <year>2019</year>
        <volume>87</volume>
        <issue>12</issue>
        <fpage>1092</fpage>
        <lpage>1099</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25779</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bell</surname>
            <given-names>EW</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Ensembling multiple raw coevolutionary features with deep residual neural networks for contact-map prediction in CASP13</article-title>
        <source>Proteins Struct Funct Bioinform</source>
        <year>2019</year>
        <volume>87</volume>
        <issue>12</issue>
        <fpage>1082</fpage>
        <lpage>1091</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25798</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Adhikari</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CONFOLD: residue-residue contact-guided ab initio protein folding</article-title>
        <source>Proteins Struct Funct Bioinform</source>
        <year>2015</year>
        <volume>83</volume>
        <issue>8</issue>
        <fpage>1436</fpage>
        <lpage>1449</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.24829</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Adhikari</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>CONFOLD2: improved contact-driven ab initio protein structure modeling</article-title>
        <source>BMC Bioinform</source>
        <year>2018</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>22</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-018-2032-6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Sheridan R, Fieldhouse RJ, Hayat S, Sun Y, Antipin Y, Yang L, Hopf T, Marks DS, Sander C: Evfold. org: Evolutionary couplings and protein 3D structure prediction. BioRxiv 2015:021022.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Michel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hayat</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Skwark</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Sander</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Marks</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>PconsFold: improved contact predictions improve protein models</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>17</issue>
        <fpage>i482</fpage>
        <lpage>i488</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu458</pub-id>
        <pub-id pub-id-type="pmid">25161237</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Monastyrskyy</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>d'Andrea</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Fidelis</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tramontano</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kryshtafovych</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of residue–residue contact prediction in CASP10</article-title>
        <source>Proteins Struct Funct Bioinform</source>
        <year>2014</year>
        <volume>82</volume>
        <fpage>138</fpage>
        <lpage>153</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.24340</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Senior</surname>
            <given-names>AW</given-names>
          </name>
          <name>
            <surname>Evans</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Jumper</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kirkpatrick</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sifre</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Qin</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Žídek</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nelson</surname>
            <given-names>AWR</given-names>
          </name>
          <name>
            <surname>Bridgland</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Improved protein structure prediction using potentials from deep learning</article-title>
        <source>Nature</source>
        <year>2020</year>
        <volume>577</volume>
        <issue>7792</issue>
        <fpage>706</fpage>
        <lpage>710</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-019-1923-7</pub-id>
        <pub-id pub-id-type="pmid">31942072</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Analysis of distance-based protein structure prediction by deep learning in CASP13</article-title>
        <source>Proteins Struct Funct Bioinform</source>
        <year>2019</year>
        <volume>87</volume>
        <issue>12</issue>
        <fpage>1069</fpage>
        <lpage>1081</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.25810</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Anishchenko</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Ovchinnikov</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Baker</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Improved protein structure prediction using predicted interresidue orientations</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2020</year>
        <volume>117</volume>
        <issue>3</issue>
        <fpage>1496</fpage>
        <lpage>1503</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1914677117</pub-id>
        <pub-id pub-id-type="pmid">31896580</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Bhagwat M, Aravind L: Psi-blast tutorial. In: <italic>Comparative genomics.</italic> Springer; 2007: 177–186.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure prediction based on position-specific scoring matrices</article-title>
        <source>J Mol Biol</source>
        <year>1999</year>
        <volume>292</volume>
        <issue>2</issue>
        <fpage>195</fpage>
        <lpage>202</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1999.3091</pub-id>
        <pub-id pub-id-type="pmid">10493868</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other"><ext-link ext-link-type="uri" xlink:href="https://github.com/jianlin-cheng/DFOLD">https://github.com/jianlin-cheng/DFOLD</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Greener</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Kandathil</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Deep learning extends de novo protein modelling coverage of genomes using iteratively predicted structural constraints</article-title>
        <source>Nat Commun</source>
        <year>2019</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-019-11994-0</pub-id>
        <pub-id pub-id-type="pmid">30602773</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
          <name>
            <surname>Kandathil</surname>
            <given-names>SM</given-names>
          </name>
        </person-group>
        <article-title>High precision in protein contact prediction using fully convolutional neural networks and minimal sequence features</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>19</issue>
        <fpage>3308</fpage>
        <lpage>3315</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty341</pub-id>
        <pub-id pub-id-type="pmid">29718112</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>D-J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>ResPRE: high-accuracy protein contact prediction by coupling precision matrix with deep residual neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>22</issue>
        <fpage>4647</fpage>
        <lpage>4655</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz291</pub-id>
        <pub-id pub-id-type="pmid">31070716</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mirdita</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>von den Driesch</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Galiez</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Steinegger</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Uniclust databases of clustered and deeply annotated protein sequences and alignments</article-title>
        <source>Nucl Acids Res</source>
        <year>2017</year>
        <volume>45</volume>
        <issue>D1</issue>
        <fpage>D170</fpage>
        <lpage>D176</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1081</pub-id>
        <pub-id pub-id-type="pmid">27899574</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Steinegger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Clustering huge protein sequence sets in linear time</article-title>
        <source>Nat Commun</source>
        <year>2018</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-018-04964-5</pub-id>
        <pub-id pub-id-type="pmid">29317637</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Zhang C, Zheng W, Mortuza S, Li Y, Zhang Y: DeepMSA: constructing deep multiple sequence alignment to improve contact prediction and fold-recognition for distant-homology proteins. <italic>Bioinformatics</italic> 2019.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Remmert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Biegert</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hauser</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>HHblits: lightning-fast iterative protein sequence searching by HMM-HMM alignment</article-title>
        <source>Nat Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <issue>2</issue>
        <fpage>173</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1818</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Eddy S: HMMER user’s guide. <italic>Department of Genetics, Washington University School of Medicine</italic> 1992, <bold>2</bold>(1):13.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Ulyanov D, Vedaldi A, Lempitsky V: Instance normalization: the missing ingredient for fast stylization. Preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/160708022">arXiv:160708022</ext-link> 2016.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Xing</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>AmoebaContact and GDFold as a pipeline for rapid de novo protein structure prediction</article-title>
        <source>Nat Mach Intell</source>
        <year>2019</year>
        <volume>2019</volume>
        <fpage>1</fpage>
        <lpage>9</lpage>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Nair V, Hinton GE: Rectified linear units improve restricted boltzmann machines. In: <italic>Proceedings of the 27th international conference on machine learning (ICML-10): 2010</italic>. 807–814.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Goodfellow IJ, Warde-Farley D, Mirza M, Courville A, Bengio Y: Maxout networks. Preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/13024389">arXiv:13024389</ext-link> 2013.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Hu J, Shen L, Sun G: Squeeze-and-excitation networks. In: <italic>Proceedings of the IEEE conference on computer vision and pattern recognition: 2018</italic>. 7132–7141.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <year>2014</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J: Delving deep into rectifiers: surpassing human-level performance on imagenet classification. In: <italic>Proceedings of the IEEE international conference on computer vision: 2015</italic>. 1026–1034.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Kingma DP, Ba J: Adam: a method for stochastic optimization. Preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/14126980">arXiv:14126980</ext-link> 2014.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qian</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>On the momentum term in gradient descent learning algorithms</article-title>
        <source>Neural Netw</source>
        <year>1999</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>145</fpage>
        <lpage>151</lpage>
        <pub-id pub-id-type="doi">10.1016/S0893-6080(98)00116-6</pub-id>
        <pub-id pub-id-type="pmid">12662723</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brünger</surname>
            <given-names>AT</given-names>
          </name>
          <name>
            <surname>Adams</surname>
            <given-names>PD</given-names>
          </name>
          <name>
            <surname>Clore</surname>
            <given-names>GM</given-names>
          </name>
          <name>
            <surname>DeLano</surname>
            <given-names>WL</given-names>
          </name>
          <name>
            <surname>Gros</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Grosse-Kunstleve</surname>
            <given-names>RW</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>J-S</given-names>
          </name>
          <name>
            <surname>Kuszewski</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Nilges</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pannu</surname>
            <given-names>NS</given-names>
          </name>
        </person-group>
        <article-title>Crystallography and NMR system: a new software suite for macromolecular structure determination</article-title>
        <source>Acta Crystallogr D Biol Crystallogr</source>
        <year>1998</year>
        <volume>54</volume>
        <issue>5</issue>
        <fpage>905</fpage>
        <lpage>921</lpage>
        <pub-id pub-id-type="doi">10.1107/S0907444998003254</pub-id>
        <pub-id pub-id-type="pmid">9757107</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Karasikov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pagès</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Grudinin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Smooth orientation-dependent scoring function for coarse-grained protein quality assessment</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>16</issue>
        <fpage>2801</fpage>
        <lpage>2808</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1037</pub-id>
        <pub-id pub-id-type="pmid">30590384</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
