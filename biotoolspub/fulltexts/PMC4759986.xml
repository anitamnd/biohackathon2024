<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4759986</article-id>
    <article-id pub-id-type="publisher-id">932</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-016-0932-x</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MetaCRAM: an integrated pipeline for metagenomic taxonomy identification and compression</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Kim</surname>
          <given-names>Minji</given-names>
        </name>
        <address>
          <email>mkim158@illinois.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Xiejia</given-names>
        </name>
        <address>
          <email>xzhan121@illinois.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ligo</surname>
          <given-names>Jonathan G.</given-names>
        </name>
        <address>
          <email>ligo2@illinois.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Farnoud</surname>
          <given-names>Farzad</given-names>
        </name>
        <address>
          <email>farnoud@caltech.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff2"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Veeravalli</surname>
          <given-names>Venugopal V.</given-names>
        </name>
        <address>
          <email>vvv@illinois.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Milenkovic</surname>
          <given-names>Olgica</given-names>
        </name>
        <address>
          <email>milenkov@illinois.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><label/>Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, 61801 USA </aff>
      <aff id="Aff2"><label/>Department of Electrical Engineering, California Institute of Technology, Pasadena, 91125 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>19</day>
      <month>2</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>2</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2016</year>
    </pub-date>
    <volume>17</volume>
    <elocation-id>94</elocation-id>
    <history>
      <date date-type="received">
        <day>5</day>
        <month>10</month>
        <year>2015</year>
      </date>
      <date date-type="accepted">
        <day>2</day>
        <month>2</month>
        <year>2016</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© Kim et al. 2016</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>Metagenomics is a genomics research discipline devoted to the study of microbial communities in environmental samples and human and animal organs and tissues. Sequenced metagenomic samples usually comprise reads from a large number of different bacterial communities and hence tend to result in large file sizes, typically ranging between 1–10 GB. This leads to challenges in analyzing, transferring and storing metagenomic data. In order to overcome these data processing issues, we introduce MetaCRAM, the first <italic>de novo</italic>, parallelized software suite specialized for FASTA and FASTQ format metagenomic read processing and lossless compression.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>MetaCRAM integrates algorithms for taxonomy identification and assembly, and introduces parallel execution methods; furthermore, it enables genome reference selection and CRAM based compression. MetaCRAM also uses novel reference-based compression methods designed through extensive studies of integer compression techniques and through fitting of empirical distributions of metagenomic read-reference positions. MetaCRAM is a lossless method compatible with standard CRAM formats, and it allows for fast selection of relevant files in the compressed domain via maintenance of taxonomy information. The performance of MetaCRAM as a stand-alone compression platform was evaluated on various metagenomic samples from the NCBI Sequence Read Archive, suggesting 2- to 4-fold compression ratio improvements compared to gzip. On average, the compressed file sizes were 2-13 percent of the original raw metagenomic file sizes.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>We described the first architecture for reference-based, lossless compression of metagenomic data. The compression scheme proposed offers significantly improved compression ratios as compared to off-the-shelf methods such as zip programs. Furthermore, it enables running different components in parallel and it provides the user with taxonomic and assembly information generated during execution of the compression pipeline.</p>
      </sec>
      <sec>
        <title>Availability</title>
        <p>The MetaCRAM software is freely available at <ext-link ext-link-type="uri" xlink:href="http://web.engr.illinois.edu/~mkim158/metacram.html">http://web.engr.illinois.edu/~mkim158/metacram.html</ext-link>. The website also contains a README file and other relevant instructions for running the code. Note that to run the code one needs a minimum of 16 GB of RAM. In addition, virtual box is set up on a 4GB RAM machine for users to run a simple demonstration.</p>
      </sec>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (doi:10.1186/s12859-016-0932-x) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Metagenomics</kwd>
      <kwd>Genomic compression</kwd>
      <kwd>Parallel algorithms</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CCF 0809895</award-id>
        <principal-award-recipient>
          <name>
            <surname>Veeravalli</surname>
            <given-names>Venugopal V.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation (US)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CCF 1218764</award-id>
        <principal-award-recipient>
          <name>
            <surname>Veeravalli</surname>
            <given-names>Venugopal V.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>IOS 1339388</award-id>
        <principal-award-recipient>
          <name>
            <surname>Ligo</surname>
            <given-names>Jonathan G.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CSoI-CCF 0939370</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zhang</surname>
            <given-names>Xiejia</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>U01 BD2K</award-id>
        <principal-award-recipient>
          <name>
            <surname>Milenkovic</surname>
            <given-names>Olgica</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation (US)</institution>
          </institution-wrap>
        </funding-source>
        <award-id>DGE 1144245</award-id>
        <principal-award-recipient>
          <name>
            <surname>Kim</surname>
            <given-names>Minji</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2016</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Metagenomics is an emerging discipline focused on genomic studies of complex microorganismal population. In particular, metagenomics enables a range of analyses pertaining to species composition, the properties of the species and their genes as well as their influence on the host organism or the environment. As the interactions between microbial populations and their hosts plays an important role in the development and functionality of the host, metagenomics is becoming an increasingly important research area in biology, environmental and medical sciences. As an example, the National Institute of Health (NIH) recently initiated a far-reaching Human Microbiome Project [<xref ref-type="bibr" rid="CR1">1</xref>] which has the aim to identify species living at different sites of the human body (in particular, the gut and skin [<xref ref-type="bibr" rid="CR2">2</xref>]), observe their roles in regulating metabolism and digestion, and evaluate their influence on the immune system. The findings of such studies may have important impacts on our understanding of the influence of microbials on an individual’s health and disease, and hence aid in developing personalized medicine approaches. Another example is the Sorcerer II Global Ocean Sampling Expedition [<xref ref-type="bibr" rid="CR3">3</xref>], led by the Craig Venter Institute, the purpose of which is to study microorganisms that live in the ocean and influence/maintain the fragile equilibrium of this ecosystem.</p>
    <p>There are many challenges in metagenomic data analysis. Unlike classical genomic samples, metagenomic samples comprise many diverse organisms, the majority of which is usually unknown. Furthermore, due to low sequencing depth, most widely used assembly methods – in particular, those based on de Bruijn graphs – often fail to produce quality results and it remains a challenge to develop accurate and sensitive meta-assemblers. These and other issues are further exacerbated by the very large file size of the samples and their ever increasing number. Nevertheless, many algorithmic methods have been developed to facilitate some aspects of microbial population analysis: examples include MEGAN (MEta Genome ANalyzer) [<xref ref-type="bibr" rid="CR4">4</xref>], a widely used tool that allows for an integrative analysis of metagenomic, metatranscriptomic, metaproteomic, and rRNA data; and PICRUSt (Phylogenetic Investigation of Communities by Reconstruction of Unobserved States) [<xref ref-type="bibr" rid="CR5">5</xref>], developed to predict metagenome functional contents from 16S rRNA marker gene sequences. Although suitable for taxonomic and functional analysis of data, neither MEGAN nor PICRUSt involve a data compression component, as is to be expected from highly specialized analytic software.</p>
    <p>In parallel, a wide range of software solutions have been developed to efficiently compress classical genomic data (a comprehensive survey of the state-of-the-art techniques may be found in [<xref ref-type="bibr" rid="CR6">6</xref>]). Specialized methods for compressing whole genomes have been reported in [<xref ref-type="bibr" rid="CR7">7</xref>–<xref ref-type="bibr" rid="CR9">9</xref>], building upon methods such as modified Lempel-Ziv encoding and the Burrows-Wheeler transform. Compression of reads is achieved by mapping the reads to reference genomes and encoding only the differences between the reference and the read; or, in a <italic>de novo</italic> fashion that does not rely on references and uses classical sequence compression methods. Quip [<xref ref-type="bibr" rid="CR10">10</xref>] and CRAM [<xref ref-type="bibr" rid="CR11">11</xref>] are two of the best known reference-based compression algorithms, whereas ReCoil [<xref ref-type="bibr" rid="CR12">12</xref>], SCALCE [<xref ref-type="bibr" rid="CR13">13</xref>], MFCompress [<xref ref-type="bibr" rid="CR14">14</xref>], and the NCBI Sequence Read Archive method compress data without the use of reference genomes. Reference-based algorithms in general achieve better compression ratios than reference-free algorithms by exploiting the similarity between some predetermined reference and the newly sequenced reads. Unfortunately, none of the current reference-based method can be successfully applied to metagenomic data, due to the inherent lack of “good” or known reference genomes. Hence, the only means for compressing metagenomic FASTA and FASTQ files is through the use of <italic>de novo</italic> compression methods.</p>
    <p>As a solution to the metagenomic big data problem, we introduce MetaCRAM, the first <italic>de novo</italic>, parallel, CRAM-like software specialized for FASTA-format metagenomic read compression, which in addition provides taxonomy identification, alignment and assembly information. This information primarily facilitates compression, but also allows for fast searching of the data in the compressive domain and for basic metagenomic analysis. The gist of the classification method is to use a taxonomy identification tool – in this case, Kraken [<xref ref-type="bibr" rid="CR15">15</xref>] – which can accurately identify a sufficiently large number of organisms from a metagenomic mix. By aligning the reads to the identified reference genomes of organisms via Bowtie2 [<xref ref-type="bibr" rid="CR16">16</xref>], one can perform efficient <italic>lossless</italic> reference-based compression via the CRAM suite. Those reads not aligned to any of the references can be assembled into contigs through existing metagenome assembly software algorithms, such as Velvet [<xref ref-type="bibr" rid="CR17">17</xref>] or IDBA-UD [<xref ref-type="bibr" rid="CR18">18</xref>]; sufficiently long contigs can subsequently be used to identify additional references through BLAST (Basic Local Alignment Search Tool) [<xref ref-type="bibr" rid="CR19">19</xref>]. The reads aligned to references are compressed into the standard CRAM format [<xref ref-type="bibr" rid="CR11">11</xref>], using three different integer encoding methods, Huffman [<xref ref-type="bibr" rid="CR20">20</xref>], Golomb [<xref ref-type="bibr" rid="CR21">21</xref>], and Extended Golomb encoding [<xref ref-type="bibr" rid="CR22">22</xref>].</p>
    <p>MetaCRAM is an automated software with many options that accommodate different user preferences, and it is compatible with the standard CRAM and SAMtools data format. In addition, its default operational mode is lossless, although additional savings are possible if one opts for discarding read ID information. We report on both the lossless and “lossy” techniques in the “<xref rid="Sec6" ref-type="sec">Methods</xref>” Section. MetaCRAM also separates the read compression process from the quality score compression technique, as the former technique is by now well understood while the latter is subject to constant changes due to different quality score formats in sequencing technologies. These changes may be attributed to increasing qualities of reads and changes in the correlations of the score values which depend on the sequencing platform. For quality score compression, the recommended method is QualComp [<xref ref-type="bibr" rid="CR23">23</xref>].</p>
    <p>MetaCRAM offers significant compression ratio improvements when compared to standard bzip and gzip methods, and methods that directly compress raw reads. These improvements range from 2–4 fold file size reductions, which leads to large storage cost reductions. Furthermore, although MetaCRAM has a relatively long compression phase, decompression may be performed in a matter of minutes. This makes the method suitable for both real time and archival applications.</p>
    <p>The paper is organized as follows. The “<xref rid="Sec2" ref-type="sec">Results</xref>” Section contains an in-depth performance analysis of MetaCRAM with respect to processing and retrieval time, and achievable compression ratios. The “<xref rid="Sec5" ref-type="sec">Discussion</xref>” Section describes the advantages of using MetaCRAM for data compression compared to other general-purpose methods, and describes directions for future algorithmic improvements. The “<xref rid="Sec6" ref-type="sec">Methods</xref>” Section contains detailed information about the methodology behind the MetaCRAM algorithmic blocks and it also outlines the way constituent algorithms are integrated and their purposes in the pipeline.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <p>The block diagram of the MetaCRAM algorithm is given in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, and the operation of the algorithm may be succinctly explained as follows. The first step is to identify suitable references for compression, which is achieved by identifying dominant taxonomies in the sample. The number of references is chosen based on cut-off abundance thresholds, which themselves are chosen using several criteria that trade-off compression ratio and compression time. Once the references are chosen, the raw reads are aligned to their closest references and the starting positions of the reads are statistically analyzed to determine the best integer compression method to be used for their encoding. Furthermore, reads that do not align sufficiently well with any of the chosen references are assembled using IDBA_UD, and the contig outputs of the assembler are used to identify additional references via BLAST search. Reads not matched with any references after multiple iterations of the above procedure are compressed independently with the MFCompress suite. The results associated with each of the described processing stages are discussed in the next subsections. Note that here and throughout the paper, we use standard terms in genomics and bioinformatics without explanations.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Block Diagram. The block diagram of the MetaCRAM Algorithm for Metagenomic Data Processing and Compression. Its main components are taxonomy identification, alignment, assembly and compression</p></caption><graphic xlink:href="12859_2016_932_Fig1_HTML" id="MO1"/></fig></p>
    <p>We tested MetaCRAM as a stand-alone platform and compared it to MFCompress, a recently developed software suite specialized for FASTA files, and bzip2 and gzip [<xref ref-type="bibr" rid="CR24">24</xref>], standard general purpose compression tools (available at <ext-link ext-link-type="uri" xlink:href="http://www.bzip.org">http://www.bzip.org</ext-link>). Other software tools for compression of sequencing data such as SCALCE and Quip, and SAMZIP [<xref ref-type="bibr" rid="CR25">25</xref>] and SlimGene [<xref ref-type="bibr" rid="CR26">26</xref>], were not tested because they were either for FASTQ or SAM file formats, and not FASTA files.</p>
    <p>As already pointed out, MetaCRAM does not directly process FASTQ file formats for multiple reasons: 1) the quality of sequencers are improving significantly, reaching the point where quality scores may contain very little information actually used during analysis; 2) reads with low quality scores are usually discarded and not included in metagenomics analysis – only high quality sequences are kept; 3) there exist software tools such as QualComp [<xref ref-type="bibr" rid="CR23">23</xref>], specifically designed for compressing quality scores that users can run independently along with MetaCRAM.</p>
    <sec id="Sec3">
      <title>Taxonomy identification and reference genome selection</title>
      <p>As the first step of our analysis, we compared two metagenomic taxonomy identification programs, Kraken and MetaPhyler in terms of computation time and identification accuracy on synthetic data, as it is impossible to test the accuracy of taxonomy identification on real biological datasets. For this purpose, we created mixtures of reads from 15 species, listed in the Additional file <xref rid="MOESM1" ref-type="media">1</xref>. The two Illumina paired-end read files were created by MetaSim [<xref ref-type="bibr" rid="CR27">27</xref>] with 1 % error rate, and they amounted to a file of size 6.7 GB. Kraken finished its processing task in 22 min and successfully identified all species within the top 50 most abundant taxons. On the other hand, MetaPhyler ran for 182 min and failed to identify Acetobacterium woodii and Haloterrigena turkmenica at the <italic>genus</italic> level. This example illustrates a <italic>general trend</italic> in our comparative findings, and we therefore adopted Kraken as a default taxonomy retrieval tool for MetaCRAM.</p>
      <p>When deciding how to choose references for compression, one of the key questions is to decide which outputs of the Kraken taxonomy identification tool are relevant. Recall that Kraken reports the species identified according to the number of reads matched to their genomes. The most logical approach to this problem is hence to choose a threshold for the abundance values of reads representing different bacterial species, and only use sequences of species with high abundance as compression references. Unfortunately, the choice for the optimal threshold value is unclear and it may differ from one dataset to another; at the same time, the threshold is a key parameter that determines the overall compression ratio – choosing too few references may lead to poor compression due to the lack of quality alignments, while choosing too many references may reduce the compression ratio due to the existence of many pointers to the reference files. In addition, if we allow too many references, we sacrifice computation time for the same final alignment rate. It is therefore important to test the impact of the threshold choice on the resulting number of selected reference genomes.</p>
      <p>In Table <xref rid="Tab1" ref-type="table">1</xref>, we listed our comparison results for all five datasets studied, using two threshold values: 75 (high) and 10 (low). For these two choices, the results are colored gray and white, respectively. We observe that we get slightly worse compression ratios if we select too few references, as may be seen for the files ERR321482 and ERR532393. Still, the processing time is significantly smaller when using fewer references, leading to 30 to 80 minutes of savings in real time. It is worth to point out that this result may also be due to the different qualities of internal hard drives: for example, the columns in gray were obtained running the code on Seagate Barracuda ST3000, while the results listed in white were obtained via testing on Western Digital NAS.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Analysis of the influence of different threshold values on reference genome selection after taxonomy identification and compression ratios</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Data</th><th align="left">Original (MB)</th><th align="left"><bold>Comp. (MB)</bold></th><th align="left"><bold>Processing time</bold></th><th align="left"><bold>Align. %</bold></th><th align="left"><bold>No. files</bold></th><th align="left">Comp. (MB)</th><th align="left">Processing time</th><th align="left">Align. %</th><th align="left">No. files</th></tr></thead><tbody><tr><td align="left">ERR321482</td><td align="left">1429</td><td align="left">191</td><td align="left">299 m 20 s</td><td align="left">26.99</td><td align="left">211</td><td align="left">193</td><td align="left">239 m 28 s</td><td align="left">24.22</td><td align="left">29</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">422 m 21 s</td><td align="left">3.57</td><td align="left">1480</td><td align="left"/><td align="left">398 m 3 s</td><td align="left">6.5</td><td align="left">1567</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">12 m 24 s</td><td align="left"/><td align="left"/><td align="left"/><td align="left">8 m 13 s</td><td align="left"/><td align="left"/></tr><tr><td align="left">SRR359032</td><td align="left">3981</td><td align="left">319</td><td align="left">127 m 34 s</td><td align="left">57.72</td><td align="left">26</td><td align="left">320</td><td align="left">93 m 60 s</td><td align="left">57.71</td><td align="left">7</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">245 m 53 s</td><td align="left">9.7</td><td align="left">30</td><td align="left"/><td align="left">206 m 18 s</td><td align="left">9.71</td><td align="left">32</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">8 m 37s</td><td align="left"/><td align="left"/><td align="left"/><td align="left">7 m 27 s</td><td align="left"/><td align="left"/></tr><tr><td align="left">ERR532393</td><td align="left">8230</td><td align="left">948</td><td align="left">639 m 55 s</td><td align="left">45.78</td><td align="left">267</td><td align="left">963</td><td align="left">522 m</td><td align="left">42.45</td><td align="left">39</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">1061 m 50 s</td><td align="left">1.98</td><td align="left">1456</td><td align="left"/><td align="left">1067 m 49 s</td><td align="left">7.16</td><td align="left">1639</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">73 m 59 s</td><td align="left"/><td align="left"/><td align="left"/><td align="left">28 m 13s</td><td align="left"/><td align="left"/></tr><tr><td align="left">SRR1450398</td><td align="left">5399</td><td align="left">703</td><td align="left">440 m 4 s</td><td align="left">7.14</td><td align="left">190</td><td align="left">703</td><td align="left">364 m 34 s</td><td align="left">6.82</td><td align="left">26</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">866 m 56 s</td><td align="left">0.6</td><td align="left">793</td><td align="left"/><td align="left">790 m 52 s</td><td align="left">0.91</td><td align="left">818</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">21 m 2 s</td><td align="left"/><td align="left"/><td align="left"/><td align="left">17 m 38 s</td><td align="left"/><td align="left"/></tr><tr><td align="left">SRR062462</td><td align="left">6478</td><td align="left">137</td><td align="left">217 m 21 s</td><td align="left">2.55</td><td align="left">278</td><td align="left">139</td><td align="left">197 m 15 s</td><td align="left">2.13</td><td align="left">50</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">254 m 26 s</td><td align="left">0.13</td><td align="left">570</td><td align="left"/><td align="left">241 m 2 s</td><td align="left">0.51</td><td align="left">656</td></tr><tr><td align="left"/><td align="left"/><td align="left"/><td align="left">15 m 45 s</td><td align="left"/><td align="left"/><td align="left"/><td align="left">19 m 31 s</td><td align="left"/><td align="left"/></tr></tbody></table><table-wrap-foot><p>Columns in bold represent a threshold of 75 species, while the columns not bolded correspond to a cutoff of 10 species. The results are shown for MetaCRAM-Huffman. “Align. %” refers to the alignment rates for the first and second round, and “No. files” refers to the number of reference genome files selected in the first and second iteration. Processing times are recorded row by row denoting real, user, and system time in order</p></table-wrap-foot></table-wrap></p>
      <p>Many of the most abundant references may be from the same genus, and this may potentially lead to the problem of multiple alignment due to subspecies redundancy. The almost negligible effect of the number of reference genomes on alignment rate implies that combining them to remove the redundancy would improve computational efficiency, as suggested in [<xref ref-type="bibr" rid="CR28">28</xref>]. Nevertheless, extensive computer simulations reveal that the loss due to multiple alignment is negligible whenever we choose up to 75–100 references. Therefore, our recommendation is to use, as a rule of thumb, the threshold 75 in order to achieve the best possible compression ratio and at the same time provide a more complete list of genomic references for further analysis.</p>
    </sec>
    <sec id="Sec4">
      <title>Compression performance analysis</title>
      <p>Our chosen comparison quality criteria include the compression ratio (i.e., the ratio of the uncompressed file and the compressed file size), as well as the compression and decompression time, as measured on an affordable general purpose computing platform: Intel Core i5–3470 CPU at 3.2 GHz, with a 16 GB RAM. We present test results for five datasets: ERR321482, SRR359032, ERR532393, SRR1450398, and SRR062462, including metagenomic samples as diverse as a human gut microbiome or a Richmond Mine biofilm sample, retrieved from the NCBI Sequence Read Archive [<xref ref-type="bibr" rid="CR29">29</xref>]. Additional file <xref rid="MOESM2" ref-type="media">2</xref> contains detailed descriptions of the datasets tested.</p>
      <p>The comparison results of compression ratios among six software suites are given in Table <xref rid="Tab2" ref-type="table">2</xref> and Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The methods compared include three different modes of MetaCRAM, termed Huffman, Golomb and Extended Golomb MetaCRAM. These three techniques differ from each other with respect to the integer compression scheme used. The schemes will be described in detail in the next sections, although we remark that the three methods are chosen to illustrate various compression ratio and decompression time trade-offs.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Compression ratio. The compression ratios for all six software suites, indicating the compression ratio</p></caption><graphic xlink:href="12859_2016_932_Fig2_HTML" id="MO2"/></fig><table-wrap id="Tab2"><label>Table 2</label><caption><p>Comparison of compression ratios of six software suites</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Data</th><th align="left">Original (MB)</th><th align="left">MCH1 (MB)</th><th align="left">MCH2 (MB)</th><th align="left">MCG (MB)</th><th align="left">MCEG (MB)</th><th align="left">Align. %</th><th align="left">Qual value (MB)</th><th align="left">bzip2 (MB)</th><th align="left">gzip (MB)</th><th align="left">MFComp (MB)</th></tr></thead><tbody><tr><td align="left">ERR321482</td><td align="left">1429</td><td align="left"><bold>191</bold></td><td align="left">186</td><td align="left">312</td><td align="left">213</td><td align="left">29.6</td><td align="left">411</td><td align="left">362</td><td align="left">408</td><td align="left">229</td></tr><tr><td align="left">SRR359032</td><td align="left">3981</td><td align="left">319</td><td align="left">282</td><td align="left">657</td><td align="left">458</td><td align="left">61.8</td><td align="left">2183</td><td align="left">998</td><td align="left">1133</td><td align="left"><bold>263</bold></td></tr><tr><td align="left">ERR532393</td><td align="left">8230</td><td align="left"><bold>948</bold></td><td align="left">898</td><td align="left">1503</td><td align="left">1145</td><td align="left">46.8</td><td align="left">3410</td><td align="left">2083</td><td align="left">2366</td><td align="left">1126</td></tr><tr><td align="left">SRR1450398</td><td align="left">5399</td><td align="left"><bold>703</bold></td><td align="left">697</td><td align="left">854</td><td align="left">729</td><td align="left">7.7</td><td align="left">365</td><td align="left">1345</td><td align="left">1532</td><td align="left">726</td></tr><tr><td align="left">SRR062462</td><td align="left">6478</td><td align="left"><bold>137</bold></td><td align="left">135</td><td align="left">188</td><td align="left">144</td><td align="left">2.7</td><td align="left">153</td><td align="left">222</td><td align="left">356</td><td align="left">161</td></tr></tbody></table><table-wrap-foot><p>For short hand notation, we used“MCH” = MetaCRAM-Huffman, “MCG” = MetaCRAM-Golomb, “MCEG” = MetaCRAM-extended Golomb, “MFComp” = MFCompress. MCH1 is the default option of MetaCRAM with Huffman encoding, and MCH2 is a version of MetaCRAM in which we removed the redundancy in both quality scores and the read IDs. “Align. %” refers to the total alignment rates from the first and second iteration. Minimum compressed file size achievable by the methods are written in bold case letters. Minimum compressed file size achievable by the methods are written in bold case letters</p></table-wrap-foot></table-wrap></p>
      <p>The result indicates that MetaCRAM using Huffman integer encoding method improves compression ratios of the classical gzip algorithm 2–3 fold on average. For example, MetaCRAM reduces the file size of SRR062462 to only 2 % of the original file size. Observe that MetaCRAM also offers additional features that go beyond compression only, such as taxonomy identification and assembly. Users have the options to retrieve the alignment rate, list of reference genomes, contig files, and alignment information in SAM format. This list produced by MetaCRAM may be stored with very small storage overhead and then used for quick identification of files based on their taxonomic content, which allows for selection in the compressive domain. Information regarding gene profiles was not included in the pipeline output, as gene analysis does not directly contribute to the quality of the compression algorithm.</p>
      <p>In the listed results, the column named “Qual Value (MB)” provides the estimated size of the quality scores for each file, after alignment to references found by Kraken. In our implementation, we replaced these scores with a single “*” symbol per read and also removed the redundancy in read IDs. The result shows that these two options provide better ratios than the default ratio, as shown in Table <xref rid="Tab2" ref-type="table">2</xref> column “MCH2”. However, since read IDs may be needed for analysis of some dataset, we also report results for the default “MCH1” mode which does not dispose of ID tags.</p>
      <p>In terms of the processing time shown in Table <xref rid="Tab3" ref-type="table">3</xref>, the MetaCRAM suite is at a clear disadvantage, with processing time 150-fold slower than bzip2 in the worst case. Figure <xref rid="Fig3" ref-type="fig">3</xref> presents the average runtime of each stage for all five datasets tested, and illustrates that assembly, alignment, and BLAST search are computationally demanding, accounting for 62 percentage of the total time. This implies that removing the second and subsequent assembly rounds of MetaCRAM reduces the processing time significantly, at the cost of a smaller compression ratio. Table <xref rid="Tab4" ref-type="table">4</xref> compares the compression ratios of MetaCRAM with one round and with two rounds of reference discovery, and indicates that removing the assembly, alignment and BLAST steps adds 1–6 MB to the compressed file size. Thus, the user has an option to skip the second round in order to expedite the processing time.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Average Runtime of Each Stage of MetaCRAM. Detailed distribution of the average runtimes of MetaCRAM for all five datasets tested. We used “_1” to indicate the processes executed in the first round, and “_2” to denote the processes executed in the second round</p></caption><graphic xlink:href="12859_2016_932_Fig3_HTML" id="MO3"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>Comparison of processing (compression) times of six software suites. Times are recorded row by row denoting real, user, and system time in order</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Data</th><th align="left">Time</th><th align="left">MCH</th><th align="left">MCG</th><th align="left">MCEG</th><th align="left">bzip2</th><th align="left">gzip</th><th align="left">MFComp</th></tr></thead><tbody><tr><td align="left">ERR321482</td><td align="left">real</td><td align="left">299 m 20 s</td><td align="left">294 m 27 s</td><td align="left">274 m 43 s</td><td align="left">2 m 2 s</td><td align="left">3 m 49 s</td><td align="left">2 m 38 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">422 m 21 s</td><td align="left">422 m 49 s</td><td align="left">402 m 25 s</td><td align="left">1 m 56 s</td><td align="left">3 m 45 s</td><td align="left">4 m 49 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">12 m 24 s</td><td align="left">8 m 48 s</td><td align="left">12 m 13 s</td><td align="left">0 m 1 s</td><td align="left">0 m 1 s</td><td align="left">0 m 13 s</td></tr><tr><td align="left">SRR359032</td><td align="left">real</td><td align="left">127 m 34 s</td><td align="left">129 m 32 s</td><td align="left">128 m 14 s</td><td align="left">5 m 36 s</td><td align="left">10 m 39 s</td><td align="left">8 m 2 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">245 m 53 s</td><td align="left">247 m 43 s</td><td align="left">253 m 16 s</td><td align="left">5 m 19 s</td><td align="left">10 m 30 s</td><td align="left">13 m 3 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">8 m 37 s</td><td align="left">10 m 1 s</td><td align="left">15 m 25 s</td><td align="left">0 m 2 s</td><td align="left">0 m 2 s</td><td align="left">0 m 15 s</td></tr><tr><td align="left">ERR532393</td><td align="left">real</td><td align="left">639 m 55 s</td><td align="left">635 m 53 s</td><td align="left">641 m 32 s</td><td align="left">11 m 28 s</td><td align="left">22 m 18 s</td><td align="left">17 m 2 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">1061 m 50 s</td><td align="left">1069 m 9 s</td><td align="left">1090 m 20 s</td><td align="left">11 m 4 s</td><td align="left">21 m 58 s</td><td align="left">28 m 29 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">73 m 59 s</td><td align="left">27 m 59 s</td><td align="left">43 m 35 s</td><td align="left">0 m 5 s</td><td align="left">0 m 5 s</td><td align="left">0 m 21 s</td></tr><tr><td align="left">SRR1450398</td><td align="left">real</td><td align="left">440 m 4 s</td><td align="left">439 m 42 s</td><td align="left">440 m 36 s</td><td align="left">7 m 38 s</td><td align="left">14 m 39 s</td><td align="left">10 m 32 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">66 m 56 s</td><td align="left">865 m 38 s</td><td align="left">865 m 6 s</td><td align="left">7 m 19 s</td><td align="left">14 m 24 s</td><td align="left">18 m 8 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">821 m 2 s</td><td align="left">23 m 51 s</td><td align="left">26 m 5 s</td><td align="left">0 m 3 s</td><td align="left">0 m 3 s</td><td align="left">0 m 18 s</td></tr><tr><td align="left">SRR062462</td><td align="left">real</td><td align="left">217 m 21 s</td><td align="left">224 m 32 s</td><td align="left">215 m 58 s</td><td align="left">2 m 48 s</td><td align="left">2 m 6 s</td><td align="left">6 m 38 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">254 m 26 s</td><td align="left">261 m 19 s</td><td align="left">256 m 17 s</td><td align="left">2 m 7 s</td><td align="left">1 m 18 s</td><td align="left">10 m 39 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">15 m 45 s</td><td align="left">16 m 48 s</td><td align="left">20 m 14 s</td><td align="left">0 m 3 s</td><td align="left">0 m 3 s</td><td align="left">0 m 16 s</td></tr></tbody></table></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparison of compressed file sizes of MetaCRAM-Huffman using 2 rounds and 1 round</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Data</th><th align="left">Original (MB)</th><th align="left">MCH-2rounds (MB)</th><th align="left">Align. %</th><th align="left">MCH-1round (MB)</th><th align="left">Align. %</th><th align="left">gzip (MB)</th><th align="left">MFComp (MB)</th></tr></thead><tbody><tr><td align="left">ERR321482</td><td align="left">1429</td><td align="left">191</td><td align="left">29.6</td><td align="left">192</td><td align="left">27</td><td align="left">408</td><td align="left">229</td></tr><tr><td align="left">SRR359032</td><td align="left">3981</td><td align="left">319</td><td align="left">61.8</td><td align="left">315</td><td align="left">57.7</td><td align="left">1133</td><td align="left">263</td></tr><tr><td align="left">ERR532393</td><td align="left">8230</td><td align="left">948</td><td align="left">46.8</td><td align="left">952</td><td align="left">45.8</td><td align="left">2366</td><td align="left">1126</td></tr><tr><td align="left">SRR1450398</td><td align="left">5399</td><td align="left">703</td><td align="left">7.7</td><td align="left">707</td><td align="left">7.1</td><td align="left">1532</td><td align="left">726</td></tr><tr><td align="left">SRR062462</td><td align="left">6478</td><td align="left">137</td><td align="left">2.7</td><td align="left">143</td><td align="left">2.6</td><td align="left">356</td><td align="left">161</td></tr></tbody></table><table-wrap-foot><p>For short hand notation, we used“MCH-2rounds” = MetaCRAM-Huffman with 2 rounds, “MCH-1round” = MetaCRAM-Huffman with 1 round. We also used the shortcut “MFComp” = MFCompress and “Align. %” refers to the percentage of reads aligned during 2 rounds and 1 round, respectively, for MCH-2rounds and MCH-1round</p></table-wrap-foot></table-wrap></p>
      <p>Likewise, Table <xref rid="Tab5" ref-type="table">5</xref> illustrates that the retrieval time of MetaCRAM is longer than that of bzip2, gzip, and MFCompress, but still highly efficient. In practice, the processing time is not as relevant as the retrieval time, as compression is performed once while retrieval is performed multiple times. For long term archival of data, MetaCRAM is clearly the algorithm of choice since the compression ratio, rather than processing or retrieval time, is the most important quality criteria.
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Comparison of retrieval (decompression) times of six software suites. Times are recorded row by row denoting real, user, and system time in order</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Data</th><th align="left">Time</th><th align="left">MCH</th><th align="left">MCG</th><th align="left">MCEG</th><th align="left">bzip2</th><th align="left">gzip</th><th align="left">MFComp</th></tr></thead><tbody><tr><td align="left">ERR321482</td><td align="left">real</td><td align="left">23 m 17 s</td><td align="left">25 m 18 s</td><td align="left">24 m 56 s</td><td align="left">0 m 57 s</td><td align="left">0 m 17 s</td><td align="left">2 m 26 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">16 m 17 s</td><td align="left">16 m 30 s</td><td align="left">17 m 7 s</td><td align="left">0 m 45 s</td><td align="left">0 m 9 s</td><td align="left">4 m 42 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">9 m 2 s</td><td align="left">10 m 42 s</td><td align="left">10 m 25 s</td><td align="left">0 m 2 s</td><td align="left">0 m 1 s</td><td align="left">0 m 4 s</td></tr><tr><td align="left">SRR359032</td><td align="left">real</td><td align="left">12 m 16 s</td><td align="left">11 m 43 s</td><td align="left">13 m 17 s</td><td align="left">2 m 37 s</td><td align="left">1 m 28 s</td><td align="left">7 m 58 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">11 m 59 s</td><td align="left">11 m 24 s</td><td align="left">12 m 43 s</td><td align="left">2 m 8 s</td><td align="left">0 m 28 s</td><td align="left">15 m 10 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">2 m 24 s</td><td align="left">1 m 42 s</td><td align="left">3 m 12 s</td><td align="left">0 m 4 s</td><td align="left">0 m 2 s</td><td align="left">0 m 19 s</td></tr><tr><td align="left">ERR532393</td><td align="left">real</td><td align="left">48 m 19 s</td><td align="left">47 m 5 s</td><td align="left">55 m 58 s</td><td align="left">5 m 25 s</td><td align="left">2 m 30 s</td><td align="left">15 m 29 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">39 m 59 s</td><td align="left">40 m 5 s</td><td align="left">43 m 21 s</td><td align="left">4 m 23 s</td><td align="left">0 m 55 s</td><td align="left">29 m 23 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">15 m 39 s</td><td align="left">13 m 25 s</td><td align="left">29 m 17 s</td><td align="left">0 m 7 s</td><td align="left">0 m 5 s</td><td align="left">0 m 17 s</td></tr><tr><td align="left">SRR1450398</td><td align="left">real</td><td align="left">28 m 43 s</td><td align="left">27 m 54 s</td><td align="left">29 m 27 s</td><td align="left">3 m 25 s</td><td align="left">1 m 54 s</td><td align="left">10 m 8 s</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">29 m 55 s</td><td align="left">29 m 47 s</td><td align="left">30 m 45 s</td><td align="left">2 m 52 s</td><td align="left">0 m 37 s</td><td align="left">19 m 1 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">7 m 10 s</td><td align="left">5 m 52 s</td><td align="left">7 m 4 s</td><td align="left">0 m 5 s</td><td align="left">0 m 3 s</td><td align="left">0 m 26 s</td></tr><tr><td align="left">SRR062462</td><td align="left">real</td><td align="left">23 m 9 s</td><td align="left">22 m 55 s</td><td align="left">26 m 6 s</td><td align="left">1 m 3 s</td><td align="left">1 m 19 s</td><td align="left">5 m 52</td></tr><tr><td align="left"/><td align="left">user</td><td align="left">21 m 10 s</td><td align="left">21 m 10 s</td><td align="left">21 m 58 s</td><td align="left">0 m 42 s</td><td align="left">0 m 22 s</td><td align="left">10 m 31 s</td></tr><tr><td align="left"/><td align="left">sys</td><td align="left">4 m 49 s</td><td align="left">4 m 53 s</td><td align="left">10 m 12 s</td><td align="left">0 m 4 s</td><td align="left">0 m 3 s</td><td align="left">0 m 26 s</td></tr></tbody></table></table-wrap></p>
      <p>We also remark on the impact of different integer encoding methods on the compression ratio. Huffman, Golomb, and extended Golomb codes all have their advantages and disadvantages. For the tested datasets, Huffman clearly achieves the best ratio, as it represents the optimal compression method, whereas Golomb and extended Golomb compression improve the real and system time as a result of computation efficiency. However, the parallel implementation of MetaCRAM makes the comparison of processing time of the three methods slightly biased: for example, if we perform compression while performing assembly, compression will take much more time than compressing while running an alignment algorithm. As the processing and retrieval time is not consistent among the three methods, we recommend using Huffman coding for archival storage.</p>
    </sec>
  </sec>
  <sec id="Sec5" sec-type="discussion">
    <title>Discussion</title>
    <p>In what follows, we comment on a number of useful properties of the MetaCRAM program, including compatibility, losslessness, partial assembly results and compressive computing.</p>
    <p><bold>Compatibility.</bold> MetaCRAM uses well established and widely tested genomic analysis tools, and it also follows the standard genomic data compression format CRAM, hence making the results of downstream analysis compatible with a current standard for genomic compression.</p>
    <p><bold>Lossless compression principle.</bold> By its very nature, MetaCRAM is a lossless compression scheme as it encodes the differential information between the reference and the metagenomic reads in a 100 % accurate fashion. Nevertheless, we enabled a feature that allow for some partial loss of information, such as the read ID tags. It is left to the discretion of the user to choose suitable options.</p>
    <p><bold>CRAM versus MFCompress.</bold> MFCompress achieves good compression ratios when compressing highly redundant reads. MetaCRAM consistently achieves a rate proportional to the alignment rate because it only encodes the small difference between the reference genome and the read. As more microbial genome become available, MetaCRAM will most likely offer higher compression ratio than other tools in general. Note that only on one data file - SRR359032 - did MFCompress achieve better compression ratios than MetaCRAM, most likely due to the redundancy issues previously mentioned.</p>
    <p><bold>Metagenomic assembly.</bold> Metagenomic assembly is a challenging task, and there is a widely accepted belief that it is frequently impossible to perform meaningful assembly on mixture genomes containing species from related genomes. Nevertheless, we are using assembly mostly as a means for identifications, but at the same time its output provides useful contigs for gene transfer analysis and discovery. In the case that assembly fails on a dataset, we suggest skipping the assembly step so as to trade off computation time with discovery of new reference genomes and contigs.</p>
    <p><bold>Compressive computing.</bold> There has been an effort towards computing in the compressed domain, in order to eliminate the need for persistne compression and decompression time when all one needs to perform is simple alignment [<xref ref-type="bibr" rid="CR30">30</xref>]. Similarly, MetaCRAM offers easy retrieval and selection based on the list of references stored as an option. For example, suppose we perform MetaCRAM on all available human gut metagenome data. If we want to analyze the datasets with a concentration of <italic>Escherichia coli</italic>, we avoid sacrificing retrieval time by quickly scanning the list of reference files and only retrieving the datasets with <italic>E. coli</italic>.</p>
  </sec>
  <sec id="Sec6">
    <title>Methods</title>
    <sec id="Sec7">
      <title>Pre-Processing</title>
      <p>MetaCRAM accepts both unpaired and paired-end reads. If paired-end reads are given as an input to MetaCRAM, then the first preprocessing step is to append the read IDs with a “_1” or a “_2” indicating that the read came from the first or second mate, respectively. Another preprocessing step includes filtering out the quality scores in case that the input file is in FASTQ format. This filtering process allows for using new and emerging quality score compression methods without constantly updating the MetaCRAM platform. Note that the paired end labeling is done automatically, while filtering can be implemented outside the integrated pipeline by the user, based on his/her requirements for quality score lossy or lossless compression goals.</p>
      <p>MetaCRAM uses as a default FASTA files that do not contain quality values, in which case the resulting SAM file contains the symbol “I” repeated as many times as the length of the sequence. These symbols amount to about 100 bytes per read, and this overhead increases proportionally to the number of reads (Table <xref rid="Tab2" ref-type="table">2</xref> of the “<xref rid="Sec2" ref-type="sec">Results</xref>” Section illustrates the amount of storage space that data quality scores occupy in each dataset, ranging from 153 MB to 3.4 GB). In order to reduce the size of this unnecessary field, MetaCRAM replaces the sequence of “I”s with a single symbol “*”, complying with the standard SAM format. Likewise, read IDs are highly repetitive in nature: for instance, every read ID starts with the data name such as “SRR359032.”, followed by its unique read number. Rather than repeating the data name for every read, we simply store it once, and append it when performing decompression. Both versions of MetaCRAM – one incorporating these two options – and another one without the described features are available to the user. The former version of the methods requires a slightly longer compression and decompression time.</p>
    </sec>
    <sec id="Sec8">
      <title>Taxonomy identification</title>
      <p>Given the labeled read sequences of a metagenomic sample, the first step is to identify the mixture of species present in the sample. There are several taxonomy identification methods currently in use: the authors of [<xref ref-type="bibr" rid="CR31">31</xref>] proposes to use the 16S rRNA regions for bacterial genome identification, MetaPhyler [<xref ref-type="bibr" rid="CR32">32</xref>] scans for unique markers exceeding length 20 and provides a taxonomy level as specific as the genus. On the other hand, a new taxonomy identification software known as Kraken [<xref ref-type="bibr" rid="CR15">15</xref>], based on exact alignment of <italic>k</italic>-mers to the database of known species, often outperforms MetaPhyler and other methods both in terms of speed and discovery of true positives, as indicated by our tests.</p>
      <p>MetaCRAM employs Kraken as a default tool in the pipeline. Kraken produces an output report which is automatically processed by MetaCRAM. Part of the report contains information about species present in the sample, as well as their abundance. We rank order the species in from the most abundant to the least abundant, where abundance is based on the number of reads identified to match a species in the database. For downstream analysis, MetaCRAM selects the “most relevant” species and uses their genomes as references. The default definition of “most relevant” is the top 75 species, but one has the option to choose a threshold for the abundance value or for the number of references used. As an illustration, Table <xref rid="Tab1" ref-type="table">1</xref> lists the results of an analysis of the impact of different thresholds on the processing time and the compression ratio.</p>
    </sec>
    <sec id="Sec9">
      <title>Alignment and assembly</title>
      <p>After a group of reference genomes is carefully chosen based on the Kraken software output, alignment of reads to the reference genomes is performed. This task is accomplished by using Bowtie2, a standard software tool for ultra-fast alignment of short reads to long genomes. The alignment information is stored in a SAM (Sequence Alignment/Map) file format and subsequently used for compression via reference-based algorithms.</p>
      <p>Due to the fact that many species in a metagenome sample have never been sequenced before, some reads will not be aligned to any of the references with high alignment scores, and we collectively refer to them as <italic>unaligned</italic> reads hereafter. In order to discover reference genomes for unaligned reads, we assemble the unaligned reads in a relatively efficient, although often time consuming manner using a metagenomic assembler. Our metagenomic assembler of choice is IDBA-UD [<xref ref-type="bibr" rid="CR18">18</xref>], given that in our tests it produced the largest number of contigs leading to new reference identification. Alternatives to IDBA-UD include the Ray Meta software [<xref ref-type="bibr" rid="CR33">33</xref>].</p>
      <p>When the reads have high sequencing depth and large overlaps, the <italic>contigs</italic> produced by the assembler may be queried using BLAST to identify the organisms they most likely originated from. The user may choose to BLAST only the top <italic>n</italic> longest contigs, where <italic>n</italic> is a user specified number, but in our analysis we use <italic>all</italic> contigs (which is also the default setting). Subsequently, we align the unaligned reads to the newly found references.</p>
      <p>In some rare cases, the assembler may fail depending on the number of species in the metasample and the sequencing depth, in which case one may want to skip the assembly step and compress the unaligned reads in a reference-free manner. For reference-free compression, the software of choice in MetaCRAM is MFCompress [<xref ref-type="bibr" rid="CR14">14</xref>]. As long as the assembler is successful, one can reduce the volume of unaligned reads by iterating the process of assembly, BLAST, and alignment as illustrated at the top right hand of Fig. <xref rid="Fig1" ref-type="fig">1</xref>. All our demonstrations and results are based on two iterations of the described algorithmic loop.</p>
    </sec>
    <sec id="Sec10">
      <title>Distribution of read starting positions</title>
      <p>We empirically studied the distribution of integers representing the read positions, variation positions, and paired-end offsets in order to choose the most suitable compression method. As an example, the distribution of the starting positions for the reads that aligned to JH603150 (genome of Klebsiella oxytoca) in the dataset SRR359032 is shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. This distribution was truncated after achieving a 90 % coverage of the data (i.e., after only 10 % of the read start positions exceeded the depicted maximum length). The empirical distribution is shown in yellow, while a fitted power law distributions is plotted and determined according to [<xref ref-type="bibr" rid="CR22">22</xref>], with <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$P_{i} = 2^{-\log _{m} i}\frac {1}{2i(m-1)}$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:mo>log</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munder><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2016_932_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>i</italic> is the integer to be encoded, and <italic>m</italic> is the divisor in the extended Golomb code. The parameter choose shown is <italic>m</italic>=3 and 4. The negative binomial distribution is fitted using Maximum Likelihood Estimation (MLE), while the Geometric distribution is fitted by two different means: using MLE and ezfit, a MATLAB script which performs an unconstrained nonlinear minimization of the sum of squared residuals with respect to various parameters.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Integer Distribution. Distribution fitting of integers to be encoded, truncated at 90 % of the integer data</p></caption><graphic xlink:href="12859_2016_932_Fig4_HTML" id="MO4"/></fig></p>
      <p>For single reference alignment methods, it was reported that the best fit for the empirical distribution is a geometric distribution or a negative binomial distribution [<xref ref-type="bibr" rid="CR34">34</xref>]. However, due to sequencing errors and non-uniform distributions of hydrogen bond breakage, the empirical data often deviates from geometric or negative binomial distributions [<xref ref-type="bibr" rid="CR35">35</xref>]. In addition, for metagenomic samples, there exist multiple references which may have good alignments with reads that did not originally correspond to the genomic sample of the reference. This creates additional changes in the read starting position with respect to the geometric distribution. Moreover, one has to encode not only the read positions but also the variation positions and paired-end offsets, making it difficult to claim any one of the fitted distributions is better than others. This observation is supported by Fig. <xref rid="Fig4" ref-type="fig">4</xref>. Since there is no known <italic>efficient</italic> optimal encoding method for a set of integers with negative binomial distributions, and Golomb and extended Golomb encoding are optimal for geometric distributions and power law distributions, respectively, we use these two methods with <italic>m</italic>=3. The parameter <italic>m</italic> is chosen based on extensive experiments, although the user has the freedom to adjust and modify its value.</p>
      <p>As the number of unaligned reads that remains after a few iterations of MetaCRAM is relatively small, these reads were compressed using a reference-free tool such as MFCompress [<xref ref-type="bibr" rid="CR14">14</xref>], which is based on finite-context models. Furthermore, the SAM files produced after running Bowtie2 are converted to the sorted and indexed binary format of a BAM file using SAMtools [<xref ref-type="bibr" rid="CR36">36</xref>]. Each BAM file is compressed via reference-based compression against its representative to a standard CRAM format. We tested three different modes of the CRAM toolkit [<xref ref-type="bibr" rid="CR11">11</xref>]: Huffman, Golomb, and Extended Golomb encoding, all of which are described in the next section. Note that the Extended Golomb encoding method is our new addition to the classical CRAM method, as it appears to offer good compromises between compression and decompression speed and compression ratios.</p>
      <p>Intrinsically, SAM files contain quality values and unique read IDs for each read, which inevitably account for a large file size: quality values are characters of length as long as the sequence, and read IDs often repeat the name of the dataset. By default, MetaCRAM preserves all quality values and read IDs as designed in CRAM.</p>
      <sec id="Sec11">
        <title>Compression</title>
        <p>Compression in the reference-based mode is accomplished by compressing the starting points of references with respect to the reference genomes and the base differences between the reads and references. As both the starting points and bases belong to a finite integer alphabet, we used three different integer compression methods, briefly described below.</p>
        <p>Huffman coding is a prefix-free variable length compression method for known distributions [<xref ref-type="bibr" rid="CR20">20</xref>] which is information-theoretically optimal [<xref ref-type="bibr" rid="CR37">37</xref>]. The idea is to encode more frequent symbols with fewer bits than non-frequent ones. For example, given an alphabet <italic>A</italic>=(<italic>a</italic>,<italic>b</italic>,<italic>c</italic>,<italic>d</italic>,<italic>e</italic>) and the corresponding distribution <italic>P</italic>=(0.25,0.25,0.2,0.15,0.15), building a Huffman tree results in the codebook <italic>C</italic>=(00,10,11,010,011). Decoding relies on the Huffman tree constructed during encoding which is stored in an efficient manner, usually ordered according to the frequency of the symbol. Due to the prefix-free property, Huffman coding is uniquely decodable coding and does not require any special marker between words. Two drawbacks of Huffman coding that make it a costly solution for genomic compression are its storage complexity, since we need to record large tree structures for big alphabet size which arise when encoding positions in long sequences and the need to know the underlying distribution <italic>a priori</italic>. Adaptive Huffman coding mitigates the second problem, at the cost of increased computational complexity associated with constructing multiple encoding trees [<xref ref-type="bibr" rid="CR38">38</xref>]. In order to alleviate computational challenges, we implemented so called <italic>canonical</italic> Huffman encoding, which bypasses the problem of storing a large code tree by sequentially encoding lengths of the codes [<xref ref-type="bibr" rid="CR39">39</xref>].</p>
        <p>Golomb codes are optimal prefix-free codes for countably infinite lists of non-negative integers following a geometric distribution [<xref ref-type="bibr" rid="CR21">21</xref>]. In Golomb coding, one encodes an integer <italic>n</italic> in two parts, using its quotient <italic>q</italic> and remainder <italic>r</italic> with respect to the divisor <italic>m</italic>. The quotient is encoded in <italic>unary</italic>, while the remainder is encoded via <italic>truncated binary</italic> encoding. Given a list of integers following a geometric distribution with known mean <italic>μ</italic>, the dividend <italic>m</italic> can be optimized so as to reduce code length. In [<xref ref-type="bibr" rid="CR40">40</xref>], the optimal value of <italic>m</italic> was derived for <italic>m</italic>=2<sup><italic>k</italic></sup>, for any integer <italic>k</italic>. The encoding is known as the Golomb-Rice procedure, and it proceeds as follows: first, we let <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$k^{*}=\textit {max}\Bigg \{0, 1+\left \lfloor \log _{2}\Big (\frac {\log (\phi -1)}{\log \big (\frac {\mu }{\mu +1}\big)}\Big) \right \rfloor \Bigg \}$\end{document}</tex-math><mml:math id="M4"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">max</mml:mtext><mml:mstyle mathsize="2.45em"><mml:mfenced close="" open="{" separators=""><mml:mrow/></mml:mfenced></mml:mstyle><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfenced close="⌋" open="⌊" separators=""><mml:mrow><mml:munder><mml:mrow><mml:mo>log</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munder><mml:mstyle mathsize="1.61em"><mml:mfenced close="" open="(" separators=""><mml:mrow/></mml:mfenced></mml:mstyle><mml:mfrac><mml:mrow><mml:mo>log</mml:mo><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>log</mml:mo><mml:mstyle mathsize="1.19em"><mml:mfenced close="" open="(" separators=""><mml:mrow/></mml:mfenced></mml:mstyle><mml:mfrac><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mstyle mathsize="1.19em"><mml:mfenced close="" open=")" separators=""><mml:mrow/></mml:mfenced></mml:mstyle></mml:mrow></mml:mfrac><mml:mstyle mathsize="1.61em"><mml:mfenced close="" open=")" separators=""><mml:mrow/></mml:mfenced></mml:mstyle></mml:mrow></mml:mfenced><mml:mstyle mathsize="2.45em"><mml:mfenced close="" open="}" separators=""><mml:mrow/></mml:mfenced></mml:mstyle></mml:math><inline-graphic xlink:href="12859_2016_932_Article_IEq2.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\phi =\frac {(\sqrt {5}+1)}{2}$\end{document}</tex-math><mml:math id="M6"><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:msqrt><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msqrt><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2016_932_Article_IEq3.gif"/></alternatives></inline-formula>. Unary coding represents an integer <italic>i</italic> by <italic>i</italic> ones followed by a single zero. For example, the integer <italic>i</italic>=4 in unary reads as 11110. Truncated binary encoding is a prefix-free code for an alphabet of size <italic>m</italic>, which is more efficient than standard binary encoding. Because the remainder <italic>r</italic> can only take values in {0,1,…, m-1}, according to truncated binary encoding, we assign to the first 2<sup><italic>k</italic>+1</sup>−<italic>m</italic> symbols codewords of fixed length <italic>k</italic>. The remaining symbols are encoded via codewords of length <italic>k</italic>+1, where <italic>k</italic>=⌊log2(<italic>m</italic>)⌋. For instance, given <italic>n</italic>=7 and <italic>m</italic>=3, we have 7=2×3+1, implying <italic>q</italic>=2 and <italic>r</italic>=1. Encoding 2 in unary gives 110 and 1 in truncated binary reads as 10. Hence, the codeword used to encode the initial integer is the concatenation of the two representations, namely 11010.</p>
        <p>Decoding of Golomb encoded codewords is also decoupled into decoding of the quotient and the remainder. Given a codeword, the number of ones before the first zero determines the quotient <italic>q</italic>, while the remaining <italic>k</italic> or <italic>k</italic>+1 bits, represents the remainder <italic>r</italic> according to truncated binary decoding for an alphabet of size <italic>m</italic>. The integer <italic>n</italic> is obtained as <italic>n</italic>=<italic>q</italic>×<italic>m</italic>+<italic>r</italic>.</p>
        <p>Golomb encoding has one advantages over Huffman coding in so far that it is computationally efficient (as it only requires division operations). One does not need to the distribution <italic>a priori</italic>, although there are clearly no guarantees that Golomb coding for an unknown distribution will be even near-optimal: Golomb encoding is optimal only for integers following a geometric distribution.</p>
        <p>An extension of Golomb encoding, termed <italic>extended</italic> Golomb [<xref ref-type="bibr" rid="CR22">22</xref>] coding, is an iterative method for encoding non-negative integers following a power law distribution. One divides an integer <italic>n</italic> by <italic>m</italic> until the quotient becomes 0, and then encodes the number of iterations <italic>M</italic> in unary, and an array of remainders <italic>r</italic> according to an encoding table. This method has an advantage over Golomb coding when encoding large integers, such is the case for read position compression. As an example, consider the integer <italic>n</italic>=1000: with <italic>m</italic>=2, Golomb coding would produce <italic>q</italic>=500 and <italic>r</italic>=0, and unary encoding of 500 requires 501 bits. With extended Golomb coding, the number of iterations equals <italic>M</italic>=9 and encoding requires only 10 bits. As an illustration, let us encode <italic>n</italic>=7 given <italic>m</italic>=3. In the first iteration, 7=2×3+1, so <italic>r</italic><sub>1</sub>=1 is encoded as 10, and <italic>q</italic><sub>1</sub>=2. Since the quotient is not 0, we iterate the process: 2=0×3+2 implies <italic>r</italic><sub>2</sub>=2, which is encoded as 1, and <italic>q</italic><sub>2</sub>=0. Because the quotient is at this step 0, we encode <italic>M</italic>=2 as 110 and <italic>r</italic>=<italic>r</italic><sub>2</sub><italic>r</italic><sub>1</sub>=110, and our codeword is 110110.</p>
        <p>The decoding of extended Golomb code is also performed in <italic>M</italic> iterations. Since we have a remainder stored at each iteration and the last quotient equals <italic>q</italic><sub><italic>M</italic></sub>=0, it is possible to reconstruct the original integer. Similar to Golomb coding, extended Golomb encoding is computationally efficient, but optimal only for integers with power law distribution.</p>
        <p>There are various other methods for integer encoding, such as Elias Gamma and Delta Encoding [<xref ref-type="bibr" rid="CR41">41</xref>], which are not pursued in this paper due to the fact that they do not appear to offer good performance for the empirical distributions observed in our read position encoding experiments.</p>
      </sec>
    </sec>
    <sec id="Sec12">
      <title>Products</title>
      <p>The compressed unaligned reads, CRAM files, list of reference genomes (optional), alignment rate (optional), contig files (optional) are all packaged into an archive. The resulting archive can be stored in a distributed manner and when desired, the reads can be losslessly reconstructed via the CRAM toolkit. Additional file <xref rid="MOESM3" ref-type="media">3</xref> contains software instructions, and detailed descriptions of created files and folders by MetaCRAM processing are available in Additional file <xref rid="MOESM4" ref-type="media">4</xref>.</p>
    </sec>
    <sec id="Sec13">
      <title>Decompression</title>
      <p>Lossless reconstruction of the reads from the compressed archive is done in two steps. For those reads with known references in CRAM format, decompression is performed with an appropriate integer decompression algorithm. When the files are converted back into the SAM format, we retrieve only the two necessary fields for FASTA format, i.e., the read IDs and the sequences printed in separate lines. Unaligned reads are decompressed separately, through the decoding methods used in MFCompress.</p>
    </sec>
    <sec id="Sec14">
      <title>Post-processing</title>
      <p>The two parts of reads are now combined into one file, and they are sorted by the read IDs in an ascending order. If the reads were paired-end, they are separated into two files according to the mate “flag” assigned in the processing step.</p>
    </sec>
    <sec id="Sec15">
      <title>Effects of parallelization</title>
      <p>One key innovation in the implementation of MetaCRAM is parallelization of the process, which was inspired by parallel <italic>single genome</italic> assembly used in TIGER [<xref ref-type="bibr" rid="CR42">42</xref>]. Given that metagenomic assembly is computationally highly demanding, and in order to fully utilize the computing power of a standard desktop, MetaCRAM performs meta assembly of unaligned reads and compression of aligned reads in parallel. As shown in Table <xref rid="Tab6" ref-type="table">6</xref>, parallelization improves real, user, and system time by 23–40 %.
<table-wrap id="Tab6"><label>Table 6</label><caption><p>Processing time improvements for two rounds of MetaCRAM on the SRR359032 dataset (5.4 GB, without removing redundancy in description lines) resulting from parallelization of assembly and compression</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Time</th><th align="left">Without parallelization</th><th align="left">With parallelization</th><th align="left">Reduction (%)</th></tr></thead><tbody><tr><td align="left">Real</td><td align="center">235 m 40 s</td><td align="center">170 m 4 s</td><td align="center">27.7</td></tr><tr><td align="left">User</td><td align="center">449 m 40 s</td><td align="center">346 m 33 s</td><td align="center">22.9</td></tr><tr><td align="left">System</td><td align="center">14 m 13 s</td><td align="center">8 m 45 s</td><td align="center">40.1</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec16">
    <title>Availability of supporting data</title>
    <p>The datasets supporting the results of this article are available in the National Center for Biotechnology Information Sequence Read Archive repository, under accession numbers ERR321482 (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sra/ERX294615">http://www.ncbi.nlm.nih.gov/sra/ERX294615</ext-link>), SRR359032 (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sra/SRX103579">http://www.ncbi.nlm.nih.gov/sra/SRX103579</ext-link>), ERR532393 (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sra/ERX497596">http://www.ncbi.nlm.nih.gov/sra/ERX497596</ext-link>), SRR1450398 (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sra/SRX621521">http://www.ncbi.nlm.nih.gov/sra/SRX621521</ext-link>), SRR062462 (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sra/SRX024927">http://www.ncbi.nlm.nih.gov/sra/SRX024927</ext-link>).</p>
  </sec>
  <sec id="Sec17" sec-type="conclusion">
    <title>Conclusions</title>
    <p>We introduced MetaCRAM, the first parallel architecture for reference-based, lossless compression of metagenomic data. The compression scheme is compatible with standard CRAM formats and offers significantly improved compression ratios compared to the existing software suites, compressing file to 2-13 percent of the original size. Furthermore, it provides the user with taxonomy and assembly information, allowing for fast selection of relevant files in the compressed domain. Thus, MetaCRAM may represent an important processing platform for large metagenomic files.</p>
  </sec>
</body>
<back>
  <app-group>
    <app id="App1">
      <sec id="Sec18">
        <title>Additional files</title>
        <p>
          <media position="anchor" xlink:href="12859_2016_932_MOESM1_ESM.pdf" id="MOESM1">
            <label>Additional file 1</label>
            <caption>
              <p><bold>Comparison between Kraken and MetaPhyler.</bold> We compare two taxonomy identification tools and decide that Kraken outperforms MetaPhyler in terms of both speed and accuracy. Additional file <xref rid="MOESM4" ref-type="media">4</xref> contains a table of randomly selected set of 15 species used for the comparison. (PDF 11 kb)</p>
            </caption>
          </media>
        </p>
        <p>
          <media position="anchor" xlink:href="12859_2016_932_MOESM2_ESM.pdf" id="MOESM2">
            <label>Additional file 2</label>
            <caption>
              <p><bold>Datasets used for testing MetaCRAM.</bold> This file has detailed descriptions of the 5 datasets used for testing MetaCRAM, with unique ID specified in the NCBI SRA and the type of library used. (PDF 13 kb)</p>
            </caption>
          </media>
        </p>
        <p>
          <media position="anchor" xlink:href="12859_2016_932_MOESM3_ESM.pdf" id="MOESM3">
            <label>Additional file 3</label>
            <caption>
              <p><bold>Software instruction.</bold> This file includes specific commands to compress or decompress MetaCRAM, including options available. It also contains default software commands used for each step of MetaCRAM pipeline. (PDF 117 kb)</p>
            </caption>
          </media>
        </p>
        <p>
          <media position="anchor" xlink:href="12859_2016_932_MOESM4_ESM.pdf" id="MOESM4">
            <label>Additional file 4</label>
            <caption>
              <p><bold>Outcome of MetaCRAM.</bold> Additional file <xref rid="MOESM2" ref-type="media">2</xref> illustrates detailed outcome of MetaCRAM, such as files and folders produced after compression and decompression, and an example of console output. (PDF 82 kb)</p>
            </caption>
          </media>
        </p>
      </sec>
    </app>
  </app-group>
  <fn-group>
    <fn>
      <p>
        <bold>Competing interests</bold>
      </p>
      <p>The authors declare that they have no competing interests.</p>
    </fn>
    <fn>
      <p>
        <bold>Authors’ contributions</bold>
      </p>
      <p>MK, XZ, JL, FF, VV and OM contributed to the theoretical development of the algorithmic method. MK, XZ and JL implemented the algorithms, while MK, XZ, and FF, tested it on a number of datasets. MK also co-wrote the paper and suggested a number of components in the execution pipeline. OM conceived the works, proposed the compression architecture and wrote parts of the paper. All authors read and approved the final manuscript.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>This work was supported by National Science Foundation grants CCF 0809895, CCF 1218764, IOS 1339388, CSoI-CCF 0939370, National Institute of Health U01 BD2K for Targeted Software Development U01 CA198943-02, and the National Science Foundation Graduate Research Fellowship Program under Grant Number DGE-1144245. The authors also thank Amin Emad for useful discussions in the early stage of the project.</p>
  </ack>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peterson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Garges</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Giovanni</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>McInnes</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Schloss</surname>
            <given-names>JA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The nih human microbiome project</article-title>
        <source>Genome Res</source>
        <year>2009</year>
        <volume>19</volume>
        <issue>12</issue>
        <fpage>2317</fpage>
        <lpage>323</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.096651.109</pub-id>
        <?supplied-pmid 19819907?>
        <pub-id pub-id-type="pmid">19819907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kong</surname>
            <given-names>HH</given-names>
          </name>
        </person-group>
        <article-title>Skin microbiome: genomics-based insights into the diversity and role of skin microbes</article-title>
        <source>Trends Mol Med</source>
        <year>2011</year>
        <volume>17</volume>
        <issue>6</issue>
        <fpage>320</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1016/j.molmed.2011.01.013</pub-id>
        <?supplied-pmid 21376666?>
        <pub-id pub-id-type="pmid">21376666</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rusch</surname>
            <given-names>DB</given-names>
          </name>
          <name>
            <surname>Halpern</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Sutton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Heidelberg</surname>
            <given-names>KB</given-names>
          </name>
          <name>
            <surname>Williamson</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yooseph</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The sorcerer ii global ocean sampling expedition: northwest atlantic through eastern tropical pacific</article-title>
        <source>PLoS Biol</source>
        <year>2007</year>
        <volume>5</volume>
        <issue>3</issue>
        <fpage>77</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.0050077</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huson</surname>
            <given-names>DH</given-names>
          </name>
          <name>
            <surname>Auch</surname>
            <given-names>AF</given-names>
          </name>
          <name>
            <surname>Qi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Schuster</surname>
            <given-names>SC</given-names>
          </name>
        </person-group>
        <article-title>Megan analysis of metagenomic data</article-title>
        <source>Genome research</source>
        <year>2007</year>
        <volume>17</volume>
        <issue>3</issue>
        <fpage>377</fpage>
        <lpage>86</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.5969107</pub-id>
        <?supplied-pmid 17255551?>
        <pub-id pub-id-type="pmid">17255551</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Langille</surname>
            <given-names>MG</given-names>
          </name>
          <name>
            <surname>Zaneveld</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Caporaso</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>McDonald</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Knights</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Reyes</surname>
            <given-names>JA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Predictive functional profiling of microbial communities using 16s rrna marker gene sequences</article-title>
        <source>Nature biotechnology</source>
        <year>2013</year>
        <volume>31</volume>
        <issue>9</issue>
        <fpage>814</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.2676</pub-id>
        <?supplied-pmid 23975157?>
        <pub-id pub-id-type="pmid">23975157</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deorowicz</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Grabowski</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Data compression for sequencing data</article-title>
        <source>Algoritm Mol Biol</source>
        <year>2013</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>25</fpage>
        <pub-id pub-id-type="doi">10.1186/1748-7188-8-25</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <mixed-citation publication-type="other">Adjeroh D, Zhang Y, Mukherjee A, Powell M, Bell T. Dna sequence compression using the burrows-wheeler transform. In: Bioinformatics Conference, 2002. Proceedings. IEEE Computer Society. IEEE: 2002. p. 303–13. <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1039352%26tag=1">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1039352%26tag=1</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <mixed-citation publication-type="other">Nevill-Manning CG, Witten IH. Protein is incompressible. In: Data Compression Conference, 1999. Proceedings. DCC’99. IEEE: 1999. p. 257–66. <ext-link ext-link-type="uri" xlink:href="https://www.researchgate.net/profile/Xin_Chen78/publication/10984449_DNACompress_fast_and_effective_DNA_sequence_compression/links/5445db610cf22b3c14ddf08b.pdf">https://www.researchgate.net/profile/Xin_Chen78/publication/10984449_DNACompress_fast_and_effective_DNA_ sequence_compression/links/5445db610cf22b3c14ddf08b.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Tromp</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Dnacompress: fast and effective dna sequence compression</article-title>
        <source>Bioinforma</source>
        <year>2002</year>
        <volume>18</volume>
        <issue>12</issue>
        <fpage>1696</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/18.12.1696</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DC</given-names>
          </name>
          <name>
            <surname>Ruzzo</surname>
            <given-names>WL</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Katze</surname>
            <given-names>MG</given-names>
          </name>
        </person-group>
        <article-title>Compression of next-generation sequencing reads aided by highly efficient de novo assembly</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2012</year>
        <volume>22</volume>
        <fpage>e171</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gks754</pub-id>
        <pub-id pub-id-type="pmid">22904078</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fritz</surname>
            <given-names>MH-Y</given-names>
          </name>
          <name>
            <surname>Leinonen</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Cochrane</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Birney</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Efficient storage of high throughput dna sequencing data using reference-based compression</article-title>
        <source>Genome Res</source>
        <year>2011</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>734</fpage>
        <lpage>40</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.114819.110</pub-id>
        <pub-id pub-id-type="pmid">21245279</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yanovsky</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Recoil-an algorithm for compression of extremely large datasets of dna data</article-title>
        <source>Algoritm Mol Biol</source>
        <year>2011</year>
        <volume>6</volume>
        <issue>1</issue>
        <fpage>23</fpage>
        <pub-id pub-id-type="doi">10.1186/1748-7188-6-23</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hach</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Numanagić</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Alkan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sahinalp</surname>
            <given-names>SC</given-names>
          </name>
        </person-group>
        <article-title>Scalce: boosting sequence compression algorithms using locally consistent encoding</article-title>
        <source>Bioinforma</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>23</issue>
        <fpage>3051</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts593</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pinho</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Pratas</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Mfcompress: a compression tool for fasta and multi-fasta data</article-title>
        <source>Bioinforma</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>1</issue>
        <fpage>117</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt594</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wood</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Salzberg</surname>
            <given-names>SL</given-names>
          </name>
        </person-group>
        <article-title>Kraken: ultrafast metagenomic sequence classification using exact alignments</article-title>
        <source>Genome Biol</source>
        <year>2014</year>
        <volume>15</volume>
        <issue>3</issue>
        <fpage>46</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2014-15-3-r46</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Langmead</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Salzberg</surname>
            <given-names>SL</given-names>
          </name>
        </person-group>
        <article-title>Fast gapped-read alignment with bowtie 2</article-title>
        <source>Nature methods</source>
        <year>2012</year>
        <volume>9</volume>
        <issue>4</issue>
        <fpage>357</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1923</pub-id>
        <?supplied-pmid 22388286?>
        <pub-id pub-id-type="pmid">22388286</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zerbino</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Birney</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Velvet: algorithms for de novo short read assembly using de bruijn graphs</article-title>
        <source>Genome Res</source>
        <year>2008</year>
        <volume>18</volume>
        <issue>5</issue>
        <fpage>821</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.074492.107</pub-id>
        <?supplied-pmid 18349386?>
        <pub-id pub-id-type="pmid">18349386</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Leung</surname>
            <given-names>HC</given-names>
          </name>
          <name>
            <surname>Yiu</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Chin</surname>
            <given-names>FY</given-names>
          </name>
        </person-group>
        <article-title>Idba-ud: a de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth</article-title>
        <source>Bioinforma</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>11</issue>
        <fpage>1420</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts174</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Gish</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Myers</surname>
            <given-names>EW</given-names>
          </name>
          <name>
            <surname>Lipman</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <article-title>Basic local alignment search tool</article-title>
        <source>J Mol Biol</source>
        <year>1990</year>
        <volume>215</volume>
        <issue>3</issue>
        <fpage>403</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1016/S0022-2836(05)80360-2</pub-id>
        <?supplied-pmid 2231712?>
        <pub-id pub-id-type="pmid">2231712</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huffman</surname>
            <given-names>DA</given-names>
          </name>
        </person-group>
        <article-title>A method for the construction of minimum redundancy codes</article-title>
        <source>Proceedings of the IRE</source>
        <year>1952</year>
        <volume>40</volume>
        <issue>9</issue>
        <fpage>1098</fpage>
        <lpage>101</lpage>
        <pub-id pub-id-type="doi">10.1109/JRPROC.1952.273898</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Golomb</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Run-length encodings</article-title>
        <source>Inf Theory IEEE Transac</source>
        <year>1966</year>
        <volume>12</volume>
        <issue>3</issue>
        <fpage>399</fpage>
        <pub-id pub-id-type="doi">10.1109/TIT.1966.1053907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Somasundaram</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Domnic</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Extended golomb code for integer representation</article-title>
        <source>Multimed IEEE Transac</source>
        <year>2007</year>
        <volume>9</volume>
        <issue>2</issue>
        <fpage>239</fpage>
        <lpage>46</lpage>
        <pub-id pub-id-type="doi">10.1109/TMM.2006.886260</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ochoa</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Asnani</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bharadia</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chowdhury</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Weissman</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yona</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Qualcomp: a new lossy compressor for quality scores based on rate distortion theory</article-title>
        <source>BMC Bioinforma</source>
        <year>2013</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>187</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-187</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <mixed-citation publication-type="other">Seward J. Bzip2 and Libbzip2. <ext-link ext-link-type="uri" xlink:href="http://www.bzip.org">http://www.bzip.org</ext-link>. Accessed Mar 2015.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sakib</surname>
            <given-names>MN</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>WJ</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>CT</given-names>
          </name>
        </person-group>
        <article-title>Improving transmission efficiency of large sequence alignment/map (sam) files</article-title>
        <source>PloS ONE</source>
        <year>2011</year>
        <volume>6</volume>
        <issue>12</issue>
        <fpage>28251</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0028251</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kozanitis</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Saunders</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kruglyak</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Bafna</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Varghese</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Compressing genomic sequence fragments using slimgene</article-title>
        <source>J Comput Biol</source>
        <year>2011</year>
        <volume>18</volume>
        <issue>3</issue>
        <fpage>401</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1089/cmb.2010.0253</pub-id>
        <?supplied-pmid 21385043?>
        <pub-id pub-id-type="pmid">21385043</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Richter</surname>
            <given-names>DC</given-names>
          </name>
          <name>
            <surname>Ott</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Auch</surname>
            <given-names>AF</given-names>
          </name>
          <name>
            <surname>Schmid</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Huson</surname>
            <given-names>DH</given-names>
          </name>
        </person-group>
        <article-title>Metasim: a sequencing simulator for genomics and metagenomics</article-title>
        <source>PloS ONE</source>
        <year>2008</year>
        <volume>3</volume>
        <issue>10</issue>
        <fpage>3373</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0003373</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <mixed-citation publication-type="other">Kim D, Song L, Breitwieser FP, Salzberg SL. Centrifuge: Rapid and Accurate Classification of Metagenomic Sequences. <ext-link ext-link-type="uri" xlink:href="http://www.ccb.jhu.edu/people/infphilo/data/Centrifuge-poster.pdf">http://www.ccb.jhu.edu/people/infphilo/data/Centrifuge-poster.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Leinonen</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sugawara</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Shumway</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>The sequence read archive</article-title>
        <source>Nucl Acids Res.</source>
        <year>2011</year>
        <volume>39</volume>
        <issue>suppl 1</issue>
        <fpage>D19</fpage>
        <lpage>D21</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkq1019</pub-id>
        <?supplied-pmid 21062823?>
        <pub-id pub-id-type="pmid">21062823</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Loh</surname>
            <given-names>PR</given-names>
          </name>
          <name>
            <surname>Baym</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Berger</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Compressive genomics</article-title>
        <source>Nature Biotechnol</source>
        <year>2012</year>
        <volume>30</volume>
        <issue>7</issue>
        <fpage>627</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.2241</pub-id>
        <pub-id pub-id-type="pmid">22781691</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>WT</given-names>
          </name>
          <name>
            <surname>Marsh</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Forney</surname>
            <given-names>LJ</given-names>
          </name>
        </person-group>
        <article-title>Characterization of microbial diversity by determining terminal restriction fragment length polymorphisms of genes encoding 16s rrna</article-title>
        <source>Appl Environmen Microbiol</source>
        <year>1997</year>
        <volume>63</volume>
        <issue>11</issue>
        <fpage>4516</fpage>
        <lpage>22</lpage>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <mixed-citation publication-type="other">Liu B, Gibbons T, Ghodsi M, Pop M. Metaphyler: Taxonomic profiling for metagenomic sequences. In: Bioinformatics and Biomedicine (BIBM), 2010 IEEE International Conference On. IEEE: 2010. p. 95–100. <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5706544">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5706544</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boisvert</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Raymond</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Godzaridis</surname>
            <given-names>É</given-names>
          </name>
          <name>
            <surname>Laviolette</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Corbeil</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Ray meta: scalable de novo metagenome assembly and profiling</article-title>
        <source>Genome Biol</source>
        <year>2012</year>
        <volume>13</volume>
        <issue>12</issue>
        <fpage>R122</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2012-13-12-r122</pub-id>
        <?supplied-pmid 23259615?>
        <pub-id pub-id-type="pmid">23259615</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lander</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Waterman</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>Genomic mapping by fingerprinting random clones: a mathematical analysis</article-title>
        <source>Genomics</source>
        <year>1988</year>
        <volume>2</volume>
        <issue>3</issue>
        <fpage>231</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1016/0888-7543(88)90007-9</pub-id>
        <?supplied-pmid 3294162?>
        <pub-id pub-id-type="pmid">3294162</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dohm</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Lottaz</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Borodina</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Himmelbauer</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Substantial biases in ultra-short read data sets from high-throughput dna sequencing</article-title>
        <source>Nucl Acids Res</source>
        <year>2008</year>
        <volume>36</volume>
        <issue>16</issue>
        <fpage>105</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkn425</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Handsaker</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wysoker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fennell</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ruan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Homer</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The sequence alignment/map format and samtools</article-title>
        <source>Bioinforma</source>
        <year>2009</year>
        <volume>25</volume>
        <issue>16</issue>
        <fpage>2078</fpage>
        <lpage>79</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37</label>
      <mixed-citation publication-type="other">Cover TM, Thomas JA. Elements of Information Theory: John Wiley &amp; Sons; 2012. https://books.google.com/books?hl=en\%26lr=\%26id=VWq5GG6ycxMC\%26oi=fnd%26pg=PT10\%26dq=cover+and+thomas+elements+of\%26ots=bX7kL1T5RT\%26sig=f4NgnjEBb5-4-JGAyUNPvmv-juw\%23v=onepage\%26q=cover\%20and\%20thomas\%20elements\%20of\%26f=false.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cormack</surname>
            <given-names>GV</given-names>
          </name>
          <name>
            <surname>Horspool</surname>
            <given-names>RN</given-names>
          </name>
        </person-group>
        <article-title>Algorithms for adaptive huffman codes</article-title>
        <source>Inf Process Lett</source>
        <year>1984</year>
        <volume>18</volume>
        <issue>3</issue>
        <fpage>159</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/0020-0190(84)90021-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39</label>
      <mixed-citation publication-type="other">Witten IH, Moffat A, Bell TC. Managing Gigabytes: Compressing and Indexing Documents and Images: Morgan Kaufmann; 1999. https://books.google.com/books?hl=en\%26lr=\%26id=2F74jyPl48EC\%26oi=fnd\%26pg=PR23\%26dq=managing+gigabytes+compressing+and\%26ots=5ReQGq6U7b%26sig=Kl_278eXxgig0ZDgQz_U_mZD7Mo\#v=onepage\%26q=managing\%20gigabytes\%20compressing\%20and\%26f=false.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kiely</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Selecting the golomb parameter in rice coding</article-title>
        <source>IPN progress report</source>
        <year>2004</year>
        <volume>42</volume>
        <fpage>159</fpage>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Elias</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Universal codeword sets and representations of the integers</article-title>
        <source>Inf Theory, IEEE Transac</source>
        <year>1975</year>
        <volume>21</volume>
        <issue>2</issue>
        <fpage>194</fpage>
        <lpage>203</lpage>
        <pub-id pub-id-type="doi">10.1109/TIT.1975.1055349</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>XL</given-names>
          </name>
          <name>
            <surname>Heo</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>El Hajj</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Hwu</surname>
            <given-names>WM</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Tiger: tiled iterative genome assembler</article-title>
        <source>BMC Bioinforma</source>
        <year>2012</year>
        <volume>13</volume>
        <issue>Suppl 19</issue>
        <fpage>18</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-13-S19-S18</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
