<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7703791</article-id>
    <article-id pub-id-type="pmid">31501851</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz704</article-id>
    <article-id pub-id-type="publisher-id">btz704</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Gene Expression</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Spectrum: fast density-aware spectral clustering for single and multi-omic data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-4453-9484</contrib-id>
        <name>
          <surname>John</surname>
          <given-names>Christopher R</given-names>
        </name>
        <xref ref-type="aff" rid="btz704-aff1">1</xref>
        <xref ref-type="corresp" rid="btz704-cor1"/>
        <!--<email>christopher.john@qmul.ac.uk</email>-->
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9632-2159</contrib-id>
        <name>
          <surname>Watson</surname>
          <given-names>David</given-names>
        </name>
        <xref ref-type="aff" rid="btz704-aff2">2</xref>
        <xref ref-type="aff" rid="btz704-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Barnes</surname>
          <given-names>Michael R</given-names>
        </name>
        <xref ref-type="aff" rid="btz704-aff1">1</xref>
        <xref ref-type="aff" rid="btz704-aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pitzalis</surname>
          <given-names>Costantino</given-names>
        </name>
        <xref ref-type="aff" rid="btz704-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lewis</surname>
          <given-names>Myles J</given-names>
        </name>
        <xref ref-type="aff" rid="btz704-aff1">1</xref>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Cowen</surname>
          <given-names>Lenore</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <aff id="btz704-aff1"><label>1</label><institution>Centre for Experimental Medicine and Rheumatology, William Harvey Research Institute, Bart’s and The London School of Medicine and Dentistry, Queen Mary University of London</institution>, London EC1M 6BQ, <country country="GB">UK</country></aff>
    <aff id="btz704-aff2"><label>2</label><institution>Oxford Internet Institute, University of Oxford</institution>, Oxford OX1 3JS, <country country="GB">UK</country></aff>
    <aff id="btz704-aff3"><label>3</label><institution>The Alan Turing Institute</institution>, London NW1 2DB, <country country="GB">UK</country></aff>
    <author-notes>
      <corresp id="btz704-cor1">To whom correspondence should be addressed. <email>christopher.john@qmul.ac.uk</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>15</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-09-10">
      <day>10</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>4</issue>
    <fpage>1159</fpage>
    <lpage>1166</lpage>
    <history>
      <date date-type="received">
        <day>08</day>
        <month>6</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>19</day>
        <month>8</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>06</day>
        <month>9</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz704.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Clustering patient omic data is integral to developing precision medicine because it allows the identification of disease subtypes. A current major challenge is the integration multi-omic data to identify a shared structure and reduce noise. Cluster analysis is also increasingly applied on single-omic data, for example, in single cell RNA-seq analysis for clustering the transcriptomes of individual cells. This technology has clinical implications. Our motivation was therefore to develop a flexible and effective spectral clustering tool for both single and multi-omic data.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present Spectrum, a new spectral clustering method for complex omic data. Spectrum uses a self-tuning density-aware kernel we developed that enhances the similarity between points that share common nearest neighbours. It uses a tensor product graph data integration and diffusion procedure to reduce noise and reveal underlying structures. Spectrum contains a new method for finding the optimal number of clusters (<italic>K</italic>) involving eigenvector distribution analysis. Spectrum can automatically find <italic>K</italic> for both Gaussian and non-Gaussian structures. We demonstrate across 21 real expression datasets that Spectrum gives improved runtimes and better clustering results relative to other methods.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Spectrum is available as an R software package from CRAN <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/Spectrum/index.html">https://cran.r-project.org/web/packages/Spectrum/index.html</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Precision medicine is the concept that patients may be stratified into different subtypes to personalize therapy. A growing number of studies stratify patients using their genome-wide expression data (e.g. mRNA, miRNA, protein, methylation), such as those by The Cancer Genome Atlas (TCGA) (<xref rid="btz704-B1" ref-type="bibr">Agrawal <italic>et al.</italic>, 2014</xref>; <xref rid="btz704-B2" ref-type="bibr">Akbani <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B6" ref-type="bibr">Ceccarelli <italic>et al.</italic>, 2016</xref>; <xref rid="btz704-B7" ref-type="bibr">Ciriello <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B10" ref-type="bibr">Fishbein <italic>et al.</italic>, 2017</xref>; <xref rid="btz704-B19" ref-type="bibr">Network, 2013</xref>, <xref rid="btz704-B20" ref-type="bibr">2014</xref>) and other consortia (<xref rid="btz704-B16" ref-type="bibr">Lefaudeux <italic>et al.</italic>, 2017</xref>). Clustering algorithms are used to find patient subtypes and may be run on data from single or multiple platforms. Single-omic cluster analysis is performed by algorithms such as: Monte Carlo consensus clustering (M3C) (<xref rid="btz704-B13" ref-type="bibr">John <italic>et al.</italic>, 2018</xref>), CLEST (<xref rid="btz704-B9" ref-type="bibr">Dudoit and Fridlyand, 2002</xref>), PINSPlus (<xref rid="btz704-B22" ref-type="bibr">Nguyen <italic>et al.</italic>, 2018</xref>) and similarity network fusion (SNF) (<xref rid="btz704-B29" ref-type="bibr">Wang <italic>et al.</italic>, 2014</xref>). However, clustering multi-omic data into an integrated solution is a major current challenge. State-of-the-art methods include: iClusterPlus (<xref rid="btz704-B27" ref-type="bibr">Shen <italic>et al.</italic>, 2009</xref>), SNF, CIMLR (<xref rid="btz704-B25" ref-type="bibr">Ramazzotti <italic>et al.</italic>, 2018</xref>) and PINSplus. The primary aims of multi-omic clustering are: (i) identifying a shared structure between platforms, and (ii) reducing noise from individual platforms. There is demand in this area for new, fast, effective methods and accessible software.</p>
    <p>Single-cell RNA-seq is a technique that can be used to detect specific cell types by clustering of individual cell transcriptomes (<xref rid="btz704-B14" ref-type="bibr">Kiselev <italic>et al.</italic>, 2017</xref>). Analysing transcriptomes of individual cells may further our understanding of biology and has clinical applications. Single-cell RNA-seq data pose unique issues for clustering, as there are often more points to cluster and the data are usually found in dense globular clusters. Tools applied in this domain include: single-cell consensus clustering (SC3) (<xref rid="btz704-B14" ref-type="bibr">Kiselev <italic>et al.</italic>, 2017</xref>), Seurat (<xref rid="btz704-B4" ref-type="bibr">Butler <italic>et al.</italic>, 2018</xref>), MUDAN and single-cell interpretation via multikernel learning (SIMLR) (<xref rid="btz704-B30" ref-type="bibr">Wang <italic>et al.</italic>, 2017</xref>). Maintaining fast runtimes is important given the high number of points. SIMLR uses a sophisticated procedure to learn the optimal similarity matrix. However, it is very time consuming and it is not clear if SIMLR provides clustering performance advantages relative to other methods.</p>
    <p>Spectral clustering refers to a class of algorithms that have become a hot topic in machine learning due to their ability to handle complex data (<xref rid="btz704-B21" ref-type="bibr">Ng <italic>et al.</italic>, 2002</xref>; <xref rid="btz704-B28" ref-type="bibr">Shu and Latecki, 2016</xref>; <xref rid="btz704-B32" ref-type="bibr">Xiang and Gong, 2008</xref>; <xref rid="btz704-B36" ref-type="bibr">Zelnik-Manor and Perona, 2005</xref>; <xref rid="btz704-B37" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>). They are characterized by clustering eigenvectors derived from a matrix representing the data’s graph (<xref rid="btz704-B21" ref-type="bibr">Ng <italic>et al.</italic>, 2002</xref>). Several of these methods are applied in genomic data analysis (<xref rid="btz704-B29" ref-type="bibr">Wang <italic>et al.</italic>, 2014</xref><xref rid="btz704-B30" ref-type="bibr">, 2017</xref>). However, there have been a range of other developments in spectral clustering that provide ample opportunities for method development and implementation. A density-aware kernel (<xref rid="btz704-B37" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>) enhances local connections in higher density regions of the graph, however, this kernel does not self-tune to the data. Another method uses tensor product graph (TPG) integration and diffusion to integrate data sources and reduce noise (<xref rid="btz704-B28" ref-type="bibr">Shu and Latecki, 2016</xref>). One method retrieves eigenvectors of the data’s graph selected according to their multimodality for Gaussian mixture modelling (GMM) with the Bayesian Information Criterion (BIC) to decide on the optimal K (<xref rid="btz704-B32" ref-type="bibr">Xiang and Gong, 2008</xref>). The fast approximate spectral clustering (FASP) method (<xref rid="btz704-B33" ref-type="bibr">Yan <italic>et al.</italic>, 2009</xref>) enables rapid clustering of thousands of points on a desktop computer. Our aim was to assemble and advance this work.</p>
    <p>Spectrum includes both methodological advancements and implements pre-existing techniques. Spectrum is distinct in a number of ways from previous spectral clustering-based tools (<xref rid="btz704-B29" ref-type="bibr">Wang <italic>et al.</italic>, 2014</xref><xref rid="btz704-B30" ref-type="bibr">, 2017</xref>). Our contributions include: (i) a new self-tuning kernel that adapts to local density in the graph; (ii) a TPG data integration and diffusion procedure to combine different data sources and reduce noise; (iii) implementation of the FASP method for massive datasets; (iv) a new technique based on eigenvector distributional analysis to estimate the optimal <italic>K</italic>. Spectrum is provided as an accessible R software package (<ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/Spectrum/index.html">https://cran.r-project.org/web/packages/Spectrum/index.html</ext-link>) and has a detailed vignette.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>It is first instructive to describe the Zelnik-Manor self-tuning kernel (<xref rid="btz704-B36" ref-type="bibr">Zelnik-Manor and Perona, 2005</xref>) and the Zhang density-aware kernel (<xref rid="btz704-B37" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>) in order to understand our proposed kernel. The kernel is used to calculate the similarity matrix in spectral clustering that represents the data’s graph. Making a good similarity matrix in this initial step is key to getting good clustering performance.</p>
    <sec>
      <title>2.1 Zelnik-Manor self-tuning kernel</title>
      <p>The Zelnik-Manor kernel was designed to adapt to different data’s scale and so not require time-consuming parameter tuning. Let <inline-formula id="IE1"><mml:math id="IM1"><mml:mi>E</mml:mi></mml:math></inline-formula> denote an expression matrix <inline-formula id="IE2"><mml:math id="IM2"><mml:mi>E</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, where <inline-formula id="IE3"><mml:math id="IM3"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of points and <inline-formula id="IE4"><mml:math id="IM4"><mml:mi>M</mml:mi></mml:math></inline-formula> is the number of features, let <inline-formula id="IE5"><mml:math id="IM5"><mml:mi>A</mml:mi></mml:math></inline-formula> denote its similarity matrix <inline-formula id="IE6"><mml:math id="IM6"><mml:mi>A</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. Given a set of <inline-formula id="IE7"><mml:math id="IM7"><mml:mi>N</mml:mi></mml:math></inline-formula> points, <inline-formula id="IE8"><mml:math id="IM8"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, the Zelnik-Manor kernel is defined as:
<disp-formula id="E1"><mml:math id="M1"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula>Where <inline-formula id="IE9"><mml:math id="IM9"><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes the Euclidean distance between points <inline-formula id="IE10"><mml:math id="IM10"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE11"><mml:math id="IM11"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula id="IE12"><mml:math id="IM12"><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a local scaling parameter and is calculated for every point <inline-formula id="IE13"><mml:math id="IM13"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. <inline-formula id="IE14"><mml:math id="IM14"><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> corresponds to <inline-formula id="IE15"><mml:math id="IM15"><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> where <inline-formula id="IE16"><mml:math id="IM16"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the <inline-formula id="IE17"><mml:math id="IM17"><mml:msup><mml:mrow><mml:mi>P</mml:mi><mml:mi mathvariant="normal">th</mml:mi></mml:mrow><mml:mrow/></mml:msup></mml:math></inline-formula> nearest neighbour of <inline-formula id="IE18"><mml:math id="IM18"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. <inline-formula id="IE19"><mml:math id="IM19"><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> controls how rapidly <inline-formula id="IE20"><mml:math id="IM20"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> falls off as <inline-formula id="IE21"><mml:math id="IM21"><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> increases. Selecting this parameter to equal one of the nearest-neighbour distances of <inline-formula id="IE22"><mml:math id="IM22"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> allows the kernel to automatically tune to data with different scales. <inline-formula id="IE23"><mml:math id="IM23"><mml:mi>P</mml:mi></mml:math></inline-formula> is a free parameter and does not typically require parameter tuning to perform well.</p>
    </sec>
    <sec>
      <title>2.2 Zhang density-aware kernel</title>
      <p><xref rid="btz704-B37" ref-type="bibr">Zhang <italic>et al.</italic> (2011)</xref> proposed a kernel that takes into account the common neighbours of points <inline-formula id="IE24"><mml:math id="IM24"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE25"><mml:math id="IM25"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> when calculating <inline-formula id="IE26"><mml:math id="IM26"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The kernel increases <inline-formula id="IE27"><mml:math id="IM27"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> when <inline-formula id="IE28"><mml:math id="IM28"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE29"><mml:math id="IM29"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> share more neighbours, and therefore adapts to the data’s local density. Taking into account local density in this manner improves clustering performance by amplifying intra-cluster similarity (<xref rid="btz704-B37" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>).
<disp-formula id="E2"><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="normal">CNN</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula>Where <inline-formula id="IE30"><mml:math id="IM30"><mml:mi mathvariant="normal">CNN</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> is the number of points in the join region of the <inline-formula id="IE31"><mml:math id="IM31"><mml:mo>ε</mml:mo></mml:math></inline-formula>-neighbourhoods around points <inline-formula id="IE32"><mml:math id="IM32"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE33"><mml:math id="IM33"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where the <inline-formula id="IE34"><mml:math id="IM34"><mml:mo>ε</mml:mo></mml:math></inline-formula>-neighbourhood of a point represents the sphere around that point with radius <inline-formula id="IE35"><mml:math id="IM35"><mml:mo>ε</mml:mo></mml:math></inline-formula>. <inline-formula id="IE36"><mml:math id="IM36"><mml:mo>σ</mml:mo></mml:math></inline-formula> denotes a global scaling parameter.</p>
      <p>In the Zhang kernel, both <inline-formula id="IE37"><mml:math id="IM37"><mml:mo>ε</mml:mo></mml:math></inline-formula> and <inline-formula id="IE38"><mml:math id="IM38"><mml:mo>σ</mml:mo></mml:math></inline-formula> must be tuned for each new dataset, unlike the Zelnik-Manor kernel that takes advantage of the nearest-neighbour distances to select <inline-formula id="IE39"><mml:math id="IM39"><mml:mo>σ</mml:mo></mml:math></inline-formula> quickly and gives good results. Parameter tuning for the Zhang kernel is slow and it is hard to define a good objective function. We propose a new kernel that adapts to local density in a similar way, but does not require parameter tuning for every new dataset. It does this by comparing the common nearest neighbours of points <inline-formula id="IE40"><mml:math id="IM40"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE41"><mml:math id="IM41"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p>
    </sec>
    <sec>
      <title>2.3 Adaptive density-aware kernel</title>
      <p>We propose the following kernel:
<disp-formula id="E3"><label>(1)</label><mml:math id="M3"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="normal">CNN</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula>Where <inline-formula id="IE42"><mml:math id="IM42"><mml:mi mathvariant="normal">CNN</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> denotes the number of points in the intersection between the two sets of nearest neighbours of points <inline-formula id="IE43"><mml:math id="IM43"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE44"><mml:math id="IM44"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. <inline-formula id="IE45"><mml:math id="IM45"><mml:mi>S</mml:mi></mml:math></inline-formula> is the free parameter that defines the number of nearest neighbours to include in each set. Because <inline-formula id="IE46"><mml:math id="IM46"><mml:mi>S</mml:mi></mml:math></inline-formula> is not a distance value like <inline-formula id="IE47"><mml:math id="IM47"><mml:mo>ε</mml:mo></mml:math></inline-formula> in the Zhang kernel it will automatically adapt to data with different scales.</p>
      <p>Our kernel incorporates the advantages from both of the above kernels, whilst not requiring tuning to obtain good clustering performance. In this study, the kernel parameters were set to <inline-formula id="IE48"><mml:math id="IM48"><mml:mi>P</mml:mi></mml:math></inline-formula>=3 and <inline-formula id="IE49"><mml:math id="IM49"><mml:mi>S</mml:mi></mml:math></inline-formula>=7. These are free parameters, so there are not definitive values. Higher values will prefer global structures, while lower values local structures. However, these parameter settings were used for all experiments in this manuscript, including those on simulated data and are later shown to generalize well.</p>
      <p>The first step of the Spectrum algorithm is to calculate the similarity matrix or matrices using the adaptive density-aware kernel. Note, this kernel is for continuous (non-binary) data. Additionally, if Spectrum is applied to multi-view data, the points must be matching between different views. If we are dealing with multiple datasets, then we have a set of <inline-formula id="IE50"><mml:math id="IM50"><mml:mi>T</mml:mi></mml:math></inline-formula> matrices <inline-formula id="IE51"><mml:math id="IM51"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula id="IE52"><mml:math id="IM52"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula id="IE53"><mml:math id="IM53"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the number of features per sample from the <inline-formula id="IE54"><mml:math id="IM54"><mml:msup><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">th</mml:mi></mml:mrow><mml:mrow/></mml:msup></mml:math></inline-formula> data type and <inline-formula id="IE55"><mml:math id="IM55"><mml:mi>N</mml:mi></mml:math></inline-formula> the number of points. Using <xref ref-type="disp-formula" rid="E3">Equation (1)</xref>, in the case of multiple input datasets, this yields a new set of <inline-formula id="IE56"><mml:math id="IM56"><mml:mi>T</mml:mi></mml:math></inline-formula> similarity matrices, <inline-formula id="IE57"><mml:math id="IM57"><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, while if we have just one platform (<inline-formula id="IE58"><mml:math id="IM58"><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>) we have a single similarity matrix <inline-formula id="IE59"><mml:math id="IM59"><mml:mi>A</mml:mi></mml:math></inline-formula>.</p>
      <p><bold>Combining multi-view data and</bold> <bold>TPG</bold> <bold>diffusion.</bold> For combining the similarity matrices (graphs) in the set <inline-formula id="IE60"><mml:math id="IM60"><mml:mi>Y</mml:mi></mml:math></inline-formula>, Spectrum uses a recent technique from the machine learning literature (<xref rid="btz704-B28" ref-type="bibr">Shu and Latecki, 2016</xref>) that involves calculating a cross view TPG from each pair of individual graphs. Cross-view TPGs capture higher order information of the data. The cross-view TPGs are integrated using linear combinations to form a single graph. Graph diffusion is then performed to reveal the underlying data structure. Shu <italic>et al.</italic> give a computationally efficient algorithm for this. The operation is mathematically analogous to the TPG approach but can be calculated using a non TPG which makes it much faster. Spectrum uses a minor modification of this method for a single data type. Note, the linear combination is weighted equally and assumes each view contributes towards a common structure, so very noisy data or data representing a very different structure should be excluded beforehand. The steps taken are as follows:
<list list-type="order"><list-item><p>Combine similarity matrices from the set <inline-formula id="IE61"><mml:math id="IM61"><mml:mi>Y</mml:mi></mml:math></inline-formula>. If we are dealing with a single similarity matrix, <inline-formula id="IE62"><mml:math id="IM62"><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>, then this step is skipped, but steps 2-5 are the same:
<disp-formula id="E4"><label>(2)</label><mml:math id="M4"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>Sparsify <inline-formula id="IE63"><mml:math id="IM63"><mml:mi>A</mml:mi></mml:math></inline-formula> by keeping only the <inline-formula id="IE64"><mml:math id="IM64"><mml:msup><mml:mrow><mml:mi>Z</mml:mi><mml:mi mathvariant="normal">th</mml:mi></mml:mrow><mml:mrow/></mml:msup></mml:math></inline-formula> nearest neighbours of each sample <inline-formula id="IE65"><mml:math id="IM65"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and setting the rest to 0. This makes a <italic>k</italic>-nearest-neighbour (<italic>k</italic>NN) graph. Let <inline-formula id="IE66"><mml:math id="IM66"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> be the set of <inline-formula id="IE67"><mml:math id="IM67"><mml:mi>Z</mml:mi></mml:math></inline-formula> nearest neighbours for <inline-formula id="IE68"><mml:math id="IM68"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, then:
<disp-formula id="E5"><label>(3)</label><mml:math id="M5"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mfenced open="{" close="" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mi mathvariant="normal">j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi mathvariant="normal">otherwise</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula></p></list-item><list-item><p>Row normalise <inline-formula id="IE69"><mml:math id="IM69"><mml:mi>A</mml:mi></mml:math></inline-formula>, so that each row sums to 1:
<disp-formula id="E6"><label>(4)</label><mml:math id="M6"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>Perform graph diffusion iterations. Let <inline-formula id="IE70"><mml:math id="IM70"><mml:msup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>A</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE71"><mml:math id="IM71"><mml:mi>I</mml:mi></mml:math></inline-formula> be the identity matrix for<inline-formula id="IE72"><mml:math id="IM72"><mml:mi mathvariant="normal"> </mml:mi><mml:mi>A</mml:mi></mml:math></inline-formula>. Then for the <inline-formula id="IE73"><mml:math id="IM73"><mml:msup><mml:mrow><mml:mi>t</mml:mi><mml:mi mathvariant="normal">th</mml:mi></mml:mrow><mml:mrow/></mml:msup></mml:math></inline-formula> iteration from <inline-formula id="IE74"><mml:math id="IM74"><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">iters</mml:mi></mml:math></inline-formula>:
<disp-formula id="E7"><label>(5)</label><mml:math id="M7"><mml:msup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>I</mml:mi></mml:math></disp-formula></p></list-item><list-item><p>We then take the final similarity matrix as <inline-formula id="IE75"><mml:math id="IM75"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. This ends the procedure. <inline-formula id="IE76"><mml:math id="IM76"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> can now be used as the matrix for the rest of spectral clustering described in subsequent steps.</p></list-item></list></p>
      <p>The parameters <inline-formula id="IE77"><mml:math id="IM77"><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> and <inline-formula id="IE78"><mml:math id="IM78"><mml:mi mathvariant="normal">iters</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math></inline-formula> are set in alignment with previous work that demonstrated their effective performance (<xref rid="btz704-B28" ref-type="bibr">Shu and Latecki, 2016</xref>). Shu <italic>et al.</italic> demonstrated that their algorithm is not very sensitive to these parameters.</p>
      <p><bold>Spectral clustering of similarity matrix.</bold> Starting with <inline-formula id="IE79"><mml:math id="IM79"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, Spectrum uses the Ng spectral clustering method (<xref rid="btz704-B21" ref-type="bibr">Ng <italic>et al.</italic>, 2002</xref>), but with the eigengap heuristic to estimate the number of clusters and GMM to cluster the final eigenvector matrix. More specifically:
<list list-type="order"><list-item><p>Using <inline-formula id="IE80"><mml:math id="IM80"><mml:mi>D</mml:mi></mml:math></inline-formula>, the diagonal matrix whose <inline-formula id="IE81"><mml:math id="IM81"><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> element is the sum of <inline-formula id="IE82"><mml:math id="IM82"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>’s <inline-formula id="IE83"><mml:math id="IM83"><mml:msup><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">th</mml:mi></mml:mrow><mml:mrow/></mml:msup></mml:math></inline-formula> row, construct the normalized graph Laplacian <inline-formula id="IE84"><mml:math id="IM84"><mml:mi>L</mml:mi></mml:math></inline-formula>:
<disp-formula id="E8"><label>(6)</label><mml:math id="M8"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></disp-formula></p></list-item><list-item><p>Perform the eigendecomposition of <inline-formula id="IE85"><mml:math id="IM85"><mml:mi>L</mml:mi></mml:math></inline-formula> and thus extract its eigenvectors <inline-formula id="IE86"><mml:math id="IM86"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>…</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and eigenvalues <inline-formula id="IE87"><mml:math id="IM87"><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>.</p></list-item><list-item><p>Evaluate the eigengap for eigenvalues, starting with the second eigenvalue, <inline-formula id="IE88"><mml:math id="IM88"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula>, and choose the optimal k, denoted by <inline-formula id="IE89"><mml:math id="IM89"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, for which the eigengap is maximised:
<disp-formula id="E9"><label>(7)</label><mml:math id="M9"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">argmax</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mo>λ</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>Get the <inline-formula id="IE90"><mml:math id="IM90"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>…</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula id="IE91"><mml:math id="IM91"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> largest eigenvectors of <inline-formula id="IE92"><mml:math id="IM92"><mml:mi>L</mml:mi></mml:math></inline-formula>, then form the matrix, <inline-formula id="IE93"><mml:math id="IM93"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>…</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math></inline-formula> by stacking the eigenvectors in columns.</p></list-item><list-item><p>Form the matrix <inline-formula id="IE94"><mml:math id="IM94"><mml:mi>Y</mml:mi></mml:math></inline-formula> from <inline-formula id="IE95"><mml:math id="IM95"><mml:mi>X</mml:mi></mml:math></inline-formula> by renormalizing each of <inline-formula id="IE96"><mml:math id="IM96"><mml:mi>X</mml:mi></mml:math></inline-formula>’s rows to have unit length:
<disp-formula id="E10"><label>(8)</label><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula></p></list-item><list-item><p>Now each row of <inline-formula id="IE97"><mml:math id="IM97"><mml:mi>Y</mml:mi></mml:math></inline-formula> is treated as a sample, <inline-formula id="IE98"><mml:math id="IM98"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, then all points are clustered into <inline-formula id="IE99"><mml:math id="IM99"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> clusters using GMM. Spectrum uses the implementation of GMM from the ClusterR CRAN package.</p></list-item></list></p>
      <p><bold>A flexible heuristic for finding <italic>K</italic> when spectral clustering.</bold> A natural way to solve the problem of estimating <italic>K</italic> when spectral clustering is analysis of the eigendecomposition of the graph Laplacian. The classical eigengap method is effective for Gaussian clusters, however, its rule must be modified to detect non-Gaussian structures, thus limiting its applicability (see Section 3). We describe a new heuristic for finding <italic>K</italic> that can be used for Gaussian or non-Gaussian structures and as a complementary method to analyse genome-wide expression datasets. The method examines the multimodality of the eigenvectors of the graph Laplacian and looks for a point beyond which there is no more substantial decrease in multimodality.</p>
      <p>Intuitively, the degree of multimodality defines how informative a given eigenvector is, and when we pass the optimal <italic>K</italic> moving along the sorted eigenvectors, <inline-formula id="IE100"><mml:math id="IM100"><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>…</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, we expect a large drop in useful information. Multimodality is quantified using the well-known dip test statistic (<xref rid="btz704-B11" ref-type="bibr">Hartigan and Hartigan, 1985</xref>). The method can work better (see Section 3) if the nearest-neighbour parameter of the kernel is tuned from <inline-formula id="IE101"><mml:math id="IM101"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>10</mml:mn></mml:math></inline-formula>. This is done by selecting the kernel that gives the maximum multimodality gap. Analysing the multimodality drop was inspired by the Xiang and Gong study (<xref rid="btz704-B32" ref-type="bibr">Xiang and Gong, 2008</xref>), in which the authors select the most informative eigenvectors using an expectation maximization (EM) technique, then use GMM and the BIC to choose <italic>K</italic>. An issue with this EM method is the instability of the results due to the random initialization of the algorithm and its local search. We now detail an alternative procedure for finding <italic>K</italic> and tuning the kernel based on decreases in eigenvector multimodality.</p>
      <p>Let the set of dip test statistics be <inline-formula id="IE102"><mml:math id="IM102"><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, calculated from the eigenvectors, <inline-formula id="IE103"><mml:math id="IM103"><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>…</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>. Note that larger values of <inline-formula id="IE104"><mml:math id="IM104"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> correspond to greater eigenvector multimodality. To calculate the multimodality difference between consecutive values, we use <inline-formula id="IE105"><mml:math id="IM105"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. Since we require two values to get <inline-formula id="IE106"><mml:math id="IM106"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the calculation must begin at <inline-formula id="IE107"><mml:math id="IM107"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula>, which corresponds to the first pair of eigenvectors. Let the set of <inline-formula id="IE108"><mml:math id="IM108"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> values calculated from <inline-formula id="IE109"><mml:math id="IM109"><mml:mi>Z</mml:mi></mml:math></inline-formula> be <inline-formula id="IE110"><mml:math id="IM110"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">maxK</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></inline-formula> where <inline-formula id="IE111"><mml:math id="IM111"><mml:mi mathvariant="italic">maxK</mml:mi></mml:math></inline-formula> is the maximum value of <inline-formula id="IE112"><mml:math id="IM112"><mml:mi>K</mml:mi></mml:math></inline-formula> to be considered, the steps for this are as follows:
<list list-type="order"><list-item><p>Find the optimal kernel, <inline-formula id="IE113"><mml:math id="IM113"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. Each kernel is calculated using <xref ref-type="disp-formula" rid="E3">Equation (1)</xref> and the nearest-neighbour parameter <inline-formula id="IE114"><mml:math id="IM114"><mml:mi>P</mml:mi></mml:math></inline-formula> is tuned via a search from <inline-formula id="IE115"><mml:math id="IM115"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>10</mml:mn></mml:math></inline-formula>. To do this, calculate the <inline-formula id="IE116"><mml:math id="IM116"><mml:msup><mml:mrow><mml:mi>P</mml:mi><mml:mi mathvariant="normal">th</mml:mi></mml:mrow><mml:mrow/></mml:msup></mml:math></inline-formula> graph Laplacian [<xref ref-type="disp-formula" rid="E8">Equation (6)</xref>] from the <inline-formula id="IE117"><mml:math id="IM117"><mml:msup><mml:mrow><mml:mi>P</mml:mi><mml:mi mathvariant="normal">th</mml:mi></mml:mrow><mml:mrow/></mml:msup></mml:math></inline-formula> kernel. Obtain the eigenvectors of these, <inline-formula id="IE118"><mml:math id="IM118"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Calculate <inline-formula id="IE119"><mml:math id="IM119"><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> from these eigenvectors, then <inline-formula id="IE120"><mml:math id="IM120"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Get <inline-formula id="IE121"><mml:math id="IM121"><mml:mi mathvariant="normal">min</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> for each <inline-formula id="IE122"><mml:math id="IM122"><mml:mi>P</mml:mi></mml:math></inline-formula>, yielding a set <inline-formula id="IE123"><mml:math id="IM123"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>…</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>. <inline-formula id="IE124"><mml:math id="IM124"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the kernel that corresponds to <inline-formula id="IE125"><mml:math id="IM125"><mml:mi mathvariant="normal">min</mml:mi><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p></list-item><list-item><p>Get the <italic>k</italic>NN graph of <inline-formula id="IE126"><mml:math id="IM126"><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, row normalize, then perform diffusion iterations [<xref ref-type="disp-formula" rid="E5">Equations(3)–(5)</xref>]. Optional.</p></list-item><list-item><p>Calculate the graph Laplacian, <inline-formula id="IE127"><mml:math id="IM127"><mml:mi>L</mml:mi></mml:math></inline-formula> [<xref ref-type="disp-formula" rid="E8">Equation (6)</xref>].</p></list-item><list-item><p>Perform eigendecomposition of <inline-formula id="IE128"><mml:math id="IM128"><mml:mi>L</mml:mi></mml:math></inline-formula> yielding the eigenvectors, <inline-formula id="IE129"><mml:math id="IM129"><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>…</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p></list-item><list-item><p>Calculate the dip test statistics <inline-formula id="IE130"><mml:math id="IM130"><mml:mi>Z</mml:mi></mml:math></inline-formula> for the eigenvectors in <inline-formula id="IE131"><mml:math id="IM131"><mml:mi>V</mml:mi></mml:math></inline-formula>, then calculate the differences of these, <inline-formula id="IE132"><mml:math id="IM132"><mml:mi>D</mml:mi></mml:math></inline-formula>.</p></list-item><list-item><p>Pass <inline-formula id="IE133"><mml:math id="IM133"><mml:mi>D</mml:mi></mml:math></inline-formula> into the algorithm described below for finding the last substantial drop in multimodality. Let <inline-formula id="IE134"><mml:math id="IM134"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> be the optimal <italic>K</italic> found by this method.</p></list-item><list-item><p>Continue with steps 4–6 corresponding to the Ng spectral clustering method, with GMM to cluster the final eigenvector matrix, with <italic>K</italic> set to <inline-formula id="IE135"><mml:math id="IM135"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>.</p></list-item></list></p>
      <p>One could select <italic>K</italic> using the maximum multimodality gap. However, we found that this simpler method is susceptible to local minima (see Section 3). This naturally led to making an algorithm to find the last substantial drop. For finding <inline-formula id="IE136"><mml:math id="IM136"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> from set <inline-formula id="IE137"><mml:math id="IM137"><mml:mi>Z</mml:mi></mml:math></inline-formula>, we now describe this straightforward algorithm that reads along the elements of <inline-formula id="IE138"><mml:math id="IM138"><mml:mi>Z</mml:mi></mml:math></inline-formula>, to find a point where there is no more substantial decrease in multimodality.</p>
      <p><bold>Finding last substantial multimodality gap.</bold> This algorithm will search <inline-formula id="IE139"><mml:math id="IM139"><mml:mi>D</mml:mi></mml:math></inline-formula>, storing in memory the biggest difference in multimodality. Let that be <inline-formula id="IE140"><mml:math id="IM140"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. A more negative <inline-formula id="IE141"><mml:math id="IM141"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> corresponds a bigger drop in the elements of <inline-formula id="IE142"><mml:math id="IM142"><mml:mi>Z</mml:mi></mml:math></inline-formula>. The method then examines if there are any more points ahead of this drop (up until <inline-formula id="IE143"><mml:math id="IM143"><mml:msub><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> points) that are <inline-formula id="IE144"><mml:math id="IM144"><mml:mo>≤</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula>, where <inline-formula id="IE145"><mml:math id="IM145"><mml:mi>f</mml:mi></mml:math></inline-formula> is the minimum magnitude that the drop must be to replace <inline-formula id="IE146"><mml:math id="IM146"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. If a new <inline-formula id="IE147"><mml:math id="IM147"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is found, this new difference is stored in memory. This process continues until no more substantial drops are found with the threshold <inline-formula id="IE148"><mml:math id="IM148"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to stop the search. More specifically:
<list list-type="order"><list-item><p>Skip the first element of <inline-formula id="IE149"><mml:math id="IM149"><mml:mi>D</mml:mi></mml:math></inline-formula>, <inline-formula id="IE150"><mml:math id="IM150"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, as this corresponds to the drop from the first to second eigenvector, which is non-informative. Store in memory <inline-formula id="IE151"><mml:math id="IM151"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, the greatest drop by default. Call this <inline-formula id="IE152"><mml:math id="IM152"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Initialise a counter <inline-formula id="IE153"><mml:math id="IM153"><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> for keeping count of how many indices ahead we are of the stored <inline-formula id="IE154"><mml:math id="IM154"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p></list-item><list-item><p>Iterate from <inline-formula id="IE155"><mml:math id="IM155"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">maxK</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and with each iteration check if <inline-formula id="IE156"><mml:math id="IM156"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. If so, let <inline-formula id="IE157"><mml:math id="IM157"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> be the new <inline-formula id="IE158"><mml:math id="IM158"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, otherwise continue. If <inline-formula id="IE159"><mml:math id="IM159"><mml:mi>c</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, break the loop and accept the current stored <inline-formula id="IE160"><mml:math id="IM160"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> as the solution.</p></list-item><list-item><p>The optimal number of classes is <inline-formula id="IE161"><mml:math id="IM161"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>, where <inline-formula id="IE162"><mml:math id="IM162"><mml:mi>i</mml:mi></mml:math></inline-formula> is the index of <inline-formula id="IE163"><mml:math id="IM163"><mml:mi>D</mml:mi></mml:math></inline-formula> corresponding to the <inline-formula id="IE164"><mml:math id="IM164"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> taken as <inline-formula id="IE165"><mml:math id="IM165"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in step 2.</p></list-item></list></p>
      <p>The parameters used in this study for the multimodality drop procedure were <inline-formula id="IE166"><mml:math id="IM166"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:math></inline-formula> and <inline-formula id="IE167"><mml:math id="IM167"><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula>, values we empirically selected based on our experience.</p>
    </sec>
    <sec>
      <title>2.4 Generating simulated datasets for analysis</title>
      <p>Gaussian cluster simulations were all performed using the CRAN clusterlab package (<xref rid="btz704-B13" ref-type="bibr">John <italic>et al.</italic>, 2018</xref>), following the standard operating procedure. In the case of non-Gaussian structures, found throughout the Supplementary Figures, either the CRAN mlbench or clusterSim packages were used to simulate the data, using the default settings.</p>
    </sec>
    <sec>
      <title>2.5 Downloading and processing of real data for analysis</title>
      <p><bold>TCGA datasets.</bold> The seven multi-omic TCGA datasets (<xref rid="btz704-B1" ref-type="bibr">Agrawal <italic>et al.</italic>, 2014</xref>; <xref rid="btz704-B2" ref-type="bibr">Akbani <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B6" ref-type="bibr">Ceccarelli <italic>et al.</italic>, 2016</xref>; <xref rid="btz704-B7" ref-type="bibr">Ciriello <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B10" ref-type="bibr">Fishbein <italic>et al.</italic>, 2017</xref>; <xref rid="btz704-B19" ref-type="bibr">Network, 2013</xref><xref rid="btz704-B20" ref-type="bibr">, 2014</xref>) were downloaded from the Broad Institute (<ext-link ext-link-type="uri" xlink:href="http://gdac.broadinstitute.org/">http://gdac.broadinstitute.org/</ext-link>). Pre-normalized data were used for each platform (mRNA, miRNA and protein) and was log<sub>2</sub> transformed to reduce the influence of extreme values. For every dataset each one was filtered in the same manner, using the coefficient of variation to select the top 50% most variable features. Code for data pre-processing is found in the following GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/crj32/spectrum_manuscript">https://github.com/crj32/spectrum_manuscript</ext-link>). The processed multi-omic data are in the Synapse repository syn18911550. RNA-seq datasets were taken from the same studies as the multi-omic data and filtering of features was done in the same manner. However, more patients were included in the RNA-seq analyses because we did not have to unify the patients between platforms. The RNA-seq data is included in the Synapse repository syn18911550. Code for performing log-rank tests in also in the GitHub as well as commands for running methods.</p>
      <p><bold>Single-cell RNA-seq datasets.</bold> The seven single-cell RNA-seq datasets (<xref rid="btz704-B3" ref-type="bibr">Baron <italic>et al.</italic>, 2016</xref>; <xref rid="btz704-B5" ref-type="bibr">Camp <italic>et al.</italic>, 2017</xref>; <xref rid="btz704-B8" ref-type="bibr">Darmanis <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B17" ref-type="bibr">Li <italic>et al.</italic>, 2017</xref>; <xref rid="btz704-B18" ref-type="bibr">Muraro <italic>et al.</italic>, 2016</xref>; <xref rid="btz704-B23" ref-type="bibr">Patel <italic>et al.</italic>, 2014</xref>; <xref rid="btz704-B24" ref-type="bibr">Pollen <italic>et al.</italic>, 2014</xref>) were obtained from the Hemberg lab website (<ext-link ext-link-type="uri" xlink:href="https://hemberg-lab.github.io/scRNA.seq.datasets/">https://hemberg-lab.github.io/scRNA.seq.datasets/</ext-link>). For each dataset, we used log<sub>2</sub> normalized counts and selected the top 100 most variable genes for analysis. Code for data pre-processing is found in the manuscript’s GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/crj32/spectrum_manuscript">https://github.com/crj32/spectrum_manuscript</ext-link>). Additionally, we include the single cell RNA-seq data in the Synapse repository syn18911550. Code for calculating normalized mutual information (NMI) is in the GitHub as are commands for running methods.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Spectrum provides fast effective clustering of single and multi-omic data</title>
      <p>First, we tested Spectrum’s ability to identify the ground truth <italic>K</italic> on individual simulated Gaussian datasets (<xref ref-type="fig" rid="btz704-F1">Fig. 1a</xref> and b and <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1</xref>). In each case, Spectrum correctly identified the optimal <italic>K</italic>. The method can also detect more complex non-Gaussian structures (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S2</xref>). To demonstrate the performance of Spectrum on real data from a single platform, we ran the algorithm on seven TCGA RNA-seq datasets (<xref rid="btz704-B1" ref-type="bibr">Agrawal <italic>et al.</italic>, 2014</xref>; <xref rid="btz704-B2" ref-type="bibr">Akbani <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B6" ref-type="bibr">Ceccarelli <italic>et al.</italic>, 2016</xref>; <xref rid="btz704-B7" ref-type="bibr">Ciriello <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B10" ref-type="bibr">Fishbein <italic>et al.</italic>, 2017</xref>; <xref rid="btz704-B19" ref-type="bibr">Network, 2013</xref><xref rid="btz704-B20" ref-type="bibr">, 2014</xref>). We used log-rank tests to evaluate the significance of survival time differences between identified clusters. Comparison of Spectrum <italic>P</italic> values with those from CLEST, M3C, PINSplus, and SNF found that Spectrum performed better overall in finding clusters significantly related to patient survival (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>). For comparing different methods, we took both a rank and <italic>P</italic>-value-based approach to assess performance, individual <italic>P</italic> values and rankings for each method on each RNA-seq dataset are included in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>. The brain cancer RNA-seq dataset (<xref rid="btz704-B6" ref-type="bibr">Ceccarelli <italic>et al.</italic>, 2016</xref>) was used as an example to display the Spectrum single-omic clustering results using a <italic>t</italic>-distributed stochastic neighbour embedding (t-SNE) plot and the related survival curve was also shown (<xref ref-type="fig" rid="btz704-F2">Fig. 2a and b</xref>). The clusters in the brain cancer dataset found with Spectrum were compared with those from SNF on t-SNE plots (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S3a</xref> and b). As well as obtaining a lower <italic>P</italic>-value, Spectrum yielded more compact clusters than SNF (measured by silhouette width). To give an initial indication of the relative computational resources required for a single platform analysis, algorithm runtime was investigated on a kidney cancer RNA-seq dataset (<xref rid="btz704-B19" ref-type="bibr">Network, 2013</xref>) with 240 points and 5000 features. This analysis was performed on a single core of an Intel Core i7-6560U CPU @ 2.20 GHz laptop computer with 16 GB of DDR3 RAM. Spectrum was the fastest method (1.13 s), closely followed by SNF (2.67 s). PINSplus was still fast (8.53 s), while M3C (123.91 s) and CLEST (283.34 s) were both slower.
</p>
      <fig id="btz704-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Spectrum clusters five simulated Gaussian clusters and finds the correct <italic>K</italic>. (<bold>a</bold>) PCA showing the five simulated Gaussian clusters. (<bold>b</bold>) The eigenvalues of the eigenvectors from the data’s graph Laplacian, the greatest eigengap is between the fifth and sixth eigenvectors, therefore correctly indicating <italic>K </italic>= 5</p>
        </caption>
        <graphic xlink:href="btz704f1"/>
      </fig>
      <fig id="btz704-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Spectrum clusters RNA-seq data to find cancer subtypes with different survival times. (<bold>a</bold>) t-SNE plot illustrating the four clusters Spectrum identified in a brain cancer RNA-seq dataset (<xref rid="btz704-B6" ref-type="bibr">Ceccarelli <italic>et al.</italic>, 2016</xref>). (<bold>b</bold>) Survival curve analysis results using the discovered clusters showing a <italic>P</italic>-value from a Cox proportional hazards regression model using a log-rank test to test the significance of the survival time differences between clusters</p>
        </caption>
        <graphic xlink:href="btz704f2"/>
      </fig>
      <p>To test the behaviour of Spectrum’s TPG integration method, we conducted a multi-omic data simulation where three Gaussian clusters were generated for each view, and each view had 300 points with 500 features with random noise added (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S4a</xref>). Individual platform clustering using Spectrum did not detect the optimal <italic>K</italic> (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S4b</xref> and c). However, using the TPG integration and diffusion method, Spectrum identified the optimal <italic>K</italic> for the combined dataset (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S4d</xref>). As expected, SNF also identified the optimal <italic>K</italic> on this simple test dataset (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S5</xref>). We proceeded to test Spectrum’s ability to detect clusters with significant differences in survival time on seven multi-omic TCGA datasets relative to other methods (<xref rid="btz704-T1" ref-type="table">Table 1</xref>). The analysis included mRNA, miRNA and protein data. Similar to our observations on a single platform, Spectrum performed very well, particularly on the larger datasets with greater potential for clinical significance, namely, the breast (<italic>P</italic> = 1.47E-07) and brain cancer (<italic>P</italic> = 3.76E-16) datasets.
</p>
      <table-wrap id="btz704-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Spectrum multi-omic clustering performance relative to other algorithms</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="(" span="1"/>
            <col valign="top" align="char" char="(" span="1"/>
            <col valign="top" align="char" char="(" span="1"/>
            <col valign="top" align="char" char="(" span="1"/>
            <col valign="top" align="char" char="(" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th align="left" rowspan="1" colspan="1">
                <italic>N</italic>
              </th>
              <th align="left" rowspan="1" colspan="1">Spectrum</th>
              <th align="left" rowspan="1" colspan="1">PINSplus</th>
              <th align="left" rowspan="1" colspan="1">iClusterPlus</th>
              <th align="left" rowspan="1" colspan="1">SNF</th>
              <th align="left" rowspan="1" colspan="1">CIMLR</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Bladder</td>
              <td rowspan="1" colspan="1">338</td>
              <td rowspan="1" colspan="1">0.0042 (3)</td>
              <td rowspan="1" colspan="1">0.31 (5)</td>
              <td rowspan="1" colspan="1">0.0022 (2)</td>
              <td rowspan="1" colspan="1">0.00022 (1)</td>
              <td rowspan="1" colspan="1">0.0047 (4)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Brain</td>
              <td rowspan="1" colspan="1">425</td>
              <td rowspan="1" colspan="1">3.76E-16 (1)</td>
              <td rowspan="1" colspan="1">0.0053 (4)</td>
              <td rowspan="1" colspan="1">1.72E-07 (3)</td>
              <td rowspan="1" colspan="1">4.17E-11 (2)</td>
              <td rowspan="1" colspan="1">0.013 (5)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Breast</td>
              <td rowspan="1" colspan="1">634</td>
              <td rowspan="1" colspan="1">1.47E-07 (1)</td>
              <td rowspan="1" colspan="1">2.85E-05 (4)</td>
              <td rowspan="1" colspan="1">1.78E-05 (3)</td>
              <td rowspan="1" colspan="1">0.94 (5)</td>
              <td rowspan="1" colspan="1">2.04E-07 (2)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Kidney</td>
              <td rowspan="1" colspan="1">240</td>
              <td rowspan="1" colspan="1">0.91 (5)</td>
              <td rowspan="1" colspan="1">0.038 (2)</td>
              <td rowspan="1" colspan="1">0.24 (4)</td>
              <td rowspan="1" colspan="1">0.045 (3)</td>
              <td rowspan="1" colspan="1">0.0026 (1)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PCPG</td>
              <td rowspan="1" colspan="1">80</td>
              <td rowspan="1" colspan="1">0.043 (1)</td>
              <td rowspan="1" colspan="1">0.18 (4)</td>
              <td rowspan="1" colspan="1">0.093 (3)</td>
              <td rowspan="1" colspan="1">0.09 (2)</td>
              <td rowspan="1" colspan="1">0.54 (5)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Skin</td>
              <td rowspan="1" colspan="1">338</td>
              <td rowspan="1" colspan="1">0.0014 (1)</td>
              <td rowspan="1" colspan="1">0.96 (5)</td>
              <td rowspan="1" colspan="1">0.4 (3)</td>
              <td rowspan="1" colspan="1">0.51 (4)</td>
              <td rowspan="1" colspan="1">0.0029 (2)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Thyroid</td>
              <td rowspan="1" colspan="1">219</td>
              <td rowspan="1" colspan="1">0.049 (1)</td>
              <td rowspan="1" colspan="1">0.09 (2)</td>
              <td rowspan="1" colspan="1">0.67 (5)</td>
              <td rowspan="1" colspan="1">0.18 (4)</td>
              <td rowspan="1" colspan="1">0.17 (3)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">P integrated</td>
              <td rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">1.07E-22</td>
              <td align="center" rowspan="1" colspan="1">1.04E-05</td>
              <td align="center" rowspan="1" colspan="1">1.91E-10</td>
              <td align="center" rowspan="1" colspan="1">2.22E-11</td>
              <td align="center" rowspan="1" colspan="1">5.18E-11</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Rank score</td>
              <td align="center" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">13</td>
              <td align="center" rowspan="1" colspan="1">26</td>
              <td align="center" rowspan="1" colspan="1">23</td>
              <td align="center" rowspan="1" colspan="1">21</td>
              <td align="center" rowspan="1" colspan="1">22</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note</italic>: <italic>P</italic> values are from a Cox proportional hazards regression model using a log-rank test to test the significance of the survival time differences between clusters. In brackets next to the <italic>P</italic> values are the ranks for each dataset. The first final row is the integrated <italic>P</italic>-value using Fisher’s method, the second is the sum of the ranks (lower is better). PCPG stands for Pheochromocytoma and Paraganglioma. For all datasets, the three data types used were mRNA, miRNA and protein.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We visually compared the multi-omic clusters found with Spectrum with those from SNF using uniform manifold approximation and projection (UMAP) plots for the first three multi-omic datasets (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S6a</xref>–c). Spectrum runs UMAP or t-SNE on the integrated similarity matrix as a new data visualization method for multi-omic data. The silhouette width was used as an additional scoring metric to the <italic>P</italic> values to investigate the quality of the clustering. On the brain and breast multi-omic datasets, Spectrum yielded higher silhouette widths than SNF, while for the bladder dataset the opposite was true. On the breast dataset SNF could be visually seen on the UMAP plot as missing a third cluster that Spectrum detected (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S6c</xref>). To investigate the consistency of the results from Spectrum and SNF, both methods were run on two parts of the randomly split brain cancer multi-omic dataset (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S7a</xref> and b). This dataset was chosen because it was the largest (<italic>N</italic> = 425), therefore likely to be stable in structure after splitting. Both Spectrum and SNF identified the same optimal <italic>K</italic> on each split, supporting their ability to perform consistently. These findings support the use of Spectrum as a complementary multi-omic spectral clustering tool to SNF and other methods.</p>
      <p>Next, to gain an initial insight into relative multi-omic runtimes, we tested the algorithms on the kidney TCGA dataset (<xref rid="btz704-B19" ref-type="bibr">Network, 2013</xref>). Spectrum performed the fastest (2.5 s), followed by SNF (4.06 s), PINSplus (27.22 s), CIMLR (59.56 s) and iClusterPlus (305.35 s). A more extensive analysis of runtime was performed for the single and multi-omic algorithms using simulated data. This worked by increasing the number of points from 100 to 1000 in steps of 100, with each dataset containing 5000 features (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S8a</xref> and b). These analyses demonstrated the preferable runtimes of Spectrum relative to other methods. Spectrum’s good performance in finding clinically related clusters comes with a bonus of faster runtimes.</p>
      <p>We next demonstrated the advantage of Spectrum’s adaptive density-aware kernel by comparison with the classic Zelnik-Manor kernel, a non-density-aware kernel that adapts to local data scale only. First, Spectrum using either of the two kernels was run on a non-Gaussian synthetic dataset consisting of two worm-like structures. The clustering demonstrated that the density-aware kernel improved the classification (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S9a</xref> and b). Next, differences on TCGA multi-omic data were examined. Analysis of the brain cancer multi-omic dataset (<xref rid="btz704-B6" ref-type="bibr">Ceccarelli <italic>et al.</italic>, 2016</xref>) found the density-aware kernel detected two additional clusters in comparison with the Zelnik-Manor kernel (<xref ref-type="fig" rid="btz704-F3">Fig. 3a</xref>). UMAP plots demonstrated the density-aware kernel results in visually more compact clusters than the Zelnik-Manor kernel. This was expected, as the density-aware kernel enhances connections in the graph where the points share common nearest neighbours. The survival <italic>P</italic> values produced by the different methods were shown on survival curves (<xref ref-type="fig" rid="btz704-F3">Fig. 3b</xref>). Spectrum obtained a greater level of significance using the density-aware kernel (<italic>P</italic> = 3.76E-16) than using the Zelnik-Manor kernel (<italic>P</italic> = 1.68E-11). We expanded this comparison to include all seven TCGA multi-omic datasets to find that the density-aware kernel has a noticeable advantage over the Zelnik-Manor non density-aware kernel (<xref rid="btz704-T2" ref-type="table">Table 2</xref>). These findings demonstrate the potential for improvement gains by using a kernel that considers common nearest neighbours.
</p>
      <fig id="btz704-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>The adaptive density-aware kernel demonstrates an advantage in multi-omic analysis. On the right-hand side of the panel are the results for the Zelnik-Manor kernel, while the density-aware kernel results are shown on the left-hand side. (<bold>a</bold>) Spectrum clustering assignments from the brain cancer dataset (<xref rid="btz704-B6" ref-type="bibr">Ceccarelli <italic>et al.</italic>, 2016</xref>), UMAP was run on the integrated similarity matrices for mRNA, miRNA and protein data to generate the plots. (<bold>b</bold>) Survival curves with <italic>P</italic> values from a Cox proportional hazards regression model using a log-rank test to assess significance between clusters</p>
        </caption>
        <graphic xlink:href="btz704f3"/>
      </fig>
      <table-wrap id="btz704-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Comparison of spectrum density-aware kernel versus the Zelnik-Manor self-tuning kernel in a multi-omic cluster analysis</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th align="left" rowspan="1" colspan="1">Data types</th>
              <th align="left" rowspan="1" colspan="1">
                <italic>N</italic>
              </th>
              <th align="left" rowspan="1" colspan="1">Spectrum density aware</th>
              <th align="left" rowspan="1" colspan="1">Spectrum Zelnik-Manor</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Bladder</td>
              <td rowspan="1" colspan="1">mRNA, miRNA, protein</td>
              <td rowspan="1" colspan="1">338</td>
              <td rowspan="1" colspan="1">0.0042</td>
              <td rowspan="1" colspan="1">0.0033</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Brain</td>
              <td rowspan="1" colspan="1">mRNA, miRNA, protein</td>
              <td rowspan="1" colspan="1">425</td>
              <td rowspan="1" colspan="1">3.76E-16</td>
              <td rowspan="1" colspan="1">1.68E-11</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Breast</td>
              <td rowspan="1" colspan="1">mRNA, miRNA, protein</td>
              <td rowspan="1" colspan="1">634</td>
              <td rowspan="1" colspan="1">1.47E-07</td>
              <td rowspan="1" colspan="1">3.56E-07</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Kidney</td>
              <td rowspan="1" colspan="1">mRNA, miRNA, protein</td>
              <td rowspan="1" colspan="1">240</td>
              <td rowspan="1" colspan="1">0.91</td>
              <td rowspan="1" colspan="1">0.86</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PCPG</td>
              <td rowspan="1" colspan="1">mRNA, miRNA, protein</td>
              <td rowspan="1" colspan="1">80</td>
              <td rowspan="1" colspan="1">0.043</td>
              <td rowspan="1" colspan="1">0.35</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Skin</td>
              <td rowspan="1" colspan="1">mRNA, miRNA, protein</td>
              <td rowspan="1" colspan="1">338</td>
              <td rowspan="1" colspan="1">0.0014</td>
              <td rowspan="1" colspan="1">0.0058</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Thyroid</td>
              <td rowspan="1" colspan="1">mRNA, miRNA, protein</td>
              <td rowspan="1" colspan="1">219</td>
              <td rowspan="1" colspan="1">0.049</td>
              <td rowspan="1" colspan="1">0.054</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">P integrated</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">1.07E-22</td>
              <td rowspan="1" colspan="1">7.71E-17</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic>Note</italic>: Values correspond to <italic>P</italic> values from a Cox proportional hazards regression model using a log-rank test to test the significance of the survival time differences between clusters. The final row is the integrated <italic>P</italic>-value using Fisher’s method. PCPG stands for Pheochromocytoma and Paraganglioma.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.2 Spectrum performs well at identifying cell types in single-cell RNA-seq data</title>
      <p>We examined Spectrum’s performance on simulated datasets that resemble single-cell RNA-seq, as they were made to consist of many Gaussian blobs that can overlap. Spectrum identified the correct <italic>K</italic> for both the <italic>K</italic> = 10 simulated dataset and the <italic>K</italic> = 20 dataset (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S10a</xref>–d). Next, we tested Spectrum’s performance relative to other methods on seven real single-cell RNA-seq datasets (<xref rid="btz704-B3" ref-type="bibr">Baron <italic>et al.</italic>, 2016</xref>; <xref rid="btz704-B5" ref-type="bibr">Camp <italic>et al.</italic>, 2017</xref>; <xref rid="btz704-B8" ref-type="bibr">Darmanis <italic>et al.</italic>, 2015</xref>; <xref rid="btz704-B17" ref-type="bibr">Li <italic>et al.</italic>, 2017</xref>; <xref rid="btz704-B18" ref-type="bibr">Muraro <italic>et al.</italic>, 2016</xref>; <xref rid="btz704-B23" ref-type="bibr">Patel <italic>et al.</italic>, 2014</xref>; <xref rid="btz704-B24" ref-type="bibr">Pollen <italic>et al.</italic>, 2014</xref>) by comparing the assigned clusters with the provided cell type labels using NMI (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>). Spectrum had the highest summed NMI (NMI = 5.89), closely followed by Seurat (NMI = 5.74), MUDAN (NMI = 5.71), SC3 (NMI = 5.49) and SIMLR (NMI = 5.01). Spectrum’s summed NMI was favourably weighted by its performance on the Pollen dataset (NMI = 0.95). Using a rank-based score to eliminate this advantage, Spectrum still came joint first with SC3 (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>). A similarity matrix for the Pollen data results was shown and t-SNE plots showing the Spectrum clustering assignments were produced (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figs S11 and S12</xref>). Overall, Spectrum, Seurat, SC3 and MUDAN performed similarly in these comparisons, however, SIMLR did not perform as well (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>).</p>
      <p>Notably, in the comparative analysis shown in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>, since the Baron and Muraro datasets had higher numbers of points, to reduce runtime Spectrum was run using the FASP method (with 900 centroids). Even with the FASP data compression for these two datasets, Spectrum yielded the highest NMI relative to the other methods. Comparing Spectrum runtime on the Baron dataset (<italic>N</italic> = 8569) yielded 1.95 h without FASP versus 14.23 s with FASP. Analyses were performed on a single core of an Intel Core i7-6560U CPU @ 2.20 GHz laptop computer with 16 GB of DDR3 RAM. On the Muraro dataset (<italic>N</italic> = 2126), without FASP took 1.97 min and with took 11.83 s. Since the complexity of spectral clustering is cubic,<inline-formula id="IE168"><mml:math id="IM168"><mml:mi mathvariant="normal"> </mml:mi><mml:mi>O</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> and the complexity of <italic>k</italic> means is linear, <inline-formula id="IE169"><mml:math id="IM169"><mml:mi>O</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="italic">KNT</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula id="IE170"><mml:math id="IM170"><mml:mi>T</mml:mi></mml:math></inline-formula> is the number of <italic>k</italic> means iterations, using <italic>k</italic> means as a precursor to compress the data (FASP) is computationally advantageous on larger datasets.</p>
      <p>To gain an initial insight into relative runtimes of all methods (without using Spectrum’s FASP implementation), methods were run on the Camp dataset (777 points). This analysis found MUDAN performed the fastest (0.23 s), followed by Seurat (2.45 s), Spectrum (12.64 s), SC3 (183.66 s) and SIMLR (264.31 s). A more detailed runtime analysis was performed for all algorithms on simulated datasets with 500 to 4000 points in steps of 500 with 1000 features (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S13</xref>). Spectrum was in the middle in terms of speed, usually performing faster than the SC3 algorithm. However, SC3 adjusted its own parameters to work faster at higher numbers of points making it of comparable speed to Spectrum. Spectrum was slower than MUDAN and Seurat, but much faster than SIMLR. Overall, these data demonstrate Spectrum is well suited to clustering small to large single cell RNA-seq datasets, with FASP required for the later.</p>
    </sec>
    <sec>
      <title>3.3 A fast new heuristic for finding <italic>K</italic> when performing spectral clustering</title>
      <p>Since the eigengap method does not automatically recognize both Gaussian and non-Gaussian structures (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figs S1 and S2</xref>), we developed a complementary method which can. The method involves examining the multimodality of the eigenvectors of the data’s graph Laplacian, so we call it ‘the multimodality gap’. To demonstrate this method, five Gaussian blobs were generated (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S14a</xref>) and the multimodality of the data’s graph’s eigenvectors were also displayed (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S14b</xref>). The dip-test statistic (<xref rid="btz704-B11" ref-type="bibr">Hartigan and Hartigan, 1985</xref>) (<italic>Z</italic>) which measures multimodality demonstrated a large gap between eigenvectors five and six. Therefore, using this method it was correctly concluded that <italic>K</italic> = 5. Each individual eigenvector was plotted out (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S14c</xref>) to demonstrate the changing distribution of the eigenvectors. As observed in the analysis of the set of <italic>Z</italic> values, there was a transition from a multimodal distribution at eigenvector five to a unimodal distribution at eigenvector six, supporting <italic>K </italic>= 5. To further demonstrate the method, several simulations were run and the method successfully clustered both complex non-Gaussian (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S15a</xref>–d) and Gaussian clusters (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S16a</xref>–d). However, since the simple method of looking for the greatest gap in the set of <italic>Z</italic> values can get stuck in local minima (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S16d</xref>), the method was further enhanced by adding an algorithm to search for the last substantial gap.</p>
      <p>We found the multimodality gap requires kernel tuning to perform well on certain datasets. This was evident in non-Gaussian data simulations, as with kernel tuning there is a perfect clustering result for the spirals test data (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S17a</xref>), while without kernel tuning the method fails to cluster correctly (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S17b</xref>). Kernel tuning is performed by simply changing the <inline-formula id="IE171"><mml:math id="IM171"><mml:mi>P</mml:mi></mml:math></inline-formula> parameter of the self-tuning kernel and for each kernel finding the maximum multimodality gap between any pair of eigenvectors. The kernel that yields the greatest gap is the optimal kernel, where the most negative <italic>D</italic> value corresponds to that kernel with the maximum gap (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S17c</xref>). We examined the performance of the multimodality gap across the seven TCGA multi-omic datasets to demonstrate its applicability as an alternative method to the eigengap. This analysis found the multimodality gap can provide different <italic>P</italic> values compared with the eigengap (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S3</xref>). Preferable methods will vary according to the data. For example, the multimodality gap (<italic>P</italic> = 0.0019) has a lower <italic>P</italic>-value than the eigengap (<italic>P</italic> = 0.91) on the kidney cancer data (<xref rid="btz704-B19" ref-type="bibr">Network, 2013</xref>). Including a second method to automatically decide <italic>K</italic> gives the user power to find the best approach for their data and presents a solution to an open problem in spectral clustering.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Spectrum provides density-aware spectral clustering for complex omic data. Spectrum adapts to each new dataset by using each point’s <italic>k</italic>-nearest neighbours and their distances, instead of parameters that require tuning with each new dataset (<xref rid="btz704-B21" ref-type="bibr">Ng <italic>et al.</italic>, 2002</xref>; <xref rid="btz704-B37" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>), when performing kernel calculations. This enables the method to work quickly and yield good results. Spectrum was the fastest method in the single-omic and multi-omic TCGA data analysis. Our data also demonstrate good performance with Spectrum as lower <italic>P</italic> values and higher NMI values are often obtained on real data. This is partially due to the density-aware kernel that considers more local statistical properties of the data other than scale (<xref rid="btz704-B36" ref-type="bibr">Zelnik-Manor and Perona, 2005</xref>). Increasing the similarity between samples that share more common nearest neighbours enhances intra-cluster similarity. This produces more compact clusters and reinforces the underlying structure.</p>
    <p>SNF was the first multi-view spectral clustering method to be developed for multi-omic data (<xref rid="btz704-B29" ref-type="bibr">Wang <italic>et al.</italic>, 2014</xref>). Spectrum is in the same family of algorithms; however, it does not include methods developed in the SNF study or advance upon them. Spectrum has several differences: (i) A different kernel that adapts to local density by strengthening local connections between points that share common nearest neighbours. (ii) A different data integration method that uses a TPG integration and diffusion technique. (iii) An alternative method for finding <italic>K</italic> that analyses eigenvector distributions. (iv) Use of GMM instead of <italic>k</italic>-means to cluster the graph’s eigenvectors. GMM can detect clusters with different variance and is preferred for spectral clustering (<xref rid="btz704-B36" ref-type="bibr">Zelnik-Manor and Perona, 2005</xref>). (v) Spectrum performs <italic>k</italic>NN graph diffusion on a single-view whereas SNF does not. This is because SNF only performs cross-diffusion between two or more different <italic>k</italic>NN graphs (from different data views). <italic>k</italic>NN graph diffusion is valuable, as has been demonstrated to reduce noise (<xref rid="btz704-B28" ref-type="bibr">Shu and Latecki, 2016</xref>). Spectrum is a novel and complementary tool.</p>
    <p>Spectral clustering represents one of the most popular and promising techniques to integrate multi-omic data, partly because of the many well-established multi-view data integration methods developed in computer science (<xref rid="btz704-B15" ref-type="bibr">Kumar <italic>et al.</italic>, 2011</xref>; <xref rid="btz704-B26" ref-type="bibr">Rappoport and Shamir, 2018</xref>; <xref rid="btz704-B28" ref-type="bibr">Shu and Latecki, 2016</xref>; <xref rid="btz704-B29" ref-type="bibr">Wang <italic>et al.</italic>, 2014</xref>). However, there are other interesting types of integrative methods not tested in our study, including MANCIE </p>
    <p>(<xref rid="btz704-B34" ref-type="bibr">Zang <italic>et al.</italic>, 2016</xref>). MANCIE uses a correlation-based method that allows one data view to modify data in a second view by taking the first principal component or a weighted mean of the data. Another method, NBS (<xref rid="btz704-B12" ref-type="bibr">Hofree <italic>et al.</italic>, 2013</xref>) projects binary somatic mutation data from cancer tumours onto public gene–gene interaction networks. Network propagation is applied to spread the influence of each mutation profile over its neighbourhood network. The result is a matrix of continuous values for each gene that reflect the network proximity of the gene to mutated genes in that patient. This matrix can then be used for clustering. There have also been efforts elsewhere to combine somatic mutation data with pathway information to subtype cancer patients (<xref rid="btz704-B31" ref-type="bibr">Wang <italic>et al.</italic>, 2018</xref>).</p>
    <p>Spectrum could be used to integrate somatic mutation data from tumours if the data were first made continuous, for example, as in the NBS method. To accept binary data directly, the kernel would have to be modified. We leave this for future work. The next step for Spectrum is to allow for missing data when performing integrating multi-omic data. This was recently proposed in the NEMO spectral clustering algorithm that uses mean imputation at the similarity matrix level (<xref rid="btz704-B26" ref-type="bibr">Rappoport and Shamir, 2018</xref>).</p>
    <p>The multimodality gap heuristic for finding <italic>K</italic> increases the flexibility of Spectrum. This is because it can recognize both complex shapes and Gaussian clusters. There are few good solutions to this problem, none of which are implemented in a publicly available R library. The Zelnik-Manor self-tuning algorithm (<xref rid="btz704-B36" ref-type="bibr">Zelnik-Manor and Perona, 2005</xref>) involves a gradient descent technique that is complex to code and time consuming to execute. In contrast, the multimodality gap is relatively straightforward to implement, effective, and can be used to tune the kernel. Non-Gaussian clusters may occur in flow cytometry data (<xref rid="btz704-B35" ref-type="bibr">Zare <italic>et al.</italic>, 2010</xref>) and in image analysis (<xref rid="btz704-B32" ref-type="bibr">Xiang and Gong, 2008</xref>). Overall, Spectrum is a fast, sophisticated and efficient clustering method and is well suited to clustering a range of data.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz704_Supplementary_Data</label>
      <media xlink:href="btz704_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>This study was supported by funding from the UK Medical Research Council (MRC) (grant number G0800648).</p>
    <sec>
      <title>Funding</title>
      <p>No funding source to declare.</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz704-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Agrawal</surname><given-names>N.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Integrated genomic characterization of papillary thyroid carcinoma</article-title>. <source>Cell</source>, <volume>159</volume>, <fpage>676</fpage>–<lpage>690</lpage>.<pub-id pub-id-type="pmid">25417114</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Akbani</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Genomic classification of cutaneous melanoma</article-title>. <source>Cell</source>, <volume>161</volume>, <fpage>1681</fpage>–<lpage>1696</lpage>.<pub-id pub-id-type="pmid">26091043</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baron</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>A single-cell transcriptomic map of the human and mouse pancreas reveals inter-and intra-cell population structure</article-title>. <source>Cell Syst</source>., <volume>3</volume>, <fpage>346</fpage>–<lpage>360.e344</lpage>.<pub-id pub-id-type="pmid">27667365</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Butler</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Integrating single-cell transcriptomic data across different conditions, technologies, and species</article-title>. <source>Nat. Biotechnol</source>., <volume>36</volume>, <fpage>411</fpage>.<pub-id pub-id-type="pmid">29608179</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Camp</surname><given-names>J.G.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Multilineage communication regulates human liver bud development from pluripotency</article-title>. <source>Nature</source>, <volume>546</volume>, <fpage>533</fpage>.<pub-id pub-id-type="pmid">28614297</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ceccarelli</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Molecular profiling reveals biologically discrete subsets and pathways of progression in diffuse glioma</article-title>. <source>Cell</source>, <volume>164</volume>, <fpage>550</fpage>–<lpage>563</lpage>.<pub-id pub-id-type="pmid">26824661</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ciriello</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Comprehensive molecular portraits of invasive lobular breast cancer</article-title>. <source>Cell</source>, <volume>163</volume>, <fpage>506</fpage>–<lpage>519</lpage>.<pub-id pub-id-type="pmid">26451490</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Darmanis</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>A survey of human brain transcriptome diversity at the single cell level</article-title>. <source>Proc. Natl. Acad Sci. USA</source>, <volume>112</volume>, <fpage>7285</fpage>–<lpage>7290</lpage>.<pub-id pub-id-type="pmid">26060301</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dudoit</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Fridlyand</surname><given-names>J.</given-names></name></person-group> (<year>2002</year>) 
<article-title>A prediction-based resampling method for estimating the number of clusters in a dataset</article-title>. <source>Genome Biol</source>., <volume>3</volume>, RESEARCH0036.</mixed-citation>
    </ref>
    <ref id="btz704-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fishbein</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Comprehensive molecular characterization of pheochromocytoma and paraganglioma</article-title>. <source>Cancer Cell</source>, <volume>31</volume>, <fpage>181</fpage>–<lpage>193</lpage>.<pub-id pub-id-type="pmid">28162975</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hartigan</surname><given-names>J.A.</given-names></name>, <name name-style="western"><surname>Hartigan</surname><given-names>P.M.</given-names></name></person-group> (<year>1985</year>) 
<article-title>The dip test of unimodality</article-title>. <source>Ann. Statist</source>., <volume>13</volume>, <fpage>70</fpage>–<lpage>84</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hofree</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Network-based stratification of tumor mutations</article-title>. <source>Nat. Methods</source>, <volume>10</volume>, <fpage>1108</fpage>.<pub-id pub-id-type="pmid">24037242</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>John</surname><given-names>C.R.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) M3C: a Monte Carlo reference-based consensus clustering algorithm. <italic>bioRxiv</italic>, <fpage>377002</fpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kiselev</surname><given-names>V.Y.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>SC3: consensus clustering of single-cell RNA-seq data</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>483</fpage>.<pub-id pub-id-type="pmid">28346451</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Co-regularized multi-view spectral clustering</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>24</volume>, <fpage>1413</fpage>–<lpage>1421</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lefaudeux</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>U-BIOPRED clinical adult asthma clusters linked to a subset of sputum omics</article-title>. <source>J. Allergy Clin. Immunol</source>., <volume>139</volume>, <fpage>1797</fpage>–<lpage>1807</lpage>.<pub-id pub-id-type="pmid">27773852</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Reference component analysis of single-cell transcriptomes elucidates cellular heterogeneity in human colorectal tumors</article-title>. <source>Nat. Genet</source>., <volume>49</volume>, <fpage>708</fpage>.<pub-id pub-id-type="pmid">28319088</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Muraro</surname><given-names>M.J.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>A single-cell transcriptome atlas of the human pancreas</article-title>. <source>Cell Syst</source>., <volume>3</volume>, <fpage>385</fpage>–<lpage>394.e383</lpage>.<pub-id pub-id-type="pmid">27693023</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Network</surname><given-names>C.G.A.R.</given-names></name></person-group> (<year>2013</year>) 
<article-title>Comprehensive molecular characterization of clear cell renal cell carcinoma</article-title>. <source>Nature</source>, <volume>499</volume>, <fpage>43</fpage>.<pub-id pub-id-type="pmid">23792563</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Network</surname><given-names>C.G.A.R.</given-names></name></person-group> (<year>2014</year>) 
<article-title>Comprehensive molecular characterization of urothelial bladder carcinoma</article-title>. <source>Nature</source>, <volume>507</volume>, <fpage>315</fpage>.<pub-id pub-id-type="pmid">24476821</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ng</surname><given-names>A.Y.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>On spectral clustering: analysis and an algorithm</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>14</volume>, <fpage>849</fpage>–<lpage>856</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nguyen</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>PINSPlus: a tool for tumor subtype discovery in integrated genomic data</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2843</fpage>–<lpage>2846</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Patel</surname><given-names>A.P.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Single-cell RNA-seq highlights intratumoral heterogeneity in primary glioblastoma</article-title>. <source>Science</source>, <volume>344</volume>, <fpage>1396</fpage>–<lpage>1401</lpage>.<pub-id pub-id-type="pmid">24925914</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pollen</surname><given-names>A.A.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Low-coverage single-cell mRNA sequencing reveals cellular heterogeneity and activated signaling pathways in developing cerebral cortex</article-title>. <source>Nat. Biotechnol</source>., <volume>32</volume>, <fpage>1053</fpage>.<pub-id pub-id-type="pmid">25086649</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ramazzotti</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Multi-omic tumor data reveal diversity of molecular mechanisms that correlate with survival</article-title>. <source>Nat. Commun</source>., <volume>9</volume>, <fpage>4453</fpage>.<pub-id pub-id-type="pmid">30367051</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Rappoport</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Shamir</surname><given-names>R.</given-names></name></person-group> (<year>2018</year>) NEMO: cancer subtyping by integration of partial multi-omic data. <italic>bioRxiv</italic>, <fpage>415224</fpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Integrative clustering of multiple genomic data types using a joint latent variable model with application to breast and lung cancer subtype analysis</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>2906</fpage>–<lpage>2912</lpage>.<pub-id pub-id-type="pmid">19759197</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shu</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Latecki</surname><given-names>L.J.</given-names></name></person-group> (<year>2016</year>) Integration of single-view graphs with diffusion of tensor product graphs for multi-view spectral clustering. <italic>Asian Conference on Machine Learning</italic>, <volume>45</volume>, <fpage>362</fpage>–<lpage>377</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Similarity network fusion for aggregating data types on a genomic scale</article-title>. <source>Nat. Methods</source>, <volume>11</volume>, <fpage>333</fpage>.<pub-id pub-id-type="pmid">24464287</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Visualization and analysis of single-cell RNA-seq data by kernel-based similarity learning</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>414</fpage>.<pub-id pub-id-type="pmid">28263960</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Typing tumors using pathways selected by somatic evolution</article-title>. <source>Nat. Commun</source>., <volume>9</volume>, <fpage>4159</fpage>.<pub-id pub-id-type="pmid">30297789</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xiang</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Gong</surname><given-names>S.</given-names></name></person-group> (<year>2008</year>) 
<article-title>Spectral clustering with eigenvector selection</article-title>. <source>Pattern Recogn</source>., <volume>41</volume>, <fpage>1012</fpage>–<lpage>1029</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Yan</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) <chapter-title>Fast approximate spectral clustering</chapter-title> In: <source>Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>. 
<publisher-name>ACM</publisher-name>, pp. <fpage>907</fpage>–<lpage>916</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zang</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>High-dimensional genomic data bias correction and data integration using MANCIE</article-title>. <source>Nat. Commun</source>., <volume>7</volume>, <fpage>11305</fpage>.<pub-id pub-id-type="pmid">27072482</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zare</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Data reduction for spectral clustering to analyze high throughput flow cytometry data</article-title>. <source>BMC Bioinformatics</source>, <volume>11</volume>, <fpage>403</fpage>.<pub-id pub-id-type="pmid">20667133</pub-id></mixed-citation>
    </ref>
    <ref id="btz704-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zelnik-Manor</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Perona</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Self-tuning spectral clustering</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>17</volume>, <fpage>1601</fpage>–<lpage>1608</lpage>.</mixed-citation>
    </ref>
    <ref id="btz704-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Local density adaptive similarity measurement for spectral clustering</article-title>. <source>Pattern Recogn. Lett</source>., <volume>32</volume>, <fpage>352</fpage>–<lpage>358</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
