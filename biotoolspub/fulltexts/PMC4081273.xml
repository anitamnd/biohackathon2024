<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PeerJ</journal-id>
    <journal-id journal-id-type="iso-abbrev">PeerJ</journal-id>
    <journal-id journal-id-type="pmc">PeerJ</journal-id>
    <journal-id journal-id-type="publisher-id">PeerJ</journal-id>
    <journal-title-group>
      <journal-title>PeerJ</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2167-8359</issn>
    <publisher>
      <publisher-name>PeerJ Inc.</publisher-name>
      <publisher-loc>San Francisco, USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4081273</article-id>
    <article-id pub-id-type="publisher-id">453</article-id>
    <article-id pub-id-type="doi">10.7717/peerj.453</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Bioinformatics</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Computational Biology</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Computational Science</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Human–Computer Interaction</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Science and Medical Education</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>scikit-image: image processing in Python</article-title>
    </title-group>
    <contrib-group>
      <contrib id="author-1" contrib-type="author" corresp="yes">
        <name>
          <surname>van der Walt</surname>
          <given-names>Stéfan</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <email>stefan@sun.ac.za</email>
      </contrib>
      <contrib id="author-2" contrib-type="author">
        <name>
          <surname>Schönberger</surname>
          <given-names>Johannes L.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-2">2</xref>
      </contrib>
      <contrib id="author-3" contrib-type="author">
        <name>
          <surname>Nunez-Iglesias</surname>
          <given-names>Juan</given-names>
        </name>
        <xref ref-type="aff" rid="aff-3">3</xref>
      </contrib>
      <contrib id="author-4" contrib-type="author">
        <name>
          <surname>Boulogne</surname>
          <given-names>François</given-names>
        </name>
        <xref ref-type="aff" rid="aff-4">4</xref>
      </contrib>
      <contrib id="author-5" contrib-type="author">
        <name>
          <surname>Warner</surname>
          <given-names>Joshua D.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-5">5</xref>
      </contrib>
      <contrib id="author-6" contrib-type="author">
        <name>
          <surname>Yager</surname>
          <given-names>Neil</given-names>
        </name>
        <xref ref-type="aff" rid="aff-6">6</xref>
      </contrib>
      <contrib id="author-7" contrib-type="author">
        <name>
          <surname>Gouillart</surname>
          <given-names>Emmanuelle</given-names>
        </name>
        <xref ref-type="aff" rid="aff-7">7</xref>
      </contrib>
      <contrib id="author-8" contrib-type="author">
        <name>
          <surname>Yu</surname>
          <given-names>Tony</given-names>
        </name>
        <xref ref-type="aff" rid="aff-8">8</xref>
      </contrib>
      <contrib id="author-9" contrib-type="author">
        <collab>the scikit-image contributors</collab>
      </contrib>
      <aff id="aff-1"><label>1</label><institution>Stellenbosch University</institution>, <addr-line>Stellenbosch</addr-line>, <country>South Africa</country></aff>
      <aff id="aff-2"><label>2</label><institution>Department of Computer Science, University of North Carolina at Chapel Hill</institution>, <addr-line>Chapel Hill, NC</addr-line>, <country>USA</country></aff>
      <aff id="aff-3"><label>3</label><institution>Victorian Life Sciences Computation Initiative</institution>, <addr-line>Carlton, VIC</addr-line>, <country>Australia</country></aff>
      <aff id="aff-4"><label>4</label><institution>Department of Mechanical and Aerospace Engineering, Princeton University</institution>, <addr-line>Princeton, NJ</addr-line>, <country>USA</country></aff>
      <aff id="aff-5"><label>5</label><institution>Department of Biomedical Engineering, Mayo Clinic</institution>, <addr-line>Rochester, MN</addr-line>, <country>USA</country></aff>
      <aff id="aff-6"><label>6</label><institution>AICBT Ltd</institution>, <addr-line>Oxford</addr-line>, <country>UK</country></aff>
      <aff id="aff-7"><label>7</label><institution>Joint Unit, CNRS/Saint-Gobain</institution>, <addr-line>Cavaillon</addr-line>, <country>France</country></aff>
      <aff id="aff-8"><label>8</label><institution>Enthought, Inc.</institution>, <addr-line>Austin, TX</addr-line>, <country>USA</country></aff>
    </contrib-group>
    <contrib-group>
      <contrib id="editor-1" contrib-type="editor">
        <name>
          <surname>Gomez</surname>
          <given-names>Shawn</given-names>
        </name>
      </contrib>
    </contrib-group>
    <pub-date pub-type="epub" date-type="pub" iso-8601-date="2014-06-19">
      <day>19</day>
      <month>6</month>
      <year iso-8601-date="2014">2014</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2014</year>
    </pub-date>
    <volume>2</volume>
    <elocation-id>e453</elocation-id>
    <history>
      <date date-type="received" iso-8601-date="2014-04-02">
        <day>2</day>
        <month>4</month>
        <year iso-8601-date="2014">2014</year>
      </date>
      <date date-type="accepted" iso-8601-date="2014-06-04">
        <day>4</day>
        <month>6</month>
        <year iso-8601-date="2014">2014</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2014 Van der Walt et al.</copyright-statement>
      <copyright-year>2014</copyright-year>
      <copyright-holder>Van der Walt et al.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="https://peerj.com/articles/453"/>
    <abstract>
      <p>scikit-image is an image processing library that implements algorithms and utilities for use in research, education and industry applications. It is released under the liberal Modified BSD open source license, provides a well-documented API in the Python programming language, and is developed by an active, international team of collaborators. In this paper we highlight the advantages of open source to achieve the goals of the scikit-image library, and we showcase several real-world image processing applications that use scikit-image. More information can be found on the project homepage, <uri xlink:href="http://scikit-image.org">http://scikit-image.org</uri>.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>Image processing</kwd>
      <kwd>Reproducible research</kwd>
      <kwd>Education</kwd>
      <kwd>Visualization</kwd>
      <kwd>Open source</kwd>
      <kwd>Python</kwd>
      <kwd>Scientific programming</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1">
        <funding-source>NIH F30DK098832</funding-source>
      </award-group>
      <funding-statement>Portions of the research reported in this publication were supported by the National Institute of Diabetes and Digestive and Kidney Diseases of the National Institutes of Health under award number F30DK098832. Portions of the research reported in this paper were supported by the Victorian Life Sciences Computation Initiative. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>In our data-rich world, images represent a significant subset of all measurements made. Examples include DNA microarrays, microscopy slides, astronomical observations, satellite maps, robotic vision capture, synthetic aperture radar images, and higher-dimensional images such as 3-D magnetic resonance or computed tomography imaging. Exploring these rich data sources requires sophisticated software tools that should be easy to use, free of charge and restrictions, and able to address all the challenges posed by such a diverse field of analysis.</p>
    <p>This paper describes scikit-image, a collection of image processing algorithms implemented in the Python programming language by an active community of volunteers and available under the liberal BSD Open Source license. The rising popularity of Python as a scientific programming language, together with the increasing availability of a large eco-system of complementary tools, makes it an ideal environment in which to produce an image processing toolkit.</p>
    <p>The project aims are:</p>
    <list list-type="simple" id="list-1">
      <list-item>
        <label>1.</label>
        <p>
          <italic>To provide high quality, well-documented and easy-to-use implementations of common image processing algorithms.</italic>
        </p>
        <p>Such algorithms are essential building blocks in many areas of scientific research, algorithmic comparisons and data exploration. In the context of reproducible science, it is important to be able to inspect any source code used for algorithmic flaws or mistakes. Additionally, scientific research often requires custom modification of standard algorithms, further emphasizing the importance of open source.</p>
      </list-item>
      <list-item>
        <label>2.</label>
        <p>
          <italic>To facilitate education in image processing.</italic>
        </p>
        <p>The library allows students in image processing to learn algorithms in a hands-on fashion by adjusting parameters and modifying code. In addition, a <monospace>novice</monospace> module is provided, not only for teaching programming in the “turtle graphics” paradigm, but also to familiarize users with image concepts such as color and dimensionality. Furthermore, the project takes part in the yearly Google Summer of Code program<xref ref-type="fn" rid="peerj-453-fn1"><sup>1</sup></xref><fn id="peerj-453-fn1"><label>1</label><p><uri xlink:href="https://developers.google.com/open-source/soc">https://developers.google.com/open-source/soc</uri> (accessed 30 March 2014).</p></fn>, where students learn about image processing and software engineering through contributing to the project.</p>
      </list-item>
      <list-item>
        <label>3.</label>
        <p>
          <italic>To address industry challenges.</italic>
        </p>
        <p>High quality reference implementations of trusted algorithms provide industry with a reliable way of attacking problems without having to expend significant energy in re-implementing algorithms already available in commercial packages. Companies may use the library entirely free of charge, and have the option of contributing changes back, should they so wish.</p>
      </list-item>
    </list>
  </sec>
  <sec>
    <title>Getting started</title>
    <p>One of the main goals of scikit-image is to make it easy for any user to get started quickly—especially users already familiar with Python’s scientific tools. To that end, the basic image is just a standard NumPy array, which exposes pixel data directly to the user. A new user can simply load an image from disk (or use one of scikit-image’s sample images), process that image with one or more image filters, and quickly display the results:</p>
    <preformat>from skimage import data, io, filter

image = data.coins()  # or any NumPy array!
edges = filter.sobel(image)
io.imshow(edges)</preformat>
    <p>The above demonstration loads <monospace>data.coins</monospace>, an example image shipped with scikit-image. For a more complete example, we import NumPy for array manipulation and matplotlib for plotting (<xref rid="ref-28" ref-type="bibr">Van der Walt, Colbert &amp; Varoquaux, 2011</xref>; <xref rid="ref-16" ref-type="bibr">Hunter, 2007</xref>). At each step, we add the picture or the plot to a matplotlib figure shown in <xref ref-type="fig" rid="fig-1">Fig. 1</xref>.</p>
    <preformat>import numpy as np
import matplotlib.pyplot as plt

# Load a small section of the image.
image = data.coins()[0:95, 70:370]

fig, axes = plt.subplots(ncols=2, nrows=3,
                         figsize=(8, 4))
ax0, ax1, ax2, ax3, ax4, ax5  = axes.flat
ax0.imshow(image, cmap=plt.cm.gray)
ax0.set_title('Original', fontsize=24)
ax0.axis('off')</preformat>
    <p>Since the image is represented by a NumPy array, we can easily perform operations such as building a histogram of the intensity values.</p>
    <fig id="fig-1" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.7717/peerj.453/fig-1</object-id>
      <label>Figure 1</label>
      <caption>
        <title>Illustration of several functions available in scikit-image: adaptive threshold, local maxima, edge detection and labels.</title>
        <p>The use of NumPy arrays as our data container also enables the use of NumPy’s built-in <italic>histogram</italic> function.</p>
      </caption>
      <graphic xlink:href="peerj-02-453-g001"/>
    </fig>
    <preformat># Histogram.
values, bins = np.histogram(image,
                            bins=np.arange(256))

ax1.plot(bins[:-1], values, lw=2, c='k')
ax1.set_xlim(xmax=256)
ax1.set_yticks([0, 400])
ax1.set_aspect(.2)
ax1.set_title('Histogram', fontsize=24)</preformat>
    <p>To divide the foreground and background, we threshold the image to produce a binary image. Several threshold algorithms are available. Here, we employ <monospace>filter.threshold_adaptive</monospace> where the threshold value is the weighted mean for the local neighborhood of a pixel.</p>
    <preformat># Apply threshold.
from skimage.filter import threshold_adaptive

bw = threshold_adaptive(image, 95, offset=-15)

ax2.imshow(bw, cmap=plt.cm.gray)
ax2.set_title('Adaptive threshold', fontsize=24)
ax2.axis('off')</preformat>
    <p>We can easily detect interesting features, such as local maxima and edges. The function <monospace>feature.peak_local_max</monospace> can be used to return the coordinates of local maxima in an image.</p>
    <preformat># Find maxima.
from skimage.feature import peak_local_max

coordinates = peak_local_max(image, min_distance=20)

ax3.imshow(image, cmap=plt.cm.gray)
ax3.autoscale(False)
ax3.plot(coordinates[:, 1],
         coordinates[:, 0], c='r.')
ax3.set_title('Peak local maxima', fontsize=24)
ax3.axis('off')</preformat>
    <p>Next, a Canny filter (<monospace>filter.canny</monospace>) (<xref rid="ref-7" ref-type="bibr">Canny, 1986</xref>) detects the edge of each coin.</p>
    <preformat># Detect edges.
from skimage import filter

edges = filter.canny(image, sigma=3,
                     low_threshold=10,
                     high_threshold=80)

ax4.imshow(edges, cmap=plt.cm.gray)
ax4.set_title('Edges', fontsize=24)
ax4.axis('off')</preformat>
    <p>Then, we attribute to each coin a label (<monospace>morphology.label</monospace>) that can be used to extract a sub-picture. Finally, physical information such as the position, area, eccentricity, perimeter, and moments can be extracted using <monospace>measure.regionprops</monospace>.</p>
    <preformat># Label image regions.
from skimage.measure import regionprops
import matplotlib.patches as mpatches
from skimage.morphology import label

label_image = label(edges)

ax5.imshow(image, cmap=plt.cm.gray)
ax5.set_title('Labeled items', fontsize=24)
ax5.axis('off')

for region in regionprops(label_image):
    # Draw rectangle around segmented coins.
    minr, minc, maxr, maxc = region.bbox
    rect = mpatches.Rectangle((minc, minr),
                              maxc - minc,
                              maxr - minr,
                              fill=False,
                              edgecolor='red',
                              linewidth=2)
    ax5.add_patch(rect)

plt.tight_layout()
plt.show()</preformat>
    <p>scikit-image thus makes it possible to perform sophisticated image processing tasks with only a few function calls.</p>
  </sec>
  <sec>
    <title>Library overview</title>
    <p>The scikit-image project started in August of 2009 and has received contributions from more than 100 individuals.<xref ref-type="fn" rid="peerj-453-fn2"><sup>2</sup></xref><fn id="peerj-453-fn2"><label>2</label><p><uri xlink:href="https://www.ohloh.net/p/scikit-image">https://www.ohloh.net/p/scikit-image</uri></p></fn> The package can be installed on all major platforms (e.g., BSD, GNU/Linux, OS X, Windows) from, amongst other sources, the Python Package Index (PyPI),<xref ref-type="fn" rid="peerj-453-fn3"><sup>3</sup></xref><fn id="peerj-453-fn3"><label>3</label><p><uri xlink:href="http://pypi.python.org">http://pypi.python.org</uri></p></fn> Continuum Analytics Anaconda,<xref ref-type="fn" rid="peerj-453-fn4"><sup>4</sup></xref><fn id="peerj-453-fn4"><label>4</label><p><uri xlink:href="https://store.continuum.io/cshop/anaconda">https://store.continuum.io/cshop/anaconda</uri></p></fn> Enthought Canopy,<xref ref-type="fn" rid="peerj-453-fn5"><sup>5</sup></xref><fn id="peerj-453-fn5"><label>5</label><p><uri xlink:href="https://www.enthought.com/products/canopy">https://www.enthought.com/products/canopy</uri></p></fn> Python(x,y),<xref ref-type="fn" rid="peerj-453-fn6"><sup>6</sup></xref><fn id="peerj-453-fn6"><label>6</label><p><uri xlink:href="https://code.google.com/p/pythonxy">https://code.google.com/p/pythonxy</uri></p></fn> NeuroDebian (<xref rid="ref-14" ref-type="bibr">Halchenko &amp; Hanke, 2012</xref>) and GNU/Linux distributions such as Ubuntu.<xref ref-type="fn" rid="peerj-453-fn7"><sup>7</sup></xref><fn id="peerj-453-fn7"><label>7</label><p><uri xlink:href="http://packages.ubuntu.com">http://packages.ubuntu.com</uri></p></fn> In March 2014 alone, the package was downloaded more than 5000 times from PyPI.<xref ref-type="fn" rid="peerj-453-fn8"><sup>8</sup></xref><fn id="peerj-453-fn8"><label>8</label><p><uri xlink:href="http://pypi.python.org/pypi/scikit-image">http://pypi.python.org/pypi/scikit-image</uri> (accessed 30 March 2014).</p></fn></p>
    <p>As of version 0.10, the package contains the following sub-modules:</p>
    <list list-type="simple" id="list-2">
      <list-item>
        <label>•</label>
        <p>color: Color space conversion.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>data: Test images and example data.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>draw: Drawing primitives (lines, text, etc.) that operate on NumPy arrays.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>exposure: Image intensity adjustment, e.g., histogram equalization, etc.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>feature: Feature detection and extraction, e.g., texture analysis, corners, etc.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>filter: Sharpening, edge finding, rank filters, thresholding, etc.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>graph: Graph-theoretic operations, e.g., shortest paths.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>io: Wraps various libraries for reading, saving, and displaying images and video, such as Pillow<xref ref-type="fn" rid="peerj-453-fn9"><sup>9</sup></xref><fn id="peerj-453-fn9"><label>9</label><p><uri xlink:href="http://pillow.readthedocs.org/en/latest/">http://pillow.readthedocs.org/en/latest/</uri> (accessed 30 May 2015).</p></fn> and FreeImage.<xref ref-type="fn" rid="peerj-453-fn10"><sup>10</sup></xref><fn id="peerj-453-fn10"><label>10</label><p><uri xlink:href="http://freeimage.sourceforge.net/">http://freeimage.sourceforge.net/</uri> (accessed 15 May 2015).</p></fn></p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>measure: Measurement of image properties, e.g., similarity and contours.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>morphology: Morphological operations, e.g., opening or skeletonization.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>novice: Simplified interface for teaching purposes.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>restoration: Restoration algorithms, e.g., deconvolution algorithms, denoising, etc.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>segmentation: Partitioning an image into multiple regions.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>transform: Geometric and other transforms, e.g., rotation or the Radon transform.</p>
      </list-item>
      <list-item>
        <label>•</label>
        <p>viewer: A simple graphical user interface for visualizing results and exploring parameters.</p>
      </list-item>
    </list>
    <p>For further details on each module, we refer readers to the API documentation online.<xref ref-type="fn" rid="peerj-453-fn11"><sup>11</sup></xref><fn id="peerj-453-fn11"><label>11</label><p><uri xlink:href="http://scikit-image.org/docs/dev/api/api.html">http://scikit-image.org/docs/dev/api/api.html</uri></p></fn></p>
  </sec>
  <sec>
    <title>Data format and pipelining</title>
    <p>scikit-image represents images as NumPy arrays (<xref rid="ref-28" ref-type="bibr">Van der Walt, Colbert &amp; Varoquaux, 2011</xref>), the de facto standard for storage of multi-dimensional data in scientific Python. Each array has a dimensionality, such as 2 for a 2-D grayscale image, 3 for a 2-D multi-channel image, or 4 for a 3-D multi-channel image; a shape, such as (<italic>M</italic>, <italic>N</italic>, 3) for an RGB color image with <italic>M</italic> vertical and <italic>N</italic> horizontal pixels; and a numeric data type, such as <monospace>float</monospace> for continuous-valued pixels and <monospace>uint8</monospace> for 8-bit pixels. Our use of NumPy arrays as the fundamental data structure maximizes compatibility with the rest of the scientific Python ecosystem. Data can be passed as-is to other tools such as NumPy, SciPy, matplotlib, scikit-learn (<xref rid="ref-22" ref-type="bibr">Pedregosa et al., 2011</xref>), Mahotas (<xref rid="ref-8" ref-type="bibr">Coelho, 2013</xref>), OpenCV, and more.</p>
    <p>Images of differing data-types can complicate the construction of pipelines. scikit-image follows an “Anything In, Anything Out” approach, whereby all functions are expected to allow input of an arbitrary data-type but, for efficiency, also get to choose their own output format. Data-type ranges are clearly defined. Floating point images are expected to have values between 0 and 1 (unsigned images) or −1 and 1 (signed images), while 8-bit images are expected to have values in {0, 1, 2, …, 255}. We provide utility functions, such as <monospace>img_as_float</monospace>, to easily convert between data-types.</p>
  </sec>
  <sec>
    <title>Development practices</title>
    <p>The purpose of scikit-image is to provide a high-quality library of powerful, diverse image processing tools free of charge and restrictions. These principles are the foundation for the development practices in the scikit-image community.</p>
    <p>The library is licensed under the <italic>Modified BSD license</italic>, which allows unrestricted redistribution for any purpose as long as copyright notices and disclaimers of warranty are maintained (<xref rid="ref-31" ref-type="bibr">Wilson, 2012</xref>). It is compatible with GPL licenses, so users of scikit-image can choose to make their code available under the GPL. However, unlike the GPL, it does not require users to open-source derivative work (BSD is not a so-called copyleft license). Thus, scikit-image can also be used in closed-source, commercial environments.</p>
    <p>The development team of scikit-image is an open community that collaborates on the <italic>GitHub</italic> platform for issue tracking, code review, and release management.<xref ref-type="fn" rid="peerj-453-fn12"><sup>12</sup></xref><fn id="peerj-453-fn12"><label>12</label><p><uri xlink:href="https://github.com/scikit-image">https://github.com/scikit-image</uri></p></fn><italic>Google Groups</italic> is used as a public discussion forum for user support, community development, and announcements.<xref ref-type="fn" rid="peerj-453-fn13"><sup>13</sup></xref><fn id="peerj-453-fn13"><label>13</label><p><uri xlink:href="https://groups.google.com/group/scikit-image">https://groups.google.com/group/scikit-image</uri></p></fn></p>
    <p>scikit-image complies with the PEP8 coding style standard (<xref rid="ref-30" ref-type="bibr">Van Rossum, Warsaw &amp; Coghlan, 2001</xref>) and the NumPy documentation format (<xref rid="ref-29" ref-type="bibr">Van der Walt &amp; NumPy developers, 2008</xref>) in order to provide a consistent, familiar user experience across the library similar to other scientific Python packages. As mentioned earlier, the data representation used is <italic>n</italic>-dimensional NumPy arrays, which ensures broad interoperability within the scientific Python ecosystem. The majority of the scikit-image API is intentionally designed as a functional interface which allows one to simply apply one function to the output of another. This modular approach also lowers the barrier of entry for new contributors, since one only needs to master a small part of the entire library in order to make an addition.</p>
    <p>We ensure high code quality by a thorough review process using the pull request interface on GitHub.<xref ref-type="fn" rid="peerj-453-fn14"><sup>14</sup></xref><fn id="peerj-453-fn14"><label>14</label><p><uri xlink:href="https://help.github.com/articles/using-pull-requests">https://help.github.com/articles/using-pull-requests</uri> (accessed 15 May 2014).</p></fn> This enables the core developers and other interested parties to comment on specific lines of proposed code changes, and for the proponents of the changes to update their submission accordingly. Once all the changes have been approved, they can be merged automatically. This process applies not just to outside contributions, but also to the core developers.</p>
    <p>The source code is mainly written in Python, although certain performance critical sections are implemented in Cython, an optimising static compiler for Python (<xref rid="ref-1" ref-type="bibr">Behnel et al., 2011</xref>). scikit-image aims to achieve full unit test coverage, which is above 87% as of release 0.10 and continues to rise. A continuous integration system<xref ref-type="fn" rid="peerj-453-fn15"><sup>15</sup></xref><fn id="peerj-453-fn15"><label>15</label><p><uri xlink:href="https://travis-ci.org">https://travis-ci.org</uri>, <uri xlink:href="https://coveralls.io">https://coveralls.io</uri> (accessed 30 March 2014).</p></fn> automatically checks each commit for unit test coverage and failures on both Python 2 and Python 3. Additionally, the code is analyzed by flake8 (<xref rid="ref-9" ref-type="bibr">Cordasco, 2010</xref>) to ensure compliance with the PEP8 coding style standards (<xref rid="ref-30" ref-type="bibr">Van Rossum, Warsaw &amp; Coghlan, 2001</xref>). Finally, the properties of each public function are documented thoroughly in an API reference guide, embedded as Python docstrings and accessible through the official project homepage or an interactive Python console. Short usage examples are typically included inside the docstrings, and new features are accompanied by longer, self-contained example scripts added to the narrative documentation and compiled to a gallery on the project website. We use Sphinx (<xref rid="ref-4" ref-type="bibr">Brandl, 2007</xref>) to automatically generate both library documentation and the website.</p>
    <p>The development master branch is fully functional at all times and can be obtained from GitHub<xref ref-type="fn" rid="peerj-453-fn12"><sup>12</sup></xref>. The community releases major updates as stable versions approximately every six months. Major releases include new features, while minor releases typically contain only bug fixes. Going forward, users will be notified about API-breaking changes through deprecation warnings for two full major releases before the changes are applied.</p>
  </sec>
  <sec>
    <title>Usage examples</title>
    <sec>
      <title>Research</title>
      <p>Often, a disproportionately large component of research involves dealing with various image data-types, color representations, and file format conversion. scikit-image offers robust tools for converting between image data-types (<xref rid="ref-18" ref-type="bibr">Microsoft, 1995</xref>; <xref rid="ref-19" ref-type="bibr">Munshi &amp; Leech, 2010</xref>; <xref rid="ref-21" ref-type="bibr">Paeth, 1990</xref>) and to do file input/output (I/O) operations. Our purpose is to allow investigators to focus their time on research, instead of expending effort on mundane low-level tasks.</p>
      <p>The package includes a number of algorithms with broad applications across image processing research, from computer vision to medical image analysis. We refer the reader to the current API documentation for a full listing of current capabilities<xref ref-type="fn" rid="peerj-453-fn16"><sup>16</sup></xref><fn id="peerj-453-fn16"><label>16</label><p><uri xlink:href="http://scikit-image.org/docs/dev">http://scikit-image.org/docs/dev</uri> (accessed 30 March 2014).</p></fn>. In this section we illustrate two real-world usage examples of scikit-image in scientific research.</p>
      <p>First, we consider the analysis of a large stack of images, each representing drying droplets containing nanoparticles (see <xref ref-type="fig" rid="fig-2">Fig. 2</xref>). As the drying proceeds, cracks propagate from the edge of the drop to its center. The aim is to understand crack patterns by collecting statistical information about their positions, as well as their time and order of appearance. To improve the speed at which data is processed, each experiment, constituting an image stack, is automatically analysed without human intervention. The contact line is detected by a circular Hough transform (<monospace>transform.hough_circle</monospace>) providing the drop radius and its center. Then, a smaller concentric circle is drawn (<monospace>draw.circle_perimeter</monospace>) and used as a mask to extract intensity values from the image. Repeating the process on each image in the stack, collected pixels can be assembled to make a space–time diagram. As a result, a complex stack of images is reduced to a single image summarizing the underlying dynamic process.</p>
      <fig id="fig-2" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.453/fig-2</object-id>
        <label>Figure 2</label>
        <caption>
          <title>scikit-image is used to track the propagation of cracks (black lines) in a drying colloidal droplet.</title>
          <p>The sequence of pictures shows the temporal evolution of the system with the drop contact line, in green, detected by the Hough transform and the circle, in white, used to extract an annulus of pixel intensities. The result shown illustrates the angular position of cracks and their time of appearance.</p>
        </caption>
        <graphic xlink:href="peerj-02-453-g002"/>
      </fig>
      <p>Next, in regenerative medicine research, scikit-image is used to monitor the regeneration of spinal cord cells in zebrafish embryos (<xref ref-type="fig" rid="fig-3">Fig. 3</xref>). This process has important implications for the treatment of spinal cord injuries in humans (<xref rid="ref-2" ref-type="bibr">Bhatt et al., 2004</xref>; <xref rid="ref-27" ref-type="bibr">Thuret, Moon &amp; Gage, 2006</xref>).</p>
      <p>To understand how spinal cords regenerate in these animals, injured cords are subjected to different treatments. Neuronal precursor cells (labeled green in <xref ref-type="fig" rid="fig-3">Fig. 3A</xref>) are normally uniformly distributed across the spinal cord. At the wound site, they have been removed. We wish to monitor the arrival of new cells at the wound site over time. In <xref ref-type="fig" rid="fig-3">Fig. 3</xref>, we see an embryo two days after wounding, with precursor cells beginning to move back into the wound site (the site of minimum fluorescence). The <monospace>measure.profile_line</monospace> function measures the fluorescence along the cord, directly proportional to the number of cells. We can thus monitor the recovery process and determine which treatments prevent or accelerate recovery.</p>
      <fig id="fig-3" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.453/fig-3</object-id>
        <label>Figure 3</label>
        <caption>
          <title>The <italic>measure.profile_line</italic> function being used to track recovery in spinal cord injuries.</title>
          <p>(A) An image of fluorescently-labeled nerve cells in an injured zebrafish embryo. (B) The automatically determined region of interest. The SciPy library was used to determine the region extent (<xref rid="ref-20" ref-type="bibr">Oliphant, 2007</xref>; <xref rid="ref-17" ref-type="bibr">Jones, Oliphant &amp; Peterson, 2001</xref>), and functions from the scikit-image draw module were used to draw it. (C) The image intensity along the line of interest, averaged over the displayed width.</p>
        </caption>
        <graphic xlink:href="peerj-02-453-g003"/>
      </fig>
    </sec>
    <sec>
      <title>Education</title>
      <p>scikit-image’s simple, well-documented application programming interface (API) makes it ideal for educational use, either via self-taught exploration or formal training sessions.</p>
      <p>The online gallery of examples not only provides an overview of the functionality available in the package but also introduces many of the algorithms commonly used in image processing. This visual index also helps beginners overcome a common entry barrier: locating the class (denoising, segmentation, etc.) and name of operation desired, without being proficient with image processing jargon. For many functions, the documentation includes links to research papers or Wikipedia pages to further guide the user.</p>
      <p>Demonstrating the broad utility of scikit-image in education, thirteen-year-old Rishab Gargeya of the Harker School won the Synopsys Silicon Valley Science and Technology Championship using scikit-image in his project, “A software based approach for automated pathology diagnosis of diabetic retinopathy in the human retina” (<xref rid="ref-26" ref-type="bibr">science-fair.org, 2014</xref>).</p>
      <p>We have delivered image processing tutorials using scikit-image at various annual scientific Python conferences, such as PyData 2012, SciPy India 2012, and EuroSciPy 2013. Course materials for some of these sessions are found in <xref rid="ref-13" ref-type="bibr">Haenel, Gouillart &amp; Varoquaux (2014)</xref> and are licensed under the permissive CC-BY license (<xref rid="ref-10" ref-type="bibr">Creative Commons, 2013</xref>). These typically include an introduction to the package and provide intuitive, hands-on introductions to image processing concepts. The well documented application programming interface (API) along with tools that facilitate visualization contribute to the learning experience, and make it easy to investigate the effect of different algorithms and parameters. For example, when investigating denoising, it is easy to observe the difference between applying a median filter (<monospace>filter.rank.median</monospace>) and a Gaussian filter (<monospace>filter.gaussian_filter</monospace>), demonstrating that a median filter preserves straight lines much better.</p>
      <p>Finally, easy access to readable source code gives users an opportunity to learn how algorithms are implemented and gives further insight into some of the intricacies of a fast Python implementation, such as indexing tricks and look-up tables.</p>
    </sec>
    <sec>
      <title>Industry</title>
      <p>Due to the breadth and maturity of its code base, as well as the its commercial-friendly license, scikit-image is well suited for industrial applications.</p>
      <p>BT Imaging (<uri xlink:href="http://www.btimaging.com">http://www.btimaging.com</uri>) designs and builds tools that use photoluminescence (PL) imaging for photovoltaic applications. PL imaging can characterize the quality of multicrystalline silicon wafers by illuminating defects that are not visible under standard viewing conditions. <xref ref-type="fig" rid="fig-4">Figure 4A</xref> shows an optical image of a silicon wafer, and <xref ref-type="fig" rid="fig-4">Fig. 4B</xref> shows the same wafer using PL imaging. In <xref ref-type="fig" rid="fig-4">Fig. 4C</xref>, the wafer defects and impurities have been detected through automated image analysis. scikit-image plays a key role in the image processing pipeline. For example, a Hough transform (<monospace>transform.hough_line</monospace>) finds the wafer edges in order to segment the wafer from the background. scikit-image is also used for feature extraction. Crystal defects (dislocations) are detected using a band-pass filter, which is implemented as a Difference of Gaussians (<monospace>filter.gaussian_filter</monospace>).</p>
      <p>The image processing results are input to machine learning algorithms, which assess intrinsic wafer quality. Solar cell manufacturers can use this information to reject poor quality wafers and thereby increase the fraction of solar cells that have high solar conversion efficiency.</p>
      <fig id="fig-4" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.453/fig-4</object-id>
        <label>Figure 4</label>
        <caption>
          <title>Use of scikit-image to study silicon wafer impurities.</title>
          <p>(A) An image of an as-cut silicon wafer before it has been processed into a solar cell. (B) A PL image of the same wafer. Wafer defects, which have a negative impact solar cell efficiency, are visible as dark regions. (C) Image processing results. Defects in the crystal growth (dislocations) are colored blue, while red indicates the presence of impurities.</p>
        </caption>
        <graphic xlink:href="peerj-02-453-g004"/>
      </fig>
      <p>scikit-image is also applied in a commercial setting for biometric security applications. AICBT Ltd uses multispectral imaging to detect when a person attempts to conceal their identity using a facial mask.<xref ref-type="fn" rid="peerj-453-fn17"><sup>17</sup></xref><fn id="peerj-453-fn17"><label>17</label><p><uri xlink:href="http://www.aicbt.com/disguise-detection">http://www.aicbt.com/disguise-detection</uri> (accessed 30 March 2014).</p></fn> scikit-image performs file I/O (<monospace>io.imread</monospace>), histogram equalization (<monospace>exposure.equalize_hist</monospace>), and aligns a visible wavelength image with a thermal image (<monospace>transform.AffineTransform</monospace>). The system determines the surface temperature of a subject’s skin and detects situations where the face is being obscured.</p>
    </sec>
  </sec>
  <sec>
    <title>Example: image registration and stitching</title>
    <p>This section gives a step-by-step outline of how to perform panorama stitching using the primitives found in scikit-image. The full source code is at <uri xlink:href="https://github.com/scikit-image/scikit-image-demos">https://github.com/scikit-image/scikit-image-demos</uri>.</p>
    <sec>
      <title>Data loading</title>
      <p>The “ImageCollection” class provides an easy way of representing multiple images on disk. For efficiency, images are not read until accessed.</p>
      <preformat>from skimage import io
ic = io.ImageCollection('data/*')</preformat>
      <p><xref ref-type="fig" rid="fig-5">Figure 5A</xref> shows the Petra dataset, which displays the same facade from two different angles. For this demonstration, we will estimate a projective transformation that relates the two images. Since the outer parts of these photographs do not conform well to such a model, we select only the central parts. To further speed up the demonstration, images are downscaled to 25% of their original size.</p>
      <fig id="fig-5" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.453/fig-5</object-id>
        <label>Figure 5</label>
        <caption>
          <title>An example application of scikit-image: image registration and warping to combine overlapping images.</title>
          <p>(A) Photographs taken in Petra, Jordan by François Malan. License: CC-BY. (B) Putative matches computed from ORB binary features. (C) Matches filtered using RANSAC. (D) The second input frame (middle) is warped to align with the first input frame (left), yielding the averaged image shown on the right. (E) The final panorama image, registered and warped using scikit-image, blended with Enblend.</p>
        </caption>
        <graphic xlink:href="peerj-02-453-g005"/>
      </fig>
      <preformat>from skimage.color import rgb2gray
from skimage import transform

image0 = rgb2gray(ic[0][:, 500:500+1987, :])
image1 = rgb2gray(ic[1][:, 500:500+1987, :])

image0 = transform.rescale(image0, 0.25)
image1 = transform.rescale(image1, 0.25)</preformat>
    </sec>
    <sec>
      <title>Feature detection and matching</title>
      <p>“Oriented FAST and rotated BRIEF” (ORB) features (<xref rid="ref-23" ref-type="bibr">Rublee et al., 2011</xref>) are detected in both images. Each feature yields a binary descriptor; those are used to find the putative matches shown in <xref ref-type="fig" rid="fig-5">Fig. 5B</xref>.</p>
      <preformat>from skimage.feature import ORB, match_descriptors

orb = ORB(n_keypoints=1000, fast_threshold=0.05)

orb.detect_and_extract(image0)
keypoints1 = orb.keypoints
descriptors1 = orb.descriptors

orb.detect_and_extract(image1)
keypoints2 = orb.keypoints
descriptors2 = orb.descriptors

matches12 = match_descriptors(descriptors1,
                              descriptors2,
                              cross_check=True)</preformat>
    </sec>
    <sec>
      <title>Transform estimation</title>
      <p>To filter the matches, we apply RANdom SAmple Consensus (RANSAC) (<xref rid="ref-12" ref-type="bibr">Fischler &amp; Bolles, 1981</xref>), a common method for outlier rejection. This iterative process estimates transformation models based on randomly chosen subsets of matches, finally selecting the model which corresponds best with the majority of matches. The new matches are shown in <xref ref-type="fig" rid="fig-5">Fig. 5C</xref>.</p>
      <preformat>from skimage.measure import ransac

# Select keypoints from the source (image to be
# registered) and target (reference image).

src = keypoints2[matches12[:, 1]][:, ::-1]
dst = keypoints1[matches12[:, 0]][:, ::-1]

model_robust, inliers = \
    ransac((src, dst), ProjectiveTransform,
           min_samples=4, residual_threshold=2)</preformat>
    </sec>
    <sec>
      <title>Warping</title>
      <p>Next, we produce the panorama itself. The first step is to find the shape of the output image by considering the extents of all warped images.</p>
      <preformat>r, c = image1.shape[:2]

# Note that transformations take coordinates in
# (x, y) format, not (row, column), in order to be
# consistent with most literature.
corners = np.array([[0, 0],
                    [0, r],
                    [c, 0],
                    [c, r]])

# Warp the image corners to their new positions.
warped_corners = model_robust(corners)

# Find the extents of both the reference image and
# the warped target image.
all_corners = np.vstack((warped_corners, corners))

corner_min = np.min(all_corners, axis=0)
corner_max = np.max(all_corners, axis=0)

output_shape = (corner_max - corner_min)
output_shape = np.ceil(output_shape[::-1])</preformat>
      <p>The images are now warped according to the estimated transformation model. Values outside the input images are set to −1 to distinguish the “background”.</p>
      <p>A shift is added to ensure that both images are visible in their entirety. Note that <monospace>warp</monospace> takes the <italic>inverse</italic> mapping as input.</p>
      <preformat>from skimage.color import gray2rgb
from skimage.exposure import rescale_intensity
from skimage.transform import warp
from skimage.transform import SimilarityTransform

offset = SimilarityTransform(translation=-corner_min)

image0_ = warp(image0, offset.inverse,
               output_shape=output_shape, cval=-1)

image1_ = warp(image1, (model_robust + offset).inverse,
               output_shape=output_shape, cval=-1)</preformat>
      <p>An alpha channel is added to the warped images before merging them into a single image:</p>
      <preformat>def add_alpha(image, background=-1):
    """Add an alpha layer to the image.

    The alpha layer is set to 1 for foreground
    and 0 for background.
    """
    rgb = gray2rgb(image)
    alpha = (image != background)
    return np.dstack((rgb, alpha))

image0_alpha = add_alpha(image0_)
image1_alpha = add_alpha(image1_)

merged = (image0_alpha + image1_alpha)
alpha = merged[..., 3]

# The summed alpha layers give us an indication of
# how many images were combined to make up each
# pixel.  Divide by the number of images to get
# an average.
merged /= np.maximum(alpha, 1)[..., np.newaxis]</preformat>
      <p>The merged image is shown in <xref ref-type="fig" rid="fig-5">Fig. 5D</xref>. Note that, while the columns are well aligned, the color intensities at the boundaries are not well matched.</p>
    </sec>
    <sec>
      <title>Blending</title>
      <p>To blend images smoothly we make use of the open source package Enblend (<xref rid="ref-11" ref-type="bibr">Dersch, 2010</xref>), which in turn employs multi-resolution splines and Laplacian pyramids (<xref rid="ref-5" ref-type="bibr">Burt &amp; Adelson, 1983a</xref>; <xref rid="ref-6" ref-type="bibr">Burt &amp; Adelson, 1983b</xref>). The final panorama is shown in <xref ref-type="fig" rid="fig-5">Fig. 5E</xref>.</p>
    </sec>
  </sec>
  <sec sec-type="discussion">
    <title>Discussion</title>
    <sec>
      <title>Related work</title>
      <p>In this section, we describe other libraries with similar goals to ours.</p>
      <p>Within the scientific Python ecosystem, <bold>Mahotas</bold> contains many similar functions, and is furthermore also designed to work with NumPy arrays (<xref rid="ref-8" ref-type="bibr">Coelho, 2013</xref>). The major philosophical difference between Mahotas and scikit-image is that Mahotas is almost exclusively written in templated C++, while scikit-image is written in Python and Cython. We feel that our choice lowers the barrier of entry for new contributors. However, thanks to the interoperability between the two provided by the NumPy array data format, users don’t have to choose between them, and can simply use the best components of each.</p>
      <p>ImageJ and its batteries-included <bold>Fiji</bold> distribution are probably the most popular open-source tools for image analysis (<xref rid="ref-25" ref-type="bibr">Schneider, Rasband &amp; Eliceiri, 2012</xref>; <xref rid="ref-24" ref-type="bibr">Schindelin et al., 2012</xref>). Although Fiji’s breadth of functionality is unparalleled, it is centered around interactive, GUI use. For many developers, then, scikit-image offers several advantages. Although Fiji offers a programmable macro mode that supports many scripting languages, many of the macro functions activate GUI elements and cannot run in headless mode. This is problematic for data analysis in high-performance computing cluster environments or web backends, for example. Additionally, Fiji’s inclusive plugin policy results in an inconsistent API and variable documentation quality. Using scikit-image to develop new functionality or to build batch applications for distributed computing is often much simpler, thanks to its consistent API and the wide distribution of the scientific Python stack.</p>
      <p>In many respects, the <bold>image processing toolbox</bold> of the Matlab environment is quite similar to scikit-image. For example, its API is mostly functional and applies to generic multidimensional numeric arrays. However, Matlab’s commercial licensing can be a significant nuisance to users. Additionally, the licensing cost increases dramatically for parallel computing, with per-worker pricing.<xref ref-type="fn" rid="peerj-453-fn18"><sup>18</sup></xref><fn id="peerj-453-fn18"><label>18</label><p><uri xlink:href="http://www.mathworks.com.au/products/distriben/description3.html">http://www.mathworks.com.au/products/distriben/description3.html</uri> (accessed 9 May 2014).</p></fn> Finally, the closed source nature of the toolbox prevents users from learning from the code or modifying it for specific purposes, which is a common necessity in scientific research. We refer readers back to the Development Practices section for a summary of the practical and philosophical advantages of our open-source licensing.</p>
      <p><bold>OpenCV</bold> is a BSD-licensed open-source library focused on computer vision, with a separate module for image processing (<xref rid="ref-3" ref-type="bibr">Bradski, 2000</xref>). It is developed in C/C++ and the project’s main aim is to provide implementations for real-time applications. This results in fast implementations with a comparatively high barrier of entry for code study and modification. The library provides interfaces for several high-level programming languages, including Python through the NumPy-array data-type for images. The Python interface is essentially a one-to-one copy of the underlying C/C++ API, and thus image processing pipelines have to follow an imperative programming style. In contrast, scikit-image provides a Pythonic interface with the option to follow an imperative or functional approach. Beyond that, OpenCV’s image processing module is traditionally limited to 2-dimensional imagery.</p>
      <p>The choice of image processing package depends on several factors, including speed, code quality and correctness, community support, ecosystem, feature richness, and users’ ability to contribute. Sometimes, advantages in one factor come at the cost of another. For example, our approach of writing code in a high-level language may affect performance, or our strict code review guidelines may hamper the number of features we ultimately provide. We motivate our design decisions for scikit-image in the Development Practices section, and leave readers to decide which library is right for them.</p>
    </sec>
    <sec>
      <title>Roadmap</title>
      <p>In many open source projects, decisions about future development are made through “rough consensus and working code” (<xref rid="ref-15" ref-type="bibr">Hoffman, 2014</xref>). In scikit-image there are two ways to propose new ideas: through discussion on the mailing list, or as pull requests. The latter route has the advantage of a concrete implementation to guide the conversation, and often mailing list discussions also result in a request for a proof of concept implementation. While conversations are usually led by active developers, the entire community is invited to participate. Once general agreement is reached that the proposed idea aligns with the current project goals and is feasible, work is divided on a volunteer basis. As such, the schedule for completion is often flexible.</p>
      <p>The following goals have been identified for the next release of scikit-image:</p>
      <list list-type="simple" id="list-3">
        <list-item>
          <label>•</label>
          <p>Obtain full test coverage.</p>
        </list-item>
        <list-item>
          <label>•</label>
          <p>Overhaul the functions for image reading/writing.</p>
        </list-item>
        <list-item>
          <label>•</label>
          <p>Improve the project infrastructure, e.g., create an interactive gallery of examples.</p>
        </list-item>
        <list-item>
          <label>•</label>
          <p>Add support for graph-based operations.</p>
        </list-item>
        <list-item>
          <label>•</label>
          <p>Significantly extend higher dimensional (multi-layer) support.</p>
        </list-item>
      </list>
      <p>We also invite readers to submit their own feature requests to the mailing list for further discussion.</p>
    </sec>
  </sec>
  <sec>
    <title>Conclusion</title>
    <p>scikit-image provides easy access to a powerful array of image processing functionality. Over the past few years, it has seen significant growth in both adoption and contribution,<xref ref-type="fn" rid="peerj-453-fn19"><sup>19</sup></xref><fn id="peerj-453-fn19"><label>19</label><p><uri xlink:href="https://www.ohloh.net/p/scikit-image">https://www.ohloh.net/p/scikit-image</uri> (accessed 15 May 2014).</p></fn> and the team is excited to collaborate with others to see it grow even further, and to establish it the de facto library for image processing in Python.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We thank Timo Friedrich and Jan Kaslin for providing the zebrafish lesion data. We also acknowledge the efforts of the more than 100 contributors to the scikit-image code base: <uri xlink:href="https://github.com/scikit-image/scikit-image/graphs/contributors">https://github.com/scikit-image/scikit-image/graphs/contributors</uri>.</p>
  </ack>
  <sec sec-type="additional-information">
    <title>Additional Information and Declarations</title>
    <fn-group content-type="competing-interests">
      <title>Competing Interests</title>
      <fn id="conflict-1" fn-type="con">
        <p>Neil Yager is an employee of AICBT Ltd; Tony Yu is an employee of Enthought, Inc.</p>
      </fn>
    </fn-group>
    <fn-group content-type="author-contributions">
      <title>Author Contributions</title>
      <fn id="contribution-1" fn-type="con">
        <p><xref ref-type="contrib" rid="author-1">Stéfan van der Walt</xref>, <xref ref-type="contrib" rid="author-2">Johannes L. Schönberger</xref>, <xref ref-type="contrib" rid="author-3">Juan Nunez-Iglesias</xref>, <xref ref-type="contrib" rid="author-4">François Boulogne</xref> and <xref ref-type="contrib" rid="author-6">Neil Yager</xref> conceived and designed the experiments, performed the experiments, wrote the paper, prepared figures and/or tables, reviewed drafts of the paper, wrote software.</p>
      </fn>
      <fn id="contribution-2" fn-type="con">
        <p><xref ref-type="contrib" rid="author-5">Joshua D. Warner</xref>, <xref ref-type="contrib" rid="author-7">Emmanuelle Gouillart</xref> and <xref ref-type="contrib" rid="author-8">Tony Yu</xref> conceived and designed the experiments, performed the experiments, wrote the paper, reviewed drafts of the paper, wrote software.</p>
      </fn>
    </fn-group>
  </sec>
  <ref-list content-type="authoryear">
    <title>References</title>
    <ref id="ref-1">
      <label>Behnel et al. (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Behnel</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Bradshaw</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Citro</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Dalcin</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Seljebotn</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Cython: the best of both worlds</article-title>
        <source>Computing in Science and Engineering</source>
        <issue>2</issue>
        <year>2011</year>
        <volume>13</volume>
        <fpage>31</fpage>
        <lpage>39</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2010.118</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-2">
      <label>Bhatt et al. (2004)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bhatt</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Otto</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Depoister</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Fetcho</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>Cyclic amp-induced repair of zebrafish spinal circuits</article-title>
        <source>Science</source>
        <year>2004</year>
        <volume>305</volume>
        <fpage>254</fpage>
        <lpage>258</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1098439</pub-id>
        <pub-id pub-id-type="pmid">15247482</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-3">
      <label>Bradski (2000)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bradski</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The OpenCV library</article-title>
        <source>Dr. Dobb’s Journal of Software Tools</source>
        <issue>11</issue>
        <year>2000</year>
        <volume>25</volume>
        <fpage>120</fpage>
        <lpage>126</lpage>
      </element-citation>
    </ref>
    <ref id="ref-4">
      <label>Brandl (2007)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Brandl</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <year>2007</year>
        <comment>Sphinx Python documentation generator. <italic>Available at <uri xlink:href="http://sphinx-doc.org/">http://sphinx-doc.org/</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-5">
      <label>Burt &amp; Adelson (1983a)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burt</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Adelson</surname>
            <given-names>EH</given-names>
          </name>
        </person-group>
        <article-title>The Laplacian pyramid as a compact image code</article-title>
        <source>IEEE Transactions on Communications</source>
        <issue>4</issue>
        <year>1983a</year>
        <volume>31</volume>
        <fpage>532</fpage>
        <lpage>540</lpage>
        <pub-id pub-id-type="doi">10.1109/TCOM.1983.1095851</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-6">
      <label>Burt &amp; Adelson (1983b)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burt</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Adelson</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>A multiresolution spline with application to image mosaics</article-title>
        <source>ACM Transactions on Graphics</source>
        <issue>4</issue>
        <year>1983b</year>
        <volume>2</volume>
        <fpage>217</fpage>
        <lpage>236</lpage>
        <pub-id pub-id-type="doi">10.1145/245.247</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-7">
      <label>Canny (1986)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Canny</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>A computational approach to edge detection</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>1986</year>
        <volume>8</volume>
        <fpage>679</fpage>
        <lpage>714</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.1986.4767851</pub-id>
        <pub-id pub-id-type="pmid">21869365</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-8">
      <label>Coelho (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Coelho</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Mahotas: open source software for scriptable computer vision</article-title>
        <source>Journal of Open Research Software</source>
        <issue>1</issue>
        <year>2013</year>
        <volume>1</volume>
        <pub-id pub-id-type="doi">10.5334/jors.ac</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-9">
      <label>Cordasco (2010)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Cordasco</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <year>2010</year>
        <comment>Flake8. <italic>Available at <uri xlink:href="https://pypi.python.org/pypi/flake8">https://pypi.python.org/pypi/flake8</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-10">
      <label>Creative Commons (2013)</label>
      <element-citation publication-type="other">
        <person-group>
          <collab>
            <institution>Creative Commons</institution>
          </collab>
        </person-group>
        <year>2013</year>
        <comment>CC-BY license. <italic>Available at <uri xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-11">
      <label>Dersch (2010)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Dersch</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <year>2010</year>
        <comment>Enblend 4.0 documentation. <italic>Available at <uri xlink:href="http://enblend.sourceforge.net/enblend.doc/enblend_4.1.pdf">http://enblend.sourceforge.net/enblend.doc/enblend_4.1.pdf</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-12">
      <label>Fischler &amp; Bolles (1981)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fischler</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bolles</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</article-title>
        <source>Communications of the ACM</source>
        <issue>6</issue>
        <year>1981</year>
        <volume>24</volume>
        <fpage>381</fpage>
        <lpage>395</lpage>
        <pub-id pub-id-type="doi">10.1145/358669.358692</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-13">
      <label>Haenel, Gouillart &amp; Varoquaux (2014)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Haenel</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Gouillart</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
          <collab>
            <institution>scipy-lecture-notes contributors</institution>
          </collab>
        </person-group>
        <year>2014</year>
        <comment>Scipy lecture notes. <italic>Available at <uri xlink:href="http://scipy-lectures.github.io/">http://scipy-lectures.github.io/</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-14">
      <label>Halchenko &amp; Hanke (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Halchenko</surname>
            <given-names>YO</given-names>
          </name>
          <name>
            <surname>Hanke</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Open is not enough. Let’s take the next step: an integrated, community-driven computing platform for neuroscience</article-title>
        <source>Frontiers in Neuroinformatics</source>
        <issue>22</issue>
        <year>2012</year>
        <volume>6</volume>
        <pub-id pub-id-type="doi">10.3389/fninf.2012.00022</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-15">
      <label>Hoffman (2014)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="editor">
          <name>
            <surname>Hoffman</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <source>The tao of IETF: a novice’s guide to the internet engineering task force</source>
        <year>2014</year>
        <comment><italic>Available at <uri xlink:href="http://www.ietf.org/tao.html">http://www.ietf.org/tao.html</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-16">
      <label>Hunter (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hunter</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Matplotlib: A 2D Graphics Environment</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <issue>3</issue>
        <year>2007</year>
        <volume>9</volume>
        <fpage>90</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-17">
      <label>Jones, Oliphant &amp; Peterson (2001)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Jones</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Oliphant</surname>
            <given-names>TE</given-names>
          </name>
          <name>
            <surname>Peterson</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <year>2001</year>
        <comment>SciPy: open source scientific tools for Python. <italic>Available at <uri xlink:href="http://scipy.org">http://scipy.org</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-18">
      <label>Microsoft (1995)</label>
      <element-citation publication-type="other">
        <person-group>
          <collab>
            <institution>Microsoft</institution>
          </collab>
        </person-group>
        <year>1995</year>
        <comment>DirectX data conversion rules. <italic>Available at <uri xlink:href="http://msdn.microsoft.com/en-us/library/windows/desktop/dd607323">http://msdn.microsoft.com/en-us/library/windows/desktop/dd607323</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-19">
      <label>Munshi &amp; Leech (2010)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Munshi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Leech</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <year>2010</year>
        <comment>OpenGL ES common profile specification, version 2.0.25 (full specification). <italic>Available at <uri xlink:href="https://www.khronos.org/registry/gles/specs/2.0/es_full_spec_2.0.25.pdf">https://www.khronos.org/registry/gles/specs/2.0/es_full_spec_2.0.25.pdf</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-20">
      <label>Oliphant (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oliphant</surname>
            <given-names>TE</given-names>
          </name>
        </person-group>
        <article-title>Python for scientific computing</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <issue>3</issue>
        <year>2007</year>
        <volume>9</volume>
        <fpage>10</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2007.58</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-21">
      <label>Paeth (1990)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Paeth</surname>
            <given-names>AW</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Glassner</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Proper treatment of pixels as integers</article-title>
        <source>Graphics gems</source>
        <year>1990</year>
        <publisher-loc>Boston</publisher-loc>
        <publisher-name>AP Professional</publisher-name>
        <fpage>254</fpage>
        <lpage>256</lpage>
      </element-citation>
    </ref>
    <ref id="ref-22">
      <label>Pedregosa et al. (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Thirion</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Grisel</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Blondel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Prettenhofer</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Dubourg</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Vanderplas</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Passos</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cournapeau</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Brucher</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Perrot</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Duchesnay</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Scikit-learn: Machine Learning in Python</article-title>
        <source>Journal of Machine Learning Research</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="ref-23">
      <label>Rublee et al. (2011)</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Rublee</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Rabaud</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Konolige</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Bradski</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>ORB: an efficient alternative to SIFT or SURF</article-title>
        <conf-name>Proceedings of the 2011 international conference on computer vision (ICCV)</conf-name>
        <year>2011</year>
        <fpage>2564</fpage>
        <lpage>2571</lpage>
      </element-citation>
    </ref>
    <ref id="ref-24">
      <label>Schindelin et al. (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schindelin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Arganda-Carreras</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Frise</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Kaynig</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Longair</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pietzsch</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Preibisch</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rueden</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Saalfeld</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmid</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Tinevez</surname>
            <given-names>J-Y</given-names>
          </name>
          <name>
            <surname>White</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Hartenstein</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Eliceiri</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tomancak</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Cardona</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Fiji: an open-source platform for biological-image analysis</article-title>
        <source>Nature Methods</source>
        <issue>7</issue>
        <year>2012</year>
        <volume>9</volume>
        <fpage>676</fpage>
        <lpage>682</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id>
        <pub-id pub-id-type="pmid">22743772</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-25">
      <label>Schneider, Rasband &amp; Eliceiri (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schneider</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Rasband</surname>
            <given-names>WS</given-names>
          </name>
          <name>
            <surname>Eliceiri</surname>
            <given-names>KW</given-names>
          </name>
        </person-group>
        <article-title>NIH image to ImageJ: 25 years of image analysis</article-title>
        <source>Nature Methods</source>
        <issue>7</issue>
        <year>2012</year>
        <volume>9</volume>
        <fpage>671</fpage>
        <lpage>675</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2089</pub-id>
        <pub-id pub-id-type="pmid">22930834</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-26">
      <label>science-fair.org (2014)</label>
      <element-citation publication-type="other">
        <person-group>
          <collab>
            <institution>science-fair.org</institution>
          </collab>
        </person-group>
        <year>2014</year>
        <comment>Privately sponsored project, project awards 2014. Synopsis Silicon Valley Science and Technology Championship. <italic>Available at <uri xlink:href="http://science-fair.org/database/project_awards.php?schoolname=Privately+Sponsored+Project&amp;school_year=2014">http://science-fair.org/database/project_awards.php?schoolname=Privately+Sponsored+Project&amp;school_year=2014</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-27">
      <label>Thuret, Moon &amp; Gage (2006)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thuret</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Moon</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gage</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Therapeutic interventions after spinal cord injury</article-title>
        <source>Nature Reviews Neuroscience</source>
        <year>2006</year>
        <volume>7</volume>
        <fpage>628</fpage>
        <lpage>643</lpage>
        <pub-id pub-id-type="doi">10.1038/nrn1955</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-28">
      <label>Van der Walt, Colbert &amp; Varoquaux (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van der Walt</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Colbert</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The NumPy array: a structure for efficient numerical computation</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <issue>2</issue>
        <year>2011</year>
        <volume>13</volume>
        <fpage>22</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-29">
      <label>Van der Walt &amp; NumPy developers (2008)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Van der Walt</surname>
            <given-names>S</given-names>
          </name>
          <collab>
            <institution>NumPy developers</institution>
          </collab>
        </person-group>
        <year>2008</year>
        <comment>A guide to NumPy/SciPy documentation. <italic>Available at <uri xlink:href="https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt">https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-30">
      <label>Van Rossum, Warsaw &amp; Coghlan (2001)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Van Rossum</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Warsaw</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Coghlan</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <year>2001</year>
        <comment>PEP 8: style guide for Python code.<italic>Available at <uri xlink:href="http://www.python.org/dev/peps/pep-0008/">http://www.python.org/dev/peps/pep-0008/</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
    <ref id="ref-31">
      <label>Wilson (2012)</label>
      <element-citation publication-type="other">
        <person-group>
          <name>
            <surname>Wilson</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <year>2012</year>
        <comment>The modified BSD license—an overview. <italic>Available at <uri xlink:href="http://oss-watch.ac.uk/resources/modbsd">http://oss-watch.ac.uk/resources/modbsd</uri></italic> (accessed 30 March 2014)</comment>
      </element-citation>
    </ref>
  </ref-list>
</back>
