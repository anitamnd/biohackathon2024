<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">NAR Genom Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">NAR Genom Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">nargab</journal-id>
    <journal-title-group>
      <journal-title>NAR Genomics and Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2631-9268</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7671387</article-id>
    <article-id pub-id-type="doi">10.1093/nargab/lqaa009</article-id>
    <article-id pub-id-type="publisher-id">lqaa009</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Standard Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepMicrobes: taxonomic classification for metagenomics with deep learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-2876-3013</contrib-id>
        <name>
          <surname>Liang</surname>
          <given-names>Qiaoxing</given-names>
        </name>
        <xref ref-type="aff" rid="AFF1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9969-4492</contrib-id>
        <name>
          <surname>Bible</surname>
          <given-names>Paul W</given-names>
        </name>
        <xref ref-type="aff" rid="AFF1">1</xref>
        <xref ref-type="aff" rid="AFF2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Yu</given-names>
        </name>
        <xref ref-type="aff" rid="AFF1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9243-9923</contrib-id>
        <name>
          <surname>Zou</surname>
          <given-names>Bin</given-names>
        </name>
        <xref ref-type="aff" rid="AFF1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wei</surname>
          <given-names>Lai</given-names>
        </name>
        <!--<email>weil9@mail.sysu.edu.cn</email>-->
        <xref ref-type="aff" rid="AFF1">1</xref>
        <xref ref-type="corresp" rid="COR1"/>
      </contrib>
    </contrib-group>
    <aff id="AFF1"><label>1</label><institution>State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University</institution>, Guangzhou 510060, <country country="CN">China</country></aff>
    <aff id="AFF2"><label>2</label><institution>College of Arts and Sciences, Marian University</institution>, Indianapolis, IN 46222, <country country="US">USA</country></aff>
    <author-notes>
      <corresp id="COR1">To whom correspondence should be addressed. Tel: +86 20 66677302; Fax: +86 20 87335446; Email: <email>weil9@mail.sysu.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-02-19">
      <day>19</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>2</volume>
    <issue>1</issue>
    <elocation-id>lqaa009</elocation-id>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>7</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>05</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>04</day>
        <month>2</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press on behalf of NAR Genomics and Bioinformatics.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact <email>journals.permissions@oup.com</email></license-p>
      </license>
    </permissions>
    <self-uri xlink:href="lqaa009.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>Large-scale metagenomic assemblies have uncovered thousands of new species greatly expanding the known diversity of microbiomes in specific habitats. To investigate the roles of these uncultured species in human health or the environment, researchers need to incorporate their genome assemblies into a reference database for taxonomic classification. However, this procedure is hindered by the lack of a well-curated taxonomic tree for newly discovered species, which is required by current metagenomics tools. Here we report DeepMicrobes, a deep learning-based computational framework for taxonomic classification that allows researchers to bypass this limitation. We show the advantage of DeepMicrobes over state-of-the-art tools in species and genus identification and comparable accuracy in abundance estimation. We trained DeepMicrobes on genomes reconstructed from gut microbiomes and discovered potential novel signatures in inflammatory bowel diseases. DeepMicrobes facilitates effective investigations into the uncharacterized roles of metagenomic species.</p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Basic Research Program of China</named-content>
          <named-content content-type="funder-identifier">10.13039/501100012166</named-content>
        </funding-source>
        <award-id>2015CB964601</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">National Natural Science Foundation of China</named-content>
          <named-content content-type="funder-identifier">10.13039/501100001809</named-content>
        </funding-source>
        <award-id>81570828</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="13"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="SEC1">
    <title>INTRODUCTION</title>
    <p>Shotgun metagenomic sequencing provides unprecedented insight into the critical functional roles of microorganisms in human health and the environment (<xref rid="B1" ref-type="bibr">1</xref>). One of the fundamental analysis steps in metagenomic data interpretation is to assign individual reads to their taxon-of-origin, which is termed taxonomic classification. Many of the large-scale metagenomic assembly efforts have reconstructed thousands of uncultivated novel species from metagenome samples (<xref rid="B2" ref-type="bibr">2–4</xref>), which hugely expands the known diversity of microbiomes in specific habitats like the human gut. Developing methods for investigating the role of these novel uncultured organisms in the health state of their hosts remains an important and unsolved challenge in microbiome research.</p>
    <p>Incorporating these metagenomic species (MGS) into reference databases for use with current metagenomics tools for taxonomic classification proves difficult and time consuming. Metagenome-assembled genomes (MAGs) are typically highly fragmented compared to genomes obtained using whole genome sequencing from cultures. This fragmentation degrades the effectiveness of traditional alignment tools. Tools using rare or unique short sequences (<italic>k</italic>-mers) for classification also suffer performance losses with the presence of unknown microbes. Kraken (<xref rid="B5" ref-type="bibr">5</xref>), for example, builds a lowest common ancestor (LCA) database to store <italic>k</italic>-mer information of each organism. Unfortunately, this process relies on a well-curated taxonomic tree retrieved from the taxonomy database maintained by National Center for Biotechnology Information (NCBI). Many of the newly discovered MGS do not have representative taxon nodes in the database.</p>
    <p>Machine learning techniques provide a possible solution to bypass the curation of a taxonomic tree. Previous machine learning algorithms for taxonomic classification mainly utilize handcrafted sequence composition features such as oligonucleotide frequency (<xref rid="B6" ref-type="bibr">6</xref>,<xref rid="B7" ref-type="bibr">7</xref>). These approaches either underperform alignment methods in terms of precision and recall or require prohibitive running times when processing large datasets (<xref rid="B8" ref-type="bibr">8</xref>). Deep learning is a class of machine learning algorithms capable of modeling complex dependencies between input data (e.g. genomic fragments) and target output variables (e.g. species-of-origin) in an end-to-end fashion (<xref rid="B9" ref-type="bibr">9</xref>). In addition, the fragmentation of reference genomes become a negligible problem since genomes are cut to the length of sequencing reads for training.</p>
    <p>Here we describe DeepMicrobes, a deep learning-based computational framework for taxonomic classification of short metagenomics sequencing reads. To illustrate its application in MGS investigation, we trained DeepMicrobes on the previously defined complete bacterial repertoire of the human gut microbiota (<xref rid="B2" ref-type="bibr">2</xref>). The repertoire is composed of 2505 species, most of which are identified by metagenome assembly of human gut microbiomes. The general usage outline of DeepMicrobes is presented in Figure <xref ref-type="fig" rid="F1">1A</xref>. We show that DeepMicrobes surpasses state-of-the-art taxonomic classification tools in genus or species identification and performs at least comparably in abundance estimation on the gut-derived data. We reanalyzed a gut microbiome dataset from the Integrative Human Microbiome Project (iHMP) (<xref rid="B10" ref-type="bibr">10</xref>) using DeepMicrobes and discovered potential uncultured species signatures in inflammatory bowel diseases.</p>
    <fig id="F1" orientation="portrait" position="float">
      <label>Figure 1.</label>
      <caption>
        <p>Overview of DeepMicrobes. (<bold>A</bold>) DeepMicrobes facilitates taxonomic classification for cohorts of interest using newly discovered species in large-scale metagenomic assembly studies. (<bold>B</bold>) The deep neural network architecture of DeepMicrobes. (<bold>C</bold>–<bold>E</bold>) The algorithm details of <italic>k</italic>-mer embedding, bidirectional LSTM and the self-attention mechanism, respectively. LSTM, long short-term memory.</p>
      </caption>
      <graphic xlink:href="lqaa009fig1"/>
    </fig>
  </sec>
  <sec sec-type="materials|methods" id="SEC2">
    <title>MATERIALS AND METHODS</title>
    <sec id="SEC2-1">
      <title>Data for model training</title>
      <p>We downloaded 2505 representative genomes of human gut species identified previously by a large-scaled assembling study of human gut microbiomes, as well as the taxonomy assigned to them above the species level, from <ext-link ext-link-type="ftp" xlink:href="ftp://ftp.ebi.ac.uk/pub/databases/metagenomics/umgs_analyses">ftp://ftp.ebi.ac.uk/pub/databases/metagenomics/umgs_analyses</ext-link>. This species collection is composed of 1952 unclassified metagenomic species (UMGS) and 553 gut species from the human-specific reference (HR) database, hereafter referred to as HGR (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>).</p>
      <p>We trained separate models for species and genus classification. The genomes were excluded from training the genus model if they were not assigned at the genus level. For each classification category, namely species or genus, we simulated equal proportion of 150 bp reads with the ART Illumina read simulator (<xref rid="B11" ref-type="bibr">11</xref>) using HiSeq 2500 error model (HS25), paired-end reads with insert size of 400 and standard deviation of 50 bp. The ART simulator automatically sampled reads from forward and reverse complement genome strands. A pair of reads were treated as two single-end reads during training. Reads of all the categories were shuffled before training. The number of reads to simulate depended on how many training steps were required for models to converge. After simulation, we randomly trimmed the reads from 3′ end to 75–150 bp in equal probability. Each read was given a numerical label according to the species or genus that it was simulated from. Reads along with their labels were converted to the TensorFlow format TFRecord, a binary format that facilitates reading input instances into the learning model.</p>
      <p>We created evaluation sets for the species and genus models using the methods described above, except that we ran ART and trimming using a random seed different from the one used to generate the training sets and ran the models using paired-end mode. The evaluation sets were used to search for optimal hyperparameters and decide when to stop training. They were not seen during training to protect against overfitting the models.</p>
    </sec>
    <sec id="SEC2-2">
      <title>Benchmark datasets</title>
      <sec id="SEC2-2-1">
        <title>Simulation of reads from gut-derived MAGs</title>
        <p>We downloaded 3269 high-quality MAGs reconstructed from human gut microbiomes using the ENA study accession ERP108418 (<xref rid="B2" ref-type="bibr">2</xref>) (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>). We used the following criteria to select high-quality MAGs for benchmark: &gt;90% completeness, 0% contamination and 0% strain heterogeneity, which were determined with CheckM (<xref rid="B12" ref-type="bibr">12</xref>). The genomes used to generate the training set had been excluded. We used the MAGs assignment method described previously (<xref rid="B2" ref-type="bibr">2</xref>) to assign species label to the MAGs using the scripts available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Finn-Lab/MGS-gut">https://github.com/Finn-Lab/MGS-gut</ext-link>. Briefly, the MAGs and training genomes were first converted into a MinHash sketch with default <italic>k</italic>-mer and sketch sizes respectively (<xref rid="B13" ref-type="bibr">13</xref>). The closest relative of each MAG in the training set was then determined based on the lowest Mash distance. Subsequently, each pair of genomes were aligned with MUMmer 3.23 (<xref rid="B14" ref-type="bibr">14</xref>) to obtain the fraction of the MAG aligned (aligned query, AQ) and average nucleotide identity (ANI) between them. According to previously established standards for species delineation (<xref rid="B15" ref-type="bibr">15</xref>,<xref rid="B16" ref-type="bibr">16</xref>), only MAGs with AQ &gt;60% and ANI &gt;95% were labeled as the same species as their closest relatives. The pipeline was also used to compute the similarity between each training genome and its closest training genome in other species categories.</p>
        <p>These gut-derived MAGs were used to generate the benchmark datasets used to compare the performance of different model architectures and the performance of the best model on reads derived from different sequencing platforms, respectively. To select the best model, we simulated 10 000 paired-end reads per MAG with ART simulator using HiSeq 2500 error model with an insert size of 400 and standard deviation of 50 bp. We trimmed the 150 bp reads from 3′ end to 75–150 bp as described above. To simulate reads with different lengths and error-profiles depending on sequencing platforms, we simulated five fixed-length datasets comprised 10 000 paired-end reads per MAG using different ART error models (-m 400, -s 50): 75 bp, GenomeAnalyzer II; 100 bp, HiSeq 2000; 125 bp and 150 bp, HiSeq 2500; 250 bp, MiSeq v3.</p>
      </sec>
      <sec id="SEC2-2-2">
        <title>Generation of mock communities from gastrointestinal bacterial isolates</title>
        <p>We downloaded 258 whole genome-sequenced bacterial isolate sequencing data from the Human Gastrointestinal Bacteria Culture Collection (HBC) (<xref rid="B17" ref-type="bibr">17</xref>) using ENA accession ERP105624 and ERP012217 (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S3</xref>). Any isolates ambiguously assigned at the genus level were excluded. For each of the ten mock communities, we simulated relative abundances for each isolate using a different random seed from a lognormal distribution, as this method is widely used to model microbial abundance distribution. We used the <italic>rlnorm</italic> function in R for random generation with the mean set to 1 and the standard deviation to 2 (<xref rid="B18" ref-type="bibr">18</xref>). We normalized the sum of the random numbers to 1 by dividing each number by their sum and randomly sampled 10 million paired-end reads in total for each mock community. This dataset was used to compare the performance of DeepMicrobes with the other taxonomic classification tools with regard to precision, recall, abundance estimation, classification rate and speed. The ground truth abundance profiles were generated by summing the relative abundances, which is the read count proportion, of the isolates according to their genus or species assignment. The ground truth profiles for genus and species are available in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S4 and 5</xref>, respectively.</p>
      </sec>
      <sec id="SEC2-2-3">
        <title>Simulation of reads from species absent from reference databases</title>
        <p>We downloaded the 7903 genomes previously reconstructed from the metagenomes of a wide range of habitats using NCBI BioProject accession PRJNA348753 (<xref rid="B19" ref-type="bibr">19</xref>). These genomes were then aligned to the reference databases of different taxonomic classification tools using the pipeline described above to determine their distance (AQ and ANI) to the species included in each database. For CLARK (<xref rid="B20" ref-type="bibr">20</xref>) and CLARK-<italic>S</italic> (<xref rid="B21" ref-type="bibr">21</xref>) the genomes automatically downloaded via set_targets.sh were taken as the reference for genome alignment. To avoid disadvantaging Kraken and Kraken 2 (which provide pre-built database indexes), we excluded the genomes released after the update dates of their pre-built databases from the RefSeq complete prokaryotic genome database downloaded on 20 September 2019. For DeepMicrobes the 2505 genomes used to create the training set were taken as the reference for genome alignment. We defined the absence of the species from the reference databases as genome alignments with both AQ &lt;60% and ANI &lt;95% to their closest relatives in the databases. We further retained the genomes whose AQ &gt;10%, yielding a total of 121 genomes whose species were absent from the databases and prone to false positive classifications (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S6</xref>). We simulated 1× coverage of paired-end reads with length 150 bp using ART simulator (-ss HS 25, -f 1, -m 400, -s 50) for each of the 121 genomes and randomly trimmed the reads to 75–150 bp.</p>
      </sec>
    </sec>
    <sec id="SEC2-3">
      <title>Performance metrics</title>
      <p>Species and genus level performances of DeepMicrobes were benchmarked using the species and genus classification models, respectively.</p>
      <sec id="SEC2-3-1">
        <title>Read-level precision and recall</title>
        <p>We use read-level precision and recall to determine the threshold for the confidence score. For each model architecture we select the threshold making read-level precision of species classification &gt;0.95 measured on the benchmark dataset simulated from gastrointestinal-derived MAGs. For threshold selection, precision and recall are calculated considering the 32 690 000 paired-end reads as a whole dataset. The number of total reads is 10 000 when measuring the metrics for each MAG. The read-level precision and recall of genus classification are computed for each of the mock communities. Formally, read-level precision and recall are defined as follows:<disp-formula><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}\ {\rm Precisio}{{\rm n}_{{\rm read}}} = \frac{{\# \ {\rm reads}\ {\rm classified}\ {\rm correctly}}}{{\# \ {\rm reads}\ {\rm classified}}}\end{equation*}$$\end{document}</tex-math></disp-formula><disp-formula><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}\ {\rm Recal}{{\rm l}_{{\rm read}}} = \frac{{\# \ {\rm reads}\ {\rm classified}\ {\rm correctly}}}{{\# \ {\rm reads}}}\end{equation*}$$\end{document}</tex-math></disp-formula></p>
      </sec>
      <sec id="SEC2-3-2">
        <title>Community-level precision and recall</title>
        <p>Community-level precision and recall describe whether the presence or absence of taxa (i.e. species or genus) in a microbial community is correctly identified by a taxonomic classifier, where<disp-formula><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}\ {\rm Precisio}{{\rm n}_{{\rm community}}} = \frac{{\# \ {\rm taxa}\ {\rm identified}\ {\rm correctly}}}{{\# \ {\rm taxa}\ {\rm {\rm identified}}}}\end{equation*}$$\end{document}</tex-math></disp-formula><disp-formula><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}\ {\rm Recal}{{\rm l}_{{\rm community}}} = \frac{{\# \ {\rm taxa}\ {\rm identified}\ {\rm correctly}}}{{\# \ {\rm taxa}\ {\rm in}\ {\rm the}\ {\rm truth}\ {\rm set}}}\end{equation*}$$\end{document}</tex-math></disp-formula></p>
        <p>To assess the community-level precision and recall given an abundance cutoff, we normalize the read count at the genus level of each taxonomic classifier to sum of 1. We applied two abundance cutoffs (0.01% and 0.0001%) on the profiles and only consider predicted genus above the cutoffs when calculating community-level precision and recall. Community-level precision and recall are not computed at the species level, because a large fraction of the isolates represent unclassified novel species and only a small fraction of the species is shared between our training set and the databases of the other taxonomic classification tools. When comparing the number of identified species for each simulated dataset, we require at least one supporting reads for the identification of a species.</p>
      </sec>
      <sec id="SEC2-3-3">
        <title>Classification rate</title>
        <p>We do not perform filtering by abundance or read count for the classification rate and abundance estimation benchmarks. We define the classification of reads in this paper as confidence score &gt;0.50. In our testing, this confidence threshold results in both the species and genus classification models achieving read-level precision &gt;0.95 on both the gastrointestinal-derived MAGs and the mock communities simulated benchmarks. DeepMicrobes provides the confidence score as an adjustable parameter for users to modify depending on their different requirements.</p>
        <p>Tools like Kraken output hierarchical read counts that are the sum of assignments at least made at a specific taxon level. For tools that do not output these values, we generate them by summing up the number of assignments at and below the level. For example, we summed up the number of hits at the level of genus, species, subspecies, and leaf to calculate the number of reads classified by Centrifuge (<xref rid="B22" ref-type="bibr">22</xref>) at the genus level.</p>
      </sec>
      <sec id="SEC2-3-4">
        <title>Abundance estimation</title>
        <p>To generate the abundance profiles for each taxonomic classifier, we divided each taxon sum by the total number of reads classified at the species or genus level yielding an abundance vector summing to one. A previous abundance estimation benchmark study adopted the L2 (Euclidean) distance for use with taxonomic classification tools (<xref rid="B23" ref-type="bibr">23</xref>). The L2 distance between predicted and ground truth abundance vectors was calculated using the <italic>norm</italic> function implemented in R package PET (<ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package">https://CRAN.R-project.org/package</ext-link> = PET). For species quantification based on the 14 species shared by the database/training set of all classifiers, we generated species abundance profiles for each classifier as described above, but only the abundance of these species was considered when calculating L2 distance.</p>
      </sec>
    </sec>
    <sec id="SEC2-4">
      <title>Model architectures</title>
      <p>In this section, we provide the technical details of the deep learning algorithms used and give the mathematical description of the network layers and computational modules. This includes descriptions of the sequence encoding schemes and the network models tested. The architecture of DeepMicrobes is described below and a schematic representation is presented in Figure <xref ref-type="fig" rid="F1">1B</xref>. The technical details of the other tested architectures are available in Supplementary Material.</p>
      <sec id="SEC2-4-1">
        <title>One-hot encoding and k-mer embedding</title>
        <p>We tried two strategies to encode DNA sequences into numeric matrices, namely one-hot encoding and <italic>k</italic>-mer embedding. For one-hot encoding we convert DNA into 4 × <italic>L</italic> matrix, where A = [1, 0, 0, 0], C = [0, 1, 0, 0], G = [0, 0, 1, 0] and T = [0, 0, 0, 1]. Specifically, the convolutional model, hybrid convolutional and recurrent model, and seq2species (<xref rid="B24" ref-type="bibr">24</xref>) model take as input one-hot encoded DNA, whereas embedding-based models utilize <italic>k</italic>-mer embedding as the first layer of deep neural networks (DNNs). For <italic>k</italic>-mer embedding, we split a DNA sequence of length <italic>L</italic> into a list of substrings of length <italic>K</italic> with a stride of one, yielding <italic>L</italic> – <italic>K</italic> + 1 substrings. The length of <italic>K</italic> is chosen to reach balance between the model's fitting capacity and computational resources since the vocabulary size grows exponentially in <italic>K</italic> by 4<italic><sup>K</sup></italic> (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S7</xref>). We use 12-mers unless otherwise stated. Notably, we confirmed that the final best architecture using 12-mers performs much better than the variants using 8-mers to 11-mers (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S7 and 11</xref>).</p>
        <p>The <italic>k</italic>-mer vocabulary is constructed using Jellyfish (<xref rid="B25" ref-type="bibr">25</xref>). We only retain canonical <italic>k</italic>-mers as representatives (-C parameter of Jellyfish), which downsizes the vocabulary. We include a word symbol &lt;unk&gt; in the vocabulary to represent <italic>k</italic>-mers with Ns. Each <italic>k</italic>-mer is indexed with a positive integer <italic>V</italic> according to its lexical order in the vocabulary (<italic>V</italic> = [1, 2, …, i]). The position of 0 is reserved to denote zero-padding for variable-length sequences, because the TensorFlow input pipeline require that all sequences in a mini-batch should be in the same length. The padding does not affect the performance of the final best model, because its dynamic long short-term memory (LSTM) layer automatically dismisses the padding regions and outputs fixed-length feature maps.</p>
        <p>The embedding layer of the DNN utilizes these indexes (for fast look-ups in the implementation) to map each <italic>k</italic>-mer to a <italic>d</italic><sub>embed</sub> dimensional dense vector (hereafter referred to as <italic>k</italic>-mer embedding vector). See below for details.</p>
      </sec>
      <sec id="SEC2-4-2">
        <title>Embedding-based recurrent self-attention model (Embed + LSTM + Attention)</title>
        <p>Suppose we have a DNA sequence, which is composed of <inline-formula><tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math></inline-formula><italic>k</italic>-mers, represented in a sequence of <italic>k</italic>-mer embedding vectors (Figure <xref ref-type="fig" rid="F1">1C</xref>).<disp-formula><tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}S = \left( {{{\boldsymbol{w}}_1},{\rm{\ }}{{\boldsymbol{w}}_2},{\rm{\ }} \ldots {{\boldsymbol{w}}_{\boldsymbol{n}}}} \right)\ \end{equation*}$$\end{document}</tex-math></disp-formula>where <inline-formula><tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${{\boldsymbol{w}}_{\boldsymbol{i}}}$\end{document}</tex-math></inline-formula> is a vector standing for a <italic>d</italic><sub>embed</sub> dimensional <italic>k</italic>-mer embedding for the <inline-formula><tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$i$\end{document}</tex-math></inline-formula>-th <italic>k</italic>-mer (<inline-formula><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${{\boldsymbol{w}}_{\boldsymbol{n}}}{\boldsymbol{\ }} \in {\boldsymbol{\ }}{\mathbb{R}^{{{\boldsymbol{d}}_{{\boldsymbol{embed}}}}}}$\end{document}</tex-math></inline-formula>). <inline-formula><tex-math id="M10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$S$\end{document}</tex-math></inline-formula> is a 2-D matrix concatenating all the <italic>k</italic>-mer embedding vectors together. <inline-formula><tex-math id="M11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$S$\end{document}</tex-math></inline-formula> has the shape <italic>d</italic><sub>embed</sub>-by-<inline-formula><tex-math id="M12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math></inline-formula>.</p>
        <p>We use a bidirectional LSTM to process the 2-D embedding matrix <inline-formula><tex-math id="M13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$S$\end{document}</tex-math></inline-formula> generated with the embedding layer (Figure <xref ref-type="fig" rid="F1">1D</xref>). Let the hidden unit number of each unidirectional LSTM be <italic>d</italic><sub>lstm</sub>. Formally,<disp-formula><tex-math id="M14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}\ \overrightarrow {{h_t}} = \overrightarrow {{\rm LSTM}} \ \left( {{w_t},\ \overrightarrow {{h_{t - 1}}} } \right)\end{equation*}$$\end{document}</tex-math></disp-formula><disp-formula><tex-math id="M15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}\ \overleftarrow {{h_t}} = \overleftarrow {{\rm LSTM}} \ \left( {{w_t},\ \overleftarrow {{h_{t + 1}}} } \right)\end{equation*}$$\end{document}</tex-math></disp-formula></p>
        <p>We concatenate each <inline-formula><tex-math id="M16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\overrightarrow {{h_t}}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\overleftarrow {{h_t}}$\end{document}</tex-math></inline-formula> to obtain the hidden state as <inline-formula><tex-math id="M18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${h_i} = [ {\overrightarrow {{h_t}} ,\ \overleftarrow {{h_t}} } ]$\end{document}</tex-math></inline-formula>. For simplicity, we denote all the <inline-formula><tex-math id="M19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${h_i}$\end{document}</tex-math></inline-formula> output from the bidirectional LSTM as <inline-formula><tex-math id="M20">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$H$\end{document}</tex-math></inline-formula> who has a shape of 2<italic>d</italic><sub>lstm</sub>-by-<inline-formula><tex-math id="M21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math></inline-formula>.<disp-formula><tex-math id="M22">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}H = \left( {{{\boldsymbol{h}}_1},{\rm{\ }}{{\boldsymbol{h}}_2},{\rm{\ }} \ldots {{\boldsymbol{h}}_{\boldsymbol{n}}}} \right)\ \end{equation*}$$\end{document}</tex-math></disp-formula></p>
        <p>We apply a self-attention mechanism (<xref rid="B26" ref-type="bibr">26</xref>) between the bidirectional LSTM and fully connected layers (Figure <xref ref-type="fig" rid="F1">1E</xref>). The self-attention mechanism computes a linear combination of the <inline-formula><tex-math id="M23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math></inline-formula> LSTM hidden vectors in <inline-formula><tex-math id="M24">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$H$\end{document}</tex-math></inline-formula> and outputs a vector of attention weights <inline-formula><tex-math id="M25">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${{\bf a}}$\end{document}</tex-math></inline-formula>. Formally,<disp-formula><tex-math id="M26">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{{\bf a}} = softmax\ \left( {\tanh \left( {{H^T}{W_{s1}}} \right){{\boldsymbol{w}}_{{\boldsymbol{s}}2}}} \right)\end{equation*}$$\end{document}</tex-math></disp-formula>where <inline-formula><tex-math id="M27">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${W_{s1}}$\end{document}</tex-math></inline-formula> is a weight matrix sized 2<italic>d</italic><sub>lstm</sub>-by-<italic>d</italic><sub>a</sub> (<italic>d</italic><sub>a</sub> is a hyperparameter that can be set arbitrarily) and <inline-formula><tex-math id="M28">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${{\boldsymbol{w}}_{{\boldsymbol{s}}2}}$\end{document}</tex-math></inline-formula> is a weight vector sized <italic>d</italic><sub>a</sub>.</p>
        <p>To allow the model to focus on multiple components in a DNA sequence, we perform <inline-formula><tex-math id="M29">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$r$\end{document}</tex-math></inline-formula> rows of attention (i.e. generate <inline-formula><tex-math id="M30">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$r$\end{document}</tex-math></inline-formula> different attention weightings over length of the DNA sequence) and form the multi-head attention matrix <inline-formula><tex-math id="M31">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$A$\end{document}</tex-math></inline-formula> whose shape is <inline-formula><tex-math id="M32">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math></inline-formula>-by-<inline-formula><tex-math id="M33">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\ r$\end{document}</tex-math></inline-formula>. Thus,<disp-formula><tex-math id="M34">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}A = softmax\ \left( {\tanh \left( {{H^T}{W_{s1}}} \right){W_{s2}}} \right)\end{equation*}$$\end{document}</tex-math></disp-formula>where <inline-formula><tex-math id="M35">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${W_{s1}}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M36">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${W_{s2}}$\end{document}</tex-math></inline-formula> are both weight matrices of the linear transformations and <inline-formula><tex-math id="M37">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${W_{s2}}$\end{document}</tex-math></inline-formula> is extended into a <italic>d</italic><sub>a</sub>-by-<inline-formula><tex-math id="M38">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$r$\end{document}</tex-math></inline-formula> matrix. Here softmax function (see ‘Model Training’ section for details) is performed along the <inline-formula><tex-math id="M39">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$r$\end{document}</tex-math></inline-formula>dimension of the input to ensure each column of attention scores sum up to 1. The attention scores indicate the relative importance of each <italic>k</italic>-mer.</p>
        <p>These importance scores are then used to weight the LSTM hidden vectors generated from each <italic>k</italic>-mer. This allows the model to pay attention to some specific parts of a DNA sequence which might contribute most to classification. To this end, we multiply the LSTM hidden states <inline-formula><tex-math id="M40">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$H$\end{document}</tex-math></inline-formula> and the attention matrix <inline-formula><tex-math id="M41">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$A$\end{document}</tex-math></inline-formula>. The resulting matrix <inline-formula><tex-math id="M42">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$M$\end{document}</tex-math></inline-formula> has a shape of 2<italic>d</italic><sub>lstm</sub>-by-<inline-formula><tex-math id="M43">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$r$\end{document}</tex-math></inline-formula> that is irrelevant to the input sequence length <inline-formula><tex-math id="M44">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math></inline-formula>.<disp-formula><tex-math id="M45">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}M = HA\end{equation*}$$\end{document}</tex-math></disp-formula></p>
        <p><inline-formula><tex-math id="M46">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$M$\end{document}</tex-math></inline-formula> is passed through a three layer fully connected classifier and softmax function that converts output activations to class probabilities (see ‘Model Training’ section below for details of softmax function; a <italic>fully connected layer</italic> is also known as a <italic>dense layer</italic>). The fully connected classifier, also termed multilayer perceptron (MLP), consists of three linear transformations with ReLU activations in between. Formally,<disp-formula><tex-math id="M47">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{\rm{MLP\ }}\left( x \right) = {\rm{ReLU}}\left( {{\rm{ReLU}}\left( {x{W_1} + \ {b_1}} \right){W_2} + \ {b_2}} \right){W_3} + \ {b_3}\end{equation*}$$\end{document}</tex-math></disp-formula>where the dimensions of <inline-formula><tex-math id="M48">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${W_1}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M49">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${W_2}$\end{document}</tex-math></inline-formula> are tunable hyperparameters and the dimension of <inline-formula><tex-math id="M50">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${W_3}$\end{document}</tex-math></inline-formula> depends on the number of output classification categories.</p>
      </sec>
    </sec>
    <sec id="SEC2-5">
      <title>Model training</title>
      <p>The DNNs were implemented using the TensorFlow framework. We used NVIDIA Tesla P40 24GB GPU to accelerate computation. We trained the models until they converged on the evaluation set. For each architecture of DNN, we performed random search to pick the optimal combination of hyperparameters. In detail, we randomly sampled 30 candidate hyperparameters setting from the search space and picked the models which performed best on the evaluation set. The optimal hyperparameters for each model are listed in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S8</xref>.</p>
      <p>For the final best architecture, namely the embedding-based recurrent self-attention model, we used a batch size of 2048 and initialized training using a learning rate of 0.001 with a decay rate of 0.05. We did not use regularization methods like dropout or L2 normalization.</p>
      <p>We used Adam as the optimizer and minimized the objective function, which is the cross-entropy loss computed between softmax activated prediction output and one-hot encoded ground truth label. The softmax function takes as input a <italic>C</italic>-dimensional vector <bold>x</bold> and outputs a <italic>C</italic>-dimensional vector <bold>y</bold> of values between 0 and 1. More formally, the softmax function computes<disp-formula><tex-math id="M51">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{{\bf y}} = {\rm{softmax\ }}\left( {{\bf x}} \right) = \left[ {\frac{{{{\boldsymbol{e}}^{{{\boldsymbol{x}}_1}}}}}{{\mathop \sum \nolimits_i {{\boldsymbol{e}}^{{{\boldsymbol{x}}_{\boldsymbol{i}}}}}}},\ \ldots ,\ \frac{{{{\boldsymbol{e}}^{{{\boldsymbol{x}}_{\boldsymbol{C}}}}}}}{{\mathop \sum \nolimits_i {{\boldsymbol{e}}^{{{\boldsymbol{x}}_{\boldsymbol{i}}}}}}}} \right]\ \end{equation*}$$\end{document}</tex-math></disp-formula>where <italic>C</italic> is the number of classification categories (i.e., species or genus). The denominator <inline-formula><tex-math id="M52">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathop \sum \limits_i {{\boldsymbol{e}}^{{{\boldsymbol{x}}_{\boldsymbol{i}}}}}$\end{document}</tex-math></inline-formula> makes sure that <inline-formula><tex-math id="M53">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\mathop \sum \limits_i {{\boldsymbol{y}}_{\boldsymbol{i}}} = 1$\end{document}</tex-math></inline-formula>. Thus, <bold>y</bold> can be seen as the probability distribution of prediction over all the categories. The cross-entropy loss objective is defined as<disp-formula><tex-math id="M54">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$$\begin{equation*}{\rm{objective}} = - \mathop \sum \limits_{c\ = \ 1}^C {t_c}\ {\rm{log}}\left( {{y_c}} \right)\end{equation*}$$\end{document}</tex-math></disp-formula>where <inline-formula><tex-math id="M55">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${y_c}$\end{document}</tex-math></inline-formula> is the probability that the input DNA sequence is of taxon <italic>c</italic> and <inline-formula><tex-math id="M56">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${t_c}$\end{document}</tex-math></inline-formula> is the binary value (0 or 1) indicates whether taxon <italic>c</italic> is the correct assignment.</p>
    </sec>
    <sec id="SEC2-6">
      <title>Software versions and databases of other taxonomic classifiers</title>
      <p>We compared the performance of DeepMicrobes with Kraken, Kraken 2, Centrifuge, CLARK, CLARK-<italic>S</italic>, Kaiju (<xref rid="B27" ref-type="bibr">27</xref>), DIAMOND-MEGAN and BLAST-MEGAN (<xref rid="B28" ref-type="bibr">28</xref>). These tools were run with default options. The tools were run in paired-end mode, except for DIAMOND-MEGAN and BLAST-MEGAN. For paired-end data we averaged the softmax probability distributions generated by DeepMicrobes for two ends of reads. We ran Kraken (v1.0) using the pre-built MiniKraken 8GB database included complete bacterial, archaeal and viral genomes in RefSeq (as of 18 October 2017). We ran Kraken 2 (v2.0.6) using pre-built MiniKraken2 v1 8GB database including RefSeq bacteria, archaea and viral libraries (available on 23 April 2019). Centrifuge (v1.0.3) was run using pre-built NCBI nucleotide non-redundant sequence database (updated on 3 March 2018). The bacteria (and archaea) database for CLARK and CLARK-<italic>S</italic> (v1.2.5) was downloaded via the set_targets.sh script (on 25 August 2018). Kaiju (v1.5.0) was run using pre-built microbial subset of the NCBI nr database (as of 16 May 2017). To run DIAMOND-MEGAN, we queried unpaired reads using DIAMOND (v0.9.22.123) against nr database downloaded from NCBI (on 27 August 2018). To run BLAST-MEGAN, we queried unpaired reads using BLAST executable (v2.6.0+) against nt index downloaded from NCBI (on 25 August 2018) with Megablast mode and an <italic>E</italic>-value of 1e-20. After database query, we ran MEGAN (v5.3.11) on the tabular files generated with DIAMOND and BLAST to summarize the LCA taxon for each read.</p>
      <p>We created a custom database for Kaiju with the 2505 genomes of human gut species used to train DeepMicrobes. Protein sequences were predicted with Prodigal (<xref rid="B29" ref-type="bibr">29</xref>) (v2.6.3) using the default single mode as previously described (<xref rid="B2" ref-type="bibr">2</xref>). We assigned a different pseudo species-level taxonomic identifier to each species. These taxonomic identifiers did not duplicate any existing NCBI taxonomic identifiers. The parent nodes of each species were retrieved from taxonomy_hgr.tab and taxonomy_umgs.tab available at <ext-link ext-link-type="ftp" xlink:href="ftp://ftp.ebi.ac.uk/pub/databases/metagenomics/umgs_analyses">ftp://ftp.ebi.ac.uk/pub/databases/metagenomics/umgs_analyses</ext-link>. The custom Kaiju index was created using kaiju-mkbwt and kaiju-mkfmi.</p>
    </sec>
    <sec id="SEC2-7">
      <title>Computational environment</title>
      <p>DeepMicrobes and other taxonomic classifiers were benchmarked on a compute node having 256 Gb of memory and two Intel E5–2650 v4 processors, each of which with 12 cores (24 threads). DeepMicrobes was further accelerated utilizing a NVIDIA Tesla P40 24GB GPU during both training and testing. Specifically, CPUs extract and transform the training and testing data and then feed it to a model running on a GPU. We parallelized the data preparation across 8 CPU cores using the <italic>num_parallel_calls</italic> argument of the TensorFlow input pipeline. The run-time of DeepMicrobes includes the time used for TFRecord conversion. The computational time benchmark for other classifiers was measured by running a single instance of each classifier provided all 48 threads and memory. We also tried running other classifiers provided 8 threads and all memory and compared the time with 48 threads.</p>
    </sec>
    <sec id="SEC2-8">
      <title>Uncultured species signatures of inflammatory bowel diseases</title>
      <p>We downloaded the gut metagenome samples from 106 subjects with or without inflammatory bowel diseases (Crohn's disease or ulcerative colitis) using SRA BioProject accession PRJNA398089 (<xref rid="B10" ref-type="bibr">10</xref>), which is part of the Integrative Human Microbiome Project (iHMP). We randomly chose one sample as representative if multiple samples for a subject were available. The dataset is composed of 26 healthy subjects, 50 subjects with Crohn's disease and 30 subjects with ulcerative colitis. The samples were quality controlled using Trimmomatic (v0.36) (<xref rid="B30" ref-type="bibr">30</xref>) with minimum read length 75 bp. Host reads were further removed using KneadData (v0.6.1). We then analyzed the samples using the species model of DeepMicrobes with confidence score 0.50 and generated species abundance profiles using the method described above. We used LEfSe (<xref rid="B31" ref-type="bibr">31</xref>) to determine the species most likely to explain differences between the three subject groups. Briefly, we used the non-parametric factorial Kruskal–Wallis sum-rank test to detect species with significant abundance (<italic>P</italic> &lt; 0.05) with respect to each group. The resulting subset of species was used to build a linear discriminant analysis (LDA) model to estimate the effect size of each differentially abundant species. The species whose LDA effect size &gt;2.0 were retained and ranked according to the effect size.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="SEC3">
    <title>RESULTS</title>
    <sec id="SEC3-1">
      <title>A deep learning architecture for taxonomic classification</title>
      <p>Deep learning has been applied for the classification of 16S rRNA reads (<xref rid="B24" ref-type="bibr">24</xref>) and representation learning from metagenomic reads longer than 1 kb (<xref rid="B32" ref-type="bibr">32</xref>). However, taxonomic classification of short shotgun sequencing reads is more challenging. The model should learn genome-wide patterns during training, whereas only information from a short genomic fragment is available during application.</p>
      <p>To determine what kind of deep neural network (DNN) is suitable for modeling the taxonomic signatures of shotgun metagenomic sequencing reads, we presented a systematic exploration of DNN architectures with different combinations of network architectural building blocks, DNA encoding schemes and other hyperparameters. To train the models for species classification, we simulated equal proportion of variable-length reads between 75 and 150 bp for each of the 2505 gut species (<xref rid="B2" ref-type="bibr">2</xref>) (‘Materials and Methods’ section). To test the models, we simulated variable-length reads from a held-out set of 3269 MAGs reconstructed from human gut microbiomes (‘Materials and Methods’ section), which represent phylogenetic diversity within the gut ecosystem spanning multiple populations. The distribution of read-level precision and recall across these MAGs is used as the metric for model selection. The confidence threshold to decide whether reads are classified or not is determined by benchmarking a gradient of confidence score with a stride of 0.05 on the whole test set (i.e. reads simulated from all the MAGs are considered as a single set). The minimum confidence scores ensuring &gt;0.95 read-level precision are chosen for each architecture (Figure <xref ref-type="fig" rid="F2">2</xref>; <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S6 and 7</xref>).</p>
      <fig id="F2" orientation="portrait" position="float">
        <label>Figure 2.</label>
        <caption>
          <p>Performance of different DNN methods. (<bold>A</bold>) The read-level precision and recall of different models on simulated reads from the gut-derived MAGs. Each point represents the metric measured on a MAG. (<bold>B</bold>) The read-level precision and recall of the three of the best models across a series of confidence score. The minimum confidence threshold where precision &gt;0.95 is selected for each model.</p>
        </caption>
        <graphic xlink:href="lqaa009fig2"/>
      </fig>
      <p>We first tried three DNNs that take as input one-hot encoded DNA matrices, including a ResNet-like convolutional neural network (CNN), a hybrid DNN of CNN and bidirectional long short-term memory (LSTM), and the seq2species model proposed for short 16S rRNA read classification (‘Materials and Methods’ section). The ResNet-like CNN (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S1</xref>) and the hybrid DNN (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S2</xref>) are representative of architectures that achieved state-of-the-art performance in predicting the impact of mutations (<xref rid="B33" ref-type="bibr">33</xref>) and transcription factor binding (<xref rid="B34" ref-type="bibr">34</xref>), respectively. However, the accuracy and overall prediction confidence of the three DNNs are low, with seq2species performs best relatively, followed by the hybrid DNN (Figure <xref ref-type="fig" rid="F2">2A</xref>; <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S9 and 10</xref>). This implies that taxonomic classification for short metagenomic reads requires a distinct deep learning scheme.</p>
      <p>One likely reason for the low performance of the DNNs above may be one-hot encoding. Apart from being information-sparse, such encoding scheme represents complementary strands of a DNA sequence as two unrelated matrices. To overcome these limitations, we make an analogy between <italic>k</italic>-mers and words and used <italic>k</italic>-mer embedding to represent DNA sequences (Figure <xref ref-type="fig" rid="F1">1C</xref>), which is a common practice in natural language processing (NLP). Reverse complement <italic>k</italic>-mers are treated as the same word. To assess the contribution of this encoding scheme to model performance, we trained a baseline model whose only trainable parameters are the weights in the embedding layer (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S3</xref>). In addition, we trained two variants of the baseline model by applying CNN or bidirectional LSTM after the embedding layer, respectively (Materials and Methods; <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S4 and S5</xref>). We found that the baseline model outperforms previous DNNs that use one-hot encoding, which indicates that the <italic>k</italic>-mer embedding layer is capable of embedding taxonomic attributes in each <italic>k</italic>-mer vector. Interestingly, the CNN variant performs worse than the baseline, though it contains more trainable parameters. In contrast, the LSTM variant further improves the baseline (Figure <xref ref-type="fig" rid="F2">2A</xref>; <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S9 and 10</xref>).</p>
      <p>We also proposed a third variant (Figure <xref ref-type="fig" rid="F1">1B</xref>), where a self-attention mechanism (<xref rid="B26" ref-type="bibr">26</xref>) is applied to the hidden states generated by the LSTM variant (Materials and Methods). Self-attention enables the model to focus on specific regions of an input DNA sequence and generate sequence-level representation. The self-attention variant achieves higher read-level precision (mean = 0.942) and recall (mean = 0.428) than the second-best LSTM variant (read-level precision mean = 0.893, read-level recall mean = 0.155). Although we chose different confidence thresholds for different models, we observed that both the read-level precision and recall of the self-attention variant are better than the LSTM variant and the baseline model across a series of confidence scores (Figure <xref ref-type="fig" rid="F2">2B</xref>), surpassing other DNNs utilizing convolution (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S6</xref>). Therefore, this self-attention augmented embedding-based recurrent model is selected for DeepMicrobes.</p>
      <p>The diversity of the MAGs used to create the test set further provides us with the opportunity to explore what factors affect the performance of DeepMicrobes (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>). As expected, the degree of similarity between tested MAGs and the representative genomes in training set is the major factor that affects the read-level recall (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S8</xref>). In addition, species with relatively small genomes tend to be high in recall, as their genomic features could be easier to grasp than species with large genomes, given a theoretical upper bound on the model's total capacity. What affects the read-level precision most is the similarity between different categories (i.e. species). In general, DeepMicrobes achieves near-perfect precision when the aligned proportion &lt;50% between a pair of most similar categories (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S9</xref>). We did not observe a clear relationship between performance and specific taxonomic groups (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S10</xref>).</p>
      <p>The test set we mentioned above is comprised of variable-length reads. To investigate the impact of sequencing platform on performance, we simulated five additional test sets, each of which represents read length and error profile of a specific next-generation sequencing platform (‘Materials and Methods’ section). Generally, the read-level precision of DeepMicrobes is high for reads ≥ 100 bp and from the commonly-used HiSeq and MiSeq platforms (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S11 and Tables S11-12</xref>). The results also show that both the read-level precision and recall are higher for longer reads, even when the read length is not seen during training. This implies that DeepMicrobes generalizes well and performs even better on MiSeq reads with length, for example, 300 or 400 bp.</p>
    </sec>
    <sec id="SEC3-2">
      <title>Comparison of DeepMicrobes with other taxonomic classification tools</title>
      <p>We next evaluate whether the DeepMicrobes, which is trained on a bacterial repertoire of the human gut microbiota, has an advantage over state-of-the-art metagenomics tools for taxonomic classification of gut metagenome sequences. Although it is the most ideal choice to benchmark on genuine metagenomic reads, such data would not provide us with read-level and community-level ground truth for taxon identification and abundance estimation. One common alternative is to create mock communities by combining real reads obtained from whole genome sequencing for microbial isolates (<xref rid="B5" ref-type="bibr">5</xref>,<xref rid="B22" ref-type="bibr">22</xref>). Thus, we created 10 such microbial communities by random sampling reads from the isolates cultured from human fecal samples (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S3</xref>), many of which represent candidate novel species yet to be named (‘Materials and Methods’ section).</p>
      <p>The lack of overlap in reference databases of different tools at the species level lead us to focus our comparisons on genus-level performance. We classified each mock sample using DeepMicrobes and other taxonomic classification tools, including Kraken, Kraken 2, Centrifuge, CLARK, CLARK-<italic>S</italic>, Kaiju, DIAMOND-MEGAN and BLAST-MEGAN. The confidence threshold for the genus model is determined according to read-level classification accuracy measured on these real reads (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S13</xref>). We observed that the genus model achieves a read-level precision of 0.969 and a recall of 0.866 on average using threshold 0.50, which is the default setting for DeepMicrobes.</p>
      <p>We benchmarked the performance of genus identification using two abundance cutoffs, 0.01% and 0.0001%, representing two analysis scenarios. The first scenario is useful for detecting high-abundance taxa (e.g. studies in metabolic disorders), and the second favors high sensitivity for detecting low-abundance taxa (e.g. pathogen detection). In general, a low abundance cutoff increases the community-level recall at the cost of precision. We found that only DeepMicrobes succeeded in identifying all the genera using abundance cutoff 0.01% (Figure <xref ref-type="fig" rid="F3">3A</xref>). The genomes of microorganisms living in a specific habitat might be divergent from their representatives in standard databases like RefSeq and NCBI non-redundant databases. This may partially explain the poor performance of other tools. Although Kaiju, DIAMOND-MEGAN and BLAST-MEGAN identified all the genera using cutoff 0.0001%, their community-level precision decreased dramatically (Figure <xref ref-type="fig" rid="F3">3A</xref>). DeepMicrobes also surpasses the other tools in community-level precision under the low-abundance cutoff and ranks second after BLAST-MEGAN under the high cutoff. In addition, the classification speed of DeepMicrobes is acceptable (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S12</xref>).</p>
      <fig id="F3" orientation="portrait" position="float">
        <label>Figure 3.</label>
        <caption>
          <p>Benchmark results of DeepMicrobes and other taxonomic classification tools on the ten mock communities. (<bold>A</bold>) Genus-level precision and recall measured at the community level using abundance cutoff 0.01% and 0.0001%. Each point represents a mock community. A random jitter of 0.005 is added on the recall to reduce overplotting. (<bold>B</bold>) Distance between the genus abundance profile for each tool compared with the true composition. (<bold>C</bold>) Genus-level classification rate for each tool. (<bold>D</bold>) Distance between the species abundance profile for each tool compared with the true composition. These results consider the 14 species included in the reference databases of all the tools in abundance estimation. (<bold>E</bold>) Species-level classification rate for each tool. The error bars represent standard error.</p>
        </caption>
        <graphic xlink:href="lqaa009fig3"/>
      </fig>
      <p>Next, we compared DeepMicrobes with other taxonomic classification tools with respect to the accuracy of abundance estimation. Our results show that DeepMicrobes outperforms other tools in genus quantification (Figure <xref ref-type="fig" rid="F3">3B</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S13</xref>). Moreover, the genus model of DeepMicrobes classified on average 89.40% of the reads in the mock communities, much higher than the second most sensitive tools, Kaiju, which classified on average 68.27% of the reads (Figure <xref ref-type="fig" rid="F3">3C</xref>). In addition, we sought to compare the performance of species quantification using the 14 species shared by all the reference datasets, though they only represent a limited fraction of the whole communities. We found that DeepMicrobes is at least comparable to other tools in species-level abundance estimation (Figure <xref ref-type="fig" rid="F3">3D</xref>). The proportion of reads classified by the species model of DeepMicrobes is slightly lower than Kraken and CLARK (Figure <xref ref-type="fig" rid="F3">3E</xref>). However, the proportion of false positive classifications might vary among different tools.</p>
      <p>To separate the source of performance increase with the habitat specific database that contains MAGs and the deep learning algorithm, we compared DeepMicrobes with Kaiju, which is one of the best competitor tools especially in genus-level quantification and classification rate, using the same reference database. We created a custom Kaiju database composed of the genomes used to train DeepMicrobes (‘Materials and Methods’ section). We observed that the custom Kaiju classified on average 83.25% of the reads at the genus level and correctly recalled more genera than the original Kaiju that uses the microbial subset of the NCBI nr database (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S14</xref>). This demonstrates that both the deep learning algorithm and the MAG-containing database contribute to the improvement in sensitivity. Surprisingly, the performance of genus quantification of the custom Kaiju is worse than the original Kaiju, which implies that the improvement in abundance estimation should be mostly attributed to the deep learning algorithm. In addition, the community-level precision of Kaiju greatly improved using the gut specific reference database. Notably, the community-level precision of custom Kaiju is comparable to DeepMicrobes using abundance cutoff 0.0001%. This suggests that the habitat specific database is the major contributor to precise taxon identification from the metagenomes of the corresponding habitat.</p>
      <p>The absence of a species from the reference database could be a major source of false positives. We assessed how such species affect the community-level precision of DeepMicrobes and other tools in terms of the proportion of misclassified reads and the number of misidentified species from that species. Here we benchmarked with the four tools (Kraken, Kraken 2, CLARK and CLARK-<italic>S</italic>) that performed best apart from DeepMicrobes by taking taxa identification, abundance estimation, and also classification speed into consideration. We used 121 genomes (<xref rid="B19" ref-type="bibr">19</xref>), whose species is absence from all the databases, spanning different degrees of relationship to the closest genome in the databases. We simulated 1× coverage variable-length reads for each genome (‘Materials and Methods’ section). Generally, other tools misclassify more reads and misidentify more species as the relationship gets closer, except that less misidentifications are produced when ANI is higher due to more concentrated distribution of misclassified reads (Figure <xref ref-type="fig" rid="F4">4</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S6</xref>). In contrast, the species model of DeepMicrobes produces far fewer false positives than other tools regardless of different degrees of similarity that were tested. This indicates that DeepMicrobes is higher in species-level precision than other tools, especially when the microbial communities harbor many unknown species.</p>
      <fig id="F4" orientation="portrait" position="float">
        <label>Figure 4.</label>
        <caption>
          <p>Species-level false positive classification and identification measured on the species absent from the databases. Each point represents the proportion of misclassified reads at the species level or the number of misidentified species measured for a simulated dataset of one species-absent genome. The ANI between each genome and its closest genome in database and the proportion of each genome aligned to its closest genome in database (i.e. the proportion of genome used for ANI calculation) are calculated with MUMmer.</p>
        </caption>
        <graphic xlink:href="lqaa009fig4"/>
      </fig>
      <p>Taken together, DeepMicrobes outperforms state-of-the-art taxonomic classification tools in genus and species identification and achieves better or at least comparable accuracy in abundance estimation. Therefore, DeepMicrobes is ready to serve as a relatively reliable tool to help us explore the important but yet to be discovered roles of novel MGS, which complements results generated with other taxonomic classification tools using standard and universal databases.</p>
    </sec>
    <sec id="SEC3-3">
      <title>Discovery of uncultured species related to inflammatory bowel diseases</title>
      <p>We used the species model of DeepMicrobes to classify reads from 106 gut metagenomes sequenced as part of the iHMP (<xref rid="B10" ref-type="bibr">10</xref>) (‘Materials and Methods’ section). The fecal samples were collected from healthy subjects and patients with inflammatory bowel diseases (IBD) including Crohn's disease (CD) and ulcerative colitis (UC). The previous study used MetaPhlAn2 for taxonomic analysis and identified a series of species that are differentially abundant in CD or UC (<xref rid="B10" ref-type="bibr">10</xref>). However, the species included in MetaPhlAn2 database are mainly well-defined ones (<xref rid="B35" ref-type="bibr">35</xref>). To determine whether the uncultured species, which are newly discovered by genome reconstruction from gut microbiomes, possess unexplored associations with IBD, we analyzed the species abundance profiles generated by DeepMicrobes with LEfSe (‘Materials and Methods’ section). The result show that most of the identified candidate biomarkers are unclassified MGS (UMGS) defined previously (<xref rid="B2" ref-type="bibr">2</xref>) (Figure <xref ref-type="fig" rid="F5">5A</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S14</xref>).</p>
      <fig id="F5" orientation="portrait" position="float">
        <label>Figure 5.</label>
        <caption>
          <p>Potential uncultured species biomarkers of IBD identified with LEfSe. The group names (Crohn's disease, Ulcerative colitis and Non-IBD) for each species are assigned by LEfSe. The <italic>P</italic>-values (Kruskal–Wallis test) calculated by LEfSe are shown. The assigned taxa for each species in the highest resolution are indicated in brackets. (<bold>A</bold>) The LDA scores for 10 of the most differentially abundant species. The species are ranked using LDA scores. (<bold>B</bold>) Relative abundance distribution for UMGS368, as a ratio of the median relative abundance in non-IBD individuals. (<bold>C</bold>) Relative abundance distributions for UMGS37 and UMGS41, as a ratio of the median relative abundance in non-IBD individuals.</p>
        </caption>
        <graphic xlink:href="lqaa009fig5"/>
      </fig>
      <p>We observed that some of the identified species are new members of the taxa whose correlation with CD or UC has been reported. For example, the previous study found that <italic>Alistipes</italic> species, such as <italic>Alistipes shahii</italic>, <italic>Alistipes finegoldii</italic> and <italic>Alistipes putredinis</italic> are depleted in IBD (<xref rid="B10" ref-type="bibr">10</xref>). Here we identified another <italic>Alistipes</italic> species, UMGS368, whose abundance also decreases in CD and UC (Figure <xref ref-type="fig" rid="F5">5B</xref>). In addition, we identified some uncultured species whose genera have not been found to increase in UC, such as UMGS37 and UMGS41, which are <italic>Lachnospira</italic> and <italic>Anaeromassilibacillus</italic> species, respectively (Figure <xref ref-type="fig" rid="F5">5C</xref>). These results complement previous findings and might potentially provide new insight into the diagnosis and treatment of IBD.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="SEC4">
    <title>DISCUSSION</title>
    <p>Metagenomic assembly efforts so far have greatly expanded the known diversity of uncultured microorganisms living in specific habitats. For example, the human microbiome harbors a large fraction of species without any representatives in standard reference databases which mainly include genomes obtained using culture-dependent approaches. These species might encode a number of newly identified protein families which possess distinctive metabolic functional capacities (<xref rid="B2" ref-type="bibr">2</xref>). Furthermore, the pan-genomes of species in specific environments might diverge from their representatives in universal databases (<xref rid="B4" ref-type="bibr">4</xref>).</p>
    <p>In this study, we present DeepMicrobes, a deep learning-based computational framework that aims to facilitate effective utilization of the new taxonomic knowledge acquired in large-scale metagenomic assemblies into tools for microbiome research. We can train a model to classify metagenomic reads at any taxonomic rank provided with any collection of training genomes representing different categories. Specifically, we are allowed to bypass the laborious and time-consuming curation of a taxonomic tree, which is required by other taxonomic classification tools like Kraken for database creation.</p>
    <p>One limitation of our current framework is that adding new species requires retraining the entire deep neural network. Future efforts to address this issue may include incremental learning. The goal of incremental learning is to retain the knowledge acquired from the old classes and meanwhile learn the new classes (<xref rid="B36" ref-type="bibr">36</xref>). This could allow continuous learning as new classes (e.g. new species) of data arrive (<xref rid="B37" ref-type="bibr">37</xref>).</p>
    <p>Accurate taxonomic classification of short shotgun metagenomic reads requires a distinct DNA encoding approach and DNN architecture. We found that <italic>k</italic>-mer embedding significantly boosts model performance. Interestingly, <italic>k</italic>-mer embedding has recently been showed to surpass one-hot encoding in predicting transcription factor binding (<xref rid="B38" ref-type="bibr">38</xref>). This suggests the general applicability of <italic>k</italic>-mer embedding in other biological fields. Notably, the <italic>k</italic>-mer length we used in this study is optimized for typical data volume of thousands of genomes generated in large-scale metagenomic assembly projects. We suggest that researches who may want to use <italic>k</italic>-mer embedding in other scenarios should try different <italic>k</italic>-mer lengths (e.g. 6–12 bp) to finally find a balance between underfitting and overfitting, especially when training on only a few categories.</p>
    <p>Our finding that LSTM surpasses CNN highlights the importance of order and context of oligonucleotides in taxonomic classification. Given the evidence from image classification, CNNs might not take into account the spatial ordering of local motifs (<xref rid="B39" ref-type="bibr">39</xref>). This can have little impact on tasks where only the occurrence of a few nucleotides is the key to classification (e.g. transcription factor binding site detection). However, it is more complex to model taxonomic signatures, such as single-nucleotide variants and insertions and deletions especially for short microbial sequencing reads. In contrast, LSTM understands a <italic>k</italic>-mer better with the help of knowledge from the previous and next k-mer. Hence, ordering and contextual information are retained and passed to the next layer.</p>
    <p>To our knowledge, DeepMicrobes is the first deep learning architecture that incorporates self-attention mechanisms for DNA sequence analysis. The better performance of DeepMicrobes than the other embedding-based models implies that the model should focus on some specific parts of a DNA sequence rather than treat the whole sequence equally. In addition to boosting performance, attention scores potentially provide simple and straightforward method for identifying the regions of the DNA sequences that contribute most to prediction making the algorithm more interpretable than black-box approaches. Other attention architectures, such as hierarchical attention networks (<xref rid="B40" ref-type="bibr">40</xref>) and the Transformer (<xref rid="B41" ref-type="bibr">41</xref>), take up too much memory to be feasible in our task. Nonetheless, their applications on genomic sequences are promising for investigation. Another bonus of the self-attention mechanism is that it enables the model to encode variable-length DNA sequences into a fixed-size representation. As a result, DeepMicrobes can be directly applied to longer DNA sequences such as those generated using long-read sequencing platforms without any modification in the model architecture. However, here we focus on next-generation sequencing reads and retraining might be required to adapt to reads whose lengths and error profiles are strongly different.</p>
    <p>We trained DeepMicrobes on the complete bacterial repertoire of human gut microbiota defined previously. The benchmark results on real sequencing reads show that DeepMicrobes outperforms state-of-the-art taxonomic classification tools in species and genus identification. Specifically, the algorithm of DeepMicrobes produces far fewer false positives than other tools. As for abundance estimation, DeepMicrobes surpasses other tools in genus quantification and performs comparably to them in species quantification.</p>
    <p>We reanalyzed the IBD gut metagenome dataset and discovered potential signatures related to CD, UC or healthy state within these uncultured species, some of which corroborate previous findings at the genus level while others constitute novel findings. This suggests that the uncultured members in gut microbiome might have underappreciated roles in human health and disease. We believe that DeepMicrobes, together with other taxonomic classification tools, will provide a comprehensive picture of microbiome structure and pave the way for the discovery of the functional roles of uncharacterized MGS.</p>
  </sec>
  <sec sec-type="data-availability" id="SEC5">
    <title>DATA AVAILABILITY</title>
    <p>The DeepMicrobes program, trained model parameters, hyperparameters and the implementation of the other DNN architectures are provided at GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/MicrobeLab/DeepMicrobes">https://github.com/MicrobeLab/DeepMicrobes</ext-link>). The sequences of benchmark datasets, the abundance profiles of different taxonomic classification tools on the ten mock communities, the species profiles of the IBD dataset generated with DeepMicrobes, the predicted protein sequences and the custom database for Kaiju are available at GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/MicrobeLab/DeepMicrobes-data">https://github.com/MicrobeLab/DeepMicrobes-data</ext-link>). The command lines used to run the taxonomic classification tools and the R scripts used to generate figures for benchmarking are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/MicrobeLab/DeepMicrobes-data/tree/master/scripts">https://github.com/MicrobeLab/DeepMicrobes-data/tree/master/scripts</ext-link>.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>lqaa009_Supplemental_Files</label>
      <media xlink:href="lqaa009_supplemental_files.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ACK1">
    <title>ACKNOWLEDGEMENTS</title>
    <p>We thank all members of the Wei Laboratory for their support and discussion.</p>
  </ack>
  <sec id="SEC6">
    <title>SUPPLEMENTARY DATA</title>
    <p><ext-link ext-link-type="uri" xlink:href="https://academic.oup.com/nargab/article-lookup/doi/10.1093/nargab/lqaa009#supplementary-data">Supplementary Data</ext-link> are available at NARGAB Online.</p>
  </sec>
  <sec id="SEC7">
    <title>FUNDING</title>
    <p>National Basic Research Program of China [2015CB964601]; National Natural Science Foundation of China [81570828]. Funding for open access charge: National Basic Research Program of China [2015CB964601].</p>
    <p><italic>Conflict of interest statement</italic>. None declared.</p>
  </sec>
  <ref-list id="REF1">
    <title>REFERENCES</title>
    <ref id="B1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Quince</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Walker</surname><given-names>A.W.</given-names></name>, <name name-style="western"><surname>Simpson</surname><given-names>J.T.</given-names></name>, <name name-style="western"><surname>Loman</surname><given-names>N.J.</given-names></name>, <name name-style="western"><surname>Segata</surname><given-names>N.</given-names></name></person-group><article-title>Shotgun metagenomics, from sampling to analysis</article-title>. <source>Nat. Biotechnol.</source><year>2017</year>; <volume>35</volume>:<fpage>833</fpage>–<lpage>844</lpage>.<pub-id pub-id-type="pmid">28898207</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Almeida</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Mitchell</surname><given-names>A.L.</given-names></name>, <name name-style="western"><surname>Boland</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Forster</surname><given-names>S.C.</given-names></name>, <name name-style="western"><surname>Gloor</surname><given-names>G.B.</given-names></name>, <name name-style="western"><surname>Tarkowska</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Lawley</surname><given-names>T.D.</given-names></name>, <name name-style="western"><surname>Finn</surname><given-names>R.D.</given-names></name></person-group><article-title>A new genomic blueprint of the human gut microbiota</article-title>. <source>Nature</source>. <year>2019</year>; <volume>568</volume>:<fpage>499</fpage>–<lpage>504</lpage>.<pub-id pub-id-type="pmid">30745586</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stewart</surname><given-names>R.D.</given-names></name>, <name name-style="western"><surname>Auffret</surname><given-names>M.D.</given-names></name>, <name name-style="western"><surname>Warr</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Walker</surname><given-names>A.W.</given-names></name>, <name name-style="western"><surname>Roehe</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Watson</surname><given-names>M.</given-names></name></person-group><article-title>Compendium of 4, 941 rumen metagenome-assembled genomes for rumen microbiome biology and enzyme discovery</article-title>. <source>Nat. Biotechnol.</source><year>2019</year>; <volume>37</volume>:<fpage>953</fpage>–<lpage>961</lpage>.<pub-id pub-id-type="pmid">31375809</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pasolli</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Asnicar</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Manara</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Zolfo</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Karcher</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Armanini</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Beghini</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Manghi</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Tett</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Ghensi</surname><given-names>P.</given-names></name><etal>et al</etal>.</person-group><article-title>Extensive unexplored human microbiome diversity revealed by over 150, 000 genomes from metagenomes spanning age, Geography, and Lifestyle</article-title>. <source>Cell</source>. <year>2019</year>; <volume>176</volume>:<fpage>649</fpage>–<lpage>662</lpage>.<pub-id pub-id-type="pmid">30661755</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wood</surname><given-names>D.E.</given-names></name>, <name name-style="western"><surname>Salzberg</surname><given-names>S.L.</given-names></name></person-group><article-title>Kraken: ultrafast metagenomic sequence classification using exact alignments</article-title>. <source>Genome Biol.</source><year>2014</year>; <volume>15</volume>:<fpage>R46</fpage>.<pub-id pub-id-type="pmid">24580807</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rosen</surname><given-names>G.L.</given-names></name>, <name name-style="western"><surname>Reichenberger</surname><given-names>E.R.</given-names></name>, <name name-style="western"><surname>Rosenfeld</surname><given-names>A.M.</given-names></name></person-group><article-title>NBC: the naïve Bayes classification tool webserver for taxonomic classification of metagenomic reads</article-title>. <source>Bioinformatics</source>. <year>2011</year>; <volume>27</volume>:<fpage>127</fpage>–<lpage>129</lpage>.<pub-id pub-id-type="pmid">21062764</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vervier</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Mahé</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Tournoud</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Veyrieras</surname><given-names>J.B.</given-names></name>, <name name-style="western"><surname>Vert</surname><given-names>J.P.</given-names></name></person-group><article-title>Large-scale machine learning for metagenomics sequence classification</article-title>. <source>Bioinformatics</source>. <year>2016</year>; <volume>32</volume>:<fpage>1023</fpage>–<lpage>1032</lpage>.<pub-id pub-id-type="pmid">26589281</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>McIntyre</surname><given-names>A.B.R.</given-names></name>, <name name-style="western"><surname>Ounit</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Afshinnekoo</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Prill</surname><given-names>R.J.</given-names></name>, <name name-style="western"><surname>Hénaff</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Alexander</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Minot</surname><given-names>S.S.</given-names></name>, <name name-style="western"><surname>Danko</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Foox</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Ahsanuddin</surname><given-names>S.</given-names></name><etal>et al</etal>.</person-group><article-title>Comprehensive benchmarking and ensemble approaches for metagenomic classifiers</article-title>. <source>Genome Biol.</source><year>2017</year>; <volume>18</volume>:<fpage>182</fpage>–<lpage>200</lpage>.<pub-id pub-id-type="pmid">28934964</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Eraslan</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Avsec</surname><given-names>Ž.</given-names></name>, <name name-style="western"><surname>Gagneur</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Theis</surname><given-names>F.J.</given-names></name></person-group><article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat. Rev. Genet.</source><year>2019</year>; <volume>20</volume>:<fpage>389</fpage>–<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lloyd-Price</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Arze</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Ananthakrishnan</surname><given-names>A.N.</given-names></name>, <name name-style="western"><surname>Schirmer</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Avila-Pacheco</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Poon</surname><given-names>T.W.</given-names></name>, <name name-style="western"><surname>Andrews</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Ajami</surname><given-names>N.J.</given-names></name>, <name name-style="western"><surname>Bonham</surname><given-names>K.S.</given-names></name>, <name name-style="western"><surname>Brislawn</surname><given-names>C.J.</given-names></name><etal>et al</etal>.</person-group><article-title>Multi-omics of the gut microbial ecosystem in inflammatory bowel diseases</article-title>. <source>Nature</source>. <year>2019</year>; <volume>569</volume>:<fpage>655</fpage>–<lpage>662</lpage>.<pub-id pub-id-type="pmid">31142855</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Myers</surname><given-names>J.R.</given-names></name>, <name name-style="western"><surname>Marth</surname><given-names>G.T.</given-names></name></person-group><article-title>ART: a next-generation sequencing read simulator</article-title>. <source>Bioinformatics</source>. <year>2012</year>; <volume>28</volume>:<fpage>593</fpage>–<lpage>594</lpage>.<pub-id pub-id-type="pmid">22199392</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Parks</surname><given-names>D.H.</given-names></name>, <name name-style="western"><surname>Imelfort</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Skennerton</surname><given-names>C.T.</given-names></name>, <name name-style="western"><surname>Hugenholtz</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Tyson</surname><given-names>G.W.</given-names></name></person-group><article-title>CheckM: Assessing the quality of microbial genomes recovered from isolates, single cells, and metagenomes</article-title>. <source>Genome Res.</source><year>2015</year>; <volume>25</volume>:<fpage>1043</fpage>–<lpage>1055</lpage>.<pub-id pub-id-type="pmid">25977477</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ondov</surname><given-names>B.D.</given-names></name>, <name name-style="western"><surname>Treangen</surname><given-names>T.J.</given-names></name>, <name name-style="western"><surname>Melsted</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Mallonee</surname><given-names>A.B.</given-names></name>, <name name-style="western"><surname>Bergman</surname><given-names>N.H.</given-names></name>, <name name-style="western"><surname>Koren</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Phillippy</surname><given-names>A.M.</given-names></name></person-group><article-title>Mash: fast genome and metagenome distance estimation using MinHash</article-title>. <source>Genome Biol.</source><year>2016</year>; <volume>17</volume>:<fpage>132</fpage>.<pub-id pub-id-type="pmid">27323842</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kurtz</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Phillippy</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Delcher</surname><given-names>A.L.</given-names></name>, <name name-style="western"><surname>Smoot</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Shumway</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Antonescu</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Salzberg</surname><given-names>S.L.</given-names></name></person-group><article-title>Versatile and open software for comparing large genomes</article-title>. <source>Genome Biol.</source><year>2004</year>; <volume>5</volume>:<fpage>R12</fpage>.<pub-id pub-id-type="pmid">14759262</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Varghese</surname><given-names>N.J.</given-names></name>, <name name-style="western"><surname>Mukherjee</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Ivanova</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Konstantinidis</surname><given-names>K.T.</given-names></name>, <name name-style="western"><surname>Mavrommatis</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Kyrpides</surname><given-names>N.C.</given-names></name>, <name name-style="western"><surname>Pati</surname><given-names>A.</given-names></name></person-group><article-title>Microbial species delineation using whole genome sequences</article-title>. <source>Nucleic Acids Res.</source><year>2015</year>; <volume>43</volume>:<fpage>6761</fpage>–<lpage>6771</lpage>.<pub-id pub-id-type="pmid">26150420</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jain</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Rodriguez-R</surname><given-names>L.M.</given-names></name>, <name name-style="western"><surname>Phillippy</surname><given-names>A.M.</given-names></name>, <name name-style="western"><surname>Konstantinidis</surname><given-names>K.T.</given-names></name>, <name name-style="western"><surname>Aluru</surname><given-names>S.</given-names></name></person-group><article-title>High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries</article-title>. <source>Nat. Commun.</source><year>2018</year>; <volume>9</volume>:<fpage>5114</fpage>.<pub-id pub-id-type="pmid">30504855</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Forster</surname><given-names>S.C.</given-names></name>, <name name-style="western"><surname>Kumar</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Anonye</surname><given-names>B.O.</given-names></name>, <name name-style="western"><surname>Almeida</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Viciani</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Stares</surname><given-names>M.D.</given-names></name>, <name name-style="western"><surname>Dunn</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Mkandawire</surname><given-names>T.T.</given-names></name>, <name name-style="western"><surname>Zhu</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Shao</surname><given-names>Y.</given-names></name><etal>et al</etal>.</person-group><article-title>A human gut bacterial genome and culture collection for improved metagenomic analyses</article-title>. <source>Nat. Biotechnol.</source><year>2019</year>; <volume>37</volume>:<fpage>186</fpage>–<lpage>192</lpage>.<pub-id pub-id-type="pmid">30718869</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fritz</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Hofmann</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Majda</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Dahms</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Dröge</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Fiedler</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Lesker</surname><given-names>T.R.</given-names></name>, <name name-style="western"><surname>Belmann</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Demaere</surname><given-names>M.Z.</given-names></name>, <name name-style="western"><surname>Darling</surname><given-names>A.E.</given-names></name><etal>et al</etal>.</person-group><article-title>CAMISIM: Simulating metagenomes and microbial communities</article-title>. <source>Microbiome</source>. <year>2019</year>; <volume>7</volume>:<fpage>17</fpage>.<pub-id pub-id-type="pmid">30736849</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Parks</surname><given-names>D.H.</given-names></name>, <name name-style="western"><surname>Rinke</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Chuvochina</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Chaumeil</surname><given-names>P.A.</given-names></name>, <name name-style="western"><surname>Woodcroft</surname><given-names>B.J.</given-names></name>, <name name-style="western"><surname>Evans</surname><given-names>P.N.</given-names></name>, <name name-style="western"><surname>Hugenholtz</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Tyson</surname><given-names>G.W.</given-names></name></person-group><article-title>Recovery of nearly 8,000 metagenome-assembled genomes substantially expands the tree of life</article-title>. <source>Nat. Microbiol.</source><year>2017</year>; <volume>2</volume>:<fpage>1533</fpage>–<lpage>1542</lpage>.<pub-id pub-id-type="pmid">28894102</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ounit</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Wanamaker</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Close</surname><given-names>T.J.</given-names></name>, <name name-style="western"><surname>Lonardi</surname><given-names>S.</given-names></name></person-group><article-title>CLARK: fast and accurate classification of metagenomic and genomic sequences using discriminative k-mers</article-title>. <source>BMC Genomics</source>. <year>2015</year>; <volume>16</volume>:<fpage>236</fpage>.<pub-id pub-id-type="pmid">25879410</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ounit</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Lonardi</surname><given-names>S.</given-names></name></person-group><article-title>Higher classification sensitivity of short metagenomic reads with CLARK-S</article-title>. <source>Bioinformatics</source>. <year>2016</year>; <volume>32</volume>:<fpage>3823</fpage>–<lpage>3825</lpage>.<pub-id pub-id-type="pmid">27540266</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Song</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Breitwieser</surname><given-names>F.P.</given-names></name>, <name name-style="western"><surname>Salzberg</surname><given-names>S.L.</given-names></name></person-group><article-title>Centrifuge: rapid and sensitive classification of metagenomic sequences</article-title>. <source>Genome Res.</source><year>2016</year>; <volume>26</volume>:<fpage>1721</fpage>–<lpage>1729</lpage>.<pub-id pub-id-type="pmid">27852649</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ye</surname><given-names>S.H.</given-names></name>, <name name-style="western"><surname>Siddle</surname><given-names>K.J.</given-names></name>, <name name-style="western"><surname>Park</surname><given-names>D.J.</given-names></name>, <name name-style="western"><surname>Sabeti</surname><given-names>P.C.</given-names></name></person-group><article-title>Benchmarking metagenomics tools for taxonomic classification</article-title>. <source>Cell</source>. <year>2019</year>; <volume>178</volume>:<fpage>779</fpage>–<lpage>794</lpage>.<pub-id pub-id-type="pmid">31398336</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <label>24.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Busia</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Dahl</surname><given-names>G.E.</given-names></name>, <name name-style="western"><surname>Fannjiang</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Alexander</surname><given-names>D.H.</given-names></name>, <name name-style="western"><surname>Dorfman</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Poplin</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>McLean</surname><given-names>C.Y.</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>P.-C.</given-names></name>, <name name-style="western"><surname>DePristo</surname><given-names>M.</given-names></name></person-group><article-title>A deep learning approach to pattern recognition for short DNA sequences</article-title>. <year>2019</year>; <comment>bioRxiv doi:</comment><comment>10 August 2019, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/353474</pub-id>.</mixed-citation>
    </ref>
    <ref id="B25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Marçais</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Kingsford</surname><given-names>C.</given-names></name></person-group><article-title>A fast, lock-free approach for efficient parallel counting of occurrences of k-mers</article-title>. <source>Bioinformatics</source>. <year>2011</year>; <volume>27</volume>:<fpage>764</fpage>–<lpage>770</lpage>.<pub-id pub-id-type="pmid">21217122</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <label>26.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>Z.</given-names></name>, <name name-style="western"><surname>Feng</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Santos</surname><given-names>C.N. dos</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Xiang</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Bengio</surname><given-names>Y.</given-names></name></person-group><article-title>A structured self-attentive sentence embedding</article-title>. <year>2017</year>; <comment>arXiv doi:</comment><comment>09 March 2017, preprint: not peer reviewed</comment><uri xlink:href="https://www.arxiv.org/abs/1703.03130">https://arxiv.org/abs/1703.03130</uri>.</mixed-citation>
    </ref>
    <ref id="B27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Menzel</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Ng</surname><given-names>K.L.</given-names></name>, <name name-style="western"><surname>Krogh</surname><given-names>A.</given-names></name></person-group><article-title>Fast and sensitive taxonomic classification for metagenomics with Kaiju</article-title>. <source>Nat. Commun.</source><year>2016</year>; <volume>7</volume>:<fpage>11257</fpage>.<pub-id pub-id-type="pmid">27071849</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huson</surname><given-names>D.H.</given-names></name>, <name name-style="western"><surname>Beier</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Flade</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Górska</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>El-Hadidi</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Mitra</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Ruscheweyh</surname><given-names>H.J.</given-names></name>, <name name-style="western"><surname>Tappu</surname><given-names>R.</given-names></name></person-group><article-title>MEGAN Community Edition - Interactive exploration and analysis of large-scale microbiome sequencing data</article-title>. <source>PLoS Comput. Biol.</source><year>2016</year>; <volume>12</volume>:<fpage>e1004957</fpage>.<pub-id pub-id-type="pmid">27327495</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hyatt</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>G.-L.</given-names></name>, <name name-style="western"><surname>Locascio</surname><given-names>P.F.</given-names></name>, <name name-style="western"><surname>Land</surname><given-names>M.L.</given-names></name>, <name name-style="western"><surname>Larimer</surname><given-names>F.W.</given-names></name>, <name name-style="western"><surname>Hauser</surname><given-names>L.J.</given-names></name></person-group><article-title>Prodigal: prokaryotic gene recognition and translation initiation site identification</article-title>. <source>BMC Bioinformatics</source>. <year>2010</year>; <volume>11</volume>:<fpage>119</fpage>.<pub-id pub-id-type="pmid">20211023</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bolger</surname><given-names>A.M.</given-names></name>, <name name-style="western"><surname>Lohse</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Usadel</surname><given-names>B.</given-names></name></person-group><article-title>Trimmomatic: A flexible trimmer for Illumina sequence data</article-title>. <source>Bioinformatics</source>. <year>2014</year>; <volume>30</volume>:<fpage>2114</fpage>–<lpage>2120</lpage>.<pub-id pub-id-type="pmid">24695404</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Segata</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Izard</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Waldron</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Gevers</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Miropolsky</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Garrett</surname><given-names>W.S.</given-names></name>, <name name-style="western"><surname>Huttenhower</surname><given-names>C.</given-names></name></person-group><article-title>Metagenomic biomarker discovery and explanation</article-title>. <source>Genome Biol.</source><year>2011</year>; <volume>12</volume>:<fpage>R60</fpage>.<pub-id pub-id-type="pmid">21702898</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <label>32.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Rojas-Carulla</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Tolstikhin</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Luque</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Youngblut</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Ley</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Schölkopf</surname><given-names>B.</given-names></name></person-group><article-title>GeNet: Deep Representations for Metagenomics</article-title>. <year>2019</year>; <comment>arXiv doi:</comment><comment>30 January 2019, preprint: not peer reviewed</comment><uri xlink:href="https://www.arxiv.org/abs/1901.11015">https://arxiv.org/abs/1901.11015</uri>.</mixed-citation>
    </ref>
    <ref id="B33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sundaram</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Gao</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Padigepati</surname><given-names>S.R.</given-names></name>, <name name-style="western"><surname>McRae</surname><given-names>J.F.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Kosmicki</surname><given-names>J.A.</given-names></name>, <name name-style="western"><surname>Fritzilas</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Hakenberg</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Dutta</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Shon</surname><given-names>J.</given-names></name><etal>et al</etal>.</person-group><article-title>Predicting the clinical impact of human mutation with deep neural networks</article-title>. <source>Nat. Genet.</source><year>2018</year>; <volume>50</volume>:<fpage>1161</fpage>–<lpage>1170</lpage>.<pub-id pub-id-type="pmid">30038395</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Quang</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>X.</given-names></name></person-group><article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>. <source>Nucleic Acids Res.</source><year>2016</year>; <volume>44</volume>:<fpage>e107</fpage>.<pub-id pub-id-type="pmid">27084946</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Segata</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Waldron</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Ballarini</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Narasimhan</surname><given-names>V.</given-names></name>, <name name-style="western"><surname>Jousson</surname><given-names>O.</given-names></name>, <name name-style="western"><surname>Huttenhower</surname><given-names>C.</given-names></name></person-group><article-title>Metagenomic microbial community profiling using unique clade-specific marker genes</article-title>. <source>Nat. Methods</source>. <year>2012</year>; <volume>9</volume>:<fpage>811</fpage>–<lpage>814</lpage>.<pub-id pub-id-type="pmid">22688413</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <label>36.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Castro</surname><given-names>F.M.</given-names></name>, <name name-style="western"><surname>Marín-Jiménez</surname><given-names>M.J.</given-names></name>, <name name-style="western"><surname>Guil</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Schmid</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Alahari</surname><given-names>K.</given-names></name></person-group><person-group person-group-type="editor"><name name-style="western"><surname>Ferrari</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Hebert</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sminchisescu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Weiss</surname><given-names>Y</given-names></name></person-group><article-title>End-to-End Incremental Learning</article-title>. <source>Proceedings of the European Conference on Computer Vision (ECCV)</source>. <year>2018</year>; <publisher-loc>Germany</publisher-loc><publisher-name>Springer International Publishing</publisher-name><fpage>241</fpage>–<lpage>257</lpage>.</mixed-citation>
    </ref>
    <ref id="B37">
      <label>37.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Xiao</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Peng</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>Z.</given-names></name></person-group><article-title>Error-Driven Incremental Learning in Deep Convolutional Neural Network for Large-Scale Image Classification</article-title>. <source>Proceedings of the 22nd ACM international conference on Multimedia</source>. <year>2014</year>; <publisher-loc>Orlando</publisher-loc><publisher-name>ASSOC COMPUTING MACHINERY</publisher-name><fpage>177</fpage>–<lpage>186</lpage>.</mixed-citation>
    </ref>
    <ref id="B38">
      <label>38.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>Z.</given-names></name>, <name name-style="western"><surname>Bao</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>D.-S.</given-names></name></person-group><article-title>Recurrent neural network for predicting transcription factor binding sites</article-title>. <source>Sci. Rep.</source><year>2018</year>; <volume>8</volume>:<fpage>15270</fpage>.<pub-id pub-id-type="pmid">30323198</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <label>39.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Brendel</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M.</given-names></name></person-group><article-title>Approximating CNNs with bag-of-local-features models works surprisingly well on ImageNet</article-title>. <year>2019</year>; <comment>arXiv doi:</comment><comment>20 March 2019, preprint: not peer reviewed</comment><uri xlink:href="https://www.arxiv.org/abs/1904.00760">https://arxiv.org/abs/1904.00760</uri>.</mixed-citation>
    </ref>
    <ref id="B40">
      <label>40.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Sinha</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Dong</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Cheung</surname><given-names>J.C.K.</given-names></name>, <name name-style="western"><surname>Ruths</surname><given-names>D.</given-names></name></person-group><person-group person-group-type="editor"><name name-style="western"><surname>Riloff</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Chiang</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Hockenmaier</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Tsujii</surname><given-names>J</given-names></name></person-group><article-title>A hierarchical neural attention-based text classifier</article-title>. <source>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</source>. <year>2018</year>; <publisher-loc>Brussels</publisher-loc><publisher-name>Association for Computational Linguistics</publisher-name><fpage>817</fpage>–<lpage>823</lpage>.</mixed-citation>
    </ref>
    <ref id="B41">
      <label>41.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Vaswani</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Shazeer</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Parmar</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Uszkoreit</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Gomez</surname><given-names>A.N.</given-names></name>, <name name-style="western"><surname>Kaiser</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Polosukhin</surname><given-names>I.</given-names></name></person-group><person-group person-group-type="editor"><name name-style="western"><surname>Guyon</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Luxburg</surname><given-names>UV</given-names></name>, <name name-style="western"><surname>Bengio</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Wallach</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Fergus</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Vishwanathan</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Garnett</surname><given-names>R</given-names></name></person-group><article-title>Attention is all you need</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2017</year>; <publisher-loc>Long Beach</publisher-loc><publisher-name>Neural information processing systems (NIPS)</publisher-name><fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
