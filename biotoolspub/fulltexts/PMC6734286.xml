<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Genome Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genome Biol</journal-id>
    <journal-title-group>
      <journal-title>Genome Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1474-7596</issn>
    <issn pub-type="epub">1474-760X</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6734286</article-id>
    <article-id pub-id-type="publisher-id">1795</article-id>
    <article-id pub-id-type="doi">10.1186/s13059-019-1795-z</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A comparison of automatic cell identification methods for single-cell RNA sequencing data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Abdelaal</surname>
          <given-names>Tamim</given-names>
        </name>
        <address>
          <email>t.r.m.abdelaal-1@tudelft.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Michielsen</surname>
          <given-names>Lieke</given-names>
        </name>
        <address>
          <email>l.c.m.michielsen@student.tudelft.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cats</surname>
          <given-names>Davy</given-names>
        </name>
        <address>
          <email>d.cats@lumc.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hoogduin</surname>
          <given-names>Dylan</given-names>
        </name>
        <address>
          <email>ddhoogduin@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mei</surname>
          <given-names>Hailiang</given-names>
        </name>
        <address>
          <email>H.Mei@lumc.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Reinders</surname>
          <given-names>Marcel J. T.</given-names>
        </name>
        <address>
          <email>m.j.t.reinders@tudelft.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8601-2149</contrib-id>
        <name>
          <surname>Mahfouz</surname>
          <given-names>Ahmed</given-names>
        </name>
        <address>
          <email>a.mahfouz@lumc.nl</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000089452978</institution-id><institution-id institution-id-type="GRID">grid.10419.3d</institution-id><institution>Leiden Computational Biology Center, </institution><institution>Leiden University Medical Center, </institution></institution-wrap>Einthovenweg 20, 2333 ZC Leiden, The Netherlands </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 4740</institution-id><institution-id institution-id-type="GRID">grid.5292.c</institution-id><institution>Delft Bioinformatics Laboratory, </institution><institution>Delft University of Technology, </institution></institution-wrap>Van Mourik Broekmanweg 6, 2628 XE Delft, The Netherlands </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000000089452978</institution-id><institution-id institution-id-type="GRID">grid.10419.3d</institution-id><institution>Sequencing Analysis Support Core, Department of Biomedical Data Sciences, </institution><institution>Leiden University Medical Center, </institution></institution-wrap>Einthovenweg 20, 2333 ZC Leiden, The Netherlands </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>9</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>9</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <elocation-id>194</elocation-id>
    <history>
      <date date-type="received">
        <day>18</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>8</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s). 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Single-cell transcriptomics is rapidly advancing our understanding of the cellular composition of complex tissues and organisms. A major limitation in most analysis pipelines is the reliance on manual annotations to determine cell identities, which are time-consuming and irreproducible. The exponential growth in the number of cells and samples has prompted the adaptation and development of supervised classification methods for automatic cell identification.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here, we benchmarked 22 classification methods that automatically assign cell identities including single-cell-specific and general-purpose classifiers. The performance of the methods is evaluated using 27 publicly available single-cell RNA sequencing datasets of different sizes, technologies, species, and levels of complexity. We use 2 experimental setups to evaluate the performance of each method for within dataset predictions (intra-dataset) and across datasets (inter-dataset) based on accuracy, percentage of unclassified cells, and computation time. We further evaluate the methods’ sensitivity to the input features, number of cells per population, and their performance across different annotation levels and datasets. We find that most classifiers perform well on a variety of datasets with decreased accuracy for complex datasets with overlapping classes or deep annotations. The general-purpose support vector machine classifier has overall the best performance across the different experiments.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">We present a comprehensive evaluation of automatic cell identification methods for single-cell RNA sequencing data. All the code used for the evaluation is available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/tabdelaal/scRNAseq_Benchmark">https://github.com/tabdelaal/scRNAseq_Benchmark</ext-link>). Additionally, we provide a Snakemake workflow to facilitate the benchmarking and to support the extension of new methods and new datasets.</p>
      </sec>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (10.1186/s13059-019-1795-z) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>scRNA-seq</kwd>
      <kwd>Benchmark</kwd>
      <kwd>Classification</kwd>
      <kwd>Cell identity</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>European Commission H2020 MSCA</institution>
        </funding-source>
        <award-id>675743</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par4">Single-cell RNA sequencing (scRNA-seq) provides unprecedented opportunities to identify and characterize the cellular composition of complex tissues. Rapid and continuous technological advances over the past decade have allowed scRNA-seq technologies to scale to thousands of cells per experiment [<xref ref-type="bibr" rid="CR1">1</xref>]. A common analysis step in analyzing single-cell data involves the identification of cell populations presented in a given dataset. This task is typically solved by unsupervised clustering of cells into groups based on the similarity of their gene expression profiles, followed by cell population annotation by assigning labels to each cluster. This approach proved very valuable in identifying novel cell populations and resulted in cellular maps of entire cell lineages, organs, and even whole organisms [<xref ref-type="bibr" rid="CR2">2</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. However, the annotation step is cumbersome and time-consuming as it involves manual inspection of cluster-specific marker genes. Additionally, manual annotations, which are often not based on standardized ontologies of cell labels, are not reproducible across different experiments within and across research groups. These caveats become even more pronounced as the number of cells and samples increases, preventing fast and reproducible annotations.</p>
    <p id="Par5">To overcome these challenges, a growing number of classification approaches are being adapted to automatically label cells in scRNA-seq experiments. scRNA-seq classification methods predict the identity of each cell by learning these identities from annotated training data (e.g., a reference atlas). scRNA-seq classification methods are relatively new compared to the plethora of methods addressing different computational aspects of single-cell analysis (such as normalization, clustering, and trajectory inference). However, the number of classification methods is rapidly growing to address the aforementioned challenges [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>]. While all scRNA-seq classification methods share a common goal, i.e., accurate annotation of cells, they differ in terms of their underlying algorithms and the incorporation of prior knowledge (e.g., cell type marker gene tables).</p>
    <p id="Par6">In contrast to the extensive evaluations of clustering, differential expression, and trajectory inference methods [<xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR12">12</xref>], there is currently one single attempt comparing methods to assign cell type labels to cell clusters [<xref ref-type="bibr" rid="CR13">13</xref>]. The lack of a comprehensive comparison of scRNA-seq classification methods leaves users without indications as to which classification method best fits their problem. More importantly, a proper assessment of the existing approaches in comparison with the baseline methods can greatly benefit new developments in the field and prevent unnecessary complexity.</p>
    <p id="Par7">Here, we benchmarked 22 classification methods to automatically assign cell identities including single-cell-specific and general-purpose classifiers. The methods were evaluated using 27 publicly available single-cell RNA sequencing datasets of different sizes, technologies, species, and complexity. The performance of the methods was evaluated based on their accuracy, percentage of unclassified cells, and computation time. We performed several experiments to cover different levels of challenge in the classification task and to test specific features or tasks such as the feature selection, scalability, and rejection experiments. We evaluated the classification performance through two experimental setups: (1) intra-dataset in which we applied 5-fold cross-validation within each dataset and (2) inter-dataset involving across datasets comparisons. The inter-dataset comparison is more realistic and more practical, where a reference dataset (e.g., atlas) is used to train a classifier which can then be applied to identify cells in new unannotated datasets. However, in order to perform well across datasets, the classifier should also perform well using the intra-dataset setup on the reference dataset. The intra-dataset experiments, albeit artificial, provide an ideal scenario to evaluate different aspects of the classification process (e.g., feature selection, scalability, and different annotation levels), regardless of the technical and biological variations across datasets. In general, most classifiers perform well across all datasets in both experimental setups (inter- and intra-dataset), including the general-purpose classifiers. In our experiments, incorporating prior knowledge in the form of marker genes does not improve the performance. We observed large variation across different methods in the computation time and classification performance in response to changing the input features and the number of cells. Our results highlight the general-purpose support vector machine (<italic>SVM</italic>) classifier as the best performer overall.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>Benchmarking automatic cell identification methods (intra-dataset evaluation)</title>
      <p id="Par8">We benchmarked the performance and computation time of all 22 classifiers (Table <xref rid="Tab1" ref-type="table">1</xref>) across 11 datasets used for intra-dataset evaluation (Table <xref rid="Tab2" ref-type="table">2</xref>). Classifiers were divided into two categories: (1) supervised methods which require a training dataset labeled with the corresponding cell populations in order to train the classifier or (2) prior-knowledge methods, for which either a marker gene file is required as an input or a pretrained classifier for specific cell populations is provided.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Automatic cell identification methods included in this study</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Name</th><th>Version</th><th>Language</th><th>Underlying classifier</th><th>Prior knowledge</th><th>Rejection option</th><th>Reference</th></tr></thead><tbody><tr><td>Garnett</td><td>0.1.4</td><td>R</td><td>Generalized linear model</td><td>Yes</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR14">14</xref>]</td></tr><tr><td>Moana</td><td>0.1.1</td><td>Python</td><td>SVM with linear kernel</td><td>Yes</td><td>No</td><td>[<xref ref-type="bibr" rid="CR15">15</xref>]</td></tr><tr><td>DigitalCellSorter</td><td>GitHub version: e369a34</td><td>Python</td><td>Voting based on cell type markers</td><td>Yes</td><td>No</td><td>[<xref ref-type="bibr" rid="CR16">16</xref>]</td></tr><tr><td>SCINA</td><td>1.1.0</td><td>R</td><td>Bimodal distribution fitting for marker genes</td><td>Yes</td><td>No</td><td>[<xref ref-type="bibr" rid="CR17">17</xref>]</td></tr><tr><td>scVI</td><td>0.3.0</td><td>Python</td><td>Neural network</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR18">18</xref>]</td></tr><tr><td>Cell-BLAST</td><td>0.1.2</td><td>Python</td><td>Cell-to-cell similarity</td><td>No</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR19">19</xref>]</td></tr><tr><td>ACTINN</td><td>GitHub version: 563bcc1</td><td>Python</td><td>Neural network</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR20">20</xref>]</td></tr><tr><td>LAmbDA</td><td>GitHub version: 3891d72</td><td>Python</td><td>Random forest</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR21">21</xref>]</td></tr><tr><td>scmapcluster</td><td>1.5.1</td><td>R</td><td>Nearest median classifier</td><td>No</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR22">22</xref>]</td></tr><tr><td>scmapcell</td><td>1.5.1</td><td>R</td><td>kNN</td><td>No</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR22">22</xref>]</td></tr><tr><td>scPred</td><td>0.0.0.9000</td><td>R</td><td>SVM with radial kernel</td><td>No</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR23">23</xref>]</td></tr><tr><td>CHETAH</td><td>0.99.5</td><td>R</td><td>Correlation to training set</td><td>No</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR24">24</xref>]</td></tr><tr><td>CaSTLe</td><td>GitHub version: 258b278</td><td>R</td><td>Random forest</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR25">25</xref>]</td></tr><tr><td>SingleR</td><td>0.2.2</td><td>R</td><td>Correlation to training set</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR26">26</xref>]</td></tr><tr><td>scID</td><td>0.0.0.9000</td><td>R</td><td>LDA</td><td>No</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR27">27</xref>]</td></tr><tr><td>singleCellNet</td><td>0.1.0</td><td>R</td><td>Random forest</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR28">28</xref>]</td></tr><tr><td>LDA</td><td>0.19.2</td><td>Python</td><td>LDA</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR29">29</xref>]</td></tr><tr><td>NMC</td><td>0.19.2</td><td>Python</td><td>NMC</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR29">29</xref>]</td></tr><tr><td>RF</td><td>0.19.2</td><td>Python</td><td>RF (50 trees)</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR29">29</xref>]</td></tr><tr><td>SVM</td><td>0.19.2</td><td>Python</td><td>SVM (linear kernel)</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR29">29</xref>]</td></tr><tr><td>SVM<sub>rejection</sub></td><td>0.19.2</td><td>Python</td><td>SVM (linear kernel)</td><td>No</td><td>Yes</td><td>[<xref ref-type="bibr" rid="CR29">29</xref>]</td></tr><tr><td>kNN</td><td>0.19.2</td><td>Python</td><td>kNN (<italic>k</italic> = 9)</td><td>No</td><td>No</td><td>[<xref ref-type="bibr" rid="CR29">29</xref>]</td></tr></tbody></table></table-wrap>
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Overview of the datasets used during this study</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>No. of cells</th><th>No. of genes</th><th>No. of cell populations (&gt; 10 cells)</th><th>Description</th><th>Protocol</th><th>Reference</th></tr></thead><tbody><tr><td>Baron (Mouse)<sup>a</sup></td><td>1886</td><td>14,861</td><td>13 (9)</td><td>Mouse pancreas</td><td>inDrop</td><td>[<xref ref-type="bibr" rid="CR30">30</xref>]</td></tr><tr><td>Baron (Human)<sup>a,b</sup></td><td>8569</td><td>17,499</td><td>14 (13)</td><td>Human pancreas</td><td>inDrop</td><td>[<xref ref-type="bibr" rid="CR30">30</xref>]</td></tr><tr><td>Muraro<sup>a,b</sup></td><td>2122</td><td>18,915</td><td>9 (8)</td><td>Human pancreas</td><td>CEL-Seq2</td><td>[<xref ref-type="bibr" rid="CR31">31</xref>]</td></tr><tr><td>Segerstolpe<sup>a,b</sup></td><td>2133</td><td>22,757</td><td>13 (9)</td><td>Human pancreas</td><td>SMART-Seq2</td><td>[<xref ref-type="bibr" rid="CR32">32</xref>]</td></tr><tr><td>Xin<sup>a,b</sup></td><td>1449</td><td>33,889</td><td>4 (4)</td><td>Human pancreas</td><td>SMARTer</td><td>[<xref ref-type="bibr" rid="CR33">33</xref>]</td></tr><tr><td>CellBench 10X<sup>a,b</sup></td><td>3803</td><td>11,778</td><td>5 (5)</td><td>Mixture of five human lung cancer cell lines</td><td>10X chromium</td><td>[<xref ref-type="bibr" rid="CR34">34</xref>]</td></tr><tr><td>CellBench CEL-Seq2<sup>a,b</sup></td><td>570</td><td>12,627</td><td>5 (5)</td><td>Mixture of five human lung cancer cell lines</td><td>CEL-Seq2</td><td>[<xref ref-type="bibr" rid="CR34">34</xref>]</td></tr><tr><td>TM<sup>a</sup></td><td>54,865</td><td>19,791</td><td>55 (55)</td><td>Whole <italic>Mus musculus</italic></td><td>SMART-Seq2</td><td>[<xref ref-type="bibr" rid="CR6">6</xref>]</td></tr><tr><td>AMB<sup>a</sup></td><td>12,832</td><td>42,625</td><td>4/22/110 (3/16/92)</td><td>Primary mouse visual cortex</td><td>SMART-Seq v4</td><td>[<xref ref-type="bibr" rid="CR35">35</xref>]</td></tr><tr><td>Zheng sorted<sup>a</sup></td><td>20,000</td><td>21,952</td><td>10 (10)</td><td>FACS-sorted PBMC</td><td>10X CHROMIUM</td><td>[<xref ref-type="bibr" rid="CR36">36</xref>]</td></tr><tr><td>Zheng 68K<sup>a</sup></td><td>65,943</td><td>20,387</td><td>11 (11)</td><td>PBMC</td><td>10X CHROMIUM</td><td>[<xref ref-type="bibr" rid="CR36">36</xref>]</td></tr><tr><td>VISp<sup>b</sup> (Mouse)</td><td>12,832</td><td>42,625</td><td>3/36 (3/34)</td><td>Primary visual cortex</td><td>SMART-Seq v4</td><td>[<xref ref-type="bibr" rid="CR35">35</xref>]</td></tr><tr><td>ALM<sup>b</sup> (Mouse)</td><td>8758</td><td>42,461</td><td>3/37 (3/34)</td><td>Anterior lateral motor area</td><td>SMART-Seq v4</td><td>[<xref ref-type="bibr" rid="CR35">35</xref>]</td></tr><tr><td>MTG<sup>b</sup> (Human)</td><td>14,636</td><td>16,161</td><td>3/35 (3/34)</td><td>Middle temporal gyrus</td><td>SMART-Seq v4</td><td>[<xref ref-type="bibr" rid="CR37">37</xref>]</td></tr><tr><td>PbmcBench pbmc1.10Xv2<sup>b</sup></td><td>6444</td><td>33,694</td><td>9 (9)</td><td>PBMC</td><td>10X version 2</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc1.10Xv3<sup>b</sup></td><td>3222</td><td>33,694</td><td>8 (8)</td><td>PBMC</td><td>10X version 3</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc1.CL<sup>b</sup></td><td>253</td><td>33,694</td><td>7 (7)</td><td>PBMC</td><td>CEL-Seq2</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc1.DR<sup>b</sup></td><td>3222</td><td>33,694</td><td>9 (9)</td><td>PBMC</td><td>Drop-Seq</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc1.iD<sup>b</sup></td><td>3222</td><td>33,694</td><td>7 (7)</td><td>PBMC</td><td>inDrop</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc1.SM2<sup>b</sup></td><td>253</td><td>33,694</td><td>6 (6)</td><td>PBMC</td><td>SMART-Seq2</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc1.SW<sup>b</sup></td><td>3176</td><td>33,694</td><td>7 (7)</td><td>PBMC</td><td>Seq-Well</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc2.10Xv2<sup>,b</sup></td><td>3362</td><td>33,694</td><td>9 (9)</td><td>PBMC</td><td>10X version 2</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc2.CL<sup>b</sup></td><td>273</td><td>33,694</td><td>5 (5)</td><td>PBMC</td><td>CEL-Seq2</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc2.DR<sup>b</sup></td><td>3362</td><td>33,694</td><td>6 (6)</td><td>PBMC</td><td>Drop-Seq</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc2.iD<sup>b</sup></td><td>3362</td><td>33,694</td><td>9 (9)</td><td>PBMC</td><td>inDrop</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc2.SM2<sup>b</sup></td><td>273</td><td>33,694</td><td>6 (6)</td><td>PBMC</td><td>SMART-Seq2</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr><tr><td>PbmcBench pbmc2.SW<sup>b</sup></td><td>551</td><td>33,694</td><td>4 (4)</td><td>PBMC</td><td>Seq-Well</td><td>[<xref ref-type="bibr" rid="CR38">38</xref>]</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>Used for intra-dataset evaluation</p><p><sup>b</sup>Used for inter-dataset evaluation</p></table-wrap-foot></table-wrap></p>
      <p id="Par9">The datasets used in this study vary in the number of cells, genes, and cell populations (annotation level), in order to represent different levels of challenges in the classification task and to evaluate how each classifier performs in each case (Table <xref rid="Tab2" ref-type="table">2</xref>). They include relatively typical sized scRNA-seq datasets (1500–8500 cells), such as the 5 pancreatic datasets (Baron Mouse, Baron Human, Muraro, Segerstolpe, and Xin), which include both mouse and human pancreatic cells and vary in the sequencing protocol used. The Allen Mouse Brain (AMB) dataset is used to evaluate how the classification performance changes when dealing with different levels of cell population annotation as the AMB dataset contains three levels of annotations for each cell (3, 16, or 92 cell populations), denoted as AMB3, AMB16, and AMB92, respectively. The Tabula Muris (TM) and Zheng 68K datasets represent relatively large scRNA-seq datasets (&gt; 50,000 cells) and are used to assess how well the classifiers scale with large datasets. For all previous datasets, cell populations were obtained through clustering. To assess how the classifiers perform when dealing with sorted populations, we included the CellBench dataset and the Zheng sorted dataset, representing sorted populations for lung cancer cell lines and peripheral blood mononuclear cells (PBMC), respectively. Including the Zheng sorted and Zheng 68K datasets allows the benchmarking of 4 prior-knowledge classifiers, since the marker gene files or pretrained classifiers are available for the 4 classifiers for PBMCs.</p>
    </sec>
    <sec id="Sec4">
      <title>All classifiers perform well in intra-dataset experiments</title>
      <p id="Par10">Generally, all classifiers perform well in the intra-dataset experiments, including the general-purpose classifiers (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). However, <italic>Cell-BLAST</italic> performs poorly for the Baron Mouse and Segerstople pancreatic datasets. Further, <italic>scVI</italic> has low performance on the deeply annotated datasets TM (55 cell populations) and AMB92 (92 cell populations), and <italic>kNN</italic> produces low performance for the Xin and AMB92 datasets.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Performance comparison of supervised classifiers for cell identification using different scRNA-seq datasets. Heatmap of the <bold>a</bold> median F1-scores and <bold>b</bold> percentage of unlabeled cells across all cell populations per classifier (rows) per dataset (columns). Gray boxes indicate that the corresponding method could not be tested on the corresponding dataset. Classifiers are ordered based on the mean of the median F1-scores. Asterisk (*) indicates that the prior-knowledge classifiers, <italic>SCINA</italic>, <italic>DigitalCellSorter</italic>, <italic>Garnett</italic><sub><italic>CV</italic></sub>, <italic>Garnett</italic><sub><italic>pretrained</italic></sub>, and <italic>Moana</italic>, could not be tested on all cell populations of the PBMC datasets. <italic>SCINA</italic><sub><italic>DE</italic></sub>, <italic>Garnett</italic><sub><italic>DE</italic></sub>, and <italic>DigitalCellSorter</italic><sub><italic>DE</italic></sub> are versions of <italic>SCINA</italic>, <italic>Garnett</italic><sub><italic>CV</italic></sub>, and <italic>DigitalCellSorter</italic>; the marker genes are defined using differential expression from the training data. Different numbers of marker genes, 5, 10, 15, and 20, were tested, and the best result is shown here. <italic>SCINA</italic>, <italic>Garnett</italic>, and <italic>DigitalCellSorter</italic> produced the best result for the Zheng sorted dataset using 20, 15, and 5 markers, and for the Zheng 68K dataset using 10, 5, and 5 markers, respectively</p></caption><graphic xlink:href="13059_2019_1795_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par11">For the pancreatic datasets, the best-performing classifiers are <italic>SVM</italic>, <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scPred</italic>, <italic>scmapcell</italic>, <italic>scmapcluster</italic>, <italic>scVI</italic>, <italic>ACTINN</italic>, <italic>singleCellNet</italic>, <italic>LDA</italic>, and <italic>NMC</italic>. <italic>SVM</italic> is the only classifier to be in the top five list for all five pancreatic datasets, while <italic>NMC</italic>, for example, appears only in the top five list for the Xin dataset. The Xin dataset contains only four pancreatic cell types (alpha, beta, delta, and gamma) making the classification task relatively easy for all classifiers, including <italic>NMC</italic>. Considering the median F1-score alone to judge the classification performance can be misleading since some classifiers incorporate a rejection option (e.g., <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scmapcell</italic>, <italic>scPred</italic>), by which a cell is assigned as “unlabeled” if the classifier is not confident enough. For example, for the Baron Human dataset, the median F1-score for <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scmapcell</italic>, <italic>scPred</italic>, and <italic>SVM</italic> is 0.991, 0.984, 0.981, and 0.980, respectively (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a). However, <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scmapcell</italic>, and <italic>scPred</italic> assigned 1.5%, 4.2%, and 10.8% of the cells, respectively, as unlabeled while <italic>SVM</italic> (without rejection) classified 100% of the cells with a median F1-score of 0.98 (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b). This shows an overall better performance for <italic>SVM</italic> and <italic>SVM</italic><sub><italic>rejection</italic></sub>, with higher performance and less unlabeled cells.</p>
      <p id="Par12">The CellBench 10X and CEL-Seq2 datasets represent an easy classification task, where the five sorted lung cancer cell lines are quite separable [<xref ref-type="bibr" rid="CR34">34</xref>]. All classifiers have an almost perfect performance on both CellBench datasets (median F1-score ≈ 1).</p>
      <p id="Par13">For the TM dataset, the top five performing classifiers are <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>SVM</italic>, <italic>scmapcell</italic>, <italic>Cell-BLAST</italic>, and <italic>scPred</italic> with a median F1-score &gt; 0.96, showing that these classifiers can perform well and scale to large scRNA-seq datasets with a deep level of annotation. Furthermore, <italic>scmapcell</italic> and <italic>scPred</italic> assigned 9.5% and 17.7% of the cells, respectively, as unlabeled, which shows a superior performance for <italic>SVM</italic><sub><italic>rejection</italic></sub> and <italic>SVM</italic>, with a higher median F1-score and 2.9% and 0% unlabeled cells, respectively.</p>
    </sec>
    <sec id="Sec5">
      <title>Performance evaluation across different annotation levels</title>
      <p id="Par14">We used the AMB dataset with its three different levels of annotations, to evaluate the classifiers’ performance behavior with an increasing number of smaller cell populations within the same dataset. For AMB3, the classification task is relatively easy, differentiating between three major brain cell types (inhibitory neurons, esxcitatory neurons, and non-neuronal). All classifiers perform almost perfectly with a median F1-score &gt; 0.99 (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a). For AMB16, the classification task becomes slightly more challenging and the performance of some classifiers drops, especially <italic>kNN</italic>. The top five classifiers are <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scmapcell</italic>, <italic>scPred</italic>, <italic>SVM</italic>, and <italic>ACTINN</italic>, where <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scmapcell</italic>, and <italic>scPred</italic> assigned 1.1%, 4.9%, and 8.4% of the cells as unlabeled, respectively. For the deeply annotated AMB92 dataset, the performance of all classifiers drops further, specially for <italic>kNN</italic> and <italic>scVI</italic>, where the median F1-score is 0.130 and zero, respectively. The top five classifiers are <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scmapcell</italic>, <italic>SVM</italic>, <italic>LDA</italic>, and <italic>scmapcluster</italic>, with <italic>SVM</italic><sub><italic>rejection</italic></sub> assigning less cells as unlabeled compared to <italic>scmapcell</italic> (19.8% vs 41.9%), and once more, <italic>SVM</italic><sub><italic>rejection</italic></sub> shows improved performance over <italic>scmapcell</italic> (median F1-score of 0.981 vs 0.906). These results show an overall superior performance for general-purpose classifiers (<italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>SVM</italic>, and <italic>LDA</italic>) compared to other scRNA-seq-specific classifiers across different levels of cell population annotation.</p>
      <p id="Par15">Instead of only looking at the median F1-score, we also evaluated the F1-score per cell population for each classifier (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1). We confirmed previous conclusions that <italic>kNN</italic> performance drops with deep annotations which include smaller cell populations (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1B-C), and <italic>scVI</italic> poorly performs on the deeply annotated AMB92 dataset. Additionally, we observed that some cell populations are much harder to classify compared to other populations. For example, most classifiers had a low performance on the <italic>Serpinf1</italic> cells in the AMB16 dataset.</p>
    </sec>
    <sec id="Sec6">
      <title>Incorporating prior-knowledge does not improve intra-dataset performance on PBMC data</title>
      <p id="Par16">For the two PBMC datasets (Zheng 68K and Zheng sorted), the prior-knowledge classifiers <italic>Garnett</italic>, <italic>Moana</italic>, <italic>DigitalCellSorter</italic>, and <italic>SCINA</italic> could be evaluated and benchmarked with the rest of the classifiers. Although the best-performing classifier on Zheng 68K is <italic>SCINA</italic> with a median F1-score of 0.998, this performance is based only on 3, out of 11, cell populations (Monocytes, B cells, and NK cells) for which marker genes are provided. Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1 summarizes which PBMC cell populations can be classified by the prior-knowledge methods. Interestingly, none of the prior-knowledge methods showed superior performance compared to other classifiers, despite the advantage these classifiers have over other classifiers given they are tested on fewer cell populations due to the limited availability of marker genes. <italic>Garnett</italic>, <italic>Moana</italic>, and <italic>DigitalCellSorter</italic> could be tested on 7, 7, and 5 cell populations, respectively (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1). Besides <italic>SCINA</italic>, the top classifiers for the Zheng 68K dataset are <italic>CaSTLe</italic>, <italic>ACTINN</italic>, <italic>singleCellNet</italic>, and <italic>SVM</italic>. <italic>SVM</italic><sub><italic>rejection</italic></sub> and <italic>Cell-BLAST</italic> show high performance, at the expense of a high rejection rate of 61.8% and 29%, respectively (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Moreover, <italic>scPred</italic> failed when tested on the Zheng 68K dataset. Generally, all classifiers show relatively lower performance on the Zheng 68K dataset compared to other datasets, as the Zheng 68K dataset contains 11 immune cell populations which are harder to differentiate, particularly the T cell compartment (6 out of 11 cell populations). This difficulty of separating these populations was previously noted in the original study [<xref ref-type="bibr" rid="CR36">36</xref>]. Also, the confusion matrices for <italic>CaSTLe</italic>, <italic>ACTINN</italic>, <italic>singleCellNet</italic>, and <italic>SVM</italic> clearly indicate the high similarity between cell populations, such as (1) monocytes with dendritic cells, (2) the 2 CD8+ T populations, and (3) the 4 CD4+ T populations (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S2).</p>
      <p id="Par17">The classification of the Zheng sorted dataset is relatively easier compared to the Zheng 68K dataset, as almost all classifiers show improved performance (Fig. <xref rid="Fig1" ref-type="fig">1</xref>), with the exception that <italic>LAmbDA</italic> failed while being tested on the Zheng sorted dataset. The prior-knowledge methods show high performance (median F1-score &gt; 0.93), which is still comparable to other classifiers such as <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>scVI</italic>, <italic>scPred</italic>, and <italic>SVM</italic>. Yet, the supervised classifiers do not require any marker genes, and they can predict more (all) cell populations.</p>
    </sec>
    <sec id="Sec7">
      <title>The performance of prior-knowledge classifiers strongly depends on the selected marker genes</title>
      <p id="Par18">Some prior-knowledge classifiers, <italic>SCINA</italic>, <italic>DigitalCellSorter</italic>, and <italic>Garnett</italic><sub><italic>CV</italic></sub>, used marker genes to classify the cells. For the PBMC datasets, the number of marker genes per cell population varies across classifiers (2–161 markers) and the marker genes show very little overlap. Only one B cell marker gene, CD79A, is shared by all classifiers while none of the marker genes for the other cell populations is shared by the three classifiers. We analyzed the effect of the number of marker genes, mean expression, dropout rate, and the specificity of each marker gene (beta score, see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section) on the performance of the classifier (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S3). The dropout rate and marker specificity (beta-score) are strongly correlated with the median F1-score, highlighting that the performance does not only depend on biological knowledge, but also on technical factors.</p>
      <p id="Par19">The difference between the marker genes used by each method underscores the challenge of marker gene selection, especially for smaller cell populations. Moreover, public databases of cell type markers (e.g., PanglaoDB [<xref ref-type="bibr" rid="CR39">39</xref>] and CellMarker [<xref ref-type="bibr" rid="CR40">40</xref>]) often provide different markers for the same population. For example, CellMarker provides 33 marker genes for B cells, while PanglaoDB provides 110 markers, with only 11 marker genes overlap between the two databases.</p>
      <p id="Par20">Given the differences between “expert-defined” markers and the correlation of classification performance and technical dataset-specific features (e.g., dropout rate), we tested if the performance of prior-knowledge methods can be improved by automatically selecting marker genes based on differential expression. Through the cross-validation scheme, we used the training folds to select the marker genes of each cell population based on differential expression (see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section) and later used these markers to evaluate the classifiers’ performance on the testing fold. We tested this approach on the two PBMC datasets, Zheng sorted and Zheng 68K for different numbers of marker genes (5, 10, 15, and 20 markers). In Fig. <xref rid="Fig1" ref-type="fig">1</xref>, the best result across the number of markers for <italic>SCINA</italic><sub><italic>DE</italic></sub>, <italic>Garnett</italic><sub><italic>DE</italic></sub>, and <italic>DigitalCellSorter</italic><sub><italic>DE</italic></sub> are shown.</p>
      <p id="Par21">The median F1-score obtained using the differential expression-defined markers is significantly lower compared to the original versions of classifiers using the markers defined by the authors. This lower performance is in part due to the low performance on challenging populations, such as subpopulations of CD4+ and CD8+ T cell populations (F1-score ≤ 0.68) (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S4). These challenging populations are not identified by the original classifiers since the markers provided by the authors only considered annotations at a higher level (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1). For example, the median F1-score of <sub><italic>SCINADE</italic></sub> on Zheng sorted is 0.38, compared to a median F1-score of 1.0 for <italic>SCINA</italic> (using the original markers defined by the authors). However, <italic>SCINA</italic> only considers three cell populations: CD14+ monocytes, CD56+ NK cells, and CD19+ B cells. If we only consider these cell populations for <italic>SCINA</italic><sub><italic>DE</italic></sub>, this results in a median F1-score of 0.95.</p>
      <p id="Par22">We observed that the optimal number of marker genes varies per classifier and dataset. For the Zheng sorted dataset, the optimal number of markers is 5, 15, and 20 for <italic>DigitalCellSorter</italic><sub><italic>DE</italic></sub>, <italic>Garnett</italic><sub><italic>DE</italic></sub>, and <italic>SCINA</italic><sub><italic>DE</italic></sub>, respectively, while for Zheng 68K, this is 5, 5, and 10. All together, these results illustrate the dependence of the classification performance on the careful selection of marker genes which is evidently a challenging task.</p>
    </sec>
    <sec id="Sec8">
      <title>Classification performance depends on dataset complexity</title>
      <p id="Par23">A major aspect affecting the classification performance is the complexity of the dataset at hand. We described the complexity of each dataset in terms of the pairwise similarity between cell populations (see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section) and compared the complexity to the performance of the classifiers and the number of cell populations in a dataset (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). When the complexity and/or the number of cell populations of the dataset increases, the performance generally decreases. The performance of all classifiers is relatively low on the Zheng 68K dataset, which can be explained by the high pairwise correlations between the mean expression profiles of each cell population (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S5). These correlations are significantly lower for the TM and AMB92 datasets, justifying the higher performance of the classifiers on these two datasets (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figures S6–S7). While both TM and AMB92 have more cell populations (55 and 92, respectively) compared to Zheng 68K (11 populations), these populations are less correlated to one another, making the task easier for all the classifiers.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Complexity of the datasets compared to the performance of the classifiers. <bold>a</bold> Boxplots of the median F1-scores of all classifiers for each dataset used during the intra-dataset evaluation. <bold>b</bold> Barplots describing the complexity of the datasets (see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section). Datasets are ordered based on complexity. Box- and bar plots are colored according to the number of cell populations in each dataset</p></caption><graphic xlink:href="13059_2019_1795_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec9">
      <title>Performance evaluation across datasets (inter-dataset evaluation)</title>
      <p id="Par24">While evaluating the classification performance within a dataset (intra-dataset) is important, the realistic scenario in which a classifier is useful requires cross-dataset (i.e., inter-dataset) classification. We used 22 datasets (Table <xref rid="Tab2" ref-type="table">2</xref>) to test the classifiers’ ability to predict cell identities in a dataset that was not used for training. First, we tested the classifiers’ performance across different sequencing protocols, applied to the same samples within the same lab using the two CellBench datasets. We evaluated the classification performance when training on one protocol and testing on the other. Similar to the intra-dataset evaluation result, all classifiers performed well in this case (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S8).</p>
      <p id="Par25">Second, we tested the classification performance on the PbmcBench datasets, which represent a more extensive protocol comparison. PbmcBench consists of 2 samples (pbmc1 and pbmc2), sequenced using 7 different protocols (Table <xref rid="Tab2" ref-type="table">2</xref>) with the exception that 10Xv3 was not applied to the pbmc2 sample. We used the pbmc1 datasets to evaluate the classification performance of all pairwise train-test combinations between the 7 protocols (42 experiments, see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section). Moreover, we extended the evaluation to include comparisons across different samples for the same protocol, using pbmc1 and pbmc2 (6 experiments, see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section). All 48 experiment results are summarized in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. Overall, several classifiers performed well including <italic>SCINA</italic><sub><italic>DE</italic></sub> using 20 marker genes, <italic>singleCellNet</italic>, <italic>scmapcell</italic>, <italic>scID</italic>, and <italic>SVM</italic>, with an average median F1-score &gt; 0.75 across all 48 experiments (Fig. <xref rid="Fig3" ref-type="fig">3</xref>a, Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S9A). <italic>SCINA</italic><sub><italic>DE</italic></sub>, <italic>Garnett</italic><sub><italic>DE</italic></sub>, and <italic>DigitalCellSorter</italic><sub><italic>DE</italic></sub> were tested using 5, 10, 15, and 20 marker genes; Fig. <xref rid="Fig3" ref-type="fig">3</xref>a shows the best result for each classifier, where <italic>SCINA</italic><sub><italic>DE</italic></sub> and <italic>Garnett</italic><sub><italic>DE</italic></sub> performed best using 20 and 5 marker genes, respectively, while <italic>DigitalCellSorter</italic><sub><italic>DE</italic></sub> had a median F1-score of 0 during all experiments using all different numbers of marker genes. <italic>DigitalCellSorter</italic><sub><italic>DE</italic></sub> could only identify B cells in the test sets, usually with an F1-score between 0.8 and 1.0, while the F1-score for all other cell populations was 0.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Classification performance across the PbmcBench datasets. <bold>a</bold> Heatmap showing the median F1-scores of the supervised classifiers for all train-test pairwise combination across different protocols. The training set is indicated in the gray box on top of the heatmap, and the test set is indicated using the column labels below. Results shown to the left of the red line represent the comparison between different protocols using sample pbmc1. Results shown to the right of the red line represent the comparison between different samples using the same protocol, with pbmc 1 used for training and pbmc2 used for testing. Boxplots on the right side of the heatmap summarize the performance of each classifier across all experiments. The mean of the median F1-scores, also used to order the classifiers, is indicated in the boxplots using a red dot. Boxplots underneath the heatmap summarize the performance of the classifiers per experiment. For <italic>SCINA</italic><sub><italic>DE</italic></sub>, <italic>Garnett</italic><sub><italic>DE</italic></sub>, and <italic>DigitalCellSorter</italic><sub><italic>DE</italic></sub>, different numbers of marker genes were tested. Only the best result is shown here. <bold>b</bold> Median F1-score of the prior-knowledge classifiers on both samples of the different protocols. The protocol is indicated in the gray box on top of the heatmap, and the sample is indicated with the labels below. Classifiers are ordered based on their mean performance across all datasets</p></caption><graphic xlink:href="13059_2019_1795_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par26">We also tested the prior-knowledge classifiers on all 13 PbmcBench datasets. The prior-knowledge classifiers showed lower performance compared to other classifiers (average median F1-score &lt; 0.6), with the exception of <italic>SCINA</italic> which was only tested on three cell populations (Fig. <xref rid="Fig3" ref-type="fig">3</xref>b, Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S9B). These results are in line with our previous conclusions from the Zheng sorted and Zheng 68K datasets in the intra-dataset evaluation.</p>
      <p id="Par27">Comparing the performance of the classifiers across the different protocols, we observed a higher performance for all classifiers for specific pairs of protocols. For example, all classifiers performed well when trained on 10Xv2 and tested on 10Xv3, and vice versa. On the other hand, other pairs of protocols had a good performance only in one direction, training on Seq-Well produced good predictions on 10Xv3, but not the other way around. Compared to all other protocols, the performance of all classifiers was low when they were either trained or tested on Smart-seq2 data. This can, in part, be due to the fact that Smart-seq2 data does not contain unique molecular identifier (UMI), in contrast to all other protocols.</p>
      <p id="Par28">We also tested the classification performance using the 3 brain datasets, VISp, ALM, and MTG (Table <xref rid="Tab2" ref-type="table">2</xref>), which allowed us to compare the performances across species (mouse and human) as well as single-cell RNA-seq (used in VISp and ALM) vs single-nucleus RNA-seq (used in MTG). We tested all possible train-test combinations for both levels of annotation, three major brain cell types (inhibitory neurons, excitatory neurons, and non-neuronal cells), and the deeper annotation level with 34 cell populations (18 experiments, see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section). Prediction of the three major cell types was easy, where almost all classifiers showed high performance (Fig. <xref rid="Fig4" ref-type="fig">4</xref>a) with some exceptions. For example, <italic>scPred</italic> failed the classification task completely when testing on the MTG dataset, producing 100% unlabeled cells (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S10A). Predicting the 34 cell populations turned out to be a more challenging task, especially when the MTG human dataset is included either as training or testing data, resulting in significantly lower performance across all classifiers (Fig. <xref rid="Fig4" ref-type="fig">4</xref>b). Across all nine experiments at the deeper annotation, the top-performing classifiers were <italic>SVM</italic>, <italic>ACTINN</italic>, <italic>singleCellNet</italic>, <italic>SingleR</italic>, and <italic>LAmbDA</italic>, with almost 0% unlabeled cells (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S10B).
<fig id="Fig4"><label>Fig. 4</label><caption><p>Classification performance across brain datasets. Heatmaps show the median F1-scores of the supervised classifiers when tested on <bold>a</bold> major lineage annotation with three cell populations and <bold>b</bold> deeper level of annotation with 34 cell populations. The training sets are indicated using the column labels on top of the heatmap. The test set is indicated in the gray box. In each heatmap, the classifiers are ordered based on their mean performance across all experiments</p></caption><graphic xlink:href="13059_2019_1795_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par29">Finally, to evaluate the classification performance across different protocols and different labs, we used the four human pancreatic datasets: Baron Human, Muraro, Segerstople, and Xin (see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section, Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2). We tested four combinations by training on three datasets and test on one dataset, in which case the classification performance can be affected by batch differences between the datasets. We evaluated the performance of the classifiers when trained using the original data as well as aligned data using the mutual nearest neighbor (MNN) method [<xref ref-type="bibr" rid="CR41">41</xref>]. Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S11 shows UMAPs [<xref ref-type="bibr" rid="CR42">42</xref>] of the combined dataset before and after alignment, demonstrating better grouping of pancreatic cell types after alignment.</p>
      <p id="Par30">For the original (unaligned) data, the best-performing classifiers across all four experiments are <italic>scVI</italic>, <italic>SVM</italic>, <italic>ACTINN</italic>, <italic>scmapcell</italic>, and <italic>SingleR</italic> (Fig. <xref rid="Fig5" ref-type="fig">5</xref>a, Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S12A). For the aligned data, the best-performing classifiers are <italic>kNN</italic>, <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>singleCellNet</italic>, <italic>SVM</italic>, and <italic>NMC</italic> (Fig. <xref rid="Fig5" ref-type="fig">5</xref>b, Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S12B). Some classifiers benefit from aligning datasets such as <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>kNN</italic>, <italic>NMC</italic>, and <italic>singleCellNet</italic>, resulting in higher median F1-scores (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). On the other hand, some other classifiers failed the classification task completely, such as <italic>scmapcell</italic> which labels all cells as unlabeled. Some other classifiers failed to run over the aligned datasets, such as <italic>ACTINN</italic>, <italic>scVI</italic>, <italic>Cell-BLAST</italic>, <italic>scID</italic>, <italic>scmapcluster</italic>, and <italic>scPred</italic>. These classifiers work only with positive gene expression data, while the aligned datasets contain positive and negative gene expression values.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Classification performance across pancreatic datasets. Heatmaps showing the median F1-score for each classifier for the <bold>a</bold> unaligned and <bold>b</bold> aligned datasets. The column labels indicate which of the four datasets was used as a test set, in which case the other three datasets were used as training. Gray boxes indicate that the corresponding method could not be tested on the corresponding dataset. In each heatmap, the classifiers are ordered based on their mean performance across all experiments</p></caption><graphic xlink:href="13059_2019_1795_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec10">
      <title>Rejection option evaluation</title>
      <p id="Par31">Classifiers developed for scRNA-seq data often incorporate a rejection option to identify cell populations in the test set that were not seen during training. These populations cannot be predicted correctly and therefore should remain unassigned. To test whether the classifiers indeed leave these unseen populations unlabeled, we applied two different experiments using negative controls of different tissues and using unseen populations of the same tissue.</p>
      <p id="Par32">First, the classifiers were trained on a data set from one tissue (e.g., pancreas) and used to predict cell populations of a completely different tissue (e.g., brain) [<xref ref-type="bibr" rid="CR22">22</xref>]. The methods should thus reject all (100%) of the cells in the test dataset. We carried out four different negative control experiments (see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section, Fig. <xref rid="Fig6" ref-type="fig">6</xref>a). <italic>scmapcluster</italic> and <italic>scPred</italic> have an almost perfect score for all four combinations, rejecting close 100% of the cells. Other top-performing methods for this task, <italic>SVM</italic><sub><italic>rejection</italic></sub> and <italic>scmapcell</italic>, failed when trained on mouse pancreatic data and tested on mouse brain data. All labeled cells of the AMB16 dataset are predicted to be beta cells in this case. The prior-knowledge classifiers, <italic>SCINA</italic>, <italic>Garnett</italic><sub><italic>pretrained</italic></sub>, and <italic>DigitalCellSorter</italic>, could only be tested on the Baron Human pancreatic dataset. <italic>Garnett</italic><sub><italic>CV</italic></sub> could, on top of that, also be trained on the Baron Human dataset and tested on the Zheng 68K dataset. During the training phase, <italic>Garnett</italic><sub><italic>CV</italic></sub> tries to find representative cells for the cell populations described in the marker gene file. Being trained on Baron Human using the PBMC marker gene file, it should not be able to find any representatives, and therefore, all cells in the Zheng 68K dataset should be unassigned. Surprisingly, <italic>Garnett</italic><sub><italic>CV</italic></sub> still finds representatives for PBMC cells in the pancreatic data, and thus, the cells in the test set are labeled. However, being trained on the PBMC dataset and tested on the pancreatic dataset, it does have a perfect performance.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Performance of the classifiers during the rejection experiments. <bold>a</bold> Percentage of unlabeled cells during the negative control experiment for all the classifiers with a rejection option. The prior-knowledge classifiers could not be tested on all datasets, and this is indicated with a gray box. The species of the dataset is indicated in the gray box on top. Column labels indicate which datasets are used for training and testing. <bold>b</bold> Percentage of unlabeled cells for all classifiers with a rejection option when a cell population was removed from the training set. Column labels indicate which cell population was removed. This cell population was used as a test set. In both <bold>a</bold> and <bold>b</bold>, the classifiers are sorted based on their mean performance across all experiments</p></caption><graphic xlink:href="13059_2019_1795_Fig6_HTML" id="MO6"/></fig></p>
      <p id="Par33">To test the rejection option in a more realistic and challenging scenario, we trained the classifiers on some cell populations from one dataset and used the held out cell populations in the test set (see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section). Since the cell populations in the test set were not seen during training, they should remain unlabeled. Here, the difficulty of the task was gradually increased (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3). First, all the T cells were removed from the training set. Next, only the CD4+ T cells were removed. Finally, only CD4+/CD45RO+ memory T cells, a subpopulation of the CD4+ T cells, were removed. The top-performing methods for this task are <italic>scmapcell</italic>, <italic>scPred</italic>, <italic>scID</italic>, <italic>SVM</italic><sub><italic>rejection</italic></sub>, and <italic>SCINA</italic> (Fig. <xref rid="Fig6" ref-type="fig">6</xref>b)<italic>.</italic> We expected that rejecting T cells would be a relatively easy task as they are quite distinct from all other cell populations in the dataset. It should thus be comparable to the negative control experiment. Rejecting CD4+/CD45RO+ memory T cells, on the other hand, would be more difficult as they could easily be confused with all other subpopulations of CD4+ T cells. Surprisingly, almost all classifiers, except for <italic>scID</italic> and <italic>scmapcluster</italic>, show the opposite.</p>
      <p id="Par34">To better understand this unexpected performance, we analyzed the labels assigned by <italic>SVM</italic><sub><italic>rejection</italic></sub>. In the first task (T cells removed from the training set), <italic>SVM</italic><sub><italic>rejection</italic></sub> labels almost all T cells as B cells. This can be explained by the fact that <italic>SVM</italic><sub><italic>rejection</italic></sub>, and most classifiers for that matter, relies on the classification posterior probabilities to assign labels but ignores the actual similarity between each cell and the assigned population. In task 2 (CD4+ T cells were removed), there were two subpopulations of CD8+ T cells in the training set. In that case, two cell populations are equally similar to the cells in the test set, resulting in low posterior probabilities for both classes and thus the cells in the test set remain unlabeled. If one of these CD8+ T cell populations was removed from the training set, only 10.53% instead of 75.57% of the CD4+ T cells were assigned as unlabeled by <italic>SVM</italic><sub><italic>rejection</italic></sub>. All together, our results indicate that despite the importance of incorporating a rejection option in cell identity classifiers, the implementation of this rejection option remains challenging.</p>
    </sec>
    <sec id="Sec11">
      <title>Performance sensitivity to the input features</title>
      <p id="Par35">During the intra-datasets cross-validation experiment described earlier, we used all features (genes) as input to the classifiers. However, some classifiers suffer from overtraining when too many features are used. Therefore, we tested the effect of feature selection on the performance of the classifiers. While different strategies for feature selection in scRNA-seq classification experiments exist, selecting genes with a higher number of dropouts compared to the expected number of dropouts has been shown to outperform other methods [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR43">43</xref>]. We selected subsets of features from the TM dataset using the dropout method. In the experiments, we used the top 100, 200, 500, 1000, 2000, 5000, and 19,791 (all) genes. Some classifiers include a built-in feature selection method which is used by default. To ensure that all methods use the same set of features, the built-in feature selection was turned off during these experiments.</p>
      <p id="Par36">Some methods are clearly overtrained when the number of features increases (Fig. <xref rid="Fig7" ref-type="fig">7</xref>a). For example, <italic>scmapcell</italic> shows the highest median F1-score when using less features, and the performance drops when the number of features increases. On the other hand, the performance of other classifiers, such as <italic>SVM</italic>, keeps improving when the number of features increases. These results indicate that the optimal number of features is different for each classifier.
<fig id="Fig7"><label>Fig. 7</label><caption><p>Computation time evaluation across different numbers of features, cells, and annotation levels. Line plots show <bold>a</bold> the median F1-score, <bold>b</bold> percentage of unlabeled cells, and <bold>e</bold> computation time of each classifier applied to the TM dataset with the top 100, 200, 500, 1000, 2000, 5000, and 19,791 (all) genes as input feature sets. Genes were ranked based on dropout-based feature selection. <bold>c</bold> The median F1-score, <bold>d</bold> percentage of unlabeled cells, and <bold>f</bold> computation time of each classifier applied to the downsampled TM datasets containing 463, 2280, 4553, 9099, 22,737, and 45,469 (all) cells. <bold>g</bold> The computation time of each classifier is plotted against the number of cell populations. Note that the <italic>y</italic>-axis is 100^x scaled in <bold>a</bold> and <bold>c</bold> and log-scaled in <bold>e</bold>–<bold>g</bold>. The <italic>x</italic>-axis is log-scaled in <bold>a</bold>–<bold>f</bold></p></caption><graphic xlink:href="13059_2019_1795_Fig7_HTML" id="MO7"/></fig></p>
      <p id="Par37">Looking at the median F1-score, there are several methods with a high maximal performance. <italic>Cell-BLAST</italic>, <italic>ACTINN</italic>, <italic>scmapcell</italic>, <italic>scPred</italic>, <italic>SVM</italic><sub><italic>rejection</italic></sub>, and <italic>SVM</italic> all have a median F1-score higher than 0.97 for one or more of the feature sets. Some of these well-performing methods, however, leave many cells unlabeled. <italic>scmapcell</italic> and <italic>scPred</italic>, for instance, yield a maximum median F1-score of 0.976 and 0.982, respectively, but 10.7% and 15.1% of the cells are assigned as unlabeled (Fig. <xref rid="Fig7" ref-type="fig">7</xref>b). On the other hand, <italic>SVM</italic><sub><italic>rejection</italic></sub> has the highest median F1-score (0.991) overall with only 2.9% unlabeled. Of the top-performing classifiers, only <italic>ACTINN</italic> and <italic>SVM</italic> label all the cells. Overall <italic>SVM</italic> shows the third highest performance with a score of 0.979.</p>
    </sec>
    <sec id="Sec12">
      <title>Scalability: performance sensitivity to the number of cells</title>
      <p id="Par38">scRNA-seq datasets vary significantly across studies in terms of the number of cells analyzed. To test the influence of the size of the dataset on the performance of the classifier, we downsampled the TM dataset in a stratified way (i.e., preserving population frequencies) to 1, 5, 10, 20, 50, and 100% of the original number of 45,469 cells (see the “<xref rid="Sec16" ref-type="sec">Methods</xref>” section) and compared the performance of the classifiers (Fig. <xref rid="Fig7" ref-type="fig">7</xref>c, d). Using less than 500 cells in the dataset, most classifiers have a relatively high performance. Only <italic>scID</italic>, <italic>LAmbDA</italic>, <italic>CaSTLe</italic>, and <italic>Cell-BLAST</italic> have a median F1-score below 0.85. Surprisingly, <italic>SVM</italic><sub><italic>rejection</italic></sub> has almost the same median F1-score when using 1% of the data as when using all data (0.993 and 0.994). It must be noted here, however, that the percentage of unlabeled cells decreases significantly (from 28.9% to 1.3%). Overall, the performance of all classifiers stabilized when tested on ≥ 20% (9099 cells) of the original data.</p>
    </sec>
    <sec id="Sec13">
      <title>Running time evaluation</title>
      <p id="Par39">To compare the runtimes of the classification methods and see how they scale when the number of cells increases, we compared the number of cells in each dataset with the computation time of the classifiers (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S13). Overall, big differences in the computation time can be observed when comparing the different methods. <italic>SingleR</italic> showed the highest computation time overall. Running <italic>SingleR</italic> on the Zheng 68K dataset took more than 39 h, while <italic>scmapcluster</italic> was finished within 10 s on this dataset. Some of the methods have a high runtime for the small datasets. On the smallest dataset, Xin, all classifiers have a computation time &lt; 5 min, with most classifiers finishing within 60 s. <italic>Cell-BLAST</italic>, however, takes more than 75 min. In general, all methods show an increase in computation time when the number of cells increases. However, when comparing the second largest (TM) and the largest (Zheng 68K) datasets, not all methods show an increase in computation time. Despite the increase in the number of cells between the two datasets, <italic>CaSTLe</italic>, <italic>CHETAH</italic>, and <italic>SingleR</italic> have a decreasing computation time. A possible explanation could be that the runtime of these methods also depends on the number of genes or the number of cell populations in the dataset. To evaluate the run time of the methods properly, we therefore investigated the effect of the number of cells, features, and cell populations separately (Fig. <xref rid="Fig7" ref-type="fig">7</xref>e–g).</p>
      <p id="Par40">To assess the effect of the number of genes on the computation time, we compared the computation time of the methods during the feature selection experiment (Fig. <xref rid="Fig7" ref-type="fig">7</xref>e). Most methods scale linearly with the number of genes. However, <italic>LDA</italic> does not scale very well when the number of genes increases. If the number of features is higher than the number of cells, the complexity of <italic>LDA</italic> is O(<italic>g</italic>^3), where <italic>g</italic> is the number of genes [<xref ref-type="bibr" rid="CR44">44</xref>].</p>
      <p id="Par41">The effect of the number of cells on the timing showed that all methods increase in computation time when the number of cells increases (Fig. <xref rid="Fig7" ref-type="fig">7</xref>f). The differences in runtime on the largest dataset are larger. <italic>scmapcluster</italic>, for instance, takes 5 s to finish, while <italic>Cell-BLAST</italic> takes more than 11 h.</p>
      <p id="Par42">Finally, to evaluate the effect of the number of cell populations, the runtime of the methods on the AMB3, AMB16, and AMB92 datasets was compared (Fig. <xref rid="Fig7" ref-type="fig">7</xref>g). For most methods, this shows an increase in runtime when the number of cell populations increases, specially <italic>singleCellNet</italic>. For other methods, such as <italic>ACTINN</italic> and <italic>scmapcell</italic>, the runtime remains constant. Five classifiers, <italic>scmapcell</italic>, <italic>scmapcluster</italic>, <italic>SVM</italic>, <italic>RF</italic>, and <italic>NMC</italic>, have a computation time below 6 min on all the datasets.</p>
    </sec>
  </sec>
  <sec id="Sec14">
    <title>Discussion</title>
    <p id="Par43">In this study, we evaluated the performance of 22 different methods for automatic cell identification using 27 scRNA-seq datasets. We performed several experiments to cover different levels of challenges in the classification task and to test specific aspects of the classifiers such as the feature selection, scalability, and rejection experiments. We summarize our findings across the different experiments (Fig. <xref rid="Fig8" ref-type="fig">8</xref>) and provide a detailed summary of which dataset was used for each experiment (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4). This overview can be used as a user guide to choose the most appropriate classifier depending on the experimental setup at hand. Overall, several classifiers performed accurately across different datasets and experiments, particularly <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>SVM</italic>, <italic>singleCellNet</italic>, <italic>scmapcell</italic>, <italic>scPred</italic>, <italic>ACTINN</italic>, and <italic>scVI</italic>. We observed relatively lower performance for the inter-dataset setup, likely due to the technical and biological differences between the datasets, compared to the intra-dataset setup. <italic>SVM</italic><sub><italic>rejection</italic></sub>, <italic>SVM</italic>, and <italic>singleCellNet</italic> performed well for both setups, while <italic>scPred</italic> and <italic>scmapcell</italic> performed better in the intra-dataset setup, and <italic>scVI</italic> and <italic>ACTINN</italic> had a better performance in the inter-dataset setup (Fig. <xref rid="Fig8" ref-type="fig">8</xref>). Of note, we evaluated all classifiers using the default settings. While adjusting these settings for a specific dataset might improve the performances, it increases the risk of overtraining.
<fig id="Fig8"><label>Fig. 8</label><caption><p>Summary of the performance of all classifiers during different experiments. For each experiment, the heatmap shows whether a classifier performs good, intermediate, or poor. Light gray indicates that a classifier could not be tested during an experiment. The gray boxes to the right of the heatmap indicate the four different categories of experiments: intra-dataset, inter-dataset, rejection, and timing. Experiments itself are indicated using the row labels. Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S4 shows which datasets were used to score the classifiers exactly for each experiment. Gray boxes above the heatmap indicate the two classifier categories. Within these two categories, the classifiers are sorted based on their mean performance on the intra- and inter-dataset experiments</p></caption><graphic xlink:href="13059_2019_1795_Fig8_HTML" id="MO8"/></fig></p>
    <p id="Par44">Considering all three evaluation metrics (median F1-score, percentage of unlabeled cells, and computation time), <italic>SVM</italic><sub><italic>rejection</italic></sub> and <italic>SVM</italic> are overall the best-performing classifiers for the scRNA-seq datasets used. Although <italic>SVM</italic> has a shorter computation time, the high accuracy of the rejection option of <italic>SVM</italic><sub><italic>rejection</italic></sub>, which allows flagging new cells and assigning them as unlabeled, results in an improved performance compared to <italic>SVM</italic>. Our results show that <italic>SVM</italic><sub><italic>rejection</italic></sub> and <italic>SVM</italic> scale well to large datasets as well as deep annotation levels. In addition, they did not suffer from the large number of features (genes) present in the data, producing the highest performance on the TM dataset using all genes, due to the incorporated L2 regularization. The comparable or higher overall performance of a general-purpose classier such as <italic>SVM</italic> warrants caution when designing scRNA-seq-specific classifiers that they do not introduce unnecessary complexity. For example, deep learning methods, such as <italic>ACTINN</italic> and <italic>scVI</italic>, showed overall lower performance compared to <italic>SVM</italic>, supporting recent observations by Köhler et al. [<xref ref-type="bibr" rid="CR45">45</xref>].</p>
    <p id="Par45"><italic>scPred</italic> (which is based on an SVM with a radial kernel), <italic>LDA</italic>, <italic>ACTINN</italic>, and <italic>singleCellNet</italic> performed well on most datasets, yet the computation time is long for large datasets<italic>. singleCellNet</italic> also becomes slower with a large number of cell populations. Additionally, in some cases, <italic>scPred</italic> and <italic>scmapcell/cluster</italic> reject higher proportions of cells as unlabeled compared to <italic>SVM</italic><sub><italic>rejection</italic></sub>, without a substantial improvement in the accuracy. In general, incorporating a rejection option with classification is a good practice to allow the detection of potentially novel cell populations (not present in the training data) and improve the performance for the classified cells with high confidence. However, for the datasets used in this study, the performance of classifiers with a rejection option, except for <italic>SVM</italic><sub><italic>rejection</italic></sub>, did not show substantial improvement compared to other classifiers. Furthermore, our results indicate that designing a proper rejection option can be challenging for complex datasets (e.g., PBMC) and that relying on the posterior probabilities alone might not yield optimal results.</p>
    <p id="Par46">For datasets with deep levels of annotation (i.e., large number) of cell populations, the classification performance of all classifiers is relatively low, since the classification task is more challenging. <italic>scVI</italic>, in particular, failed to scale with deeply annotated datasets, although it works well for datasets with a relatively small number of cell populations. Further, applying the prior-knowledge classifiers becomes infeasible for deeply annotated datasets, as the task of defining the marker genes becomes even more challenging.</p>
    <p id="Par47">We evaluated the performance of the prior-knowledge methods (marker-based and pretrained) on PBMC datasets only, due to the limited availability of author-provided marker genes. For all PBMC datasets, the prior-knowledge methods did not improve the classification performance over supervised methods, which do not incorporate such prior knowledge. We extended some prior-knowledge methods such that the marker genes were defined in a data-driven manner using differential expression which did not improve the performance of these classifiers, except for <italic>SCINA</italic><sub><italic>DE</italic></sub> (with 20 marker genes) for the PbmcBench datasets. The data-driven selection of markers allows the prediction of more cell populations compared to the number of populations for which marker genes were originally provided. However, this data-driven selection violates the fundamental assumption in prior-knowledge methods that incorporating expert-defined markers improves classification performance. Further, several supervised classifiers which do not require markers to be defined a priori (e.g., <italic>scPred</italic> and <italic>scID</italic>) already apply a differential expression test to find the best set of genes to use while training the model. The fact that prior-knowledge methods do not outperform other supervised methods and given the challenges associated with explicit marker definition indicate that incorporating prior knowledge in the form of marker genes is not beneficial, at least for PBMC data.</p>
    <p id="Par48">In the inter-dataset experiments, we tested the ability of the classifiers to identify populations across different scRNA-seq protocols. Our results show that some protocols are more compatible with one another (e.g., 10Xv2 and 10Xv3), Smart-Seq2 is distinct from the other UMI-based methods, and CEL-Seq2 suffers from low replicability of cell populations across samples. These results can serve as a guide in order to choose the best set of protocols that can be used in studies where more than one protocol is used.</p>
    <p id="Par49">The intra-dataset evaluation included the Zheng sorted dataset, which consists of 10 FACS-sorted cell populations based on the expression of surface protein markers. Our results show relatively lower classification performance compared to other datasets, except the Zheng 68K dataset. The poor correlation between the expression levels of these protein markers and their coding genes mRNA levels [<xref ref-type="bibr" rid="CR46">46</xref>] might explain this low performance.</p>
    <p id="Par50">Overall, we observed that the performance of almost all methods was relatively high on various datasets, while some datasets with overlapping populations (e.g., Zheng 68K dataset) remain challenging. The inter-dataset comparison requires extensive development in order to deal with technical differences between protocols, batches, and labs, as well as proper matching between different cell population annotations. Further, the pancreatic datasets are known to project very well across studies, and hence, using them to evaluate inter-dataset performance can be misleading. We recommend considering other challenging tissues and cell populations.</p>
  </sec>
  <sec id="Sec15">
    <title>Conclusions</title>
    <p id="Par51">We present a comprehensive evaluation of automatic cell identification methods for single-cell RNA sequencing data. Generally, all classifiers perform well across all datasets, including the general-purpose classifiers. In our experiments, incorporating prior knowledge in the form of marker genes does not improve the performance (on PBMC data). We observed large differences in the performance between methods in response to changing the input features. Furthermore, the tested methods vary considerably in their computation time which also varies differently across methods based on the number of cells and features.</p>
    <p id="Par52">Taken together, we recommend the use of the general-purpose <italic>SVM</italic><sub><italic>rejection</italic></sub> classifier (with a linear kernel) since it has a better performance compared to the other classifiers tested across all datasets. Other high-performing classifiers include <italic>SVM</italic> with a remarkably fast computation time at the expense of losing the rejection option, <italic>singleCellNet</italic>, <italic>scmapcell</italic>, and <italic>scPred</italic>. To support the future extension of this benchmarking work with new classifiers and datasets, we provide a Snakemake workflow to automate the performed benchmarking analyses (<ext-link ext-link-type="uri" xlink:href="https://github.com/tabdelaal/scRNAseq_Benchmark/tree/snakemake_and_docker">https://github.com/tabdelaal/scRNAseq_Benchmark/</ext-link>).</p>
  </sec>
  <sec id="Sec16">
    <title>Methods</title>
    <sec id="Sec17">
      <title>Classification methods</title>
      <p id="Par53">We evaluated 22 scRNA-seq classifiers, publicly available as R or Python packages or scripts (Table <xref rid="Tab1" ref-type="table">1</xref>). This set includes 16 methods developed specifically for scRNA-seq data as well as 6 general-purpose classifiers from the scikit-learn library in Python [<xref ref-type="bibr" rid="CR29">29</xref>]: linear discriminant analysis (<italic>LDA</italic>), nearest mean classifier (<italic>NMC</italic>), <italic>k</italic>-nearest neighbor (<italic>kNN</italic>), support vector machine (<italic>SVM</italic>) with linear kernel, SVM with rejection option (<italic>SVM</italic><sub><italic>rejection</italic></sub>), and random forest (<italic>RF</italic>). The following functions from the scikit-learn library were used respectively: LinearDiscriminantAnalysis(), NearestCentroid(), KNeighborsClassifier(n_neighbors=9), LinearSVC(), LinearSVC() with CalibratedClassifierCV() wrapper, and RandomForestClassifier(n_estimators=50). For <italic>kNN</italic>, 9 neighbors were chosen. After filtering the datasets, only cell populations consisting of 10 cells or more remained. Using 9 neighbors would thus ensure that this classifier could also predict very small populations. For <italic>SVM</italic><sub><italic>rejection</italic></sub>, a threshold of 0.7 was used on the posterior probabilities to assign cells as “unlabeled.” During the rejection experiments, also an LDA with rejection was implemented. In contrast to the LinearSVC(), the LinearDiscriminantAnalysis() function can output the posterior probabilities, which was also thresholded at 0.7.</p>
      <p id="Par54">scRNA-seq-specific methods were excluded from the evaluation if they did not return the predicted labels for each cell. For example, we excluded <italic>MetaNeighbor</italic> [<xref ref-type="bibr" rid="CR47">47</xref>] because the tool only returns the area under the receiver operator characteristic curve (AUROC). For all methods, the latest (May 2019) package was installed or scripts were downloaded from their GitHub. For <italic>scPred</italic>, it should be noted that it is only compatible with an older version of Seurat (v2.0). For <italic>CHETAH</italic>, it is important that the R version 3.6 or newer is installed. For <italic>LAmbDA</italic>, instead of the predicted label, the posterior probabilities were returned for each cell population. Here, we assigned the cells to the cell population with the highest posterior probability.</p>
      <p id="Par55">During the benchmark, all methods were run using their default settings, and if not available, we used the settings provided in the accompanying examples or vignettes. As input, we provided each method with the raw count data (after cell and gene filtering as described in the “<xref rid="Sec19" ref-type="sec">Data preprocessing</xref>” section) according to the method documentation. The majority of the methods have a built-in normalization step. For the general-purpose classifiers, we provided log-transformed counts, <italic>log</italic><sub>2</sub>(<italic>count</italic> + 1).</p>
      <p id="Par56">Some methods required a marker gene file or pretrained classifier as an input (e.g., <italic>Garnett</italic>, <italic>Moana</italic>, <italic>SCINA</italic>, <italic>DigitalCellSorter</italic>). In this case, we use the marker gene files or pretrained classifiers provided by the authors. We did not attempt to include additional marker gene files for all datasets, and hence, the evaluation of those methods is restricted to datasets where a marker gene file for cell populations is available.</p>
    </sec>
    <sec id="Sec18">
      <title>Datasets</title>
      <p id="Par57">A total of 27 scRNA-seq datasets were used to evaluate and benchmark all classification methods, from which 11 datasets were used for intra-dataset evaluation using a cross-validation scheme, and 22 datasets were used for inter-dataset evaluation, with 6 datasets overlapping for both tasks as described in Table <xref rid="Tab2" ref-type="table">2</xref>. Datasets vary across species (human and mouse), tissue (brain, pancreas, PBMC, and whole mouse), and the sequencing protocol used. The brain datasets, including Allen Mouse Brain (AMB), VISp, ALM (GSE115746), and MTG (phs001790), were downloaded from the Allen Institute Brain Atlas <ext-link ext-link-type="uri" xlink:href="http://celltypes.brain-map.org/rnaseq">http://celltypes.brain-map.org/rnaseq</ext-link>. All 5 pancreatic datasets were obtained from <ext-link ext-link-type="uri" xlink:href="https://hemberg-lab.github.io/scRNA.seq.datasets/">https://hemberg-lab.github.io/scRNA.seq.datasets/</ext-link> (Baron Mouse: GSE84133, Baron Human: GSE84133, Muraro: GSE85241, Segerstolpe: E-MTAB-5061, Xin: GSE81608). The CellBench 10X dataset was obtained from (GSM3618014), and the CellBench CEL-Seq2 dataset was obtained from 3 datasets (GSM3618022, GSM3618023, GSM3618024) and concatenated into 1 dataset. The Tabula Muris (TM) dataset was downloaded from <ext-link ext-link-type="uri" xlink:href="https://tabula-muris.ds.czbiohub.org/">https://tabula-muris.ds.czbiohub.org/</ext-link> (GSE109774). For the Zheng sorted datasets, we downloaded the 10 PBMC-sorted populations (CD14+ monocytes, CD19+ B cells, CD34+ cells, CD4+ helper T cells, CD4+/CD25+ regulatory T cells, CD4+/CD45RA+/CD25− naive T cells, CD4+/CD45RO+ memory T cells, CD56+ natural killer cells, CD8+ cytotoxic T cells, CD8+/CD45RA+ naive cytotoxic T cells) from <ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/single-cell-gene-expression/datasets">https://support.10xgenomics.com/single-cell-gene-expression/datasets</ext-link>; next, we downsampled each population to 2000 cells obtaining a dataset of 20,000 cells in total. For the Zheng 68K dataset, we downloaded the gene-cell count matrix for the “Fresh 68K PBMCs” [<xref ref-type="bibr" rid="CR36">36</xref>] from <ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/single-cell-gene-expression/datasets">https://support.10xgenomics.com/single-cell-gene-expression/datasets</ext-link> (SRP073767). All 13 PbmcBench datasets, 7 different sequencing protocols applied on 2 PBMC samples, were downloaded from the Broad Institute Single Cell portal <ext-link ext-link-type="uri" xlink:href="https://portals.broadinstitute.org/single_cell/study/SCP424/single-cell-comparison-pbmc-data">https://portals.broadinstitute.org/single_cell/study/SCP424/single-cell-comparison-pbmc-data</ext-link>. The cell population annotation for all datasets was provided with the data, except the Zheng 68K dataset, for which we obtained the cell population annotation from <ext-link ext-link-type="uri" xlink:href="https://github.com/10XGenomics/single-cell-3prime-paper/tree/master/pbmc68k_analysis">https://github.com/10XGenomics/single-cell-3prime-paper/tree/master/pbmc68k_analysis</ext-link>. These annotations were used as a “ground truth” during the evaluation of the cell population predictions obtained from the classification methods.</p>
    </sec>
    <sec id="Sec19">
      <title>Data preprocessing</title>
      <p id="Par58">Based on the manual annotation provided in the datasets, we started by filtering out cells that were labeled as doublets, debris, or unlabeled cells. Next, we filtered genes with zero counts across all cells. For cells, we calculated the median number of detected genes per cell, and from that, we obtained the median absolute deviation (MAD) across all cells in the log scale. We filtered out cells when the total number of detected genes was below three MAD from the median number of detected genes per cell. The number of cells and genes in Table <xref rid="Tab2" ref-type="table">2</xref> represent the size of each dataset after this stage of preprocessing.</p>
      <p id="Par59">Moreover, before applying cross-validation to evaluate each classifier, we excluded cell populations with less than 10 cells across the entire dataset; Table <xref rid="Tab2" ref-type="table">2</xref> summarizes the number of cell populations before and after this filtration step for each dataset.</p>
    </sec>
    <sec id="Sec20">
      <title>Intra-dataset classification</title>
      <p id="Par60">For the supervised classifiers, we evaluated the performance by applying a 5-fold cross-validation across each dataset after filtering genes, cells, and small cell populations. The folds were divided in a stratified manner in order to keep equal proportions of each cell population in each fold. The training and testing folds were exactly the same for all classifiers.</p>
      <p id="Par61">The prior-knowledge classifiers, <italic>Garnett</italic>, <italic>Moana</italic>, <italic>DigitalCellSorter</italic>, and <italic>SCINA</italic>, were only evaluated on the Zheng 68K and Zheng sorted datasets, for which the marker gene files or the pretrained classifiers were available, after filtering genes and cells. Each classifier uses the dataset and the marker gene file as inputs and outputs the cell population label corresponding to each cell. No cross-validation is applied in this case, except for <italic>Garnett</italic> where we could either use the pretrained version (<italic>Garnett</italic><sub><italic>pretrained</italic></sub>) provided from the original study, or train our own classifier using the marker gene file along with the training data (<italic>Garnett</italic><sub><italic>CV</italic></sub>). In this case, we applied 5-fold cross-validation using the same train and test sets described earlier. Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1 shows the mapping of cell populations between the Zheng datasets and each of the prior-knowledge classifiers. For <italic>Moana</italic>, a pretrained classifier was used, this classifier also predicted cells to be memory CD8+ T cells and CD16+ monocytes, while these cell populations were not in the Zheng datasets.</p>
    </sec>
    <sec id="Sec21">
      <title>Evaluation of marker genes</title>
      <p id="Par62">The performance and choice of the marker genes per cell population per classifier were evaluated by comparing the F1-score of each cell population with four different characteristics of the marker genes across the cells for that particular cell population: (1) the number of marker genes, (2) the mean expression, (3) the average dropout rate, and (4) the average beta of the marker genes [<xref ref-type="bibr" rid="CR37">37</xref>]. Beta is a score developed to measure how specific a marker gene for a certain cell population is based on binary expression.</p>
    </sec>
    <sec id="Sec22">
      <title>Selecting marker genes using differential expression</title>
      <p id="Par63">Using the cross-validation scheme, training data of each fold was used to select sets of 5, 10, 15, and 20 differentially expressed (DE) marker genes. First, if the data was not already normalized, a CPM read count normalization was applied to the data. Next, the data was log-transformed using <italic>log</italic><sub>2</sub>(<italic>count</italic> + 1), and afterwards, the DE test could be applied. As recommended in [<xref ref-type="bibr" rid="CR48">48</xref>], MAST was used to find the DE genes [<xref ref-type="bibr" rid="CR49">49</xref>]. The implementation of MAST in the FindAllMarkers() function of Seurat v2.3.0 was used to do a one-vs-all differential expression analysis [<xref ref-type="bibr" rid="CR50">50</xref>]. Genes returned by Seurat were sorted, and the top 5, 10, 15, or 20 significant genes with a positive fold change were selected as marker genes. These marker genes were then used for population prediction of the test data of the corresponding fold. These marker gene lists can be used by prior-knowledge classifiers such as <italic>SCINA</italic>, <italic>Garnett</italic><sub><italic>CV</italic></sub>, and <italic>DigitalCellSorter</italic>, by modifying the cell type marker gene file required as an input to these classifiers. Such modification cannot be applied to the pretrained classifiers of <italic>Garnett</italic><sub><italic>pretrained</italic></sub> and <italic>Moana</italic>.</p>
    </sec>
    <sec id="Sec23">
      <title>Dataset complexity</title>
      <p id="Par64">To describe the complexity of a dataset, the average expression of all genes for each cell population (<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\mathrm{avg}}_{C_i} $$\end{document}</tex-math><mml:math id="M2" display="inline"><mml:msub><mml:mi>avg</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:math><inline-graphic xlink:href="13059_2019_1795_Article_IEq1.gif"/></alternatives></inline-formula>) in the dataset was calculated, representing the prototype of each cell population in the full gene space. Next, the pairwise Pearson correlation between these centroids was calculated <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \underset{\forall i,j}{\mathrm{corr}}\left({\mathrm{avg}}_{C_i},{\mathrm{avg}}_{C_j}\right) $$\end{document}</tex-math><mml:math id="M4" display="inline"><mml:munder><mml:mtext>corr</mml:mtext><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>avg</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:msub><mml:mi>avg</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="13059_2019_1795_Article_IEq2.gif"/></alternatives></inline-formula>. For each cell population, the highest correlation to another cell population was recorded. Finally, the mean of these per cell population maximum correlations was taken to describe the complexity of a dataset.
<disp-formula id="Equa"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \mathrm{Complexity}=\mathrm{mean}\left(\underset{\forall i,i\ne j}{\max}\underset{\forall i,j}{\mathrm{corr}}\left({\mathrm{avg}}_{C_i},{\mathrm{avg}}_{C_j}\right)\right) $$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mtext>Complexity</mml:mtext><mml:mo>=</mml:mo><mml:mtext>mean</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:munder><mml:mo>max</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mtext>corr</mml:mtext><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>avg</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:msub><mml:mi>avg</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="13059_2019_1795_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec24">
      <title>Inter-dataset classification</title>
      <sec id="Sec25">
        <title>CellBench</title>
        <p id="Par65">Both CellBench datasets, 10X and CEL-Seq2, were used once as training data and once as test data, to obtain predictions for the five lung cancer cell lines. The common set of detected genes by both datasets was used as features in this experiment.</p>
      </sec>
      <sec id="Sec26">
        <title>PbmcBench</title>
        <p id="Par66">Using pbmc1 sample only, we tested all train-test pairwise combinations between all 7 protocols, resulting in 42 experiments. Using both pbmc1 and pbmc2 samples, for the same protocol, we used pbmc1 as training data and pbmc2 as test data, resulting in 6 additional experiments (10Xv3 was not applied for pbmc2). As we are now dealing with PBMC data, we evaluated all classifiers, including the prior-knowledge classifiers, as well as the modified versions of <italic>SCINA</italic>, <italic>Garnett</italic><sub><italic>CV</italic></sub>, and <italic>DigitalCellSorter</italic>, in which the marker genes are obtained through differential expression from the training data as previously described. Through all these 48 experiments, genes that are not expressed in the training data were excluded from the feature space. Also, as these PbmcBench datasets differ in the number of cell populations (Table <xref rid="Tab2" ref-type="table">2</xref>), only the cell populations provided by the training data were used for the test data prediction evaluation.</p>
      </sec>
      <sec id="Sec27">
        <title>Brain</title>
        <p id="Par67">We used the three brain datasets, VISp, ALM, and MTG with two levels of annotations, 3 and 34 cell populations. We tested all possible train-test combinations, by either using one dataset to train and test on another (6 experiments) or using two concatenated datasets to train and test on the third (3 experiments). A total of 9 experiments were applied for each annotation level. We used the common set of detected genes between the datasets involved in each experiment as features.</p>
      </sec>
      <sec id="Sec28">
        <title>Pancreas</title>
        <p id="Par68">We selected the four major endocrine pancreatic cell types (alpha, beta, delta, and gamma) across all four human pancreatic datasets: Baron Human, Muraro, Segerstolpe, and Xin. Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2 summarizes the number of cells in each cell type across all datasets. To account for batch effects and technical variations between different protocols, datasets were aligned using MNN [<xref ref-type="bibr" rid="CR41">41</xref>] from the scran R package (version 1.1.2.0). Using both the raw data (unaligned) and the aligned data, we applied leave-one-dataset-out cross-validation where we train on three datasets and test on the left out dataset.</p>
      </sec>
    </sec>
    <sec id="Sec29">
      <title>Performance evaluation metrics</title>
      <p id="Par69">The performance of the methods on the datasets is evaluated using three different metrics: (1) For each cell population in the dataset, the F1-score is reported. The median of these F1-scores is used as a measure for the performance on the dataset. (2) Some of the methods do not label all the cells. These unassigned cells are not considered in the F1-score calculation. The percentage of unlabeled cells is also used to evaluate the performance. (3) The computation time of the methods is also measured.</p>
    </sec>
    <sec id="Sec30">
      <title>Feature selection</title>
      <p id="Par70">Genes are selected as features based on their dropout rate. The method used here is based on the method described in [<xref ref-type="bibr" rid="CR22">22</xref>]. During feature selection, a sorted list of the genes is made. Based on this list, the top <italic>n</italic> number of genes can be easily selected during the experiments. First, the data is normalized using <italic>log</italic><sub>2</sub>(<italic>count</italic> + 1). Next, for each gene, the percentage of dropouts, <italic>d</italic>, and the mean, <italic>m</italic>, of the normalized data are calculated. Genes that have a mean or dropout rate of 0 are not considered during the next steps. These genes will be at the bottom of the sorted list. For all other genes, a linear model is fitted to the mean and log2(<italic>d</italic>). Based on their residuals, the genes are sorted in descending order and added to the top of the list.</p>
    </sec>
    <sec id="Sec31">
      <title>Scalability</title>
      <p id="Par71">For the scalability experiment, we used the TM dataset. To ensure that the dataset could be downsampled without losing cell populations, only the 16 most abundant cell populations were considered during this experiment. We downsampled these cell populations in a stratified way to 1, 5, 10, 20, 50, and 100% of its original size (45,469 cells).</p>
    </sec>
    <sec id="Sec32">
      <title>Rejection</title>
      <sec id="Sec33">
        <title>Negative control</title>
        <p id="Par72">Two human datasets, Zheng 68K and Baron Human, and two mouse datasets, AMB16 and Baron Mouse, were used. The Zheng 68K dataset was first stratified downsampled to 11% of its original size to reduce computation time. For each species, two different experiments were applied by using one dataset as a training set and the other as a test set and vice versa.</p>
      </sec>
      <sec id="Sec34">
        <title>Unseen cell populations</title>
        <p id="Par73">Zheng 68K dataset was stratified downsampled to 11% of its original size to reduce computation time. Three different experiments were conducted. First, all cell populations that are a subpopulation of T cells were considered the test set. Next, the test set consisted of all subpopulations of CD4+ T cells. Last, only the CD4+/CD45RO+ memory T cells were in the test set. Each time, all cell populations that were not in the test set were part of the training set. Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3 gives an exact overview of the populations per training and test set.</p>
      </sec>
    </sec>
    <sec id="Sec35">
      <title>Benchmarking pipeline</title>
      <p id="Par74">In order to ensure reproducibility and support the future extension of this benchmarking work with new classification methods and benchmarking datasets, a Snakemake [<xref ref-type="bibr" rid="CR51">51</xref>] workflow for automating the performed benchmarking analyses was developed with an MIT license (<ext-link ext-link-type="uri" xlink:href="https://github.com/tabdelaal/scRNAseq_Benchmark/tree/snakemake_and_docker">https://github.com/tabdelaal/scRNAseq_Benchmark/</ext-link>). Each tool (license permitting) is packaged in a Docker container (<ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/u/scrnaseqbenchmark">https://hub.docker.com/u/scrnaseqbenchmark</ext-link>) alongside the wrapper scripts and their dependencies. These images will be used through Snakemake’s singularity integration to allow the workflow to be run without the requirement to install specific methods and to ensure reproducibility. Documentation is also provided to execute and extend this benchmarking workflow to help researchers to further evaluate interested methods.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Additional files</title>
    <sec id="Sec36">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="13059_2019_1795_MOESM1_ESM.pdf">
            <label>Additional file 1</label>
            <caption>
              <p>Supplementary data, Tables S1-S4 and Figures S1–13. (PDF 12800 kb)</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="13059_2019_1795_MOESM2_ESM.docx">
            <label>Additional file 2</label>
            <caption>
              <p>Review history. (DOCX 42 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>Tamim Abdelaal and Lieke Michielsen contributed equally to this work.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
    <sec id="FPar20">
      <title>Review history</title>
      <p id="Par760">The review history is available as Additional file <xref rid="MOESM2" ref-type="media">2</xref>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>TA, LM, MJTR, and AM conceived the study and designed the experiments. TA and LM performed the experiments. DH, DC, and HM designed and developed the Snakemake workflow. MJTR and AM supervised the experiments. TA, LM, HM, and AM wrote the manuscript. All authors reviewed and approved the manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the European Commission of a H2020 MSCA award under proposal number [675743] (ISPIC).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The filtered datasets analyzed during the current study can be downloaded from Zenodo (10.5281/zenodo.3357167). The source code is available in the GitHub repository, at <ext-link ext-link-type="uri" xlink:href="https://github.com/tabdelaal/scRNAseq_Benchmark">https://github.com/tabdelaal/scRNAseq_Benchmark</ext-link> [<xref ref-type="bibr" rid="CR52">52</xref>], and in the Zenodo repository, at 10.5281/zenodo.3369158 [<xref ref-type="bibr" rid="CR53">53</xref>]. The source code is released under MIT license. Datasets accession numbers: AMB, VISp, and ALM [<xref ref-type="bibr" rid="CR35">35</xref>] (GSE115746), MTG [<xref ref-type="bibr" rid="CR31">31</xref>] (phs001790), Baron Mouse [<xref ref-type="bibr" rid="CR30">30</xref>] (GSE84133), Baron Human [<xref ref-type="bibr" rid="CR30">30</xref>] (GSE84133), Muraro [<xref ref-type="bibr" rid="CR31">31</xref>] (GSE85241), Segerstolpe [<xref ref-type="bibr" rid="CR32">32</xref>] (E-MTAB-5061), Xin [<xref ref-type="bibr" rid="CR33">33</xref>] (GSE81608), CellBench 10X [<xref ref-type="bibr" rid="CR34">34</xref>] (GSM3618014), CellBench CEL-Seq2 [<xref ref-type="bibr" rid="CR34">34</xref>] (GSM3618022, GSM3618023, GSM3618024), TM [<xref ref-type="bibr" rid="CR6">6</xref>] (GSE109774), and Zheng sorted and Zheng 68K [<xref ref-type="bibr" rid="CR36">36</xref>] (SRP073767). The PbmcBench datasets [<xref ref-type="bibr" rid="CR38">38</xref>] are not yet uploaded to any data repository.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p id="Par75">Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p id="Par76">Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par77">The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Svensson</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Vento-Tormo</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Teichmann</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <article-title>Exponential scaling of single-cell RNA-seq in the past decade</article-title>
        <source>Nat Protoc</source>
        <year>2018</year>
        <volume>13</volume>
        <fpage>599</fpage>
        <lpage>604</lpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2017.149</pub-id>
        <?supplied-pmid 29494575?>
        <pub-id pub-id-type="pmid">29494575</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Plass</surname>
            <given-names>Mireya</given-names>
          </name>
          <name>
            <surname>Solana</surname>
            <given-names>Jordi</given-names>
          </name>
          <name>
            <surname>Wolf</surname>
            <given-names>F. Alexander</given-names>
          </name>
          <name>
            <surname>Ayoub</surname>
            <given-names>Salah</given-names>
          </name>
          <name>
            <surname>Misios</surname>
            <given-names>Aristotelis</given-names>
          </name>
          <name>
            <surname>Glažar</surname>
            <given-names>Petar</given-names>
          </name>
          <name>
            <surname>Obermayer</surname>
            <given-names>Benedikt</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>Fabian J.</given-names>
          </name>
          <name>
            <surname>Kocks</surname>
            <given-names>Christine</given-names>
          </name>
          <name>
            <surname>Rajewsky</surname>
            <given-names>Nikolaus</given-names>
          </name>
        </person-group>
        <article-title>Cell type atlas and lineage tree of a whole complex animal by single-cell transcriptomics</article-title>
        <source>Science</source>
        <year>2018</year>
        <volume>360</volume>
        <issue>6391</issue>
        <fpage>eaaq1723</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aaq1723</pub-id>
        <pub-id pub-id-type="pmid">29674432</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Packer</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Ramani</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Cusanovich</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Huynh</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Daza</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comprehensive single-cell transcriptional profiling of a multicellular organism</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>357</volume>
        <fpage>661</fpage>
        <lpage>667</lpage>
        <pub-id pub-id-type="doi">10.1126/science.aam8940</pub-id>
        <?supplied-pmid 28818938?>
        <pub-id pub-id-type="pmid">28818938</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fincher</surname>
            <given-names>Christopher T.</given-names>
          </name>
          <name>
            <surname>Wurtzel</surname>
            <given-names>Omri</given-names>
          </name>
          <name>
            <surname>de Hoog</surname>
            <given-names>Thom</given-names>
          </name>
          <name>
            <surname>Kravarik</surname>
            <given-names>Kellie M.</given-names>
          </name>
          <name>
            <surname>Reddien</surname>
            <given-names>Peter W.</given-names>
          </name>
        </person-group>
        <article-title>Cell type transcriptome atlas for the planarianSchmidtea mediterranea</article-title>
        <source>Science</source>
        <year>2018</year>
        <volume>360</volume>
        <issue>6391</issue>
        <fpage>eaaq1736</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aaq1736</pub-id>
        <pub-id pub-id-type="pmid">29674431</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Han</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Fei</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lai</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mapping the Mouse Cell Atlas by Microwell-Seq</article-title>
        <source>Cell</source>
        <year>2018</year>
        <volume>173</volume>
        <fpage>1307</fpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2018.05.012</pub-id>
        <?supplied-pmid 29775597?>
        <pub-id pub-id-type="pmid">29775597</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schaum</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Karkanias</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Neff</surname>
            <given-names>NF</given-names>
          </name>
          <name>
            <surname>May</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Quake</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Wyss-Coray</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell transcriptomics of 20 mouse organs creates a Tabula Muris</article-title>
        <source>Nature</source>
        <year>2018</year>
        <volume>562</volume>
        <fpage>367</fpage>
        <lpage>372</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-018-0590-4</pub-id>
        <pub-id pub-id-type="pmid">30283141</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Spielmann</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ibrahim</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>AJ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The single-cell transcriptional landscape of mammalian organogenesis</article-title>
        <source>Nature</source>
        <year>2019</year>
        <volume>566</volume>
        <fpage>496</fpage>
        <lpage>502</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-019-0969-x</pub-id>
        <?supplied-pmid 30787437?>
        <pub-id pub-id-type="pmid">30787437</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Henry</surname>
            <given-names>V. J.</given-names>
          </name>
          <name>
            <surname>Bandrowski</surname>
            <given-names>A. E.</given-names>
          </name>
          <name>
            <surname>Pepin</surname>
            <given-names>A.-S.</given-names>
          </name>
          <name>
            <surname>Gonzalez</surname>
            <given-names>B. J.</given-names>
          </name>
          <name>
            <surname>Desfeux</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>OMICtools: an informative directory for multi-omic data analysis</article-title>
        <source>Database</source>
        <year>2014</year>
        <volume>2014</volume>
        <issue>0</issue>
        <fpage>bau069</fpage>
        <lpage>bau069</lpage>
        <pub-id pub-id-type="doi">10.1093/database/bau069</pub-id>
        <pub-id pub-id-type="pmid">25024350</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zappia</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Phipson</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Oshlack</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Exploring the single-cell RNA-seq analysis landscape with the scRNA-tools database</article-title>
        <source>PLoS Comput Biol</source>
        <year>2018</year>
        <volume>14</volume>
        <fpage>e1006245</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006245</pub-id>
        <?supplied-pmid 29939984?>
        <pub-id pub-id-type="pmid">29939984</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saelens</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Cannoodt</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Todorov</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Saeys</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A comparison of single-cell trajectory inference methods</article-title>
        <source>Nat Biotechnol</source>
        <year>2019</year>
        <volume>37</volume>
        <fpage>547</fpage>
        <lpage>554</lpage>
        <pub-id pub-id-type="doi">10.1038/s41587-019-0071-9</pub-id>
        <?supplied-pmid 30936559?>
        <pub-id pub-id-type="pmid">30936559</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duò</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Robinson</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Soneson</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>A systematic performance evaluation of clustering methods for single-cell RNA-seq data</article-title>
        <source>F1000Res</source>
        <year>2018</year>
        <volume>7</volume>
        <fpage>1141</fpage>
        <pub-id pub-id-type="doi">10.12688/f1000research.15666.2</pub-id>
        <?supplied-pmid 30271584?>
        <pub-id pub-id-type="pmid">30271584</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Soneson</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Robinson</surname>
            <given-names>MD</given-names>
          </name>
        </person-group>
        <article-title>Bias, robustness and scalability in single-cell differential expression analysis</article-title>
        <source>Nat Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>255</fpage>
        <lpage>261</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.4612</pub-id>
        <?supplied-pmid 29481549?>
        <pub-id pub-id-type="pmid">29481549</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Diaz-Mejia</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Javier Diaz-Mejia</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Pico</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>MacParland</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Ketela</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Evaluation of methods to assign cell type labels to cell clusters from single-cell RNA-sequencing data</source>
        <year>2019</year>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Pliner HA, Shendure J, Trapnell C. Supervised classification enables rapid annotation of cell atlases. bioRxiv. 2019; 538652. 10.1101/538652<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/jD2Xo">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Wagner F, Yanai I. Moana: A robust and scalable cell type classification framework for single-cell RNA-Seq data. bioRxiv. 2018; 456129. 10.1101/456129<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/GIxrc">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Domanskyi S, Szedlak A, Hawkins NT, Wang J, Paternostro G, Piermarocchi C. Polled Digital Cell Sorter (p-DCS): automatic identification of hematological cell types from single cell RNA-sequencing clusters. bioRxiv. 2019; 539833. 10.1101/539833<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/Aazdm">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">Zhang Z, Luo D, Zhong X, Choi JH, Ma Y, Mahrt E, et al. SCINA: semi-supervised analysis of single cells in silico. bioRxiv. 2019; 559872. 10.1101/559872<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/zqYpC">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lopez</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Regier</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cole</surname>
            <given-names>MB</given-names>
          </name>
          <name>
            <surname>Jordan</surname>
            <given-names>MI</given-names>
          </name>
          <name>
            <surname>Yosef</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Deep generative modeling for single-cell transcriptomics</article-title>
        <source>Nat Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>1053</fpage>
        <lpage>1058</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0229-2</pub-id>
        <?supplied-pmid 30504886?>
        <pub-id pub-id-type="pmid">30504886</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Cao Z-J, Wei L, Lu S, Yang D-C, Gao G. Cell BLAST: searching large-scale scRNA-seq databases via unbiased cell embedding. bioRxiv. 2019; 587360. 10.1101/587360<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/2erN7">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Ma F, Pellegrini M. Automated identification of cell types in single cell RNA sequencing. bioRxiv. 2019; 532093. 10.1101/532093<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/pITwW">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Johnson TS, Wang T, Huang Z, Yu CY, Wu Y, Han Y, et al. LAmbDA: label ambiguous domain adaptation dataset integration reduces batch effects and improves dsubtype detection. Bioinformatics. 2019. 10.1093/bioinformatics/btz295<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/7Hgi">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kiselev</surname>
            <given-names>VY</given-names>
          </name>
          <name>
            <surname>Yiu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hemberg</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>scmap: projection of single-cell RNA-seq data across data sets</article-title>
        <source>Nat Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>359</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.4644</pub-id>
        <?supplied-pmid 29608555?>
        <pub-id pub-id-type="pmid">29608555</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Alquicira-Hernandez J, Nguyen Q, Powell JE. scPred: scPred: cell type prediction at single-cell resolution. bioRxiv. 2018; 369538. 10.1101/369538<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/trO4D">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Kanter JK de, Lijnzaad P, Candelli T, Margaritis T, Holstege F. CHETAH: a selective, hierarchical cell type identification method for single-cell RNA sequencing. bioRxiv. 2019; 558908. 10.1101/558908<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/SQu7Z">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lieberman</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Rokach</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shay</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>CaSTLe – classification of single cells by transfer learning: harnessing the power of publicly available single cell RNA sequencing experiments to annotate new experiments</article-title>
        <source>PLoS One</source>
        <year>2018</year>
        <volume>13</volume>
        <fpage>e0205499</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0205499</pub-id>
        <?supplied-pmid 30304022?>
        <pub-id pub-id-type="pmid">30304022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aran</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Looney</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fong</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Reference-based analysis of lung single-cell sequencing reveals a transitional profibrotic macrophage</article-title>
        <source>Nat Immunol</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>163</fpage>
        <lpage>172</lpage>
        <pub-id pub-id-type="doi">10.1038/s41590-018-0276-y</pub-id>
        <?supplied-pmid 30643263?>
        <pub-id pub-id-type="pmid">30643263</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Boufea K, Seth S, Batada NN. scID: identification of equivalent transcriptional cell populations across single cell RNA-seq data using discriminant analysis. 10.1101/470203<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/LloZA">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Tan Y, Cahan P. SingleCellNet: a computational tool to classify single cell RNA-Seq data across platforms and across species. bioRxiv. 2018; 508085. 10.1101/508085<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/7Snvz">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Thirion</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Grisel</surname>
            <given-names>O</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: Machine Learning in Python</article-title>
        <source>JMLR.</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>30</lpage>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baron</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Veres</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wolock</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Faust</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Gaujoux</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Vetere</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A single-cell transcriptomic map of the human and mouse pancreas reveals inter- and intra-cell population structure</article-title>
        <source>Cell Syst</source>
        <year>2016</year>
        <volume>3</volume>
        <fpage>346</fpage>
        <lpage>60.e4</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2016.08.011</pub-id>
        <?supplied-pmid 27667365?>
        <pub-id pub-id-type="pmid">27667365</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Muraro</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Dharmadhikari</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Grün</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Groen</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Dielen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Jansen</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A single-cell transcriptome atlas of the human pancreas</article-title>
        <source>Cell Syst</source>
        <year>2016</year>
        <volume>3</volume>
        <fpage>385</fpage>
        <lpage>94.e3</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2016.09.002</pub-id>
        <?supplied-pmid 27693023?>
        <pub-id pub-id-type="pmid">27693023</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Segerstolpe</surname>
            <given-names>Å</given-names>
          </name>
          <name>
            <surname>Palasantza</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Eliasson</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Andersson</surname>
            <given-names>E-M</given-names>
          </name>
          <name>
            <surname>Andréasson</surname>
            <given-names>A-C</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell transcriptome profiling of human pancreatic islets in health and type 2 diabetes</article-title>
        <source>Cell Metab</source>
        <year>2016</year>
        <volume>24</volume>
        <fpage>593</fpage>
        <lpage>607</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cmet.2016.08.020</pub-id>
        <?supplied-pmid 27667667?>
        <pub-id pub-id-type="pmid">27667667</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Okamoto</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ni</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Adler</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>RNA sequencing of single human islet cells reveals type 2 diabetes genes</article-title>
        <source>Cell Metab</source>
        <year>2016</year>
        <volume>24</volume>
        <fpage>608</fpage>
        <lpage>615</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cmet.2016.08.018</pub-id>
        <?supplied-pmid 27667665?>
        <pub-id pub-id-type="pmid">27667665</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tian</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Freytag</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lê Cao</surname>
            <given-names>K-A</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>JalalAbadi</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Benchmarking single cell RNA-sequencing analysis pipelines using mixture control experiments</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>479</fpage>
        <lpage>487</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0425-8</pub-id>
        <?supplied-pmid 31133762?>
        <pub-id pub-id-type="pmid">31133762</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tasic</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Graybuck</surname>
            <given-names>LT</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>KA</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>TN</given-names>
          </name>
          <name>
            <surname>Bertagnolli</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Shared and distinct transcriptomic cell types across neocortical areas</article-title>
        <source>Nature</source>
        <year>2018</year>
        <volume>563</volume>
        <fpage>72</fpage>
        <lpage>78</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-018-0654-5</pub-id>
        <?supplied-pmid 30382198?>
        <pub-id pub-id-type="pmid">30382198</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>GXY</given-names>
          </name>
          <name>
            <surname>Terry</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Belgrader</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ryvkin</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Bent</surname>
            <given-names>ZW</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Massively parallel digital transcriptional profiling of single cells</article-title>
        <source>Nat Commun</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>14049</fpage>
        <pub-id pub-id-type="doi">10.1038/ncomms14049</pub-id>
        <?supplied-pmid 28091601?>
        <pub-id pub-id-type="pmid">28091601</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hodge</surname>
            <given-names>Rebecca D.</given-names>
          </name>
          <name>
            <surname>Bakken</surname>
            <given-names>Trygve E.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>Jeremy A.</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>Kimberly A.</given-names>
          </name>
          <name>
            <surname>Barkan</surname>
            <given-names>Eliza R.</given-names>
          </name>
          <name>
            <surname>Graybuck</surname>
            <given-names>Lucas T.</given-names>
          </name>
          <name>
            <surname>Close</surname>
            <given-names>Jennie L.</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>Brian</given-names>
          </name>
          <name>
            <surname>Johansen</surname>
            <given-names>Nelson</given-names>
          </name>
          <name>
            <surname>Penn</surname>
            <given-names>Osnat</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Zizhen</given-names>
          </name>
          <name>
            <surname>Eggermont</surname>
            <given-names>Jeroen</given-names>
          </name>
          <name>
            <surname>Höllt</surname>
            <given-names>Thomas</given-names>
          </name>
          <name>
            <surname>Levi</surname>
            <given-names>Boaz P.</given-names>
          </name>
          <name>
            <surname>Shehata</surname>
            <given-names>Soraya I.</given-names>
          </name>
          <name>
            <surname>Aevermann</surname>
            <given-names>Brian</given-names>
          </name>
          <name>
            <surname>Beller</surname>
            <given-names>Allison</given-names>
          </name>
          <name>
            <surname>Bertagnolli</surname>
            <given-names>Darren</given-names>
          </name>
          <name>
            <surname>Brouner</surname>
            <given-names>Krissy</given-names>
          </name>
          <name>
            <surname>Casper</surname>
            <given-names>Tamara</given-names>
          </name>
          <name>
            <surname>Cobbs</surname>
            <given-names>Charles</given-names>
          </name>
          <name>
            <surname>Dalley</surname>
            <given-names>Rachel</given-names>
          </name>
          <name>
            <surname>Dee</surname>
            <given-names>Nick</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>Song-Lin</given-names>
          </name>
          <name>
            <surname>Ellenbogen</surname>
            <given-names>Richard G.</given-names>
          </name>
          <name>
            <surname>Fong</surname>
            <given-names>Olivia</given-names>
          </name>
          <name>
            <surname>Garren</surname>
            <given-names>Emma</given-names>
          </name>
          <name>
            <surname>Goldy</surname>
            <given-names>Jeff</given-names>
          </name>
          <name>
            <surname>Gwinn</surname>
            <given-names>Ryder P.</given-names>
          </name>
          <name>
            <surname>Hirschstein</surname>
            <given-names>Daniel</given-names>
          </name>
          <name>
            <surname>Keene</surname>
            <given-names>C. Dirk</given-names>
          </name>
          <name>
            <surname>Keshk</surname>
            <given-names>Mohamed</given-names>
          </name>
          <name>
            <surname>Ko</surname>
            <given-names>Andrew L.</given-names>
          </name>
          <name>
            <surname>Lathia</surname>
            <given-names>Kanan</given-names>
          </name>
          <name>
            <surname>Mahfouz</surname>
            <given-names>Ahmed</given-names>
          </name>
          <name>
            <surname>Maltzer</surname>
            <given-names>Zoe</given-names>
          </name>
          <name>
            <surname>McGraw</surname>
            <given-names>Medea</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>Thuc Nghi</given-names>
          </name>
          <name>
            <surname>Nyhus</surname>
            <given-names>Julie</given-names>
          </name>
          <name>
            <surname>Ojemann</surname>
            <given-names>Jeffrey G.</given-names>
          </name>
          <name>
            <surname>Oldre</surname>
            <given-names>Aaron</given-names>
          </name>
          <name>
            <surname>Parry</surname>
            <given-names>Sheana</given-names>
          </name>
          <name>
            <surname>Reynolds</surname>
            <given-names>Shannon</given-names>
          </name>
          <name>
            <surname>Rimorin</surname>
            <given-names>Christine</given-names>
          </name>
          <name>
            <surname>Shapovalova</surname>
            <given-names>Nadiya V.</given-names>
          </name>
          <name>
            <surname>Somasundaram</surname>
            <given-names>Saroja</given-names>
          </name>
          <name>
            <surname>Szafer</surname>
            <given-names>Aaron</given-names>
          </name>
          <name>
            <surname>Thomsen</surname>
            <given-names>Elliot R.</given-names>
          </name>
          <name>
            <surname>Tieu</surname>
            <given-names>Michael</given-names>
          </name>
          <name>
            <surname>Quon</surname>
            <given-names>Gerald</given-names>
          </name>
          <name>
            <surname>Scheuermann</surname>
            <given-names>Richard H.</given-names>
          </name>
          <name>
            <surname>Yuste</surname>
            <given-names>Rafael</given-names>
          </name>
          <name>
            <surname>Sunkin</surname>
            <given-names>Susan M.</given-names>
          </name>
          <name>
            <surname>Lelieveldt</surname>
            <given-names>Boudewijn</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>David</given-names>
          </name>
          <name>
            <surname>Ng</surname>
            <given-names>Lydia</given-names>
          </name>
          <name>
            <surname>Bernard</surname>
            <given-names>Amy</given-names>
          </name>
          <name>
            <surname>Hawrylycz</surname>
            <given-names>Michael</given-names>
          </name>
          <name>
            <surname>Phillips</surname>
            <given-names>John W.</given-names>
          </name>
          <name>
            <surname>Tasic</surname>
            <given-names>Bosiljka</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>Hongkui</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>Allan R.</given-names>
          </name>
          <name>
            <surname>Koch</surname>
            <given-names>Christof</given-names>
          </name>
          <name>
            <surname>Lein</surname>
            <given-names>Ed S.</given-names>
          </name>
        </person-group>
        <article-title>Conserved cell types with divergent features in human versus mouse cortex</article-title>
        <source>Nature</source>
        <year>2019</year>
        <volume>573</volume>
        <issue>7772</issue>
        <fpage>61</fpage>
        <lpage>68</lpage>
        <pub-id pub-id-type="doi">10.1038/s41586-019-1506-7</pub-id>
        <pub-id pub-id-type="pmid">31435019</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Ding J, Adiconis X, Simmons SK, Kowalczyk MS, Hession CC, Marjanovic ND, et al. Systematic comparative analysis of single cell RNA-sequencing methods. bioRxiv. 2019; 632216. 10.1101/632216<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/vM9z">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Franzén O, Gan L-M, Björkegren JLM. PanglaoDB: a web server for exploration of mouse and human single-cell RNA sequencing data. Database. 2019;2019. 10.1093/database/baz046<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/HOhB">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Quan</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>CellMarker: a manually curated resource of cell markers in human and mouse</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <fpage>D721</fpage>
        <lpage>D728</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky900</pub-id>
        <?supplied-pmid 30289549?>
        <pub-id pub-id-type="pmid">30289549</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haghverdi</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lun</surname>
            <given-names>ATL</given-names>
          </name>
          <name>
            <surname>Morgan</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Marioni</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>421</fpage>
        <lpage>427</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.4091</pub-id>
        <?supplied-pmid 29608177?>
        <pub-id pub-id-type="pmid">29608177</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">McInnes L, Healy J, Melville JUMAP. Uniform manifold approximation and projection for dimension reduction. arXiv [stat.ML]. 2018; <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1802.03426">http://arxiv.org/abs/1802.03426</ext-link><ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/oOdZC">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Andrews</surname>
            <given-names>Tallulah S</given-names>
          </name>
          <name>
            <surname>Hemberg</surname>
            <given-names>Martin</given-names>
          </name>
        </person-group>
        <article-title>M3Drop: dropout-based feature selection for scRNASeq</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>35</volume>
        <issue>16</issue>
        <fpage>2865</fpage>
        <lpage>2867</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1044</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Training linear discriminant analysis in linear time</source>
        <year>2008</year>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Köhler ND, Büttner M, Theis FJ. Deep learning does not outperform classical machine learning for cell-type annotation. bioRxiv. 2019; 653907. 10.1101/653907<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/BdDN">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">van den Berg PR, Budnik B, Slavov N, Semrau S. Dynamic post-transcriptional regulation during embryonic stem cell differentiation. bioRxiv. 2017; 123497. 10.1101/123497<ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/3qMtz6/HE08">.</ext-link></mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crow</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ballouz</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>ZJ</given-names>
          </name>
          <name>
            <surname>Gillis</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Characterizing the replicability of cell types defined by single cell RNA-sequencing data using MetaNeighbor</article-title>
        <source>Nat Commun</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>884</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-018-03282-0</pub-id>
        <?supplied-pmid 29491377?>
        <pub-id pub-id-type="pmid">29491377</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luecken</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>FJ</given-names>
          </name>
        </person-group>
        <article-title>Current best practices in single-cell RNA-seq analysis: a tutorial</article-title>
        <source>Mol Syst Biol</source>
        <year>2019</year>
        <volume>15</volume>
        <fpage>e8746</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20188746</pub-id>
        <?supplied-pmid 31217225?>
        <pub-id pub-id-type="pmid">31217225</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Finak</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>McDavid</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yajima</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gersuk</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Shalek</surname>
            <given-names>AK</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MAST: a flexible statistical framework for assessing transcriptional changes and characterizing heterogeneity in single-cell RNA sequencing data</article-title>
        <source>Genome Biol</source>
        <year>2015</year>
        <volume>16</volume>
        <fpage>278</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-015-0844-5</pub-id>
        <?supplied-pmid 26653891?>
        <pub-id pub-id-type="pmid">26653891</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Butler</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hoffman</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Smibert</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Papalexi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Satija</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Integrating single-cell transcriptomic data across different conditions, technologies, and species</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <fpage>411</fpage>
        <lpage>420</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.4096</pub-id>
        <?supplied-pmid 29608179?>
        <pub-id pub-id-type="pmid">29608179</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Köster</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rahmann</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Snakemake—a scalable bioinformatics workflow engine</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>3600</fpage>
        <lpage>3600</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty350</pub-id>
        <?supplied-pmid 29788404?>
        <pub-id pub-id-type="pmid">29788404</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Abdelaal T, Michielsen L, Cats D, Hoogduin D, Mei H, Reinders MJT, et al. scRNA-seq classification benchmarking source code. Github. 2019. <ext-link ext-link-type="uri" xlink:href="https://github.com/tabdelaal/scRNAseq_Benchmark">https://github.com/tabdelaal/scRNAseq_Benchmark</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Abdelaal T, Michielsen L, Cats D, Hoogduin D, Mei H, Reinders MJT, et al. scRNA-seq classification benchmarking source code: Zenodo; 2019. 10.5281/zenodo.3369158.</mixed-citation>
    </ref>
  </ref-list>
</back>
