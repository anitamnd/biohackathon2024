<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6751173</article-id>
    <article-id pub-id-type="publisher-id">49967</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-019-49967-4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Multi-view based integrative analysis of gene expression data for identifying biomarkers</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Zi-Yi</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Xiao-Ying</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shu</surname>
          <given-names>Jun</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Hui</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7619-1400</contrib-id>
        <name>
          <surname>Ren</surname>
          <given-names>Yan-Qiong</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Zong-Ben</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Liang</surname>
          <given-names>Yong</given-names>
        </name>
        <address>
          <email>yliang@must.edu.mo</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label>Faculty of Information Technology &amp; State Key Laboratory of Quality Research in Chinese Medicines, Macau University of Science and Technology, Taipa, 999078 Macau China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1757 5521</institution-id><institution-id institution-id-type="GRID">grid.464311.5</institution-id><institution>Computer Engineering Technical College, </institution><institution>Guangdong Polytechnic of Science and Technology, </institution></institution-wrap>Zhuhai, 519090 China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0599 1243</institution-id><institution-id institution-id-type="GRID">grid.43169.39</institution-id><institution>School of Mathematics and Statistics &amp; Ministry of Education Key Lab of Intelligent Networks and Network Security, </institution><institution>Xi’an Jiaotong University, </institution></institution-wrap>Xi’an, 710049 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>9</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>9</volume>
    <elocation-id>13504</elocation-id>
    <history>
      <date date-type="received">
        <day>8</day>
        <month>4</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>30</day>
        <month>8</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The widespread applications in microarray technology have produced the vast quantity of publicly available gene expression datasets. However, analysis of gene expression data using biostatistics and machine learning approaches is a challenging task due to (1) high noise; (2) small sample size with high dimensionality; (3) batch effects and (4) low reproducibility of significant biomarkers. These issues reveal the complexity of gene expression data, thus significantly obstructing microarray technology in clinical applications. The integrative analysis offers an opportunity to address these issues and provides a more comprehensive understanding of the biological systems, but current methods have several limitations. This work leverages state of the art machine learning development for multiple gene expression datasets integration, classification and identification of significant biomarkers. We design a novel integrative framework, MVIAm - Multi-View based Integrative Analysis of microarray data for identifying biomarkers. It applies multiple cross-platform normalization methods to aggregate multiple datasets into a multi-view dataset and utilizes a robust learning mechanism Multi-View Self-Paced Learning (MVSPL) for gene selection in cancer classification problems. We demonstrate the capabilities of MVIAm using simulated data and studies of breast cancer and lung cancer, it can be applied flexibly and is an effective tool for facing the four challenges of gene expression data analysis. Our proposed model makes microarray integrative analysis more systematic and expands its range of applications.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Computational models</kwd>
      <kwd>Data integration</kwd>
      <kwd>Data mining</kwd>
      <kwd>Machine learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Macau Science and Technology Development Funds Grand No.003/2016/AFJ and No.0055/2018/A2 from the Macau Special Administrative Region of the People’s Republic of China.</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par2">Microarray technology is one of the most recent advances being used for cancer research, which can measure the expression levels of many thousands or tens of thousands of genes simultaneously. With the rapid development of microarray technology, many database repositories of high throughput gene expression data have been created and published for researchers to use, Gene Expression Omnibus (GEO), for example, currently have stored more than 2.76 million samples over 105,000 studies<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. The use of gene expression datasets to discover highly reliable biomarkers is an important goal in clinical applications. The significant biomarkers can help researchers to detect the disease in individuals, classify the type of disease, predict the response of therapy and so on<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>.</p>
    <p id="Par3">Analysis of gene expression data using biostatistics and machine learning approaches is facing four major challenges: (1) High noise: Random noise and systematic biases exist in gene expression data not only impact the scientific validity and costs of studies but also disrupts accurate prediction of phenotype that may ultimately impact patients<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup>. (2) Small sample size with high dimensionality: The gene expression dataset generally contains a large number of genes and small size of samples, which called large <italic>p</italic> &amp; small <italic>n</italic> problem<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. Only a small fraction of genes are closely relevant to the target disease, and most genes are irrelevant<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. From a machine learning perspective, numerous irrelevant genes may introduce noise and reduce the performance of the classifier<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. (3) Batch effects: It occurs because measurements are affected by many factors including experiments principle, data collection standards, and personnel differences. The systematic noise introduced when samples are processed in multiple batches have a detrimental effect on data derived from microarrays<sup><xref ref-type="bibr" rid="CR9">9</xref>,<xref ref-type="bibr" rid="CR10">10</xref></sup>. (4) Low reproducibility of significant biomarkers: The published significant biomarkers from internal validation rarely overlap with other research groups<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. These four issues reveal the complexity of gene expression data, which constrains the development of microarray technology in clinical applications.</p>
    <p id="Par4">To face these challenges and take advantage of multiple published gene expression datasets, the integrative analysis of gene expression data has become an effective tool by aggregating multiple datasets and increasing the statistical power in identifying a small subset of genes to effectively predict the type of the disease<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>. Current microarray integrative analysis was first proposed by Hamid <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, basically classified into “late stage” data integration and “early stage” data integration. However, current methods for microarray integrative analysis have several limitations. Most “late stage” data integration methods identify genes based on combining univariate summary statistics, such as <italic>p</italic>-value<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, effect size<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and rank aggregation<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup>. As a result, it is difficult to identify non-redundant significant genes and systematically determine (e.g. cross-validation) how many genes to include in the subset, such as GeneMeta<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> and metaArray<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. Moreover, such methods neglect correlations among genes and do not eliminate the batch effects between different datasets. Current “early stage” data integration methods usually apply one cross-platform normalization method to aggregate multiple datasets into a single unified large dataset. After that, classification and variable selection for the merged dataset can be achieved by the machine learning methods. For example, Ma <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> proposed the meta threshold gradient descent regularization (MTGDR) for gene selection in the integrative analysis of gene expression data. Meta-lasso method was published by Li <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, which not only boosts the statistic power to identify significant genes but also keeps the flexibility of gene selection. Recently, Hughey <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> developed integrative analysis using elastic net penalized with logistic regression model (L<sub><italic>EN</italic></sub>), a powerful and versatile method for variable selection in classification. Special emphasis, cross-platform normalization is an essential part of the “early stage” data integration, because it can eliminate the differences between datasets from different microarray platforms while preserving underlying the differences in biology<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. A number of cross-platform normalization methods have been developed and provide effective batch adjustment for microarray data, such as ComBat<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, cross-platform normalization (XPN) method<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, and batch effects removal (ber)<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. However, different cross-platform normalization methods are based on different statistical models with different accuracy, precision and overall effectiveness<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. Current “early stage” data integration methods usually apply one cross-platform normalization method, which cannot ensure maximum elimination of the batch effects. Beyond that, none of these integrative analysis methods have a robust learning mechanism to minimize the influence of the noise. Therefore, there is a crucial need for a novel integrative analysis method for robust analysis of the microarray data, prediction of cancer types and identification of significant biomarkers.</p>
    <p id="Par5">We design a novel integrative framework called MVIAm (Multi-View based Integrative Analysis of microarray data for identifying biomarkers). MVIAm can be divided into three phases: pre-processing each dataset, aggregation and generate multi-view data, and analysis of multi-view data. MVIAm aggregates multiple microarray gene expression datasets through different cross-platform normalization methods and generates multiple aggregated gene expression datasets. Each aggregated dataset has the same set of samples and features but is generated by the different statistical models, which belongs to one type of multi-view data<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. The novel integrative framework MVIAm extends the traditional “early” stage data integration to multi-view data integration. Generally, multi-view data contains complementary information and has more comprehensive information than those of single-view data<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. In recent years, several multi-view machine learning methods for integrating multi-view data have been developed<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR30">30</xref></sup>. The supervised multi-view data integration methods generally include concatenation-based and ensemble-based integration<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. MVIAm enables more multi-view machine learning methods for supervised homogeneous data integration. The multi-view gene expression data generated by MVIAm has the following characteristics:</p>
    <p id="Par6">Multi-view data generated by MVIAm can significantly increase the sample size, which greatly alleviates large <italic>p</italic> &amp; <italic>n</italic> problem and increase the statistical power in identifying biomarkers.<list list-type="bullet"><list-item><p id="Par7">Multi-view data typically contains complementary information and has more comprehensive understanding of the biological systems.</p></list-item><list-item><p id="Par8">The batch effects cannot be completely eliminated, meaning that each view of the data still has different types of bias.</p></list-item></list></p>
    <p id="Par9">Although quality control and different cross-platform normalization methods are used to process gene expression data, it is inevitable that the data has noises and biases. In the phase of analyzing gene expression data, in order to alleviate the impact of the noise on the learning process and take advantage of significantly increased data, we introduce a robust learning mechanism called self-paced learning<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. Self-paced learning (SPL) is a typical sample reweighting method, especially used in high noise situations<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. It was proposed based on the core idea of curriculum learning<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. Curriculum learning (CL) is inspired by human learning and is learned by gradually including samples from easy to complex into the training process. SPL embeds curriculum design as a regularization term into the learning objective, automatically select samples into training from easy to complex in a purely self-paced way. Due to its generality and generalization, SPL has been widely used in various tasks<sup><xref ref-type="bibr" rid="CR35">35</xref>–<xref ref-type="bibr" rid="CR38">38</xref></sup>. Moreover, Meng <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> have provided some new theoretical understanding of the SPL scheme, which helps us have a deep insight into it. To analysis multi-view gene expression data, we propose Multi-View Self-Paced Learning (MVSPL), a robust supervised multi-view data integration method. The main idea of MVSPL is to interactively recommend high-confidence samples with smaller loss values and automatically select samples from easy to complex to train the model for each view.</p>
    <p id="Par10">In summary, the main contributions of this work can be summarized as follows:<list list-type="bullet"><list-item><p id="Par11">We design a novel framework of gene expression data integration called MVIAm, which can generate multi-view gene expression data based on different cross-platform normalization methods. Moreover, we propose a robust learning method MVSPL to analyze multi-view gene expression data for gene selection and cancer classification problem. It is an effective tool to address the challenges of microarray data analysis.</p></list-item><list-item><p id="Par12">Experimental results on both simulation and real experiments substantiate the superiority of MVSPL as compared to a sparse logistic regression model with Lasso (L<sub>1</sub>), a sparse logistic regression model with elastic net (L<sub><italic>EN</italic></sub>), ensemble-based elastic net (Ensemble_EN) and SPL.</p></list-item><list-item><p id="Par13">Our proposed model makes gene expression integrative analysis more systematic and expands the range of applications that an integrative analysis can be used to address.</p></list-item></list></p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>The MVIAm integrative framework</title>
      <p id="Par14">Figure <xref rid="Fig1" ref-type="fig">1</xref> shows the pipeline of the MVIAm, which aggregates multiple microarray datasets and identifies the significant biomarkers, assesses the prediction performance of the model. MVIAm can be divided into three phases: pre-processing each dataset, aggregation and generate multi-view data, and analysis of multi-view data.<fig id="Fig1"><label>Figure 1</label><caption><p>MVIAm, a novel framework for data integrative analysis. The first phase inputs multiple microarray datasets and processes the data according to the pre-processing steps. For the second phase of MVIAm, it applies multiple cross-platform normalization methods to aggregate multiple datasets. Each aggregated dataset possesses the same set of samples and genes, but it is generated by the different statistical normalization models, which belongs to one type of multi-view data. The third phase is the analysis of multi-view microarray data, we propose the MVSPL approach to identify significant biomarkers and predict the type of cancer.</p></caption><graphic xlink:href="41598_2019_49967_Fig1_HTML" id="d29e526"/></fig></p>
      <sec id="Sec4">
        <title>Pre-processing each data set</title>
        <p id="Par15">The original Affymetrix data was first normalized and log-transformed by a robust multi-array average (RMA)<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> method. After that, downloading and installing the appropriate custom chip definition files (CDFs) packages according to the type of microarray platform. The CDF package is necessary for probe annotation for Affymetrix data. The probes of the normalized data can be successfully mapped to Entrez Gene IDs by annotation packages in Bioconductor<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. If multiple probes match a single Entrez ID, we calculated the median of values of those probes as the expression value for this gene.</p>
      </sec>
      <sec id="Sec5">
        <title>Aggregation and generate multi-view data</title>
        <p id="Par16">One challenge of microarray integrative analysis is that each gene expression dataset may have gene expression values for slightly different sets of genes. Commonly method, the common genes from all gene expression datasets are extracted as the merged set of genes. After that, MVIAm utilizes different cross-platform normalization methods to process the gene expression dataset to eliminate the batch effects. In this work, we use two cross-platform normalization methods to eliminate the batch effects, ComBat<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> and ber<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. ComBat is an Empirical Bayes method, includes two methods, a parametric prior method (ComBat_p) and a non-parametric method (ComBat_n), based on the prior distributions of the estimated parameters. Ber, removes batch effects by using a two-stage regression approach, includes two methods, with bagging method (ber_bg) and without bagging method (ber).</p>
      </sec>
      <sec id="Sec6">
        <title>Multi-view self-paced learning (MVSPL)</title>
        <p id="Par17">Here, we detailed introduce the proposed multi-view self-paced learning (MVSPL) model, which extends the self-paced learning<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> model to multi-view scenarios. The fundamental concept of SPL please see the part of related work. Suppose given a dataset with multiple views <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\{({X}_{1}^{(j)},{y}_{1}),({X}_{2}^{(j)},{y}_{2}),\ldots ,({X}_{n}^{(j)},{y}_{n})\}$$\end{document}</tex-math><mml:math id="M2"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq1.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{i}^{(j)}=({x}_{i1}^{(j)},{x}_{i2}^{(j)},\ldots ,{x}_{ip}^{(j)})$$\end{document}</tex-math><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq2.gif"/></alternatives></inline-formula> is the <italic>i</italic>-th input sample with <italic>p</italic> features under the <italic>j</italic>-th view and <italic>y</italic><sub><italic>i</italic></sub> is the <italic>i</italic>-th sample with the value 0 or 1 for every view in the classification model. Let <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L({y}_{i},f({x}_{i}^{(j)},{\beta }^{(j)}))$$\end{document}</tex-math><mml:math id="M6"><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq3.gif"/></alternatives></inline-formula> denotes the loss function, which calculates the loss between the real label <italic>y</italic><sub><italic>i</italic></sub> and the estimated value <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f({x}_{i}^{(j)},{\beta }^{(j)})$$\end{document}</tex-math><mml:math id="M8"><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq4.gif"/></alternatives></inline-formula> in the <italic>j</italic>-th view. The <italic>β</italic><sup>(<italic>j</italic>)</sup> represents the model parameter inside the decision function <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f({x}_{i}^{(j)},{\beta }^{(j)})$$\end{document}</tex-math><mml:math id="M10"><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq5.gif"/></alternatives></inline-formula>. The objective function of MVSPL can be expressed as:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{rcl}\mathop{{\rm{\min }}}\limits_{\begin{array}{c}{\beta }^{(j)},{v}^{(j)}\in {[0,1]}^{n},j=1,2,\ldots ,m\end{array}}E({\beta }^{(j)},{v}^{(j)};{\lambda }^{(j)},{\gamma }^{(j)},\delta ) &amp; = &amp; \mathop{\sum }\limits_{j=1}^{m}\mathop{\sum }\limits_{i=1}^{n}{v}_{i}^{(j)}L({y}_{i},{f}^{(j)}({x}_{i}^{(j)},{\beta }^{(j)}))\\  &amp;  &amp; +\,\mathop{\sum }\limits_{j=1}^{m}{\lambda }^{(j)}{\Vert {\beta }^{(j)}\Vert }_{1}-\mathop{\sum }\limits_{j=1}^{m}\mathop{\sum }\limits_{i=1}^{n}{\gamma }^{(j)}{v}_{i}^{(j)}\\  &amp;  &amp; -\delta \sum _{\begin{array}{c}\begin{array}{c}1\le k,j\le m,\\ k\ne j\end{array}\end{array}}{({v}^{(k)})}^{T}{v}^{(j)},\end{array}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par18">where <italic>m</italic> denotes the total number of views. <inline-formula id="IEq6"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{i}^{(j)}$$\end{document}</tex-math><mml:math id="M14"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq6.gif"/></alternatives></inline-formula> is the <italic>i</italic>-th input sample (<italic>i</italic> = 1, 2, …, <italic>n</italic>) under the <italic>j</italic>-th view, and <italic>y</italic><sub><italic>i</italic></sub> is the corresponding label of <inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{i}^{(j)}$$\end{document}</tex-math><mml:math id="M16"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq7.gif"/></alternatives></inline-formula> for every <italic>j</italic>. <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{(j)}$$\end{document}</tex-math><mml:math id="M18"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq8.gif"/></alternatives></inline-formula> denotes the weight of <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{i}^{(j)}$$\end{document}</tex-math><mml:math id="M20"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq9.gif"/></alternatives></inline-formula>. <italic>λ</italic><sup>(<italic>j</italic>)</sup> is a tuning parameter in the <italic>j</italic>-th view, it controls the complexity of the model. <italic>γ</italic><sup>(<italic>j</italic>)</sup> denotes the age parameter, which controls the learning pace in each iteration in the <italic>j</italic>-th view. <italic>δ</italic> is the parameter controls influence from other views when one view is going to select more training samples.</p>
        <p id="Par19">MVSPL actually corresponds to the sum of SPL model under multiple views plus a regularization term <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sum }_{\begin{array}{c}1\le k,j\le m\\ k\ne j\end{array}}{({v}^{(k)})}^{T}{v}^{(j)}$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq10.gif"/></alternatives></inline-formula>. This inner product encodes the relationship between multiple views. This new regularizer demonstrates the basic assumption that multi-view data usually contains complementary information and have more comprehensive information than those of single-view data. Therefore, this new regularizer enforces the weight penalizing the loss of one view similar to that of other views.</p>
      </sec>
    </sec>
    <sec id="Sec7">
      <title>The alternative optimization strategy</title>
      <p id="Par20">The alternative optimization strategy (AOS) can be used to solve the MVSPL model. The optimization process is as follows:</p>
      <sec id="Sec8">
        <title>Initialization</title>
        <p id="Par21"><italic>v</italic><sup>(1)</sup>, <italic>v</italic><sup>(2)</sup>, …, <italic>v</italic><sup>(<italic>m</italic>)</sup> are zero vectors in <italic>R</italic><sup><italic>m</italic></sup>. <italic>γ</italic><sup>(1)</sup>, <italic>γ</italic><sup>(2)</sup>, …, <italic>γ</italic><sup>(<italic>m</italic>)</sup> are initialized with small values to allow a few samples into training for the first iteration. <italic>δ</italic> is set as a specific value in the whole learning process. Multiple classifiers are simultaneously trained on all samples in different views to obtain an initial loss of all samples in each view.</p>
      </sec>
      <sec id="Sec9">
        <title>Update <italic>v</italic><sub><italic>i</italic></sub><sup>(<italic>k</italic>)</sup>(<italic>k</italic> = 1, 2,…, <italic>m</italic>; <italic>k</italic> ≠ <italic>j</italic>)</title>
        <p id="Par22">The purpose of this step is to prepare confident samples with non-zeros <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{(k)}$$\end{document}</tex-math><mml:math id="M24"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq11.gif"/></alternatives></inline-formula> values for training on the <italic>j</italic>-th view. By calculating the derivative of Eq. (<xref rid="Equ1" ref-type="">1</xref>) with respect to <inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{(k)}$$\end{document}</tex-math><mml:math id="M26"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq12.gif"/></alternatives></inline-formula>, then we can obtain:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{l}\frac{\partial E}{\partial {v}_{i}^{(k)}}={L}_{i}({y}_{i},{f}^{(k)}({x}_{i}^{(k)},{\beta }^{(k)}))-{\gamma }^{(k)}-\delta \sum _{\begin{array}{c}1\le j\le m,j\ne k\end{array}}{v}_{i}^{(j)}.\end{array}$$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par23">According to Eq. (<xref rid="Equ2" ref-type="">2</xref>), we can obtain the optimal weight for the <italic>i</italic>-th sample in the <italic>k</italic>-th view:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{(k)}=(\begin{array}{ll}1, &amp; {L}_{i}({y}_{i},{f}^{(k)}({x}_{i}^{(k)},{\beta }^{(k)})) &lt; {\gamma }^{(k)}+\delta \sum _{\begin{array}{c}1\le j\le m,j\ne k\end{array}}\,{v}_{i}^{(j)},\\ 0, &amp; otherwise.\end{array}$$\end{document}</tex-math><mml:math id="M30" display="block"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:munder><mml:mspace width=".25em"/><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      </sec>
      <sec id="Sec10">
        <title>Update <italic>v</italic><sub><italic>i</italic></sub><sup>(<italic>j</italic>)</sup></title>
        <p id="Par24">This step aims to define which samples will be selected into the training of the <italic>j</italic>-th view. The optimization process for the <italic>v</italic><sub><italic>i</italic></sub><sup>(<italic>j</italic>)</sup> is the same as the previous step, expressed as:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{(j)}=(\begin{array}{ll}1, &amp; {L}_{i}({y}_{i},{f}^{(j)}({x}_{i}^{(j)},{\beta }^{(j)})) &lt; {\gamma }^{(j)}+\delta \sum _{\begin{array}{c}1\le k\le m,k\ne j\end{array}}{v}_{i}^{(k)},\\ 0, &amp; otherwise.\end{array}$$\end{document}</tex-math><mml:math id="M32" display="block"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par25">The difference is that the samples selected in this step will be directly used for training in the <italic>j</italic>-th view. Furthermore, we can easily observe that samples selected by other views possess higher probabilities than others to be selected into training.</p>
      </sec>
      <sec id="Sec11">
        <title>Update <italic>β</italic><sup>(<italic>j</italic>)</sup></title>
        <p id="Par26">The purpose of this step is to obtain the optimal solution for the <italic>j</italic>-th view. Here, we choose the logistic regression classifier to train the model. Equation (<xref rid="Equ1" ref-type="">1</xref>) degenerates into penalized logistic regression optimization problem:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{c}{\rm{\min }}\\ {\beta }^{(j)}\end{array}\mathop{\sum }\limits_{i=1}^{n}{v}_{i}^{(j)}{L}_{i}({y}_{i},{f}^{(j)}({x}_{i}^{(j)},{\beta }^{(j)}))+{\lambda }^{(j)}{\Vert {\beta }^{(j)}\Vert }_{1}.$$\end{document}</tex-math><mml:math id="M34" display="block"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par27">This problem can be readily solved by R package glmnet<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>.</p>
        <p id="Par28">Age parameter <italic>γ</italic><sup>(<italic>j</italic>)</sup>(<italic>j</italic> = 1, 2, …, <italic>m</italic>) is increased to allow more samples with larger loss values into training in the next iteration. When <italic>γ</italic><sup>(<italic>j</italic>)</sup> is small, only select easy samples under <italic>j</italic>-th view with small losses. With the growth of the <italic>γ</italic><sup>(<italic>j</italic>)</sup>, more samples under <italic>j</italic>-th view with larger losses will be gradually selected to train a more “mature” model. Then we repeat the above optimization process with respect to each variable under the different views until the maximum iteration times is reached.</p>
        <p id="Par29">The pipeline of the proposed MVSPL is shown in Supplementary Fig. <xref rid="MOESM1" ref-type="media">S1</xref>. And the whole process of this alternative optimization strategy for solving MVSPL is summarized in Algorithm 1.<fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>The alternative optimization strategy for solving MVSPL model.</p></caption><graphic position="anchor" xlink:href="41598_2019_49967_Figa_HTML" id="d29e2525"/></fig></p>
        <p id="Par30">According to Algorithm 1, the MVSPL model can obtain the optimal solution for each view. Algorithm 1 jointly learns the modal parameter <italic>β</italic><sup>(<italic>j</italic>)</sup> and the latent weight variables <italic>v</italic><sup>(<italic>j</italic>)</sup>, where <italic>j</italic> = 1, …, <italic>m</italic>. Steps 7–11 compute the latent weight variables of all samples <italic>n</italic> in multiple views <italic>m</italic> with the time complexity of O(<italic>n</italic> × <italic>m</italic><sup>2</sup>). With the latent weight variables fixed, Step 12 computes the optimal solution based on the generalized linear model with lasso penalty by using Coordinate Descent algorithm<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> with the time complexity of O(<italic>n</italic><sup>2</sup> × <italic>p</italic>), where <italic>p</italic> represents the number of features and <italic>n</italic> ≪ <italic>p</italic>. This step computes the optimal solution in multiple views, so the time complexity is O(<italic>n</italic><sup>2</sup> × <italic>p</italic> × <italic>m</italic>). Due to <italic>m</italic> ≪ <italic>n</italic>, therefore, the time complexity of Algorithm 1 is O(<italic>n</italic><sup>2</sup> × <italic>p</italic> × <italic>m</italic>).</p>
        <p id="Par31">In the test phase, when the test dataset <italic>D</italic><sup>′</sup> = {<italic>X</italic><sub>1</sub>, <italic>X</italic><sub>2</sub>, …, <italic>X</italic><sub><italic>u</italic></sub>} with multiple views (1, 2, …, <italic>m</italic>) are coming, where <italic>u</italic> is the number of test samples. We first fix <italic>β</italic><sup>(1)</sup>, <italic>β</italic><sup>(2)</sup>, …, <italic>β</italic><sup>(<italic>m</italic>)</sup>, and then predict the optimal <italic>y</italic><sub><italic>k</italic></sub> by solving the following minimization problem:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{l}{y}_{k}=\mathop{argmin}\limits_{{y}_{k}}\mathop{\sum }\limits_{j=1}^{m}{L}_{k}({y}_{k},{f}^{(j)}({x}_{k}^{(j)},{\beta }^{(j)}))\end{array}$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      </sec>
    </sec>
    <sec id="Sec12">
      <title>Related work</title>
      <sec id="Sec13">
        <title>Self-paced learning (SPL)</title>
        <p id="Par32">The self-paced learning model combines a weighted loss term for all samples and a general self-paced regularizer imposed on the samples weight. Suppose given a dataset <italic>D</italic> = {(<italic>X</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>), (<italic>X</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>), …, (<italic>X</italic><sub><italic>n</italic></sub>, <italic>y</italic><sub><italic>n</italic></sub>)}, where <italic>X</italic><sub><italic>i</italic></sub> = (<italic>x</italic><sub><italic>i</italic>1</sub>, <italic>x</italic><sub><italic>i</italic>2</sub>,…, <italic>x</italic><sub><italic>ip</italic></sub>) is the <italic>i</italic>-th input sample with <italic>p</italic> features and <italic>y</italic><sub><italic>i</italic></sub> is class of the <italic>i</italic>-th sample (e.g. <italic>y</italic><sub><italic>i</italic></sub> ∈ {0, 1}). Let <italic>L</italic>(<italic>y</italic><sub><italic>i</italic></sub>,<italic>f</italic>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>β</italic>)) denotes the loss function, which calculates the loss between the real label <italic>y</italic><sub><italic>i</italic></sub> and the estimated value <italic>f</italic>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>β</italic>). The <italic>β</italic> represents the model parameter inside the decision function <italic>f</italic>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>β</italic>). The goal of the SPL is to jointly learn the model parameter <italic>β</italic> and the latent weight variable <italic>v</italic> = [<italic>v</italic><sub>1</sub>, <italic>v</italic><sub>2</sub>, …, <italic>v</italic><sub><italic>n</italic></sub>] by minimizing:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathop{{\rm{\min }}}\limits_{\beta ,v\in {[0,1]}^{n}}E(\beta ,v;\lambda ,\gamma )=\mathop{\sum }\limits_{i=1}^{n}{v}_{i}L({y}_{i},f({x}_{i},\beta ))-\gamma \mathop{\sum }\limits_{i=1}^{n}{v}_{i}+\lambda {\Vert \beta \Vert }_{1}$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:munder><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>;</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par33">where <italic>γ</italic> is the age parameter for controlling the learning pace and <italic>λ</italic> is a tuning parameter. The alternative optimization strategy algorithm can effectively solve the SPL problem. When <italic>β</italic> is fixed, the optimum weight variable <inline-formula id="IEq13"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}^{\ast }=[{v}_{1}^{\ast },{v}_{2}^{\ast \ast },\mathrm{...},{v}_{n}^{\ast }]$$\end{document}</tex-math><mml:math id="M40"><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>⁎</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq13.gif"/></alternatives></inline-formula> can be calculated by:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{\ast }=\{\begin{array}{ll}1, &amp; L({y}_{i},f({x}_{i},\beta )) &lt; \gamma \\ 0, &amp; {\rm{otherwise}}\end{array}$$\end{document}</tex-math><mml:math id="M42" display="block"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="normal">otherwise</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par34">By jointly updating model parameter <italic>β</italic> and the latent weight variable <italic>v</italic>, we can conclude that: (1) When updating <italic>v</italic> with a fixed <italic>β</italic>, if the loss value of a sample is smaller than the age parameter <italic>γ</italic>, then the sample is treated as an easy sample with <inline-formula id="IEq14"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{\ast }=1$$\end{document}</tex-math><mml:math id="M44"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq14.gif"/></alternatives></inline-formula>, otherwise, <inline-formula id="IEq15"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{\ast }=0$$\end{document}</tex-math><mml:math id="M46"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq15.gif"/></alternatives></inline-formula>. (2) When updating <italic>β</italic> with a fixed <italic>v</italic>, using the selected samples (<inline-formula id="IEq16"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}^{\ast }=1$$\end{document}</tex-math><mml:math id="M48"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>⁎</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq16.gif"/></alternatives></inline-formula>) to train the classifier. (3) Before running the next iteration, increase the age parameter <italic>γ</italic> to adjust the learning pace. When <italic>γ</italic> is small, only select easy samples with small loss values. With <italic>γ</italic> increases, more samples with larger losses will be gradually selected to train a more “mature” model.</p>
        <p id="Par35">By jointly learning the model parameter <italic>β</italic> and the latent weight variable <italic>v</italic> based on the iterative algorithm with gradually increasing the age parameter, more samples can be automatically selected into training from easy to complex in a self-paced way.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec14" sec-type="results">
    <title>Results</title>
    <p id="Par36">We demonstrate the performance of the proposed MVSPL in simulation and real microarray experiments. Four methods are compared with the MVSPL method: Sparse logistic regression with the Lasso penalty (L<sub>1</sub>)<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>, Sparse logistic regression with the elastic net penalty (L<sub><italic>EN</italic></sub>)<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>, Ensemble-based elastic net (Ensemble_EN)<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> and SPL<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. When MVIAm generates single-view data, it degenerates into traditional “early stage” data integration, and data analysis can be performed by L<sub>1</sub>, L<sub><italic>EN</italic></sub> and SPL. Ensemble_EN constructs a prediction model on each view of data before combing the model predictions and obtains the final prediction result based on Eq. (<xref rid="Equ6" ref-type="">6</xref>).</p>
    <sec id="Sec15">
      <title>Analysis of simulated data</title>
      <p id="Par37">We generate three independent simulated datasets for integration and each dataset with the character of small sample size and high dimensionality. Using the normal distribution to generate <italic>X</italic> = (<italic>X</italic><sub>1</sub>, <italic>X</italic><sub>2</sub>, …, <italic>X</italic><sub><italic>n</italic></sub>) with <italic>n</italic> samples and each samples with <italic>p</italic> features, for the <italic>i</italic>-th sample, <italic>X</italic><sub><italic>i</italic></sub> = (<italic>x</italic><sub><italic>i</italic>1</sub>, <italic>x</italic><sub><italic>i</italic>2</sub>, …, <italic>x</italic><sub><italic>ip</italic></sub>). After that, the correlation parameter <italic>ρ</italic> can be added to the simulated data<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>.<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{l}{x}_{ij}={z}_{ij}\sqrt{1-\rho }+{z}_{i1}\sqrt{\rho },i \sim (1,\ldots ,n),j \sim (2,\ldots ,p).\end{array}$$\end{document}</tex-math><mml:math id="M50" display="block"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi></mml:mrow></mml:msqrt><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msqrt><mml:mi>ρ</mml:mi></mml:msqrt><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>~</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>~</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <italic>z</italic><sub><italic>ij</italic></sub>~<sub><italic>i</italic>.<italic>i</italic>.<italic>d</italic>.</sub><italic>N</italic>(0, 1). The simulated dataset is generated from the logistic regression model, which can be given as:<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{l}log(\frac{{y}_{i}}{1-{y}_{i}})={\beta }_{0}+\mathop{\sum }\limits_{j=1}^{p}{x}_{ij}{\beta }_{j}+\sigma \cdot \varepsilon ,\end{array}$$\end{document}</tex-math><mml:math id="M52" display="block"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>σ</mml:mi><mml:mo>⋅</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>where <italic>ε</italic> = (<italic>ε</italic><sub>1</sub>, <italic>ε</italic><sub>2</sub>, …, <italic>ε</italic><sub><italic>n</italic></sub>)<sup><italic>T</italic></sup> is the independent random errors from <italic>N</italic>(0, 1), <italic>σ</italic> is the noise control parameter.</p>
      <p id="Par38">We generated simulated data by the above procedure. Three independent simulated datasets were generated with the same number of variables (<italic>p</italic> = 2000). The coefficient <italic>β</italic> is set as follows:<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{l}\beta =(\mathop{\underbrace{1.5,-\,1.2,1.8,-\,2,2.5,-\,1.2,1,-1.5,2,-\,1.6}}\limits_{10},\mathop{\underbrace{0,\cdots ,0}}\limits_{1990}).\end{array}$$\end{document}</tex-math><mml:math id="M54" display="block"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="true"><mml:mrow><mml:mn>1.5</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mspace width="-.25em"/><mml:mn>1.2</mml:mn><mml:mo>,</mml:mo><mml:mn>1.8</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mspace width="-.25em"/><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mspace width="-.25em"/><mml:mn>1.2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>1.5</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mspace width="-.25em"/><mml:mn>1.6</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="true">⏟</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:munder><mml:mo>,</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="true"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="true">⏟</mml:mo></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mn>1990</mml:mn></mml:mrow></mml:munder><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par39">Four scenarios were designed for the simulated experiment:</p>
      <p id="Par40"><bold>Scenario 1</bold>: The sample size <italic>n</italic><sub><italic>dataset</italic>1</sub> = 100, <italic>n</italic><sub><italic>dataset</italic>2</sub> = 100 and <italic>n</italic><sub><italic>dataset</italic>3</sub> = 100, the correlation coefficient <italic>ρ</italic> = 0, 0.2, 0.4, 0.6 and 0.8, the noise control parameter <italic>σ</italic> = 0.</p>
      <p id="Par41"><bold>Scenario 2</bold>: The sample size <italic>n</italic><sub><italic>dataset</italic>1</sub> = 100, <italic>n</italic><sub><italic>dataset</italic>2</sub> = 100 and <italic>n</italic><sub><italic>dataset</italic>3</sub> = 100, the noise control parameter <italic>σ</italic> = 0, 0.2, 0.4, 0.6 and 0.8, the correlation coefficient <italic>ρ</italic> = 0.</p>
      <p id="Par42"><bold>Scenario 3</bold>: The sample size <italic>n</italic><sub><italic>dataset</italic>1</sub> = 50, <italic>n</italic><sub><italic>dataset</italic>2</sub> = 100 and <italic>n</italic><sub><italic>dataset</italic>3</sub> = 150, the noise control parameter <italic>σ</italic> = 0, 0.4 and 0.8, the correlation coefficient <italic>ρ</italic> = 0.</p>
      <p id="Par43"><bold>Scenario 4</bold>: The sample size <italic>n</italic><sub><italic>dataset</italic>1</sub> = 100, <italic>n</italic><sub><italic>dataset</italic>2</sub> = 100 and <italic>n</italic><sub><italic>dataset</italic>3</sub> = 100, the noise control parameter <italic>σ</italic><sub><italic>dataset</italic>1</sub> = 0.1, <italic>σ</italic><sub><italic>dataset</italic>2</sub> = 0.2 and <italic>σ</italic><sub><italic>dataset</italic>3</sub> = 0.3, the correlation coefficient <italic>ρ</italic> = 0.2.</p>
      <p id="Par44">Three independent simulated datasets are processed based on MVIAm and aggregated into a large multi-view dataset. We use four functions ComBat_p, ComBat_n, ber and ber_bg to eliminate batch effects and generate view1, view2, view3 and view4 of the aggregated multi-view data, respectively. L<sub>1</sub>, L<sub><italic>EN</italic></sub> and SPL achieve the best performance in the view of data by using ComBat_p to eliminate the batch effects. Therefore, these three competing methods use the view1 of the aggregated dataset for data analysis in four scenarios. The proposed MVSPL and Ensemble_EN have the flexibility to analyze data in multiple views. In Scenarios 1, 2 and 3, MVSPL and Ensemble_EN perform data analysis through two views of data: view1 and view2. In Scenario 4, we further explore our proposed method and its flexible scalability. Perform MVSPL through the interaction of two views, three views and four views of data, respectively. In the simulated experiment, we first combine independent simulated datasets into a large aggregated dataset. Then, the aggregated dataset is divided into two groups with random sampling, 70% samples for training and remaining samples for testing. The estimation of the optimal regularization parameter <italic>λ</italic> of the training dataset is obtained by 10-fold cross-validation. We repeat this procedure 30 times and report the average measurement.</p>
      <p id="Par45">To evaluate the prediction performance of classifiers, the accuracy, sensitivity, specificity and AUC are used in the simulation and real experiments. The definitions of these evaluation indicators can refer to<sup><xref ref-type="bibr" rid="CR47">47</xref>,<xref ref-type="bibr" rid="CR48">48</xref></sup>. In addition, the evaluation indicators for variable selection are defined as follows<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>:<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{rcl}TruePositive(TP) &amp; = &amp; {|\beta .\ast \hat{\beta }|}_{0},TrueNegative(TN)={|\bar{\beta }.\ast \overline{\hat{\beta }}|}_{0}\\ FalsePositive(FP) &amp; = &amp; {|\bar{\beta }.\ast \hat{\beta }|}_{0},FalseNegative(FN)=\,{|\beta .\ast \overline{\hat{\beta }}|}_{0}\\ \beta -sensitivity &amp; = &amp; \frac{TP}{TP+FN},\beta -specificity=\,\frac{TN}{TN+FP}\end{array}$$\end{document}</tex-math><mml:math id="M56" display="block"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="right"><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>.</mml:mo><mml:mspace width=".25em"/><mml:mo>∗</mml:mo><mml:mspace width=".25em"/><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>.</mml:mo><mml:mspace width=".25em"/><mml:mo>∗</mml:mo><mml:mspace width=".25em"/><mml:mover accent="true"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>.</mml:mo><mml:mspace width=".25em"/><mml:mo>∗</mml:mo><mml:mspace width=".25em"/><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mspace width=".25em"/><mml:msub><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>.</mml:mo><mml:mspace width=".25em"/><mml:mo>∗</mml:mo><mml:mspace width=".25em"/><mml:mover accent="true"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="right"><mml:mrow><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mspace width=".25em"/><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="41598_2019_49967_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par46">where the |·|<sub>0</sub> represents the number of non-zero elements in a vector. The logical not operators of <italic>β</italic> and <inline-formula id="IEq17"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\beta }$$\end{document}</tex-math><mml:math id="M58"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq17.gif"/></alternatives></inline-formula> are <inline-formula id="IEq18"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{\beta }$$\end{document}</tex-math><mml:math id="M60"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq18.gif"/></alternatives></inline-formula> and <inline-formula id="IEq19"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overline{\hat{\beta }}$$\end{document}</tex-math><mml:math id="M62"><mml:mover accent="true"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41598_2019_49967_Article_IEq19.gif"/></alternatives></inline-formula>, respectively. And.* is the element-wise product.</p>
      <p id="Par47">In Scenario 1, we explored the effect of different correlation coefficient parameters on the performance of the five methods. As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, for the training dataset, the difference in prediction performance of all the methods is quite small. For the test dataset, it can be clearly seen that as the correlation parameter <italic>ρ</italic> increases, the prediction accuracy of all the five methods are decreased, expect for MVSPL in <italic>ρ</italic> = 0.8. The generalization ability of MVSPL and SPL are obviously superior to L<sub>1</sub>, L<sub><italic>EN</italic></sub> and Ensemble_EN. The average test accuracy, sensitivity, and AUC obtained by MVSPL are higher than the other competing methods with varying correlation coefficient parameters <italic>ρ</italic>. The results obtained by SPL are slightly inferior to MVSPL but better than the other three methods in most situations. Moreover, Ensemble_EN outperforms L<sub>1</sub> and L<sub><italic>EN</italic></sub> with varying correlation parameters.<fig id="Fig2"><label>Figure 2</label><caption><p>Prediction performance of the different methods with different correlation coefficient parameters. The error bars represent the standard deviation (SD).</p></caption><graphic xlink:href="41598_2019_49967_Fig2_HTML" id="d29e4488"/></fig></p>
      <p id="Par48">In Scenario 2, we explored the effect of different noise control parameters on the performance of the five methods. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, consistent with the results of Scenario 1, all methods with the similar prediction performance in the training dataset. For the test dataset, when the noise control parameter increases, the prediction accuracy of all the competing methods are decreased. MVSPL and SPL demonstrate the excellent generalization performance. The average test accuracy and AUC obtained by MVSPL are superior to other competing methods with varying noise control parameters <italic>σ</italic>. For instance, with noise parameter <italic>σ</italic> = 0.4, the average test accuracy of MVSPL is 87.84% superior to 85.04%, 84.96%, 87.11% and 85.44% obtained by L<sub>1</sub>, L<sub><italic>EN</italic></sub>, SPL and Ensemble_EN, respectively. In addition, the average test prediction performance of Ensemble_EN performs better than the single-view based methods L<sub>1</sub> and L<sub><italic>EN</italic></sub> in all cases of Scenario 2.<fig id="Fig3"><label>Figure 3</label><caption><p>Prediction performance of the different integrative analysis methods with different noise control parameters. The error bars represent the standard deviation (SD).</p></caption><graphic xlink:href="41598_2019_49967_Fig3_HTML" id="d29e4523"/></fig></p>
      <p id="Par49">Table <xref rid="Tab1" ref-type="table">1</xref> shows the variable selection performance of all the five methods in Scenarios 1 and 2. <italic>β</italic>-sensitivity and <italic>β</italic>-specificity are used to evaluate the variable selection performance. It can be obviously seen that our method achieves the best <italic>β</italic>-sensitivity performance across all cases of simulated experiments. For instance, with noise parameters <italic>σ</italic> = 0.6, the average <italic>β</italic>-sensitivity performance of MVSPL is 91.73% higher than 91.12%, 91.94%, 90.23% and 91.67% obtained by L<sub>1</sub>, L<sub><italic>EN</italic></sub>, SPL and Ensemble_EN, respectively. Moreover, by analyzing more views of data, it can improve the <italic>β</italic>-sensitive performance and help identify the significant variables. The average <italic>β</italic>-sensitivity of MVSPL and Ensemble_EN are superior to other single-view analysis methods in most cases. For example, the average <italic>β</italic>-sensitivity of MVSPL and Ensemble_EN are 91.09% and 90.34% better than 88.18%, 88.91% and 88.48% obtained by L<sub>1</sub>, L<sub><italic>EN</italic></sub> and SPL with the noise parameter <italic>σ</italic> = 0.8. The <italic>β</italic>-specificity of all the methods is relatively close in different parameters, between 97.0% to 99%.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Variable selection performance (%) of the different integrative analysis methods with different parameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Method</th><th colspan="5">Correlation coefficient parameters</th><th colspan="5">Noise control parameters</th></tr><tr><th><italic>ρ</italic> = 0</th><th><italic>ρ</italic> = 0.2</th><th><italic>ρ</italic> = 0.4</th><th><italic>ρ</italic> = 0.6</th><th><italic>ρ</italic> = 0.8</th><th><italic>σ</italic> = 0</th><th><italic>σ</italic> = 0.2</th><th><italic>σ</italic> = 0.4</th><th><italic>σ</italic> = 0.6</th><th><italic>σ</italic> = 0.8</th></tr></thead><tbody><tr><td/><td colspan="10"><bold><italic>β</italic></bold><bold>-sensitivity</bold></td></tr><tr><td>L<sub>1</sub></td><td>91.21</td><td>94.85</td><td>88.79</td><td>82.24</td><td>66.67</td><td>90.48</td><td>90.82</td><td>91.12</td><td>90.52</td><td>88.18</td></tr><tr><td>L<sub><italic>EN</italic></sub></td><td>90.91</td><td>93.84</td><td>88.42</td><td>82.33</td><td>67.58</td><td>90.27</td><td>91.24</td><td>91.94</td><td>89.70</td><td>88.91</td></tr><tr><td>SPL</td><td>90.91</td><td>94.67</td><td>88.48</td><td>83.19</td><td>67.64</td><td>91.52</td><td>92.94</td><td>90.23</td><td>90.61</td><td>88.48</td></tr><tr><td>Ensemble_EN</td><td>89.67</td><td>93.67</td><td>92.33</td><td>87.67</td><td>68.33</td><td>89.67</td><td>92.33</td><td>91.67</td><td>90.67</td><td>90.34</td></tr><tr><td>MVSPL</td><td><bold>92.73</bold></td><td><bold>95.45</bold></td><td><bold>92.73</bold></td><td><bold>88.18</bold></td><td><bold>69.54</bold></td><td><bold>92.73</bold></td><td><bold>93.73</bold></td><td><bold>92.18</bold></td><td><bold>91.73</bold></td><td><bold>91.09</bold></td></tr><tr><td/><td colspan="10"><bold><italic>β</italic></bold><bold>-specificity</bold></td></tr><tr><td>L<sub>1</sub></td><td>98.71</td><td>98.71</td><td>98.79</td><td>98.46</td><td>98.87</td><td>98.81</td><td>98.79</td><td>98.68</td><td>98.56</td><td>98.63</td></tr><tr><td>L<sub><italic>EN</italic></sub></td><td>98.82</td><td>98.79</td><td>98.51</td><td>98.92</td><td>98.24</td><td>98.98</td><td>98.11</td><td>98.35</td><td>98.75</td><td>98.98</td></tr><tr><td>SPL</td><td>98.71</td><td>98.46</td><td>98.32</td><td>98.72</td><td>98.00</td><td>98.66</td><td>97.96</td><td>98.42</td><td>98.55</td><td>98.62</td></tr><tr><td>Ensemble_EN</td><td>98.77</td><td>98.20</td><td>98.01</td><td>98.49</td><td>97.90</td><td>98.54</td><td>97.86</td><td>97.44</td><td>98.55</td><td>96.94</td></tr><tr><td>MVSPL</td><td>98.42</td><td>98.44</td><td>97.86</td><td>98.16</td><td>98.37</td><td>98.50</td><td>97.49</td><td>98.02</td><td>97.75</td><td>97.01</td></tr></tbody></table><table-wrap-foot><p>The mean variable selection performance over 30 repetitions of the simulated experiments in Scenarios 1 and 2 are reported, and the best <italic>β</italic> -sensitivity are highlighted in bold.</p></table-wrap-foot></table-wrap></p>
      <p id="Par50">In Scenario 3, we explored the effect of different sample sizes on the performance of the five methods. As shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>, we can clearly observe that the test accuracy of MVSPL has achieved the optimal results. MVSPL and SPL exhibit better generalization capabilities compared to other methods, especially in high noise case <italic>σ</italic> = 0.8. Furthermore, the test accuracy of multi-view based method Ensemble_EN is superior to the single-view based methods <italic>L</italic><sub>1</sub> and <italic>L</italic><sub><italic>EN</italic></sub> in Scenario 3.<fig id="Fig4"><label>Figure 4</label><caption><p>Boxplot diagram of training and test accuracy for the different methods with 30 repetitions in Scenario 3.</p></caption><graphic xlink:href="41598_2019_49967_Fig4_HTML" id="d29e5095"/></fig></p>
      <p id="Par51">To further evaluate the performance of the proposed MVSPL method, we designed Scenario 4 in the simulated experiment. The prediction performance of MVSPL in the different number of views is shown in Supplementary Fig. <xref rid="MOESM1" ref-type="media">S2</xref>. When the number of views increases, the accuracy, sensitivity, specificity and AUC for the test dataset obtained by MVSPL are improved. And we also compare the prediction performance of MVSPL in three views and each of its views. Supplementary Fig. <xref rid="MOESM1" ref-type="media">S3</xref> clearly shows that the prediction performance in each single views of MVSPL is worse than that of MVSPL in all views.</p>
      <p id="Par52">To sum up, according to the results of simulated experiments, we can conclude that:<list list-type="bullet"><list-item><p id="Par53">MVSPL achieves the best generalization ability than the competing methods. The performance of MVSPL outperforms other competing methods with varying correlation parameters and noise parameters.</p></list-item><list-item><p id="Par54">By analyzing more views of data, it possible to improve the prediction and variable selection performance. The average performance of MVSPL and Ensemble_EN are superior to the corresponding single-view based methods in most cases.</p></list-item><list-item><p id="Par55">When the number of views increases, the prediction performance of MVSPL are improved. This implies that batch effects have an effect for data analysis and more views will contain more comprehensive information.</p></list-item></list></p>
    </sec>
    <sec id="Sec16">
      <title>Real microarray datasets</title>
      <p id="Par56">We curated data from eight publicly available microarray studies, four breast cancer datasets (same platform) and four lung cancer datasets (disparate platform) (Tables <xref rid="Tab2" ref-type="table">2</xref> and <xref rid="Tab3" ref-type="table">3</xref>). All of these four breast datasets were produced by the same microarray platform HG-U133A. Classification of breast cancer samples aims to distinguish between the sample’s estrogen receptor (ER) status (+ve or −ve). Four publicly available lung cancer microarray datasets come from disparate platforms. All these publicly available cancer gene expression datasets can be download from GEO (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/geo/">https://www.ncbi.nlm.nih.gov/geo/</ext-link>).<table-wrap id="Tab2"><label>Table 2</label><caption><p>Four publicly available breast cancer gene expression datasets used in the real data experiments.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>No. of Probes</th><th>Classes (Class1/Class2)</th><th>No. of Classes (Class1/Class2)</th><th>Affymetrix Platform</th></tr></thead><tbody><tr><td>GSE1561</td><td>22215</td><td>−ve/+ve</td><td>49 (22/27)</td><td>HG-U133A</td></tr><tr><td>GSE6532</td><td>22283</td><td>−ve/+ve</td><td>125 (40/85)</td><td>HG-U133A</td></tr><tr><td>GSE20437</td><td>22283</td><td>−ve/+ve</td><td>18 (9/9)</td><td>HG-U133A</td></tr><tr><td>GSE22093</td><td>22283</td><td>−ve/+ve</td><td>82 (41/41)</td><td>HG-U133A</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Four publicly available lung cancer gene expression datasets used in the real data experiments.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>No. of Probes</th><th>Classes (Class1/Class2)</th><th>No. of Classes (Class1/Class2)</th><th>Affymetrix Platform</th></tr></thead><tbody><tr><td>GSE10072</td><td>22284</td><td>Normal/Tumor</td><td>107 (49/58)</td><td>U133A</td></tr><tr><td>GSE19188</td><td>54675</td><td>Normal/Tumor</td><td>179 (88/91)</td><td>U133 Plus 2.0</td></tr><tr><td>GSE19804</td><td>54676</td><td>Normal/Tumor</td><td>120 (60/60)</td><td>U133 Plus 2.0</td></tr><tr><td>GSE43346</td><td>22283</td><td>Normal/Tumor</td><td>65 (42/23)</td><td>U133A</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec17">
      <title>Analysis of real data</title>
      <p id="Par57">For the real microarray data, two types of experimental designs are used in this work. One type evaluates the performance using a random partition. The other type validates the prediction performance on the independent datasets. All publicly available cancer datasets are processed and aggregated in the manner described above (Supplementary Tables <xref rid="MOESM1" ref-type="media">S1</xref> and <xref rid="MOESM1" ref-type="media">S2</xref>). All of publicly available gene expression datasets used in this paper have the class information. Special note, L<sub>1</sub>, L<sub><italic>EN</italic></sub> and SPL achieve the best performance in the view of data by using ComBat_p to eliminate the batch effects. Therefore, these three methods use this view of the aggregated dataset for data analysis in real data analysis. MVSPL and Ensemble_EN analyze two views of data in the real data experiments, which use ComBat_p and ComBat_n to eliminate the batch effects.</p>
      <sec id="Sec18">
        <title>Evaluating the performance using a random partition</title>
        <p id="Par58">For the part of evaluating the performance using a random partition, we randomly divide the datasets such that 70% of the datasets become the training samples and the remaining samples become the test samples. The estimation of the optimal regularization parameter <italic>λ</italic> of the training dataset is obtained by 10-fold cross-validation. We repeat this procedure 30 times and report the average measurement and standard error.</p>
        <p id="Par59">Figures <xref rid="Fig5" ref-type="fig">5</xref> and <xref rid="Fig6" ref-type="fig">6</xref> plot the box plot analysis of training and test prediction performance calculated on breast and lung cancer datasets under 30 repetitions, respectively. As shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>, for the training dataset, all the five methods achieve desirable performance. For instance, the median average training accuracy of all methods have obtained more than 94%. For the test dataset, the proposed MVSPL has the superior performance compared to other competing methods. For example, the median test accuracy of MVSPL is 84.21%, which is obviously better than 75.44%, 77.19%, 80.70% and 76.90% obtained by L<sub>1</sub>, L<sub><italic>EN</italic></sub>, SPL and Ensemble_EN, respectively. Our method achieves the best generalization ability than the competing methods. For lung cancer dataset, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>, the training and test prediction performance of all the five methods have reached more than 90%. Our proposed MVSPL method still obtains better classification accuracy, sensitivity, specificity and AUC than other methods. The average number of selected genes for all methods is summarized in Supplementary Table <xref rid="MOESM1" ref-type="media">S3</xref>.<fig id="Fig5"><label>Figure 5</label><caption><p>Boxplot diagram of training and test prediction performance for the methods with 30 repetitions in breast cancer dataset.</p></caption><graphic xlink:href="41598_2019_49967_Fig5_HTML" id="d29e5381"/></fig><fig id="Fig6"><label>Figure 6</label><caption><p>Boxplot diagram of training and test prediction performance for the methods with 30 repetitions in lung cancer dataset.</p></caption><graphic xlink:href="41598_2019_49967_Fig6_HTML" id="d29e5390"/></fig></p>
      </sec>
      <sec id="Sec19">
        <title>Validating the classifier on independent dataset</title>
        <p id="Par60">For the part of validating the classifier on independent dataset, the design of the validation process is the same as that of metAnalyzeAll<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. After pre-processing each dataset individually, all the training datasets and the independent validation dataset are merged in the manner described above. The classifier is trained on the samples from the aggregated training dataset and the optimal regularization parameter <italic>λ</italic> is obtained by 10-fold cross-validation. After that, the classifier is tested on the samples from the independent validation dataset.</p>
        <p id="Par61">Figure <xref rid="Fig7" ref-type="fig">7</xref> compares the validation prediction performance of L<sub>1</sub>, L<sub><italic>EN</italic></sub>, SPL, Ensemble_EN and MVSPL in the validation datasets of breast cancer and lung cancer studies. Validating classifiers on the validation dataset, MVSPL consistently outperforms other competing methods in cancer classification problem. As shown in the left hand of Fig. <xref rid="Fig7" ref-type="fig">7</xref>, in breast cancer study, the validation accuracy, specificity, and AUC of MVSPL is superior to other competing methods, except for sensitivity. Specially, MVSPL achieves approximate 10% validation accuracy gain compared with L<sub>1</sub> and L<sub><italic>EN</italic></sub>. Beyond that, Ensemble_EN with the suboptimal performance. In breast cancer study, multi-view analysis method performs better validation prediction performance than single-view analysis method. For lung cancer study, as shown in the right hand of Fig. <xref rid="Fig7" ref-type="fig">7</xref>, the validation prediction performance of the proposed MVSPL method has a significant improvement compared to other methods. For example, the validation sensitivity of MVSPL is 91.30%, which is superior to 43.24%, 45.95%, 78.26% and 73.91% obtained by L<sub>1</sub>, L<sub><italic>EN</italic></sub>, SPL and Ensemble_EN, respectively. The validation prediction performance of SPL is inferior to MVSPL but is obviously superior to L<sub>1</sub>, L<sub><italic>EN</italic></sub> and Ensemble_EN. Moreover, the validation results of Ensemble_EN is outperformed than L<sub>1</sub> and L<sub><italic>EN</italic></sub>. To summary, by learning from easy to complex samples and interact with multiple views, MVSPL with the best generalization ability than other competing methods. Generally speaking, MVSPL can be successfully applied to the microarray integrative analysis in cancer classification. The average number of selected genes for all methods is summarized in Supplementary Table <xref rid="MOESM1" ref-type="media">S4</xref>.<fig id="Fig7"><label>Figure 7</label><caption><p>Validation performance comparisons of different integrative analysis methods in the validation datasets of breast cancer and lung cancer studies.</p></caption><graphic xlink:href="41598_2019_49967_Fig7_HTML" id="d29e5462"/></fig></p>
        <p id="Par62">For a brief biological analysis of selected genes, we summaries of the 20 top-ranked genes selected by the five integrative analysis methods in two cancer studies, which are shown in Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref>, respectively. To make it easier to demonstrate the interplay between the top selected genes from the microarray integrative analysis, we constructed an network of interactions among the genes using the cBioPortal<sup><xref ref-type="bibr" rid="CR50">50</xref>,<xref ref-type="bibr" rid="CR51">51</xref></sup>. Figure <xref rid="Fig8" ref-type="fig">8</xref> shows the interactive network of the 20 top-ranked genes selected by MVSPL in breast cancer study. The interactive network shows that SNAPC5, PCBP2 and GNA13 are connected to other frequently altered genes from the TCGA breast invasive carcinoma dataset, which are also selected by other competing methods. Moreover, TNFSF11 is targeted by two FDA approved cancer drugs, it is selected only by MVSPL and SPL. For the genes that are only selected by MVSPL, UBE21 is connected to other frequently altered genes and RNASE2 is targeted by three cancer drugs. For lung cancer study, Fig. <xref rid="Fig9" ref-type="fig">9</xref> shows the interactive network of the 20 top-ranked genes obtained by the proposed MVSPL in lung cancer study. Examination of the resulting network, Fig. <xref rid="Fig9" ref-type="fig">9</xref> shows that TRPC3, DCC, MYH1, GH2 and KLHL21 are linked to other frequently altered genes from the TCGA lung adenocarcinoma dataset. MYH1 and GGT5 are targeted by certain cancer drugs. Moreover, MLNR, IGHE and RPL10L are only obtained by MVSPL, these genes are targets for cancer drugs.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Top 20 genes selected from different integrative analysis methods in breast cancer dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">L<sub>1</sub></th><th rowspan="2">L<sub><italic>EN</italic></sub></th><th rowspan="2">SPL</th><th colspan="2">Ensemble_EN</th><th colspan="2">MVSPL</th></tr><tr><th>View1</th><th>View2</th><th>View1</th><th>View2</th></tr></thead><tbody><tr><td><bold>SNAPC5</bold></td><td><bold>SNAPC5</bold></td><td>RPL7P25</td><td>GNL3LP1</td><td><bold>SNAPC5</bold></td><td>CASP5*</td><td>CASP5*</td></tr><tr><td>KPNA5</td><td>RHCG</td><td><bold>CDK14</bold></td><td>SNAPC5</td><td>GNL3LP1</td><td><bold>ALOX15</bold></td><td>GFI1B*</td></tr><tr><td>RHCG</td><td><bold>ALOX15</bold></td><td>CCNC</td><td>XYLB</td><td>XYLB</td><td><bold>SNAPC5</bold></td><td><bold>ALOX15</bold></td></tr><tr><td><bold>ALOX15</bold></td><td><bold>CDK14</bold></td><td>RHCG</td><td>UTRN</td><td>APOBEC1</td><td>SLC28A2*</td><td><bold>CDK14</bold></td></tr><tr><td>ANXA2P3</td><td>KPNA5</td><td>ANXA2P3</td><td>SMG8</td><td><bold>CDK14</bold></td><td><bold>CDK14</bold></td><td>UPK3A</td></tr><tr><td><bold>CDK14</bold></td><td>SMG8</td><td>MRM2</td><td>ACO1</td><td>UTRN</td><td>GFI1B*</td><td>SLC28A2*</td></tr><tr><td>CCNC</td><td>AHCYL1</td><td>POLR2G</td><td>AHCYL1</td><td><bold>RPL7P25</bold></td><td>UPK3A</td><td>TNFSF11</td></tr><tr><td><bold>PCBP2</bold></td><td><bold>PCBP2</bold></td><td><bold>GNA13</bold></td><td><bold>CDK14</bold></td><td>APOO</td><td>TNFSF11</td><td>RNASE2*</td></tr><tr><td>AHCYL1</td><td>APOO</td><td>UPK3A</td><td>APOBEC1</td><td>RHCG</td><td>CCNC</td><td>CCNC</td></tr><tr><td>SMG8</td><td>CCNC</td><td><bold>ALOX15</bold></td><td><bold>ALOX15</bold></td><td>AHCYL1</td><td>UBE2I*</td><td><bold>SNAPC5</bold></td></tr><tr><td>APOO</td><td><bold>GNA13</bold></td><td>RBBP9</td><td>SLC25A31</td><td>RIMS2</td><td>MPZL2*</td><td><bold>PCBP2</bold></td></tr><tr><td>ANAPC10</td><td>ANXA2P3</td><td>HIGD1B</td><td>SERPINB8</td><td>SMG8</td><td><bold>PCBP2</bold></td><td>FGGY*</td></tr><tr><td>SRD5A2</td><td>UTRN</td><td>NUBP2</td><td>APOO</td><td>ACO1</td><td>SETX*</td><td>MAT2A*</td></tr><tr><td><bold>RPL7P25</bold></td><td>MRM2</td><td>SMG8</td><td>KPNA5</td><td><bold>PCBP2</bold></td><td>NNAT*</td><td><bold>RPL7P25</bold></td></tr><tr><td>MRM2</td><td>ANAPC10</td><td><bold>SNAPC5</bold></td><td>RIMS2</td><td>SERPINB8</td><td>IRGQ*</td><td>NNAT*</td></tr><tr><td><bold>GNA13</bold></td><td>TRIM13</td><td>UBA5</td><td><bold>GNA13</bold></td><td>AKTIP</td><td><bold>GNA13</bold></td><td>ALDH1L1*</td></tr><tr><td>COX7BP1</td><td>ACO1</td><td>TNFSF11</td><td>AFDN</td><td>FA2H</td><td>RNASE2*</td><td>SENP6</td></tr><tr><td>NUBP2</td><td><bold>RPL7P25</bold></td><td>AKTIP</td><td><bold>PCBP2</bold></td><td>LIPC</td><td>NUBP2</td><td>IRGQ*</td></tr><tr><td>TRIM13</td><td>RIMS2</td><td>WWOX</td><td>RHCG</td><td><bold>ALOX15</bold></td><td>RETREG3*</td><td>SETX*</td></tr><tr><td>UTRN</td><td>BANP</td><td><bold>PCBP2</bold></td><td>WWOX</td><td>FOXK2</td><td>MAT2A*</td><td>FOXK2</td></tr></tbody></table><table-wrap-foot><p><sup>1</sup>The genes with star (*) are the unique gene selected by MVSPL, and the common genes selected by each method are emphasized with bold.</p></table-wrap-foot></table-wrap><table-wrap id="Tab5"><label>Table 5</label><caption><p>Top 20 genes selected from different integrative analysis methods in lung cancer dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">L1</th><th rowspan="2">LEN</th><th rowspan="2">SPL</th><th colspan="2">Ensemble_EN</th><th colspan="2">MVSPL</th></tr><tr><th>View1</th><th>View2</th><th>View1</th><th>View2</th></tr></thead><tbody><tr><td><bold>HTN3</bold></td><td><bold>HTN3</bold></td><td><bold>HTN3</bold></td><td><bold>HTN3</bold></td><td><bold>MYH1</bold></td><td>OR1G1</td><td><bold>HTN3</bold></td></tr><tr><td><bold>MYH1</bold></td><td><bold>MYH1</bold></td><td><bold>MYH1</bold></td><td><bold>MYH1</bold></td><td><bold>HTN3</bold></td><td><bold>HTN3</bold></td><td>OR1G1</td></tr><tr><td><bold>DCC</bold></td><td><bold>DCC</bold></td><td><bold>DCC</bold></td><td><bold>DCC</bold></td><td><bold>DCC</bold></td><td><bold>MYH1</bold></td><td><bold>GH2</bold></td></tr><tr><td>RBM15B</td><td><bold>TRBV10-2</bold></td><td><bold>TRBV10-2</bold></td><td><bold>TRBV10-2</bold></td><td>RBM15B</td><td><bold>GH2</bold></td><td><bold>MYH1</bold></td></tr><tr><td><bold>TRBV10-2</bold></td><td><bold>TRPC3</bold></td><td><bold>GH2</bold></td><td><bold>TRPC3</bold></td><td><bold>TRBV10-2</bold></td><td>MASP1</td><td>MLNR*</td></tr><tr><td><bold>TRPC3</bold></td><td>RBM15B</td><td>NEUROG1</td><td><bold>GH2</bold></td><td>NEUROG1</td><td><bold>TRBV10-2</bold></td><td><bold>TRBV10-2</bold></td></tr><tr><td><bold>KLHL21</bold></td><td><bold>GH2</bold></td><td>PITPNA</td><td>RBM15B</td><td>OR1G1</td><td><bold>ZNF107</bold></td><td><bold>ZNF107</bold></td></tr><tr><td>TRAM2</td><td>NEUROG1</td><td><bold>TRPC3</bold></td><td>NEUROG1</td><td><bold>TRPC3</bold></td><td><bold>TRPC3</bold></td><td><bold>DCC</bold></td></tr><tr><td>NEUROG1</td><td>TRAM2</td><td>OR1G1</td><td>PITPNA</td><td><bold>KLHL21</bold></td><td>MLNR*</td><td><bold>PHEX</bold></td></tr><tr><td><bold>GGT5</bold></td><td><bold>GGT5</bold></td><td>RBM15B</td><td>TRAM2</td><td>EXD3</td><td><bold>GGT5</bold></td><td>IGHE*</td></tr><tr><td><bold>GH2</bold></td><td>PITPNA</td><td>MASP1</td><td><bold>GGT5</bold></td><td><bold>GGT5</bold></td><td><bold>KLHL21</bold></td><td>FAM120C*</td></tr><tr><td>EXD3</td><td>EXD3</td><td>TRAM2</td><td>EXD3</td><td>TRAM2</td><td>ZNF254*</td><td>KLHL21</td></tr><tr><td>TTN</td><td><bold>ZNF107</bold></td><td><bold>GGT5</bold></td><td><bold>ZNF107</bold></td><td>CARHSP1</td><td><bold>PHEX</bold></td><td><bold>GGT5</bold></td></tr><tr><td><bold>ZNF107</bold></td><td><bold>KLHL21</bold></td><td>OR12D3</td><td><bold>KLHL21</bold></td><td>PITPNA</td><td><bold>DCC</bold></td><td>FAF2*</td></tr><tr><td>CARHSP1</td><td>TTN</td><td>EXD3</td><td>OR1G1</td><td><bold>GH2</bold></td><td>TMX2</td><td>ADAM3A*</td></tr><tr><td>PITPNA</td><td>OR12D3</td><td><bold>ZNF107</bold></td><td>TTN</td><td>TMX2</td><td>CARHSP1</td><td>BRD7P3*</td></tr><tr><td>MFSD11</td><td>OR1G1</td><td><bold>PHEX</bold></td><td>OR12D3</td><td><bold>PHEX</bold></td><td>TTN</td><td>MFSD11</td></tr><tr><td><bold>PHEX</bold></td><td><bold>PHEX</bold></td><td>TTN</td><td><bold>PHEX</bold></td><td><bold>ZNF107</bold></td><td>MFSD11</td><td><bold>TRPC3</bold></td></tr><tr><td>TMX2</td><td>MFSD11</td><td><bold>KLHL21</bold></td><td>MFSD11</td><td>MFSD11</td><td>IGHE*</td><td>AMELX*</td></tr><tr><td>LRCH1</td><td>CARHSP1</td><td>CAMSAP1</td><td>CARHSP1</td><td>TTN</td><td>RPL10L*</td><td>MASP1</td></tr></tbody></table><table-wrap-foot><p><sup>1</sup>The genes with star (*) are the unique gene selected by MVSPL, and the common genes selected by each method are emphasized with bold.</p></table-wrap-foot></table-wrap><fig id="Fig8"><label>Figure 8</label><caption><p>Integrative network view of the genes selected from MVSPL in breast cancer study. The genes corresponding to the selected features are highlighted by a thicker black outline. The rest of the nodes correspond to the genes that are frequently altered and are known to interact with the highlighted genes (based on publicly available interaction data). The nodes are gradient color-coded according to the alteration frequency based on microarray data derived from the TCGA breast cancer dataset via cBioPortal.</p></caption><graphic xlink:href="41598_2019_49967_Fig8_HTML" id="d29e6800"/></fig><fig id="Fig9"><label>Figure 9</label><caption><p>Integrative network view of the genes selected from MVSPL in lung cancer study.</p></caption><graphic xlink:href="41598_2019_49967_Fig9_HTML" id="d29e6809"/></fig></p>
        <p id="Par63">In addition, a number of genes selected by the five methods have been reported in the literature. For example, in breast cancer, downregulation of ALOX15 expression has been reported in<sup><xref ref-type="bibr" rid="CR52">52</xref>,<xref ref-type="bibr" rid="CR53">53</xref></sup>. The upregulated expression of CDK14 promotes tumor cell proliferation, migration and invasion through Wnt/<italic>β</italic>— catenin signaling pathway in breast cancer<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>. UPK3A is highly expressed in breast cancer<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, which is selected only by MVSPL and SPL. Beyond that, MVSPL selects some other unique genes compared with other methods. Phuong <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> confirmed that MAT2A expression in TAM-resistant human breast cancer tissues was higher than that in TAM-responsive cases. Nass <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> proposed that NNAT expression determined by immunohistochemistry might therefore become a helpful additional biomarker to identify high-risk breast cancer patients. For lung cancer, Greenman <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> reported in 2005 that the role of TTN as a cancer gene is currently a mathematically based prediction and will require direct biological evaluation. And after a few years, Tan H <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR59">59</xref></sup> said TTN and/or MUC16 were retained in the top 10 for lung cancer, suggesting their tumorigenic relevance to these cancers. MASP1 is over expressed in lung cancer<sup><xref ref-type="bibr" rid="CR60">60</xref></sup>. In this part, we analysis the 20 top-ranked genes selected by the five methods in two cancer studies in gene level. According to the network of interactions among the genes, we find a few numbers of genes are connected to other frequently altered genes from the publicly available datasets and some genes are targeted by certain cancer drugs.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec20" sec-type="conclusion">
    <title>Conclusion</title>
    <p id="Par64">Due to the complexity of gene expression data, there are four major issues constrain the development of microarray technology in clinical applications: high noise, large <italic>p</italic> &amp; small <italic>n</italic> problem, batch effects and low reproducibility of significant biomarkers. In this work, we design a novel framework called MVIAm to strive to tackle these issues. MVIAm utilizes different cross-platform normalization methods to minimize the impact of batch effects, keeps as much useful information as possible in the microarray gene expression data. In addition, the aggregated gene expression datasets generated by MVIAm belong to multi-view data. It implies that MVIAm can significantly alleviate the large <italic>p</italic> &amp; small <italic>n</italic> problem compared to the existing integrative analysis methods. Therefore, MVIAm can increase the statistical power in identifying the significant biomarkers. To analysis of multi-view gene expression data, we propose a robust learning mechanism called MVSPL to minimize high noise interference. The MVSPL method can improve the generalization performance by learning multi-view data in a meaningful order and improve the prediction performance by the interaction between multiple views. MVSPL actually corresponds to the sum of SPL model under multiple views plus a regularization term. This method implements robust learning regimes in multiple views under the regularization that the robust loss forms in multiple views are closely related. According to the results of simulation and real data experiments, MVSPL has the superior performance compared with L<sub>1</sub>, L<sub><italic>EN</italic></sub>, SPL and Ensemble_EN. Especially in the test and validation dataset, MVSPL shows prominent generalization performance. In a word, MVSPL is a feasible and effective method for variable selection and classification in high dimensional data.</p>
    <p id="Par65">There are some ongoing challenges and promising directions that motivate future work. First, our proposed method conducts variable selection with aggregated microarray data in an “all-in-or-all-out” fashion, that is, a gene identified in all of studies or not identified in any study. However, due to data heterogeneity, there may be some genes are important in some studies while unimportant in others. In the future, we will take this situation into account to improve our model. Second, rapid advances in technology have led to a vast quantity of large-scale molecular omics datasets, it provides a distinct view of the complex biological system. Multi-omics dataset with the same set of samples but several distinct feature sets, which naturally belongs to multi-view data. In the future, we will apply our method to the analysis of multi-omics data. We think the computational analysis of the multi-omics data provides an unprecedented opportunity to deepen our understanding of complex cancer mechanisms. Our proposed method makes integrative analysis more systematic and expands its range of applications.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec21">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41598_2019_49967_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1038/s41598-019-49967-4.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>This work is partially supported by the Chinese Ministry of Education’s Tian Cheng Hui Zhi Innovation and Education Improvement Funds (Grant No. 2018A01014), the Macau Science and Technology Develop Funds (Grant No. 0055/2018/A2) of Macao SAR of China and China NSFC project under contract 61661166011.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author Contributions</title>
    <p>Z.Y.Y., J.S. and Y.L. proposed the Novel MVIAm integrative framework and proposed multi-view self-paced learning approach, designed the algorithm, wrote the code and manuscript, X.Y.L., H.Z. and Y.Q.R. provided the real data and analysis the information of biology, Z.B.X. provided the technical support. All authors reviewed the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data Availability</title>
    <p>The code of this paper can be download from <ext-link ext-link-type="uri" xlink:href="https://github.com/must-bio-team/MVIAm">https://github.com/must-bio-team/MVIAm</ext-link>.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing Interests</title>
    <p id="Par66">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barrett</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>NCBI GEO: archive for functional genomics data sets-update</article-title>
        <source>Nucleic acids research</source>
        <year>2012</year>
        <volume>41</volume>
        <fpage>D991</fpage>
        <lpage>D995</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gks1193</pub-id>
        <pub-id pub-id-type="pmid">23193258</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">Pepe, M. S. &amp; Feng, Z. Improving biomarker identification with better designs and reporting. <italic>Clinical Chemistry</italic> 1093–1095 (2011).</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Draghici</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Statistical intelligence: effective analysis of high-density microarray data</article-title>
        <source>Drug discovery today</source>
        <year>2002</year>
        <volume>7</volume>
        <fpage>S55</fpage>
        <lpage>S63</lpage>
        <pub-id pub-id-type="doi">10.1016/S1359-6446(02)02292-4</pub-id>
        <pub-id pub-id-type="pmid">12047881</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kitchen</surname>
            <given-names>RR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Relative impact of key sources of systematic noise in affymetrix and illumina gene-expression microarray experiments</article-title>
        <source>BMC genomics</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>589</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-12-589</pub-id>
        <pub-id pub-id-type="pmid">22133085</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bolón-Canedo</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Sánchez-Marono</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Alonso-Betanzos</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Benítez</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Herrera</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A review of microarray datasets and applied feature selection methods</article-title>
        <source>Inf. Sci</source>
        <year>2014</year>
        <volume>282</volume>
        <fpage>111</fpage>
        <lpage>135</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ins.2014.05.042</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Clarke</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Approaches to working in high-dimensional data spaces: gene expression microarrays</article-title>
        <source>Br. journal cancer</source>
        <year>2008</year>
        <volume>98</volume>
        <fpage>1023</fpage>
        <pub-id pub-id-type="doi">10.1038/sj.bjc.6604207</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Sparse logistic regression with a L<sup>1/2</sup> penalty for gene selection in cancer classification</article-title>
        <source>BMC bioinformatics</source>
        <year>2013</year>
        <volume>14</volume>
        <fpage>198</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-198</pub-id>
        <pub-id pub-id-type="pmid">23777239</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>ZY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Robust sparse logistic regression with the <italic>L</italic><sub><italic>q</italic></sub>(0 &lt; q &lt; 1) regularization for feature selection using gene expression data</article-title>
        <source>IEEE Access</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>68586</fpage>
        <lpage>68595</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2880198</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Larkin</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Frank</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Gavras</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Sultana</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Quackenbush</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Independence and reproducibility across microarray platforms</article-title>
        <source>Nat. methods</source>
        <year>2005</year>
        <volume>2</volume>
        <fpage>337</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth757</pub-id>
        <pub-id pub-id-type="pmid">15846360</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Leek</surname>
            <given-names>JT</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Tackling the widespread and critical impact of batch effects in high-throughput data</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2010</year>
        <volume>11</volume>
        <fpage>733</fpage>
        <pub-id pub-id-type="doi">10.1038/nrg2825</pub-id>
        <pub-id pub-id-type="pmid">20838408</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Chinnaiyan</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Ghosh</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Pathway analysis reveals functional convergence of gene expression profiles in breast cancer</article-title>
        <source>BMC medical genomics</source>
        <year>2008</year>
        <volume>1</volume>
        <fpage>28</fpage>
        <pub-id pub-id-type="doi">10.1186/1755-8794-1-28</pub-id>
        <pub-id pub-id-type="pmid">18588682</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tseng</surname>
            <given-names>GC</given-names>
          </name>
          <name>
            <surname>Ghosh</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Feingold</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Comprehensive literature review and statistical considerations for microarray meta-analysis</article-title>
        <source>Nucleic acids research</source>
        <year>2012</year>
        <volume>40</volume>
        <fpage>3785</fpage>
        <lpage>3799</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr1265</pub-id>
        <pub-id pub-id-type="pmid">22262733</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sørlie</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Repeated observation of breast tumor subtypes in independent gene expression data sets</article-title>
        <source>Proc. national academy sciences</source>
        <year>2003</year>
        <volume>100</volume>
        <fpage>8418</fpage>
        <lpage>8423</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0932692100</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Hamid, J. S. <italic>et al</italic>. Data integration in genetics and genomics: methods and challenges. <italic>Hum. genomics proteomics: HGP</italic><bold>2009</bold> (2009).</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rhodes</surname>
            <given-names>DR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Large-scale meta-analysis of cancer microarray data identifies common transcriptional profiles of neoplastic transformation and progression</article-title>
        <source>Proc. Natl. Acad. Sci.</source>
        <year>2004</year>
        <volume>101</volume>
        <fpage>9309</fpage>
        <lpage>9314</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0401994101</pub-id>
        <pub-id pub-id-type="pmid">15184677</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Choi</surname>
            <given-names>JK</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Yoo</surname>
            <given-names>OJ</given-names>
          </name>
        </person-group>
        <article-title>Combining multiple microarray studies and modeling interstudy variation</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>i84</fpage>
        <lpage>i90</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg1010</pub-id>
        <pub-id pub-id-type="pmid">12855442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chang</surname>
            <given-names>L-C</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H-M</given-names>
          </name>
          <name>
            <surname>Sibille</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Tseng</surname>
            <given-names>GC</given-names>
          </name>
        </person-group>
        <article-title>Meta-analysis methods for combining multiple expression profiles: comparisons, statistical characterization and an application guideline</article-title>
        <source>BMC bioinformatics</source>
        <year>2013</year>
        <volume>14</volume>
        <fpage>368</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-368</pub-id>
        <pub-id pub-id-type="pmid">24359104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Lusa, L., Gentleman, R. &amp; Ruschhaupt, M. Genemeta: metaanalysis for high throughput experiments. R package version <bold>1</bold> (2006).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Parmigiani</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Garrett</surname>
            <given-names>ES</given-names>
          </name>
          <name>
            <surname>Anbazhagan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Gabrielson</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>A statistical framework for expression-based molecular classification in cancer</article-title>
        <source>J. Royal Stat. Soc. Ser. B (Statistical Methodol.)</source>
        <year>2002</year>
        <volume>64</volume>
        <fpage>717</fpage>
        <lpage>736</lpage>
        <pub-id pub-id-type="doi">10.1111/1467-9868.00358</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Regularized gene selection in cancer microarray meta-analysis</article-title>
        <source>BMC bioinformatics</source>
        <year>2009</year>
        <volume>10</volume>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-10-1</pub-id>
        <pub-id pub-id-type="pmid">19118496</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>C-C</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Meta-analysis based variable selection for gene expression data</article-title>
        <source>Biometrics</source>
        <year>2014</year>
        <volume>70</volume>
        <fpage>872</fpage>
        <lpage>880</lpage>
        <pub-id pub-id-type="doi">10.1111/biom.12213</pub-id>
        <pub-id pub-id-type="pmid">25196635</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hughey</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Butte</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <article-title>Robust meta-analysis of gene expression using the elastic net</article-title>
        <source>Nucleic acids research</source>
        <year>2015</year>
        <volume>43</volume>
        <fpage>e79</fpage>
        <lpage>e79</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv229</pub-id>
        <pub-id pub-id-type="pmid">25829177</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Walsh</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Batt</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Santos</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Microarray meta-analysis and cross-platform normalization: integrative genomics for robust biomarker discovery</article-title>
        <source>Microarrays</source>
        <year>2015</year>
        <volume>4</volume>
        <fpage>389</fpage>
        <lpage>406</lpage>
        <pub-id pub-id-type="doi">10.3390/microarrays4030389</pub-id>
        <pub-id pub-id-type="pmid">27600230</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>WE</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rabinovic</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Adjusting batch effects in microarray expression data using empirical bayes methods</article-title>
        <source>Biostatistics</source>
        <year>2007</year>
        <volume>8</volume>
        <fpage>118</fpage>
        <lpage>127</lpage>
        <pub-id pub-id-type="doi">10.1093/biostatistics/kxj037</pub-id>
        <pub-id pub-id-type="pmid">16632515</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shabalin</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Tjelmeland</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Perou</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Nobel</surname>
            <given-names>AB</given-names>
          </name>
        </person-group>
        <article-title>Merging two gene-expression studies via cross-platform normalization</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <fpage>1154</fpage>
        <lpage>1160</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn083</pub-id>
        <pub-id pub-id-type="pmid">18325927</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Giordan</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>A two-stage procedure for the removal of batch effects in microarray studies</article-title>
        <source>Stat. Biosci.</source>
        <year>2014</year>
        <volume>6</volume>
        <fpage>73</fpage>
        <lpage>84</lpage>
        <pub-id pub-id-type="doi">10.1007/s12561-013-9081-1</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Removing batch effects in analysis of expression microarray data: an evaluation of six batch adjustment methods</article-title>
        <source>PloS one</source>
        <year>2011</year>
        <volume>6</volume>
        <fpage>e17238</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0017238</pub-id>
        <pub-id pub-id-type="pmid">21386892</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>F-X</given-names>
          </name>
          <name>
            <surname>Ngom</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A review on machine learning principles for multi-view biological data integration</article-title>
        <source>Briefings bioinformatics</source>
        <year>2016</year>
        <volume>19</volume>
        <fpage>325</fpage>
        <lpage>340</lpage>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Li, Y., Yang, M. &amp; Zhang, Z. M. A survey of multi-view representation learning. <italic>IEEE Transactions on Knowl. Data Eng</italic>. (2018).</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Multi-view learning overview: Recent progress and new challenges</article-title>
        <source>Inf. Fusion</source>
        <year>2017</year>
        <volume>38</volume>
        <fpage>43</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="doi">10.1016/j.inffus.2017.02.007</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Singh, A. <italic>et al</italic>. Diablo: an integrative approach for identifying key molecular drivers from multi-omics assays. <italic>Bioinformatics</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Kumar, M. P., Packer, B. &amp; Koller, D. Self-paced learning for latent variable models. In <italic>Advances in Neural Information Processing Systems</italic>, 1189–1197 (2010).</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Shu, J. <italic>et al</italic>. Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting. <italic>arXiv preprint arXiv</italic>, 1902.07379 (2019).</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Bengio, Y., Louradour, J., Collobert, R. &amp; Weston, J. Curriculum learning. In <italic>Proceedings of the 26th annual international conference on machine learning</italic>, 41–48 (ACM, 2009).</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Kumar, M. P., Turki, H., Preston, D. &amp; Koller, D. Learning specific-class segmentation from diverse data. In <italic>Computer Vision (ICCV), 2011 IEEE International Conference on</italic>, 1800–1807 (IEEE, 2011).</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Tang, K., Ramanathan, V., Fei-Fei, L. &amp; Koller, D. Shifting weights: Adapting object detectors from image to video. In <italic>Advances in Neural Information Processing Systems</italic>, 638–646 (2012).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Jiang, L., Meng, D., Mitamura, T. &amp; Hauptmann, A. G. Easy samples first: Self-paced reranking for zero-example multimedia search. In <italic>Proceedings of the 22nd ACM international conference on Multimedia</italic>, 547–556 (ACM, 2014).</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chai</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z-N</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>D-Y</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>L-Y</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A new semi-supervised learning model combined with cox and sp-aft models in cancer survival analysis</article-title>
        <source>Sci. reports</source>
        <year>2017</year>
        <volume>7</volume>
        <fpage>13053</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-017-13133-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meng</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>A theoretical understanding of self-paced learning</article-title>
        <source>Inf. Sci.</source>
        <year>2017</year>
        <volume>414</volume>
        <fpage>319</fpage>
        <lpage>328</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ins.2017.05.043</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Irizarry</surname>
            <given-names>RA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Exploration, normalization, and summaries of high density oligonucleotide array probe level data</article-title>
        <source>Biostatistics</source>
        <year>2003</year>
        <volume>4</volume>
        <fpage>249</fpage>
        <lpage>264</lpage>
        <pub-id pub-id-type="doi">10.1093/biostatistics/4.2.249</pub-id>
        <pub-id pub-id-type="pmid">12925520</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gentleman</surname>
            <given-names>RC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Bioconductor: open software development for computational biology and bioinformatics</article-title>
        <source>Genome biology</source>
        <year>2004</year>
        <volume>5</volume>
        <fpage>R80</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2004-5-10-r80</pub-id>
        <pub-id pub-id-type="pmid">15461798</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Friedman</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Regularization paths for generalized linear models via coordinate descent</article-title>
        <source>J. statistical software</source>
        <year>2010</year>
        <volume>33</volume>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.18637/jss.v033.i01</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tibshirani</surname>
            <given-names>Robert</given-names>
          </name>
        </person-group>
        <article-title>Regression Shrinkage and Selection Via the Lasso</article-title>
        <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>
        <year>1996</year>
        <volume>58</volume>
        <issue>1</issue>
        <fpage>267</fpage>
        <lpage>288</lpage>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Regularization and variable selection via the elastic net</article-title>
        <source>J. Royal Stat. Soc. Ser. B (Statistical Methodol.)</source>
        <year>2005</year>
        <volume>67</volume>
        <fpage>301</fpage>
        <lpage>320</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Günther</surname>
            <given-names>OP</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A computational pipeline for the development of multi-marker bio-signature panels and ensemble classifiers</article-title>
        <source>BMC bioinformatics</source>
        <year>2012</year>
        <volume>13</volume>
        <fpage>326</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-13-326</pub-id>
        <pub-id pub-id-type="pmid">23216969</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sohn</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>S-H</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Gradient lasso for cox proportional hazards model</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <fpage>1775</fpage>
        <lpage>1781</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btp322</pub-id>
        <pub-id pub-id-type="pmid">19447787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baratloo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hosseini</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Negida</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>El Ashal</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Part 1: simple definition and calculation of accuracy, sensitivity and specificity</article-title>
        <source>Emergency</source>
        <year>2015</year>
        <volume>3</volume>
        <fpage>48</fpage>
        <lpage>49</lpage>
        <?supplied-pmid 26495380?>
        <pub-id pub-id-type="pmid">26495380</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lobo</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Jiménez-Valverde</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Real</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Auc: a misleading measure of the performance of predictive distribution models</article-title>
        <source>Glob. ecology Biogeogr.</source>
        <year>2008</year>
        <volume>17</volume>
        <fpage>145</fpage>
        <lpage>151</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1466-8238.2007.00358.x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Molecular pathway identification using biological network-regularized logistic models</article-title>
        <source>BMC genomics</source>
        <year>2013</year>
        <volume>14</volume>
        <fpage>S7</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2164-14-S8-S7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Integrative analysis of complex cancer genomics and clinical profiles using the cbioportal</article-title>
        <source>Sci. Signal.</source>
        <year>2013</year>
        <volume>6</volume>
        <fpage>pl1</fpage>
        <lpage>pl1</lpage>
        <pub-id pub-id-type="doi">10.1126/scisignal.2004088</pub-id>
        <pub-id pub-id-type="pmid">23550210</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Cerami, E. <italic>et al</italic>. The cbio cancer genomics portal: an open platform for exploring multidimensional cancer genomics data (2012).</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jiang</surname>
            <given-names>WG</given-names>
          </name>
          <name>
            <surname>Watkins</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Douglas-Jones</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mansel</surname>
            <given-names>RE</given-names>
          </name>
        </person-group>
        <article-title>Reduction of isoforms of 15-lipoxygenase (15-lox)-1 and 15-lox-2 in human breast cancer</article-title>
        <source>Prostaglandins, Leukot. Essent. Fat. Acids</source>
        <year>2006</year>
        <volume>74</volume>
        <fpage>235</fpage>
        <lpage>245</lpage>
        <pub-id pub-id-type="doi">10.1016/j.plefa.2006.01.009</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ho</surname>
            <given-names>CF-Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Expression of dha-metabolizing enzyme alox15 is regulated by selective histone acetylation in neuroblastoma cells</article-title>
        <source>Neurochem. research</source>
        <year>2018</year>
        <volume>43</volume>
        <fpage>540</fpage>
        <lpage>555</lpage>
        <pub-id pub-id-type="doi">10.1007/s11064-017-2448-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gu</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Upregulated pftk1 promotes tumor cell proliferation, migration, and invasion in breast cancer</article-title>
        <source>Med. Oncol.</source>
        <year>2015</year>
        <volume>32</volume>
        <fpage>195</fpage>
        <pub-id pub-id-type="doi">10.1007/s12032-015-0641-8</pub-id>
        <pub-id pub-id-type="pmid">26033031</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Network</surname>
            <given-names>CGAR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Comprehensive molecular characterization of urothelial bladder carcinoma</article-title>
        <source>Nature</source>
        <year>2014</year>
        <volume>507</volume>
        <fpage>315</fpage>
        <pub-id pub-id-type="doi">10.1038/nature12965</pub-id>
        <pub-id pub-id-type="pmid">24476821</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Phuong</surname>
            <given-names>NTT</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Induction of methionine adenosyltransferase 2a in tamoxifen-resistant breast cancer cells</article-title>
        <source>Oncotarget</source>
        <year>2016</year>
        <volume>7</volume>
        <fpage>13902</fpage>
        <pub-id pub-id-type="doi">10.18632/oncotarget.5298</pub-id>
        <pub-id pub-id-type="pmid">26418898</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nass</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High neuronatin (nnat) expression is associated with poor outcome in breast cancer</article-title>
        <source>Virchows Arch.</source>
        <year>2017</year>
        <volume>471</volume>
        <fpage>23</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1007/s00428-017-2154-7</pub-id>
        <pub-id pub-id-type="pmid">28540450</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Greenman</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Patterns of somatic mutation in human cancer genomes</article-title>
        <source>Nature</source>
        <year>2007</year>
        <volume>446</volume>
        <fpage>153</fpage>
        <pub-id pub-id-type="doi">10.1038/nature05610</pub-id>
        <pub-id pub-id-type="pmid">17344846</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Genome-wide mutational spectra analysis reveals significant cancer-specific heterogeneity</article-title>
        <source>Sci. reports</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>12566</fpage>
        <pub-id pub-id-type="doi">10.1038/srep12566</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kang</surname>
            <given-names>JU</given-names>
          </name>
          <name>
            <surname>Koo</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Kwon</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>JM</given-names>
          </name>
        </person-group>
        <article-title>Identification of novel candidate target genes, including ephb3, masp1 and sst at 3q26. 2-q29 in squamous cell carcinoma of the lung</article-title>
        <source>BMC cancer</source>
        <year>2009</year>
        <volume>9</volume>
        <fpage>237</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2407-9-237</pub-id>
        <pub-id pub-id-type="pmid">19607727</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
