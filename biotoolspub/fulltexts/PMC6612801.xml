<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6612801</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz339</article-id>
    <article-id pub-id-type="publisher-id">btz339</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2019 Conference Proceedings</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Macromolecular Sequence, Structure, and Function</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Comprehensive evaluation of deep learning architectures for prediction of DNA/RNA sequence binding specificities</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Trabelsi</surname>
          <given-names>Ameni</given-names>
        </name>
        <xref ref-type="author-notes" rid="btz339-FM2"/>
        <xref ref-type="aff" rid="btz339-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chaabane</surname>
          <given-names>Mohamed</given-names>
        </name>
        <xref ref-type="author-notes" rid="btz339-FM2"/>
        <xref ref-type="aff" rid="btz339-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ben-Hur</surname>
          <given-names>Asa</given-names>
        </name>
        <xref ref-type="corresp" rid="btz339-cor1"/>
        <!--<email>asa@cs.colostate.edu</email>-->
        <xref ref-type="aff" rid="btz339-aff1"/>
      </contrib>
    </contrib-group>
    <aff id="btz339-aff1">Department of Computer Science, Colorado State University, Fort Collins, CO, USA</aff>
    <author-notes>
      <corresp id="btz339-cor1">To whom correspondence should be addressed. <email>asa@cs.colostate.edu</email></corresp>
      <fn id="btz339-FM2">
        <p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-07-05">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>14</issue>
    <fpage>i269</fpage>
    <lpage>i277</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz339.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Deep learning architectures have recently demonstrated their power in predicting DNA- and RNA-binding specificity. Existing methods fall into three classes: Some are based on convolutional neural networks (CNNs), others use recurrent neural networks (RNNs) and others rely on hybrid architectures combining CNNs and RNNs. However, based on existing studies the relative merit of the various architectures remains unclear.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>In this study we present a systematic exploration of deep learning architectures for predicting DNA- and RNA-binding specificity. For this purpose, we present <monospace>deepRAM</monospace>, an end-to-end deep learning tool that provides an implementation of a wide selection of architectures; its fully automatic model selection procedure allows us to perform a fair and unbiased comparison of deep learning architectures. We find that deeper more complex architectures provide a clear advantage with sufficient training data, and that hybrid CNN/RNN architectures outperform other methods in terms of accuracy. Our work provides guidelines that can assist the practitioner in choosing an appropriate network architecture, and provides insight on the difference between the models learned by convolutional and recurrent networks. In particular, we find that although recurrent networks improve model accuracy, this comes at the expense of a loss in the interpretability of the features learned by the model.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code for <monospace>deepRAM</monospace> is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/MedChaabane/deepRAM">https://github.com/MedChaabane/deepRAM</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>DNA- and RNA-binding proteins are involved in many biological processes including transcription, translation and alternative splicing (<xref rid="btz339-B11" ref-type="bibr">Ferré <italic>et al.</italic>, 2016</xref>; <xref rid="btz339-B12" ref-type="bibr">Gerstberger <italic>et al.</italic>, 2014</xref>). Unfortunately, only some of these binding sites have been identified by biological experiments. Moreover, these experiments are expensive and time-consuming. Position weight matrices (PWMs) are the most common method to characterize the sequence specificity of a protein, thanks to their simplicity and ease of interpretation (<xref rid="btz339-B36" ref-type="bibr">Stormo, 2000</xref>). However, many studies suggest that sequence specificity can be better captured using more complex models (<xref rid="btz339-B19" ref-type="bibr">Kazan <italic>et al.</italic>, 2010</xref>; <xref rid="btz339-B33" ref-type="bibr">Rohs <italic>et al.</italic>, 2010</xref>; <xref rid="btz339-B35" ref-type="bibr">Siggers and Gordâ n, 2014</xref>).</p>
    <p>In recent years, deep neural networks have become the technique of choice for challenging tasks in computer vision (<xref rid="btz339-B21" ref-type="bibr">Krizhevsky <italic>et al.</italic>, 2012</xref>; <xref rid="btz339-B23" ref-type="bibr">LeCun <italic>et al.</italic>, 2015</xref>), speech recognition (<xref rid="btz339-B16" ref-type="bibr">Hinton <italic>et al.</italic>, 2012</xref>), machine translation (<xref rid="btz339-B39" ref-type="bibr">Sutskever <italic>et al.</italic>, 2014</xref>) and computational biology (<xref rid="btz339-B2" ref-type="bibr">Angermueller <italic>et al.</italic>, 2016</xref>). Methods based on convolutional neural networks (CNNs) (<xref rid="btz339-B22" ref-type="bibr">LeCun <italic>et al.</italic>, 1998</xref>) and recurrent neural networks (RNNs) (<xref rid="btz339-B18" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>) have been proposed for the task of identifying protein binding sites in DNA and RNA sequences, and have achieved state-of-the-art performance (<xref rid="btz339-B1" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>; <xref rid="btz339-B15" ref-type="bibr">Hassanzadeh and Wang, 2016</xref>; <xref rid="btz339-B31" ref-type="bibr">Quang and Xie, 2016</xref>; <xref rid="btz339-B34" ref-type="bibr">Shen <italic>et al.</italic>, 2018</xref>).</p>
    <p>DeepBind (<xref rid="btz339-B1" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>) was the first deep learning approach for this task. It used a single layer of convolution and demonstrated the accuracy of CNNs as well as their ability to learn signal detectors that recapitulate known motifs. <xref rid="btz339-B41" ref-type="bibr">Zeng <italic>et al.</italic> (2016)</xref> explored in more detail the effect of various architecture parameters such as the number of layers and operations such as pooling. Other studies opted for more complex architectures and introduced hybrid models that integrate both CNNs and RNNs. DeeperBind (<xref rid="btz339-B15" ref-type="bibr">Hassanzadeh and Wang, 2016</xref>) and DanQ (<xref rid="btz339-B31" ref-type="bibr">Quang and Xie, 2016</xref>) for example, add long short-term memory (LSTM) layer(s) to the DeepBind architecture. The additional RNN layers are designed to improve binding accuracy prediction by learning long-range dependencies between the sequence features learned by the CNN layers. Purely RNN-based methods were also examined: the KEGRU method (<xref rid="btz339-B34" ref-type="bibr">Shen <italic>et al.</italic>, 2018</xref>) used a layer of bidirectional gated recurrent units (bi-GRUs), combined with a <italic>k</italic>-mer embedding representation of the input sequence to create an internal state of the network that allows it to capture long-range dependencies and thus obtain good performance. Methods that are specific to modeling RNA-binding proteins (RBPs) were also developed. iDeepS for example, uses both CNN and RNN layers, and identifies sequence and structural motifs simultaneously (<xref rid="btz339-B30" ref-type="bibr">Pan <italic>et al.</italic>, 2018</xref>).</p>
    <p>Despite all these studies, it is still not clear which deep learning architecture performs best for detecting binding in DNA and RNA sequences. A fair and unbiased comparison can be very challenging especially when considering the sensitivity of deep learning methods to the step of model selection: deep neural networks have many hyper-parameters that require careful tuning, and differences in performance can be the result of the use of different model selection strategies (<xref rid="btz339-B24" ref-type="bibr">Lipton and Steinhardt, 2018</xref>; <xref rid="btz339-B27" ref-type="bibr">Melis <italic>et al.</italic>, 2018</xref>). Therefore, a meaningful comparison requires the use of a coherent model selection strategy applied uniformly across all architectures. In this study, we conduct a systematic exploration of the performance of different architectures using CNNs and/or RNNs for the study of DNA and RNA sequence binding specificity prediction. For this purpose, we have designed a collection of architecture variants, some of which correspond to published methods by varying the network components, depth and input layer representation. To ensure the objectivity of our evaluation, we used the same model selection strategy and made the pipeline fully automatic to avoid the need for hand-tuning.</p>
    <p>Our experiments use datasets collected from the Encyclopedia of DNA Elements (ENCODE) project (<xref rid="btz339-B10" ref-type="bibr">ENCODE-Project-Consortium, 2012</xref>) and verified binding site of RBPs derived from large-scale CLIP-seq experiments (<xref rid="btz339-B37" ref-type="bibr">Stražar <italic>et al.</italic>, 2016</xref>). We find that more complex architectures that combine RNNs and CNNs indeed provide improved performance over the vanilla CNN model, and that this advantage increases with increasing number of training examples that are available. However, the improvement in accuracy comes at the expense of the interpretability of the learned models and increased training times. Our results also demonstrate the advantage of using a <italic>k</italic>-mer embedding to represent the input sequence instead of the standard one-hot encoding, especially for RBP binding site prediction. Finally, we present an end-to-end deep learning toolkit called <xref rid="btz339-B11" ref-type="bibr">deepRAM</xref> that provides a framework for training and evaluating deep learning architectures for DNA/RNA sequence analysis.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>In this study, we present a comprehensive evaluation of different deep learning architectures for the task of predicting DNA- and RNA-protein binding sites. First, we present the benchmark datasets used in our study. Then, we present the architectures used in our experiments. Third, we provide the technical details of the model selection process that we followed to ensure unbiased model comparison. These methods are implemented as an open-source deep learning package called <monospace>deepRAM</monospace> that allows users to evaluate different architectures for predicting DNA- and RNA-protein binding sites. Finally, we describe our method for extracting motifs from the learned models.</p>
    <sec>
      <title>2.1 Datasets</title>
      <p>The deep learning models are evaluated on data from ChIP-seq and CLIP-seq experiments. For ChIP-seq data we used data from 83 ChIP-seq experiments from the ENCODE project that assayed binding of diverse transcription factors. These datasets were used to evaluate deep learning architectures in <xref rid="btz339-B1" ref-type="bibr">Alipanahi <italic>et al.</italic> (2015)</xref> and <xref rid="btz339-B42" ref-type="bibr">Zhou and Troyanskaya (2015)</xref>, and we use the same sequences as training/testing examples. The authors of DeepBind split the ChIP peak data into three lists: A, B and C. A is the set of the top 500 even-numbered peaks when considering the ranked list of peaks detected. B is the set of the top 500 odd-numbered peaks and C is the set of remaining peaks. For model training, we use the peaks from A and C, and the peaks from B were used for testing. Positive examples in this binary classification task consist of 101 bp regions centered on each ChIP-seq peak. The negative examples were generated by shuffling the positive sequences while matching dinucleotide composition.</p>
      <p>We also evaluate the ability of different architectures to identify RNA-binding sites. We use the same benchmark human dataset used by the developers of iONMF (<xref rid="btz339-B37" ref-type="bibr">Stražar <italic>et al.</italic>, 2016</xref>) which consists of 31 CLIP-seq experiments over 19 proteins. The data were obtained from (<ext-link ext-link-type="uri" xlink:href="https://github.com/mstrazar/ionmf">https://github.com/mstrazar/ionmf</ext-link>); original data were retrieved from DoRiNA (<xref rid="btz339-B5" ref-type="bibr">Blin <italic>et al.</italic>, 2015</xref>) and iCount (<ext-link ext-link-type="uri" xlink:href="http://icount.biolab.si/">http://icount.biolab.si/</ext-link>). Positive sites represented nucleotides that were identified as being within clusters of interaction sites derived from CLIP-seq. Negative sites were extracted from genes not participating in the protein-RNA interaction process in any of the 31 experiments. Each experiment consists of 40 000 examples divided into 30 000 examples for training and 10 000 for testing.</p>
    </sec>
    <sec>
      <title>2.2 Model architectures</title>
      <p>In this section, we describe the deep learning architectures to be evaluated (see <xref ref-type="fig" rid="btz339-F1">Fig. 1</xref>). In addition to comparing architectures, we compare two ways of representing the input sequence: either using a one-hot encoding or a <italic>k</italic>-mer embedding computed using word2vec (<xref rid="btz339-B3" ref-type="bibr">Asgari and Mofrad, 2015</xref>; <xref rid="btz339-B28" ref-type="bibr">Mikolov <italic>et al.</italic>, 2013</xref>). When using the one-hot encoding, the input sequence is represented by a 4 × <italic>L</italic> matrix where <italic>L</italic> is the length of the sequence and each position in the sequence is associated with a vector of length four with a single non-zero element corresponding to the nucleotide in that position. For the <italic>k</italic>-mer embedding representation (see <xref ref-type="fig" rid="btz339-F1">Fig. 1</xref>), we first split the sequence into overlapping <italic>k</italic>-mers of length <italic>k</italic> using a sliding window with stride <italic>s</italic> and then map each <italic>k</italic>-mer in the obtained sequence into a <italic>d</italic>-dimensional vector space using the word2vec algorithm (<xref rid="btz339-B28" ref-type="bibr">Mikolov <italic>et al.</italic>, 2013</xref>). Word2vec is an unsupervised learning algorithm which maps <italic>k</italic>-mers from the vocabulary to vectors of real numbers in a low-dimensional space. The embedding representation of <italic>k</italic>-mers is computed in such a way that their context is preserved, i.e. word2vec produces similar embedding vectors for <italic>k</italic>-mers that tend to co-occur.
</p>
      <fig id="btz339-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Overview of the deep learning architectures evaluated in this work. These include CNN-only models known for their ability to detect motifs (left), RNN-only models (center) which excel at capturing long-term sequence dependencies, and hybrid CNN-RNN models. The input for all variants is either a one-hot encoding or a <italic>k</italic>-mer embedding of the DNA/RNA sequence obtained using word2vec</p>
        </caption>
        <graphic xlink:href="btz339f1"/>
      </fig>
      <p><italic>Convolutional networks.</italic> To apply CNNs to biological sequence data we use 1D convolution. In 1D convolution we slide local signal detectors (filters) along the sequence; subsequent convolutional layers integrate the results of previous layers at increasing spatial scales, generating a representation that is able to abstract away some of the variability observed in binding sites. Each convolutional module is composed of a convolutional layer and a pooling layer (see <xref ref-type="fig" rid="btz339-F1">Fig. 1</xref>). A convolutional layer consists of 1D convolution with a specified number of kernels or filters. The results of applying each filter at each position of the sequence is transformed using a non-linear activation function. We use the commonly used rectified linear unit (ReLU), which keeps only positive filter values and sets the remaining to 0, which helps avoid the so-called vanishing gradient problem (<xref rid="btz339-B4" ref-type="bibr">Bengio <italic>et al.</italic>, 1994</xref>; <xref rid="btz339-B25" ref-type="bibr">Maas <italic>et al.</italic>, 2013</xref>). More specifically, a convolution layer computes
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mtext>convolution</mml:mtext><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>ReLU</mml:mtext><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">mn</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></disp-formula>
where <italic>X</italic> is the input matrix representing the sequence, <italic>i</italic> is the index of the output position and <italic>k</italic> is the index of the filter. Each convolutional filter <italic>W<sup>k</sup></italic> is an <italic>M </italic>×<italic> N</italic> matrix with <italic>M</italic> being the window size and <italic>N</italic> being the number of input channels. For the first convolution layer <italic>N</italic> equals the input representation dimension (four for one-hot encoding or <italic>d</italic> for the word2vec representation); for higher-level convolutional layers <italic>N</italic> is the number of filters in the previous convolutional layer. Next, the output of convolution undergoes pooling, which aggregates the outputs from neighboring positions for each filter in order to achieve consistency and invariance to small shifts in the input sequence. In this work, we use max-pooling which computes the maximum value over a fixed number of spatially adjacent overlapping windows over the convolutional layer’s output:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mtext>pooling</mml:mtext><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>Y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">max</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">iP</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">iP</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">iP</mml:mi><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula>
where <italic>Y</italic> is the output of the convolutional layer, <italic>P</italic> is the pooling window size, <italic>i</italic> is the output position and <italic>k</italic> is the index of the filter being pooled.</p>
      <p>The first convolutional layer can be thought of as a motif detector where each filter is analogous to a PWM and the convolution operation is equivalent to scanning the PWM with a sliding window across the sequence. Additional layers of convolution and pooling enable the network to extract features from larger spatial ranges and potentially capture interactions between motifs, allowing the network to represent more complex patterns than shallower networks. On the flip side, deeper networks have more parameters and require more data for obtaining high levels of performance.</p>
      <p><italic>RNN-based models</italic>. The second class of architectures we explore are RNN-only models. RNNs have an internal state that is updated as the network reads the input sequence. This internal memory allows RNNs to capture interactions between distant elements along the sequence, and is therefore commonly used in natural language processing (<xref rid="btz339-B17" ref-type="bibr">Hirschberg and Manning, 2015</xref>). Two types of RNN units were tested using <monospace>deepRAM</monospace>: LSTM units (<xref rid="btz339-B18" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>) and GRU units (<xref rid="btz339-B7" ref-type="bibr">Cho <italic>et al.</italic>, 2014</xref>; <xref rid="btz339-B8" ref-type="bibr">Chung <italic>et al.</italic>, 2014</xref>). A GRU unit given an input <italic>x<sub>t</sub></italic> at position <italic>t</italic> in the sequence performs the following operations:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>∼</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi mathvariant="normal">tanh</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>⊙</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>∼</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE1"><mml:math id="IM1"><mml:mo>⊙</mml:mo></mml:math></inline-formula> is element-wise multiplication, <italic>z<sub>t</sub></italic> and <italic>r<sub>t</sub></italic> are the two GRU gates called the update gate and reset gate, respectively; <italic>W<sub>z</sub></italic>, <italic>W<sub>r</sub></italic> and <italic>W<sub>h</sub></italic> are weight matrices, and <italic>b<sub>z</sub></italic>, <italic>b<sub>r</sub></italic> and <italic>b<sub>h</sub></italic> are the biases. <italic>h<sub>t</sub></italic> is the hidden state that is used as memory to hold information on previous data the network has seen before, and <inline-formula id="IE2"><mml:math id="IM2"><mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mover><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>∼</mml:mo></mml:mover></mml:mstyle></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the candidate memory state that is considered for potentially replacing <italic>h<sub>t</sub></italic>. The reset gate controls how much past information to forget and the update gate controls how much information to throw away and what new information to add. The gates and hidden states are vectors of real numbers of the same dimension, which is a tunable hyper-parameter.</p>
      <p>LSTM units are more complex than GRU units, and we refer the readers to the original publications for details (<xref rid="btz339-B18" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>). The basic idea of using a gating mechanism in both LSTM and GRU architectures is to capture short- and long-term dependencies in sequences. After the LSTM/GRU has iterated over the sequence, we use its hidden state at the last position, which contains information about the entire sequence, as the output of that layer.</p>
      <p>The bi-RNN (bi-GRU/bi-LSTM) is an extension of the regular RNN, which consists of a forward layer and a backward layer, representing traversals of the sequence in both directions. The output of the bi-RNN is then computed by concatenating the output vectors of the two traversals together.</p>
      <p><italic>Hybrid models.</italic> The third type of architecture we consider is that of hybrid convolutional and recurrent networks (see <xref ref-type="fig" rid="btz339-F1">Fig. 1</xref>). The convolution stage that is composed of one or more convolutional modules scans the sequence using a set of 1D convolutional filter in order to capture sequence patterns or motifs. The convolutional stage is followed by an RNN stage which is capable of learning complex high-level grammar-like relationships by considering the orientations and spatial relationships between the motifs.</p>
      <p>The final module in all three types of models is composed of one or two fully connected layers to integrate information from the entire sequence followed by a sigmoid layer to compute the probability that the input sequence contains a DNA- or RNA-binding site.</p>
      <p><italic>Evaluated architectures</italic>. The <monospace>deepRAM</monospace> tool provides implementations of several existing architectures: DeepBind (<xref rid="btz339-B1" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>), which uses a single CNN layer; DanQ, which uses a single layer CNN followed by a bidirectional LSTM (<xref rid="btz339-B31" ref-type="bibr">Quang and Xie, 2016</xref>); KEGRU, which uses <italic>k</italic>-mer embedding and a layer of GRU units (<xref rid="btz339-B34" ref-type="bibr">Shen <italic>et al.</italic>, 2018</xref>) and dilated multi-layer CNN (<xref rid="btz339-B13" ref-type="bibr">Gupta and Rush, 2017</xref>). To fully evaluate the range of deep learning architectures we considered additional variants denoted as DeepBind* (multi-layer CNN), DanQ* (DanQ with multiple layers of convolution), DeepBind-E* (multi-layer CNN with <italic>k</italic>-mer embedding), ECLSTM (<italic>k</italic>-mer embedding with single layer CNN and LSTM) and ECBLSTM (<italic>k</italic>-mer embedding with single layer CNN and bidirectional LSTM). These architectures are summarized in <xref rid="btz339-T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap id="btz339-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Overview of the models compared in this work</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Layers</th>
              <th align="left" rowspan="1" colspan="1">DeepBind</th>
              <th align="left" rowspan="1" colspan="1">DeepBinda</th>
              <th align="left" rowspan="1" colspan="1">Dilated</th>
              <th align="left" rowspan="1" colspan="1">DanQ</th>
              <th align="left" rowspan="1" colspan="1">DanQa</th>
              <th align="left" rowspan="1" colspan="1">DeepBind-Ea</th>
              <th align="left" rowspan="1" colspan="1">KEGRU</th>
              <th align="left" rowspan="1" colspan="1">ECLSTM</th>
              <th align="left" rowspan="1" colspan="1">ECBLSTM</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Embedding</td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Convolution</td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
                <sup>(3)</sup>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+<sup>(3)</sup></bold>
                <xref ref-type="table-fn" rid="tblfn2">
                  <sup>a</sup>
                </xref>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
                <sup>(3)</sup>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
                <sup>(3)</sup>
              </td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>+</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recurrent</td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">bi-LSTM</td>
              <td rowspan="1" colspan="1">bi-LSTM</td>
              <td rowspan="1" colspan="1">
                <bold>−</bold>
              </td>
              <td rowspan="1" colspan="1">bi-GRU</td>
              <td rowspan="1" colspan="1">LSTM</td>
              <td rowspan="1" colspan="1">bi-LSTM</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note</italic>: ‘+’ and ‘−’ denote the presence and absence of the layer type respectively. ‘(.)’ denotes the number of convolution layers if present. In the recurrent layers, if present, the type of RNN is specified.</p>
          </fn>
          <fn id="tblfn2">
            <label>a</label>
            <p>The dilated architecture consists of three convolution layers, one non-dilated followed by two dilated (dilation = 2) convolution layers.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>2.3 Model training, selection and evaluation</title>
      <p>Model selection is perhaps the most challenging step in deep learning as the performance of deep learning algorithms is very sensitive to the calibration parameters (<xref rid="btz339-B24" ref-type="bibr">Lipton and Steinhardt, 2018</xref>). A careful configuration and selection of the hyper-parameters is thus essential. For each dataset, we use automatic calibration that is based on randomly sampling 40 hyper-parameter settings from all possible combinations; each parameter setting is evaluated using its area under the ROC curve (AUC) in 3-fold cross-validation. Next, we use the selected best hyper-parameter setting to train five models using the full training data and choose the model with the best training performance as the final selected model. Multiple models are trained to avoid the effect of random initialization on model performance. This model selection strategy is based on the one used by the authors of DeepBind (<xref rid="btz339-B1" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>).</p>
      <p>In the training phase, we consider the number of learning steps as a hyper-parameter. For each of the 40 calibration sets, we train a model for a maximum of 40 000 learning steps and test it on the held out validation set every 5000 learning steps. The iteration with the best validation accuracy is picked as the number learning steps. The number of filters in the first convolutional layer is chosen as part of model selection; the number of filters in each subsequent layer is increased by 50% compared to the layer before it. Some model parameters were chosen on the basis of preliminary experiments that demonstrated consistent behavior across datasets (e.g. embedding <italic>k</italic>-mer length and embedding stride); complete details of the hyper-parameter space are summarized in <xref rid="btz339-T2" ref-type="table">Table 2</xref>.</p>
      <table-wrap id="btz339-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p><monospace>deepRAM</monospace> hyper-parameters, search space and sampling method</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Calibration parameters</th>
              <th align="left" rowspan="1" colspan="1">Search space</th>
              <th align="left" rowspan="1" colspan="1">Sampling</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Embedding dimensionality</td>
              <td rowspan="1" colspan="1">50</td>
              <td rowspan="1" colspan="1">Fixed</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Embedding <italic>k</italic>-mer length</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">Fixed</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Embedding stride</td>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">Fixed</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Motif length</td>
              <td rowspan="1" colspan="1">{10, 24}<xref ref-type="table-fn" rid="tblfn4"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">Fixed</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Number of filters</td>
              <td rowspan="1" colspan="1">{16, 32}</td>
              <td rowspan="1" colspan="1">Uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pooling window size</td>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">Fixed</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pooling stride</td>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">Fixed</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RNN hidden size</td>
              <td rowspan="1" colspan="1">{20, 50, 80, 100}</td>
              <td rowspan="1" colspan="1">Uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Dense layer size</td>
              <td rowspan="1" colspan="1">{None, 32 units, 64 units}</td>
              <td rowspan="1" colspan="1">Uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Optimizer</td>
              <td rowspan="1" colspan="1">{SGD, Adagrad}</td>
              <td rowspan="1" colspan="1">Uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Learning rate</td>
              <td rowspan="1" colspan="1">[1e-3, 1e-1]</td>
              <td rowspan="1" colspan="1">Log uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Momentum (SGD)</td>
              <td rowspan="1" colspan="1">[0.95, 0.99]</td>
              <td rowspan="1" colspan="1">Sqrt uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Number of learning steps</td>
              <td rowspan="1" colspan="1">[5000:40 000]<xref ref-type="table-fn" rid="tblfn5"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">Evaluate all</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Weight initialization</td>
              <td rowspan="1" colspan="1">{Xavier, normal}</td>
              <td rowspan="1" colspan="1">Uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CNN initial weight std</td>
              <td rowspan="1" colspan="1">[1e-6, 1e-1]</td>
              <td rowspan="1" colspan="1">Log uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">RNN initial weight std</td>
              <td rowspan="1" colspan="1">[1e-6, 1e-1]</td>
              <td rowspan="1" colspan="1">Log uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Fully connected initial weight std</td>
              <td rowspan="1" colspan="1">[1e-5, 1e-1]</td>
              <td rowspan="1" colspan="1">Log uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Weight decay</td>
              <td rowspan="1" colspan="1">[1e-10, 1e-1]</td>
              <td rowspan="1" colspan="1">Log uniform</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Dropout expectation</td>
              <td rowspan="1" colspan="1">{0.4, 0.55, 0.7, 0.85, 1}</td>
              <td rowspan="1" colspan="1">Uniform</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic>Note</italic>: ‘initial weight std’ refers to the SD of the distribution used to choose the weights.</p>
          </fn>
          <fn id="tblfn4">
            <label>a</label>
            <p>Ten with <italic>k</italic>-mer embedding. 24 with one-hot encoding.</p>
          </fn>
          <fn id="tblfn5">
            <label>b</label>
            <p>Step = 5000.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p><italic>Model training</italic>. To train a given model, we minimize the cross-entropy objective function. This is performed by stochastic gradient descent (SGD) or Adagrad, and the choice is made as part of the model selection process. Examples were processed using a batch size of 128 in all experiments. We used multiple regularization schemes including dropout (applied to max-pooling layers/RNN layers/hidden layers), weight decay and early stopping.</p>
      <p>We ran our experiments on an Ubuntu server with a TITAN X GPU with 12 GB of memory. Typical running times of each experiment for model selection was between 1 h for a single layer CNN and almost 4 h for a network that includes convolutional and bi-LSTM modules (see details in <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S3</xref>).</p>
    </sec>
    <sec>
      <title>2.4 Motif extraction</title>
      <p>In order to make models implemented using <monospace>deepRAM</monospace> easily interpretable, we extract motifs from the first convolutional layer following a similar methodology as in DeepBind (<xref rid="btz339-B1" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>). To do so, we feed all test sequences through the convolution stage. For each filter, we extract all sequence fragments that activate the filter and use only activations that are greater than half of the filter’s maximum value. Once all the sequence fragments are extracted, they are stacked and the nucleotide frequencies are counted to form a position frequency matrix (PFM). Sequence logos are then constructed using WebLogo (<xref rid="btz339-B9" ref-type="bibr">Crooks <italic>et al.</italic>, 2004</xref>). Finally, the discovered motifs are aligned using TOMTOM (<xref rid="btz339-B14" ref-type="bibr">Gupta <italic>et al.</italic>, 2007</xref>) against known motifs from CISBP-RNA (<xref rid="btz339-B32" ref-type="bibr">Ray <italic>et al.</italic>, 2013</xref>) for RBPs and JASPAR (<xref rid="btz339-B26" ref-type="bibr">Mathelier <italic>et al.</italic>, 2014</xref>) for transcription factors.</p>
    </sec>
    <sec>
      <title>2.5 <monospace>deepRAM</monospace></title>
      <p><monospace>deepRAM</monospace> is an end-to-end deep learning toolkit for predicting protein binding sites and motifs. It is designed to help users run experiments using a variety of architectures and implements the fully automatic model selection strategy described above. This helps avoid the need for hand-tuning and thus removes, making it user friendly without losing its flexibility. While it was designed with ChIP-seq and CLIP-seq data in mind, it can be used for any DNA/RNA sequence binary classification problem.</p>
      <p><monospace>deepRAM</monospace> allows users the flexibility to choose a deep learning model by selecting its different components: input sequence representation (one-hot or <italic>k</italic>-mer embedding), whether to use a CNN and how many layers, and whether to use an RNN, and the number of layers and their type. For CNNs the user can choose to use dilated convolution as well. Once the model is trained, the learned motifs of the first convolutional layer are automatically extracted and visualized using WebLogo, and then matched with known motifs using TOMTOM.</p>
      <p>We implemented <monospace>deepRAM</monospace> using PyTorch 1.0 (<ext-link ext-link-type="uri" xlink:href="http://pytorch.org/">http://pytorch.org/</ext-link>), which supports GPU acceleration. Our implementation has been packaged to make it runnable on any Unix-based system, and is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/MedChaabane/deepRAM">https://github.com/MedChaabane/deepRAM</ext-link>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Deeper is better</title>
      <p>We evaluated and compared the performance of the models introduced in Section 2.2 on the two tasks of predicting DNA- and RNA- protein binding sites (see <xref ref-type="fig" rid="btz339-F2">Fig. 2</xref>). Overall, all models performed well with median AUCs &gt;0.90 on ChIP-seq data and &gt;0.91 on CLIP-seq data. The proposed ECBLSTM model (Embedding, Convolution, bi-LSTM) provided the most significant improvement over DeepBind with a median AUC of 0.930 compared with 0.902 for DeepBind on ChIP-seq data, and with a more pronounced gap for CLIP-seq data: 0.951 for ECBLSTM versus 0.914 for DeepBind. All the performance differences described here are statistically significant except when noted explicitly (see <xref ref-type="fig" rid="btz339-F2">Fig. 2</xref>). Detailed accuracy values for individual datasets are provided in <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S1 and S2</xref>.
</p>
      <fig id="btz339-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>(<bold>A</bold>) The distribution of AUCs across 83 ChIP-seq datasets. (<bold>B</bold>) Heatmap annotated with <italic>P</italic>-values of pairwise model comparison using the Wilcoxon signed-rank test for ChIP-seq datasets. (<bold>C</bold>) The distribution of AUCs across 31 datasets for predicting RBP binding sites. (<bold>D</bold>) Heatmap annotated with <italic>P</italic>-values of pairwise model comparison using the Wilcoxon signed-rank test for predicting RBP binding sites. In subfigures (A) and (C), the triangle represents the average AUC for the respective model, the annotated vertical line represents the median AUC whose value is indicated. The models are sorted by their average AUC values. In subfigures (B) and (D), the color red or blue at position (<italic>i</italic>, <italic>j</italic>) in the heatmap indicates which model has a high average AUC, and its intensity indicates the magnitude of the difference</p>
        </caption>
        <graphic xlink:href="btz339f2"/>
      </fig>
      <p>DeepBind is the simplest model considered here: it uses one-hot sequence encoding, and a single convolutional layer. The results shown in <xref ref-type="fig" rid="btz339-F2">Figure 2</xref> demonstrate that adding multiple convolutional layers, dilated convolution and sequence embedding all provide improved performance over the original DeepBind. The addition of a recurrent module provides further improvement as seen by comparing the performance of ECBLSTM to a model called DeepBind-E* which has multiple convolutional layers and an embedding stage. This shows that adding recurrent connections to capture long-term dependencies between motifs detected by the convolutional layer leads to improved performance. The performance advantage of RNNs is further highlighted by comparing the performance of DanQ where the additional bidirectional LSTM layer has helped improve its performance over DeepBind.</p>
      <p>Our results demonstrate the performance advantage of deeper more complex networks. This is in contrast to <xref rid="btz339-B41" ref-type="bibr">Zeng <italic>et al.</italic> (2016</xref>) whose findings suggested that simpler models performed best in this task. Furthermore, the finding that more complex networks performed better demonstrates the effectiveness of our model tuning strategy.</p>
      <p>We note that iDeepS which is specifically designed for RNA-binding and uses a CNN over sequence and local secondary structure in combination with an LSTM module, achieved a median AUC of 0.917 for the CLIP-seq data, which is less than all the evaluated methods except DeepBind (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S7</xref> and <xref ref-type="supplementary-material" rid="sup1">Table S4</xref>). All the deep learning methods performed better than iONMF which uses multiple sources of data, including <italic>k</italic>-mer frequency, secondary structure and GO annotations (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S4</xref>). Finally, we also note that in both tasks, our implementation of DeepBind achieved nearly identical performance to the original DeepBind implementation (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S3</xref>).</p>
    </sec>
    <sec>
      <title>3.2 <italic>k</italic>-mer embedding boosts model performance</title>
      <p>We observe that using <italic>k</italic>-mer embedding to represent input sequences rather than one-hot encoding improves model performance, and more so for the RBP binding datasets. For example, among models with the same architecture, we see that ECBLSTM outperforms DanQ in both tasks (see <xref ref-type="fig" rid="btz339-F2">Fig. 2</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S2 and S3</xref>). We also observe that in the task of RNA-protein binding site prediction, all models that use embedding representation have median AUC higher than 0.94 while all models that use one-hot encoding have median AUC lower than 0.935 (<xref ref-type="fig" rid="btz339-F2">Fig. 2C</xref>). These results suggest that one-hot encoding is not the optimal strategy for representation of DNA and RNA sequences. In contrast, <italic>k</italic>-mer embedding provides contextual information by learning the statistical information of <italic>k</italic>-mer co-occurrence relationships in the input sequences.</p>
      <p>In this work, we train the <italic>k</italic>-mer embedding algorithm for each dataset with <italic>k </italic>=<italic> </italic>3 and stride <italic>s </italic>=<italic> </italic>1. Other studies (<xref rid="btz339-B29" ref-type="bibr">Min <italic>et al.</italic>, 2017</xref>; <xref rid="btz339-B34" ref-type="bibr">Shen <italic>et al.</italic>, 2018</xref>) have shown that using different values of <italic>k</italic>-mer length (values in the range of 4–7) does not have considerable effect on model performance. In preliminary experiments, we have evaluated model performance by varying the <italic>k</italic>-mer length from 3 to 7 and found that <italic>k </italic>=<italic> </italic>3 provided the best performance. In agreement with other studies, we found that model performance increases with decreasing stride values, and found that using stride value equal to 1 led to the best performance.</p>
    </sec>
    <sec>
      <title>3.3 Deeper is better with sufficient training data</title>
      <p>Based on the results shown in <xref ref-type="fig" rid="btz339-F2">Figure 2</xref>, one may conclude that relatively complex models tend to perform better than simpler models. However, this statement is based on the evaluation of the overall performance across all experiments and do not take into consideration the effect of the number of training examples. To study this aspect, we divided the ENCODE ChIP-seq datasets into two groups according to the number of training examples. The first group consists of 38 datasets with &lt;10 000 positive training samples, and the second group consists of 45 datasets with more than 10 000 positive training samples. We compare the performance of different models in these two groups and report the results in <xref ref-type="fig" rid="btz339-F3">Figure 3</xref>. We observe considerably higher AUCs for the large datasets with median AUCs between 0.967 (DeepBind) and 0.993 (ECBLSTM) compared to median AUCs between 0.864 (DeepBind) and 0.879 (DeepBind-E*) for the small datasets. It is also worth noting that the effect of the number of training examples is more pronounced with hybrid models (see <xref ref-type="fig" rid="btz339-F3">Fig. 3</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S4</xref>). Indeed, ECBLSTM, ECLSTM and DanQ* tend to perform very strongly for large datasets (median AUCs above 0.983) while interestingly, they fell behind DeepBind-E* when used on smaller datasets. This suggests the need for sufficient training data for hybrid models. Complex models such as ECBLSTM still perform well even for the smaller datasets, demonstrating that our regularization procedure was effective in preventing over-fitting.
</p>
      <fig id="btz339-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>(<bold>A</bold>) The distribution of AUCs in predicting DNA-protein binding sites across 38 ChIP-seq experiments with &lt;10 000 peaks. (<bold>B</bold>) The distribution of AUCs in predicting DNA-protein binding sites across 45 ChIP-seq experiments with more than 10 000 peaks. Figure notation follows the description in <xref ref-type="fig" rid="btz339-F2">Figure 2</xref></p>
        </caption>
        <graphic xlink:href="btz339f3"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Dilated convolution</title>
      <p>Dilated convolution uses filters with gaps to allow each filter to capture information across larger and larger stretches of the input sequence (<xref rid="btz339-B40" ref-type="bibr">Yu and Koltun, 2015</xref>). Hence, dilated convolution finds usage in applications that benefit from modeling of a wider context without incurring the increased cost of using RNNs (<xref rid="btz339-B13" ref-type="bibr">Gupta and Rush, 2017</xref>; <xref rid="btz339-B20" ref-type="bibr">Kelley <italic>et al.</italic>, 2018</xref>; <xref rid="btz339-B38" ref-type="bibr">Strubell <italic>et al.</italic>, 2017</xref>).</p>
      <p>In this work, we evaluate a dilated model which consists of three convolutional modules with dilation parameters equal to 1, 2 and 2 in the first, second and third layers, respectively. We find that the dilated convolutional model outperforms DeepBind* with significant <italic>P</italic>-values in both tasks (<xref ref-type="fig" rid="btz339-F2">Fig. 2</xref>). In addition, the dilated convolutional model had slightly higher median AUC than DanQ in the RBP binding sites datasets, which suggests that dilated convolution can capture long-range relationships similarly to LSTMs. These findings suggest that dilated convolution is a valuable architecture parameter to consider. This is likely to be even more pronounced for longer sequences such as those modeled using the Basenji method for example (<xref rid="btz339-B20" ref-type="bibr">Kelley <italic>et al.</italic>, 2018</xref>).</p>
    </sec>
    <sec>
      <title>3.5 GRU or LSTM?</title>
      <p>The results shown so far do not allow a direct comparison of GRU and LSTM units. To make that comparison we performed experiments on two additional architectures: (i) CNN layer followed by bidirectional GRU, using sequence embedding as input and (ii) a single bidirectional LSTM layer using sequence embedding as input. The first architecture is directly comparable to the ECBLSTM architecture, while the second is directly comparable to KEGRU. In both cases we observed negligible difference between the corresponding architectures (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S5 and S6</xref>).</p>
    </sec>
    <sec>
      <title>3.6 Cross-assay performance</title>
      <p>Binding assays, and especially <italic>in-vivo</italic> assays like ChIP-seq, have assay-specific biases (<xref rid="btz339-B6" ref-type="bibr">Chen <italic>et al.</italic>, 2012</xref>). To test whether complex models are more affected by those biases, we identified three transcription factors in the ChIP-seq collection for which SELEX data are available (MAX, RFX5 and YY1). We then compared the performance of models trained and tested on ChIP-seq data with the performance of models trained on SELEX and tested on ChIP-seq data. In all cases cross-assay performance was lower as expected, and the more complex model (ECBLSTM) performed better than the simplest model (DeepBind), in addition having better same-assay performance (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S5</xref>). This result provides support for the merit of complex deep learning models and demonstrates their ability to learn biologically relevant features.</p>
    </sec>
    <sec>
      <title>3.7 Model interpretation and visualization</title>
      <p>To explore the ability of selected architectures to capture informative motifs, we chose a random sample of ChIP-seq experiments and extracted motifs from the first convolutional layer as described in Section 2.4. As shown in <xref ref-type="fig" rid="btz339-F4">Figure 4A</xref>, DeepBind and DeepBind-E* are able to detect informative motifs that match well with known motifs from the JASPAR database. However, ECBLSTM turns out to perform poorly in detecting motifs compared to the two other models and most of its detected motifs are not informative despite the fact that it is the best performing model among all the models we compared. We hypothesize that when combined with RNNs, the CNN filters learn information that is geared toward providing the subsequent recurrent layer with the information it needs, which is of a different nature than the localized information learned by CNN-only models.
</p>
      <fig id="btz339-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>(<bold>A</bold>) Examples of motifs detected by first layer convolutional modules learned by DeepBind, DeepBind-E* and ECBLSTM for predicting DNA binding sites of CTCF, SRF and FOS. <italic>E</italic>-values are displayed below each motif only if it matches with the known motifs for the same Transcription Factor. Known motifs from the JASPAR database are displayed at the top. (<bold>B</bold>) Histograms of the counts of convolutional filter activations that are considered for extracting motifs along the sequences for models of CTCF, SRF and FOS binding using DeepBind and ECBLSTM</p>
        </caption>
        <graphic xlink:href="btz339f4"/>
      </fig>
      <p>To further investigate the difference between the behavior of hybrid models and CNN-only models, we explored the distribution of sequence fragments with positive activation values for a given filter with DeepBind and ECBLSTM in the positive and negative examples (<xref ref-type="fig" rid="btz339-F4">Fig. 4B</xref>). As expected, the number of activated sequence fragments in positive sequences is much higher than in negative sequences in both methods. In addition, we observe that the activated sequence fragments in positive sequences using DeepBind are concentrated in the middle of the sequence, and are uniformly distributed for negative examples. This phenomenon was not observed in the CLIP-seq data, where activated sequence fragments were uniformly distributed for both positive and negative examples. However, using ECBLSTM the activated sequence fragments are distributed uniformly across the sequence for both positive and negative sequences. Noting that the centers of positive sequences correspond to the reported ChIP-seq peaks, we conclude that DeepBind is detecting sequence motifs that represent the binding event while ECBLSTM’s convolution stage is extracting features that span the whole sequence. This is in agreement with our finding that RNNs lead to a representation which has reduced interpretability compared to that of CNNs.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>In this work, we performed an in-depth analysis and evaluation of the performance of commonly used deep learning architectures for DNA and RNA-binding site prediction. This study was aimed at providing a better understanding of the performance characteristics and advantages of different architectures to help users choose the right architecture for their work. Our experiments demonstrated the accuracy of hybrid CNN/RNN models; however, that requires the availability of sufficient training data, and these networks are harder to interpret and hence their usefulness in motif discovery might be limited. We have made the software used in our experiments available as an easy to use tool to evaluate and analyze various deep learning architectures for DNA/RNA-binding prediction in a user friendly package called <monospace>deepRAM</monospace>. We hope this work will stimulate further studies on visualizing and understanding deep models and enhance their usefulness for analyzing biological sequence data.</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz339_Supplementary_Data</label>
      <media xlink:href="btz339_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz339-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alipanahi</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source>Nat. Biotechnol</source>., <volume>33</volume>, <fpage>831</fpage>–<lpage>838</lpage>.<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Angermueller</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Deep learning for computational biology</article-title>. <source>Mol. Syst. Biol</source>., <volume>12</volume>, <fpage>878.</fpage><pub-id pub-id-type="pmid">27474269</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Asgari</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Mofrad</surname><given-names>M.R.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Continuous distributed representation of biological sequences for deep proteomics and genomics</article-title>. <source>PLoS One</source>, <volume>10</volume>, <fpage>e0141287.</fpage><pub-id pub-id-type="pmid">26555596</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bengio</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>1994</year>) 
<article-title>Learning long-term dependencies with gradient descent is difficult</article-title>. <source>IEEE Trans. Neural Netw</source>., <volume>5</volume>, <fpage>157</fpage>–<lpage>166</lpage>.<pub-id pub-id-type="pmid">18267787</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Blin</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>DoRiNA 2.0—upgrading the DoRiNA database of RNA interactions in post-transcriptional regulation</article-title>. <source>Nucleic Acids Res</source>., <volume>43</volume>, <fpage>D160</fpage>–<lpage>D167</lpage>.<pub-id pub-id-type="pmid">25416797</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Systematic evaluation of factors influencing ChIP-seq fidelity</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>609</fpage>–<lpage>614</lpage>.<pub-id pub-id-type="pmid">22522655</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Cho</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) On the properties of neural machine translation: encoder–decoder approaches. arXiv preprint, arXiv: 1409.1259.</mixed-citation>
    </ref>
    <ref id="btz339-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Chung</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint, arXiv: 1412.3555.</mixed-citation>
    </ref>
    <ref id="btz339-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Crooks</surname><given-names>G.E.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>WebLogo: a sequence logo generator</article-title>. <source>Genome Res</source>., <volume>14</volume>, <fpage>1188</fpage>–<lpage>1190</lpage>.<pub-id pub-id-type="pmid">15173120</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B10">
      <mixed-citation publication-type="journal">ENCODE-Project-Consortium (<year>2012</year>) 
<article-title>An integrated Encyclopedia of DNA elements in the human genome</article-title>. <source>Nature</source>, <volume>489</volume>, <fpage>57</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">22955616</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ferré</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Revealing protein-lncRNA interaction</article-title>. <source>Brief. Bioinform</source>., <volume>17</volume>, <fpage>106</fpage>–<lpage>116</lpage>.<pub-id pub-id-type="pmid">26041786</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gerstberger</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>A census of human RNA-binding proteins</article-title>. <source>Nat. Rev. Genet</source>., <volume>15</volume>, <fpage>829</fpage>–<lpage>845</lpage>.<pub-id pub-id-type="pmid">25365966</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Gupta</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Rush</surname><given-names>A.M.</given-names></name></person-group> (<year>2017</year>) Dilated convolutions for modeling long-distance genomic dependencies. arXiv preprint, arXiv: 1710.01278.</mixed-citation>
    </ref>
    <ref id="btz339-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gupta</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Quantifying similarity between motifs</article-title>. <source>Genome Biol</source>., <volume>8</volume>, <fpage>R24</fpage>.<pub-id pub-id-type="pmid">17324271</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B15">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Hassanzadeh</surname><given-names>H.R.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>M.D.</given-names></name></person-group> (<year>2016</year>) <chapter-title>DeeperBind: enhancing prediction of sequence specificities of DNA binding proteins</chapter-title> In: <source>2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), Shenzhen, China</source>. 
<publisher-name>IEEE</publisher-name>, pp. <fpage>178</fpage>–<lpage>183</lpage>.</mixed-citation>
    </ref>
    <ref id="btz339-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hinton</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups</article-title>. <source>IEEE Signal Process. Mag</source>., <volume>29</volume>, <fpage>82</fpage>–<lpage>97</lpage>.</mixed-citation>
    </ref>
    <ref id="btz339-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hirschberg</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Manning</surname><given-names>C.D.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Advances in natural language processing</article-title>. <source>Science</source>, <volume>349</volume>, <fpage>261</fpage>–<lpage>266</lpage>.<pub-id pub-id-type="pmid">26185244</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hochreiter</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group> (<year>1997</year>) 
<article-title>Long short-term memory</article-title>. <source>Neural Comput</source>., <volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kazan</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>RNAcontext: a new method for learning the sequence and structure binding preferences of RNA-binding proteins</article-title>. <source>PLoS Comput. Biol</source>., <volume>6</volume>, <fpage>e1000832.</fpage><pub-id pub-id-type="pmid">20617199</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kelley</surname><given-names>D.R.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Sequential regulatory activity prediction across chromosomes with convolutional neural networks</article-title>. <source>Genome Res</source>., <volume>28</volume>, <fpage>739</fpage>–<lpage>750</lpage>.<pub-id pub-id-type="pmid">29588361</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Krizhevsky</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>ImageNet classification with deep convolutional neural networks</article-title>. In: <source>Advances in neural information processing systems</source>, Lake Tahoe, USA, pp. <fpage>1097</fpage>–<lpage>1105</lpage>.</mixed-citation>
    </ref>
    <ref id="btz339-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>1998</year>) 
<article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proc. IEEE</source>, <volume>86</volume>, <fpage>2278</fpage>–<lpage>2324</lpage>.</mixed-citation>
    </ref>
    <ref id="btz339-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Deep learning</article-title>. <source>Nature</source>, <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B24">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Lipton</surname><given-names>Z.C.</given-names></name>, <name name-style="western"><surname>Steinhardt</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>) Troubling trends in machine learning scholarship. arXiv preprint, arXiv: 1807.03341.</mixed-citation>
    </ref>
    <ref id="btz339-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Maas</surname><given-names>A.L.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Rectifier nonlinearities improve neural network acoustic models</article-title>. In: <source>ICML Workshop on Deep Learning for Audio, Speech and Language Processing</source>. Atlanta Georgia.</mixed-citation>
    </ref>
    <ref id="btz339-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mathelier</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>JASPAR 2014: an extensively expanded and updated open-access database of transcription factor binding profiles</article-title>. <source>Nucleic Acids Res</source>., <volume>42</volume>, <fpage>D142</fpage>–<lpage>D147</lpage>.<pub-id pub-id-type="pmid">24194598</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B27">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Melis</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) On the state of the art of evaluation in neural language models. In: <italic>International Conference on Learning Representations (ICLR), Vancouver, Canada</italic>.</mixed-citation>
    </ref>
    <ref id="btz339-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mikolov</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Distributed representations of words and phrases and their compositionality</article-title>. <source>Adv. Neural Inf. Process. Syst</source>., <fpage>3111</fpage>–<lpage>3119</lpage>.</mixed-citation>
    </ref>
    <ref id="btz339-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Min</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Chromatin accessibility prediction via convolutional long short-term memory networks with <italic>k</italic>-mer embedding</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>i92</fpage>–<lpage>i101</lpage>.<pub-id pub-id-type="pmid">28881969</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pan</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks</article-title>. <source>BMC Genomics</source>, <volume>19</volume>, <fpage>511.</fpage><pub-id pub-id-type="pmid">29970003</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Quang</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>X.</given-names></name></person-group> (<year>2016</year>) 
<article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>e107</fpage>.<pub-id pub-id-type="pmid">27084946</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ray</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>A compendium of RNA-binding motifs for decoding gene regulation</article-title>. <source>Nature</source>, <volume>499</volume>, <fpage>172</fpage>–<lpage>177</lpage>.<pub-id pub-id-type="pmid">23846655</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rohs</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Origins of specificity in protein-DNA recognition</article-title>. <source>Annu. Rev. Biochem</source>., <volume>79</volume>, <fpage>233</fpage>–<lpage>269</lpage>.<pub-id pub-id-type="pmid">20334529</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Recurrent neural network for predicting transcription factor binding sites</article-title>. <source>Sci. Rep</source>., <volume>8</volume>, <fpage>15270.</fpage><pub-id pub-id-type="pmid">30323198</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Siggers</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Gordân</surname><given-names>R.</given-names></name></person-group> (<year>2014</year>) 
<article-title>Protein-DNA binding: complexities and multi-protein codes</article-title>. <source>Nucleic Acids Res</source>., <volume>42</volume>, <fpage>2099</fpage>–<lpage>2111</lpage>.<pub-id pub-id-type="pmid">24243859</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stormo</surname><given-names>G.D.</given-names></name></person-group> (<year>2000</year>) 
<article-title>DNA binding sites: representation and discovery</article-title>. <source>Bioinformatics</source>, <volume>16</volume>, <fpage>16</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">10812473</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stražar</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Orthogonal matrix factorization enables integrative analysis of multiple RNA binding proteins</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>1527</fpage>–<lpage>1535</lpage>.<pub-id pub-id-type="pmid">26787667</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Strubell</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) Fast and accurate sequence labeling with iterated dilated convolutions. arXiv preprint, arXiv: 1702.02098.</mixed-citation>
    </ref>
    <ref id="btz339-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sutskever</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Sequence to sequence learning with neural networks</article-title>. <source>Adv. Neural Inf. Process. Syst</source>., <fpage>3104</fpage>–<lpage>3112</lpage>.</mixed-citation>
    </ref>
    <ref id="btz339-B40">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Koltun</surname><given-names>V.</given-names></name></person-group> (<year>2015</year>) Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv: 1511.07122.</mixed-citation>
    </ref>
    <ref id="btz339-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeng</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Convolutional neural network architectures for predicting DNA-protein binding</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>i121</fpage>–<lpage>i127</lpage>.<pub-id pub-id-type="pmid">27307608</pub-id></mixed-citation>
    </ref>
    <ref id="btz339-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Troyanskaya</surname><given-names>O.G.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Predicting effects of noncoding variants with deep learning-based sequence model</article-title>. <source>Nat. Methods</source>, <volume>12</volume>, <fpage>931</fpage>–<lpage>934</lpage>.<pub-id pub-id-type="pmid">26301843</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
