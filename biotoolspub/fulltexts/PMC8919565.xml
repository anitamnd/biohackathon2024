<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8919565</article-id>
    <article-id pub-id-type="publisher-id">4626</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-04626-w</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EnsembleFam: towards more accurate protein family prediction in the twilight zone</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Kabir</surname>
          <given-names>Mohammad Neamul</given-names>
        </name>
        <address>
          <email>neamul@u.nus.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wong</surname>
          <given-names>Limsoon</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.4280.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2180 6431</institution-id><institution>Department of Computer Science, </institution><institution>National University of Singapore, </institution></institution-wrap>13 Computing Drive, 117417 Singapore, Singapore </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>14</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>14</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>90</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>2</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Current protein family modeling methods like profile Hidden Markov Model (pHMM), <italic>k</italic>-mer based methods, and deep learning-based methods do not provide very accurate protein function prediction for proteins in the twilight zone, due to low sequence similarity to reference proteins with known functions.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We present a novel method EnsembleFam, aiming at better function prediction for proteins in the twilight zone. EnsembleFam extracts the core characteristics of a protein family using similarity and dissimilarity features calculated from sequence homology relations. EnsembleFam trains three separate Support Vector Machine (SVM) classifiers for each family using these features, and an ensemble prediction is made to classify novel proteins into these families. Extensive experiments are conducted using the Clusters of Orthologous Groups (COG) dataset and G Protein-Coupled Receptor (GPCR) dataset. EnsembleFam not only outperforms state-of-the-art methods on the overall dataset but also provides a much more accurate prediction for twilight zone proteins.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">EnsembleFam, a machine learning method to model protein families, can be used to better identify members with very low sequence homology. Using EnsembleFam protein functions can be predicted  using just sequence information with better accuracy than state-of-the-art methods.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Protein function prediction</kwd>
      <kwd>Twilight zone sequence</kwd>
      <kwd>Sequence homology</kwd>
      <kwd>Support vector machine</kwd>
      <kwd>Ensemble classifier</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par4">As next-generation sequencing technologies are becoming more affordable and faster, millions of protein sequences are derived within a very short time [<xref ref-type="bibr" rid="CR1">1</xref>]. Although biological and molecular experiments are the gold standard for annotating proteins with their functions, these experiments are low throughput and also resource-demanding [<xref ref-type="bibr" rid="CR2">2</xref>]. Thus, experimentally verified functional annotation of proteins is far behind the number of sequenced proteins.</p>
    <p id="Par5">Many computational approaches have been developed to annotate proteins. These approaches try to infer the function of an unknown protein by comparing it with reference proteins having known functions. Two protein sequences can easily be compared using local sequence alignment, but the task becomes difficult when the sequences are distantly related. To solve this problem, protein sequences with similar biomolecular functions are put together in a family, so that their shared features can be computationally more easily identified and modeled. Most of the computational methods perform well for proteins that have moderate to high similarity with reference proteins of known function. However, these methods do not perform well for the so-called twilight-zone proteins [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>], which are remote homologs with low sequence similarity to reference proteins of known function. Even though this difficulty was identified more than two decades ago, recent approaches still cannot produce good enough results comparable to that of high-similarity proteins. For example, INGA [<xref ref-type="bibr" rid="CR5">5</xref>], a protein function prediction tool, works only with sequences having <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$40\%$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mn>40</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq1.gif"/></alternatives></inline-formula> sequence identity or more; HHSearch [<xref ref-type="bibr" rid="CR6">6</xref>] and LOMETS [<xref ref-type="bibr" rid="CR7">7</xref>] both experimented against twilight zone sequences (identity <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt;20\%$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>20</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq2.gif"/></alternatives></inline-formula> for HHSerach and identity <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt;25\%$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>25</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq3.gif"/></alternatives></inline-formula> for LOMETS) to analyze performance, but the performance reported by both methods is still a lot poorer compared to higher similarity region; QAUST [<xref ref-type="bibr" rid="CR8">8</xref>] tried to address this problem using multiple information sources; etc. This implies that predicting function for twilight zone protein is still a difficult computational problem.</p>
    <p id="Par6">Current protein family modeling methods can be roughly divided into three categories: sequence homology-based methods, alignment-free methods, and machine learning-based methods. These are briefly described below.</p>
    <sec id="Sec2">
      <title>Sequence homology-based methods</title>
      <p id="Par7">Protein sequence homology is the sequence similarity due to ancestry between proteins. While protein sequences may change in the course of evolution, the homologous segments (i.e. the segments conserved by evolution) are responsible for bio-molecular function with some exceptions (i.e. in some cases homologous segments may be responsible for different function) [<xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR11">11</xref>]. Many methods have been developed for detecting sequence similarity. The Smith–Waterman algorithm [<xref ref-type="bibr" rid="CR12">12</xref>] based on dynamic programming is one of the earliest and more fundamental methods. When used with an affine gap penalty, this algorithm has cubic time complexity with respect to sequence length and thus is inefficient for comparing a query protein sequence to a large database of reference sequences. So methods such as BLAST [<xref ref-type="bibr" rid="CR13">13</xref>] use heuristics to selectively compare a test protein sequence to only a subset of reference sequences in the database, where the subset consists of reference sequences having a sufficient number of exact short substring matches to the test sequence. Although pairwise sequence alignment provides valuable information, it is still a difficult task to accurately predict protein functions from these alignments. Hence, approaches that model an entire protein family based on multiple sequence alignment of the family were introduced. The pHMM (profile Hidden Markov Model) [<xref ref-type="bibr" rid="CR14">14</xref>] is a very successful example of these, and the popular protein family database Pfam [<xref ref-type="bibr" rid="CR15">15</xref>] uses pHMM to model the families. Other methods based on sequence alignment information include GOtcha [<xref ref-type="bibr" rid="CR16">16</xref>] which uses term-specific probabilities to predict proteins from sequence alignment, GOblet [<xref ref-type="bibr" rid="CR17">17</xref>] which provides different databases to choose and align sequences with a user-specified threshold to annotate unknown sequence, and OntoBlast [<xref ref-type="bibr" rid="CR18">18</xref>] which provides a weighted list of sequences of a similar function using BLAST search.</p>
    </sec>
    <sec id="Sec3">
      <title>Alignment-free methods</title>
      <p id="Par8">Researchers have also developed alignment-free methods to annotate protein sequences. One of the approaches is to use word frequency of amino acids in the sequences as features to model the families [<xref ref-type="bibr" rid="CR19">19</xref>]. Another strategy that uses oligomer distances as features along with remote homology detection, shows better performance than some alignment-based methods [<xref ref-type="bibr" rid="CR20">20</xref>]. There are also many methods that use additional information, such as protein-protein interaction data, to annotate proteins [<xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR23">23</xref>].</p>
    </sec>
    <sec id="Sec4">
      <title>Machine learning-based method</title>
      <p id="Par9">Predicting protein function only from protein sequences, without using any other type of information is challenging. Many machine learning-based methods have been developed in this regard. One such example is SVM-Prot [<xref ref-type="bibr" rid="CR24">24</xref>], where structural and residue properties such as amino acid decomposition, hydrophobicity, polarity, etc. of a protein constitute the feature vector to train an SVM classifier. A more interesting example is SVM-Fisher [<xref ref-type="bibr" rid="CR25">25</xref>] which couples an iterative profile HMM training scheme to an SVM, where the vector of profile HMM gradients of a protein is used as the feature vector for training the SVM. A refinement of this, with much better performance, is SVM-pairwise [<xref ref-type="bibr" rid="CR26">26</xref>], where given a reference set of protein sequences, the vector of pairwise sequence similarity scores of a protein to each of the reference proteins is instead used as the feature vector for training SVM classifiers for each protein family. Besides SVM, <italic>k</italic>-nearest neighbour (e.g. MS-kNN [<xref ref-type="bibr" rid="CR27">27</xref>]), gradient tree boosting (e.g. PredSAV [<xref ref-type="bibr" rid="CR28">28</xref>]) and other machine learning methods have also been used. Another popular method, CATH FunFam [<xref ref-type="bibr" rid="CR29">29</xref>], uses structure and sequence information to predict function domains. Along with these, the Continuous Assessment of Functional Annotation (CAFA) [<xref ref-type="bibr" rid="CR30">30</xref>] competition also introduces many different function prediction methods to predict Gene Ontology [<xref ref-type="bibr" rid="CR31">31</xref>] terms. Most of the top methods in the competition are based on machine-learning and show great performance. A few examples of top methods from CAFA [<xref ref-type="bibr" rid="CR30">30</xref>] are GOLabeler [<xref ref-type="bibr" rid="CR32">32</xref>], PANNZER [<xref ref-type="bibr" rid="CR33">33</xref>], INGA [<xref ref-type="bibr" rid="CR5">5</xref>], FunFam [<xref ref-type="bibr" rid="CR34">34</xref>], etc.</p>
      <p id="Par10">More recently, deep learning methods have been used for protein function prediction. An example is ProLanGO [<xref ref-type="bibr" rid="CR35">35</xref>], which treats protein function prediction as a language translation problem, where a protein is mapped to a sequence of words in a “protein language” ProLan, and then translated to a “protein function language” GOLan using three layers of specially trained recurrent neural networks (RNNs). UDSMProt [<xref ref-type="bibr" rid="CR36">36</xref>] is another recent method, which uses similar language modeling task with a pre-trained RNN model, and can be applied for enzyme class prediction, gene ontology prediction and fold detection from unlabeled protein sequence. An example which appears to have a much more impressive performance in protein family prediction is DeepFam [<xref ref-type="bibr" rid="CR37">37</xref>], which uses a convolutional neural network (CNN) to extract high-level features from amino acid sequence.</p>
    </sec>
    <sec id="Sec5">
      <title>Limitations of the current approaches</title>
      <p id="Par11">Sequence homology-based methods suffered from two shortcomings. The first is that sequence alignment is too inefficient for comparing a query protein sequence to a large database of reference sequences. The second is that, when heuristics are used to select a small subset of the database, as in BLAST, there is a large reduction in sensitivity, as test sequences that are remote homologs to reference sequences in that database often do not have sufficient numbers of exact short matches to these reference sequences.</p>
      <p id="Par12">Alignment-free methods also have their shortcomings. Firstly, these methods typically require exact matches of <italic>k</italic>-mers, but remote homologs may not have many of these; this affects sensitivity. Secondly, alignment-free methods do not take into account the order of <italic>k</italic>-mers in the protein sequences; this loses biological information and affects specificity. Thirdly, finding the optimal value of <italic>k</italic> for <italic>k</italic>-mer based methods is another challenge. In general, alignment-free methods do not perform as well as alignment-based methods.</p>
      <p id="Par13">Although machine learning-based methods provide good results, they have weaknesses. For example, in SVM-Pairwise, the size of the feature vector is the number of reference protein sequences, which is a very large number. This puts severe demand on memory size during training and for storing the models of each protein family. It is also time-consuming to generate the feature vector of a query sequence, which makes the prediction slower. Moreover, totally novel query sequences and query sequences that are very different in length from the reference sequences require special treatment. For DeepFam, which is a multi-class classifier, the number of classes is fixed and each query sequence must be assigned to one of these classes. If a query sequence is from a new family, DeepFam [<xref ref-type="bibr" rid="CR37">37</xref>] will wrongly force it to one of the trained classes. And in the case of ProLanGO [<xref ref-type="bibr" rid="CR35">35</xref>], the protein sequences are modeled using a machine translation model which is popularly used for natural languages. But protein sequences differ from a natural language in many aspects. Moreover, in general, deep learning models have a large number of parameters to fit. Protein families with fewer training sequences cannot be modeled well using deep learning.</p>
      <p id="Par14">Other than these methods, some methods use information from different sources and combine them to make a final prediction for protein functions. For example, QAUST [<xref ref-type="bibr" rid="CR8">8</xref>] uses structure similarity, protein-protein interaction, and sequence information to determine protein functions; INGA [<xref ref-type="bibr" rid="CR5">5</xref>] uses protein interaction networks, sequence similarity and domain assignments to make prediction; etc. Methods like GOLabeler [<xref ref-type="bibr" rid="CR32">32</xref>] works with comparatively lower similarity sequences (having sequence identity of <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&lt; 60\%$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>60</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq4.gif"/></alternatives></inline-formula>), which may include twilight zone proteins along with sequences having decent enough similarity. QAUST [<xref ref-type="bibr" rid="CR8">8</xref>] focuses on twilight zone proteins, but all the required information (such as PPI data) for this method may not be readily available for many query proteins, which can lead to a poor prediction outcome. Thus, a computational method that can improve prediction for twilight zone proteins with minimum information provided, should be sought.</p>
    </sec>
    <sec id="Sec6">
      <title>Our approach</title>
      <p id="Par15">We introduce here EnsembleFam, a protein family modeling approach inspired by SVM-Pairwise. In SVM-Pairwise, for every protein sequence, its pairwise similarity scores to every reference protein sequence are used to form its feature vector; this makes the feature vector huge and time-consuming to produce. EnsembleFam differs from SVM-Pairwise in two important ways. Firstly, instead of calculating pairwise similarity with all reference sequences, the similarity scores are calculated per protein family. Thus the size of the feature vector used by EnsembleFam is orders of magnitude smaller than that of SVM-Pairwise and is much more efficient to produce. Secondly, EnsembleFam trains multiple SVM models for each family and makes a final prediction by ensembling individual predictions. As a result, EnsembleFam is much more sensitive on twilight zone proteins, while being highly competitive on easier proteins. Lastly, especially when compared to other machine learning methods, EnsembleFam has means for distinguishing members of new unknown protein families from members of the reference protein families.</p>
    </sec>
  </sec>
  <sec id="Sec7">
    <title>Results</title>
    <sec id="Sec8">
      <title>Dataset</title>
      <p id="Par16">To assess the performance of EnsembleFam we used two datasets namely Clusters of Orthologous Groups of proteins (COG) dataset and G Protein-Coupled Receptor (GPCR) dataset. These two datasets are widely used and have different characteristics. Although the Pfam database [<xref ref-type="bibr" rid="CR15">15</xref>] is one of the most popular protein family databases, it was not adopted for this study due to its bias towards the protein Hidden Markov Model (pHMM).</p>
      <sec id="Sec9">
        <title>Clusters of orthologous groups of proteins dataset</title>
        <p id="Par17">COG is one of the most extensively used functional databases. We used the latest version of the database which is made public in 2014 [<xref ref-type="bibr" rid="CR38">38</xref>]. The protein family assignment in the COG database is done by pairwise sequence comparison in the whole-genome context. The functional annotation in this database should be reliable as the functional curation for clusters was done manually.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Detailed description of the three subsets of the COG database based on threshold number of members in each family</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Name</th><th align="left">Min no. of members</th><th align="left">No. of families</th><th align="left">No. of proteins</th></tr></thead><tbody><tr><td align="left">COG-500-1074</td><td align="left">500</td><td align="left">1074</td><td align="left">1,129,428</td></tr><tr><td align="left">COG-250-1796</td><td align="left">250</td><td align="left">1796</td><td align="left">1,389,595</td></tr><tr><td align="left">COG-100-2892</td><td align="left">100</td><td align="left">2892</td><td align="left">1,565,976</td></tr></tbody></table></table-wrap></p>
        <p id="Par18">In the COG database different family consists of a different number of proteins which varies over a very high range. As we compare our method with DeepFam [<xref ref-type="bibr" rid="CR37">37</xref>], we filtered the database in the same way so that it can be compared with DeepFam. For this, the sequences longer than 1000 amino acids were filtered away as DeepFam requires a fixed length for all proteins. EnsembleFam can work with a variable length of proteins without any restrictions. There are in total 4655 protein families with 1,674,176 proteins after removing the longer sequences. Furthermore, the database is divided into three different subsets based on the minimum number of sequences in one family. The three thresholds used for this filtration are 100, 250, and 500. Therefore, the three sub-databases are named as COG-500-1074, COG-250-1796, COG-100-2892. Here, COG-500-1074 indicates the COG database where each family has a minimum of 500 members and the number of families in this subset is 1074. The detailed description of these three subsets can be found in Table <xref rid="Tab1" ref-type="table">1</xref>. For each subset, we have used a 3-fold cross-validation to train and test the models.</p>
      </sec>
      <sec id="Sec10">
        <title>G protein-coupled receptor dataset</title>
        <p id="Par19">G protein-coupled receptor (GPCR) dataset is an important dataset for drug discovery as well as protein family classification. It provides a hierarchical classification with family, subfamily and sub-subfamily label for GPCR proteins. In this research, we used one of the biggest GPCR dataset, GDS [<xref ref-type="bibr" rid="CR39">39</xref>], which consists of 8, 222 protein sequences divided into 5 families, 38 sub-families and 86 sub-subfamilies.</p>
      </sec>
    </sec>
    <sec id="Sec11">
      <title>Performance evaluation on COG dataset</title>
      <p id="Par20">In this part, we compare EnsembleFam with pHMM and DeepFam on the predictions of COG proteins.<fig id="Fig1"><label>Fig. 1</label><caption><p>Homology between training and test set of COG dataset. The bars indicate the fraction of test data having identity less than or equal to the indicated value on the <italic>x</italic>-axis. For each fold of the dataset, the homology is calculated for test sequence against the training sequences and the seed sequences used to build pHMM feature models. For each identity percentage, the three different bars indicate the average of 3-fold of the three different subsets of COG dataset</p></caption><graphic xlink:href="12859_2022_4626_Fig1_HTML" id="MO1"/></fig></p>
      <sec id="Sec12">
        <title>Homology between training and test set</title>
        <p id="Par21">To run the experiment on our proposed approach, we use an independent test set, which is never used during any step of the training. For each dataset, we have divided the dataset into three equal splits and used two splits for training and one for the test. To show the independence of the test set, we try to find the homology between the training and test set. For each test sequence, we align them against the corresponding training sequences along with the pHMM seed sequences which we used to collect features. Then we collected the percentage of identity with any of those sequences using BLAST. We only collect a percentage of identity if the alignment length of the query sequence is greater than or equal to 100 residues, as a rule of thumb. In Fig. <xref rid="Fig1" ref-type="fig">1</xref>, we can see the average fraction of sequences in our test sets lying in different percentages of identity for COG dataset. For all the three datasets, more than 65% of test data fraction lie within an identity of less than or equal to 70% with the training set.</p>
        <p id="Par22">Although most of the test sequences have a considerable percentage of identity, we have a substantial amount of sequences with identity less than or equal to <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$40\%$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mn>40</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq5.gif"/></alternatives></inline-formula>. This portion of the test set, known as the twilight zone, is relatively harder to predict than others because they have a very low identity to the training set. Almost <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$12\%$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mn>12</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq6.gif"/></alternatives></inline-formula> of the test set for all the three datasets are in this region.</p>
      </sec>
      <sec id="Sec13">
        <title>Prediction accuracy for twilight zone proteins</title>
        <p id="Par23">One of the performance criteria we used to compare EnsembleFam with other methods, is prediction accuracy. In EnsembleFam, as we build one model for each family of each dataset (e.g. 1074 models for COG-500-1074 dataset), there can be multiple predicted labels for each test protein. To calculate the prediction accuracy we divided the test set in multiple subsets based on the number of predictions made by EnsembleFam.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Performance comparison of different methods on the twilight zone sequences, i.e. sequences having less than <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$40\%$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mn>40</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq7.gif"/></alternatives></inline-formula> identity is shown in this table</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Method</th><th align="left">predCount = 1</th><th align="left">predCount = 2</th><th align="left">predCount = 3</th><th align="left">predCount = 4</th><th align="left">predCount = 5</th><th align="left">predCount <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&gt; 5$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq8.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left" colspan="8"><bold>Identity: </bold><inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0 &lt; x \le 30$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq9.gif"/></alternatives></inline-formula></td></tr><tr><td align="left" rowspan="3">COG-500-1074</td><td align="left">EnsembleFam</td><td align="left"><bold>72.07</bold></td><td align="left"><bold>81.00</bold></td><td align="left"><bold>82.82</bold></td><td align="left"><bold>84.96</bold></td><td align="left"><bold>85.33</bold></td><td align="left"><bold>85.27</bold></td></tr><tr><td align="left">pHMM</td><td align="left">69.54</td><td align="left">73.75</td><td align="left">55.51</td><td align="left">70.62</td><td align="left">70.85</td><td align="left">73.55</td></tr><tr><td align="left">DeepFam</td><td align="left">57.14</td><td align="left">54.52</td><td align="left">49.90</td><td align="left">46.92</td><td align="left">43.64</td><td align="left">35.94</td></tr><tr><td align="left" rowspan="3">COG-250-1796</td><td align="left">EnsembleFam</td><td align="left">72.84</td><td align="left"><bold>77.07</bold></td><td align="left"><bold>81.02</bold></td><td align="left"><bold>82.14</bold></td><td align="left"><bold>84.66</bold></td><td align="left"><bold>86.45</bold></td></tr><tr><td align="left">pHMM</td><td align="left"><bold>75.39</bold></td><td align="left">73.82</td><td align="left">73.84</td><td align="left">71.02</td><td align="left">67.44</td><td align="left">72.43</td></tr><tr><td align="left">DeepFam</td><td align="left">32.44</td><td align="left">32.54</td><td align="left">30.24</td><td align="left">29.53</td><td align="left">30.02</td><td align="left">28.68</td></tr><tr><td align="left" rowspan="3">COG-100-2892</td><td align="left">EnsembleFam</td><td align="left"><bold>75.24</bold></td><td align="left"><bold>79.55</bold></td><td align="left"><bold>81.21</bold></td><td align="left"><bold>80.63</bold></td><td align="left"><bold>82.05</bold></td><td align="left"><bold>88.95</bold></td></tr><tr><td align="left">pHMM</td><td align="left">63.44</td><td align="left">59.69</td><td align="left">53.45</td><td align="left">48.16</td><td align="left">47.42</td><td align="left">57.57</td></tr><tr><td align="left">DeepFam</td><td align="left">27.30</td><td align="left">26.13</td><td align="left">25.54</td><td align="left">27.62</td><td align="left">24.83</td><td align="left">25.36</td></tr><tr><td align="left" colspan="8"><bold>Identity: </bold><inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$30 &lt; x \le 40$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mn>30</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq10.gif"/></alternatives></inline-formula></td></tr><tr><td align="left" rowspan="3">COG-500-1074</td><td align="left">EnsembleFam</td><td align="left"><bold>90.96</bold></td><td align="left"><bold>94.51</bold></td><td align="left"><bold>95.88</bold></td><td align="left"><bold>96.16</bold></td><td align="left"><bold>97.08</bold></td><td align="left"><bold>97.84</bold></td></tr><tr><td align="left">pHMM</td><td align="left">62.22</td><td align="left">61.20</td><td align="left">88.95</td><td align="left">87.38</td><td align="left">85.19</td><td align="left">85.85</td></tr><tr><td align="left">DeepFam</td><td align="left">58.45</td><td align="left">58.32</td><td align="left">59.39</td><td align="left">58.41</td><td align="left">58.37</td><td align="left">54.81</td></tr><tr><td align="left" rowspan="3">COG-250-1796</td><td align="left">EnsembleFam</td><td align="left"><bold>91.54</bold></td><td align="left"><bold>95.19</bold></td><td align="left"><bold>95.52</bold></td><td align="left"><bold>95.95</bold></td><td align="left"><bold>96.62</bold></td><td align="left"><bold>97.73</bold></td></tr><tr><td align="left">pHMM</td><td align="left">63.05</td><td align="left">89.41</td><td align="left">89.05</td><td align="left">87.74</td><td align="left">84.82</td><td align="left">83.69</td></tr><tr><td align="left">DeepFam</td><td align="left">47.09</td><td align="left">48.38</td><td align="left">50.12</td><td align="left">51.09</td><td align="left">50.73</td><td align="left">48.78</td></tr><tr><td align="left" rowspan="3">COG-100-2892</td><td align="left">EnsembleFam</td><td align="left"><bold>92.92</bold></td><td align="left"><bold>95.23</bold></td><td align="left"><bold>96.04</bold></td><td align="left"><bold>96.35</bold></td><td align="left"><bold>96.81</bold></td><td align="left"><bold>97.99</bold></td></tr><tr><td align="left">pHMM</td><td align="left">87.07</td><td align="left">87.78</td><td align="left">86.08</td><td align="left">84.04</td><td align="left">80.16</td><td align="left">81.69</td></tr><tr><td align="left">DeepFam</td><td align="left">38.73</td><td align="left">42.62</td><td align="left">46.07</td><td align="left">48.33</td><td align="left">49.30</td><td align="left">45.32</td></tr></tbody></table><table-wrap-foot><p>The best results are highlighted in bold font. The dataset is divided into six subgroups based on the number of predictions made by <italic>EnsembleFam</italic>. Using the column “predCount = 5” as an example, the accuracy in this table is computed as follows. For a protein, if EnsembleFam makes 5 function predictions for it, and one of these is correct, the protein is counted as correct in the column “predCount = 5”; if all 5 function predictions are incorrect, the protein is counted as a wrong prediction. For the same protein, regardless of how many function predictions are made by pHMM, as long as one of these is correct, the protein is counted as correct in the column “predCount = 5”; otherwise, the protein is counted as incorrect in the column. As for DeepFam, which makes exactly one prediction for each protein, the same protein is counted as correct in the column “predCount = 5” if and only if the sole DeepFam prediction for it is correct. All the accuracy value showed in the table is the average of 3-fold cross-validation</p></table-wrap-foot></table-wrap></p>
        <p id="Par24">Here we concentrate on the prediction accuracy of EnsembleFam in the twilight zone of the test set. We divided the twilight zone sequences into two regions, one where the percentage of identity is <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 30$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mo>≤</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq11.gif"/></alternatives></inline-formula> and the other with the percentage of identity <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&gt; 30$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq12.gif"/></alternatives></inline-formula> and <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 40$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mo>≤</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq13.gif"/></alternatives></inline-formula>. The performance comparison of EnsembleFam with pHMM and DeepFam in these two regions is shown in Table <xref rid="Tab2" ref-type="table">2</xref>. For each portion, the dataset is split into six subgroups based on prediction count. From Table <xref rid="Tab2" ref-type="table">2</xref>, it is discernible that EnsembleFam prediction accuracy is almost 10–30% higher than other methods in almost all cases. EnsembleFam outperforms all other methods and its prediction accuracy is more than <inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$90\%$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mn>90</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq14.gif"/></alternatives></inline-formula> for all the subsets of COG dataset in the identity region 30–40%. Detail comparison of prediction accuracy for the whole COG dataset is provided in Additional file <xref rid="MOESM1" ref-type="media">1</xref>.</p>
        <p id="Par25">According to biological insights [<xref ref-type="bibr" rid="CR3">3</xref>] predicting sequences in the twilight zone is much harder than other sequences. But EnsembleFam solves this problem with much higher accuracy than DeepFam and pHMM on the reported dataset.</p>
      </sec>
      <sec id="Sec14">
        <title>ROC AUC score</title>
        <p id="Par26">To assess the performance of EnsembleFam, we calculated the Receiver Operating Characteristic (ROC) curve as another evaluation criterion. To get the ROC curve, the true-positive rate (TPR) and the false-positive rate (FPR) is calculated by varying the threshold of a learned model. TPR (also known as sensitivity) and FPR are computed using the following formula.<disp-formula id="Equ3"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} TPR= &amp; {} \frac{TP}{P} = \frac{\text {True Positive}}{\text {Total number of Positive}} \\ FPR= &amp; {} \frac{FP}{N} = \frac{\text {False Positive}}{\text {Total number of Negative}} \end{aligned}$$\end{document}</tex-math><mml:math id="M30" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mi>P</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>True Positive</mml:mtext></mml:mrow><mml:mrow><mml:mtext>Total number of Positive</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">FP</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>False Positive</mml:mtext></mml:mrow><mml:mrow><mml:mtext>Total number of Negative</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4626_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><fig id="Fig2"><label>Fig. 2</label><caption><p>ROC curve for a few COG families from COG-500-1074 dataset. In each chart EnsmebleFam, DeepFam and pHMM are shown in different colors. It is clear that EnsembleFam performs better than other methods</p></caption><graphic xlink:href="12859_2022_4626_Fig2_HTML" id="MO3"/></fig></p>
        <p id="Par27">In the ROC curve, the learned threshold is varied to observe how the model evolves if we want higher TPR or lower FPR. A good model will give us the highest TPR and lowest FPR for different thresholds, resulting in an inverted L-shape (<inline-formula id="IEq15"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Gamma$$\end{document}</tex-math><mml:math id="M32"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq15.gif"/></alternatives></inline-formula>) ROC curve. To compare the performance of EnsembleFam with that of pHMM and DeepFam, we have plotted the ROC curve of a few families from the COG-500-1074 dataset in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. From the figure, we can observe that the EnsembleFam curve is better <inline-formula id="IEq16"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Gamma$$\end{document}</tex-math><mml:math id="M34"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq16.gif"/></alternatives></inline-formula>-shaped than others, i.e. the predicting power of EnsembleFam is more robust. As the performance of all three methods is pretty high, we plot the curve for TPR value 0.92 and higher to observe the clear difference. The ROC area under the curve (AUC) score is also calculated. The AUC scores for the four families of COG-500-1074 shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref> is listed in Table <xref rid="Tab3" ref-type="table">3</xref>. From the AUC scores, EnsembleFam is better in all four families by a fair margin.<table-wrap id="Tab3"><label>Table 3</label><caption><p>ROC AUC score comparison of four families from COG-500-1074 dataset shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">COG family</th><th align="left">EnsembleFam</th><th align="left">pHMM</th><th align="left">DeepFam</th></tr></thead><tbody><tr><td align="left">COG 344</td><td align="left"><bold>0.999887</bold></td><td align="left">0.993374</td><td align="left">0.997536</td></tr><tr><td align="left">COG 508</td><td align="left"><bold>0.999897</bold></td><td align="left">0.983626</td><td align="left">0.996149</td></tr><tr><td align="left">COG 539</td><td align="left"><bold>0.999303</bold></td><td align="left">0.992682</td><td align="left">0.994334</td></tr><tr><td align="left">COG 796</td><td align="left"><bold>0.999084</bold></td><td align="left">0.994031</td><td align="left">0.994851</td></tr></tbody></table><table-wrap-foot><p>The best results are highlighted in bold font</p></table-wrap-foot></table-wrap></p>
        <p id="Par28">
          <fig id="Fig3">
            <label>Fig. 3</label>
            <caption>
              <p>ROC AUC score comparison between EnsembleFam, DeepFam and pHMM on the three COG datasets. The <inline-formula id="IEq17"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x-$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq17.gif"/></alternatives></inline-formula>axis shows the AUC score and the <inline-formula id="IEq18"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y-$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq18.gif"/></alternatives></inline-formula>axis shows number of families in the respective dataset having AUC scores greater than or equal to the respective <italic>x</italic> value</p>
            </caption>
            <graphic xlink:href="12859_2022_4626_Fig3_HTML" id="MO4"/>
          </fig>
        </p>
        <p id="Par29">Determining the AUC score for each family helps us choose the best model. For each dataset we have over a thousand families in our test set; e.g., we have 1074 families in COG-500-1074. To compare the AUC score of each family for the three datasets, we have plotted the AUC scores in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. In this figure, for each dataset, <italic>x</italic>-axis indicates the AUC score and <italic>y</italic>-axis indicates the number of families having equal or higher AUC scores indicated in <italic>x</italic>-axis. The best model will have an AUC score of 1.0 for all the families, which will end up being a straight line at <inline-formula id="IEq19"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y = \textit{number of families}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">number of</mml:mi><mml:mspace width="4pt"/><mml:mi mathvariant="italic">families</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq19.gif"/></alternatives></inline-formula>. All three methods have a very high AUC score for most of the families, the real difference is observed when we look at the higher AUC value (<inline-formula id="IEq20"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&gt; 0.95$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq20.gif"/></alternatives></inline-formula>). In Fig. <xref rid="Fig3" ref-type="fig">3</xref>, the number of families dropped for DeepFam and pHMM after reaching AUC score of 0.99. Whereas, EnsembleFam in all the three figures sustains longer and provides a higher AUC score for almost all the families which are closer to 1.0. This indicates that the performance of EnsembleFam is much better than DeepFam and pHMM in terms of the ROC AUC score on COG dataset.</p>
      </sec>
      <sec id="Sec15">
        <title>ROC AUC score for new families</title>
        <p id="Par30">In this section, we evaluate the performance of EnsembleFam on test examples from new families that are not used in training. In our three dataset COG-500-1074, COG-250-1796, and COG-100-2892, the number of families is respectively 1074, 1796, 2892. As we divided the dataset based on the number of sequences above a certain threshold, the COG-100-2892 dataset includes all the families of COG-500-1074 and COG-250-1796. Therefore for this experiment, we used the test sequences from unique families of COG-100-2892 to test the models trained on COG-500-1074 and COG-250-1796. The COG-500-1074 models are trained on 1074 families, thus there are 1818 (2892 – 1074 = 1818) new families in COG-100-2892 which were never used while training models for COG-500-1074. Similarly, for COG-250-1796 models there are 1096 new families in COG-100-2892. We used the sequences of these families to test the performance of the models on new unknown family proteins. As none of the sequences belong to any of the trained families, the models should predict them as negatives.<fig id="Fig4"><label>Fig. 4</label><caption><p>Test result of EnsembleFam and pHMM on new (unknown) family not used in training. For this, we used 1818 different families from COG-100-2892 to test the models of COG-500-1074, similarly 1096 different families for COG-250-1796. In the figure, <inline-formula id="IEq21"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x-$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq21.gif"/></alternatives></inline-formula>axis indicates the ROC AUC score and the <inline-formula id="IEq22"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y-$$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq22.gif"/></alternatives></inline-formula>axis indicates number of families above that AUC score</p></caption><graphic xlink:href="12859_2022_4626_Fig4_HTML" id="MO5"/></fig></p>
        <p id="Par31">We measured the ROC AUC score to assess the performance of EnsembleFam, similar to the previous section. We plotted the number of families versus AUC score curve in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. In our test sequences, all the samples are negative, but we need positive samples as well to calculate the ROC AUC score. For this, we included the positive test sequences of the respective family along with these negative test sequences from new families. From Fig. <xref rid="Fig4" ref-type="fig">4</xref> we can see EnsembleFam AUC scores are close to 1.0 for most of the families, whereas for pHMM the number of families drops after reaching an AUC score of 0.99. It shows that EnsembleFam is more robust to samples from new unknown families than pHMM. In this experiment, we have not included DeepFam as it cannot handle sequences outside of trained families. As DeepFam is a neural network-based multi-class classifier, it will always try to force the test sequence into one of the trained classes. But none of these sequences belong to any of the trained classes, i.e. DeepFam will end up predicting all of these novel sequences incorrectly. This is one of the drawbacks of DeepFam. Therefore, EnsembleFam is superior to both DeepFam and pHMM in this experiment as well.</p>
      </sec>
    </sec>
    <sec id="Sec16">
      <title>Performance evaluation on GPCR dataset</title>
      <p id="Par32">GPCR is a hierarchically classified dataset divided into family, sub-family, and sub-subfamily which is rather different from the COG dataset. For this dataset, we first build models for the leaf, i.e., sub-subfamilies; and then propagate the prediction to the roots, i.e., sub-family and family level, in a bottom-up approach. As the number of sequences in the GPCR dataset is much fewer compared to the COG dataset, we conducted a 10-fold cross-validation experiment for this dataset. All the results reported here are the average of 10-fold cross-validation.</p>
      <sec id="Sec17">
        <title>Prediction accuracy for twilight zone proteins</title>
        <p id="Par33">Similar to the COG dataset, we kept separate one portion of the data for the test and calculated homology with the training set. Due to hierarchical classification, we experimented with the sub-subfamilies and later propagated it to the upper level. As the number of sequences is quite small, there are only a few sequences in the twilight zone for this dataset. We have around 800 test proteins in each validation set, and only 4–5% of them belong to the twilight zone, i.e., have <inline-formula id="IEq23"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 40\%$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:mo>≤</mml:mo><mml:mn>40</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq23.gif"/></alternatives></inline-formula> identity with the training sequence. This only gives us around 30–40 sequences in the twilight zone.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Number of prediction made by pHMM and EnsembleFam for twilight zone proteins where <inline-formula id="IEq24"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$30 &lt; \text {identity} \le 40$$\end{document}</tex-math><mml:math id="M50"><mml:mrow><mml:mn>30</mml:mn><mml:mo>&lt;</mml:mo><mml:mtext>identity</mml:mtext><mml:mo>≤</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq24.gif"/></alternatives></inline-formula></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">seq1</th><th align="left">seq2</th><th align="left">seq3</th><th align="left">seq4</th><th align="left">seq5</th><th align="left">seq6</th><th align="left">seq7</th><th align="left">seq8</th><th align="left">seq9</th><th align="left">seq10</th><th align="left">seq11</th><th align="left">seq12</th><th align="left">seq13</th><th align="left">seq14</th></tr></thead><tbody><tr><td align="left">pHMM</td><td align="left">57</td><td align="left">54</td><td align="left">58</td><td align="left">17</td><td align="left">13</td><td align="left">7</td><td align="left">7</td><td align="left">56</td><td align="left">50</td><td align="left">50</td><td align="left">38</td><td align="left">1</td><td align="left">1</td><td align="left">54</td></tr><tr><td align="left">EnsembleFam</td><td align="left">1</td><td align="left">0</td><td align="left">0</td><td align="left">2</td><td align="left">0</td><td align="left">0</td><td align="left">3</td><td align="left">1</td><td align="left">1</td><td align="left">1</td><td align="left">1</td><td align="left">2</td><td align="left">2</td><td align="left">1</td></tr></tbody></table><table-wrap-foot><p>For each test sequence, the maximum number of predictions can be 86, i.e, the sequence belongs to all sub-subfamilies. And the minimum number of predictions can be 0, i.e., the sequence does not belong to any of the sub-subfamily. DeepFam was not included in this comparison, as DeepFam always predict a single label irrespective of the number of families</p></table-wrap-foot></table-wrap><table-wrap id="Tab5"><label>Table 5</label><caption><p>Prediction accuracy comparison of different methods on the twilight zone proteins</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">Sub-subfamily</th><th align="left">Sub-family</th><th align="left">Family</th></tr><tr><th align="left" colspan="4"><bold>Identity</bold>: <inline-formula id="IEq25"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0 &lt; x \le 30$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq25.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left">pHMM</td><td align="left">5.51</td><td align="left">11.76</td><td align="left">39.80</td></tr><tr><td align="left">DeepFam</td><td align="left">5.53</td><td align="left">16.88</td><td align="left">61.44</td></tr><tr><td align="left">EnsembleFam</td><td align="left"><bold>30</bold>.<bold>92</bold></td><td align="left"><bold>45</bold>.<bold>15</bold></td><td align="left"><bold>65</bold>.<bold>45</bold></td></tr><tr><td align="left" colspan="4"><bold>Identity</bold>: <inline-formula id="IEq26"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$30 &lt; x \le 40$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mn>30</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq26.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">pHMM</td><td align="left">14.74</td><td align="left">21.72</td><td align="left"><bold>85</bold>.<bold>37</bold></td></tr><tr><td align="left">DeepFam</td><td align="left">22.38</td><td align="left">37.18</td><td align="left">73.40</td></tr><tr><td align="left">EnsembleFam</td><td align="left"><bold>30</bold>.<bold>38</bold></td><td align="left"><bold>49</bold>.<bold>65</bold></td><td align="left">65.46</td></tr></tbody></table><table-wrap-foot><p>Best results are highlighted in bold font. For pHMM and EnsembleFam, we removed the predictions where the number of prediction is <inline-formula id="IEq27"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&gt; 5$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq27.gif"/></alternatives></inline-formula> and considered them as wrong prediction. For others, where the number of prediction is <inline-formula id="IEq28"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 5$$\end{document}</tex-math><mml:math id="M58"><mml:mrow><mml:mo>≤</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq28.gif"/></alternatives></inline-formula> and the true label is included within the predicted one, we consider as correct. For DeepFam, as it only predicts one label, if the predicted label is the same as true label then we consider it as correct. EnsembleFam outperforms other two method in almost all cases</p></table-wrap-foot></table-wrap></p>
        <p id="Par34">For pHMM and EnsembleFam, we have one predictive model for each sub-subfamily whereas, DeepFam provides only one multi-class model for all 86 sub-subfamilies. As such, there can be more than one predicted label for each sequence for both pHMM and EnsembleFam. In Table <xref rid="Tab4" ref-type="table">4</xref>, the number of predictions made by pHMM and EnsembleFam can be found for proteins with identity <inline-formula id="IEq29"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$&gt; 30$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq29.gif"/></alternatives></inline-formula> and <inline-formula id="IEq30"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 40$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mo>≤</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq30.gif"/></alternatives></inline-formula>. From Table <xref rid="Tab4" ref-type="table">4</xref>, we can perceive that the number of predictions made by pHMM for a protein is around 50 (out of 86), which is approximately <inline-formula id="IEq31"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$60\%$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mn>60</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq31.gif"/></alternatives></inline-formula> of the total number of families. Although the correct class label may be included in these predictions, these predictions might not be helpful for biologists. To make the prediction beneficial for biologists, we discarded the predictions where the prediction count is more than five, i.e., we consider those as wrong predictions while calculating the accuracy. The performance comparison of EnsembleFam with pHMM and DeepFam presented in Table <xref rid="Tab5" ref-type="table">5</xref>, demonstrates that EnsembleFam is better than other methods in correctly identifying twilight zone proteins. Performance comparison for whole GPCR dataset can be found in Additional file <xref rid="MOESM1" ref-type="media">1</xref>.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec18">
    <title>Conclusions</title>
    <p id="Par35">EnsembleFam, a protein family modeling technique using an ensemble approach and sequence homology information, is presented in this study. Different protein families can be modeled using this approach even if they have only a few (10 in this study) annotated proteins. Compared to state-of-the-art methods, EnsembleFam provides better prediction accuracy while resolving the disadvantages of those methods. EnsembleFam provides several beneficial characteristics. Firstly, EnsembleFam is more accurate than sequence homology-based and alignment-free methods. EnsembleFam provides one model for each family which correctly identifies the huge number of negative examples without having lots of false positives. Notably, EnsembleFam’s modeling technique is effective in correctly classifying proteins from the twilight zone. To tackle the problem of the growing number of unidentified protein sequences from various genome projects, EnsembleFam, a fast and more accurate modeling technique, will be very useful.</p>
    <p id="Par36">Alongside the benefits of EnsembleFam, there are several issues that are left as future work. As we know, there are a lot of proteins which do not have any domains or families assigned to them. The Pfam database provides a set of such proteins, known as domains of unknown function (DUFs) [<xref ref-type="bibr" rid="CR40">40</xref>]. We wish to conduct extensive experiments on such proteins to find possible domains for DUFs, and then later validate them experimentally as part of our future work. As described earlier, EnsembleFam provides more than one prediction for a considerable fraction of test sets. But the true label is included among these predictions in almost all cases. Compared to other methods where only one prediction is made, EnsembleFam helps a biologist in identifying the correct label instead of the wrong one. Several approaches can be taken to identify a correct label from the multiple predictions like by aligning the query sequence with a few training sequences from the predicted classes. Two very popular and significant datasets, namely the COG dataset and GPCR dataset have been used in this study. Although EnsembleFam has shown comparatively better performance in identifying twilight zone proteins, the experiments were only conducted for single-domain protein sequences. There exists a vast number of unidentified multi-domain protein sequences. The state-of-the-art method pHMM can handle multi-domain proteins but the accuracy and precision can be improved. Thus, to address this problem and to model protein families with multiple domains a new study is necessary.</p>
  </sec>
  <sec id="Sec19">
    <title>Methods</title>
    <p id="Par37">In this study, we introduce EnsembleFam. EnsembleFam is a machine learning-based approach that uses three different Support Vector Machine (SVM) classifiers to infer the family of a protein from its sequence. In this approach, we build a single-class classifier for each family, i.e. a separate ensemble classifier for each family, which determines if an input sequence belongs to that corresponding family or not. EnsembleFam uses three different sets of features to train the three SVM classifiers. The features contain different similarity and dissimilarity measures among the families. From a raw protein sequence, respective features are collected using popular tools. These features are then passed to the three SVM classifiers to make predictions for each family and then a majority voting approach is taken to determine the final prediction for a sequence if it belongs to a certain family or not. We describe the architecture of EnsembleFam and how the models are trained in this section.</p>
    <sec id="Sec20">
      <title>EnsembleFam</title>
      <sec id="Sec21">
        <title>Architecture</title>
        <p id="Par38">To build a model for a specific family, we first use Basic Local Alignment Search Tool (BLAST) [<xref ref-type="bibr" rid="CR13">13</xref>] and profile Hidden Markov Model (pHMM) [<xref ref-type="bibr" rid="CR14">14</xref>] to collect different features. These two tools use different techniques to calculate the sequence similarity of an input sequence to a given database of proteins of a family for which we want to build the model. We use these similarity scores of a family as a feature for our SVM classifiers. For each sequence, its similarity scores to all families are collected. That means each feature vector contains a score for each family indicating the similarity of the corresponding protein sequence with that family. For each protein family <italic>x</italic>, we divide the features into two categories: similarity and dissimilarity features.<list list-type="bullet"><list-item><p id="Par39"><italic>Similarity feature</italic> The sequence similarity score of a sequence to the family <italic>x</italic> is referred to as the similarity feature of the family <italic>x</italic>. A sequence that belongs to family <italic>x</italic> is expected to have a higher value for this similarity feature.</p></list-item><list-item><p id="Par40"><italic>Dissimilarity feature</italic> The sequence similarity of a sequence to families other than family <italic>x</italic> is referred to as the dissimilarity features of family <italic>x</italic>. A protein belonging to family <italic>x</italic> is expected to have lower values for the dissimilarity features of the family <italic>x</italic>.</p></list-item></list>This idea of using dissimilarity features along with the similarity features was implicit in SVM-pairwise [<xref ref-type="bibr" rid="CR26">26</xref>]. Moreover, in SVM-pairwise, the features are collected for all possible pairs of the training sequences; i.e. for a given sequence, its similarity score to all members of its own family, and all members from the rest of families are calculated. In contrast, in EnsembleFam, for each sequence, only one similarity score is generated for each family, indicating its similarity to that family. Thus the size of an EnsembleFam feature vector is in the order of the number of protein families; this is much smaller than the size of an SVM-Pairwise feature vector which is in the order of the total number of reference proteins in all families.</p>
        <p id="Par41">We use both BLAST and pHMM to collect features from the sequences. The BLASTDB we use for BLAST is created from the training families (more details in Sect. <xref rid="Sec22" ref-type="sec">Features</xref>) and provides both similarity and dissimilarity features for all families. For pHMM, we use predefined Hidden Markov Models (HMMs) from the Pfam database [<xref ref-type="bibr" rid="CR15">15</xref>]. All these predefined HMM models mostly differ from our target protein families, but there might be a slight overlap between some protein families. As such, we name these features as pHMM features, which can be considered as a mixture of similarity and dissimilarity features. Once we have collected all the features, three base SVM classifiers are trained for each family using the following feature sets:<list list-type="bullet"><list-item><p id="Par42"><italic>SVM model 1</italic> Trained on pHMM features + similarity and dissimilarity features from BLAST</p></list-item><list-item><p id="Par43"><italic>SVM model 2</italic> Trained on pHMM features + only similarity features from BLAST</p></list-item><list-item><p id="Par44"><italic>SVM model 3</italic> Trained on only similarity features from BLAST</p></list-item></list>Note that, for each family, three such base classifiers are trained using the respective similarity and dissimilarity features of that family, which are used later to predict members of that family. As a result, for each protein sequence, we get three predictions indicating either the protein belongs to the respective family or not. A majority vote is then used to make the final ensemble prediction for that family.</p>
      </sec>
      <sec id="Sec22">
        <title>Features</title>
        <p id="Par45">In EnsembleFam, BLAST and pHMM are used for generating similarity and dissimilarity features.</p>
        <p id="Par46"><italic>BLAST features</italic> Most of the features used to train our models are collected using BLAST. We use 10 reference sequence from each family (that we intend to build a model for) to create the BLAST database (BLASTDB). Let us assume we have <italic>N</italic> families in total, so our BLASTDB size will be 10<italic>N</italic>, i.e. each time a sequence is provided it will be compared against these 10<italic>N</italic> sequences. Each sequence is then run against the BLASTDB and the hits, scoring above a defined threshold, are reported in the BLAST output. From the BLAST output, we only consider one hit from one family, i.e. if a sequence hits multiple sequences of the same family we only consider the one with high scores and use it as the BLAST features for that family. By repeating this process, we collect BLAST features from all the families for each sequence. For each family (corresponding to a hit in BLAST output) we use three features to represent the similarity or dissimilarity of the given sequence to the respective family, which are: <list list-type="order"><list-item><p id="Par47"><bold>Bit-score:</bold> The bit-score of an alignment is a normalized form of a raw alignment score. The raw alignment score is defined as the sum of substitution and gap scores along with the penalties [<xref ref-type="bibr" rid="CR41">41</xref>]. Bit-scores are usually normalized using the scoring system; therefore scores from different searches can be compared with each other. The higher the bit-score of an alignment the better, i.e. the given sequence is more similar to the one in the database.</p></list-item><list-item><p id="Par48"><bold>E-value:</bold> The e-value of an alignment is the expected number of hits, having an equal or better bit-score, that can be found by chance. Hence the lower the e-value the more significant the alignment is [<xref ref-type="bibr" rid="CR41">41</xref>].</p></list-item><list-item><p id="Par49"><bold>Identity:</bold> The percentage of aligned positions of two sequences having the same residue in the two sequences is known as identity [<xref ref-type="bibr" rid="CR41">41</xref>]. Often in BLAST hits many of the sequences align with only a small portion of the sequence, as BLAST looks for local alignment. Some of these may have high scores and good e-values, yet they are not useful for our analysis as they have a low percentage of matches. In such a case, identity helps us differentiate between longer aligned sequences from the shorter one, which in turn helps us identify the correct member of the family.</p></list-item></list><bold>pHMM features:</bold> While gathering the BLAST features we create our own database and collect both similarity and dissimilarity features for our model. But for profile Hidden Markov Models (pHMMs) we do not build our own HMM models to collect features, rather we use some predefined models from the Pfam database [<xref ref-type="bibr" rid="CR15">15</xref>]. For each pHMM, we take two features (which are quite similar to the BLAST features): <list list-type="order"><list-item><p id="Par50"><bold>Bit-score:</bold> The bit-score in pHMM is somewhat similar to the one in BLAST. Here, bit-score is defined as log-odds ratio score of the likelihood of the profile HMM with respect to the likelihood of the null hypothesis [<xref ref-type="bibr" rid="CR42">42</xref>]. So bit-score can be written as, <disp-formula id="Equ4"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \text {bit-score, }S = \log _2 \frac{\text {likelihood of pHMM }}{\text {likelihood of null hypothesis}} \end{aligned}$$\end{document}</tex-math><mml:math id="M66" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>bit-score,</mml:mtext><mml:mspace width="0.333333em"/><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mo>log</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mfrac><mml:mrow><mml:mtext>likelihood of pHMM</mml:mtext><mml:mspace width="0.333333em"/></mml:mrow><mml:mrow><mml:mtext>likelihood of null hypothesis</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4626_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p></list-item><list-item><p id="Par51"><bold>E-value:</bold> The definition of the e-value is similar to the one we have seen earlier. An e-value is the number of hits expected to achieve a certain bit-score or higher by chance [<xref ref-type="bibr" rid="CR42">42</xref>].</p></list-item></list></p>
      </sec>
      <sec id="Sec23">
        <title>Training the models</title>
        <p id="Par52">Once we have collected all the features from the training sequences using BLAST and pHMM, the next step is to train the SVM classifiers for each family. We use a different subset of the features to train different classifiers. Here we discuss the feature vector size for each model:<list list-type="bullet"><list-item><p id="Par53"><bold>SVM model 1 for family</bold><italic>x</italic><bold>:</bold> The first model is trained on all the features we collected using both BLAST and pHMM. For a single sequence, we get 3 features (<italic>bit-score, e-value, identity</italic>) from each family using BLAST. If we have <italic>N</italic> family in total, then we get a total of 3<italic>N</italic> features from BLAST. Similarly, for each sequence we get 2 features (<italic>bit-score, e-value</italic>), so in total 2<italic>M</italic> features from pHMM where <italic>M</italic> is the number of pHMM models. In total, the feature vector size is <inline-formula id="IEq32"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2M + 3N$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq32.gif"/></alternatives></inline-formula> for the first model.</p></list-item><list-item><p id="Par54"><bold>SVM model 2 for family</bold><italic>x</italic><bold>:</bold> For the second model, we only use the similarity features from BLAST and pHMM features. For a single sequence, we only use the 3 features corresponding to the family <italic>x</italic> from BLAST and all the 2<italic>M</italic> features from pHMM. Hence, the feature vector size for this model is <inline-formula id="IEq33"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2M +3$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq33.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par55"><bold>SVM model 3 for family</bold><italic>x</italic><bold>:</bold> The third model is rather a simple and naive one compared to the other two. For this, we only use the similarity features from BLAST to train the model. So we have only 3 features corresponding to family <italic>x</italic> for each sequence in this model. Although this is quite a simple model, it does pretty well in predicting members of the family <italic>x</italic>.</p></list-item></list>We have all the features that we require to train the models for our target protein families. Each base SVM classifier for a family in EnsembleFam is a single-class classifier. But when we build a single-class classifier, other than the target protein family, all other protein families form the negative class and we need to incorporate the negative examples to train our classifiers. If the total number of families is <italic>N</italic> and each family has at least <italic>d</italic> reference proteins, that means we will have approximately <inline-formula id="IEq34"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d\times (N-1)$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq34.gif"/></alternatives></inline-formula> negative examples and only <italic>d</italic> positive examples. For example, if <inline-formula id="IEq35"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N=1000$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq35.gif"/></alternatives></inline-formula> and <inline-formula id="IEq36"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d=200$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq36.gif"/></alternatives></inline-formula> then the count for negative examples would be approximately 200,000 compared to 200 positive examples, which creates a huge imbalance in our training data. To avoid such a scenario in EnsembleFam, we only use 10 instances from each negative family as our training data which reduces the number from 200,000 to only 10,000, i.e. 20 times smaller in this example. Here we assume each family has only 200 examples, whereas in real data we have more and the number of families also increases a lot. So, to train our SVM models we follow this rule to reduce the number of negative examples compared to positive. As we can see from the above example, the ratio between positive and negative examples is still huge, and each classifier can gain very high accuracy (more than <inline-formula id="IEq37"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$90\%$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mn>90</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq37.gif"/></alternatives></inline-formula>) by just saying <italic>NO</italic> to all input. For our problem, it is more important to detect the positive examples, i.e., the member of a certain family than detecting the one who does not belong. For this reason, while training our SVM models we use a weighted classifier where a positive example is <inline-formula id="IEq38"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$9\text {x}$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mn>9</mml:mn><mml:mtext>x</mml:mtext></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq38.gif"/></alternatives></inline-formula> the weight of a negative example. So the models try to classify the positive examples more correctly than the negative ones. Along with that, we have used linear kernel and squared hinge loss to train three base SVM classifiers (as mentioned above) for each family.</p>
      </sec>
      <sec id="Sec24">
        <title>Ensemble prediction</title>
        <p id="Par56">We build one ensemble classifier for each family, which consists of three base SVM classifiers trained on a different subset of our feature set. Once we build all three base classifiers, the ensemble decision is taken by majority voting; i.e., if two or three of the SVM classifiers agree on a prediction then we provide that as our ensemble prediction for the input sequence. This can be defined as,<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\hat{y}} = mode\{\ C_1(\text {x}),\ C_2(\text {x}),\ C_3(\text {x})\} \end{aligned}$$\end{document}</tex-math><mml:math id="M82" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4626_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>Here, <inline-formula id="IEq39"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_j$$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq39.gif"/></alternatives></inline-formula> is the <italic>j</italic>-th classifier and <inline-formula id="IEq40"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\text {x}$$\end{document}</tex-math><mml:math id="M86"><mml:mtext>x</mml:mtext></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq40.gif"/></alternatives></inline-formula> is the input sequence. The prediction <inline-formula id="IEq41"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}$$\end{document}</tex-math><mml:math id="M88"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq41.gif"/></alternatives></inline-formula> is made by majority (plurality) voting of each base classifier.</p>
        <p id="Par57">The above formula (Eq. <xref rid="Equ1" ref-type="">1</xref>) gives us a prediction for each input for each protein family, but we also need a score (or probability) for each prediction to calculate the area under the Receiver Operating Characteristic (ROC) curve. As the ensemble prediction is made by majority voting from the three base classifiers, the ensemble score is also calculated using the same idea. We use the following formula to calculate probability score for EnsembleFam,<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Pr(ensemble) = (p_1\ p_2\ p_3) + (p_1\ p_2\ q_3) + (p_1\ q_2\ p_3) + (q_1\ p_2\ p_3) \end{aligned}$$\end{document}</tex-math><mml:math id="M90" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>p</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>p</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mspace width="4pt"/><mml:msub><mml:mi>p</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_4626_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>Here, <inline-formula id="IEq42"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_i \in [0,1] : \text {prediction probability of classifier } i$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mtext>prediction probability of classifier</mml:mtext><mml:mspace width="0.333333em"/><mml:mi>i</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq42.gif"/></alternatives></inline-formula> and <inline-formula id="IEq43"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q_i \in [0,1] : q_i = (1-p_i)$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4626_Article_IEq43.gif"/></alternatives></inline-formula></p>
        <p id="Par58">In Eq. <xref rid="Equ2" ref-type="">2</xref>, we use the formula to incorporate majority voting in our ensemble probability calculation. The equation gives a high probability if and only if at least two of the classifiers provide high probability for the input sequence.</p>
        <p id="Par59">To test the performance of EnsembleFam, we used two different types of test set to better understand the outcome. The first type is for testing the performance of EnsembleFam on trained protein families. For this first type of test set, a 3-fold cross-validation is used; i.e., out of the three equally divided subsets of the dataset, two are used for training and the other subset is used for testing the model. The second type is for testing the performance of EnsembleFam on completely unseen (novel) protein families. For this type of test sets, protein families which are never used for training and their member proteins are used for testing. This second type of testing is necessary because, in a real deployment, EnsembleFam can be expected to encounter proteins from completely novel protein families.</p>
      </sec>
    </sec>
    <sec id="Sec25">
      <title>Existing protein family modeling methods used for performance comparison</title>
      <p id="Par60">We have used pHMM and DeepFam methods to compare the performance of EnsembleFam using different metrics like prediction accuracy, area under the ROC curve. In this section, we provide a brief explanation of these two methods.</p>
      <sec id="Sec26">
        <title>Profile hidden Markov model (pHMM)</title>
        <p id="Par61">One of the most popularly used alignment-based method, profile Hidden Markov Model (pHMM), is used to compare the performance of EnsembleFam. To construct a pHMM model for a protein family, we first aligned the multiple sequences using Clustal Omega [<xref ref-type="bibr" rid="CR43">43</xref>], and then these alignments are passed to HMMER [<xref ref-type="bibr" rid="CR44">44</xref>] to build the model. In HMMER, hmmbuild is used to build the model and then hmmpress to index and compress it. Later, we used hmmscan to predict family for a given protein sequence based on e-value reported in the output. We used HMMER v3.2.1 with all the default parameters to construct the pHMMs for our evaluation.</p>
      </sec>
      <sec id="Sec27">
        <title>DeepFam</title>
        <p id="Par62">DeepFam is a deep learning-based protein family modeling method recently introduced which reported a competitive performance with pHMM. We use this method to compare the predictive performance of EnsembleFam. DeepFam builds a multi-class classifier from the training data. DeepFam models are trained using graphics processing unit (GPU) from the training sequences with all the default parameters provided in the paper. For one dataset, one multi-class classifier is built using DeepFam, later these models are used to compare the performance.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec28">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_4626_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1: Table S1</bold>. Prediction accuracy comparison of different methods on the whole COG test set. <bold>Table S2, S3, S4</bold>: Identity based performance for COG-500-1074, COG-250-1796 and COG-100-2892 dataset are shown respectively. <bold>Table S5</bold>: Prediction accuracy comparison of different methods on the whole GPCR test set. <bold>Figure S1</bold>: Homology between training and test set of GPCR. <bold>Table S6</bold>: Prediction accuracy comparison of different methods on the GPCR dataset based on identity.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary Information</title>
    <p>The online version contains supplementary material available at 10.1186/s12859-022-04626-w.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors' contributions</title>
    <p>MNK designed and implemented EnsembleFam, designed and conducted all the evaluation experiments, and wrote the manuscript. LW conceived the project and participated in refining EnsembleFam and designing its evaluation. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work is supported by the National Research Foundation, Prime Minister’s Office, Singapore under its Synthetic Biology Research and Development Programme (Award No. SBP-P3). LW is also supported in part by a Kwan Im Thong Hood Cho Temple chair professorship.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets generated and/or analysed during the current study are available in the EnsembleFam repository, <ext-link ext-link-type="uri" xlink:href="https://github.com/NeamulKabir/EnsembleFam">https://github.com/NeamulKabir/EnsembleFam</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar2">
      <title>Ethics approval and consent to participate</title>
      <p id="Par63">Not applicable.</p>
    </notes>
    <notes id="FPar3">
      <title>Consent for publication</title>
      <p id="Par64">Not applicable.</p>
    </notes>
    <notes id="FPar4" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par65">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>DeepQA: improving the estimation of single protein model quality with deep belief networks</article-title>
        <source>BMC Bioinform</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>495</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-1405-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mukherjee</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Stamatis</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bertsch</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ovchinnikova</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Katta</surname>
            <given-names>HY</given-names>
          </name>
          <name>
            <surname>Mojica</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>I-MA</given-names>
          </name>
          <name>
            <surname>Kyrpides</surname>
            <given-names>NC</given-names>
          </name>
          <name>
            <surname>Reddy</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Genomes OnLine database (GOLD) v. 7: updates and new features</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>649</fpage>
        <lpage>659</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky977</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chung</surname>
            <given-names>SY</given-names>
          </name>
          <name>
            <surname>Subbiah</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>A structural explanation for the twilight zone of protein sequence homology</article-title>
        <source>Structure</source>
        <year>1996</year>
        <volume>4</volume>
        <issue>10</issue>
        <fpage>1123</fpage>
        <lpage>1127</lpage>
        <pub-id pub-id-type="doi">10.1016/S0969-2126(96)00119-0</pub-id>
        <pub-id pub-id-type="pmid">8939745</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Twilight zone of protein sequence alignments</article-title>
        <source>Protein Eng</source>
        <year>1999</year>
        <volume>12</volume>
        <issue>2</issue>
        <fpage>85</fpage>
        <lpage>94</lpage>
        <pub-id pub-id-type="doi">10.1093/protein/12.2.85</pub-id>
        <pub-id pub-id-type="pmid">10195279</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Piovesan</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Giollo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Leonardi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Ferrari</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tosatto</surname>
            <given-names>SC</given-names>
          </name>
        </person-group>
        <article-title>Inga: protein function prediction combining interaction networks, domain assignments and sequence similarity</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>W1</issue>
        <fpage>134</fpage>
        <lpage>140</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv523</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Protein homology detection by hmm-hmm comparison</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <issue>7</issue>
        <fpage>951</fpage>
        <lpage>960</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti125</pub-id>
        <pub-id pub-id-type="pmid">15531603</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Lomets: a local meta-threading-server for protein structure prediction</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>35</volume>
        <issue>10</issue>
        <fpage>3375</fpage>
        <lpage>3382</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm251</pub-id>
        <pub-id pub-id-type="pmid">17478507</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Smaili FZ, Tian S, Roy A, Alazmi M, Arold ST, Mukherjee S, Hefty PS, Chen W, Gao X. QAUST: protein function prediction using structure similarity, protein interaction, and functional motifs. Genomics Proteomics Bioinform. 2021;</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Roberts K, Alberts B, Johnson A, Walter P, Hunt T. Molecular biology of the cell. New York: Garland Sci. 2002;32(2).</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Koonin E, Galperin MY. Sequence-evolution-function: computational approaches in comparative genomics. 2002.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Koonin</surname>
            <given-names>EV</given-names>
          </name>
        </person-group>
        <article-title>Orthologs, paralogs, and evolutionary genomics</article-title>
        <source>Annu Rev Genet</source>
        <year>2005</year>
        <volume>39</volume>
        <fpage>309</fpage>
        <lpage>338</lpage>
        <pub-id pub-id-type="doi">10.1146/annurev.genet.39.073003.114725</pub-id>
        <pub-id pub-id-type="pmid">16285863</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>TF</given-names>
          </name>
          <name>
            <surname>Waterman</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>Identification of common molecular subsequences</article-title>
        <source>J Mol Biol</source>
        <year>1981</year>
        <volume>147</volume>
        <issue>1</issue>
        <fpage>195</fpage>
        <lpage>197</lpage>
        <pub-id pub-id-type="doi">10.1016/0022-2836(81)90087-5</pub-id>
        <pub-id pub-id-type="pmid">7265238</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Gish</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Myers</surname>
            <given-names>EW</given-names>
          </name>
          <name>
            <surname>Lipman</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <article-title>Basic local alignment search tool</article-title>
        <source>J Mol Biol</source>
        <year>1990</year>
        <volume>215</volume>
        <issue>3</issue>
        <fpage>403</fpage>
        <lpage>410</lpage>
        <pub-id pub-id-type="doi">10.1016/S0022-2836(05)80360-2</pub-id>
        <pub-id pub-id-type="pmid">2231712</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eddy</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>Profile hidden Markov models</article-title>
        <source>Bioinformatics (Oxford, England)</source>
        <year>1998</year>
        <volume>14</volume>
        <issue>9</issue>
        <fpage>755</fpage>
        <lpage>763</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/14.9.755</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>El-Gebali</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mistry</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bateman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Eddy</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Luciani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Potter</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Qureshi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>LJ</given-names>
          </name>
          <name>
            <surname>Salazar</surname>
            <given-names>GA</given-names>
          </name>
          <name>
            <surname>Smart</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Pfam protein families database in 2019</article-title>
        <source>Nucleic Acids Res</source>
        <year>2019</year>
        <volume>47</volume>
        <issue>D1</issue>
        <fpage>427</fpage>
        <lpage>432</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky995</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Martin</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Berriman</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Barton</surname>
            <given-names>GJ</given-names>
          </name>
        </person-group>
        <article-title>GOtcha: a new method for prediction of protein function assessed by the annotation of seven genomes</article-title>
        <source>BMC Bioinform</source>
        <year>2004</year>
        <volume>5</volume>
        <issue>1</issue>
        <fpage>178</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-5-178</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Groth</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lehrach</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hennig</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>GOblet: a platform for gene ontology annotation of anonymous sequence data</article-title>
        <source>Nucleic Acids Res</source>
        <year>2004</year>
        <volume>32</volume>
        <issue>suppl-2</issue>
        <fpage>313</fpage>
        <lpage>317</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh406</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zehetner</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>OntoBlast function: from sequence similarities directly to potential functional annotations by ontology terms</article-title>
        <source>Nucleic Acids Res</source>
        <year>2003</year>
        <volume>31</volume>
        <issue>13</issue>
        <fpage>3799</fpage>
        <lpage>3803</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkg555</pub-id>
        <pub-id pub-id-type="pmid">12824422</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vinga</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Almeida</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Alignment-free sequence comparison-a review</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <issue>4</issue>
        <fpage>513</fpage>
        <lpage>523</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg005</pub-id>
        <pub-id pub-id-type="pmid">12611807</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lingner</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Meinicke</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Remote homology detection based on oligomer distances</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>18</issue>
        <fpage>2224</fpage>
        <lpage>2231</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl376</pub-id>
        <pub-id pub-id-type="pmid">16837522</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Mehta</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein function using protein-protein interaction data</article-title>
        <source>J Comput Biol</source>
        <year>2003</year>
        <volume>10</volume>
        <issue>6</issue>
        <fpage>947</fpage>
        <lpage>960</lpage>
        <pub-id pub-id-type="doi">10.1089/106652703322756168</pub-id>
        <pub-id pub-id-type="pmid">14980019</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Letovsky</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kasif</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Predicting protein function from protein/protein interaction data: a probabilistic approach</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <issue>suppl-1</issue>
        <fpage>197</fpage>
        <lpage>204</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg1026</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chua</surname>
            <given-names>HN</given-names>
          </name>
          <name>
            <surname>Sung</surname>
            <given-names>W-K</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Exploiting indirect neighbours and topological weight to predict protein function from protein-protein interactions</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>13</issue>
        <fpage>1623</fpage>
        <lpage>1630</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl145</pub-id>
        <pub-id pub-id-type="pmid">16632496</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>ZL</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>YZ</given-names>
          </name>
        </person-group>
        <article-title>SVM-Prot: web-based support vector machine software for functional classification of a protein from its primary sequence</article-title>
        <source>Nucleic Acids Res</source>
        <year>2003</year>
        <volume>31</volume>
        <issue>13</issue>
        <fpage>3692</fpage>
        <lpage>3697</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkg600</pub-id>
        <pub-id pub-id-type="pmid">12824396</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaakkola</surname>
            <given-names>TS</given-names>
          </name>
          <name>
            <surname>Diekhans</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Haussler</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Using the Fisher kernel method to detect remote protein homologies</article-title>
        <source>ISMB</source>
        <year>1999</year>
        <volume>99</volume>
        <fpage>149</fpage>
        <lpage>158</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <article-title>Combining pairwise sequence similarity and support vector machines for detecting remote protein evolutionary and structural relationships</article-title>
        <source>J Comput Biol</source>
        <year>2003</year>
        <volume>10</volume>
        <issue>6</issue>
        <fpage>857</fpage>
        <lpage>868</lpage>
        <pub-id pub-id-type="doi">10.1089/106652703322756113</pub-id>
        <pub-id pub-id-type="pmid">14980014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Djuric</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Vucetic</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>MS-k NN: protein function prediction by integrating multiple data sources</article-title>
        <source>BMC Bioinform</source>
        <year>2013</year>
        <volume>14</volume>
        <fpage>8</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-S3-S8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of functional effects for variants by combining gradient tree boosting with optimal neighborhood properties</article-title>
        <source>PLoS ONE</source>
        <year>2017</year>
        <volume>12</volume>
        <issue>6</issue>
        <fpage>0179314</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0179314</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dawson</surname>
            <given-names>NL</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>TE</given-names>
          </name>
          <name>
            <surname>Das</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lees</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ashford</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Orengo</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Sillitoe</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Cath: an expanded resource to predict protein function through structure and sequence</article-title>
        <source>Nucleic Acids Res</source>
        <year>2017</year>
        <volume>45</volume>
        <issue>D1</issue>
        <fpage>289</fpage>
        <lpage>295</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1098</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bergquist</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Kacsoh</surname>
            <given-names>BZ</given-names>
          </name>
          <name>
            <surname>Crocker</surname>
            <given-names>AW</given-names>
          </name>
          <name>
            <surname>Lewis</surname>
            <given-names>KA</given-names>
          </name>
          <name>
            <surname>Georghiou</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>HN</given-names>
          </name>
          <name>
            <surname>Hamid</surname>
            <given-names>MN</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The cafa challenge reports improved protein function prediction and new functional annotations for hundreds of genes through experimental screens</article-title>
        <source>Genome Biol</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>23</lpage>
        <pub-id pub-id-type="doi">10.1186/gb-2013-14-1-r1</pub-id>
        <pub-id pub-id-type="pmid">30606230</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ashburner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ball</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Blake</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Botstein</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Butler</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Cherry</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Dolinski</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Dwight</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Eppig</surname>
            <given-names>JT</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gene ontology: tool for the unification of biology</article-title>
        <source>Nat Genet</source>
        <year>2000</year>
        <volume>25</volume>
        <issue>1</issue>
        <fpage>25</fpage>
        <lpage>29</lpage>
        <pub-id pub-id-type="doi">10.1038/75556</pub-id>
        <pub-id pub-id-type="pmid">10802651</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>You</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Mamitsuka</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Golabeler: improving sequence-based large-scale protein function prediction by learning to rank</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>14</issue>
        <fpage>2465</fpage>
        <lpage>2473</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty130</pub-id>
        <pub-id pub-id-type="pmid">29522145</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Törönen P, Holm L. Pannzer-a practical tool for protein function prediction. Protein Sci. 2021;</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scheibenreif</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Littmann</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Orengo</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Funfam protein families improve residue level molecular function prediction</article-title>
        <source>BMC Bioinform</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-2988-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Freitas</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Chan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>ProLanGO: protein function prediction using neural machine translation based on a recurrent neural network</article-title>
        <source>Molecules</source>
        <year>2017</year>
        <volume>22</volume>
        <issue>10</issue>
        <fpage>1732</fpage>
        <pub-id pub-id-type="doi">10.3390/molecules22101732</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Strodthoff</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Wagner</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wenzel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Samek</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Udsmprot: universal deep sequence models for protein classification</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>8</issue>
        <fpage>2401</fpage>
        <lpage>2409</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa003</pub-id>
        <pub-id pub-id-type="pmid">31913448</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Seo</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Oh</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>DeepFam: deep learning based alignment-free method for protein family modeling and prediction</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>13</issue>
        <fpage>254</fpage>
        <lpage>262</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty275</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Galperin</surname>
            <given-names>MY</given-names>
          </name>
          <name>
            <surname>Makarova</surname>
            <given-names>KS</given-names>
          </name>
          <name>
            <surname>Wolf</surname>
            <given-names>YI</given-names>
          </name>
          <name>
            <surname>Koonin</surname>
            <given-names>EV</given-names>
          </name>
        </person-group>
        <article-title>Expanded microbial genome coverage and improved protein family annotation in the cog database</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>D1</issue>
        <fpage>261</fpage>
        <lpage>269</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku1223</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Davies</surname>
            <given-names>MN</given-names>
          </name>
          <name>
            <surname>Secker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Freitas</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Mendao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Timmis</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Flower</surname>
            <given-names>DR</given-names>
          </name>
        </person-group>
        <article-title>On the hierarchical classification of g protein-coupled receptors</article-title>
        <source>Bioinformatics</source>
        <year>2007</year>
        <volume>23</volume>
        <issue>23</issue>
        <fpage>3113</fpage>
        <lpage>3118</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm506</pub-id>
        <pub-id pub-id-type="pmid">17956878</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bateman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Coggill</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Finn</surname>
            <given-names>RD</given-names>
          </name>
        </person-group>
        <article-title>Dufs: families in search of function</article-title>
        <source>Acta Crystallogr Sect F Struct Biol Cryst Commun</source>
        <year>2010</year>
        <volume>66</volume>
        <issue>10</issue>
        <fpage>1148</fpage>
        <lpage>1152</lpage>
        <pub-id pub-id-type="doi">10.1107/S1744309110001685</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Fassler J, Cooper P. BLAST glossary. BLAST® Help, 2011.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Finn</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Clements</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Eddy</surname>
            <given-names>SR</given-names>
          </name>
        </person-group>
        <article-title>HMMER web server: interactive sequence similarity searching</article-title>
        <source>Nucleic Acids Res</source>
        <year>2011</year>
        <volume>39</volume>
        <issue>suppl-2</issue>
        <fpage>29</fpage>
        <lpage>37</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr367</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sievers</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wilm</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dineen</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Gibson</surname>
            <given-names>TJ</given-names>
          </name>
          <name>
            <surname>Karplus</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lopez</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>McWilliam</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Remmert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Fast, scalable generation of high-quality protein multiple sequence alignments using Clustal Omega</article-title>
        <source>Mol Syst Biol</source>
        <year>2011</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>539</fpage>
        <pub-id pub-id-type="doi">10.1038/msb.2011.75</pub-id>
        <pub-id pub-id-type="pmid">21988835</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Potter</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Luciani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Eddy</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lopez</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Finn</surname>
            <given-names>RD</given-names>
          </name>
        </person-group>
        <article-title>HMMER web server: 2018 update</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>46</volume>
        <issue>W1</issue>
        <fpage>200</fpage>
        <lpage>204</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky448</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
