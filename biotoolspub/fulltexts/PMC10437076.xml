<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Plant Sci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Plant Sci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Plant Sci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Plant Science</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-462X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10437076</article-id>
    <article-id pub-id-type="doi">10.3389/fpls.2023.1207139</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Plant Science</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>G2P Provides an Integrative Environment for Multi-model genomic selection analysis to improve genotype-to-phenotype prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Qian</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn003" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2293826"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Shan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn003" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2152430"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Tong</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2171842"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Qiu</surname>
          <given-names>Zhixu</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/442036"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Jun</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1835978"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fu</surname>
          <given-names>Ran</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2152424"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ma</surname>
          <given-names>Chuang</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/78201"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Xiangfeng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Jiang</surname>
          <given-names>Shuqin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>*</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Cheng</surname>
          <given-names>Qian</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>*</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2146013"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Frontiers Science Center for Molecular Design Breeding, China Agricultural University</institution>, <addr-line>Beijing</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>National Maize Improvement Center of China, College of Agriculture and Biotechnology, China Agricultural University</institution>, <addr-line>Beijing</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&amp;F University</institution>, <addr-line>Yangling, Shaanxi</addr-line>, <country>China</country></aff>
    <aff id="aff4"><sup>4</sup><institution>State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&amp;F University</institution>, <addr-line>Shaanxi, Yangling</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Achraf El Allali, Mohammed VI Polytechnic University, Morocco</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Xinhao Ouyang, Xiamen University, China; Rodrigo R. Amadeu, Bayer Crop Science, United States; Morad M. Mokhtar, University Mohammed VI Polytechnic, Morocco</p>
      </fn>
      <corresp id="fn001">*Correspondence: Shuqin Jiang, <email xlink:href="mailto:wanshi0066@126.com">wanshi0066@126.com</email>; Qian Cheng, <email xlink:href="mailto:qchengray@cau.edu.cn">qchengray@cau.edu.cn</email>
</corresp>
      <fn fn-type="equal" id="fn003">
        <p>†These authors have contributed equally to this work</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>04</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>1207139</elocation-id>
    <history>
      <date date-type="received">
        <day>17</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>7</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Wang, Jiang, Li, Qiu, Yan, Fu, Ma, Wang, Jiang and Cheng</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Wang, Jiang, Li, Qiu, Yan, Fu, Ma, Wang, Jiang and Cheng</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Genotype-to-phenotype (G2P) prediction has become a mainstream paradigm to facilitate genomic selection (GS)-assisted breeding in the seed industry. Many methods have been introduced for building GS models, but their prediction precision may vary depending on species and specific traits. Therefore, evaluation of multiple models and selection of the appropriate one is crucial to effective GS analysis. Here, we present the G2P container developed for the Singularity platform, which not only contains a library of 16 state-of-the-art GS models and 13 evaluation metrics. G2P works as an integrative environment offering comprehensive, unbiased evaluation analyses of the 16 GS models, which may be run in parallel on high-performance computing clusters. Based on the evaluation outcome, G2P performs auto-ensemble algorithms that not only can automatically select the most precise models but also can integrate prediction results from multiple models. This functionality should further improve the precision of G2P prediction. Another noteworthy function is the refinement design of the training set, in which G2P optimizes the training set based on the genetic diversity analysis of a studied population. Although the training samples in the optimized set are fewer than in the original set, the prediction precision is almost equivalent to that obtained when using the whole set. This functionality is quite useful in practice, as it reduces the cost of phenotyping when constructing training population. The G2P container and source codes are freely accessible at <ext-link xlink:href="https://g2p-env.github.io/" ext-link-type="uri">https://g2p-env.github.io/</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>genomic selection</kwd>
      <kwd>genotype-to-phenotype prediction</kwd>
      <kwd>singularity container</kwd>
      <kwd>crop breeding</kwd>
      <kwd>multi-model integration</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">
          <institution-wrap>
            <institution>Chinese Universities Scientific Fund
</institution>
            <institution-id institution-id-type="doi">10.13039/501100005236</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <funding-statement>This work was supported by the Hainan Yazhou Bay Seed Laboratory (B21HJ0505), the Chinese Universities Scientific Fund (2022TC139) and the 2115 Talent Development Program of China Agricultural University.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="2"/>
      <equation-count count="0"/>
      <ref-count count="42"/>
      <page-count count="13"/>
      <word-count count="6690"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>section-in-acceptance</meta-name>
        <meta-value>Plant Bioinformatics</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>Genomic selection (GS) is the process of genomically estimating breeding values based on genotype-to-phenotype (G2P) prediction and was originally utilized in animal breeding for estimating the breeding values of untested individuals by analyzing the genotype of a sample (<xref rid="B25" ref-type="bibr">Meuwissen et al., 2001</xref>). Recently, GS has been proposed as a promising approach for crop breeding as the dramatic decrease of genotyping expense (<xref rid="B16" ref-type="bibr">Jannink et al., 2010</xref>; <xref rid="B13" ref-type="bibr">Hickey et al., 2019</xref>). The core idea of GS is to predict phenotypes from genotypes of breeding individuals, allowing a breeder to select the best genetic material to produce a desired phenotype. Therefore, GS as a revolutionary method of precision breeding offers multiple advantages over traditional breeding: it greatly shortens the breeding cycle; it reduces the cost of phenotyping; and it allows more genetic gains per unit time (<xref rid="B16" ref-type="bibr">Jannink et al., 2010</xref>; <xref rid="B13" ref-type="bibr">Hickey et al., 2019</xref>; <xref rid="B39" ref-type="bibr">Yan and Wang, 2022a</xref>). Recently, successful applications of GS in crop breeding have been reported in a variety of crops such as maize, barley, wheat, rice, soybean and rapeseed (<xref rid="B42" ref-type="bibr">Zhao et al., 2012</xref>; <xref rid="B27" ref-type="bibr">Nielsen et al., 2016</xref>; <xref rid="B2" ref-type="bibr">Belamkar et al., 2018</xref>; <xref rid="B19" ref-type="bibr">Kumar et al., 2019</xref>; <xref rid="B36" ref-type="bibr">Wang et al., 2021</xref>; <xref rid="B14" ref-type="bibr">Hu et al., 2022</xref>).</p>
    <p>Despite the great potential of GS-assisted breeding, its broad application in crops has been impeded by the complex situation in crop breeding. For instance, multiple statistical, Bayesian, and machine learning (ML) algorithms have been developed to construct GS models in crops, but prediction precisions may vary when applying different models on different species and traits to certain degrees (<xref rid="B12" ref-type="bibr">Heffner et al., 2011</xref>; <xref rid="B29" ref-type="bibr">Ornella et al., 2014</xref>; <xref rid="B40" ref-type="bibr">Yan et al., 2021</xref>). This is because prediction accuracy is influenced by many factors, including the size of training and testing samples, the genetic structure of the breeding population, the density of whole-genome marks, the heritability of target traits, and the span of linkage disequilibrium (<xref rid="B37" ref-type="bibr">Wray et al., 2013</xref>). Therefore, to ensure the effectiveness of GS prediction, it is crucial to select the most appropriate GS model based on a comprehensive evaluation of all the methods using optimized parameters from a model library.</p>
    <p>Data as of 2021, many GS packages have been developed, such as “rrBLUP” for ridge regression best linear unbiased predictor model (RRBLUP), “BGLR” for various Bayesian models (e.g. Bayes A, Bayes B, Bayes C and etc.), and “spls” for sparse partial least squares regression model (SPLS), as well as many ML-based methods (<xref rid="B9" ref-type="bibr">Endelman, 2011</xref>; <xref rid="B6" ref-type="bibr">Colombani et al., 2012</xref>; <xref rid="B3" ref-type="bibr">Blondel et al., 2015</xref>; <xref rid="B40" ref-type="bibr">Yan et al., 2021</xref>). Although these packages and tools have been used for GS breeding in plants, an integrated environment containing the publically available GS tools may greatly ease the process of users to conduct a sufficient comparative evaluation of GS models (<xref rid="B38" ref-type="bibr">Xu et al., 2021</xref>). Additionally, most current tools do not support streamlined pipelines of data preprocessing, model selection and performance evaluation. Data preprocessing is a tedious and complicated process, including data format conversion, data quality control, as well as partition of training and testing samples. Performance evaluation requires complicated fine-tuning of model parameters and objective evaluation with an array of different metrics, such as Pearson correlation coefficient (<italic>r</italic>), Mean square error (MSE). Through these two critical steps, the best models with optimized parameters can then be selected to use for GS-assisted breeding. Because many tools must be configured differently to meet the requirement of specific computing environments, comparative evaluation of different GS models is a complicated process. The Singularity platform, developed as a scientific container for cloud computing, can easily package up tools and software to run in reproducible environments (<xref rid="B20" ref-type="bibr">Kurtzer et al., 2017</xref>). Singularity has been utilized to set up cloud computing environments for many bioinformatics tools and pipelines (<xref rid="B15" ref-type="bibr">Iacoangeli et al., 2019</xref>; <xref rid="B11" ref-type="bibr">Garofoli et al., 2019</xref>; <xref rid="B41" ref-type="bibr">Youens-Clark et al., 2019</xref>). Therefore, it provides a promising means to integrate a library of GS models, tools and preconfigured pipelines for streamlined GS analysis. With such an integrated environment, users not only can easily install and run all kinds of GS models, but also can perform streamlined GS analyses without needing advanced programming skills.</p>
    <p>In this study, we present the G2P container, developed based on the Singularity platform to serve as a reproducible environment allowing users to perform streamlined GS analysis, including data preprocessing, model construction, and model evaluation. It also allows automatic integration of prediction results to simplify the GS analysis. The library contains up to 16 state-of-the-art GS models and 13 evaluation metrics, which are integrated into a uniform framework to flexibly and conveniently call GS models for comparative evaluation. Moreover, the container-based characteristics of G2P will greatly ease the way for a bioinformatics personnel or population geneticist to perform GS analysis, especially for the situation involving comparative evaluation of multiple GS methods. G2P is not only available as a container, but also can be installed and used as a regular R package. Here, we demonstrate the features and utility of G2P through analysis of a large maize population (CUBIC) comprising 1,404 genotyped inbred lines with three phenotypes (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>; <xref rid="B24" ref-type="bibr">Luo et al., 2020</xref>).</p>
  </sec>
  <sec id="s2">
    <title>Methods</title>
    <sec id="s2_1">
      <title>Overall structure of the G2P container</title>
      <p>The G2P container has two main components. The first comprises stand-alone software and dependent libraries, offering the environment for running G2P (<xref rid="f1" ref-type="fig"><bold>Figure 1A</bold></xref>). The second component comprises the R package of G2P, containing the main modules required for GS analysis (<xref rid="f1" ref-type="fig"><bold>Figure 1B</bold></xref>). This consists of four main analytical modules that function as a streamlined pipeline, for preprocessing of genotype and phenotype data (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary materials</bold></xref>), evaluation of the 16 models in the library, integration of prediction results from multiple models, and refinement of training datasets.</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>Overview of the G2P singularity container. <bold>(A)</bold> Systems environment setup of the G2P container. The upper semicircle contains several stand-alone software programs (capital letters) for GS related analysis and offering a running environment for the G2P functions (italics) in the lower semicircle. The operating system and computing environment for the G2P container are shown on the circle. <bold>(B)</bold> The four main functional modules of the G2P package, with the main functions of each module highlighted in italics.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g001" position="float"/>
      </fig>
    </sec>
    <sec id="s2_2">
      <title>Parallel evaluation of GS models</title>
      <p>The G2P library currently contains 16 models that have been previously used in plant breeding: 14 regression-based models and two classification-based models (<xref rid="T1" ref-type="table"><bold>Table 1</bold></xref>). Streamlined pipelines for running these models are integrated into the “G2P” module, which is the core function of the G2P container. A user may specify the models from the library, and the selected models can be simultaneously constructed by setting the parameter “modelMethods” of the “G2P” module. To evaluate the prediction precision of the selected models, 13 evaluation metrics can be called by the function of “G2PEvaluation” (<xref rid="T2" ref-type="table"><bold>Table 2</bold></xref>). The 13 evaluation metrics can be classified into two categories: there are five metrics for correlation-based evaluation and eight metrics for threshold-based evaluation. The first five metrics measure the global similarity between predicted and observed phenotypic values with a variety of algorithms to compute correlation, and the remaining eight assess the model precision by examining the proportion of predicted top samples among the actual top samples with user-specified top 10%, 15%, 20%, or 30% of expected phenotypic values (<xref rid="B21" ref-type="bibr">Li et al., 2023</xref>).</p>
      <table-wrap position="float" id="T1">
        <label>Table 1</label>
        <caption>
          <p>Characteristics of the 16 GS models integrated in G2P.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="middle" align="left" rowspan="1" colspan="1">Model</th>
              <th valign="middle" align="left" rowspan="1" colspan="1">Feature</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Package</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Refs</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th valign="middle" colspan="4" align="left" rowspan="1">GS models based on regression</th>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayes A</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Scaled <italic>t</italic>-distribution for marker effects, inverse chi-square on marker variance</td>
              <td valign="top" rowspan="6" align="center" colspan="1">BGLR</td>
              <td valign="top" rowspan="6" align="center" colspan="1">(<xref rid="B8" ref-type="bibr">de los Campos and Pérez, 2015</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayes B</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Similar to Bayes A; utilizes both shrinkage and variable selection method</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayes C</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Characterized by a Gaussian distribution</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayesian LASSO (BL)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Marker variances resulting in a double exponential (DE) distribution</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayesian ridge regression (BRR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Induces homogeneous shrinkage of all marker effects towards zero; marker effect yields a Gaussian distribution</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Reproducing kernel Hilbert space (RKHS)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Effective for detecting nonadditive gene effects</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Ridge regression (RR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Normal distribution for marker effects and nonzero</td>
              <td valign="top" rowspan="2" align="center" colspan="1">rrBLUP</td>
              <td valign="top" rowspan="2" align="center" colspan="1">(<xref rid="B9" ref-type="bibr">Endelman, 2011</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Ridge regression best linear unbiased prediction (RRBLUP)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Assumes all markers have equal variances with small and nonzero effect</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">big ridge regression (bigRR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">An extension and optimization of ridge regression</td>
              <td valign="top" align="center" rowspan="1" colspan="1">hglm</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B32" ref-type="bibr">Rönnegård et al., 2010</xref>; <xref rid="B35" ref-type="bibr">Shen et al., 2013</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Least absolute shrinkage and selection operator (LASSO)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Combine both shrinkage and variable selection method</td>
              <td valign="top" align="center" rowspan="1" colspan="1">glmnet</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B10" ref-type="bibr">Friedman et al., 2010</xref>; <xref rid="B28" ref-type="bibr">Ogutu et al., 2012</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Sparse partial least squares (SPLS)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Combining variable selection and modeling in a one-step procedure</td>
              <td valign="top" align="center" rowspan="1" colspan="1">spls</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B5" ref-type="bibr">Chung et al., 2012</xref>; <xref rid="B6" ref-type="bibr">Colombani et al., 2012</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Support vector regression (SVR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Finds an appropriate line (or hyperplane in higher dimensions) to fit the data</td>
              <td valign="top" align="center" rowspan="1" colspan="1">e1071</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B7" ref-type="bibr">Cortes and Vapnik, 1995</xref>; <xref rid="B26" ref-type="bibr">Meyer et al., 2014</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Random forest regression (RFR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Uses the regression model rooted in bootstrapping sample observations</td>
              <td valign="top" align="center" rowspan="1" colspan="1">randomForest</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B4" ref-type="bibr">Breiman, 2001</xref>; <xref rid="B22" ref-type="bibr">Liaw and Wiener, 2002</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayesian regularization neural networks (BRNN)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Connects two hidden layers of opposite directions to the same output</td>
              <td valign="top" align="center" rowspan="1" colspan="1">brnn</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B31" ref-type="bibr">Rodriguez and Flores-Mara, 2019</xref>)</td>
            </tr>
            <tr>
              <th valign="middle" colspan="3" align="left" rowspan="1">GS models based on classification</th>
              <th valign="middle" align="center" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Support vector classification (SVC)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Finds an optimal boundary between the possible outputs</td>
              <td valign="top" align="center" rowspan="1" colspan="1">e1071</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B7" ref-type="bibr">Cortes and Vapnik, 1995</xref>; <xref rid="B26" ref-type="bibr">Meyer et al., 2014</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Random forest classification (RFC)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Uses bagging and feature randomness, consisting of many decision trees</td>
              <td valign="top" align="center" rowspan="1" colspan="1">randomForest</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B4" ref-type="bibr">Breiman, 2001</xref>; <xref rid="B22" ref-type="bibr">Liaw and Wiener, 2002</xref>)</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap position="float" id="T2">
        <label>Table 2</label>
        <caption>
          <p>Descriptions of the 13 evaluation metrics integrated in G2P.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="middle" align="left" rowspan="1" colspan="1">Evaluation Metrics</th>
              <th valign="middle" align="left" rowspan="1" colspan="1">Description</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Range</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th valign="middle" colspan="3" align="left" rowspan="1">(I) Correlation-based global metrics</th>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Pearson correlation coefficient (PCC, <italic>r</italic>, <italic>R</italic>)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Strength and direction of the linear relationship between <italic>X<sup>a</sup>
</italic> and <italic>Y<sup>b</sup>
</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Kendall rank correlation coefficient (KCC, tau, τ)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Ordinal association between <italic>X</italic> and <italic>Y</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Spearman rank correlation coefficient (SCC, rho, ρ)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Indicator of how well the relationship between <italic>X</italic> and <italic>Y</italic> can be described using a monotonic function</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Coefficient of determination, <italic>R</italic> squared (<italic>R</italic>
<sup>2</sup>, <italic>r</italic>
<sup>2</sup>)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Evaluating the goodness of fit of <italic>X</italic> and <italic>Y</italic> of linear regression</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Mean squared error (MSE)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Average squared difference between <italic>X</italic> and <italic>Y</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, +∞)</td>
            </tr>
            <tr>
              <th valign="middle" colspan="3" align="left" rowspan="1">(II) Threshold-based metrics</th>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Normalized discounted cumulative gain (NDCG)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Evaluating the prediction ability for selecting individuals that have top-ranked phenotypic values</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Mean normalized discounted cumulative gain (mean NDCG)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Mean of NDCG scores from <italic>k</italic> = 1 to <italic>k = K<sup>c</sup>
</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Relative efficiency (RE)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Expected gains when top <italic>k</italic> individuals are selected</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Accuracy</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Proportion of correctly classified individuals among <italic>K</italic>, for evaluating classification performance</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">F-score</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Balance between precision and recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the receiver operating characteristic curve (AUC)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the receiver operating characteristic curve, for evaluating classification performance</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the precision-recall curve (AUCpr)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the precision-recall curve, for evaluating classification performance</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Cohen’s kappa coefficient (Kappa)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Evaluating the agreement between <italic>X</italic> and <italic>Y</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <label>a</label>
            <p>Observed phenotype. <sup>b</sup>Predicted phenotype. <sup>c</sup>Total number of predicted individuals.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Comparative evaluation of multiple GS methods using a cross-validation (CV) scheme can be executed by the module “G2PcrossValidation,” and this may also facilitate the selection of the optimal parameters to achieve the best model performance. Because multiple GS models and numerous folds of CV are simultaneously evaluated, “G2PCrossValidation” is also empowered with parallel computation on high-performance computing clusters to accelerate the computing efficiency. It is also worth noting that both the “G2P” and “G2PCrossValidation” modules allow users to construct more complex models by including other information besides genotypes. After a comprehensive evaluation of the GS models in the library of G2P, the final result of the evaluated GS models is presented so that users may select the most appropriate model or models for selecting breeding materials.</p>
    </sec>
    <sec id="s2_3">
      <title>Integration of multi-model prediction results</title>
      <p>Because no single model works best for all species and traits, aggregating the results from multiple GS models will further improve the precision of phenotype prediction. G2P offers two strategies, GSMerge and GSEnsemble, to integrate multi-model results, using the functions “GSMerge” and “GSEnsemble,” respectively. The development of the GSMerge algorithm adopted the idea of maximal accuracy–maximal difference (MAMD) based on the evaluation results of different models. First, after phenotype prediction, a matrix of predicted phenotypes multiplying GS models is constructed. Second, the models are ranked based on their overall prediction precision evaluated by one metric (e.g., Pearson correlation coefficient) to generate a ranking, <italic>r1</italic>, and the top model is selected. Third, predicted phenotypic values of the top model are extracted, and then the correlations of its values with the values predicted by the other models are calculated. This generates a new ranking, <italic>r2</italic>. Fourth, the difference between the rankings <italic>r1</italic> and <italic>r2</italic> is calculated, and then a second model is selected that shows not only the best prediction precision but also the maximal difference from the top model. Finally, a new value is computed as the integrated prediction results from averaging the predicted values of the two selected models. In addition to this automatic integration process, the “GSMerge” function can also execute self-defined integration with provided weights from “GSEnsemble” described below or own experience.</p>
      <p>GSEnsemble adopts another strategy, which is to perform multiple rounds of iteration and repetition to integrate multi-model results. GSEnsemble takes the same matrix of prediction results from multi-model analysis as the initial input, and then a list of initial weights computed based on the evaluation of model precision is automatically generated. Subsequently, the self-defined GSMerge integration procedure is applied to the two models that are to be integrated. The difference is that GSEnsemble integrates results by considering the more possible weights of the two models instead of simply averaging the results from the two models. Then, after evaluation and selection, the new result from the first two models is merged with the result from the third model and the corresponding weights are recorded. These integration steps are repeated until the results from all of the models are applied to the iteration and a list of optimal weights is finally generated. It is worth noting that, rather than using one weight combination, GSEnsemble allows users to define the time of repetitions (i.e. the order in which the various models are integrated) to shuffle the input of the result matrix and obtain a weight matrix. Therefore, every set of weight combinations can be used to compute a grand phenotypic value using weighted prediction results of all the GS models in the library. Simply speaking, the fundamental difference between GSMerge and GSEnsemble is that GSEnsemble first generates a list of the optimal combinations of models and weights by a series of iterations and then computes the grand value based on the weighted results of all of the models. However, GSEnsemble processing is slower than GSMerge processing for large training populations.</p>
    </sec>
    <sec id="s2_4">
      <title>Refinement design of training dataset</title>
      <p>Compilation of an appropriate training set is extremely important for model precision and robustness, as the training set should offer sufficient genetic diversity and coverage in sample prediction. Otherwise, it may cause problematic either underfitting or overfitting issues. With the accumulation of more and more samples that are both genotyped and phenotyped, the training dataset will be refined by both selecting representative samples and removing redundant samples. G2P offers the module “TSRefine” to allow both reference-free and reference-guided algorithms to refine the training dataset. The reference-free algorithm uses the concept of the minimum moment aberration (MMA) algorithm to select a subset of candidates with the maximum discrepancy of genotypes. MMA measures the discrepancy between two individuals in their marker genotypes by averaging all pairwise similarities (<xref rid="B18" ref-type="bibr">Jin et al., 2004</xref>; <xref rid="B34" ref-type="bibr">Sen et al., 2007</xref>). In this manner, the refined training dataset may present more representative genetic diversity than the original training set. A reference-free algorithm is preferable when genotypes are difficult to obtain. In contrast, the reference-guided algorithm utilizes the testing dataset as a reference. Through the construction of two matrices of genomic relationship, one within the training set and another between individuals in the testing set with the training set. Also, three alternative criteria, “PEVmean,” “CDmean,” and “Sim,” are used as measurable criteria to seek the optimal solution until the iteration becomes stable (<xref rid="B1" ref-type="bibr">Akdemir et al., 2015</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3_1">
      <title>Demo datasets for developing the G2P container</title>
      <p>To illustrate the utility and performance of the G2P container, we used a previously published dataset of maize inbred lines, the Complete-diallel plus unbalanced breeding-derived inter-cross (CUBIC) population, for testing (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>). The CUBIC population contains 1,404 recombinant lines produced from 24 elite inbred lines that have been widely used for maize breeding in China (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>; <xref rid="B24" ref-type="bibr">Luo et al., 2020</xref>). The raw genotypic data, in the binary PLINK format, of the 1,404 lines contains 14 million single-nucleotide polymorphisms (SNPs) called from the whole-genome resequencing of the CUBIC population. The phenotypes used as the target traits for GS prediction include days to tassel (DTT), plant height (PH), and ear weight (EW), representing the three critical developmental stages of maize development. We focused on EW because it is an important trait for evaluating maize yield and one of the most complex and difficult traits to predict due to its low heritability. Members of the CUBIC population were planted in five ecological regions to collect raw phenotypic data, which were further analyzed by the best linear unbiased predictor (BLUP) model to remove variation caused by environmental effects. The original datasets and the details of genotype and phenotype collection and processing can be found at the website <ext-link xlink:href="http://cubicmaize.hzau.edu.cn" ext-link-type="uri">http://cubicmaize.hzau.edu.cn</ext-link> and in the original research articles (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>; <xref rid="B24" ref-type="bibr">Luo et al., 2020</xref>).</p>
    </sec>
    <sec id="s3_2">
      <title>Parallel evaluation of the 16 GS models using 13 evaluation metrics</title>
      <p>Subsequently, the 1,000 training samples in the CV-dataset were used for comparison with the 16 GS models in the library using the 13 evaluation metrics by 5-fold CVs with 50 replications (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 1</bold></xref>). As we expected, the 16 GS models showed greatly varied prediction precisions for the three traits. The RFR, Bayes B, and RRBLUP methods achieved the best performance using the most evaluation metrics when predicting EW, DTT, and PH phenotypes (<xref rid="f2" ref-type="fig"><bold>Figure 2A</bold></xref>). For both datasets, the 16 GS models yielded varying precision, with Pearson correlation coefficient (<italic>r</italic>) values ranging from 0.323 to 0.443 when predicting EW (<xref rid="f2" ref-type="fig"><bold>Figures 2B, C</bold></xref>). Among them, the RFR model ranked as the best method, as it achieved the best performance using all five of the correlation-based methods. Bayes B was the best choice if using metrics to predict the top 30% of samples (<xref rid="f2" ref-type="fig"><bold>Figure 2A</bold></xref>). For the other two traits, Bayes A and BL were the top two models for predicting DTT, while Bayes A and Bayes B were the top two for predicting PH (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 2</bold></xref>). This result is consistent with the previous reports that no single method is best for all species and traits, such that careful model selection is critical for effective GS-assisted breeding (<xref rid="B29" ref-type="bibr">Ornella et al., 2014</xref>; <xref rid="B40" ref-type="bibr">Yan et al., 2021</xref>; <xref rid="B30" ref-type="bibr">Robert et al., 2022</xref>). It also highlights the need to integrate the results from multiple evaluation metrics to achieve unbiased selection of the optimal GS models for a specific target trait in a designated species.</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>Parallel evaluation of the GS models. <bold>(A)</bold> The ranks of prediction precisions for days to tasseling (DTT), plant height (PH), and ear weight (EW) of 1,404 maize inbred lines on the CV-dataset and Test-dataset by the 16 GS models with 13 evaluation metrics. <bold>(B, C)</bold> Prediction precision for the EW trait using the 16 GS models. DTT and PH were considered as fixed effects, and the 9,286 SNPs were considered as random effects, on the CV-dataset and Test-dataset, respectively. The precision was evaluated based on the Pearson correlation coefficient (<italic>r</italic>).</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g002" position="float"/>
      </fig>
      <p>Perhaps one of the most important factors affecting model performance is the sample size of the training population (<xref rid="B37" ref-type="bibr">Wray et al., 2013</xref>; <xref rid="B17" ref-type="bibr">Jiang et al., 2020</xref>). To address this, G2P offers an optional function of inferring the optimal population size for model training by using different gradients of the numbers of training samples set by the users. In our demo analysis, we gradually expanded the training set from 200 to 1,000 samples, and then visualized the prediction precision of the 16 models in terms of the Pearson correlation coefficient (<italic>r</italic>) of the three traits with boxplots and line charts (<xref rid="SF1" ref-type="supplementary-material"><bold>Supplementary Figure 1</bold></xref>). Overall, all three traits showed a similar trend whereby the prediction precision of the 16 models gradually improved with the expansion of the training set—for DTT, from 0.429 to 0.603; for PH, from 0.453 to 0.619; and for EW, from 0.280 to 0.478. Furthermore, because considering additional fixed effects in a GS model may also improve prediction precision (<xref rid="B33" ref-type="bibr">Sarinelli et al., 2019</xref>), G2P allows users to add customized fixed effects to the GS model. In the demo analysis, we utilized DTT and PH as fixed effects in addition to the 9,286 SNPs and then performed 5-fold CV with 50 replicates on both the CV-dataset and Test-dataset to evaluate the models (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 3</bold></xref>). In comparison with the results generated from the model only using SNPs as random effects, the prediction precisions of 14 of the 16 models (the exceptions being RR and bigRR) were elevated. Among them, SPLS and LASSO showed the greatest improvement, increasing by 0.066 (<italic>r</italic>: 0.330 to 0.396) and 0.062 (<italic>r</italic>: 0.465 to 0.527) accuracy, respectively (<xref rid="f2" ref-type="fig"><bold>Figures 2B, C</bold></xref>). It is also worth mentioning that G2P allows batch submission of the 16 GS models and the 13 evaluation metrics for parallel evaluation if a cluster of high-performance computers is available. This functionality offers the greatest convenience to the users for comparative evaluation of GS models to assist selection of the optimal GS models.</p>
    </sec>
    <sec id="s3_3">
      <title>A benchmark test of analytical efficiency of the 16 models</title>
      <p>In addition to prediction precision, analytical efficiency is another important factor to consider, especially when the sizes of samples and features are large. G2P records the CPU run time and memory usage when performing model evaluation. In this study, we used the benchmark test to evaluate the analytical efficiency of the 16 GS models under the G2P Singularity environment on a Windows desktop with a configuration of 4-core CPU i5 6600K and 32 GB memory. The benchmark test was performed on the Test-dataset containing the 1,000 samples to record CPU run time and memory usage, and this process was repeated ten times to calculate the average efficiency.</p>
      <p>The averaged run times of the 16 models varied greatly (<xref rid="f3" ref-type="fig"><bold>Figure 3A</bold></xref>). The top three methods were SPLS, RRBLUP and RR, with run times of less than 3.5 seconds. BRR, Bayes A, B and C, and BL needed less than 20 seconds, and the other 8 methods all took more than 100 seconds. It is worth mentioning that, although RFR achieved the best precision when predicting EW, it took the longest, at 529.9 seconds. Memory usage was evaluated using a method called multiple (×) of initial data memory usage, which was 50.54 Mb when the entire dataset was loaded into memory. If no fixed effect was added, SPLS, RRBLUP, RFR, LASSO, and RFC showed the lowest memory usage, below 10×, and the top four memory-usage models were BRNN, RR, RFC and RFR, using 41.56×, 20.44×, 18.05×, and 18.70× memory, respectively (<xref rid="f3" ref-type="fig"><bold>Figure 3B</bold></xref>). When fixed effects were added to the models, memory usage increased in all cases, but to different degrees for most of the models. Finally, we examined how the sample size and marker number influence CPU run time and memory usage of the 16 GS models, finding that both sample size and marker number were positively correlated with the computing resource for most models (<xref rid="f3" ref-type="fig"><bold>Figures 3C-F</bold></xref>). Especially for RFR and RRBLUP, CPU run time and memory usage of RFR were both linearly influenced by marker number and RFR was linearly influenced by sample size.</p>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>Benchmark test of the analytical efficiency of the 16 GS models. <bold>(A, B)</bold> Comparison of results after running the 16 GS models for training and prediction on the CV-dataset in terms of CPU run time <bold>(A)</bold> and memory usage <bold>(B)</bold>. CPU run time is indicated in seconds (s) and memory usage in multiple (×) of running memory over initial data memory. <bold>(C, D)</bold> Correlation of CPU run time with the number of training samples <bold>(C)</bold> and the number of SNPs <bold>(D)</bold>. <bold>(E, F)</bold> Correlation of memory usage in megabytes (MB) with the number of training samples <bold>(E)</bold> and the number of SNPs <bold>(F)</bold>.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g003" position="float"/>
      </fig>
    </sec>
    <sec id="s3_4">
      <title>Integration of multi-model prediction results</title>
      <p>Overall, the prediction precision varied from model to model, but certain models may generate similar predicted results. This is reflected in the pairwise correlations (ranging from 0.54 to 1.00) computed between the predicted phenotypic values by any pair of models. This indicates that complementary relationships may exist between certain GS models, which we may take advantage of to integrate multi-model prediction results. G2P offers two strategies for integrating predicted results from top-precision models, the GSMerge and GSEnsemble algorithms (<xref rid="f4" ref-type="fig"><bold>Figure 4A</bold></xref>). GSMerge automatically selects two top models with relatively high precision and considerable difference in output. It then directly averages the two sets of prediction results to generate a single integrated result. In contrast, GSEnsemble considers the results from all available models, after a search of a set of optimal weights by iteration and repetition, to generate a grand value by summarizing weighted values of all the models (See Methods).</p>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>Improvement of prediction precision for the EW (ear weight) trait through integration of multi-model results. <bold>(A)</bold> Schematic illustration of the algorithms for the two result integration functions. GSMerge selects models according to the difference of two ranks (ranks of prediction precision and ranks of correlation coefficients between top1 model and others). Integration results of GSMerge is the average of prediction results of two selected models. The deeper the color, the higher the correlation. By generating a weight list and executing GSMerge, GSEnsemble selects models and gets weights of models after multiple iterations and repetitions. Integration results of GSEnsemble is the weighted average of all models. <bold>(B)</bold> Prediction precisions by GSMerge- and GSEnsemble-based integration are better than those for the single model, BRR, with fixed effects considered on the CV-dataset. The prediction precision was evaluated based on the Pearson correlation coefficient (<italic>r</italic>). <bold>(C)</bold> After integrated combination and weights from the CV-dataset are utilized on predicting Test-dataset, prediction precisions for GSMerge- and GSEnsemble-based integration are improved relative to those predicted by the best single model, RKHS, with fixed effect considered. <bold>(D)</bold> The statistics for the frequency of models selected by the GSMerge strategy using 50 times 5-fold cross validation on the CV-dataset. <bold>(E)</bold> The statistics of the weights of the models used for GSEnsemble on the CV-dataset.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g004" position="float"/>
      </fig>
      <p>Within the CV-dataset, we tested the effectiveness of integration of multi-model predictions by the two algorithms for each fold of CV. As we anticipated, when considering fixed effects, both GSMerge and GSEnsemble strategies improved the precision of EW prediction compared to the single BRR model that was the best predictor, increasing the <italic>r</italic> value from 0.464 to 0.493 and 0.502, respectively (<xref rid="f4" ref-type="fig"><bold>Figure 4B</bold></xref>). Consistent results were also observed when fixed effects were not considered. The precisions of GSMerge and GSEnsemble also increased, from 0.443 (RFR model) to 0.445 and 0.465, respectively (<xref rid="SF2" ref-type="supplementary-material"><bold>Supplementary Figure 2A</bold></xref>). Furthermore, the frequency of models selected by GSMerge among the 50 times 5-fold (a total of 250 repetitions) were summarized to help direct model selection for integration of the prediction results for the Test-dataset (<xref rid="f4" ref-type="fig"><bold>Figure 4D</bold></xref>). For GSEnsemble, the mean weights of all 250 repetitions were calculated to obtain a set of weights of the models to further utilize GSEnsemble for integrating the results from the Test-dataset (<xref rid="f4" ref-type="fig"><bold>Figure 4E</bold></xref>). The same test of GSEnsemble-based integration was performed without fixed effects, and the outcome was consistent with the outcome when considering fixed effects (<xref rid="SF2" ref-type="supplementary-material"><bold>Supplementary Figure 2</bold></xref>). Therefore, the summarized results not only give the users a reference for integration of multi-model prediction, but also assist users in understanding which model contributes the most weight under results integration.</p>
      <p>To verify the effectiveness of prediction result integration, we used the two most commonly used models (RFR and BayesB) for GSMerge on the CV-dataset to perform GSMerge on the Test-dataset as well as mean weights list for GSEnsemble on the CV-dataset to perform GSEnsemble on the Test-dataset. As we anticipated, both the GSMerge and GSEnsemble algorithms improved the prediction precision on the EW traits compared to the single models RFR and RKHS with and without fixed effects considered, respectively (<xref rid="f4" ref-type="fig"><bold>Figure 4C</bold></xref>; <xref rid="SF2" ref-type="supplementary-material"><bold>Supplementary Figure 2B</bold></xref>). It’s also worth of noting that improvement of prediction precision by GSEnsemble was better than that for GSMerge, regardless of whether fixed effects were considered. These results indicate that multi-model integration is a practical, effective strategy to achieve better prediction of desired phenotypes.</p>
    </sec>
    <sec id="s3_5">
      <title>Application of G2P container on real-world breeding data</title>
      <p>We applied the G2P container on two sets of real-world breeding data provided by a collaborating seed company. The first dataset (Dataset 1) contained 7, 046 F<sub>1</sub> hybrids generated by crossing 3, 523 inbred lines with 2 tester lines, which were planted in the ecological zone of Northeast China in 2021 and 2022 to collect phenotypes. The second dataset (Dataset 2) contained 6,777 F<sub>1</sub> hybrids generated by crossing 2, 259 inbred lines with 3 tester lines, which were planted in Central China in 2021 and 2022 to collect phenotypes. The total 5, 782 inbred lines and the 5 tester lines were genotyped using the genotyping by targeted sequencing (GBTS) platform containing 44, 229 SNPs. We first analyzed the genotypic data of the 5, 787 samples, and simulated the heterogzygous genotypes of the total 13, 841 F<sub>1</sub> hybrids, utilizing the preprocessing pipeline in the G2P container described in <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Materials</bold></xref>. The entire streamlined procedure of genotypic data analysis took about ten minutes on a desktop server (Xeon-E5 with 4-core and 64 GB memory). The raw phenotypic data of grain yield (GY) per unit collected in the two years and six locations planted in each of the ecological zones were processed by the BLUP algorithm.</p>
      <p>After the genotypic and phenotypic data were processed, we then performed the GS analysis module with the 16 GS models and 13 evaluation metrics. We randomly selected 2, 046 and 1, 777 F1 hyrbids from the Dataset 1 and 2 as external validation set, respectively. Then, we utilized the 5, 000 samples in each of the datasets to train and evaluate models, followed by predicting the GY per unit of the samples in the two external validation set. At last, the predicted GY phenotypes of the validating samples were generated by the GSEnsemble and GSMerge algorithms to integrate multi-model prediction results. The GS analysis procedure took about tree minutes on the same server to generate the model evaluation result (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 4</bold></xref>). The evaluation results showed that RRBLUP method exhibited relatively stable and precise prediction results compared to other methods in the Dataset 1, while the RKHS method outperformed other GS models. We then utilized the two algorithms, namely GSMerge and GSEnsemble developed in G2P, to integrate multi-model prediction results. For the Dataset 1, the prediction precision were improved from 0.500 (RKHS model) to 0.519 (GSEnsemble) evaluated by Pearson correlation coefficient (<xref rid="SF3" ref-type="supplementary-material"><bold>Supplementary Figure 3A</bold></xref>). For the Dataset 2, the prediction precision were improved from 0.503 (RRBLUP model) to 0.530 (GSEnsemble) evaluated by Pearson correlation (<xref rid="SF3" ref-type="supplementary-material"><bold>Supplementary Figure 3B</bold></xref>). This result indicates that integration of multi-model prediction result may greatly improved prediction precision.</p>
    </sec>
    <sec id="s3_6">
      <title>Refinement design of training dataset</title>
      <p>In addition to sample size, selecting a representative set of training samples while achieving the maximal coverage of genetic diversity in predicting samples for which phenotypes are not measured is a critical step in GS-assisted breeding. Three main advantages may benefit from refinement design of the training dataset based on the genotypes of samples: first, it can decrease the cost of phenotyping when a subset of training samples is selected; second, it may avoid model overfitting if the training samples do not properly encompass the genetic diversity of predicting samples; third, training samples may continuously grow during the actual breeding practice, and it becomes necessary to continually reevaluate the genetic structure of newly phenotyped and genotyped samples. To assist the refinement design of a training dataset, G2P offers the TSRefine module, which facilitates selection of a subset of samples from the total training set using reference-free and reference-guided algorithms (See Methods). To test the effectiveness of the TSRefine function, we compared the prediction precisions using a variety of training set sizes by random selection (RD) and TSRefine selection of 40 to 1,000 samples. The comparison showed that the PEVmean and CDmean of RRBLUP have an overwhelming advantage over those for random selection (<xref rid="f5" ref-type="fig"><bold>Figure 5A</bold></xref>). On average, prediction precisions using the training set by TSRefine selection were 0.051 to 0.056 higher than those obtained using random selection evaluated by the Pearson correlation coefficient (<italic>r</italic>). When TSRefine selected 500 representative training samples using the reference-guided model (PEVmean), the prediction precision on the Test-dataset dropped only 8.3%, from 0.494 to 0.453, compared to the precision using the entire set of the 1,000 samples (<xref rid="f5" ref-type="fig"><bold>Figure 5B</bold></xref>). This indicates that phenotyping cost may be reduced to half with only an 8.3% sacrifice in precision.</p>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>Comparison of different methods for refinement design of the training dataset. <bold>(A)</bold> Comparison of prediction precisions of the Test-dataset on EW (ear weight) between the training sets compiled by TSRefine selection (Ref-free for reference-free method, CDmean, PEVmean and Sim for reference-guided method) and random selection (RD) from the CV-dataset. RRBLUP was the GS model used to perform prediction from refined training set to Test-dataset and prediction precision evaluated based on the Pearson correlation coefficient (<italic>r</italic>). <bold>(B)</bold> Percentage decrease in prediction precision over the highest precision using different numbers of samples compiled by CDmean and PEVmean. Phenotyping cost represents the percentage of TSRefine selection in the entire CV-dataset (<italic>n</italic> = 1,000, where <italic>n</italic> is the number of selected samples). <bold>(C)</bold> Comparison of the genetic distributions of the original, prediction, and refined training samples by PCA.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g005" position="float"/>
      </fig>
      <p>Additionally, TSRefine can illustrate the distribution of the original, predicting, and refined training sets using a scatter plot generated by PCA. With this, users can better understand the genetic relationship of the above three sets in the background of the whole population structure (<xref rid="f5" ref-type="fig"><bold>Figure 5C</bold></xref>). If no genotypes of predicting samples are available, an alternative is to utilize a reference-free mode of refinement design of training dataset. When 600 representative samples were selected to compile an optimized training set, the prediction precision on the Test-dataset dropped only 5.2%, from 0.494 to 0.468 (PEVmean; <xref rid="f5" ref-type="fig"><bold>Figure 5B</bold></xref>). Notably, however, this strategy can be applied only when the training and prediction samples are largely similar in terms of genetic backgrounds. Otherwise, it may cause either model overfitting or underfitting.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>GS has become a novel breeding strategy that is considered to be an important driving force for the new era of crop breeding (<xref rid="B17" ref-type="bibr">Jiang et al., 2020</xref>). Many statistical and informatics methods have been utilized to develop GS models to facilitate prediction of phenotypes from genotypes. The most popular methods include best linear unbiased predictor (BLUP)-based, Bayesian-based and machine learning-based methods. However, because of the sophisticated genetic complexity of crop species, no single method will work best for all species and traits. Model selection to determine the most appropriate model based on the particular traits and species therefore is a crucial step in GS. To solve this challenge, we utilize the Singularity platform to develop the G2P container, which packages up a library of 16 state-of-the-art GS models and 13 evaluation metrics. The main function of G2P is to perform batch evaluation of multiple GS models with uniformed analytical framework assisted by parallel computing. This utility offers great convenience for users by enabling them to perform comprehensive and unbiased model evaluation without having programming experience.</p>
    <p>Another important feature of G2P is its use of two strategies to integrate multi-model prediction results in an automatic fashion. Our analysis showed that result integration may effectively improve prediction precision. G2P also offers the capability of conducting refinement design of training datasets, allowing selection of a subset of optimized training samples based on genetic diversity analysis of training and predicting populations. This function is quite useful in practice, as it can not only greatly reduce the cost of phenotyping when constructing training population, but also help design a GS project amid the continuous growth of breeding data with available genotypes and phenotypes. In addition to its main function of GS analysis, G2P also provides a series of bioinformatics tools for data preprocessing including data filtration, file format conversion, representative SNP selection, genotype and phenotype imputation, and data quality control. These tools greatly simplify the operation for users without much programming skill.</p>
    <p>Taking the advantages of Singularity platform, the G2P container is flexible and easy to install and to upgrade, but limitations still have to be noticed. First of all, the purpose of developing G2P container is provide a convinent environment which may simplify the procedure of installing GS tools and performing GS analysis, so that starter users without sufficient experinces in GS analysis and programming skills may use it. Thus, only a limited number of GS tools are packaged with the Singularity platform, which are easy to be developed as standard, automated pipeline. Many of machine learning or deep learning (DL)-based GS tools were not integrated into G2P container, as these methods requires sophisticated parameter tuning or GPU computing. If an experienced user wants to perform ML or DL-based GS analysis, standlone tools are highly recommended. Secondly, because one of the novel features of G2P container is to integrate prediction results from the 16 GS models, computing efficiency is also an important factor that have to be considered. Thus, preprocessing of training dataset is highly recommended to compile a marker panel better within 10K SNPs, and the training population better contains less than 10K samples. If a user wants to perform GS analysis on much larger sample set with a marker panel containing over tens of thousands of SNPs, it’s better to use standalone version of GS tools. Morever, the current analytical pipelines in G2P only consider additive effects when training a BLUP-based GS model and epistatic interactions between SNPs were not considered, as modulating of epistatsis may expotentially increase computational complexity causing unexpected error during model training. At last, the current version of G2P container only integrate regression-based methods that are mostly used for predicting quantatitve traits of common crop species, without considering special scenarios or traits subjected to GS analysis. To cope with the above-mentioned limitations, we plan to continuously upgrade the G2P container in the near future, with more GS algorithms, more analytical functions, and more user-friendly data input such as relationship matrix or kinship matrix. In the future, G2P will be developed as a workshop for crop breeders who wish to conduct cloud-based precision-designed breeding.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data availability statement</title>
    <p>Publicly available datasets were analyzed in this study. The raw datasets can be found at <ext-link xlink:href="http://cubicmaize.hzau.edu.cn/" ext-link-type="uri">http://cubicmaize.hzau.edu.cn/</ext-link> and the filtered data used in this study can be found at <ext-link xlink:href="https://g2p-env.github.io/" ext-link-type="uri">https://g2p-env.github.io/</ext-link> or built-in dataset for example.</p>
  </sec>
  <sec sec-type="author-contributions" id="s6">
    <title>Author contributions</title>
    <p>QC and SQJ conceived and supervised the project. QC, SQJ, XFW and MC wrote the manuscript. QW, ZXQ and QC developed the main G2P packages and performed demo analysis using the maize CUBIC population. SQJ and SJ developed the pipelines for data preprocessing. TL developed the evaluation modules. ZXQ, JY and RF performed the benchmark test of G2P. All authors read and approved the final manuscript.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We appreciate the Beijing Tongzhou International Seed Technology Co., Ltd for offering real-world breeding data. We would also like to express our sincere appreciation to the following individuals for their significant contributions to the generation of this data: Ms. Feng Jin and Ms. Xiuai Xia designed the production of DH lines and F1 combinations, Ms. Fang Huang worked in the field. Ms. Zixuan Tian and Ms. Xiaocui Zhao collected phenotypic data and handled genomic data of real-world dataset.</p>
  </ack>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s9">
    <title>Publisher’s note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <sec sec-type="supplementary-material" id="s10">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fpls.2023.1207139/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fpls.2023.1207139/full#supplementary-material</ext-link>
</p>
    <supplementary-material id="SF1" position="float" content-type="local-data">
      <label>Supplementary Figure 1</label>
      <caption>
        <p>Comparison of the prediction precision on the Test-dataset for DTT (days to tasseling), PH (plant height), and EW (ear weight) got the 16 GS models overall <bold>(A)</bold> and separately <bold>(B)</bold> using different numbers of training samples.</p>
      </caption>
      <media xlink:href="Image_1.jpeg">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SF2" position="float" content-type="local-data">
      <label>Supplementary Figure 2</label>
      <caption>
        <p><bold>(A)</bold> Prediction precisions by GSMerge- and GSEnsemble-based integration are better than those by the single model RFR without fixed effects considered on the CV-dataset. The prediction precision was evaluated based on the Pearson correlation coefficient (<italic>r</italic>). <bold>(B)</bold> By applying integrated combination and weights from the CV-dataset to prediction of the Test-dataset, prediction precisions with GSMerge- and GSEnsemble-based integration are more improved than those with the best single model, RFR, without fixed effects considered. <bold>(C)</bold> The statistics of model selection frequency by the GSMerge strategy through 50 times 5-fold cross validation on the CV-dataset. <bold>(D)</bold> The statistics of the weights of the 14 models used for GSEnsemble strategy on the CV-dataset.</p>
      </caption>
      <media xlink:href="Image_2.jpeg">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SF3" position="float" content-type="local-data">
      <label>Supplementary Figure 3</label>
      <caption>
        <p>The prediction precision was evaluated by Pearson correlation coefficient of two results integration methods on real-world breeding data. <bold>(A)</bold> The ecological zone of Northeast China and <bold>(B)</bold> The ecological zone of Central China</p>
      </caption>
      <media xlink:href="Image_3.jpeg">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SF4" position="float" content-type="local-data">
      <media xlink:href="DataSheet_1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="Table_1.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM2" position="float" content-type="local-data">
      <media xlink:href="Table_2.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM3" position="float" content-type="local-data">
      <media xlink:href="Table_3.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM4" position="float" content-type="local-data">
      <media xlink:href="Table_4.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akdemir</surname><given-names>D.</given-names></name><name><surname>Sanchez</surname><given-names>J. I.</given-names></name><name><surname>Jannink</surname><given-names>J.-L.</given-names></name></person-group> (<year>2015</year>). <article-title>Optimization of genomic selection training populations with a genetic algorithm</article-title>. <source>Genet. Selection Evol.</source>
<volume>47</volume>, <fpage>1</fpage>–<lpage>10</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s12711-015-0116-6</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belamkar</surname><given-names>V.</given-names></name><name><surname>Guttieri</surname><given-names>M. J.</given-names></name><name><surname>Hussain</surname><given-names>W.</given-names></name><name><surname>Jarquin</surname><given-names>D.</given-names></name><name><surname>El-Basyoni</surname><given-names>I.</given-names></name><name><surname>Poland</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Genomic selection in preliminary yield trials in a winter wheat breeding program</article-title>. <source>G3: Genes Genomes Genet.</source><volume>8</volume>, <fpage>2735</fpage>–<lpage>2747</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.118.200415</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blondel</surname><given-names>M.</given-names></name><name><surname>Onogi</surname><given-names>A.</given-names></name><name><surname>Iwata</surname><given-names>H.</given-names></name><name><surname>Ueda</surname><given-names>N.</given-names></name></person-group> (<year>2015</year>). <article-title>A ranking approach to genomic selection</article-title>. <source>PLoS One</source>
<volume>10</volume>, <elocation-id>e0128570</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0128570</pub-id>
<pub-id pub-id-type="pmid">26068103</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L.</given-names></name></person-group> (<year>2001</year>). <article-title>Random forests</article-title>. <source>Mach. Learn.</source>
<volume>45</volume>, <fpage>5</fpage>–<lpage>32</lpage>. doi: <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname><given-names>D.</given-names></name><name><surname>Chun</surname><given-names>H.</given-names></name><name><surname>Keles</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <article-title>Spls: sparse partial least squares (SPLS) regression and classification</article-title>. <source>R package version</source>
<volume>2</volume>, <fpage>1</fpage>–<lpage>1</lpage>.</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colombani</surname><given-names>C.</given-names></name><name><surname>Croiseau</surname><given-names>P.</given-names></name><name><surname>Fritz</surname><given-names>S.</given-names></name><name><surname>Guillaume</surname><given-names>F.</given-names></name><name><surname>Legarra</surname><given-names>A.</given-names></name><name><surname>Ducrocq</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>A comparison of partial least squares (PLS) and sparse PLS regressions in genomic selection in French dairy cattle</article-title>. <source>J. dairy Sci.</source><volume>95</volume>, <fpage>2120</fpage>–<lpage>2131</lpage>. doi: <pub-id pub-id-type="doi">10.3168/jds.2011-4647</pub-id><pub-id pub-id-type="pmid">22459857</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C.</given-names></name><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>1995</year>). <article-title>Support-vector networks</article-title>. <source>Mach. Learn.</source>
<volume>20</volume>, <fpage>273</fpage>–<lpage>297</lpage>. doi: <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id>
</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>de los Campos</surname><given-names>G.</given-names></name><name><surname>Pérez</surname><given-names>P.</given-names></name></person-group> (<year>2015</year>). <source>BGLR: Bayesian generalized linear regression</source> (<publisher-name>R package version 1.0</publisher-name>).</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Endelman</surname><given-names>J. B.</given-names></name></person-group> (<year>2011</year>). <article-title>Ridge regression and other kernels for genomic selection with R package rrBLUP</article-title>. <source>Plant Genome</source>
<volume>4</volume>, <fpage>250</fpage>–<lpage>255</lpage>. doi: <pub-id pub-id-type="doi">10.3835/plantgenome2011.08.0024</pub-id>
</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name><name><surname>TibshIrani</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>). <article-title>Regularization paths for generalized linear models <italic>via</italic> coordinate descent</article-title>. <source>J. Stat. software</source>
<volume>33</volume>, <fpage>1</fpage>. doi: <pub-id pub-id-type="doi">10.18637/jss.v033.i01</pub-id>
</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garofoli</surname><given-names>A.</given-names></name><name><surname>Paradiso</surname><given-names>V.</given-names></name><name><surname>Montazeri</surname><given-names>H.</given-names></name><name><surname>Jermann</surname><given-names>P. M.</given-names></name><name><surname>Roma</surname><given-names>G.</given-names></name><name><surname>Tornillo</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>PipeIT: A singularity container for molecular diagnostic somatic variant calling on the ion torrent next-generation sequencing platform</article-title>. <source>J. Mol. Diagnostics</source><volume>21</volume>, <fpage>884</fpage>–<lpage>894</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jmoldx.2019.05.001</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffner</surname><given-names>E. L.</given-names></name><name><surname>Jannink</surname><given-names>J.-L.</given-names></name><name><surname>Iwata</surname><given-names>H.</given-names></name><name><surname>Souza</surname><given-names>E.</given-names></name><name><surname>Sorrells</surname><given-names>M. E.</given-names></name></person-group> (<year>2011</year>). <article-title>Genomic selection accuracy for grain quality traits in biparental wheat populations</article-title>. <source>Crop Sci.</source>
<volume>51</volume>, <fpage>2597</fpage>–<lpage>2606</lpage>. doi: <pub-id pub-id-type="doi">10.2135/cropsci2011.05.0253</pub-id>
</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hickey</surname><given-names>L. T.</given-names></name><name><surname>Hafeez</surname><given-names>N.</given-names></name><name><surname>Robinson</surname><given-names>H.</given-names></name><name><surname>Jackson</surname><given-names>S. A.</given-names></name><name><surname>Leal-Bertioli</surname><given-names>S. C. M.</given-names></name><name><surname>Tester</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Breeding crops to feed 10 billion</article-title>. <source>Nat. Biotechnol.</source><volume>37</volume>, <fpage>744</fpage>–<lpage>754</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41587-019-0152-9</pub-id><pub-id pub-id-type="pmid">31209375</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>B.</given-names></name><name><surname>Zhao</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>F.</given-names></name><name><surname>Xie</surname><given-names>T.</given-names></name><name><surname>Xu</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Genomic selection and genetic architecture of agronomic traits during modern rapeseed breeding</article-title>. <source>Nat. Genet.</source><volume>54</volume>, <fpage>694</fpage>–<lpage>704</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41588-022-01055-6</pub-id><pub-id pub-id-type="pmid">35484301</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iacoangeli</surname><given-names>A.</given-names></name><name><surname>Al Khleifat</surname><given-names>A.</given-names></name><name><surname>Sproviero</surname><given-names>W.</given-names></name><name><surname>Shatunov</surname><given-names>A.</given-names></name><name><surname>Jones</surname><given-names>A. R.</given-names></name><name><surname>Morgan</surname><given-names>S. L.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>DNAscan: personal computer compatible NGS analysis, annotation and visualisation</article-title>. <source>BMC bioinformatics</source><volume>20</volume>(<issue>1</issue>), <page-range>1–10</page-range>. doi: <pub-id pub-id-type="doi">10.1186/s12859-019-2791-8</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jannink</surname><given-names>J.-L.</given-names></name><name><surname>Lorenz</surname><given-names>A. J.</given-names></name><name><surname>Iwata</surname><given-names>H.</given-names></name></person-group> (<year>2010</year>). <article-title>Genomic selection in plant breeding: from theory to practice</article-title>. <source>Briefings Funct. Genomics</source>
<volume>9</volume>, <fpage>166</fpage>–<lpage>177</lpage>. doi: <pub-id pub-id-type="doi">10.1093/bfgp/elq001</pub-id>
</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>S.</given-names></name><name><surname>Cheng</surname><given-names>Q.</given-names></name><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Fu</surname><given-names>R.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name></person-group> (<year>2020</year>). <article-title>Genome optimization for improvement of maize breeding</article-title>. <source>Theor. Appl. Genet.</source>
<volume>135</volume>
<issue>(5)</issue>, <fpage>1491</fpage>–<lpage>1502</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-019-03493-z</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>C.</given-names></name><name><surname>Lan</surname><given-names>H.</given-names></name><name><surname>Attie</surname><given-names>A. D.</given-names></name><name><surname>Churchill</surname><given-names>G. A.</given-names></name><name><surname>Bulutuglo</surname><given-names>D.</given-names></name><name><surname>Yandell</surname><given-names>B. S.</given-names></name></person-group> (<year>2004</year>). <article-title>Selective phenotyping for increased efficiency in genetic mapping studies</article-title>. <source>Genetics</source>
<volume>168</volume>, <fpage>2285</fpage>–<lpage>2293</lpage>. doi: <pub-id pub-id-type="doi">10.1534/genetics.104.027524</pub-id>
<pub-id pub-id-type="pmid">15611192</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>P.</given-names></name><name><surname>Bagaria</surname><given-names>P. K.</given-names></name><name><surname>Rakshit</surname><given-names>S.</given-names></name><name><surname>Roorkiwal</surname><given-names>M.</given-names></name><name><surname>Varshney</surname><given-names>R. K.</given-names></name><name><surname>Stewart-Brown</surname><given-names>B. B.</given-names></name></person-group> (<year>2019</year>). <article-title>Genomic selection for yield and seed composition traits within an applied soybean breeding program</article-title>. <source>Funct. Integr. Genomics</source>
<volume>9</volume>, <fpage>2253</fpage>–<lpage>2265</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.118.200917</pub-id>
</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurtzer</surname><given-names>G. M.</given-names></name><name><surname>Sochat</surname><given-names>V.</given-names></name><name><surname>Bauer</surname><given-names>M. W.</given-names></name></person-group> (<year>2017</year>). <article-title>Singularity: Scientific containers for mobility of compute</article-title>. <source>PLoS One</source>
<volume>12</volume>, <elocation-id>e0177459</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0177459</pub-id>
<pub-id pub-id-type="pmid">28494014</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>T.</given-names></name><name><surname>Jiang</surname><given-names>S.</given-names></name><name><surname>Fu</surname><given-names>R.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Cheng</surname><given-names>Q.</given-names></name><name><surname>Jiang</surname><given-names>S.</given-names></name></person-group> (<year>2023</year>). <article-title>IP4GS: Bringing genomic selection analysis to breeders</article-title>. <source>Front. Plant Sci.</source>
<volume>14</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2023.1131493</pub-id>
</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liaw</surname><given-names>A.</given-names></name><name><surname>Wiener</surname><given-names>M.</given-names></name></person-group> (<year>2002</year>). <article-title>Classification and regression by randomForest</article-title>. <source>R News</source>
<volume>2</volume>, <fpage>18</fpage>–<lpage>22</lpage>.</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Xiao</surname><given-names>Y.</given-names></name><name><surname>Luo</surname><given-names>J.</given-names></name><name><surname>Qiao</surname><given-names>F.</given-names></name><name><surname>Yang</surname><given-names>W.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>CUBIC: an atlas of genetic architecture promises directed maize improvement</article-title>. <source>Genome Biol.</source><volume>21</volume>, <fpage>1</fpage>–<lpage>17</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13059-020-1930-x</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>J.</given-names></name><name><surname>Wei</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Cheng</surname><given-names>S.</given-names></name><name><surname>Xiao</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>MaizeCUBIC: a comprehensive variation database for a maize synthetic population</article-title>. <source>Database</source><volume>2020</volume>. doi: <pub-id pub-id-type="doi">10.1093/database/baaa044</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meuwissen</surname><given-names>T. H.</given-names></name><name><surname>Hayes</surname><given-names>B. J.</given-names></name><name><surname>Goddard</surname><given-names>M.</given-names></name></person-group> (<year>2001</year>). <article-title>Prediction of total genetic value using genome-wide dense marker maps</article-title>. <source>Genetics</source>
<volume>157</volume>, <fpage>1819</fpage>–<lpage>1829</lpage>. doi: <pub-id pub-id-type="doi">10.1093/genetics/157.4.1819</pub-id>
<pub-id pub-id-type="pmid">11290733</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>D.</given-names></name><name><surname>Dimitriadou</surname><given-names>E.</given-names></name><name><surname>Hornik</surname><given-names>K.</given-names></name><name><surname>Weingessel</surname><given-names>A.</given-names></name><name><surname>Leisch</surname><given-names>F.</given-names></name></person-group> (<year>2014</year>). “<article-title>e1071: Misc Functions of the Department of Statistics (e1071), TU Wien</article-title>,” (<publisher-name>R package version</publisher-name>).</mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>N. H.</given-names></name><name><surname>Jahoor</surname><given-names>A.</given-names></name><name><surname>Jensen</surname><given-names>J. D.</given-names></name><name><surname>Orabi</surname><given-names>J.</given-names></name><name><surname>Cericola</surname><given-names>F.</given-names></name><name><surname>Edriss</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Genomic prediction of seed quality traits using advanced barley breeding lines</article-title>. <source>PLoS One</source><volume>11</volume>, <elocation-id>e0164494</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0164494</pub-id><pub-id pub-id-type="pmid">27783639</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogutu</surname><given-names>J. O.</given-names></name><name><surname>Schulz-Streeck</surname><given-names>T.</given-names></name><name><surname>Piepho</surname><given-names>H.-P.</given-names></name></person-group> (<year>2012</year>). <article-title>Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions</article-title>. <volume>6</volume>, <fpage>1</fpage>–<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1186/1753-6561-6-S2-S10</pub-id>
</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ornella</surname><given-names>L.</given-names></name><name><surname>Pérez</surname><given-names>P.</given-names></name><name><surname>Tapia</surname><given-names>E.</given-names></name><name><surname>González-Camacho</surname><given-names>J.</given-names></name><name><surname>Burgueño</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Genomic-enabled prediction with classification algorithms</article-title>. <source>Heredity</source><volume>112</volume>, <fpage>616</fpage>–<lpage>626</lpage>. doi: <pub-id pub-id-type="doi">10.1038/hdy.2013.144</pub-id><pub-id pub-id-type="pmid">24424163</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robert</surname><given-names>P.</given-names></name><name><surname>Auzanneau</surname><given-names>J.</given-names></name><name><surname>Goudemand</surname><given-names>E.</given-names></name><name><surname>Oury</surname><given-names>F.-X.</given-names></name><name><surname>Rolland</surname><given-names>B.</given-names></name><name><surname>Heumez</surname><given-names>E.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Phenomic selection in wheat breeding: identification and optimisation of factors influencing prediction accuracy and comparison to genomic selection</article-title>. <source>Theor. Appl. Genet.</source><volume>135</volume>, <fpage>895</fpage>–<lpage>914</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-021-04005-8</pub-id><pub-id pub-id-type="pmid">34988629</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodriguez</surname><given-names>F. H.</given-names></name><name><surname>Flores-Mara</surname><given-names>R.</given-names></name></person-group> (<year>2019</year>). <article-title>Genome-wide association analysis for resistance to infectious pancreatic necrosis virus identifies candidate genes involved in viral replication and immune response in rainbow trout (Oncorhynchus mykiss)</article-title>. <source>G3: Genes Genomes Genet.</source>
<volume>9</volume>, <fpage>2897</fpage>–<lpage>2904</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.119.400463</pub-id>
</mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rönnegård</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>X.</given-names></name><name><surname>Alam</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>hglm: A package for fitting hierarchical generalized linear models</article-title>. <source>R J.</source>
<volume>2</volume>, <fpage>20</fpage>–<lpage>28</lpage>. doi: <pub-id pub-id-type="doi">10.32614/RJ-2010-009</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarinelli</surname><given-names>J. M.</given-names></name><name><surname>Murphy</surname><given-names>J. P.</given-names></name><name><surname>Tyagi</surname><given-names>P.</given-names></name><name><surname>Holland</surname><given-names>J. B.</given-names></name><name><surname>Johnson</surname><given-names>J. W.</given-names></name><name><surname>Mergoum</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Training population selection and use of fixed effects to optimize genomic predictions in a historical USA winter wheat panel</article-title>. <source>Theor. Appl. Genet.</source><volume>132</volume>, <fpage>1247</fpage>–<lpage>1261</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-019-03276-6</pub-id><pub-id pub-id-type="pmid">30680419</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sen</surname><given-names>Ś.</given-names></name><name><surname>Satagopan</surname><given-names>J. M.</given-names></name><name><surname>BrOman</surname><given-names>K. W.</given-names></name><name><surname>Churchill</surname><given-names>G. A.</given-names></name></person-group> (<year>2007</year>). <article-title>R/qtlDesign: inbred line cross experimental design</article-title>. <source>Mamm. Genome</source>
<volume>18</volume>, <fpage>87</fpage>–<lpage>93</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00335-006-0090-y</pub-id>
<pub-id pub-id-type="pmid">17347894</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>X.</given-names></name><name><surname>Alam</surname><given-names>M.</given-names></name><name><surname>Fikse</surname><given-names>F.</given-names></name><name><surname>Rönnegård</surname><given-names>L.</given-names></name></person-group> (<year>2013</year>). <article-title>A novel generalized ridge regression method for quantitative genetics</article-title>. <source>Genetics</source>
<volume>193</volume>, <fpage>1255</fpage>–<lpage>1268</lpage>. doi: <pub-id pub-id-type="doi">10.1534/genetics.112.146720</pub-id>
<pub-id pub-id-type="pmid">23335338</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Qu</surname><given-names>H.</given-names></name><name><surname>Cui</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>R.</given-names></name><name><surname>Chater</surname><given-names>J. M.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Boosting predictabilities of agronomic traits in rice using bivariate genomic selection</article-title>. <source>Briefings Bioinf.</source><volume>22</volume>, <elocation-id>bbaa103</elocation-id>. doi: <pub-id pub-id-type="doi">10.1093/bib/bbaa103</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wray</surname><given-names>N. R.</given-names></name><name><surname>Yang</surname><given-names>J.</given-names></name><name><surname>Hayes</surname><given-names>B. J.</given-names></name><name><surname>Price</surname><given-names>A. L.</given-names></name><name><surname>Goddard</surname><given-names>M. E.</given-names></name><name><surname>Visscher</surname><given-names>P. M.</given-names></name></person-group> (<year>2013</year>). <article-title>Pitfalls of predicting complex traits from SNPs</article-title>. <source>Nat. Rev. Genet.</source>
<volume>14</volume>, <fpage>507</fpage>–<lpage>515</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nrg3457</pub-id>
<pub-id pub-id-type="pmid">23774735</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Ma</surname><given-names>K.</given-names></name><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Zhou</surname><given-names>K.</given-names></name><name><surname>Yu</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Genomic selection: A breakthrough technology in rice breeding</article-title>. <source>Crop J.</source><volume>9</volume>, <fpage>669</fpage>–<lpage>677</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cj.2021.03.008</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name></person-group> (<year>2022</year>a). <article-title>Machine learning bridges omics sciences and plant breeding</article-title>. <source>Trends Plant Science.</source>
<volume>28</volume>, <page-range>199–210</page-range> doi: <pub-id pub-id-type="doi">10.1016/j.tplants.2022.08.018</pub-id>
</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Cheng</surname><given-names>Q.</given-names></name><name><surname>Jiang</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Xiao</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>LightGBM: Accelerated genomically designed crop breeding through ensemble learning</article-title>. <source>Genome Biol.</source><volume>22</volume>, <fpage>1</fpage>–<lpage>24</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13059-021-02492-y</pub-id><pub-id pub-id-type="pmid">33397451</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Youens-Clark</surname><given-names>K.</given-names></name><name><surname>Bomhoff</surname><given-names>M.</given-names></name><name><surname>Ponsero</surname><given-names>A. J.</given-names></name><name><surname>Wood-Charlson</surname><given-names>E. M.</given-names></name><name><surname>Lynch</surname><given-names>J.</given-names></name><name><surname>Choi</surname><given-names>I.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>iMicrobe: Tools and data-driven discovery platform for the microbiome sciences</article-title>. <source>GigaScience</source><volume>8</volume>, <elocation-id>giz083</elocation-id>. doi: <pub-id pub-id-type="doi">10.1093/gigascience/giz083</pub-id><pub-id pub-id-type="pmid">31289831</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Gowda</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>W.</given-names></name><name><surname>Würschum</surname><given-names>T.</given-names></name><name><surname>Maurer</surname><given-names>H. P.</given-names></name><name><surname>Longin</surname><given-names>F. H.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Accuracy of genomic selection in European maize elite breeding populations</article-title>. <source>Theor. Appl. Genet.</source><volume>124</volume>, <fpage>769</fpage>–<lpage>776</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-011-1745-y</pub-id><pub-id pub-id-type="pmid">22075809</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Plant Sci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Plant Sci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Plant Sci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Plant Science</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-462X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10437076</article-id>
    <article-id pub-id-type="doi">10.3389/fpls.2023.1207139</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Plant Science</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>G2P Provides an Integrative Environment for Multi-model genomic selection analysis to improve genotype-to-phenotype prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Qian</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn003" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2293826"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Shan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn003" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2152430"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Tong</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2171842"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Qiu</surname>
          <given-names>Zhixu</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/442036"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Jun</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1835978"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fu</surname>
          <given-names>Ran</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2152424"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ma</surname>
          <given-names>Chuang</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/78201"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Xiangfeng</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Jiang</surname>
          <given-names>Shuqin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>*</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Cheng</surname>
          <given-names>Qian</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>*</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2146013"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Frontiers Science Center for Molecular Design Breeding, China Agricultural University</institution>, <addr-line>Beijing</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>National Maize Improvement Center of China, College of Agriculture and Biotechnology, China Agricultural University</institution>, <addr-line>Beijing</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&amp;F University</institution>, <addr-line>Yangling, Shaanxi</addr-line>, <country>China</country></aff>
    <aff id="aff4"><sup>4</sup><institution>State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&amp;F University</institution>, <addr-line>Shaanxi, Yangling</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Achraf El Allali, Mohammed VI Polytechnic University, Morocco</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Xinhao Ouyang, Xiamen University, China; Rodrigo R. Amadeu, Bayer Crop Science, United States; Morad M. Mokhtar, University Mohammed VI Polytechnic, Morocco</p>
      </fn>
      <corresp id="fn001">*Correspondence: Shuqin Jiang, <email xlink:href="mailto:wanshi0066@126.com">wanshi0066@126.com</email>; Qian Cheng, <email xlink:href="mailto:qchengray@cau.edu.cn">qchengray@cau.edu.cn</email>
</corresp>
      <fn fn-type="equal" id="fn003">
        <p>†These authors have contributed equally to this work</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>04</day>
      <month>8</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>1207139</elocation-id>
    <history>
      <date date-type="received">
        <day>17</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>7</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Wang, Jiang, Li, Qiu, Yan, Fu, Ma, Wang, Jiang and Cheng</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Wang, Jiang, Li, Qiu, Yan, Fu, Ma, Wang, Jiang and Cheng</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Genotype-to-phenotype (G2P) prediction has become a mainstream paradigm to facilitate genomic selection (GS)-assisted breeding in the seed industry. Many methods have been introduced for building GS models, but their prediction precision may vary depending on species and specific traits. Therefore, evaluation of multiple models and selection of the appropriate one is crucial to effective GS analysis. Here, we present the G2P container developed for the Singularity platform, which not only contains a library of 16 state-of-the-art GS models and 13 evaluation metrics. G2P works as an integrative environment offering comprehensive, unbiased evaluation analyses of the 16 GS models, which may be run in parallel on high-performance computing clusters. Based on the evaluation outcome, G2P performs auto-ensemble algorithms that not only can automatically select the most precise models but also can integrate prediction results from multiple models. This functionality should further improve the precision of G2P prediction. Another noteworthy function is the refinement design of the training set, in which G2P optimizes the training set based on the genetic diversity analysis of a studied population. Although the training samples in the optimized set are fewer than in the original set, the prediction precision is almost equivalent to that obtained when using the whole set. This functionality is quite useful in practice, as it reduces the cost of phenotyping when constructing training population. The G2P container and source codes are freely accessible at <ext-link xlink:href="https://g2p-env.github.io/" ext-link-type="uri">https://g2p-env.github.io/</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>genomic selection</kwd>
      <kwd>genotype-to-phenotype prediction</kwd>
      <kwd>singularity container</kwd>
      <kwd>crop breeding</kwd>
      <kwd>multi-model integration</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">
          <institution-wrap>
            <institution>Chinese Universities Scientific Fund
</institution>
            <institution-id institution-id-type="doi">10.13039/501100005236</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <funding-statement>This work was supported by the Hainan Yazhou Bay Seed Laboratory (B21HJ0505), the Chinese Universities Scientific Fund (2022TC139) and the 2115 Talent Development Program of China Agricultural University.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="2"/>
      <equation-count count="0"/>
      <ref-count count="42"/>
      <page-count count="13"/>
      <word-count count="6690"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>section-in-acceptance</meta-name>
        <meta-value>Plant Bioinformatics</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>Genomic selection (GS) is the process of genomically estimating breeding values based on genotype-to-phenotype (G2P) prediction and was originally utilized in animal breeding for estimating the breeding values of untested individuals by analyzing the genotype of a sample (<xref rid="B25" ref-type="bibr">Meuwissen et al., 2001</xref>). Recently, GS has been proposed as a promising approach for crop breeding as the dramatic decrease of genotyping expense (<xref rid="B16" ref-type="bibr">Jannink et al., 2010</xref>; <xref rid="B13" ref-type="bibr">Hickey et al., 2019</xref>). The core idea of GS is to predict phenotypes from genotypes of breeding individuals, allowing a breeder to select the best genetic material to produce a desired phenotype. Therefore, GS as a revolutionary method of precision breeding offers multiple advantages over traditional breeding: it greatly shortens the breeding cycle; it reduces the cost of phenotyping; and it allows more genetic gains per unit time (<xref rid="B16" ref-type="bibr">Jannink et al., 2010</xref>; <xref rid="B13" ref-type="bibr">Hickey et al., 2019</xref>; <xref rid="B39" ref-type="bibr">Yan and Wang, 2022a</xref>). Recently, successful applications of GS in crop breeding have been reported in a variety of crops such as maize, barley, wheat, rice, soybean and rapeseed (<xref rid="B42" ref-type="bibr">Zhao et al., 2012</xref>; <xref rid="B27" ref-type="bibr">Nielsen et al., 2016</xref>; <xref rid="B2" ref-type="bibr">Belamkar et al., 2018</xref>; <xref rid="B19" ref-type="bibr">Kumar et al., 2019</xref>; <xref rid="B36" ref-type="bibr">Wang et al., 2021</xref>; <xref rid="B14" ref-type="bibr">Hu et al., 2022</xref>).</p>
    <p>Despite the great potential of GS-assisted breeding, its broad application in crops has been impeded by the complex situation in crop breeding. For instance, multiple statistical, Bayesian, and machine learning (ML) algorithms have been developed to construct GS models in crops, but prediction precisions may vary when applying different models on different species and traits to certain degrees (<xref rid="B12" ref-type="bibr">Heffner et al., 2011</xref>; <xref rid="B29" ref-type="bibr">Ornella et al., 2014</xref>; <xref rid="B40" ref-type="bibr">Yan et al., 2021</xref>). This is because prediction accuracy is influenced by many factors, including the size of training and testing samples, the genetic structure of the breeding population, the density of whole-genome marks, the heritability of target traits, and the span of linkage disequilibrium (<xref rid="B37" ref-type="bibr">Wray et al., 2013</xref>). Therefore, to ensure the effectiveness of GS prediction, it is crucial to select the most appropriate GS model based on a comprehensive evaluation of all the methods using optimized parameters from a model library.</p>
    <p>Data as of 2021, many GS packages have been developed, such as “rrBLUP” for ridge regression best linear unbiased predictor model (RRBLUP), “BGLR” for various Bayesian models (e.g. Bayes A, Bayes B, Bayes C and etc.), and “spls” for sparse partial least squares regression model (SPLS), as well as many ML-based methods (<xref rid="B9" ref-type="bibr">Endelman, 2011</xref>; <xref rid="B6" ref-type="bibr">Colombani et al., 2012</xref>; <xref rid="B3" ref-type="bibr">Blondel et al., 2015</xref>; <xref rid="B40" ref-type="bibr">Yan et al., 2021</xref>). Although these packages and tools have been used for GS breeding in plants, an integrated environment containing the publically available GS tools may greatly ease the process of users to conduct a sufficient comparative evaluation of GS models (<xref rid="B38" ref-type="bibr">Xu et al., 2021</xref>). Additionally, most current tools do not support streamlined pipelines of data preprocessing, model selection and performance evaluation. Data preprocessing is a tedious and complicated process, including data format conversion, data quality control, as well as partition of training and testing samples. Performance evaluation requires complicated fine-tuning of model parameters and objective evaluation with an array of different metrics, such as Pearson correlation coefficient (<italic>r</italic>), Mean square error (MSE). Through these two critical steps, the best models with optimized parameters can then be selected to use for GS-assisted breeding. Because many tools must be configured differently to meet the requirement of specific computing environments, comparative evaluation of different GS models is a complicated process. The Singularity platform, developed as a scientific container for cloud computing, can easily package up tools and software to run in reproducible environments (<xref rid="B20" ref-type="bibr">Kurtzer et al., 2017</xref>). Singularity has been utilized to set up cloud computing environments for many bioinformatics tools and pipelines (<xref rid="B15" ref-type="bibr">Iacoangeli et al., 2019</xref>; <xref rid="B11" ref-type="bibr">Garofoli et al., 2019</xref>; <xref rid="B41" ref-type="bibr">Youens-Clark et al., 2019</xref>). Therefore, it provides a promising means to integrate a library of GS models, tools and preconfigured pipelines for streamlined GS analysis. With such an integrated environment, users not only can easily install and run all kinds of GS models, but also can perform streamlined GS analyses without needing advanced programming skills.</p>
    <p>In this study, we present the G2P container, developed based on the Singularity platform to serve as a reproducible environment allowing users to perform streamlined GS analysis, including data preprocessing, model construction, and model evaluation. It also allows automatic integration of prediction results to simplify the GS analysis. The library contains up to 16 state-of-the-art GS models and 13 evaluation metrics, which are integrated into a uniform framework to flexibly and conveniently call GS models for comparative evaluation. Moreover, the container-based characteristics of G2P will greatly ease the way for a bioinformatics personnel or population geneticist to perform GS analysis, especially for the situation involving comparative evaluation of multiple GS methods. G2P is not only available as a container, but also can be installed and used as a regular R package. Here, we demonstrate the features and utility of G2P through analysis of a large maize population (CUBIC) comprising 1,404 genotyped inbred lines with three phenotypes (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>; <xref rid="B24" ref-type="bibr">Luo et al., 2020</xref>).</p>
  </sec>
  <sec id="s2">
    <title>Methods</title>
    <sec id="s2_1">
      <title>Overall structure of the G2P container</title>
      <p>The G2P container has two main components. The first comprises stand-alone software and dependent libraries, offering the environment for running G2P (<xref rid="f1" ref-type="fig"><bold>Figure 1A</bold></xref>). The second component comprises the R package of G2P, containing the main modules required for GS analysis (<xref rid="f1" ref-type="fig"><bold>Figure 1B</bold></xref>). This consists of four main analytical modules that function as a streamlined pipeline, for preprocessing of genotype and phenotype data (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary materials</bold></xref>), evaluation of the 16 models in the library, integration of prediction results from multiple models, and refinement of training datasets.</p>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>Overview of the G2P singularity container. <bold>(A)</bold> Systems environment setup of the G2P container. The upper semicircle contains several stand-alone software programs (capital letters) for GS related analysis and offering a running environment for the G2P functions (italics) in the lower semicircle. The operating system and computing environment for the G2P container are shown on the circle. <bold>(B)</bold> The four main functional modules of the G2P package, with the main functions of each module highlighted in italics.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g001" position="float"/>
      </fig>
    </sec>
    <sec id="s2_2">
      <title>Parallel evaluation of GS models</title>
      <p>The G2P library currently contains 16 models that have been previously used in plant breeding: 14 regression-based models and two classification-based models (<xref rid="T1" ref-type="table"><bold>Table 1</bold></xref>). Streamlined pipelines for running these models are integrated into the “G2P” module, which is the core function of the G2P container. A user may specify the models from the library, and the selected models can be simultaneously constructed by setting the parameter “modelMethods” of the “G2P” module. To evaluate the prediction precision of the selected models, 13 evaluation metrics can be called by the function of “G2PEvaluation” (<xref rid="T2" ref-type="table"><bold>Table 2</bold></xref>). The 13 evaluation metrics can be classified into two categories: there are five metrics for correlation-based evaluation and eight metrics for threshold-based evaluation. The first five metrics measure the global similarity between predicted and observed phenotypic values with a variety of algorithms to compute correlation, and the remaining eight assess the model precision by examining the proportion of predicted top samples among the actual top samples with user-specified top 10%, 15%, 20%, or 30% of expected phenotypic values (<xref rid="B21" ref-type="bibr">Li et al., 2023</xref>).</p>
      <table-wrap position="float" id="T1">
        <label>Table 1</label>
        <caption>
          <p>Characteristics of the 16 GS models integrated in G2P.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="middle" align="left" rowspan="1" colspan="1">Model</th>
              <th valign="middle" align="left" rowspan="1" colspan="1">Feature</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Package</th>
              <th valign="top" align="center" rowspan="1" colspan="1">Refs</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th valign="middle" colspan="4" align="left" rowspan="1">GS models based on regression</th>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayes A</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Scaled <italic>t</italic>-distribution for marker effects, inverse chi-square on marker variance</td>
              <td valign="top" rowspan="6" align="center" colspan="1">BGLR</td>
              <td valign="top" rowspan="6" align="center" colspan="1">(<xref rid="B8" ref-type="bibr">de los Campos and Pérez, 2015</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayes B</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Similar to Bayes A; utilizes both shrinkage and variable selection method</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayes C</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Characterized by a Gaussian distribution</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayesian LASSO (BL)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Marker variances resulting in a double exponential (DE) distribution</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayesian ridge regression (BRR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Induces homogeneous shrinkage of all marker effects towards zero; marker effect yields a Gaussian distribution</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Reproducing kernel Hilbert space (RKHS)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Effective for detecting nonadditive gene effects</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Ridge regression (RR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Normal distribution for marker effects and nonzero</td>
              <td valign="top" rowspan="2" align="center" colspan="1">rrBLUP</td>
              <td valign="top" rowspan="2" align="center" colspan="1">(<xref rid="B9" ref-type="bibr">Endelman, 2011</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Ridge regression best linear unbiased prediction (RRBLUP)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Assumes all markers have equal variances with small and nonzero effect</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">big ridge regression (bigRR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">An extension and optimization of ridge regression</td>
              <td valign="top" align="center" rowspan="1" colspan="1">hglm</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B32" ref-type="bibr">Rönnegård et al., 2010</xref>; <xref rid="B35" ref-type="bibr">Shen et al., 2013</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Least absolute shrinkage and selection operator (LASSO)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Combine both shrinkage and variable selection method</td>
              <td valign="top" align="center" rowspan="1" colspan="1">glmnet</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B10" ref-type="bibr">Friedman et al., 2010</xref>; <xref rid="B28" ref-type="bibr">Ogutu et al., 2012</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Sparse partial least squares (SPLS)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Combining variable selection and modeling in a one-step procedure</td>
              <td valign="top" align="center" rowspan="1" colspan="1">spls</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B5" ref-type="bibr">Chung et al., 2012</xref>; <xref rid="B6" ref-type="bibr">Colombani et al., 2012</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Support vector regression (SVR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Finds an appropriate line (or hyperplane in higher dimensions) to fit the data</td>
              <td valign="top" align="center" rowspan="1" colspan="1">e1071</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B7" ref-type="bibr">Cortes and Vapnik, 1995</xref>; <xref rid="B26" ref-type="bibr">Meyer et al., 2014</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Random forest regression (RFR)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Uses the regression model rooted in bootstrapping sample observations</td>
              <td valign="top" align="center" rowspan="1" colspan="1">randomForest</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B4" ref-type="bibr">Breiman, 2001</xref>; <xref rid="B22" ref-type="bibr">Liaw and Wiener, 2002</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Bayesian regularization neural networks (BRNN)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Connects two hidden layers of opposite directions to the same output</td>
              <td valign="top" align="center" rowspan="1" colspan="1">brnn</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B31" ref-type="bibr">Rodriguez and Flores-Mara, 2019</xref>)</td>
            </tr>
            <tr>
              <th valign="middle" colspan="3" align="left" rowspan="1">GS models based on classification</th>
              <th valign="middle" align="center" rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Support vector classification (SVC)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Finds an optimal boundary between the possible outputs</td>
              <td valign="top" align="center" rowspan="1" colspan="1">e1071</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B7" ref-type="bibr">Cortes and Vapnik, 1995</xref>; <xref rid="B26" ref-type="bibr">Meyer et al., 2014</xref>)</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Random forest classification (RFC)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Uses bagging and feature randomness, consisting of many decision trees</td>
              <td valign="top" align="center" rowspan="1" colspan="1">randomForest</td>
              <td valign="top" align="center" rowspan="1" colspan="1">(<xref rid="B4" ref-type="bibr">Breiman, 2001</xref>; <xref rid="B22" ref-type="bibr">Liaw and Wiener, 2002</xref>)</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap position="float" id="T2">
        <label>Table 2</label>
        <caption>
          <p>Descriptions of the 13 evaluation metrics integrated in G2P.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="middle" align="left" rowspan="1" colspan="1">Evaluation Metrics</th>
              <th valign="middle" align="left" rowspan="1" colspan="1">Description</th>
              <th valign="middle" align="center" rowspan="1" colspan="1">Range</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th valign="middle" colspan="3" align="left" rowspan="1">(I) Correlation-based global metrics</th>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Pearson correlation coefficient (PCC, <italic>r</italic>, <italic>R</italic>)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Strength and direction of the linear relationship between <italic>X<sup>a</sup>
</italic> and <italic>Y<sup>b</sup>
</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Kendall rank correlation coefficient (KCC, tau, τ)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Ordinal association between <italic>X</italic> and <italic>Y</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Spearman rank correlation coefficient (SCC, rho, ρ)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Indicator of how well the relationship between <italic>X</italic> and <italic>Y</italic> can be described using a monotonic function</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Coefficient of determination, <italic>R</italic> squared (<italic>R</italic>
<sup>2</sup>, <italic>r</italic>
<sup>2</sup>)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Evaluating the goodness of fit of <italic>X</italic> and <italic>Y</italic> of linear regression</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Mean squared error (MSE)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Average squared difference between <italic>X</italic> and <italic>Y</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, +∞)</td>
            </tr>
            <tr>
              <th valign="middle" colspan="3" align="left" rowspan="1">(II) Threshold-based metrics</th>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Normalized discounted cumulative gain (NDCG)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Evaluating the prediction ability for selecting individuals that have top-ranked phenotypic values</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Mean normalized discounted cumulative gain (mean NDCG)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Mean of NDCG scores from <italic>k</italic> = 1 to <italic>k = K<sup>c</sup>
</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Relative efficiency (RE)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Expected gains when top <italic>k</italic> individuals are selected</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Accuracy</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Proportion of correctly classified individuals among <italic>K</italic>, for evaluating classification performance</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">F-score</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Balance between precision and recall</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the receiver operating characteristic curve (AUC)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the receiver operating characteristic curve, for evaluating classification performance</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the precision-recall curve (AUCpr)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Area under the precision-recall curve, for evaluating classification performance</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[0, 1]</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Cohen’s kappa coefficient (Kappa)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Evaluating the agreement between <italic>X</italic> and <italic>Y</italic>
</td>
              <td valign="top" align="center" rowspan="1" colspan="1">[-1, 1]</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <label>a</label>
            <p>Observed phenotype. <sup>b</sup>Predicted phenotype. <sup>c</sup>Total number of predicted individuals.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Comparative evaluation of multiple GS methods using a cross-validation (CV) scheme can be executed by the module “G2PcrossValidation,” and this may also facilitate the selection of the optimal parameters to achieve the best model performance. Because multiple GS models and numerous folds of CV are simultaneously evaluated, “G2PCrossValidation” is also empowered with parallel computation on high-performance computing clusters to accelerate the computing efficiency. It is also worth noting that both the “G2P” and “G2PCrossValidation” modules allow users to construct more complex models by including other information besides genotypes. After a comprehensive evaluation of the GS models in the library of G2P, the final result of the evaluated GS models is presented so that users may select the most appropriate model or models for selecting breeding materials.</p>
    </sec>
    <sec id="s2_3">
      <title>Integration of multi-model prediction results</title>
      <p>Because no single model works best for all species and traits, aggregating the results from multiple GS models will further improve the precision of phenotype prediction. G2P offers two strategies, GSMerge and GSEnsemble, to integrate multi-model results, using the functions “GSMerge” and “GSEnsemble,” respectively. The development of the GSMerge algorithm adopted the idea of maximal accuracy–maximal difference (MAMD) based on the evaluation results of different models. First, after phenotype prediction, a matrix of predicted phenotypes multiplying GS models is constructed. Second, the models are ranked based on their overall prediction precision evaluated by one metric (e.g., Pearson correlation coefficient) to generate a ranking, <italic>r1</italic>, and the top model is selected. Third, predicted phenotypic values of the top model are extracted, and then the correlations of its values with the values predicted by the other models are calculated. This generates a new ranking, <italic>r2</italic>. Fourth, the difference between the rankings <italic>r1</italic> and <italic>r2</italic> is calculated, and then a second model is selected that shows not only the best prediction precision but also the maximal difference from the top model. Finally, a new value is computed as the integrated prediction results from averaging the predicted values of the two selected models. In addition to this automatic integration process, the “GSMerge” function can also execute self-defined integration with provided weights from “GSEnsemble” described below or own experience.</p>
      <p>GSEnsemble adopts another strategy, which is to perform multiple rounds of iteration and repetition to integrate multi-model results. GSEnsemble takes the same matrix of prediction results from multi-model analysis as the initial input, and then a list of initial weights computed based on the evaluation of model precision is automatically generated. Subsequently, the self-defined GSMerge integration procedure is applied to the two models that are to be integrated. The difference is that GSEnsemble integrates results by considering the more possible weights of the two models instead of simply averaging the results from the two models. Then, after evaluation and selection, the new result from the first two models is merged with the result from the third model and the corresponding weights are recorded. These integration steps are repeated until the results from all of the models are applied to the iteration and a list of optimal weights is finally generated. It is worth noting that, rather than using one weight combination, GSEnsemble allows users to define the time of repetitions (i.e. the order in which the various models are integrated) to shuffle the input of the result matrix and obtain a weight matrix. Therefore, every set of weight combinations can be used to compute a grand phenotypic value using weighted prediction results of all the GS models in the library. Simply speaking, the fundamental difference between GSMerge and GSEnsemble is that GSEnsemble first generates a list of the optimal combinations of models and weights by a series of iterations and then computes the grand value based on the weighted results of all of the models. However, GSEnsemble processing is slower than GSMerge processing for large training populations.</p>
    </sec>
    <sec id="s2_4">
      <title>Refinement design of training dataset</title>
      <p>Compilation of an appropriate training set is extremely important for model precision and robustness, as the training set should offer sufficient genetic diversity and coverage in sample prediction. Otherwise, it may cause problematic either underfitting or overfitting issues. With the accumulation of more and more samples that are both genotyped and phenotyped, the training dataset will be refined by both selecting representative samples and removing redundant samples. G2P offers the module “TSRefine” to allow both reference-free and reference-guided algorithms to refine the training dataset. The reference-free algorithm uses the concept of the minimum moment aberration (MMA) algorithm to select a subset of candidates with the maximum discrepancy of genotypes. MMA measures the discrepancy between two individuals in their marker genotypes by averaging all pairwise similarities (<xref rid="B18" ref-type="bibr">Jin et al., 2004</xref>; <xref rid="B34" ref-type="bibr">Sen et al., 2007</xref>). In this manner, the refined training dataset may present more representative genetic diversity than the original training set. A reference-free algorithm is preferable when genotypes are difficult to obtain. In contrast, the reference-guided algorithm utilizes the testing dataset as a reference. Through the construction of two matrices of genomic relationship, one within the training set and another between individuals in the testing set with the training set. Also, three alternative criteria, “PEVmean,” “CDmean,” and “Sim,” are used as measurable criteria to seek the optimal solution until the iteration becomes stable (<xref rid="B1" ref-type="bibr">Akdemir et al., 2015</xref>).</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3_1">
      <title>Demo datasets for developing the G2P container</title>
      <p>To illustrate the utility and performance of the G2P container, we used a previously published dataset of maize inbred lines, the Complete-diallel plus unbalanced breeding-derived inter-cross (CUBIC) population, for testing (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>). The CUBIC population contains 1,404 recombinant lines produced from 24 elite inbred lines that have been widely used for maize breeding in China (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>; <xref rid="B24" ref-type="bibr">Luo et al., 2020</xref>). The raw genotypic data, in the binary PLINK format, of the 1,404 lines contains 14 million single-nucleotide polymorphisms (SNPs) called from the whole-genome resequencing of the CUBIC population. The phenotypes used as the target traits for GS prediction include days to tassel (DTT), plant height (PH), and ear weight (EW), representing the three critical developmental stages of maize development. We focused on EW because it is an important trait for evaluating maize yield and one of the most complex and difficult traits to predict due to its low heritability. Members of the CUBIC population were planted in five ecological regions to collect raw phenotypic data, which were further analyzed by the best linear unbiased predictor (BLUP) model to remove variation caused by environmental effects. The original datasets and the details of genotype and phenotype collection and processing can be found at the website <ext-link xlink:href="http://cubicmaize.hzau.edu.cn" ext-link-type="uri">http://cubicmaize.hzau.edu.cn</ext-link> and in the original research articles (<xref rid="B23" ref-type="bibr">Liu et al., 2020</xref>; <xref rid="B24" ref-type="bibr">Luo et al., 2020</xref>).</p>
    </sec>
    <sec id="s3_2">
      <title>Parallel evaluation of the 16 GS models using 13 evaluation metrics</title>
      <p>Subsequently, the 1,000 training samples in the CV-dataset were used for comparison with the 16 GS models in the library using the 13 evaluation metrics by 5-fold CVs with 50 replications (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 1</bold></xref>). As we expected, the 16 GS models showed greatly varied prediction precisions for the three traits. The RFR, Bayes B, and RRBLUP methods achieved the best performance using the most evaluation metrics when predicting EW, DTT, and PH phenotypes (<xref rid="f2" ref-type="fig"><bold>Figure 2A</bold></xref>). For both datasets, the 16 GS models yielded varying precision, with Pearson correlation coefficient (<italic>r</italic>) values ranging from 0.323 to 0.443 when predicting EW (<xref rid="f2" ref-type="fig"><bold>Figures 2B, C</bold></xref>). Among them, the RFR model ranked as the best method, as it achieved the best performance using all five of the correlation-based methods. Bayes B was the best choice if using metrics to predict the top 30% of samples (<xref rid="f2" ref-type="fig"><bold>Figure 2A</bold></xref>). For the other two traits, Bayes A and BL were the top two models for predicting DTT, while Bayes A and Bayes B were the top two for predicting PH (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 2</bold></xref>). This result is consistent with the previous reports that no single method is best for all species and traits, such that careful model selection is critical for effective GS-assisted breeding (<xref rid="B29" ref-type="bibr">Ornella et al., 2014</xref>; <xref rid="B40" ref-type="bibr">Yan et al., 2021</xref>; <xref rid="B30" ref-type="bibr">Robert et al., 2022</xref>). It also highlights the need to integrate the results from multiple evaluation metrics to achieve unbiased selection of the optimal GS models for a specific target trait in a designated species.</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>Parallel evaluation of the GS models. <bold>(A)</bold> The ranks of prediction precisions for days to tasseling (DTT), plant height (PH), and ear weight (EW) of 1,404 maize inbred lines on the CV-dataset and Test-dataset by the 16 GS models with 13 evaluation metrics. <bold>(B, C)</bold> Prediction precision for the EW trait using the 16 GS models. DTT and PH were considered as fixed effects, and the 9,286 SNPs were considered as random effects, on the CV-dataset and Test-dataset, respectively. The precision was evaluated based on the Pearson correlation coefficient (<italic>r</italic>).</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g002" position="float"/>
      </fig>
      <p>Perhaps one of the most important factors affecting model performance is the sample size of the training population (<xref rid="B37" ref-type="bibr">Wray et al., 2013</xref>; <xref rid="B17" ref-type="bibr">Jiang et al., 2020</xref>). To address this, G2P offers an optional function of inferring the optimal population size for model training by using different gradients of the numbers of training samples set by the users. In our demo analysis, we gradually expanded the training set from 200 to 1,000 samples, and then visualized the prediction precision of the 16 models in terms of the Pearson correlation coefficient (<italic>r</italic>) of the three traits with boxplots and line charts (<xref rid="SF1" ref-type="supplementary-material"><bold>Supplementary Figure 1</bold></xref>). Overall, all three traits showed a similar trend whereby the prediction precision of the 16 models gradually improved with the expansion of the training set—for DTT, from 0.429 to 0.603; for PH, from 0.453 to 0.619; and for EW, from 0.280 to 0.478. Furthermore, because considering additional fixed effects in a GS model may also improve prediction precision (<xref rid="B33" ref-type="bibr">Sarinelli et al., 2019</xref>), G2P allows users to add customized fixed effects to the GS model. In the demo analysis, we utilized DTT and PH as fixed effects in addition to the 9,286 SNPs and then performed 5-fold CV with 50 replicates on both the CV-dataset and Test-dataset to evaluate the models (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 3</bold></xref>). In comparison with the results generated from the model only using SNPs as random effects, the prediction precisions of 14 of the 16 models (the exceptions being RR and bigRR) were elevated. Among them, SPLS and LASSO showed the greatest improvement, increasing by 0.066 (<italic>r</italic>: 0.330 to 0.396) and 0.062 (<italic>r</italic>: 0.465 to 0.527) accuracy, respectively (<xref rid="f2" ref-type="fig"><bold>Figures 2B, C</bold></xref>). It is also worth mentioning that G2P allows batch submission of the 16 GS models and the 13 evaluation metrics for parallel evaluation if a cluster of high-performance computers is available. This functionality offers the greatest convenience to the users for comparative evaluation of GS models to assist selection of the optimal GS models.</p>
    </sec>
    <sec id="s3_3">
      <title>A benchmark test of analytical efficiency of the 16 models</title>
      <p>In addition to prediction precision, analytical efficiency is another important factor to consider, especially when the sizes of samples and features are large. G2P records the CPU run time and memory usage when performing model evaluation. In this study, we used the benchmark test to evaluate the analytical efficiency of the 16 GS models under the G2P Singularity environment on a Windows desktop with a configuration of 4-core CPU i5 6600K and 32 GB memory. The benchmark test was performed on the Test-dataset containing the 1,000 samples to record CPU run time and memory usage, and this process was repeated ten times to calculate the average efficiency.</p>
      <p>The averaged run times of the 16 models varied greatly (<xref rid="f3" ref-type="fig"><bold>Figure 3A</bold></xref>). The top three methods were SPLS, RRBLUP and RR, with run times of less than 3.5 seconds. BRR, Bayes A, B and C, and BL needed less than 20 seconds, and the other 8 methods all took more than 100 seconds. It is worth mentioning that, although RFR achieved the best precision when predicting EW, it took the longest, at 529.9 seconds. Memory usage was evaluated using a method called multiple (×) of initial data memory usage, which was 50.54 Mb when the entire dataset was loaded into memory. If no fixed effect was added, SPLS, RRBLUP, RFR, LASSO, and RFC showed the lowest memory usage, below 10×, and the top four memory-usage models were BRNN, RR, RFC and RFR, using 41.56×, 20.44×, 18.05×, and 18.70× memory, respectively (<xref rid="f3" ref-type="fig"><bold>Figure 3B</bold></xref>). When fixed effects were added to the models, memory usage increased in all cases, but to different degrees for most of the models. Finally, we examined how the sample size and marker number influence CPU run time and memory usage of the 16 GS models, finding that both sample size and marker number were positively correlated with the computing resource for most models (<xref rid="f3" ref-type="fig"><bold>Figures 3C-F</bold></xref>). Especially for RFR and RRBLUP, CPU run time and memory usage of RFR were both linearly influenced by marker number and RFR was linearly influenced by sample size.</p>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>Benchmark test of the analytical efficiency of the 16 GS models. <bold>(A, B)</bold> Comparison of results after running the 16 GS models for training and prediction on the CV-dataset in terms of CPU run time <bold>(A)</bold> and memory usage <bold>(B)</bold>. CPU run time is indicated in seconds (s) and memory usage in multiple (×) of running memory over initial data memory. <bold>(C, D)</bold> Correlation of CPU run time with the number of training samples <bold>(C)</bold> and the number of SNPs <bold>(D)</bold>. <bold>(E, F)</bold> Correlation of memory usage in megabytes (MB) with the number of training samples <bold>(E)</bold> and the number of SNPs <bold>(F)</bold>.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g003" position="float"/>
      </fig>
    </sec>
    <sec id="s3_4">
      <title>Integration of multi-model prediction results</title>
      <p>Overall, the prediction precision varied from model to model, but certain models may generate similar predicted results. This is reflected in the pairwise correlations (ranging from 0.54 to 1.00) computed between the predicted phenotypic values by any pair of models. This indicates that complementary relationships may exist between certain GS models, which we may take advantage of to integrate multi-model prediction results. G2P offers two strategies for integrating predicted results from top-precision models, the GSMerge and GSEnsemble algorithms (<xref rid="f4" ref-type="fig"><bold>Figure 4A</bold></xref>). GSMerge automatically selects two top models with relatively high precision and considerable difference in output. It then directly averages the two sets of prediction results to generate a single integrated result. In contrast, GSEnsemble considers the results from all available models, after a search of a set of optimal weights by iteration and repetition, to generate a grand value by summarizing weighted values of all the models (See Methods).</p>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>Improvement of prediction precision for the EW (ear weight) trait through integration of multi-model results. <bold>(A)</bold> Schematic illustration of the algorithms for the two result integration functions. GSMerge selects models according to the difference of two ranks (ranks of prediction precision and ranks of correlation coefficients between top1 model and others). Integration results of GSMerge is the average of prediction results of two selected models. The deeper the color, the higher the correlation. By generating a weight list and executing GSMerge, GSEnsemble selects models and gets weights of models after multiple iterations and repetitions. Integration results of GSEnsemble is the weighted average of all models. <bold>(B)</bold> Prediction precisions by GSMerge- and GSEnsemble-based integration are better than those for the single model, BRR, with fixed effects considered on the CV-dataset. The prediction precision was evaluated based on the Pearson correlation coefficient (<italic>r</italic>). <bold>(C)</bold> After integrated combination and weights from the CV-dataset are utilized on predicting Test-dataset, prediction precisions for GSMerge- and GSEnsemble-based integration are improved relative to those predicted by the best single model, RKHS, with fixed effect considered. <bold>(D)</bold> The statistics for the frequency of models selected by the GSMerge strategy using 50 times 5-fold cross validation on the CV-dataset. <bold>(E)</bold> The statistics of the weights of the models used for GSEnsemble on the CV-dataset.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g004" position="float"/>
      </fig>
      <p>Within the CV-dataset, we tested the effectiveness of integration of multi-model predictions by the two algorithms for each fold of CV. As we anticipated, when considering fixed effects, both GSMerge and GSEnsemble strategies improved the precision of EW prediction compared to the single BRR model that was the best predictor, increasing the <italic>r</italic> value from 0.464 to 0.493 and 0.502, respectively (<xref rid="f4" ref-type="fig"><bold>Figure 4B</bold></xref>). Consistent results were also observed when fixed effects were not considered. The precisions of GSMerge and GSEnsemble also increased, from 0.443 (RFR model) to 0.445 and 0.465, respectively (<xref rid="SF2" ref-type="supplementary-material"><bold>Supplementary Figure 2A</bold></xref>). Furthermore, the frequency of models selected by GSMerge among the 50 times 5-fold (a total of 250 repetitions) were summarized to help direct model selection for integration of the prediction results for the Test-dataset (<xref rid="f4" ref-type="fig"><bold>Figure 4D</bold></xref>). For GSEnsemble, the mean weights of all 250 repetitions were calculated to obtain a set of weights of the models to further utilize GSEnsemble for integrating the results from the Test-dataset (<xref rid="f4" ref-type="fig"><bold>Figure 4E</bold></xref>). The same test of GSEnsemble-based integration was performed without fixed effects, and the outcome was consistent with the outcome when considering fixed effects (<xref rid="SF2" ref-type="supplementary-material"><bold>Supplementary Figure 2</bold></xref>). Therefore, the summarized results not only give the users a reference for integration of multi-model prediction, but also assist users in understanding which model contributes the most weight under results integration.</p>
      <p>To verify the effectiveness of prediction result integration, we used the two most commonly used models (RFR and BayesB) for GSMerge on the CV-dataset to perform GSMerge on the Test-dataset as well as mean weights list for GSEnsemble on the CV-dataset to perform GSEnsemble on the Test-dataset. As we anticipated, both the GSMerge and GSEnsemble algorithms improved the prediction precision on the EW traits compared to the single models RFR and RKHS with and without fixed effects considered, respectively (<xref rid="f4" ref-type="fig"><bold>Figure 4C</bold></xref>; <xref rid="SF2" ref-type="supplementary-material"><bold>Supplementary Figure 2B</bold></xref>). It’s also worth of noting that improvement of prediction precision by GSEnsemble was better than that for GSMerge, regardless of whether fixed effects were considered. These results indicate that multi-model integration is a practical, effective strategy to achieve better prediction of desired phenotypes.</p>
    </sec>
    <sec id="s3_5">
      <title>Application of G2P container on real-world breeding data</title>
      <p>We applied the G2P container on two sets of real-world breeding data provided by a collaborating seed company. The first dataset (Dataset 1) contained 7, 046 F<sub>1</sub> hybrids generated by crossing 3, 523 inbred lines with 2 tester lines, which were planted in the ecological zone of Northeast China in 2021 and 2022 to collect phenotypes. The second dataset (Dataset 2) contained 6,777 F<sub>1</sub> hybrids generated by crossing 2, 259 inbred lines with 3 tester lines, which were planted in Central China in 2021 and 2022 to collect phenotypes. The total 5, 782 inbred lines and the 5 tester lines were genotyped using the genotyping by targeted sequencing (GBTS) platform containing 44, 229 SNPs. We first analyzed the genotypic data of the 5, 787 samples, and simulated the heterogzygous genotypes of the total 13, 841 F<sub>1</sub> hybrids, utilizing the preprocessing pipeline in the G2P container described in <xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Materials</bold></xref>. The entire streamlined procedure of genotypic data analysis took about ten minutes on a desktop server (Xeon-E5 with 4-core and 64 GB memory). The raw phenotypic data of grain yield (GY) per unit collected in the two years and six locations planted in each of the ecological zones were processed by the BLUP algorithm.</p>
      <p>After the genotypic and phenotypic data were processed, we then performed the GS analysis module with the 16 GS models and 13 evaluation metrics. We randomly selected 2, 046 and 1, 777 F1 hyrbids from the Dataset 1 and 2 as external validation set, respectively. Then, we utilized the 5, 000 samples in each of the datasets to train and evaluate models, followed by predicting the GY per unit of the samples in the two external validation set. At last, the predicted GY phenotypes of the validating samples were generated by the GSEnsemble and GSMerge algorithms to integrate multi-model prediction results. The GS analysis procedure took about tree minutes on the same server to generate the model evaluation result (<xref rid="SM1" ref-type="supplementary-material"><bold>Supplementary Table 4</bold></xref>). The evaluation results showed that RRBLUP method exhibited relatively stable and precise prediction results compared to other methods in the Dataset 1, while the RKHS method outperformed other GS models. We then utilized the two algorithms, namely GSMerge and GSEnsemble developed in G2P, to integrate multi-model prediction results. For the Dataset 1, the prediction precision were improved from 0.500 (RKHS model) to 0.519 (GSEnsemble) evaluated by Pearson correlation coefficient (<xref rid="SF3" ref-type="supplementary-material"><bold>Supplementary Figure 3A</bold></xref>). For the Dataset 2, the prediction precision were improved from 0.503 (RRBLUP model) to 0.530 (GSEnsemble) evaluated by Pearson correlation (<xref rid="SF3" ref-type="supplementary-material"><bold>Supplementary Figure 3B</bold></xref>). This result indicates that integration of multi-model prediction result may greatly improved prediction precision.</p>
    </sec>
    <sec id="s3_6">
      <title>Refinement design of training dataset</title>
      <p>In addition to sample size, selecting a representative set of training samples while achieving the maximal coverage of genetic diversity in predicting samples for which phenotypes are not measured is a critical step in GS-assisted breeding. Three main advantages may benefit from refinement design of the training dataset based on the genotypes of samples: first, it can decrease the cost of phenotyping when a subset of training samples is selected; second, it may avoid model overfitting if the training samples do not properly encompass the genetic diversity of predicting samples; third, training samples may continuously grow during the actual breeding practice, and it becomes necessary to continually reevaluate the genetic structure of newly phenotyped and genotyped samples. To assist the refinement design of a training dataset, G2P offers the TSRefine module, which facilitates selection of a subset of samples from the total training set using reference-free and reference-guided algorithms (See Methods). To test the effectiveness of the TSRefine function, we compared the prediction precisions using a variety of training set sizes by random selection (RD) and TSRefine selection of 40 to 1,000 samples. The comparison showed that the PEVmean and CDmean of RRBLUP have an overwhelming advantage over those for random selection (<xref rid="f5" ref-type="fig"><bold>Figure 5A</bold></xref>). On average, prediction precisions using the training set by TSRefine selection were 0.051 to 0.056 higher than those obtained using random selection evaluated by the Pearson correlation coefficient (<italic>r</italic>). When TSRefine selected 500 representative training samples using the reference-guided model (PEVmean), the prediction precision on the Test-dataset dropped only 8.3%, from 0.494 to 0.453, compared to the precision using the entire set of the 1,000 samples (<xref rid="f5" ref-type="fig"><bold>Figure 5B</bold></xref>). This indicates that phenotyping cost may be reduced to half with only an 8.3% sacrifice in precision.</p>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>Comparison of different methods for refinement design of the training dataset. <bold>(A)</bold> Comparison of prediction precisions of the Test-dataset on EW (ear weight) between the training sets compiled by TSRefine selection (Ref-free for reference-free method, CDmean, PEVmean and Sim for reference-guided method) and random selection (RD) from the CV-dataset. RRBLUP was the GS model used to perform prediction from refined training set to Test-dataset and prediction precision evaluated based on the Pearson correlation coefficient (<italic>r</italic>). <bold>(B)</bold> Percentage decrease in prediction precision over the highest precision using different numbers of samples compiled by CDmean and PEVmean. Phenotyping cost represents the percentage of TSRefine selection in the entire CV-dataset (<italic>n</italic> = 1,000, where <italic>n</italic> is the number of selected samples). <bold>(C)</bold> Comparison of the genetic distributions of the original, prediction, and refined training samples by PCA.</p>
        </caption>
        <graphic xlink:href="fpls-14-1207139-g005" position="float"/>
      </fig>
      <p>Additionally, TSRefine can illustrate the distribution of the original, predicting, and refined training sets using a scatter plot generated by PCA. With this, users can better understand the genetic relationship of the above three sets in the background of the whole population structure (<xref rid="f5" ref-type="fig"><bold>Figure 5C</bold></xref>). If no genotypes of predicting samples are available, an alternative is to utilize a reference-free mode of refinement design of training dataset. When 600 representative samples were selected to compile an optimized training set, the prediction precision on the Test-dataset dropped only 5.2%, from 0.494 to 0.468 (PEVmean; <xref rid="f5" ref-type="fig"><bold>Figure 5B</bold></xref>). Notably, however, this strategy can be applied only when the training and prediction samples are largely similar in terms of genetic backgrounds. Otherwise, it may cause either model overfitting or underfitting.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>GS has become a novel breeding strategy that is considered to be an important driving force for the new era of crop breeding (<xref rid="B17" ref-type="bibr">Jiang et al., 2020</xref>). Many statistical and informatics methods have been utilized to develop GS models to facilitate prediction of phenotypes from genotypes. The most popular methods include best linear unbiased predictor (BLUP)-based, Bayesian-based and machine learning-based methods. However, because of the sophisticated genetic complexity of crop species, no single method will work best for all species and traits. Model selection to determine the most appropriate model based on the particular traits and species therefore is a crucial step in GS. To solve this challenge, we utilize the Singularity platform to develop the G2P container, which packages up a library of 16 state-of-the-art GS models and 13 evaluation metrics. The main function of G2P is to perform batch evaluation of multiple GS models with uniformed analytical framework assisted by parallel computing. This utility offers great convenience for users by enabling them to perform comprehensive and unbiased model evaluation without having programming experience.</p>
    <p>Another important feature of G2P is its use of two strategies to integrate multi-model prediction results in an automatic fashion. Our analysis showed that result integration may effectively improve prediction precision. G2P also offers the capability of conducting refinement design of training datasets, allowing selection of a subset of optimized training samples based on genetic diversity analysis of training and predicting populations. This function is quite useful in practice, as it can not only greatly reduce the cost of phenotyping when constructing training population, but also help design a GS project amid the continuous growth of breeding data with available genotypes and phenotypes. In addition to its main function of GS analysis, G2P also provides a series of bioinformatics tools for data preprocessing including data filtration, file format conversion, representative SNP selection, genotype and phenotype imputation, and data quality control. These tools greatly simplify the operation for users without much programming skill.</p>
    <p>Taking the advantages of Singularity platform, the G2P container is flexible and easy to install and to upgrade, but limitations still have to be noticed. First of all, the purpose of developing G2P container is provide a convinent environment which may simplify the procedure of installing GS tools and performing GS analysis, so that starter users without sufficient experinces in GS analysis and programming skills may use it. Thus, only a limited number of GS tools are packaged with the Singularity platform, which are easy to be developed as standard, automated pipeline. Many of machine learning or deep learning (DL)-based GS tools were not integrated into G2P container, as these methods requires sophisticated parameter tuning or GPU computing. If an experienced user wants to perform ML or DL-based GS analysis, standlone tools are highly recommended. Secondly, because one of the novel features of G2P container is to integrate prediction results from the 16 GS models, computing efficiency is also an important factor that have to be considered. Thus, preprocessing of training dataset is highly recommended to compile a marker panel better within 10K SNPs, and the training population better contains less than 10K samples. If a user wants to perform GS analysis on much larger sample set with a marker panel containing over tens of thousands of SNPs, it’s better to use standalone version of GS tools. Morever, the current analytical pipelines in G2P only consider additive effects when training a BLUP-based GS model and epistatic interactions between SNPs were not considered, as modulating of epistatsis may expotentially increase computational complexity causing unexpected error during model training. At last, the current version of G2P container only integrate regression-based methods that are mostly used for predicting quantatitve traits of common crop species, without considering special scenarios or traits subjected to GS analysis. To cope with the above-mentioned limitations, we plan to continuously upgrade the G2P container in the near future, with more GS algorithms, more analytical functions, and more user-friendly data input such as relationship matrix or kinship matrix. In the future, G2P will be developed as a workshop for crop breeders who wish to conduct cloud-based precision-designed breeding.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data availability statement</title>
    <p>Publicly available datasets were analyzed in this study. The raw datasets can be found at <ext-link xlink:href="http://cubicmaize.hzau.edu.cn/" ext-link-type="uri">http://cubicmaize.hzau.edu.cn/</ext-link> and the filtered data used in this study can be found at <ext-link xlink:href="https://g2p-env.github.io/" ext-link-type="uri">https://g2p-env.github.io/</ext-link> or built-in dataset for example.</p>
  </sec>
  <sec sec-type="author-contributions" id="s6">
    <title>Author contributions</title>
    <p>QC and SQJ conceived and supervised the project. QC, SQJ, XFW and MC wrote the manuscript. QW, ZXQ and QC developed the main G2P packages and performed demo analysis using the maize CUBIC population. SQJ and SJ developed the pipelines for data preprocessing. TL developed the evaluation modules. ZXQ, JY and RF performed the benchmark test of G2P. All authors read and approved the final manuscript.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We appreciate the Beijing Tongzhou International Seed Technology Co., Ltd for offering real-world breeding data. We would also like to express our sincere appreciation to the following individuals for their significant contributions to the generation of this data: Ms. Feng Jin and Ms. Xiuai Xia designed the production of DH lines and F1 combinations, Ms. Fang Huang worked in the field. Ms. Zixuan Tian and Ms. Xiaocui Zhao collected phenotypic data and handled genomic data of real-world dataset.</p>
  </ack>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s9">
    <title>Publisher’s note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <sec sec-type="supplementary-material" id="s10">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fpls.2023.1207139/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fpls.2023.1207139/full#supplementary-material</ext-link>
</p>
    <supplementary-material id="SF1" position="float" content-type="local-data">
      <label>Supplementary Figure 1</label>
      <caption>
        <p>Comparison of the prediction precision on the Test-dataset for DTT (days to tasseling), PH (plant height), and EW (ear weight) got the 16 GS models overall <bold>(A)</bold> and separately <bold>(B)</bold> using different numbers of training samples.</p>
      </caption>
      <media xlink:href="Image_1.jpeg">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SF2" position="float" content-type="local-data">
      <label>Supplementary Figure 2</label>
      <caption>
        <p><bold>(A)</bold> Prediction precisions by GSMerge- and GSEnsemble-based integration are better than those by the single model RFR without fixed effects considered on the CV-dataset. The prediction precision was evaluated based on the Pearson correlation coefficient (<italic>r</italic>). <bold>(B)</bold> By applying integrated combination and weights from the CV-dataset to prediction of the Test-dataset, prediction precisions with GSMerge- and GSEnsemble-based integration are more improved than those with the best single model, RFR, without fixed effects considered. <bold>(C)</bold> The statistics of model selection frequency by the GSMerge strategy through 50 times 5-fold cross validation on the CV-dataset. <bold>(D)</bold> The statistics of the weights of the 14 models used for GSEnsemble strategy on the CV-dataset.</p>
      </caption>
      <media xlink:href="Image_2.jpeg">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SF3" position="float" content-type="local-data">
      <label>Supplementary Figure 3</label>
      <caption>
        <p>The prediction precision was evaluated by Pearson correlation coefficient of two results integration methods on real-world breeding data. <bold>(A)</bold> The ecological zone of Northeast China and <bold>(B)</bold> The ecological zone of Central China</p>
      </caption>
      <media xlink:href="Image_3.jpeg">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SF4" position="float" content-type="local-data">
      <media xlink:href="DataSheet_1.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="Table_1.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM2" position="float" content-type="local-data">
      <media xlink:href="Table_2.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM3" position="float" content-type="local-data">
      <media xlink:href="Table_3.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="SM4" position="float" content-type="local-data">
      <media xlink:href="Table_4.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akdemir</surname><given-names>D.</given-names></name><name><surname>Sanchez</surname><given-names>J. I.</given-names></name><name><surname>Jannink</surname><given-names>J.-L.</given-names></name></person-group> (<year>2015</year>). <article-title>Optimization of genomic selection training populations with a genetic algorithm</article-title>. <source>Genet. Selection Evol.</source>
<volume>47</volume>, <fpage>1</fpage>–<lpage>10</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s12711-015-0116-6</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belamkar</surname><given-names>V.</given-names></name><name><surname>Guttieri</surname><given-names>M. J.</given-names></name><name><surname>Hussain</surname><given-names>W.</given-names></name><name><surname>Jarquin</surname><given-names>D.</given-names></name><name><surname>El-Basyoni</surname><given-names>I.</given-names></name><name><surname>Poland</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Genomic selection in preliminary yield trials in a winter wheat breeding program</article-title>. <source>G3: Genes Genomes Genet.</source><volume>8</volume>, <fpage>2735</fpage>–<lpage>2747</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.118.200415</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blondel</surname><given-names>M.</given-names></name><name><surname>Onogi</surname><given-names>A.</given-names></name><name><surname>Iwata</surname><given-names>H.</given-names></name><name><surname>Ueda</surname><given-names>N.</given-names></name></person-group> (<year>2015</year>). <article-title>A ranking approach to genomic selection</article-title>. <source>PLoS One</source>
<volume>10</volume>, <elocation-id>e0128570</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0128570</pub-id>
<pub-id pub-id-type="pmid">26068103</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L.</given-names></name></person-group> (<year>2001</year>). <article-title>Random forests</article-title>. <source>Mach. Learn.</source>
<volume>45</volume>, <fpage>5</fpage>–<lpage>32</lpage>. doi: <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname><given-names>D.</given-names></name><name><surname>Chun</surname><given-names>H.</given-names></name><name><surname>Keles</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <article-title>Spls: sparse partial least squares (SPLS) regression and classification</article-title>. <source>R package version</source>
<volume>2</volume>, <fpage>1</fpage>–<lpage>1</lpage>.</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colombani</surname><given-names>C.</given-names></name><name><surname>Croiseau</surname><given-names>P.</given-names></name><name><surname>Fritz</surname><given-names>S.</given-names></name><name><surname>Guillaume</surname><given-names>F.</given-names></name><name><surname>Legarra</surname><given-names>A.</given-names></name><name><surname>Ducrocq</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>A comparison of partial least squares (PLS) and sparse PLS regressions in genomic selection in French dairy cattle</article-title>. <source>J. dairy Sci.</source><volume>95</volume>, <fpage>2120</fpage>–<lpage>2131</lpage>. doi: <pub-id pub-id-type="doi">10.3168/jds.2011-4647</pub-id><pub-id pub-id-type="pmid">22459857</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C.</given-names></name><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>1995</year>). <article-title>Support-vector networks</article-title>. <source>Mach. Learn.</source>
<volume>20</volume>, <fpage>273</fpage>–<lpage>297</lpage>. doi: <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id>
</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>de los Campos</surname><given-names>G.</given-names></name><name><surname>Pérez</surname><given-names>P.</given-names></name></person-group> (<year>2015</year>). <source>BGLR: Bayesian generalized linear regression</source> (<publisher-name>R package version 1.0</publisher-name>).</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Endelman</surname><given-names>J. B.</given-names></name></person-group> (<year>2011</year>). <article-title>Ridge regression and other kernels for genomic selection with R package rrBLUP</article-title>. <source>Plant Genome</source>
<volume>4</volume>, <fpage>250</fpage>–<lpage>255</lpage>. doi: <pub-id pub-id-type="doi">10.3835/plantgenome2011.08.0024</pub-id>
</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name><name><surname>TibshIrani</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>). <article-title>Regularization paths for generalized linear models <italic>via</italic> coordinate descent</article-title>. <source>J. Stat. software</source>
<volume>33</volume>, <fpage>1</fpage>. doi: <pub-id pub-id-type="doi">10.18637/jss.v033.i01</pub-id>
</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garofoli</surname><given-names>A.</given-names></name><name><surname>Paradiso</surname><given-names>V.</given-names></name><name><surname>Montazeri</surname><given-names>H.</given-names></name><name><surname>Jermann</surname><given-names>P. M.</given-names></name><name><surname>Roma</surname><given-names>G.</given-names></name><name><surname>Tornillo</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>PipeIT: A singularity container for molecular diagnostic somatic variant calling on the ion torrent next-generation sequencing platform</article-title>. <source>J. Mol. Diagnostics</source><volume>21</volume>, <fpage>884</fpage>–<lpage>894</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jmoldx.2019.05.001</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffner</surname><given-names>E. L.</given-names></name><name><surname>Jannink</surname><given-names>J.-L.</given-names></name><name><surname>Iwata</surname><given-names>H.</given-names></name><name><surname>Souza</surname><given-names>E.</given-names></name><name><surname>Sorrells</surname><given-names>M. E.</given-names></name></person-group> (<year>2011</year>). <article-title>Genomic selection accuracy for grain quality traits in biparental wheat populations</article-title>. <source>Crop Sci.</source>
<volume>51</volume>, <fpage>2597</fpage>–<lpage>2606</lpage>. doi: <pub-id pub-id-type="doi">10.2135/cropsci2011.05.0253</pub-id>
</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hickey</surname><given-names>L. T.</given-names></name><name><surname>Hafeez</surname><given-names>N.</given-names></name><name><surname>Robinson</surname><given-names>H.</given-names></name><name><surname>Jackson</surname><given-names>S. A.</given-names></name><name><surname>Leal-Bertioli</surname><given-names>S. C. M.</given-names></name><name><surname>Tester</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Breeding crops to feed 10 billion</article-title>. <source>Nat. Biotechnol.</source><volume>37</volume>, <fpage>744</fpage>–<lpage>754</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41587-019-0152-9</pub-id><pub-id pub-id-type="pmid">31209375</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>B.</given-names></name><name><surname>Zhao</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>F.</given-names></name><name><surname>Xie</surname><given-names>T.</given-names></name><name><surname>Xu</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Genomic selection and genetic architecture of agronomic traits during modern rapeseed breeding</article-title>. <source>Nat. Genet.</source><volume>54</volume>, <fpage>694</fpage>–<lpage>704</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41588-022-01055-6</pub-id><pub-id pub-id-type="pmid">35484301</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iacoangeli</surname><given-names>A.</given-names></name><name><surname>Al Khleifat</surname><given-names>A.</given-names></name><name><surname>Sproviero</surname><given-names>W.</given-names></name><name><surname>Shatunov</surname><given-names>A.</given-names></name><name><surname>Jones</surname><given-names>A. R.</given-names></name><name><surname>Morgan</surname><given-names>S. L.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>DNAscan: personal computer compatible NGS analysis, annotation and visualisation</article-title>. <source>BMC bioinformatics</source><volume>20</volume>(<issue>1</issue>), <page-range>1–10</page-range>. doi: <pub-id pub-id-type="doi">10.1186/s12859-019-2791-8</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jannink</surname><given-names>J.-L.</given-names></name><name><surname>Lorenz</surname><given-names>A. J.</given-names></name><name><surname>Iwata</surname><given-names>H.</given-names></name></person-group> (<year>2010</year>). <article-title>Genomic selection in plant breeding: from theory to practice</article-title>. <source>Briefings Funct. Genomics</source>
<volume>9</volume>, <fpage>166</fpage>–<lpage>177</lpage>. doi: <pub-id pub-id-type="doi">10.1093/bfgp/elq001</pub-id>
</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>S.</given-names></name><name><surname>Cheng</surname><given-names>Q.</given-names></name><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Fu</surname><given-names>R.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name></person-group> (<year>2020</year>). <article-title>Genome optimization for improvement of maize breeding</article-title>. <source>Theor. Appl. Genet.</source>
<volume>135</volume>
<issue>(5)</issue>, <fpage>1491</fpage>–<lpage>1502</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-019-03493-z</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>C.</given-names></name><name><surname>Lan</surname><given-names>H.</given-names></name><name><surname>Attie</surname><given-names>A. D.</given-names></name><name><surname>Churchill</surname><given-names>G. A.</given-names></name><name><surname>Bulutuglo</surname><given-names>D.</given-names></name><name><surname>Yandell</surname><given-names>B. S.</given-names></name></person-group> (<year>2004</year>). <article-title>Selective phenotyping for increased efficiency in genetic mapping studies</article-title>. <source>Genetics</source>
<volume>168</volume>, <fpage>2285</fpage>–<lpage>2293</lpage>. doi: <pub-id pub-id-type="doi">10.1534/genetics.104.027524</pub-id>
<pub-id pub-id-type="pmid">15611192</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>P.</given-names></name><name><surname>Bagaria</surname><given-names>P. K.</given-names></name><name><surname>Rakshit</surname><given-names>S.</given-names></name><name><surname>Roorkiwal</surname><given-names>M.</given-names></name><name><surname>Varshney</surname><given-names>R. K.</given-names></name><name><surname>Stewart-Brown</surname><given-names>B. B.</given-names></name></person-group> (<year>2019</year>). <article-title>Genomic selection for yield and seed composition traits within an applied soybean breeding program</article-title>. <source>Funct. Integr. Genomics</source>
<volume>9</volume>, <fpage>2253</fpage>–<lpage>2265</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.118.200917</pub-id>
</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurtzer</surname><given-names>G. M.</given-names></name><name><surname>Sochat</surname><given-names>V.</given-names></name><name><surname>Bauer</surname><given-names>M. W.</given-names></name></person-group> (<year>2017</year>). <article-title>Singularity: Scientific containers for mobility of compute</article-title>. <source>PLoS One</source>
<volume>12</volume>, <elocation-id>e0177459</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0177459</pub-id>
<pub-id pub-id-type="pmid">28494014</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>T.</given-names></name><name><surname>Jiang</surname><given-names>S.</given-names></name><name><surname>Fu</surname><given-names>R.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Cheng</surname><given-names>Q.</given-names></name><name><surname>Jiang</surname><given-names>S.</given-names></name></person-group> (<year>2023</year>). <article-title>IP4GS: Bringing genomic selection analysis to breeders</article-title>. <source>Front. Plant Sci.</source>
<volume>14</volume>. doi: <pub-id pub-id-type="doi">10.3389/fpls.2023.1131493</pub-id>
</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liaw</surname><given-names>A.</given-names></name><name><surname>Wiener</surname><given-names>M.</given-names></name></person-group> (<year>2002</year>). <article-title>Classification and regression by randomForest</article-title>. <source>R News</source>
<volume>2</volume>, <fpage>18</fpage>–<lpage>22</lpage>.</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Xiao</surname><given-names>Y.</given-names></name><name><surname>Luo</surname><given-names>J.</given-names></name><name><surname>Qiao</surname><given-names>F.</given-names></name><name><surname>Yang</surname><given-names>W.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>CUBIC: an atlas of genetic architecture promises directed maize improvement</article-title>. <source>Genome Biol.</source><volume>21</volume>, <fpage>1</fpage>–<lpage>17</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13059-020-1930-x</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>J.</given-names></name><name><surname>Wei</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Cheng</surname><given-names>S.</given-names></name><name><surname>Xiao</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>MaizeCUBIC: a comprehensive variation database for a maize synthetic population</article-title>. <source>Database</source><volume>2020</volume>. doi: <pub-id pub-id-type="doi">10.1093/database/baaa044</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meuwissen</surname><given-names>T. H.</given-names></name><name><surname>Hayes</surname><given-names>B. J.</given-names></name><name><surname>Goddard</surname><given-names>M.</given-names></name></person-group> (<year>2001</year>). <article-title>Prediction of total genetic value using genome-wide dense marker maps</article-title>. <source>Genetics</source>
<volume>157</volume>, <fpage>1819</fpage>–<lpage>1829</lpage>. doi: <pub-id pub-id-type="doi">10.1093/genetics/157.4.1819</pub-id>
<pub-id pub-id-type="pmid">11290733</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>D.</given-names></name><name><surname>Dimitriadou</surname><given-names>E.</given-names></name><name><surname>Hornik</surname><given-names>K.</given-names></name><name><surname>Weingessel</surname><given-names>A.</given-names></name><name><surname>Leisch</surname><given-names>F.</given-names></name></person-group> (<year>2014</year>). “<article-title>e1071: Misc Functions of the Department of Statistics (e1071), TU Wien</article-title>,” (<publisher-name>R package version</publisher-name>).</mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>N. H.</given-names></name><name><surname>Jahoor</surname><given-names>A.</given-names></name><name><surname>Jensen</surname><given-names>J. D.</given-names></name><name><surname>Orabi</surname><given-names>J.</given-names></name><name><surname>Cericola</surname><given-names>F.</given-names></name><name><surname>Edriss</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Genomic prediction of seed quality traits using advanced barley breeding lines</article-title>. <source>PLoS One</source><volume>11</volume>, <elocation-id>e0164494</elocation-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0164494</pub-id><pub-id pub-id-type="pmid">27783639</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogutu</surname><given-names>J. O.</given-names></name><name><surname>Schulz-Streeck</surname><given-names>T.</given-names></name><name><surname>Piepho</surname><given-names>H.-P.</given-names></name></person-group> (<year>2012</year>). <article-title>Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions</article-title>. <volume>6</volume>, <fpage>1</fpage>–<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1186/1753-6561-6-S2-S10</pub-id>
</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ornella</surname><given-names>L.</given-names></name><name><surname>Pérez</surname><given-names>P.</given-names></name><name><surname>Tapia</surname><given-names>E.</given-names></name><name><surname>González-Camacho</surname><given-names>J.</given-names></name><name><surname>Burgueño</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Genomic-enabled prediction with classification algorithms</article-title>. <source>Heredity</source><volume>112</volume>, <fpage>616</fpage>–<lpage>626</lpage>. doi: <pub-id pub-id-type="doi">10.1038/hdy.2013.144</pub-id><pub-id pub-id-type="pmid">24424163</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robert</surname><given-names>P.</given-names></name><name><surname>Auzanneau</surname><given-names>J.</given-names></name><name><surname>Goudemand</surname><given-names>E.</given-names></name><name><surname>Oury</surname><given-names>F.-X.</given-names></name><name><surname>Rolland</surname><given-names>B.</given-names></name><name><surname>Heumez</surname><given-names>E.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Phenomic selection in wheat breeding: identification and optimisation of factors influencing prediction accuracy and comparison to genomic selection</article-title>. <source>Theor. Appl. Genet.</source><volume>135</volume>, <fpage>895</fpage>–<lpage>914</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-021-04005-8</pub-id><pub-id pub-id-type="pmid">34988629</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodriguez</surname><given-names>F. H.</given-names></name><name><surname>Flores-Mara</surname><given-names>R.</given-names></name></person-group> (<year>2019</year>). <article-title>Genome-wide association analysis for resistance to infectious pancreatic necrosis virus identifies candidate genes involved in viral replication and immune response in rainbow trout (Oncorhynchus mykiss)</article-title>. <source>G3: Genes Genomes Genet.</source>
<volume>9</volume>, <fpage>2897</fpage>–<lpage>2904</lpage>. doi: <pub-id pub-id-type="doi">10.1534/g3.119.400463</pub-id>
</mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rönnegård</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>X.</given-names></name><name><surname>Alam</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>hglm: A package for fitting hierarchical generalized linear models</article-title>. <source>R J.</source>
<volume>2</volume>, <fpage>20</fpage>–<lpage>28</lpage>. doi: <pub-id pub-id-type="doi">10.32614/RJ-2010-009</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarinelli</surname><given-names>J. M.</given-names></name><name><surname>Murphy</surname><given-names>J. P.</given-names></name><name><surname>Tyagi</surname><given-names>P.</given-names></name><name><surname>Holland</surname><given-names>J. B.</given-names></name><name><surname>Johnson</surname><given-names>J. W.</given-names></name><name><surname>Mergoum</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Training population selection and use of fixed effects to optimize genomic predictions in a historical USA winter wheat panel</article-title>. <source>Theor. Appl. Genet.</source><volume>132</volume>, <fpage>1247</fpage>–<lpage>1261</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-019-03276-6</pub-id><pub-id pub-id-type="pmid">30680419</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sen</surname><given-names>Ś.</given-names></name><name><surname>Satagopan</surname><given-names>J. M.</given-names></name><name><surname>BrOman</surname><given-names>K. W.</given-names></name><name><surname>Churchill</surname><given-names>G. A.</given-names></name></person-group> (<year>2007</year>). <article-title>R/qtlDesign: inbred line cross experimental design</article-title>. <source>Mamm. Genome</source>
<volume>18</volume>, <fpage>87</fpage>–<lpage>93</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00335-006-0090-y</pub-id>
<pub-id pub-id-type="pmid">17347894</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>X.</given-names></name><name><surname>Alam</surname><given-names>M.</given-names></name><name><surname>Fikse</surname><given-names>F.</given-names></name><name><surname>Rönnegård</surname><given-names>L.</given-names></name></person-group> (<year>2013</year>). <article-title>A novel generalized ridge regression method for quantitative genetics</article-title>. <source>Genetics</source>
<volume>193</volume>, <fpage>1255</fpage>–<lpage>1268</lpage>. doi: <pub-id pub-id-type="doi">10.1534/genetics.112.146720</pub-id>
<pub-id pub-id-type="pmid">23335338</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Qu</surname><given-names>H.</given-names></name><name><surname>Cui</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>R.</given-names></name><name><surname>Chater</surname><given-names>J. M.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Boosting predictabilities of agronomic traits in rice using bivariate genomic selection</article-title>. <source>Briefings Bioinf.</source><volume>22</volume>, <elocation-id>bbaa103</elocation-id>. doi: <pub-id pub-id-type="doi">10.1093/bib/bbaa103</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wray</surname><given-names>N. R.</given-names></name><name><surname>Yang</surname><given-names>J.</given-names></name><name><surname>Hayes</surname><given-names>B. J.</given-names></name><name><surname>Price</surname><given-names>A. L.</given-names></name><name><surname>Goddard</surname><given-names>M. E.</given-names></name><name><surname>Visscher</surname><given-names>P. M.</given-names></name></person-group> (<year>2013</year>). <article-title>Pitfalls of predicting complex traits from SNPs</article-title>. <source>Nat. Rev. Genet.</source>
<volume>14</volume>, <fpage>507</fpage>–<lpage>515</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nrg3457</pub-id>
<pub-id pub-id-type="pmid">23774735</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Ma</surname><given-names>K.</given-names></name><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Zhou</surname><given-names>K.</given-names></name><name><surname>Yu</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Genomic selection: A breakthrough technology in rice breeding</article-title>. <source>Crop J.</source><volume>9</volume>, <fpage>669</fpage>–<lpage>677</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cj.2021.03.008</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name></person-group> (<year>2022</year>a). <article-title>Machine learning bridges omics sciences and plant breeding</article-title>. <source>Trends Plant Science.</source>
<volume>28</volume>, <page-range>199–210</page-range> doi: <pub-id pub-id-type="doi">10.1016/j.tplants.2022.08.018</pub-id>
</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Cheng</surname><given-names>Q.</given-names></name><name><surname>Jiang</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Xiao</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>LightGBM: Accelerated genomically designed crop breeding through ensemble learning</article-title>. <source>Genome Biol.</source><volume>22</volume>, <fpage>1</fpage>–<lpage>24</lpage>. doi: <pub-id pub-id-type="doi">10.1186/s13059-021-02492-y</pub-id><pub-id pub-id-type="pmid">33397451</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Youens-Clark</surname><given-names>K.</given-names></name><name><surname>Bomhoff</surname><given-names>M.</given-names></name><name><surname>Ponsero</surname><given-names>A. J.</given-names></name><name><surname>Wood-Charlson</surname><given-names>E. M.</given-names></name><name><surname>Lynch</surname><given-names>J.</given-names></name><name><surname>Choi</surname><given-names>I.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>iMicrobe: Tools and data-driven discovery platform for the microbiome sciences</article-title>. <source>GigaScience</source><volume>8</volume>, <elocation-id>giz083</elocation-id>. doi: <pub-id pub-id-type="doi">10.1093/gigascience/giz083</pub-id><pub-id pub-id-type="pmid">31289831</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Gowda</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>W.</given-names></name><name><surname>Würschum</surname><given-names>T.</given-names></name><name><surname>Maurer</surname><given-names>H. P.</given-names></name><name><surname>Longin</surname><given-names>F. H.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Accuracy of genomic selection in European maize elite breeding populations</article-title>. <source>Theor. Appl. Genet.</source><volume>124</volume>, <fpage>769</fpage>–<lpage>776</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00122-011-1745-y</pub-id><pub-id pub-id-type="pmid">22075809</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
