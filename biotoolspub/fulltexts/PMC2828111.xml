<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-id journal-id-type="hwp">bioinfo</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">2828111</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btq002</article-id>
    <article-id pub-id-type="publisher-id">btq002</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group>
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Disambiguating the species of biomedical named entities using natural language parsers</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Xinglong</given-names>
        </name>
        <xref ref-type="aff" rid="AFF1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="AFF1">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="COR1">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tsujii</surname>
          <given-names>Jun'ichi</given-names>
        </name>
        <xref ref-type="aff" rid="AFF1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="AFF1">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="AFF1">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ananiadou</surname>
          <given-names>Sophia</given-names>
        </name>
        <xref ref-type="aff" rid="AFF1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="AFF1">
          <sup>2</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="AFF1"><sup>1</sup> National Centre for Text Mining, <sup>2</sup> School of Computer Science, University of Manchester, Manchester, UK and <sup>3</sup> Department of Computer Science, University of Tokyo, Tokyo, Japan</aff>
    <author-notes>
      <corresp id="COR1">* To whom correspondence should be addressed.</corresp>
      <fn>
        <p>Associate Editor: Jonathan Wren</p>
      </fn>
    </author-notes>
    <pub-date pub-type="ppub">
      <day>1</day>
      <month>3</month>
      <year>2010</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>6</day>
      <month>1</month>
      <year>2010</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>6</day>
      <month>1</month>
      <year>2010</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="epub"/>. -->
    <volume>26</volume>
    <issue>5</issue>
    <fpage>661</fpage>
    <lpage>667</lpage>
    <history>
      <date date-type="received">
        <day>6</day>
        <month>5</month>
        <year>2009</year>
      </date>
      <date date-type="rev-recd">
        <day>29</day>
        <month>12</month>
        <year>2009</year>
      </date>
      <date date-type="accepted">
        <day>30</day>
        <month>12</month>
        <year>2009</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2010. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2010</copyright-year>
      <license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">
        <license-p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.5">http://creativecommons.org/licenses/by-nc/2.5</ext-link>), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <abstract>
      <p><bold>Motivation:</bold> Text mining technologies have been shown to reduce the laborious work involved in organizing the vast amount of information hidden in the literature. One challenge in text mining is linking ambiguous word forms to unambiguous biological concepts. This article reports on a comprehensive study on resolving the ambiguity in mentions of biomedical named entities with respect to model organisms and presents an array of approaches, with focus on methods utilizing natural language parsers.</p>
      <p><bold>Results:</bold> We build a corpus for organism disambiguation where every occurrence of protein/gene entity is manually tagged with a species ID, and evaluate a number of methods on it. Promising results are obtained by training a machine learning model on syntactic parse trees, which is then used to decide whether an entity belongs to the model organism denoted by a neighbouring species-indicating word (e.g. <italic>yeast</italic>). The parser-based approaches are also compared with a supervised classification method and results indicate that the former are a more favorable choice when domain portability is of concern. The best overall performance is obtained by combining the strengths of syntactic features and supervised classification.</p>
      <p><bold>Availability:</bold> The corpus and demo are available at <ext-link ext-link-type="uri" xlink:href="http://www.nactem.ac.uk/deca_details/start.cgi">http://www.nactem.ac.uk/deca_details/start.cgi</ext-link>, and the software is freely available as U-Compare components (Kano <italic>et al.</italic>, <xref ref-type="bibr" rid="B15">2009</xref>): NaCTeM Species Word Detector and NaCTeM Species Disambiguator. U-Compare is available at <ext-link ext-link-type="uri" xlink:href="http://-compare.org/">http://-compare.org/</ext-link></p>
      <p>
        <bold>Contact:</bold>
        <email>xinglong.wang@manchester.ac.uk</email>
      </p>
    </abstract>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="SEC1">
    <title>1 INTRODUCTION</title>
    <sec id="SEC1.1">
      <title>1.1 Overview</title>
      <p>The objective of text mining is to automatically extract information from unstructured text and store the information in a form that can be easily accessible by users (Ananiadou <italic>et al.</italic>, 2007; Hunter and Cohen, <xref ref-type="bibr" rid="B13">2006</xref>). Storing information in the form of words can cause ambiguity, because a string of words often refers to different meanings in different context. Therefore, a more sensible way, as adopted by many biomedical databases and ontologies, is to organize information by <italic>concept</italic>, where a concept has unambiguous meaning and can be associated with a unique identifier. To make text mining useful for the community of biomedical sciences, one crucial step is to link the <italic>hidden</italic> and <italic>ambiguous</italic> mentions of named entities in text to unique concepts in knowledge bases.</p>
      <p>This article presents our study on tackling one source of ambiguity in entity mentions: model organisms. Model organisms are species studied to understand particular biological phenomena. Biological experiments are often conducted on one species, with the expectation that the discoveries will provide insight into the workings of others, including humans, which are more difficult to study directly. From viruses, prokaryotes, to plants and animals, there are dozens of organisms commonly used in biological studies, such as <italic>Escherichia coli</italic>, <italic>Caenorhabditis elegans</italic>, <italic>Drosophila melanogaster</italic>, <italic>Homo sapiens</italic> and hundreds more are frequently mentioned in biological research papers. Given an article, it is often essential for readers to understand what organisms the biomedical entities (e.g. proteins) belong to, and on what organisms the experiments are carried out.</p>
    </sec>
    <sec id="SEC1.2">
      <title>1.2 Background and motivation</title>
      <p>In biomedical articles, entities of different species are commonly referred to using the same name, causing difficulty for software applications that link an entity to a specific species. For example, without context, ‘<italic>tumor protein p53</italic>’ may associate to over 100 proteins across 23 species.<xref ref-type="fn" rid="FN1"><sup>1</sup></xref> One way to find the species information is to look for MeSH headings, which are a set of keywords attached to a published article. However, not all articles have MeSH headings, and for the ones that have, many do not contain species keywords. Also, MeSH headings cover only the main species reported in the paper, and do not provide information on other species mentioned, whereas for many text mining applications, knowing the species for <italic>every</italic> entity mention is necessary. For example, to identify the proteins (i.e. the underlined terms) in the following sentence, knowing the ‘focus’ species of the article is not sufficient, as they belong to three different organisms: <italic>human</italic>, <italic>mouse</italic> and <italic>rat</italic>.<xref ref-type="fn" rid="FN2"><sup>2</sup></xref>
<disp-quote><p>The amounts of <italic>human</italic> and <italic>mouse</italic> <underline>CD200R-CD4d3+4</underline> and <underline><italic>r</italic>CD4d3+4</underline> protein on the microarray spots were similar …</p></disp-quote>
</p>
      <p>The importance of distinguishing model organisms has been recognized by the community of biomedical text mining. Chen <italic>et al.</italic> (<xref ref-type="bibr" rid="B5">2005</xref>) collected gene names from various source databases and calculated intra- and inter-species ambiguities. Overall, only 25 (0.02%) official symbols were ambiguous within the organisms. However, when official symbols from all 21 organisms were combined, the ambiguity increased substantially to 21 279 (14.2%) symbols. Hakenberg <italic>et al.</italic> (<xref ref-type="bibr" rid="B10">2008</xref>) and our previous work (Wang and Matthews, <xref ref-type="bibr" rid="B31">2008</xref>) showed that species disambiguation was one of the most important steps for term normalization and identification, which concerned automatically associating mentions of biomedical entities in text to unique database identifiers (Krallinger <italic>et al.</italic>, <xref ref-type="bibr" rid="B18">2008</xref>). Also, the task of extracting protein–protein interaction (PPI) in the recent BioCreAtIvE Challenge II workshop Krallinger <italic>et al.</italic> (<xref ref-type="bibr" rid="B18">2008</xref>) required protein pairs to be recognized and normalized, which inevitably involved species disambiguation. More recently, Kappeler <italic>et al.</italic> (<xref ref-type="bibr" rid="B16">2009</xref>) discussed a method that identified organism names (referred to in this article as <italic>species words</italic>), with an aim to detect the ‘focus’ species at document level. The results showed that organism detection was helpful for disambiguation, but their work did not attempt to link organisms to gene entities.</p>
      <p>As the technology of natural language parsing advances, it has been successfully adopted for several information extraction tasks, such as automatically finding PPIs in text. The idea is that syntactic structures linking interacting biological entities may have common characteristics that can be exploited by similarity measures or machine learning algorithms. For example, Erkan <italic>et al.</italic> (<xref ref-type="bibr" rid="B9">2007</xref>) used the shortest path between two genes according to edit distance in a dependency tree to define a kernel function for extracting gene interactions. Miwa <italic>et al.</italic> (<xref ref-type="bibr" rid="B20">2008</xref>) comparably evaluated a number of kernels for incorporating syntactic features, including the bag-of-word kernel, the subset tree kernel (Moschitti, <xref ref-type="bibr" rid="B24">2006</xref>) and the graph kernel (Airola <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">2008</xref>), and concluded that combining all kernels achieved better results than using any individual one. Miyao <italic>et al.</italic> (<xref ref-type="bibr" rid="B22">2009</xref>) used syntactic paths as one of the features to train a support vector machines (SVMs) model for PPIs and also discussed how different parsers and output representations affected the performance. Targeting the task of disambiguating model organisms at entity level, this article exploits parsing technology and proposes a novel approach that employs syntactic features and transforms a multi-way supervised classification task to a less complex binary relation classification one.</p>
    </sec>
    <sec id="SEC1.3">
      <title>1.3 Task specification</title>
      <p>The task concerned in this article is as follows: given a text, in which mentions of biomedical named entities are annotated, we assign a <italic>species tag</italic> to every entity mention. The types of entities studied in this work are genes and gene products (e.g. proteins), and species tags are identifiers from the NCBI Taxonomy (taxon) of model organisms (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sites/entrez?db=taxonomy">http://www.ncbi.nlm.nih.gov/sites/entrez?db=taxonomy</ext-link>). Taxon IDs are widely used in major protein and gene databases (e.g. RefSeq, UniProt, GenBank, etc.) and have become the ‘canonical’ forms to denoting organisms. On the other hand, the technique presented in this article is general: any gazetteer of model organisms can replace the NCBI Taxonomy in the framework. This article focuses on species disambiguation and makes the assumption that the named entities are already recognized. In practice, an automated named entity recognizer [e.g. ABNER (Settles, <xref ref-type="bibr" rid="B28">2005</xref>)] should be used before applying the systems.</p>
    </sec>
  </sec>
  <sec sec-type="methods" id="SEC2">
    <title>2 METHODS</title>
    <sec id="SEC2.1">
      <title>2.1 Species word detection</title>
      <p>An informative indicator for species are words that denote names of model organisms in the surrounding context of an entity. For example, <italic>p53</italic> should be tagged as a <italic>mouse</italic> protein, if it appears in the phrase ‘<italic>mouse</italic> p53’. Another clue is the presence of the species-indicating prefixes in gene and protein names. For instance, prefix ‘<italic>h</italic>’ in entity ‘<italic>h</italic>Sos-1’ suggests that it is a <italic>human</italic> protein. Throughout this article, we refer to such indicative words (e.g. <italic>mouse</italic>, <italic>hSos-1</italic>) as ‘species words’. Note that a species ‘word’ may contain multiple tokens, such as <italic>E.coli</italic>.</p>
      <p>We devised a program (Wang and Grover, <xref ref-type="bibr" rid="B30">2008</xref>) to detect such species words: it marks up a word in a document as a species word if it matches an entry in a list of names of organisms. Each entry in the list contains a species word and its corresponding taxon ID, and the list is merged from two dictionaries: the NCBI Taxonomy and the UniProt controlled vocabulary of species (<ext-link ext-link-type="uri" xlink:href="http://www.expasy.ch/cgi-bin/speclist">http://www.expasy.ch/cgi-bin/speclist</ext-link>). The NCBI portion is a flattened NCBI Taxonomy (i.e. without hierarchy) including only the identifiers of <italic>genus</italic> and <italic>species</italic> ranks. In total, the merged list contains 356 387 unique species words and 272 991 unique species IDs. The ambiguity in species words is low: 3.86% of species words map to multiple IDs, and on average each word maps to 1.043 IDs. Therefore, we use a simple dictionary look-up method for species word detection.<xref ref-type="fn" rid="FN3"><sup>3</sup></xref> In addition, entity names with prefixes ‘<italic>h</italic>’, ‘<italic>r</italic>’, ‘<italic>m</italic>’, ‘<italic>d</italic>’ and ‘<italic>y</italic>’ are also marked as ‘species words’. In biomedical publications, however, a variety of terms, such as names of diseases (e.g. ‘breast cancer’) and cell lines, can imply organisms. Indeed, one future research direction is on automatic recognition of species-indicating terms.</p>
    </sec>
    <sec id="SEC2.2">
      <title>2.2 Heuristic baselines</title>
      <p>One simple approach to assigning a species tag to an entity is by looking for the species words in its context. More specifically, we assign species IDs using <italic>one of</italic> the following rules, each of which is then used as a baseline system:
<list list-type="order"><list-item><p><italic>previous species word</italic>: if the word preceding an entity is a species word, assign the species ID indicated by that word to the entity.</p></list-item><list-item><p><italic>species word in the same sentence</italic>: if a species word and an entity appear in the same sentence, assign its species ID to the entity. When more than one species word co-occurs in the sentence, priority is given to the species word at the entity's left with the smallest distance. If all species words occur to the right of the entity, take the nearest one.</p></list-item><list-item><p><italic>majority vote</italic>: assign the most frequently occurring species ID in the document to all entity mentions.</p></list-item></list>
</p>
      <p>It is expected that the first rule would produce good precision. However, it can only disambiguate the fraction of entities that happen to have a species word to their <italic>immediate</italic> left. The second rule relaxes the first by allowing an entity to take the species indicated by its nearest species word in the same sentence, which should increase recall but decrease precision. Statistics from our dataset (<xref ref-type="sec" rid="SEC3.1">Section 3.1</xref>) show that only 8.22% entities can potentially be resolved by rule 1 and 36.04% by rule 2, while the coverage of <italic>majority vote</italic> is 86.41%.</p>
    </sec>
    <sec id="SEC2.3">
      <title>2.3 Supervised classification baseline</title>
      <p>The problem can also be approached as a classification task. Given an entity mention and its surrounding context, a machine learning model classifies the entity into one of the classes, where each class corresponds to a species ID. The model can be trained on a corpus, in which each occurrence of named entities is tagged with a species ID by domain experts. Many machine learning algorithms would fit in this classification framework and we apply a maximum entropy model (<ext-link ext-link-type="uri" xlink:href="http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html">http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html</ext-link>). Features used include contextual words, neighbouring species IDs, morphological features of named entities (e.g. prefixes), and all the species IDs occurring in the document. Function words and words that consist of only digits and punctuation are filtered out. See Wang and Matthews (<xref ref-type="bibr" rid="B31">2008</xref>) for more details on this approach.</p>
      <p>This method suffers from a problem that is common for supervised machine learning techniques: a learned model tends to bias towards the dataset that it is trained on (Japkowicz, <xref ref-type="bibr" rid="B14">2000</xref>). In the context of our task, the model would work well on disambiguating the organisms having abundant training data, whereas creating sufficient amounts of training instances for the vast number of organisms would be infeasible. <xref ref-type="sec" rid="SEC3.2">Section 3.2</xref> provides more discussion on this matter.</p>
    </sec>
    <sec id="SEC2.4">
      <title>2.4 Disambiguating species using parsers</title>
      <p>We extend the rule-based system described in <xref ref-type="sec" rid="SEC2.2">Section 2.2</xref> by utilizing the paths between words in a syntactic parse tree, and assume that if a path exists between a species word and a named entity, then the entity has the species indicated by the species word. We empirically evaluate a number of parsers by measuring their performance on this task. This task-oriented evaluation approach was also taken by Miyao <italic>et al.</italic> (<xref ref-type="bibr" rid="B22">2009</xref>) on the task of extracting PPIs. The parsers used are summarized in <xref ref-type="table" rid="T1">Table 1</xref>, where ENJU-Genia and Stanford-Genia were trained on the GENIA corpus (Tateisi <italic>et al.</italic>, <xref ref-type="bibr" rid="B29">2005</xref>), a treebank of biomedical text.
<table-wrap id="T1" position="float"><label>Table 1.</label><caption><p>Parsers and their input and output format</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th align="left" rowspan="1" colspan="1">Parser</th><th align="left" rowspan="1" colspan="1">Input</th><th align="left" rowspan="1" colspan="1">Output</th></tr></thead><tbody align="left"><tr><td align="left" rowspan="1" colspan="1">C&amp;C (Clark and Curran, <xref ref-type="bibr" rid="B6">2007</xref>)</td><td align="left" rowspan="1" colspan="1">POS-tagged</td><td align="left" rowspan="1" colspan="1">GR</td></tr><tr><td align="left" rowspan="1" colspan="1">ENJU (Miyao and Tsujii, <xref ref-type="bibr" rid="B21">2008</xref>)</td><td align="left" rowspan="1" colspan="1">POS-tagged</td><td align="left" rowspan="1" colspan="1">PAS</td></tr><tr><td align="left" rowspan="1" colspan="1">ENJU-Genia (Hara <italic>et al.</italic>, <xref ref-type="bibr" rid="B11">2007</xref>)</td><td align="left" rowspan="1" colspan="1">POS-tagged</td><td align="left" rowspan="1" colspan="1">PAS</td></tr><tr><td align="left" rowspan="1" colspan="1">Minipar (Lin, <xref ref-type="bibr" rid="B19">1998</xref>)</td><td align="left" rowspan="1" colspan="1">Sentence-detected</td><td align="left" rowspan="1" colspan="1">Minipar</td></tr><tr><td align="left" rowspan="1" colspan="1">Stanford (Klein and Manning, <xref ref-type="bibr" rid="B17">2003</xref>)</td><td align="left" rowspan="1" colspan="1">POS-tagged</td><td align="left" rowspan="1" colspan="1">SD</td></tr><tr><td align="left" rowspan="1" colspan="1">Stanford-Genia</td><td align="left" rowspan="1" colspan="1">POS-tagged</td><td align="left" rowspan="1" colspan="1">SD</td></tr></tbody></table></table-wrap>
</p>
      <p>In more detail, we first select the sentences in which an entity mention and a species word co-occur, and then parse the sentences. If a syntactic path exists between an entity and a species word, the entity is assumed to be of the species indicated by the species word. In cases where there is more than one path between an entity and a species word, the shortest path is chosen.</p>
      <p>There are several practical issues to consider when using parsers for this task. First, the text needs to be linguistically preprocessed, which includes sentence boundary detection, tokenization and part-of-speech (POS) tagging. Some parsers supply preprocessing programs, but to ensure a fair parser comparison, we use the same tools (Alex <italic>et al.</italic>, <xref ref-type="bibr" rid="B2">2008</xref>) whenever possible. The middle column in <xref ref-type="table" rid="T1">Table 1</xref> shows how the input text is linguistically preprocessed with respect to parsers. A POS-tagged text implies that it is also sentence boundary detected and tokenized, and a tokenized text implies that it is sentence detected. All parsers take POS-tagged text as input except for Minipar, which takes only sentences.</p>
      <p>Second, the output representations of the parsers are different and we prefer a format that depicts relations between words instead of syntactic constituents. In total, four representations are used: grammatical relation (GR; Briscoe <italic>et al.</italic>, <xref ref-type="bibr" rid="B4">2006</xref>), Stanford typed dependency (SD; de Marneffe <italic>et al.</italic>, <xref ref-type="bibr" rid="B8">2006</xref>), Minipar's own representation (Lin, <xref ref-type="bibr" rid="B19">1998</xref>) and ENJU's predicate-argument structure (PAS), where a dependency triple (i.e. GR, SD and Minipar) consists of head, dependent and relation, and a PAS triple contains predicate, argument and relation. The right-most column in <xref ref-type="table" rid="T1">Table 1</xref> lists the output representation of each parser, and <xref ref-type="fig" rid="F1">Figure 1</xref> shows a sentence parsed by ENJU in PAS representation.
<fig id="F1" position="float"><label>Fig. 1.</label><caption><p>Predicate-argument structure.</p></caption><graphic xlink:href="btq002f1"/></fig></p>
      <p>Third, we store parse trees as graphs and augment nodes on the graphs with biomedical annotation, such as whether a node is part of a species word or entity. This process is non-trivial for Minipar output, because Minipar uses its own tokenizer, which breaks a sentence into tokens differently. For example, protein ‘kinesin-14’ is treated as one token by our tokenizer, but is split as ‘kinesin’, ‘-’ and ‘14’ by Minipar. To alleviate this problem, we code rules by hand to make Minipar's tokenization more consistent to ours.</p>
      <p>When nodes in a parse tree are annotated, the disambiguation task becomes finding the shortest path between the nodes of entities and the nodes of species words. When an entity or a species word consists of a group of nodes (i.e. tokens), we identify the syntactic head of the entity, and the path connecting to the head node is regarded as the path to the group.</p>
    </sec>
    <sec id="SEC2.5">
      <title>2.5 Classifying relations of entities and species words</title>
      <p>A syntactic link between an entity and a species word does not guarantee that the entity has the species indicated by the species word. For example, for the sentence shown in <xref ref-type="fig" rid="F1">Figure 1</xref>, the method presented in <xref ref-type="sec" rid="SEC2.4">Section 2.4</xref> would assign both proteins ‘Kip3’ and ‘Klp67A’ the species of <italic>Drosophila</italic>. However, only ‘Klp67A’ is a <italic>Drosophila</italic> protein. Therefore, we define a species-entity relation as a pair <italic>r</italic>=〈<italic>e</italic>, <italic>s</italic>〉, where <italic>e</italic> is an entity mention and <italic>s</italic> is a species word, and <italic>r</italic> is a positive relation if <italic>e</italic> is of the species indicated by <italic>s</italic>, and a negative relation otherwise. With manually curated examples, a relation classification model can be trained to rule out negative relations. More specifically, from the sentences in the training dataset that at least one entity and one species word co-occur, we extract pairs of entity and species word and create a set of relations. Then each relation is assigned with a binary label: a relation is positive if the species ID inferred from the species word matches the gold standard species annotation, and is negative otherwise. For example, for the sentence in <xref ref-type="fig" rid="F1">Figure 1</xref>, relation 〈Kip3, TaxonID: 7215〉 is a negative instance and the pair 〈Klp67A, TaxonID: 7215〉 is a positive one, where TaxonID: 7215 is the species ID for <italic>Drosophila</italic>. From our dataset (<xref ref-type="sec" rid="SEC3.1">Section 3.1</xref>), 2154 relations are extracted, of which 74.05% are positive.</p>
      <p>For each relation, two types of features are extracted. The first are bag-of-word features, i.e. the words before, between and after the pair of entities, where the words are lemmatized, and the second are syntactic features obtained from parse analysis. Following the PPI extraction method proposed in (Sætre <italic>et al.</italic>, <xref ref-type="bibr" rid="B26">2007</xref>), we apply a SVM model. For bag-of-word features, a linear kernel is used, and for syntactic paths, a subset tree kernel (Moschitti, <xref ref-type="bibr" rid="B24">2006</xref>) is adopted, for which a path is represented in a flat tree format. The syntactic features used in the final systems (i.e. R<sc>elation</sc> and H<sc>ybrid</sc> in <xref ref-type="table" rid="T3">Table 3</xref>) are predicate-argument paths obtained from ENJU-Genia.<xref ref-type="fn" rid="FN4"><sup>4</sup></xref> <xref ref-type="fig" rid="F2">Figure 2</xref> shows a flat tree feature for the negative instance 〈Kip3, TaxonID: 7215〉 from <xref ref-type="fig" rid="F1">Figure 1</xref>. Note that all species words (e.g. <italic>Drosophila</italic>) are normalized to ‘SPECIESWORD’, and entities (e.g. Kip3) to ‘ENTITY’, which not only reduces the noise in the features, but also makes the model more species generic. In other words, the relation classification model should work on any species including the ones that do not appear in the training portion of the dataset.
<fig id="F2" position="float"><label>Fig. 2.</label><caption><p>A syntactic feature obtained from the ENJU parser.</p></caption><graphic xlink:href="btq002f2"/></fig></p>
      <p>To identify the species of an entity in unseen text, we first parse the sentence and extract pairs of species words and entities, along with the bag-of-word and syntactic features. The trained model is then applied to classify the species–entity relations. The entity mention in a positive relation is tagged with the ID indicated by the species word, while the mentions in negative relations are left untagged. This way, the relation classification approach transforms a complex multi-classification task into a binary classification one. In addition, it can achieve better domain adaptability, because the relation classification model learns the relations between entities and species words, irrespective of their names.</p>
    </sec>
    <sec id="SEC2.6">
      <title>2.6 Spreading strategies</title>
      <p>Except for the <italic>majority vote</italic> rule, the approaches described in <xref ref-type="sec" rid="SEC2.2">Sections 2.2</xref>, <xref ref-type="sec" rid="SEC2.4">2.4</xref> and <xref ref-type="sec" rid="SEC2.5">2.5</xref> are expected to yield low recall, because the rule- and parser-based systems can only detect intra-sentential relations, and hence are only applied to the entities having at least one species word appearing in the same sentence. To improve recall, we ‘spread’ the species from the disambiguated mentions to their ‘relatives’, where an entity mention ē is defined as another mention <italic>e</italic>'s relative under either of the following conditions: (i) if ē has the same surface form with <italic>e</italic>; or, (ii) if ē is an abbreviation or an antecedent of <italic>e</italic>, where abbreviation/antecedent pairs are detected using the algorithm described in Schwartz and Hearst (<xref ref-type="bibr" rid="B27">2003</xref>). Given the set of disambiguated mentions, we then ‘spread’ their species IDs to their relatives in the same document. After this process, the mentions that do not have any disambiguated relatives would still be missed by the system. In such cases, we use the species determined by the rule of <italic>majority vote</italic> (<xref ref-type="sec" rid="SEC2.2">Section 2.2</xref>). We also create a ‘hybrid’ system (i.e. H<sc>ybrid</sc>) by applying both the supervised classification and the relation classification models, and take the answer given by the latter when the two systems disagree. To achieve higher precision, the relation classification model in H<sc>ybrid</sc> does <italic>not</italic> use ‘spreading’ or ‘majority vote’ rules.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="SEC3">
    <title>3 RESULTS</title>
    <sec id="SEC3.1">
      <title>3.1 Data annotation</title>
      <p>Among publicly available resources, the corpora provided in the BioCreAtIvE I and II normalization tasks (Hirschman <italic>et al.</italic>, <xref ref-type="bibr" rid="B12">2005</xref>; Morgan and Hirschman, <xref ref-type="bibr" rid="B23">2007</xref>) are probably the closest to what we need, in that each abstract is assumed to be species specific. The corpus for BioCreAtIvE I Task 1B (BC1) consists of three subsets, respectively, covering <italic>fly</italic>, <italic>mouse</italic> and <italic>yeast</italic>, while that for BioCreAtIvE II gene normalization (BC2) task covers only <italic>human</italic>. By merging the four datasets, one can create a corpus consisting of the above four organisms. However, there are two reasons that prevent us from performing species disambiguation experiments on the merged dataset as it is. First, entity mentions in text are not manually annotated, and therefore we cannot carry out <italic>entity-level</italic> disambiguation. Secondly, all entities in an abstract are assumed to belong to a specific organism, and this simplifying assumption cannot serve the purpose of this work, which is to show that individual entities may belong to organisms other than the ‘focus’ species of the document.</p>
      <p>We addressed the above problems by manual annotation. As shown in <xref ref-type="table" rid="T2">Table 2</xref>, in total 730 abstracts were selected from the BC1 and BC2 datasets and merged into one corpus, where genes and gene products were automatically annotated using case-insensitive longest match against the species-specific vocabulary supplied with the respective source dataset. For each gene mention, domain experts were asked to choose one from a list of frequent taxon IDs.
<table-wrap id="T2" position="float"><label>Table 2.</label><caption><p>Data sources</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th align="left" rowspan="1" colspan="1">Main Organism</th><th align="left" rowspan="1" colspan="1">Source</th><th align="left" rowspan="1" colspan="1">Abstracts</th></tr></thead><tbody align="left"><tr><td align="left" rowspan="1" colspan="1"><italic>fly</italic></td><td align="left" rowspan="1" colspan="1">BC1 Devtest</td><td align="left" rowspan="1" colspan="1">108</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>mouse</italic></td><td align="left" rowspan="1" colspan="1">BC1 Devtest</td><td align="left" rowspan="1" colspan="1">250</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>yeast</italic></td><td align="left" rowspan="1" colspan="1">BC1 Devtest</td><td align="left" rowspan="1" colspan="1">110</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>human</italic></td><td align="left" rowspan="1" colspan="1">BC2 Test</td><td align="left" rowspan="1" colspan="1">262</td></tr></tbody></table></table-wrap>
</p>
      <p>The frequent taxon IDs were estimated from the training corpus for the BioCreAtIvE II Protein Interaction Pairs task (IPS), where each article is associated with pairs of UniProt IDs, from which taxon IDs can be easily derived. The IPS training corpus contains 628 full texts, with 6378 UniProt IDs belonging to 62 different species. The diversity of organisms in this corpus highlights the fact that a primary consideration when developing a species disambiguation system should be its ability to disambiguate a wide range of species with minimal additional manual effort. The organisms were then ranked by frequency and the top 10 were selected (as shown in <xref ref-type="table" rid="T5">Table 5</xref>) for annotators to choose from. The majority of the organisms covered are animals, with only a couple of bacteria and plants. Given the size of the IPS corpus, we believe this frequency list is representative. Meanwhile, we acknowledge that biologists' favorite models may vary greatly. For example, scientists studying <italic>plants</italic> may be more interested in documents on, e.g. <italic>Arabidopsis thaliana</italic>, than those on <italic>human</italic>. During the annotation process, the domain experts can also choose ‘Other’, when none of the 10 most frequent species apply, or ‘not an entity’, when he/she believes the automatically recognized entity is a false positive.</p>
      <p>As the dictionary-based named entity tagging was unlikely to obtain perfect recall, and the annotators were only allowed to correct false positives but not false negatives, the resulting corpus was expected to miss some gene names.<xref ref-type="fn" rid="FN5"><sup>5</sup></xref> The time saved on annotating gene names, however, was invested in creating more mappings between species IDs and gene names.</p>
      <p>We appointed three PhD level biologists to perform annotation, and on average an annotator spent 4 min on each abstract. To avoid being misled, during annotation, they were not aware of the source of the file (i.e. <italic>fly</italic>, <italic>human</italic>, <italic>mouse</italic> or <italic>yeast</italic>), but were allowed to seek help from search engines such as Google and PubMed. To see human experts' performance on this task, 10% of the abstracts were doubly annotated by different annotators. By randomly taking one set of annotation as gold standard, and the other as system output, we calculated the inter-annotator agreement with an <italic>F</italic><sub>1</sub> score at 93.58%, indicating that human annotators have high agreement when assigning species to biomedical entities.</p>
      <p>In summary, 6402 genes and gene products are automatically identified using the dictionary-based named entity recognizer, where 86 out of 730 abstracts do not appear to contain any entity and are hence removed from the dataset. Also, 2.80% entities are false positives as judged by the annotators (i.e. ‘not an entity’). The rest 6223 genes are manually assigned with either a taxon ID or an ‘Other’ tag, with <italic>human</italic> (9606) being the most frequent at 50.30%. <xref ref-type="table" rid="T5">Table 5</xref> shows the species distribution of this dataset.</p>
    </sec>
    <sec id="SEC3.2">
      <title>3.2 Evaluation results</title>
      <p>Evaluation was carried out with 5-fold cross-validation, and the systems were compared using averaged precision, recall and <italic>F</italic><sub>1</sub> over each species. Micro- and macro-averages of the scores were obtained, where micro-average is the mean of the summation of contingency metrics for all model organisms, so that scores of the more frequent species influence the mean more than those of less frequent ones, and macro-average is the mean over all labels, thus attributing equal weights to each species, and measuring a system's adaptability across different organisms. <xref ref-type="table" rid="T3">Table 3</xref> shows the evaluation results. The parser-based (e.g. C&amp;C), relation classification (i.e. R<sc>elation</sc>) and the hybrid (i.e. H<sc>ybrid</sc>) methods are compared with the rule-based (e.g. R<sc>ule</sc>-M<sc>ajority</sc>) and supervised classification (i.e. ML) baselines. Note that the parser-based systems and relation classification used the spreading strategies as described in <xref ref-type="sec" rid="SEC2.6">Section 2.6</xref>. We performed statistical significance tests using randomization (Noreen, <xref ref-type="bibr" rid="B25">1989</xref>) on a number of pairs of methods, and <xref ref-type="table" rid="T4">Table 4</xref> shows the results. ‘+’, ‘−’ and ‘N’ symbols indicate that the method in the corresponding row is significantly better than, worse than or not different (<italic>P</italic>&lt;0.05) from the method in the column. The six metrics compared are micro-precision, micro-recall, micro-<italic>F</italic><sub>1</sub>, macro-precision, macro-recall and macro-<italic>F</italic><sub>1</sub>. For example, the top-left cell in <xref ref-type="table" rid="T4">Table 4</xref> shows that using the parser ENJU-Genia significantly improved macro-precision and macro-<italic>F</italic><sub>1</sub> over R<sc>ule</sc>-S<sc>p</sc>, but decreased the micro-scores and did not make a difference in macro-recall.
<table-wrap id="T3" position="float"><label>Table 3.</label><caption><p>Averaged 5-fold cross-validation evaluation results</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">micro-avg.</th><th align="left" rowspan="1" colspan="1">macro-avg.</th></tr></thead><tbody align="left"><tr><td align="left" rowspan="1" colspan="1">R<sc>ule</sc>-M<sc>ajority</sc></td><td align="left" rowspan="1" colspan="1">72.20 / 62.39 / 66.94</td><td align="left" rowspan="1" colspan="1">27.77 / 46.67 / 29.32</td></tr><tr><td align="left" rowspan="1" colspan="1">R<sc>ule</sc>-S<sc>p</sc></td><td align="left" rowspan="1" colspan="1">74.09 / 64.03 / 68.69</td><td align="left" rowspan="1" colspan="1">29.77 / 53.81 / 32.20</td></tr><tr><td align="left" rowspan="1" colspan="1">R<sc>ule</sc>-S<sc>p</sc>S<sc>ENT</sc></td><td align="left" rowspan="1" colspan="1">72.94 / 63.03 / 67.63</td><td align="left" rowspan="1" colspan="1">30.22 / 54.76 / 32.93</td></tr><tr><td align="left" rowspan="1" colspan="1">C&amp;C</td><td align="left" rowspan="1" colspan="1">73.82 / 63.79 / 68.44</td><td align="left" rowspan="1" colspan="1">30.51 / 53.59 / 33.43</td></tr><tr><td align="left" rowspan="1" colspan="1">ENJU</td><td align="left" rowspan="1" colspan="1">72.98 / 63.06 / 67.66</td><td align="left" rowspan="1" colspan="1">31.35 / 55.00 / 34.61</td></tr><tr><td align="left" rowspan="1" colspan="1">ENJU-Genia</td><td align="left" rowspan="1" colspan="1">73.00 / 63.08 / 67.68</td><td align="left" rowspan="1" colspan="1">30.11 / 53.42 / 32.97</td></tr><tr><td align="left" rowspan="1" colspan="1">Minipar</td><td align="left" rowspan="1" colspan="1">73.02 / 63.10 / 67.69</td><td align="left" rowspan="1" colspan="1">30.19 / 53.56 / 33.10</td></tr><tr><td align="left" rowspan="1" colspan="1">Stanford</td><td align="left" rowspan="1" colspan="1">73.67 / 63.66 / 68.30</td><td align="left" rowspan="1" colspan="1">31.17 / 56.35 / 34.35</td></tr><tr><td align="left" rowspan="1" colspan="1">Stanford-Genia</td><td align="left" rowspan="1" colspan="1">73.48 / 63.50 / 68.13</td><td align="left" rowspan="1" colspan="1">30.61 / 55.61 / 33.78</td></tr><tr><td align="left" rowspan="1" colspan="1">ML</td><td align="left" rowspan="1" colspan="1">82.69 / 82.69 / 82.69</td><td align="left" rowspan="1" colspan="1">27.01 / 27.84 / 27.37</td></tr><tr><td align="left" rowspan="1" colspan="1">R<sc>elation</sc></td><td align="left" rowspan="1" colspan="1">75.24 / 63.99 / 69.16</td><td align="left" rowspan="1" colspan="1">31.97 / 55.61 / 34.80</td></tr><tr><td align="left" rowspan="1" colspan="1">H<sc>ybrid</sc></td><td align="left" rowspan="1" colspan="1">83.80 / 83.80 / 83.80</td><td align="left" rowspan="1" colspan="1">57.56 / 49.72 / 49.90</td></tr></tbody></table><table-wrap-foot><fn><p>Precision/recall/<italic>F</italic><sub>1</sub>-score, in %.</p></fn></table-wrap-foot></table-wrap>
<table-wrap id="T4" position="float"><label>Table 4.</label><caption><p>Results of statistical significance tests between pairs of methods</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">ENJU-Genia</th><th align="left" rowspan="1" colspan="1">C&amp;C</th><th align="left" rowspan="1" colspan="1">ML</th><th align="left" rowspan="1" colspan="1">R<sc>elation</sc></th><th align="left" rowspan="1" colspan="1">H<sc>ybrid</sc></th></tr></thead><tbody align="left"><tr><td align="left" rowspan="1" colspan="1">R<sc>ule</sc>-S<sc>p</sc></td><td align="left" rowspan="1" colspan="1">+/+/+/ − / N / −</td><td align="left" rowspan="1" colspan="1">+/+/+/ − / N / −</td><td align="left" rowspan="1" colspan="1">− / − / − /+/+/+</td><td align="left" rowspan="1" colspan="1">− / − / − / − / − / −</td><td align="left" rowspan="1" colspan="1">− / − / − / − / − / −</td></tr><tr><td align="left" rowspan="1" colspan="1">ENJU-Genia</td><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">− / N / − / N / N / −</td><td align="left" rowspan="1" colspan="1">− / − / − /+/+/+</td><td align="left" rowspan="1" colspan="1">− / − / − / − / − / −</td><td align="left" rowspan="1" colspan="1">− / − / − / − / − / −</td></tr><tr><td align="left" rowspan="1" colspan="1">C&amp;C</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">− / − / − /+/+/+</td><td align="left" rowspan="1" colspan="1">− / − / − / − / − / −</td><td align="left" rowspan="1" colspan="1">− / − / − / − / − / −</td></tr><tr><td align="left" rowspan="1" colspan="1">ML</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">+/+/+/ − / − / −</td><td align="left" rowspan="1" colspan="1">− / − / − / − / − / −</td></tr><tr><td align="left" rowspan="1" colspan="1">R<sc>elation</sc></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">− / − / − / − /+/ −</td></tr></tbody></table></table-wrap>
</p>
      <p>The rule-based systems set high baselines. In terms of micro-averaged scores, the performance of the parser-based approaches were slightly worse than R<sc>ule</sc>-S<sc>p</sc> and comparable with R<sc>ule</sc>-S<sc>p</sc>S<sc>ent</sc>. However, they excelled the rule-based ones as measured by macro-averages. Among the parsers tested, the levels of micro-averaged scores vary slightly, with C&amp;C (Clark and Curran, <xref ref-type="bibr" rid="B6">2007</xref>) in lead. R<sc>elation</sc> achieved better micro- and macro-averages as compared with the parser- and rule-based systems, thanks to its relation classification model, which alleviated the problems caused by the oversimplified assumption made by the parser-based approaches: an entity belongs to the species denoted by its closest species word on a syntactic path.</p>
      <p>ML outperformed the rule- and parser-based approaches in terms of micro-averaged precision. However, the parser-based, relation classification and hybrid approaches have a clear advantage over ML on macro-averages, indicating their capability in tackling a wider range of organisms. <xref ref-type="fig" rid="F3">Figure 3</xref> shows the performance of ML, R<sc>elation</sc> and H<sc>ybrid</sc> on individual organisms. The labels on the <italic>x</italic>-axis denote organisms, ordered by frequency, with smaller numbers indicating more frequent ones. <xref ref-type="table" rid="T5">Table 5</xref> lists details of their performance on the most frequent 10 organisms. These statistics reveal that ML can only disambiguate five species that have relatively large amount of training instances, and fails completely on others. This is because the model used by ML was trained on a dataset in which occurrences of some species [e.g. <italic>B.taurus (9913)</italic>] are very sparse. In other words, this is a multi-classification task on heterogeneous and imbalanced datasets, a challenge for a supervised classification model to learn to discriminate enough between classes.
<fig id="F3" position="float"><label>Fig. 3.</label><caption><p>Performance of ML, R<sc>elation</sc>, H<sc>ybrid</sc> over individual organisms.</p></caption><graphic xlink:href="btq002f3"/></fig>
<table-wrap id="T5" position="float"><label>Table 5.</label><caption><p>The percentage of the species and the micro-averaged <italic>F</italic><sub>1</sub> scores (%) of ML, R<sc>elation</sc> and H<sc>ybrid</sc> with respect to each species</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th align="left" rowspan="1" colspan="1">Species Name (TaxonID)</th><th align="left" rowspan="1" colspan="1">Pct (%)</th><th align="left" rowspan="1" colspan="1">ML</th><th align="left" rowspan="1" colspan="1">R<sc>elation</sc></th><th align="left" rowspan="1" colspan="1">H<sc>ybrid</sc></th></tr></thead><tbody align="left"><tr><td align="left" rowspan="1" colspan="1"><italic>Homo sapiens</italic> (9606)</td><td align="left" rowspan="1" colspan="1">50.30</td><td align="left" rowspan="1" colspan="1">85.60</td><td align="left" rowspan="1" colspan="1">70.51</td><td align="left" rowspan="1" colspan="1">86.48</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Mus musculus</italic> (10090)</td><td align="left" rowspan="1" colspan="1">26.70</td><td align="left" rowspan="1" colspan="1">79.38</td><td align="left" rowspan="1" colspan="1">78.17</td><td align="left" rowspan="1" colspan="1">80.41</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Drosophila melanogaster</italic> (7227)</td><td align="left" rowspan="1" colspan="1">10.01</td><td align="left" rowspan="1" colspan="1">87.07</td><td align="left" rowspan="1" colspan="1">79.53</td><td align="left" rowspan="1" colspan="1">87.37</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Saccharomyces cerevisiae</italic> (4932)</td><td align="left" rowspan="1" colspan="1">7.79</td><td align="left" rowspan="1" colspan="1">82.66</td><td align="left" rowspan="1" colspan="1">74.13</td><td align="left" rowspan="1" colspan="1">84.64</td></tr><tr><td align="left" rowspan="1" colspan="1">Other</td><td align="left" rowspan="1" colspan="1">1.01</td><td align="left" rowspan="1" colspan="1">0.00</td><td align="left" rowspan="1" colspan="1">18.56</td><td align="left" rowspan="1" colspan="1">25.00</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Rattus norvegicus</italic> (10116)</td><td align="left" rowspan="1" colspan="1">0.78</td><td align="left" rowspan="1" colspan="1">48.42</td><td align="left" rowspan="1" colspan="1">33.77</td><td align="left" rowspan="1" colspan="1">59.41</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Escherichia coli</italic> K-12 (83333)</td><td align="left" rowspan="1" colspan="1">0.28</td><td align="left" rowspan="1" colspan="1">0.00</td><td align="left" rowspan="1" colspan="1">0.00</td><td align="left" rowspan="1" colspan="1">0.00</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Xenopus tropicalis</italic> (8364)</td><td align="left" rowspan="1" colspan="1">0.12</td><td align="left" rowspan="1" colspan="1">0.00</td><td align="left" rowspan="1" colspan="1">7.50</td><td align="left" rowspan="1" colspan="1">36.36</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Caenorhabditis elegans</italic> (6239)</td><td align="left" rowspan="1" colspan="1">0.11</td><td align="left" rowspan="1" colspan="1">0.00</td><td align="left" rowspan="1" colspan="1">38.71</td><td align="left" rowspan="1" colspan="1">22.22</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Bos taurus</italic> (9913)</td><td align="left" rowspan="1" colspan="1">0.04</td><td align="left" rowspan="1" colspan="1">0.00</td><td align="left" rowspan="1" colspan="1">50.00</td><td align="left" rowspan="1" colspan="1">100.00</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>Arabidopsis thaliana</italic> (3702)</td><td align="left" rowspan="1" colspan="1">0.03</td><td align="left" rowspan="1" colspan="1">0.00</td><td align="left" rowspan="1" colspan="1">22.22</td><td align="left" rowspan="1" colspan="1">66.67</td></tr></tbody></table></table-wrap>
</p>
      <p>On the other hand, R<sc>elation</sc> achieved comparable performance on the frequent organisms, and also worked relatively well on rare ones, displaying its good adaptability across domains. Overall, H<sc>ybrid</sc> obtained the highest points in nearly every scoring category, indicating the success in applying relation classification in conjunction with ML.<xref ref-type="fn" rid="FN6"><sup>6</sup></xref> H<sc>ybrid</sc> integrated the two methods in a crude way, leaving ample room for exploring better combination approaches in the future.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="SEC4">
    <title>4 DISCUSSION</title>
    <p>There are several causes to the large variance in the performance of R<sc>elation</sc> and H<sc>ybrid</sc> on individual species (as shown in <xref ref-type="fig" rid="F3">Fig. 3</xref>). In the case of R<sc>elation</sc>, the spreading rule, which relies on the ‘one sense per discourse’ heuristic, can be overly aggressive and propagate a wrong decision across the whole document. As for H<sc>ybrid</sc>, since the relation classification model did not use the spreading rule (described in <xref ref-type="sec" rid="SEC2.6">Section 2.6</xref>), it would only attempt to correct the entities that have co-occurring species words in the same sentence, affecting 36.04% entities, and therefore only marginally improved the performance over ML. For both systems, errors made by the species word detection program (described in <xref ref-type="sec" rid="SEC2.1">Section 2.1</xref>) may also result in false positives and false negatives. For example, the program cannot detect any species word for <italic>E.coli K-12 (83333)</italic> and therefore none of the systems successfully disambiguated this model organism.</p>
    <p>The current systems do not tackle coordination, which often infers that more than one species ID applies to a gene/protein mention (e.g. ‘<italic>mouse</italic> and <italic>human</italic> SPO11’). Feedback from the annotators suggests that this problem is particularly common for the <italic>mammalian</italic> organisms, such as <italic>human</italic>, <italic>mouse</italic> and <italic>rat</italic>. It is the future work to extend the framework and allow assignment of multiple species IDs, possibly also taking into account the hierarchy of model organisms.</p>
  </sec>
  <sec sec-type="conclusions" id="SEC5">
    <title>5 CONCLUSIONS</title>
    <p>This article reports on our experiments and discoveries on the task of disambiguating the model organisms of gene and gene products. We addressed disambiguating the species of entities, instead of that of documents, and a number of approaches were implemented and compared. For evaluation, we developed a gold standard corpus, consisting of 644 MEDLINE abstracts, in which each occurrence of a gene name is manually tagged with an NCBI taxonomy ID, indicating its model organism. As measured by micro-averaged <italic>F</italic><sub>1</sub> score, the systems solely relying on syntactic parse analysis did not outperform a baseline system that determines an entity mention's species by looking for its nearest species word in the same sentence. Nevertheless, the parser-based systems achieved higher macro-averaged scores.</p>
    <p>A supervised multi-classification approach was also tested, and yielded the second best micro-averaged performance. However, it can only disambiguate the species that have abundant training instances, resulting in a low macro-averaged score of 27.37%. To fix this problem, we proposed a binary relation classification model. Trained on word and syntactic features, the model can filter out erroneous species–entity relations and achieve significantly better micro-averages than the rule- and parser-based systems, and better macro-averages than the supervised classification approach.</p>
    <p>Relying on informative keywords in the context, the proposed approaches potentially can detect <italic>any</italic> species. Developing a relation classification model also requires training data. However, a generic binary model can be trained and applied to new domains without the need for extra manually annotated data. This is evidently advantageous over the multi-classification method (i.e. ML), which requires fresh annotated datasets to adapt to new domains. The best overall performance was obtained by combining the strengths of a syntactic parser (i.e. ENJU-Genia), a relation classification model, and a supervised classification model.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn id="FN1">
      <p><sup>1</sup>The search was performed over the RefSeq database on July 1, 2009 and the number of species was manually counted.</p>
    </fn>
    <fn id="FN2">
      <p><sup>2</sup>Prefix ‘r’ in ‘rCD4d3+4’ indicates that it is a <italic>rat</italic> protein.</p>
    </fn>
    <fn id="FN3">
      <p><sup>3</sup>When a word maps to multiple IDs, we assign to it the <italic>species</italic> instead of <italic>genus</italic> ID, and between multiple <italic>species</italic> IDs, we choose the most frequent one, as estimated from the BioCreAtIvE II IPS corpus (<xref ref-type="sec" rid="SEC3.1">Section 3.1</xref>).</p>
    </fn>
    <fn id="FN4">
      <p><sup>4</sup>We conducted classification experiments using only bag-of-word features, and using bag-of-word features in conjunction with syntactic features from each parser shown in <xref ref-type="table" rid="T1">Table 1</xref>. The combination of bag-of-word and ENJU-Genia PAS features yielded the best accuracy, and hence was used.</p>
    </fn>
    <fn id="FN5">
      <p><sup>5</sup>We did not use the gold standard text excerpts of genes because the BC1 annotation guidelines state that ‘Genes are required to come from the appropriate organism for the specific database’ (Colosimo <italic>et al.</italic>, <xref ref-type="bibr" rid="B7">2005</xref>), indicating that the curators were asked to annotate only the genes belonging to the organism in question.</p>
    </fn>
    <fn id="FN6">
      <p><sup>6</sup>Combining ML and R<sc>ule</sc>-S<sc>p</sc> yielded a micro-<italic>F</italic><sub>1</sub> score of 81.05%, which was significantly lower than the H<sc>ybrid</sc> system presented here.</p>
    </fn>
  </fn-group>
  <ack>
    <title>ACKNOWLEDGEMENTS</title>
    <p>The authors would like to thank the biologists who annotated the species corpus, and Yoshinobu Kano for his help in making the software available in U-Compare.</p>
    <p><italic>Funding</italic>: Pfizer Ltd.; Joint Information Systems Committee (to UK National Centre for Text Mining).</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </ack>
  <ref-list>
    <title>REFERENCES</title>
    <ref id="B1">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Airola</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A graph kernel for protein-protein interaction extraction</article-title>
        <source>Proceedings of BioNLP</source>
        <year>2008</year>
        <publisher-loc>Columbus, Ohio</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alex</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Assisted curation: does text mining really help?</article-title>
        <source>Pac. Symp. Biocompu.</source>
        <year>2008</year>
        <volume>13</volume>
        <fpage>556</fpage>
        <lpage>567</lpage>
      </element-citation>
    </ref>
    <ref id="B3">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ananiadou</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Text mining and its potential applications in systems biology</article-title>
        <source>Trends Biotechnol.</source>
        <year>2006</year>
        <volume>24</volume>
        <fpage>571</fpage>
        <lpage>579</lpage>
        <pub-id pub-id-type="pmid">17045684</pub-id>
      </element-citation>
    </ref>
    <ref id="B4">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Briscoe</surname>
            <given-names>E</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The second release of the RASP system</article-title>
        <source>Proceedings of the Joint Conference of the International Committee on Computational Linguistics and the Association for Computational Linguistics, Interactive Presentation Sessions</source>
        <year>2006</year>
        <publisher-loc>Sydney</publisher-loc>
        <fpage>77</fpage>
        <lpage>80</lpage>
      </element-citation>
    </ref>
    <ref id="B5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gene name ambiguity of eukaryotic nomenclatures</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>248</fpage>
        <lpage>256</lpage>
        <pub-id pub-id-type="pmid">15333458</pub-id>
      </element-citation>
    </ref>
    <ref id="B6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Clark</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Curran</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>Wide-coverage efficient statistical parsing with CCG and log-linear models</article-title>
        <source>Comput. Linguist.</source>
        <year>2007</year>
        <volume>33</volume>
        <fpage>493</fpage>
        <lpage>552</lpage>
      </element-citation>
    </ref>
    <ref id="B7">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Colosimo</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Data preparation and interannotator agreement: BioCreAtIvE task 1B</article-title>
        <source>BMC Bioinformatics</source>
        <year>2005</year>
        <volume>6</volume>
        <issue>Suppl. 1</issue>
        <fpage>S11</fpage>
        <pub-id pub-id-type="pmid">15960823</pub-id>
      </element-citation>
    </ref>
    <ref id="B8">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>de Marneffe</surname>
            <given-names>M.-C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Generating typed dependency parses from phrase structure</article-title>
        <source>Proceedings of the 5th International Conference on Language Resources and Evaluation</source>
        <year>2006</year>
        <publisher-loc>Genoa, Italy</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B9">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Erkan</surname>
            <given-names>G</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Semi-supervised classification for extracting protein interaction sentences using dependency parsing</article-title>
        <source>Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</source>
        <year>2007</year>
        <publisher-loc>Prague, Czech Republic</publisher-loc>
        <fpage>228</fpage>
        <lpage>237</lpage>
      </element-citation>
    </ref>
    <ref id="B10">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hakenberg</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Inter-species normalization of gene mentions with GNAT</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <fpage>i126</fpage>
        <lpage>i132</lpage>
        <pub-id pub-id-type="pmid">18689813</pub-id>
      </element-citation>
    </ref>
    <ref id="B11">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hara</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evaluating impact of re-training a lexical disambiguation model on domain adaptation of an HPSG parser</article-title>
        <source>Proceedings of the 10th International Conference on Parsing Technology</source>
        <year>2007</year>
        <publisher-loc>Prague, Czech Republic</publisher-loc>
        <fpage>11</fpage>
        <lpage>22</lpage>
      </element-citation>
    </ref>
    <ref id="B12">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hirschman</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Overview of BioCreAtIvE task 1B: normalised gene lists</article-title>
        <source>BMC Bioinformatics</source>
        <year>2005</year>
        <volume>6</volume>
        <issue>Suppl. 1</issue>
        <fpage>S11</fpage>
        <pub-id pub-id-type="pmid">15960823</pub-id>
      </element-citation>
    </ref>
    <ref id="B13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hunter</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>KB</given-names>
          </name>
        </person-group>
        <article-title>Biomedical language processing: what's beyond PubMed</article-title>
        <source>Mol. Cell</source>
        <year>2006</year>
        <volume>21</volume>
        <fpage>589</fpage>
        <lpage>594</lpage>
        <pub-id pub-id-type="pmid">16507357</pub-id>
      </element-citation>
    </ref>
    <ref id="B14">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Japkowicz</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Learning from imbalanced data sets: a comparison of various strategies</article-title>
        <source>Proceedings of the AAAI Workshop on Learning from Imbalanced Data Sets</source>
        <year>2000</year>
        <publisher-loc>Austin, Texas</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B15">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kano</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>U-Compare: share and compare text mining tools with UIMA</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <fpage>1997</fpage>
        <lpage>1998</lpage>
        <pub-id pub-id-type="pmid">19414535</pub-id>
      </element-citation>
    </ref>
    <ref id="B16">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Kappeler</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>TX task: automatic detection of focus organisms in biomedical publications</article-title>
        <source>Proceedings of BioNLP</source>
        <year>2009</year>
        <publisher-loc>Boulder, Colorado</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B17">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Klein</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Manning</surname>
            <given-names>CD</given-names>
          </name>
        </person-group>
        <article-title>Accurate unlexicalized parsing</article-title>
        <source>Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</source>
        <year>2003</year>
        <publisher-loc>Sapporo, Japan</publisher-loc>
        <fpage>423</fpage>
        <lpage>430</lpage>
      </element-citation>
    </ref>
    <ref id="B18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krallinger</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evaluation of text-mining systems for biology: overview of the Second BioCreAtIvE community challenge</article-title>
        <source>Genome Biol.</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>Suppl. 2</issue>
        <fpage>S1</fpage>
        <pub-id pub-id-type="pmid">18834487</pub-id>
      </element-citation>
    </ref>
    <ref id="B19">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Dependency-based evaluation of Minipar</article-title>
        <source>Proceedings of Workshop on the Evaluation of Parsing Systems</source>
        <year>1998</year>
        <publisher-loc>Granada, Spain</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B20">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Miwa</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Combining multiple layers of syntactic information for protein-protein interaction extraction</article-title>
        <source>Proceedings of the 3rd International Symposium on Semantic Mining in Biomedicine</source>
        <year>2008</year>
        <publisher-loc>Turku, Finland</publisher-loc>
        <fpage>101</fpage>
        <lpage>108</lpage>
      </element-citation>
    </ref>
    <ref id="B21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Miyao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tsujii</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Feature forest models for probabilistic HPSG parsing</article-title>
        <source>Comput. Linguist.</source>
        <year>2008</year>
        <volume>34</volume>
        <fpage>35</fpage>
        <lpage>80</lpage>
      </element-citation>
    </ref>
    <ref id="B22">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Miyao</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evaluating contributions of natural language parsers to protein-protein interaction extraction</article-title>
        <source>Bioinformatics</source>
        <year>2009</year>
        <volume>25</volume>
        <fpage>394</fpage>
        <lpage>400</lpage>
        <pub-id pub-id-type="pmid">19073593</pub-id>
      </element-citation>
    </ref>
    <ref id="B23">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Morgan</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Hirschman</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Overview of BioCreAtIvE II gene normalisation</article-title>
        <source>Proceedings of the BioCreAtIvE II Workshop</source>
        <year>2007</year>
        <publisher-loc>Madrid, Spain</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B24">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Moschitti</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Making tree kernels practical for natural language learning</article-title>
        <source>Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics</source>
        <year>2006</year>
        <publisher-loc>Trento, Italy</publisher-loc>
        <fpage>113</fpage>
        <lpage>120</lpage>
      </element-citation>
    </ref>
    <ref id="B25">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Noreen</surname>
            <given-names>EW</given-names>
          </name>
        </person-group>
        <source>Computer Intensive Methods for Testing Hypothesis - An Introduction.</source>
        <year>1989</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Wiley-Interscience</publisher-name>
      </element-citation>
    </ref>
    <ref id="B26">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Sætre</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Syntactic features for protein-protein interaction extraction</article-title>
        <source>Proceedings of the 2nd International Symposium on Languages in Biology and Medicine</source>
        <year>2007</year>
        <publisher-loc>Singapore</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B27">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schwartz</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Hearst</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>A simple algorithm for identifying abbreviation definitions in biomedical text</article-title>
        <source>Pac. Symp. Biocompu.</source>
        <year>2003</year>
        <volume>8</volume>
        <fpage>451</fpage>
        <lpage>462</lpage>
      </element-citation>
    </ref>
    <ref id="B28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Settles</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>ABNER: an open source tool for automatically tagging genes, proteins, and other entity names in text</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>3191</fpage>
        <lpage>3192</lpage>
        <pub-id pub-id-type="pmid">15860559</pub-id>
      </element-citation>
    </ref>
    <ref id="B29">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Tateisi</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Syntax annotation for the GENIA corpus</article-title>
        <source>Proceedings of the 2nd International Joint Conference on Natural Language Processing</source>
        <year>2005</year>
        <publisher-loc>Jeju Island, Korea</publisher-loc>
        <fpage>220</fpage>
        <lpage>225</lpage>
      </element-citation>
    </ref>
    <ref id="B30">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Grover</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Learning the species of biomedical named entities from annotated corpora</article-title>
        <source>Proceedings of the International Conference on Language Resources and Evaluation</source>
        <year>2008</year>
        <publisher-loc>Marrakech, Morocco</publisher-loc>
      </element-citation>
    </ref>
    <ref id="B31">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Matthews</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Distinguishing the species of biomedical named entities for term identification</article-title>
        <source>BMC Bioinformatics</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>Suppl. 11</issue>
        <fpage>S6</fpage>
        <pub-id pub-id-type="pmid">19025692</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
