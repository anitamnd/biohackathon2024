<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//ACS//DTD ACS Journal DTD v1.02 20061031//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName ACSJournal-v102.dtd?>
<?SourceDTD.Version 1.02?>
<?ConverterInfo.XSLTName acs2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Anal Chem</journal-id>
    <journal-id journal-id-type="iso-abbrev">Anal Chem</journal-id>
    <journal-id journal-id-type="publisher-id">ac</journal-id>
    <journal-id journal-id-type="coden">ancham</journal-id>
    <journal-title-group>
      <journal-title>Analytical Chemistry</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0003-2700</issn>
    <issn pub-type="epub">1520-6882</issn>
    <publisher>
      <publisher-name>American Chemical Society</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8969107</article-id>
    <article-id pub-id-type="pmid">35290737</article-id>
    <article-id pub-id-type="doi">10.1021/acs.analchem.1c02220</article-id>
    <article-categories>
      <subj-group>
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Deep Learning-Assisted Peak Curation for Large-Scale
LC-MS Metabolomics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="ath1">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0493-8592</contrib-id>
        <name>
          <surname>Gloaguen</surname>
          <given-names>Yoann</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
        <xref rid="aff2" ref-type="aff">‡</xref>
        <xref rid="aff3" ref-type="aff">§</xref>
      </contrib>
      <contrib contrib-type="author" id="ath2">
        <name>
          <surname>Kirwan</surname>
          <given-names>Jennifer A.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">†</xref>
        <xref rid="aff3" ref-type="aff">§</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes" id="ath3">
        <name>
          <surname>Beule</surname>
          <given-names>Dieter</given-names>
        </name>
        <xref rid="cor1" ref-type="other">*</xref>
        <xref rid="aff2" ref-type="aff">‡</xref>
        <xref rid="aff3" ref-type="aff">§</xref>
      </contrib>
      <aff id="aff1"><label>†</label><institution>Berlin
Institute of Health at Charité, Metabolomics Platform</institution>, 10178 Berlin, <country>Germany</country></aff>
      <aff id="aff2"><label>‡</label><institution>Berlin
Institute of Health at Charité, Core Unit Bioinformatics</institution>, 10178 Berlin, <country>Germany</country></aff>
      <aff id="aff3"><label>§</label><institution>Max
Delbrück Center for Molecular Medicine in the Helmholtz Association</institution>, 13125 Berlin, <country>Germany</country></aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>*</label>Email: <email>dieter.beule@bih-charite.de</email>.</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>03</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <day>29</day>
      <month>03</month>
      <year>2022</year>
    </pub-date>
    <volume>94</volume>
    <issue>12</issue>
    <fpage>4930</fpage>
    <lpage>4937</lpage>
    <history>
      <date date-type="received">
        <day>27</day>
        <month>05</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>01</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Authors. Published by American Chemical Society</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>The Authors</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>Permits non-commercial access and re-use, provided that author attribution and integrity are maintained; but does not permit creation of adaptations or other derivative works (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">https://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract>
      <p content-type="toc-graphic">
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_0006" id="ab-tgr1"/>
      </p>
      <p>Available automated
methods for peak detection in untargeted metabolomics
suffer from poor precision. We present NeatMS, which uses machine
learning based on a convoluted neural network to reduce the number
and fraction of false peaks. NeatMS comes with a pre-trained model
representing expert knowledge in the differentiation of true chemical
signal from noise. Furthermore, it provides all necessary functions
to easily train new models or improve existing ones by transfer learning.
Thus, the tool improves peak curation and contributes to the robust
and scalable analysis of large-scale experiments. We show how to integrate
it into different liquid chromatography–mass spectrometry (LC-MS)
analysis workflows, quantify its performance, and compare it to various
other approaches. NeatMS software is available as open source on github
under permissive MIT license and is also provided as easy-to-install
PyPi and Bioconda packages.</p>
    </abstract>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution>Bundesministerium f?r Bildung und Forschung</institution>
            <institution-id institution-id-type="doi">10.13039/501100002347</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>031L0220A</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>document-id-old-9</meta-name>
        <meta-value>ac1c02220</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>document-id-new-14</meta-name>
        <meta-value>ac1c02220</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>ccc-price</meta-name>
        <meta-value/>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Liquid chromatography–mass
spectrometry (LC-MS) is a widely
used method in untargeted metabolomics. The postacquisition raw data
processing, which aims to detect compound-related peaks and distinguish
them from noise signals, is still a major challenge. Noise is defined
as the background level of signal, which surrounds the chemical signals
of interest. It can be caused by random fluctuations in the electrical
environment, although its definition is often expanded to include
chemical signals, which are of low intensity and quality and poorly
reproducible. Many algorithms and tools have been developed to automate
the process of peak picking (e.g., XCMS,<sup><xref ref-type="bibr" rid="ref1">1</xref></sup> MZmine2,<sup><xref ref-type="bibr" rid="ref2">2</xref></sup> Optimus,<sup><xref ref-type="bibr" rid="ref3">3</xref></sup> MS-DIAL<sup><xref ref-type="bibr" rid="ref4">4</xref></sup>). Pipelines for the
automatic LC-MS raw data processing usually consist of the following
steps: definition of regions of interest (ROI), detection of chromatographic
peaks, quantification of these peaks, peak matching or grouping for
samples within the batch or analysis, and clustering of peaks belonging
to the same compound. XCMS and MZmine2 (called MZmine in the rest
of the manuscript) are the most widely used open-source software that
perform all of these steps and provide the user with a table of peaks
found in the spectra and their integral intensities for each sample.
However, there is a tendency for peak picking software to overpick
peaks, i.e., they accept a large number of peaks, which are either
(i) noise or (ii) low intensity, poorly reproducible peaks, or (iii)
real peaks, which have incorrectly defined boundaries, thus creating
a high number of false-positive peaks in the final dataset.<sup><xref ref-type="bibr" rid="ref5">5</xref></sup> A previous detailed comparison of XCMS and MZMine
demonstrated that the majority of peaks picked by both software packages
were false positives.<sup><xref ref-type="bibr" rid="ref6">6</xref></sup> Poor consistency
between software is another major issue, with individual datasets
showing overlaps of as little as 36% of the peaks picked by a single
software.<sup><xref ref-type="bibr" rid="ref6">6</xref></sup> Poor peak picking may obstruct
or impede downstream analysis and biomedical interpretation of metabolomics
studies and thus some kind of manual peak curation is still the norm.
This also makes analysis of large-scale studies extremely laborious
and limits reproducibility of analysis. Recent progress in machine
learning (ML) algorithms<sup><xref ref-type="bibr" rid="ref7">7</xref></sup> and availability
of affordable parallel processing hardware (GPUs) has sparked the
application of deep learning methods in both gas chromatography–mass
spectrometry (GC-MS)<sup><xref ref-type="bibr" rid="ref8">8</xref>,<xref ref-type="bibr" rid="ref9">9</xref></sup> and LC-MS in peak detection.<sup><xref ref-type="bibr" rid="ref10">10</xref>,<xref ref-type="bibr" rid="ref11">11</xref></sup> ML has also been used for intra- and interbatch corrections<sup><xref ref-type="bibr" rid="ref12">12</xref></sup> in LC-MS. A recent review<sup><xref ref-type="bibr" rid="ref13">13</xref></sup> discusses the latest advancement of machine learning tools
for LCMS-based metabolomics. Peakonly<sup><xref ref-type="bibr" rid="ref10">10</xref></sup> is a deep neural network-based peak picking, segmentation, and integration
algorithm that attempts to achieve a higher precision than conventional
peak picking algorithm. However, it falls short in sensitivity compared
to these tools. DNN<sup><xref ref-type="bibr" rid="ref11">11</xref></sup> introduces the idea
of postprocessing results from conventional algorithms with a neural
network-based peak quality classification for the special case of
prealigned peaks. This is an important proof of concept, but is not
applicable to all study designs, and the required run time seems prohibitive
for large-scale studies and routine use.</p>
  </sec>
  <sec id="sec2">
    <title>Methods</title>
    <p>Here,
we introduce NeatMS, which is designed to serve as an independent
deep learning-based peak filter tool in existing analysis pipelines.
It addresses the overpicking issue by automatically evaluating and
classifying peaks based on quality. To achieve this, we introduce
three peak quality classes (high, acceptable, and “poor quality
or noise”—henceforth called noise; see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Figure S1</ext-link> for some examples) and provide a pre-trained neural
network to allow for out-of-the-box usage. Transfer learning and complete
re-training are also supported. NeatMS can be easily integrated into
existing workflows (see <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>a); it uses a convolutional network architecture shown in <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>b.</p>
    <fig id="fig1" position="float">
      <label>Figure 1</label>
      <caption>
        <p>(a) Integration of NeatMS
(red) into an existing workflow (blue):
samples are run through the LCMS data acquisition, raw data are processed
using standard automated tools to extract peaks, and both raw data
and extracted peaks are used as input for NeatMS that assigns them
to three classes: high quality, and acceptable or noise. The classification
information can be used in the downstream analysis. NeatMS comes with
a pre-trained network and includes all components for re-training
and transfer learning. (b) Architecture of the neural network: NeatMS
includes a two-dimensional (2D) convolutional base for feature extraction
and a classifier made of two fully connected layers. This architecture
was chosen due to its high performance in object detection and pattern
recognition.<sup><xref ref-type="bibr" rid="ref13">13</xref></sup> The max pooling layer between
the convolutional layers reduces data size in the retention time dimension.
This enables a higher abstraction of the data and reduces the number
of learned parameters and thus helps to prevent overfitting as well
as to reduce computational training effort. The classifier is made
of two fully connected layers and uses a softmax function to produce
three output values, which correspond to the peak classes.</p>
      </caption>
      <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_0002" id="gr1" position="float"/>
    </fig>
    <p>NeatMS is designed to be easily integrated into existing
workflows
and is adaptable to different measurement protocols, instruments,
and preprocessing tools. Therefore, NeatMS can be used in different
ways. Most simply, it is used to classify quality of an input dataset
using an existing model. NeatMS also allows the creation of new or
improvement of existing classification models using training data.
The training data can be generated with an integrated labeling tool.
For all usage, the input data formats are the same and processing
always starts with a data preparation step.</p>
    <sec id="sec3">
      <title>LC-MS Data Acquisition</title>
      <p>To evaluate the performance
of NeatMS, we use two datasets with known chemical standards (CS).
Dataset 1 consists of 20 quality control samples “QC 2”
from the Biocrates P400 kit<sup><xref ref-type="bibr" rid="ref14">14</xref></sup> consisting
of 80 chemical standards (CS) at proprietary concentrations in a lyophilized
plasma matrix. Dataset 2 is based on the Biocrates kit calibration
sample “Cal 1”, which is matrix-free and contains 41
of the chemical standards also present in dataset 1. Note however
that the concentration of the chemical standards (CS) in “Cal
1” is substantially lower than that in “QC 2”,
and the detailed concentration relation is however an unknown trade
secret of Biocrates. We created a serial dilution in water (1:1.2,
1:1.4, 1:1.6, 1:1.8, 1:2, 1:3, 1:5, 1:7.5, 1:10, 1:15, 1:20, 1:30,
1:50, and 1:100). Following dilution, we added 39 compounds (Biocrates
internal standard mix) at the same concentration to each sample to
act as chemical background. Each dilution was measured in triplicate.
The objective of this dilution series was to quantitatively assess
how NeatMS performed over a range of low peak intensities and near
the limit of detection. All data were acquired following Biocrates
P400 kit standard protocol on an Agilent 1290 coupled with a Thermo
Q Exactive instrument. Datasets 1 and 2 were preprocessed with MZmine
and XCMS using the versions and parameters detailed in Supporting
Information <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Table S1</ext-link>. For XCMS centWave,
we applied IPO<sup><xref ref-type="bibr" rid="ref15">15</xref></sup> for parameter optimization
individually for each dataset; furthermore, we used the XCMS peak
merging feature. For MZmine, we used the parameters recommended in
the user documentation.</p>
    </sec>
    <sec id="sec4">
      <title>Data Preparation</title>
      <p>Although the peak
detection is performed
by an external tool, workflow or pipeline, the full signal is used
for classification and is directly retrieved from the raw data. This
prevents biases originating from data transformations applied by the
different peak detection tools (baseline correction, smoothing, etc.).
Therefore, the input data of the module consists of .csv formatted
files describing the peaks detected and the raw sample files in mzML
format. Other vendor-specific raw file formats can be converted into
mzML format using the msconvert tool available in ProteoWizard.<sup><xref ref-type="bibr" rid="ref16">16</xref></sup> The csv input files can be generated using standard
preprocessing tools such as MZmine or XCMS. The position of the module
within standard data processing workflows is illustrated in <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>a. The output of
NeatMS is again in csv format and contains the information from the
input csv as well as the peak classification and labeling generated
by the software.</p>
      <p>Before any transformation, NeatMS excludes
unacceptably narrow peaks from further processing by requiring a minimum
scan number of 5 (configurable minimum scan number input filter).
As the model evaluates the peak shapes and the quality of their extraction
from the raw signal (e.g., peak boundaries), it is important to provide
contextual information. This is performed by extracting a larger retention
time (RT) window containing both the peak itself, as defined by the
preprocessing tool, and the signal surrounding the peak (called peak
margin thereafter). The RT window of the signal to be extracted is
defined as follows (with <italic>n</italic> = 1 by default)<disp-formula id="ueq1"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_m001" position="anchor"/></disp-formula>A min–max
normalization is then applied
to the extracted signal<disp-formula id="ueq2"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_m002" position="anchor"/></disp-formula>The resulting signal is linearly
interpolated
to obtain a vector of size <italic>s</italic> (120 by default). The <italic>s</italic>/(2<italic>n</italic> + 1) that is, by default, the central
40 values represents the peak signal, and the <italic>n</italic> × <italic>s</italic>/(2<italic>n</italic> + 1) that is by default the 40 values
on each side represents the peak margins as shown in <xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>. A second (binary) vector
of length <italic>s</italic> is then created to describe whether an
intensity value (single point) is part of the peak window (1) or the
margin (0). The resulting data structure is a two-dimensional tensor,
or matrix, of size 2 × <italic>s</italic>, as shown in <xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>. Although <italic>n</italic> and <italic>s</italic> can be adjusted by the user, the
pre-trained model provided with NeatMS has been trained using default
parameters and requires no adjustment when using this model.</p>
      <fig id="fig2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Data structure
of a single peak after preprocessing for neural
network feeding; <italic>s</italic>: size of scaled intensity vector, <italic>n</italic>: margin width (as a fraction of peak width), <italic>I</italic>: scaled intensity vector of size <italic>s</italic>, <italic>W</italic>: binary window vector of size <italic>s</italic> (0 = margin, 1
= peak).</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_0003" id="gr2" position="float"/>
      </fig>
    </sec>
    <sec id="sec4.1">
      <title>Convoluted Neural Network
Architecture</title>
      <p>The neural network
(see <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>b) is
built following generic convolutional network architecture including
a convolutional base for feature extraction and a classifier made
of fully connected layers. The convolutional architecture of the network
was selected due to its high performance in object detection and pattern
recognition.<sup><xref ref-type="bibr" rid="ref17">17</xref></sup> The convolutional base is
composed of two convolutional layers, with a max pooling layer between
them. This operation halves the size of the data in the retention
time dimension and enables a higher abstraction of the data to classify,
which helps to prevent potential overfitting. This layer also reduces
the number of parameters to learn and the computational cost. The
classifier part of the network is made of two dense layers and produces
three output values through a softmax activation function, which corresponds
to the number of peak quality classes. Rectified linear unit (ReLU)
activation function is used throughout the rest of the network. The
convolutional layers use a stride of 1 with a “same”
padding. The kernel size and channel number for every layer are detailed
in the figure.</p>
    </sec>
    <sec id="sec4.2">
      <title>Training</title>
      <p>Our NeatMS analysis first
evaluates the pre-trained
(PT) model. This initial model was trained by the authors on a wide
range of peak shapes from different datasets. Additionally, we used
the transfer learning approach to optimize the generic PT model to
the specifics of dataset 1; we will call the resulting second model
transfer learning (TL). The pre-trained (PT) as well as the transfer
learning (TL) model used in this work are provided in the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Supporting Information</ext-link>. All components needed
to perform creation of new models or use transfer learning to improve
existing ones are part of the open-source NeatMS software. Thus, users
can also retrain the system for their specific column/instrument/peak
detection workflow combination if the provided pre-trained (PT) model
does not suffice.</p>
      <p>The creation of a new training dataset is
facilitated by an interactive visualization and labeling tool that
can be run within a Jupyter notebook.<sup><xref ref-type="bibr" rid="ref18">18</xref></sup> Preparing a training dataset requires the user to be experienced
with mass spectrometry data analysis and chromatographic peaks evaluation.
The decisions by the user for the training data will be learned by
the algorithm and thus must be consistent and trustworthy. This tool
requires the same input as the main NeatMS tool and presents the user
with randomly selected peaks for manual assignment to the three labeling
classes. Typically, a few hundred peaks can be labeled within an hour.
The PT model is based on about 5000 peaks, and the TL model was adjusted
using about 2500 peaks. Once the desired number of peaks have been
labeled, the model can be trained using two different approaches (full
training or transfer learning, see below). The labeled dataset is
divided into an 80/10/10 training/test/validation split by default.
Model testing and validation are always performed the same way regardless
of the training approach chosen. The test set is used during the actual
training process to prevent overfitting. The validation set remains
untouched during the entire training process and is subsequently used
for hyperparameter optimization. This optimization can be performed
automatically or manually, but performing it manually allows more
control over the specificity vs. sensitivity of the model. Instructions
for the manual process are given in the documentation.</p>
      <p>The training
tool enables the freezing of any network layer, making
it possible to select the specific layers in which weights should
be adjusted. It is, however, considered better practice to only adjust
the classifier part by freezing the entire convolutional base when
the training set is very small. Guidance on layer selection is given
in the advanced section of the documentation. This approach is especially
important for transfer learning and enables fine tuning of the pre-trained
models by further training specific layers.<sup><xref ref-type="bibr" rid="ref19">19</xref></sup> The advantage of this approach over full training is that it requires
a much smaller training dataset and thus less manual labeling effort.
However, the tool also supports full training of entirely new models.
This approach consists of using only the network architecture and
fully training the model from scratch. This approach will produce
the best results for the data being analyzed but requires a large
training dataset. Instructions on how to import models are available
in the documentation.</p>
    </sec>
    <sec id="sec4.3">
      <title>Implementation</title>
      <p>NeatMS is written
in Python 3.6 and
is available as a python package through PyPi package installer and
Bioconda. The data handling and operations are performed using NumPy<sup><xref ref-type="bibr" rid="ref20">20</xref></sup> and scikit-learn,<sup><xref ref-type="bibr" rid="ref21">21</xref></sup> and the neural network is constructed using Keras<sup><xref ref-type="bibr" rid="ref22">22</xref></sup> and Tensorflow.<sup><xref ref-type="bibr" rid="ref23">23</xref></sup> As a Python
package, the intended use of the module is to be embedded as an extra
step within a data processing pipeline. The module can be integrated
and automatically executed by any pipeline or workflow management
tool capable of running python code. However, it can also be used
as a standalone application through a dedicated python script or within
a Jupyter notebook. Several Jupyter notebooks are provided for tutorial
purposes and can serve as templates and examples. The generated results
are reported in standard .csv format and can also be exported as pandas<sup><xref ref-type="bibr" rid="ref24">24</xref></sup> dataframes for direct integration in python-supported
pipelines. The structure of the output can be controlled through a
dedicated method to ensure smooth integration into the majority of
data processing pipelines. Optional filters can also be turned on
and parameterized. Details about the full usage of the export method
are provided in the documentation.</p>
    </sec>
  </sec>
  <sec id="sec5">
    <title>Results and Discussion</title>
    <p><xref rid="tbl1" ref-type="other">Table <xref rid="tbl1" ref-type="other">1</xref></xref> summarizes
the number of peaks and class assignments from NeatMS for dataset
1 using both the PT and TL models. <xref rid="tbl1" ref-type="other">Table <xref rid="tbl1" ref-type="other">1</xref></xref> shows that even if we do not use transfer
learning, NeatMS can still deliver a useful improvement for existing
MZmine workflows. It substantially reduces the number of peaks that
need to be considered for downstream analysis. This facilitates, e.g.,
differential analysis either on only high-quality data or on high-
and acceptable-quality data. For XCMS, the separation between acceptable
and high-quality class is not so clean due to the fact that the training
set was exclusively based on peaks reported by MZmine. Both MZmine
and XCMS users can start working with the PT model and will immediately
improve their workflow performance and incrementally create further
improvements by training better models. Further discussion will be
focused on NeatMS using the MZmine trained TL model. Results with
XCMS could likely be further improved by creating an XCMS-specific
trained model.</p>
    <table-wrap id="tbl1" position="float">
      <label>Table 1</label>
      <caption>
        <title>NeatMS and Peakonly Comparison<xref rid="t1fn1" ref-type="table-fn">a</xref></title>
      </caption>
      <table frame="hsides" rules="groups" border="0">
        <colgroup>
          <col align="left"/>
          <col align="left"/>
          <col align="left"/>
          <col align="left"/>
          <col align="left"/>
          <col align="left"/>
          <col align="left"/>
        </colgroup>
        <thead>
          <tr>
            <th style="border:none;" align="center"> </th>
            <th style="border:none;" align="center"> </th>
            <th style="border:none;" align="center">NeatMS MZmine TL model</th>
            <th style="border:none;" align="center">NeatMS MZmine PT model</th>
            <th style="border:none;" align="center">NeatMS XCMS TL
model</th>
            <th style="border:none;" align="center">NeatMS XCMS PT model</th>
            <th style="border:none;" align="center">peakonly</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="5" style="border:none;" align="left">peak number</td>
            <td style="border:none;" align="left">input</td>
            <td style="border:none;" align="left">6977</td>
            <td style="border:none;" align="left">6977</td>
            <td style="border:none;" align="left">5994</td>
            <td style="border:none;" align="left">5994</td>
            <td style="border:none;" align="left">1907</td>
          </tr>
          <tr>
            <td style="border:none;" align="left">classified</td>
            <td style="border:none;" align="left">5505</td>
            <td style="border:none;" align="left">5505</td>
            <td style="border:none;" align="left">4513</td>
            <td style="border:none;" align="left">4513</td>
            <td style="border:none;" align="left">not reported</td>
          </tr>
          <tr>
            <td style="border:none;" align="left">high quality</td>
            <td style="border:none;" align="left">1069</td>
            <td style="border:none;" align="left">2127</td>
            <td style="border:none;" align="left">2280</td>
            <td style="border:none;" align="left">2635</td>
            <td style="border:none;" align="left">not reported</td>
          </tr>
          <tr>
            <td style="border:none;" align="left">acceptable quality</td>
            <td style="border:none;" align="left">1945</td>
            <td style="border:none;" align="left">1817</td>
            <td style="border:none;" align="left">714</td>
            <td style="border:none;" align="left">1088</td>
            <td style="border:none;" align="left">not reported</td>
          </tr>
          <tr>
            <td style="border:none;" align="left">noise</td>
            <td style="border:none;" align="left">2491</td>
            <td style="border:none;" align="left">1560</td>
            <td style="border:none;" align="left">1519</td>
            <td style="border:none;" align="left">791</td>
            <td style="border:none;" align="left">not reported</td>
          </tr>
          <tr>
            <td rowspan="4" style="border:none;" align="left">CS found</td>
            <td style="border:none;" align="left">input and classified</td>
            <td style="border:none;" align="left">94.25%</td>
            <td style="border:none;" align="left">94.25%</td>
            <td style="border:none;" align="left">97.13%</td>
            <td style="border:none;" align="left">97.13%</td>
            <td style="border:none;" align="left">79.44%</td>
          </tr>
          <tr>
            <td style="border:none;" align="left">high quality</td>
            <td style="border:none;" align="left">79.31%</td>
            <td style="border:none;" align="left">88.19%</td>
            <td style="border:none;" align="left">91.44%</td>
            <td style="border:none;" align="left">92.94%</td>
            <td style="border:none;" align="left">not reported</td>
          </tr>
          <tr>
            <td style="border:none;" align="left">acceptable
quality</td>
            <td style="border:none;" align="left">11.25%</td>
            <td style="border:none;" align="left">4.94%</td>
            <td style="border:none;" align="left">2.13%</td>
            <td style="border:none;" align="left">3.69%</td>
            <td style="border:none;" align="left">not reported</td>
          </tr>
          <tr>
            <td style="border:none;" align="left">noise</td>
            <td style="border:none;" align="left">3.69%</td>
            <td style="border:none;" align="left">1.13%</td>
            <td style="border:none;" align="left">3.56%</td>
            <td style="border:none;" align="left">0.50%</td>
            <td style="border:none;" align="left">not reported</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="t1fn1">
          <label>a</label>
          <p>Tool and model
comparison using
dataset 1 showing average number of peaks found across 20 samples
and average percentages of detected CS. The input row shows the results
returned by the original peak detection tools (MZmine, XCMS), and
other rows show the details of the three peak classes given by NeatMS.
The total number of peaks after classification is smaller than the
input due to the application of a minimum scan number filter that
NeatMS uses (a default value of 5 is used).</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>Median relative standard deviations (RSDs) increase
substantially
from high-quality to noise peaks (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>b), with acceptable-quality peaks falling
in between. NeatMS quality class assignment differs strongly from
conventional QC-RSD filtering methods because we also observe many
noise peaks with low RSDs. This effect is present with XCMS and MZmine
for both models (not shown). <xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>d,e shows that the CSs are consistently found by NeatMS
across various low dilution samples and generally tend to move from
high to acceptable quality as dilution increases. Eventually, some
fall into the NeatMS noise category while most can no longer be detected
by MZmine as the signal decreases with increasing dilution. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Figure S2</ext-link> (peak width distribution) shows that
the noise class is dominated by rather broad peaks while the high-quality
class shows a consistent peak width distribution independent of the
peak area. This indicates that our three classes represent a sensible
quality classification for peaks. <xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>a (ROC curve) shows that the learning itself
was very successful, the model closely resembles the expert knowledge
of the trainer. Thus, NeatMS evaluation is comparable to, but much
faster and much more reproducible and consistent than, human expert
evaluation. NeatMS must be considered superior for large-scale studies
with hundreds or thousands of samples and potentially several millions
of peaks. By including training and transfer learning functionality
into our solution, we empower researchers to adapt and optimize the
learned classification and filtering to their specific data, needs,
and preferences.</p>
    <fig id="fig3" position="float">
      <label>Figure 3</label>
      <caption>
        <p>NeatMS results for dataset 1 (a–c) and dataset
2 (d, e)
based on TL model and MZmine output. (a) ROC curves showing learning
efficacy for three different group separations. The curves are created
using the validation set of the TL model learning; the high-quality
class probability returned by the model is used as the varying parameter.
(b) Box plots of RSDs: high-quality peaks show lower individual RSDs
and reduced within-class RSD variability. Each feature for which peaks
were present in at least four samples was assigned to a quality based
on the most frequently reported class. (c) Venn diagram comparing
peakonly and NeatMS. Numbers show averages over the 20 samples: total number of detected peaks
(black), percent of recovered CSs (red). On average, NeatMS reports
63.5 CSs as high quality, i.e., recovers 79% of original, another
11% are considered acceptable quality. Note that matching peaks derived
by different algorithms is challenging in itself and not completely
unambiguous; cf. <xref rid="sec6" ref-type="other">Data Analysis Details</xref> section
for details. (d) Classification of individual CS over different dilutions
and for different tools, NeatMS high-quality class outperforms peakonly
for most dilutions. A substantial number of additional CSs are categorized
in the “acceptable quality” class. (e) Sankey diagram
showing the distribution of the 41 diluted CSs for all three replicates
in different quality classes and their change between dilution steps.
Each dilution step is represented by a stacked barplot; the widths
of the flows between bar plots (dilutions) represent the fraction
of CSs going from one class to another.</p>
      </caption>
      <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_0004" id="gr3" position="float"/>
    </fig>
    <sec id="sec6">
      <title>Data Analysis
Details</title>
      <p>Our validation with dataset 1
focuses on the number of known spiked chemical standards found by
the different tools. Peak identification was performed using compound-specific
RT and <italic>m</italic>/<italic>z</italic> tolerance windows provided
with the Biocrates kit. To compute the final results, percentages
were calculated on the basis that all 80 compounds are detectable
in all 20 samples. The same approach was used to analyze the recovery
of CSs in dataset 2. These samples contain the same 80 CSs as dataset
1, but only 41 of the CSs were diluted, while 39 were used as internal
standards and thus were at the same concentration throughout (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Figure S3b</ext-link>). The Sankey diagram (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>e) was created by comparing
the peak classes of the CSs for all three replicates in the consecutive
dilution points to generate migration flows. A class corresponding
to nondetected CSs was added to conserve an even CS population size
throughout. To create the Venn diagrams (<xref rid="fig3" ref-type="fig">Figures <xref rid="fig3" ref-type="fig">3</xref></xref>c and <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">S5</ext-link>), peaks
reported by one tool were compared to the list of peaks reported by
the other tool and considered the same when any two peaks presented
a mutual overlap higher than 50% in the RT and <italic>m</italic>/<italic>z</italic> dimensions, respectively. However, tools can differ widely
in the peak boundaries assignment for the same peak. Therefore, any
peak matching method will remain imperfect and ambiguous. This explains
the noncomplete overlap of peaks found by NeatMS compared to peakonly.
To generate RSD results in <xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>b, we used peak alignment (using the MZmine join aligner
algorithm) and assigned the features to the most frequently found
quality class across the 20 samples. Features were retained only when
present in a minimum of four samples.</p>
    </sec>
    <sec id="sec7">
      <title>Comparison with Peakonly</title>
      <p><xref rid="tbl1" ref-type="other">Table <xref rid="tbl1" ref-type="other">1</xref></xref> also shows
a comparison of NeatMS to results
obtained with the recently published peakonly tool,<sup><xref ref-type="bibr" rid="ref10">10</xref></sup> which also applies machine learning on raw data to detect
high-quality peaks. We choose the peakonly parameters as suggested
by the authors and also tried to further optimize them; see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Figure S4</ext-link>. Unfortunately, it was not possible
to apply transfer learning or any re-training for peakonly because
the software does not provide the necessary components to do this.</p>
      <p><xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>d shows
that NeatMS high-quality class equals or outperforms peakonly in CS
peak recognition for all dilutions. Additional CSs are classified
as acceptable. A more detailed comparison for dataset 1 is shown in <xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>c (for XCMS, we find
comparable results; see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Figure S5</ext-link>). NeatMS
High and Acceptable quality classes together contain on average more
than 90% of CSs. Peakonly reports an average of 1907 peaks, containing
on average 79% of the CSs. Approximately the same percentage of CS
is contained in 1069 high-quality peaks reported by NeatMS. The concordance
is however not perfect. Only rarely do we miss CSs that peakonly reports
(0.7%). A small portion of the CS matched signals are considered Noise
by NeatMS. Upon visual inspection, our expert usually agrees with
the NeatMS algorithm (see <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Figure S6</ext-link>).</p>
    </sec>
    <sec id="sec8">
      <title>Comparison
with DNN and MetaClean</title>
      <p>In addition to the
comparison with peakonly,<sup><xref ref-type="bibr" rid="ref10">10</xref></sup> we also compared
NeatMS with a deep neural network-based peak filtering tool developed
by Kantz et al.<sup><xref ref-type="bibr" rid="ref11">11</xref></sup> (referred to as DNN tool
thereafter) using their default parameters. In contrast to peakonly
and NeatMS, DNN uses a peak position imputation/gap filling approach,
i.e., positions that contain peaks in a certain minimal number of
samples are evaluated and quantified in all samples. Similar functionality
is also optionally provided by MZmine; thus, NeatMS can also support
this approach although this makes an unbiased evaluation of tool performance
more difficult. This becomes very obvious in dataset 2, where we do
not want to use information from the highly concentrated samples to
infer algorithm performance on the lowly concentrated samples. <xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref>a visualizes the
comparison of NeatMS and DNN for dataset 1, and the full confusion
matrices are shown in Supporting Information <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Tables S4 and S5</ext-link>. Note that gap filling does not substantially alter
NeatMS results; cf. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Table S3</ext-link>. Overall,
DNN finds about 85% CS in the Good category compared to about 91%
by NeatMS. Overall, the results of the two tools are consistent but
NeatMS still outperforms DNN. Furthermore, processing with DNN required
about 24 h, while NeatMS took less than 10 min on the same hardware.
Similar differences applied in terms of storage needs. This is in
line with the DNN authors claiming to provide an “important
proof of concept” and our ambition to provide easy-to-use software.
Users of all three tools—DNN, peakonly, or NeatMS—should
be aware that just as any other compound, contaminants may produce
high-quality or low-quality peaks. Addressing contaminant-related
issues is indeed an important task but is outside of the scope of
this work or tools like DNN or peakonly, respectively.</p>
      <fig id="fig4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Venn diagram comparing
(a) DNN and NeatMS and (b) MetaClean and
NeatMS analogue to peakonly comparison in <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>c using dataset 1. Numbers shown are averages
over 20 samples: total number of detected peaks (black), percent of
recovered CSs (red). The total compounds percentage refers to the
total recovered CS. For clarity, the figure is limited to MetaClean
“Pass” and DNN “Good” classes, and the
full confusion matrices are given in Supporting Information <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Tables S4–S7</ext-link>.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_0005" id="gr4" position="float"/>
      </fig>
      <p>Finally, we compared NeatMS performances with those of MetaClean,<sup><xref ref-type="bibr" rid="ref25">25</xref></sup> which uses a machine learning-based classifier
to reduce false-positive peak detection by assigning “Pass”
or “Fail” labels to peaks aligned and grouped across
samples. The tool is designed to use with XCMS, and peaks must be
aligned and gap-filled. <xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref>b visualizes the comparison of NeatMS and MetaClean for dataset
1, and the full confusion matrices are given in Supporting Information <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">Tables S6 and S7</ext-link>. At least for this dataset NeatMS
recovers much more CS (about 94%) compared to 36% by MetaClean. Compute
and storage resources requirements are comparable to NeatMS.</p>
    </sec>
  </sec>
  <sec id="sec9">
    <title>Conclusions</title>
    <p>NeatMS outperforms existing tools for peak curation; it requires
neither large computing power nor long computing time; all data analysis
described in this manuscript can be done with a standard laptop within
minutes, and all described training can be done with a modern PC within
a few hours. NeatMS software is available as open source on github
under permissive MIT license and also provided as easy-to-install
PyPi and Bioconda<sup><xref ref-type="bibr" rid="ref26">26</xref></sup> packages. NeatMS comes
with comprehensive user documentation, tutorials, and importantly
also contains an easy-to-use training tool. Users can thus create
their own models or improve existing ones according to their specific
needs. NeatMS supports standard input and output formats and is therefore
easily added into existing workflows. Thus, it is compatible with
many use cases and may help to enable improved and reproducible data
analysis for large LC-MS studies.</p>
  </sec>
</body>
<back>
  <notes id="notes-1" notes-type="si">
    <title>Supporting Information Available</title>
    <p>The Supporting Information
is available free of charge at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/10.1021/acs.analchem.1c02220?goto=supporting-info">https://pubs.acs.org/doi/10.1021/acs.analchem.1c02220</ext-link>.<list id="silist" list-type="simple"><list-item><p>Example of CS peaks (Figure
S1); peak width density
plots per quality class (Figure S2); peak number and internal standard
recovery (Figure S3); average detected peak number and standard compound
recovered by peakonly on dataset 1 relative to parameter selection
(Figure S4); Venn diagram comparing peakonly and the combination XCMS
with NeatMS TL model (Figure S5); extracted ion chromatogram of a
noise peak reported by MZmine (Figure S6); parameters of the different
tools used for datasets 1 and 2 (Table S1); performance of peakonly
with NeatMS (Table S2); NeatMS results using TL model on dataset 1
(Table S3); confusion matrix of DNN and NeatMS number of peaks per
class (Table S4); confusion matrix of DNN and NeatMS CS recovery per
class (Table S5); confusion matrix of MetaClean and NeatMS number
of peaks per class (Table S6); and confusion matrix of MetaClean and
NeatMS CS recovery per class (Table S7) (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.1c02220/suppl_file/ac1c02220_si_001.pdf">PDF</ext-link>)</p></list-item></list></p>
  </notes>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sifile1">
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ac1c02220_si_001.pdf">
        <caption>
          <p>ac1c02220_si_001.pdf</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <notes notes-type="" id="notes-4">
    <title>Author Contributions</title>
    <p>The manuscript
was written through contributions of all authors. All authors have
given approval to the final version of the manuscript.</p>
  </notes>
  <notes notes-type="COI-statement" id="NOTES-d7e798-autogenerated">
    <p>The authors declare no
competing financial interest.</p>
  </notes>
  <notes notes-type="" id="notes-2">
    <title>Notes</title>
    <p>The github
repository contains some sample
data from dataset 1; the full datasets can be downloaded from <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://doi.org/10.5281/zenodo.3973172">http://doi.org/10.5281/zenodo.3973172</uri>.</p>
  </notes>
  <notes notes-type="" id="notes-3">
    <title>Notes</title>
    <p>NeatMS is open source and is
freely available
at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/bihealth/NeatMS">https://github.com/bihealth/NeatMS</uri> under permissive MIT license. A PyPi package is available at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://pypi.org/project/NeatMS/;">https://pypi.org/project/NeatMS/;</uri> a Bioconda package is available at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://anaconda.org/bioconda/neatms">https://anaconda.org/bioconda/neatms</uri>. The user documentation can be found at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://neatms.readthedocs.io/en/latest/">https://neatms.readthedocs.io/en/latest/</uri>.</p>
  </notes>
  <ack>
    <title>Acknowledgments</title>
    <p>The authors thank Alina Eisenberger and Raphaela Fritsche
for generating datasets 1 and 2, Friederike Gutmann and Mathias Kuhring
for testing NeatMS and providing valuable feedback, and Eric Blanc
for his valuable insight on machine learning. This work was supported
by BMBF-grant 031L0220A.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="ref1">
      <mixed-citation publication-type="journal" id="cit1"><name><surname>Smith</surname><given-names>C. A.</given-names></name>; <name><surname>Want</surname><given-names>E. J.</given-names></name>; <name><surname>O’Maille</surname><given-names>G.</given-names></name>; <name><surname>Abagyan</surname><given-names>R.</given-names></name>; <name><surname>Siuzdak</surname><given-names>G.</given-names></name><article-title>XCMS: Processing
Mass Spectrometry Data for Metabolite Profiling Using Nonlinear Peak
Alignment, Matching, and Identification</article-title>. <source>Anal.
Chem.</source><year>2006</year>, <volume>78</volume>, <fpage>779</fpage>–<lpage>787</lpage>. <pub-id pub-id-type="doi">10.1021/ac051437y</pub-id>.<pub-id pub-id-type="pmid">16448051</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <mixed-citation publication-type="journal" id="cit2"><name><surname>Pluskal</surname><given-names>T.</given-names></name>; <name><surname>Castillo</surname><given-names>S.</given-names></name>; <name><surname>Villar-Briones</surname><given-names>A.</given-names></name>; <name><surname>Orešič</surname><given-names>M.</given-names></name><article-title>MZmine 2:
Modular Framework for Processing, Visualizing, and Analyzing Mass
Spectrometry-Based Molecular Profile Data</article-title>. <source>BMC
Bioinf.</source><year>2010</year>, <volume>11</volume>, <elocation-id>395</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2105-11-395</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref3">
      <mixed-citation publication-type="journal" id="cit3"><name><surname>Protsyuk</surname><given-names>I.</given-names></name>; <name><surname>Melnik</surname><given-names>A. V.</given-names></name>; <name><surname>Nothias</surname><given-names>L.-F.</given-names></name>; <name><surname>Rappez</surname><given-names>L.</given-names></name>; <name><surname>Phapale</surname><given-names>P.</given-names></name>; <name><surname>Aksenov</surname><given-names>A. A.</given-names></name>; <name><surname>Bouslimani</surname><given-names>A.</given-names></name>; <name><surname>Ryazanov</surname><given-names>S.</given-names></name>; <name><surname>Dorrestein</surname><given-names>P. C.</given-names></name>; <name><surname>Alexandrov</surname><given-names>T.</given-names></name><article-title>3D Molecular
Cartography Using LC–MS Facilitated
by Optimus and’ili Software</article-title>. <source>Nat. Protoc.</source><year>2018</year>, <volume>13</volume>, <fpage>134</fpage>–<lpage>154</lpage>. <pub-id pub-id-type="doi">10.1038/nprot.2017.122</pub-id>.<pub-id pub-id-type="pmid">29266099</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <mixed-citation publication-type="journal" id="cit4"><name><surname>Tsugawa</surname><given-names>H.</given-names></name>; <name><surname>Cajka</surname><given-names>T.</given-names></name>; <name><surname>Kind</surname><given-names>T.</given-names></name>; <name><surname>Ma</surname><given-names>Y.</given-names></name>; <name><surname>Higgins</surname><given-names>B.</given-names></name>; <name><surname>Ikeda</surname><given-names>K.</given-names></name>; <name><surname>Kanazawa</surname><given-names>M.</given-names></name>; <name><surname>VanderGheynst</surname><given-names>J.</given-names></name>; <name><surname>Fiehn</surname><given-names>O.</given-names></name>; <name><surname>Arita</surname><given-names>M.</given-names></name><article-title>MS-DIAL: Data-Independent MS/MS Deconvolution
for Comprehensive Metabolome Analysis</article-title>. <source>Nat.
Methods</source><year>2015</year>, <volume>12</volume>, <fpage>523</fpage>–<lpage>526</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.3393</pub-id>.<pub-id pub-id-type="pmid">25938372</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <mixed-citation publication-type="journal" id="cit5"><name><surname>Myers</surname><given-names>O. D.</given-names></name>; <name><surname>Sumner</surname><given-names>S. J.</given-names></name>; <name><surname>Li</surname><given-names>S.</given-names></name>; <name><surname>Barnes</surname><given-names>S.</given-names></name>; <name><surname>Du</surname><given-names>X.</given-names></name><article-title>One Step Forward
for Reducing False Positive and False Negative Compound Identifications
from Mass Spectrometry Metabolomics Data: New Algorithms for Constructing
Extracted Ion Chromatograms and Detecting Chromatographic Peaks</article-title>. <source>Anal. Chem.</source><year>2017</year>, <volume>89</volume>, <fpage>8696</fpage>–<lpage>8703</lpage>. <pub-id pub-id-type="doi">10.1021/acs.analchem.7b00947</pub-id>.<pub-id pub-id-type="pmid">28752754</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <mixed-citation publication-type="journal" id="cit6"><name><surname>Myers</surname><given-names>O. D.</given-names></name>; <name><surname>Sumner</surname><given-names>S. J.</given-names></name>; <name><surname>Li</surname><given-names>S.</given-names></name>; <name><surname>Barnes</surname><given-names>S.</given-names></name>; <name><surname>Du</surname><given-names>X.</given-names></name><article-title>Detailed Investigation
and Comparison of the XCMS and MZmine 2 Chromatogram Construction
and Chromatographic Peak Detection Methods for Preprocessing Mass
Spectrometry Metabolomics Data</article-title>. <source>Anal. Chem.</source><year>2017</year>, <volume>89</volume>, <fpage>8689</fpage>–<lpage>8695</lpage>. <pub-id pub-id-type="doi">10.1021/acs.analchem.7b01069</pub-id>.<pub-id pub-id-type="pmid">28752757</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <mixed-citation publication-type="journal" id="cit7"><person-group person-group-type="allauthors"><name><surname>Zhang</surname><given-names>A.</given-names></name>; <name><surname>Lipton</surname><given-names>Z. C.</given-names></name>; <name><surname>Li</surname><given-names>M.</given-names></name>; <name><surname>Smola</surname><given-names>A.
J.</given-names></name></person-group><article-title>Dive into Deep
Learning</article-title>, <source>arXiv preprint</source><year>2021</year>, arXiv:2106.11342.</mixed-citation>
    </ref>
    <ref id="ref8">
      <mixed-citation publication-type="journal" id="cit8"><name><surname>Borgsmüller</surname><given-names>N.</given-names></name>; <name><surname>Gloaguen</surname><given-names>Y.</given-names></name>; <name><surname>Opialla</surname><given-names>T.</given-names></name>; <name><surname>Blanc</surname><given-names>E.</given-names></name>; <name><surname>Sicard</surname><given-names>E.</given-names></name>; <name><surname>Royer</surname><given-names>A.-L.</given-names></name>; <name><surname>Le Bizec</surname><given-names>B.</given-names></name>; <name><surname>Durand</surname><given-names>S.</given-names></name>; <name><surname>Migné</surname><given-names>C.</given-names></name>; <name><surname>Pétéra</surname><given-names>M.</given-names></name>; <name><surname>Pujos-Guillot</surname><given-names>E.</given-names></name>; <name><surname>Giacomoni</surname><given-names>F.</given-names></name>; <name><surname>Guitton</surname><given-names>Y.</given-names></name>; <name><surname>Beule</surname><given-names>D.</given-names></name>; <name><surname>Kirwan</surname><given-names>J.</given-names></name><article-title>WiPP: Workflow for
Improved Peak Picking for Gas Chromatography-Mass Spectrometry (GC-MS)
Data</article-title>. <source>Metabolites</source><year>2019</year>, <volume>9</volume>, <elocation-id>171</elocation-id><pub-id pub-id-type="doi">10.3390/metabo9090171</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref9">
      <mixed-citation publication-type="journal" id="cit9"><name><surname>Lebanov</surname><given-names>L.</given-names></name>; <name><surname>Tedone</surname><given-names>L.</given-names></name>; <name><surname>Ghiasvand</surname><given-names>A.</given-names></name>; <name><surname>Paull</surname><given-names>B.</given-names></name><article-title>Random Forests Machine
Learning Applied to Gas Chromatography – Mass Spectrometry
Derived Average Mass Spectrum Data Sets for Classification and Characterisation
of Essential Oils</article-title>. <source>Talanta</source><year>2020</year>, <volume>208</volume>, <elocation-id>120471</elocation-id><pub-id pub-id-type="doi">10.1016/j.talanta.2019.120471</pub-id>.<pub-id pub-id-type="pmid">31816792</pub-id></mixed-citation>
    </ref>
    <ref id="ref10">
      <mixed-citation publication-type="journal" id="cit10"><name><surname>Melnikov</surname><given-names>A. D.</given-names></name>; <name><surname>Tsentalovich</surname><given-names>Y. P.</given-names></name>; <name><surname>Yanshole</surname><given-names>V. V.</given-names></name><article-title>Deep Learning for
the Precise Peak
Detection in High-Resolution LC–MS Data</article-title>. <source>Anal. Chem.</source><year>2020</year>, <volume>92</volume>, <fpage>588</fpage>–<lpage>592</lpage>. <pub-id pub-id-type="doi">10.1021/acs.analchem.9b04811</pub-id>.<pub-id pub-id-type="pmid">31841624</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <mixed-citation publication-type="journal" id="cit11"><name><surname>Kantz</surname><given-names>E. D.</given-names></name>; <name><surname>Tiwari</surname><given-names>S.</given-names></name>; <name><surname>Watrous</surname><given-names>J. D.</given-names></name>; <name><surname>Cheng</surname><given-names>S.</given-names></name>; <name><surname>Jain</surname><given-names>M.</given-names></name><article-title>Deep Neural
Networks for Classification of LC-MS Spectral Peaks</article-title>. <source>Anal. Chem.</source><year>2019</year>, <volume>91</volume>, <fpage>12407</fpage>–<lpage>12413</lpage>. <pub-id pub-id-type="doi">10.1021/acs.analchem.9b02983</pub-id>.<pub-id pub-id-type="pmid">31483992</pub-id></mixed-citation>
    </ref>
    <ref id="ref12">
      <mixed-citation publication-type="journal" id="cit12"><name><surname>Rong</surname><given-names>Z.</given-names></name>; <name><surname>Tan</surname><given-names>Q.</given-names></name>; <name><surname>Cao</surname><given-names>L.</given-names></name>; <name><surname>Zhang</surname><given-names>L.</given-names></name>; <name><surname>Deng</surname><given-names>K.</given-names></name>; <name><surname>Huang</surname><given-names>Y.</given-names></name>; <name><surname>Zhu</surname><given-names>Z.-J.</given-names></name>; <name><surname>Li</surname><given-names>Z.</given-names></name>; <name><surname>Li</surname><given-names>K.</given-names></name><article-title>NormAE: Deep Adversarial
Learning Model to Remove Batch Effects in Liquid Chromatography Mass
Spectrometry-Based Metabolomics Data</article-title>. <source>Anal.
Chem.</source><year>2020</year>, <volume>92</volume>, <fpage>5082</fpage>–<lpage>5090</lpage>. <pub-id pub-id-type="doi">10.1021/acs.analchem.9b05460</pub-id>.<pub-id pub-id-type="pmid">32207605</pub-id></mixed-citation>
    </ref>
    <ref id="ref13">
      <mixed-citation publication-type="journal" id="cit13"><name><surname>Rampler</surname><given-names>E.</given-names></name>; <name><surname>Abiead</surname><given-names>Y. E.</given-names></name>; <name><surname>Schoeny</surname><given-names>H.</given-names></name>; <name><surname>Rusz</surname><given-names>M.</given-names></name>; <name><surname>Hildebrand</surname><given-names>F.</given-names></name>; <name><surname>Fitz</surname><given-names>V.</given-names></name>; <name><surname>Koellensperger</surname><given-names>G.</given-names></name><article-title>Recurrent
Topics in Mass Spectrometry-Based
Metabolomics and Lipidomics—Standardization, Coverage, and
Throughput</article-title>. <source>Anal. Chem.</source><year>2021</year>, <volume>93</volume>, <fpage>519</fpage>–<lpage>545</lpage>. <pub-id pub-id-type="doi">10.1021/acs.analchem.0c04698</pub-id>.<pub-id pub-id-type="pmid">33249827</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <mixed-citation publication-type="weblink" id="cit14"><article-title>AbsoluteIDQ p400 HR Kit - Metabolomics kit for Exactive<sup>TM</sup></article-title>. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://biocrates.com/absoluteidq-p400-hr-kit/">https://biocrates.com/absoluteidq-p400-hr-kit/</uri> (accessed July 28, <year>2020</year>).</mixed-citation>
    </ref>
    <ref id="ref15">
      <mixed-citation publication-type="journal" id="cit15"><name><surname>Libiseller</surname><given-names>G.</given-names></name>; <name><surname>Dvorzak</surname><given-names>M.</given-names></name>; <name><surname>Kleb</surname><given-names>U.</given-names></name>; <name><surname>Gander</surname><given-names>E.</given-names></name>; <name><surname>Eisenberg</surname><given-names>T.</given-names></name>; <name><surname>Madeo</surname><given-names>F.</given-names></name>; <name><surname>Neumann</surname><given-names>S.</given-names></name>; <name><surname>Trausinger</surname><given-names>G.</given-names></name>; <name><surname>Sinner</surname><given-names>F.</given-names></name>; <name><surname>Pieber</surname><given-names>T.</given-names></name>; <name><surname>Magnes</surname><given-names>C.</given-names></name><article-title>IPO: A Tool for Automated
Optimization of XCMS Parameters</article-title>. <source>BMC Bioinf.</source><year>2015</year>, <volume>16</volume>, <elocation-id>118</elocation-id><pub-id pub-id-type="doi">10.1186/s12859-015-0562-8</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref16">
      <mixed-citation publication-type="journal" id="cit16"><name><surname>Chambers</surname><given-names>M. C.</given-names></name>; <name><surname>Maclean</surname><given-names>B.</given-names></name>; <name><surname>Burke</surname><given-names>R.</given-names></name>; <name><surname>Amodei</surname><given-names>D.</given-names></name>; <name><surname>Ruderman</surname><given-names>D. L.</given-names></name>; <name><surname>Neumann</surname><given-names>S.</given-names></name>; <name><surname>Gatto</surname><given-names>L.</given-names></name>; <name><surname>Fischer</surname><given-names>B.</given-names></name>; <name><surname>Pratt</surname><given-names>B.</given-names></name>; <name><surname>Egertson</surname><given-names>J.</given-names></name>; <name><surname>Hoff</surname><given-names>K.</given-names></name>; <name><surname>Kessner</surname><given-names>D.</given-names></name>; <name><surname>Tasman</surname><given-names>N.</given-names></name>; <name><surname>Shulman</surname><given-names>N.</given-names></name>; <name><surname>Frewen</surname><given-names>B.</given-names></name>; <name><surname>Baker</surname><given-names>T. A.</given-names></name>; <name><surname>Brusniak</surname><given-names>M.-Y.</given-names></name>; <name><surname>Paulse</surname><given-names>C.</given-names></name>; <name><surname>Creasy</surname><given-names>D.</given-names></name>; <name><surname>Flashner</surname><given-names>L.</given-names></name>; <name><surname>Kani</surname><given-names>K.</given-names></name>; <name><surname>Moulding</surname><given-names>C.</given-names></name>; <name><surname>Seymour</surname><given-names>S. L.</given-names></name>; <name><surname>Nuwaysir</surname><given-names>L. M.</given-names></name>; <name><surname>Lefebvre</surname><given-names>B.</given-names></name>; <name><surname>Kuhlmann</surname><given-names>F.</given-names></name>; <name><surname>Roark</surname><given-names>J.</given-names></name>; <name><surname>Rainer</surname><given-names>P.</given-names></name>; <name><surname>Detlev</surname><given-names>S.</given-names></name>; <name><surname>Hemenway</surname><given-names>T.</given-names></name>; <name><surname>Huhmer</surname><given-names>A.</given-names></name>; <name><surname>Langridge</surname><given-names>J.</given-names></name>; <name><surname>Connolly</surname><given-names>B.</given-names></name>; <name><surname>Chadick</surname><given-names>T.</given-names></name>; <name><surname>Holly</surname><given-names>K.</given-names></name>; <name><surname>Eckels</surname><given-names>J.</given-names></name>; <name><surname>Deutsch</surname><given-names>E. W.</given-names></name>; <name><surname>Moritz</surname><given-names>R. L.</given-names></name>; <name><surname>Katz</surname><given-names>J. E.</given-names></name>; <name><surname>Agus</surname><given-names>D. B.</given-names></name>; <name><surname>MacCoss</surname><given-names>M.</given-names></name>; <name><surname>Tabb</surname><given-names>D. L.</given-names></name>; <name><surname>Mallick</surname><given-names>P.</given-names></name><article-title>A Cross-Platform
Toolkit
for Mass Spectrometry and Proteomics</article-title>. <source>Nat. Biotechnol.</source><year>2012</year>, <volume>30</volume>, <fpage>918</fpage>–<lpage>920</lpage>. <pub-id pub-id-type="doi">10.1038/nbt.2377</pub-id>.<pub-id pub-id-type="pmid">23051804</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <mixed-citation publication-type="journal" id="cit17"><name><surname>Rawat</surname><given-names>W.</given-names></name>; <name><surname>Wang</surname><given-names>Z.</given-names></name><article-title>Deep Convolutional Neural Networks for Image Classification: A Comprehensive
Review</article-title>. <source>Neural Comput.</source><year>2017</year>, <volume>29</volume>, <fpage>2352</fpage>–<lpage>2449</lpage>. <pub-id pub-id-type="doi">10.1162/NECO_a_00990</pub-id>.<pub-id pub-id-type="pmid">28599112</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <mixed-citation publication-type="journal" id="cit18"><name><surname>Perez</surname><given-names>F.</given-names></name>; <name><surname>Granger</surname><given-names>B. E.</given-names></name><article-title>IPython: A System for Interactive Scientific Computing</article-title>. <source>Comput. Sci. Eng.</source><year>2007</year>, <volume>9</volume>, <fpage>21</fpage>–<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2007.53</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref19">
      <mixed-citation publication-type="journal" id="cit19"><name><surname>Pan</surname><given-names>S. J.</given-names></name>; <name><surname>Yang</surname><given-names>Q.</given-names></name><article-title>A Survey on Transfer
Learning</article-title>. <source>IEEE Trans.
Knowl. Data Eng.</source><year>2010</year>, <volume>22</volume>, <fpage>1345</fpage>–<lpage>1359</lpage>. <pub-id pub-id-type="doi">10.1109/TKDE.2009.191</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref20">
      <mixed-citation publication-type="journal" id="cit20"><name><surname>van
der Walt</surname><given-names>S.</given-names></name>; <name><surname>Colbert</surname><given-names>S. C.</given-names></name>; <name><surname>Varoquaux</surname><given-names>G.</given-names></name><article-title>The NumPy
Array: A Structure for Efficient Numerical Computation</article-title>. <source>Comput. Sci. Eng.</source><year>2011</year>, <volume>13</volume>, <fpage>22</fpage>–<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref21">
      <mixed-citation publication-type="journal" id="cit21"><name><surname>Pedregosa</surname><given-names>F.</given-names></name>; <name><surname>Varoquaux</surname><given-names>G.</given-names></name>; <name><surname>Gramfort</surname><given-names>A.</given-names></name>; <name><surname>Michel</surname><given-names>V.</given-names></name>; <name><surname>Thirion</surname><given-names>B.</given-names></name>; <name><surname>Grisel</surname><given-names>O.</given-names></name>; <name><surname>Blondel</surname><given-names>M.</given-names></name>; <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>; <name><surname>Weiss</surname><given-names>R.</given-names></name>; <name><surname>Dubourg</surname><given-names>V.</given-names></name>; <name><surname>Vanderplas</surname><given-names>J.</given-names></name>; <name><surname>Passos</surname><given-names>A.</given-names></name>; <name><surname>Cournapeau</surname><given-names>D.</given-names></name>; <name><surname>Brucher</surname><given-names>M.</given-names></name>; <name><surname>Perrot</surname><given-names>M.</given-names></name>; <name><surname>Duchesnay</surname><given-names>É.</given-names></name><article-title>Scikit-Learn:
Machine Learning in Python</article-title>. <source>J. Mach. Learn.
Res.</source><year>2011</year>, <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <mixed-citation publication-type="undeclared" id="cit22"><person-group person-group-type="allauthors"><name><surname>Chollet</surname><given-names>F.</given-names></name></person-group><etal/><source>Keras</source>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="ref23">
      <mixed-citation publication-type="undeclared" id="cit23"><person-group person-group-type="allauthors"><name><surname>Abadi</surname><given-names>M.</given-names></name>; <name><surname>Agarwal</surname><given-names>A.</given-names></name>; <name><surname>Barham</surname><given-names>P.</given-names></name>; <name><surname>Brevdo</surname><given-names>E.</given-names></name>; <name><surname>Chen</surname><given-names>Z.</given-names></name>; <name><surname>Citro</surname><given-names>C.</given-names></name>; <name><surname>Corrado</surname><given-names>G. S.</given-names></name>; <name><surname>Davis</surname><given-names>A.</given-names></name>; <name><surname>Dean</surname><given-names>J.</given-names></name>; <name><surname>Devin</surname><given-names>M.</given-names></name>; <name><surname>Ghemawat</surname><given-names>S.</given-names></name>; <name><surname>Goodfellow</surname><given-names>I.</given-names></name>; <name><surname>Harp</surname><given-names>A.</given-names></name>; <name><surname>Irving</surname><given-names>G.</given-names></name>; <name><surname>Isard</surname><given-names>M.</given-names></name>; <name><surname>Jia</surname><given-names>Y.</given-names></name>; <name><surname>Jozefowicz</surname><given-names>R.</given-names></name>; <name><surname>Kaiser</surname><given-names>L.</given-names></name>; <name><surname>Kudlur</surname><given-names>M.</given-names></name>; <name><surname>Levenberg</surname><given-names>J.</given-names></name>; <name><surname>Mané</surname><given-names>D.</given-names></name>; <name><surname>Monga</surname><given-names>R.</given-names></name>; <name><surname>Moore</surname><given-names>S.</given-names></name>; <name><surname>Murray</surname><given-names>D.</given-names></name>; <name><surname>Olah</surname><given-names>C.</given-names></name>; <name><surname>Schuster</surname><given-names>M.</given-names></name>; <name><surname>Shlens</surname><given-names>J.</given-names></name>; <name><surname>Steiner</surname><given-names>B.</given-names></name>; <name><surname>Sutskever</surname><given-names>I.</given-names></name>; <name><surname>Talwar</surname><given-names>K.</given-names></name>; <name><surname>Tucker</surname><given-names>P.</given-names></name>; <name><surname>Vanhoucke</surname><given-names>V.</given-names></name>; <name><surname>Vasudevan</surname><given-names>V.</given-names></name>; <name><surname>Viégas</surname><given-names>F.</given-names></name>; <name><surname>Vinyals</surname><given-names>O.</given-names></name>; <name><surname>Warden</surname><given-names>P.</given-names></name>; <name><surname>Wattenberg</surname><given-names>M.</given-names></name>; <name><surname>Wicke</surname><given-names>M.</given-names></name>; <name><surname>Yu</surname><given-names>Y.</given-names></name>; <name><surname>Zheng</surname><given-names>X.</given-names></name></person-group><source>TensorFlow: Large-Scale Machine Learning
on Heterogeneous Systems</source>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="ref24">
      <mixed-citation publication-type="conf-proc" id="cit24"><person-group person-group-type="allauthors"><name><surname>McKinney</surname><given-names>W.</given-names></name></person-group> In <source>Data Structures for
Statistical Computing in Python</source>, Proceedings of the 9th Python
in Science Conference; <person-group person-group-type="editor"><name><surname>van der Walt</surname><given-names>S.</given-names></name>; <name><surname>Millman</surname><given-names>J.</given-names></name></person-group>, Eds.; <year>2010</year>; pp <fpage>56</fpage>–<lpage>61</lpage>.</mixed-citation>
    </ref>
    <ref id="ref25">
      <mixed-citation publication-type="journal" id="cit25"><name><surname>Chetnik</surname><given-names>K.</given-names></name>; <name><surname>Petrick</surname><given-names>L.</given-names></name>; <name><surname>Pandey</surname><given-names>G.</given-names></name><article-title>MetaClean:
A Machine Learning-Based
Classifier for Reduced False Positive Peak Detection in Untargeted
LC–MS Metabolomics Data</article-title>. <source>Metabolomics</source><year>2020</year>, <volume>16</volume>, <elocation-id>117</elocation-id><pub-id pub-id-type="doi">10.1007/s11306-020-01738-3</pub-id>.<pub-id pub-id-type="pmid">33085002</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <mixed-citation publication-type="journal" id="cit26"><name><surname>Grüning</surname><given-names>B.</given-names></name>; <name><surname>Dale</surname><given-names>R.</given-names></name>; <name><surname>Sjödin</surname><given-names>A.</given-names></name>; <name><surname>Chapman</surname><given-names>B. A.</given-names></name>; <name><surname>Rowe</surname><given-names>J.</given-names></name>; <name><surname>Tomkins-Tinch</surname><given-names>C. H.</given-names></name>; <name><surname>Valieris</surname><given-names>R.</given-names></name>; <name><surname>Köster</surname><given-names>J.</given-names></name><article-title>Bioconda:
Sustainable and Comprehensive Software Distribution for the Life Sciences</article-title>. <source>Nat. Methods</source><year>2018</year>, <volume>15</volume>, <fpage>475</fpage>–<lpage>476</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0046-7</pub-id>.<pub-id pub-id-type="pmid">29967506</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
