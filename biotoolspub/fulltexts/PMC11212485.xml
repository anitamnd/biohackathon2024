<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11212485</article-id>
    <article-id pub-id-type="pmid">38383048</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae101</article-id>
    <article-id pub-id-type="publisher-id">btae101</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>LAVASET: Latent Variable Stochastic Ensemble of Trees. An ensemble method for correlated datasets with spatial, spectral, and temporal dependencies</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1854-1799</contrib-id>
        <name>
          <surname>Kasapi</surname>
          <given-names>Melpomeni</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
        <xref rid="btae101-cor1" ref-type="corresp"/>
        <!--mk218@imperial.ac.uk-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Kexin</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3372-8423</contrib-id>
        <name>
          <surname>Ebbels</surname>
          <given-names>Timothy M D</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>O’Regan</surname>
          <given-names>Declan P</given-names>
        </name>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ware</surname>
          <given-names>James S</given-names>
        </name>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Royal Brompton &amp; Harefield Hospitals, Guy’s and St. Thomas’ NHS Foundation Trust</institution>, London SW3 6NP, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Program in Medical &amp; Population Genetics, Broad Institute of MIT &amp; Harvard</institution>, Cambridge, MA 02142, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4971-9003</contrib-id>
        <name>
          <surname>Posma</surname>
          <given-names>Joram M</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <xref rid="btae101-cor1" ref-type="corresp"/>
        <!--jmp111@ic.ac.uk-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae101-cor1">Corresponding authors. Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London, London W12 0NN, United Kingdom. E-mails: <email>mk218@imperial.ac.uk</email> (M.K.) and <email>jmp111@ic.ac.uk</email> (J.M.P.)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-02-21">
      <day>21</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>3</issue>
    <elocation-id>btae101</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="editorial-decision">
        <day>18</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>07</day>
        <month>3</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae101.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Random forests (RFs) can deal with a large number of variables, achieve reasonable prediction scores, and yield highly interpretable feature importance values. As such, RFs are appropriate models for feature selection and further dimension reduction. However, RFs are often not appropriate for correlated datasets due to their mode of selecting individual features for splitting. Addressing correlation relationships in high-dimensional datasets is imperative for reducing the number of variables that are assigned high importance, hence making the dimension reduction most efficient. Here, we propose the LAtent VAriable Stochastic Ensemble of Trees (LAVASET) method that derives latent variables based on the distance characteristics of each feature and aims to incorporate the correlation factor in the splitting step.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Without compromising on performance in the majority of examples, LAVASET outperforms RF by accurately determining feature importance across all correlated variables and ensuring proper distribution of importance values. LAVASET yields mostly non-inferior prediction accuracies to traditional RFs when tested in simulated and real 1D datasets, as well as more complex and high-dimensional 3D datatypes. Unlike traditional RFs, LAVASET is unaffected by single ‘important’ noisy features (false positives), as it considers the local neighbourhood. LAVASET, therefore, highlights neighbourhoods of features, reflecting real signals that collectively impact the model’s predictive ability.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>LAVASET is freely available as a standalone package from <ext-link xlink:href="https://github.com/melkasapi/LAVASET" ext-link-type="uri">https://github.com/melkasapi/LAVASET</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Biobank Resource</institution>
          </institution-wrap>
        </funding-source>
        <award-id>47602</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Wellcome Trust</institution>
            <institution-id institution-id-type="DOI">10.13039/100010269</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Health Data Research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Medical Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000265</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>British Heart Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000274</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute for Health Research</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000272</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Imperial College Biomedical Research Centre</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIHR Imperial College Biomedical Research Centre</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>British Heart Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000274</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Research and Innovation</institution>
            <institution-id institution-id-type="DOI">10.13039/100014013</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Biotechnology and Biological Sciences Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000268</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Commission</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000780</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Random forest (RF) classifiers are frequently used to analyse biological data for prediction and feature selection tasks. RFs can deal with a large number of variables, achieve reasonable prediction scores, and yield highly interpretable feature importance values (<xref rid="btae101-B3" ref-type="bibr">Breiman 2001</xref>). As such, they are appropriate models for feature selection and further dimension reduction (DR) for integrated datasets. The premise of the original RF algorithm is to assemble an ensemble of trees that complement each other and increase variability of predictor selection (<xref rid="btae101-B14" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic> 2021</xref>). However, each node and subsequent split still only consider one predictor variable, limiting both the predictive ability and correct feature importance assignment in complex biological settings that include correlated features.</p>
    <p><xref rid="btae101-B14" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic> (2021)</xref> have recently developed a new information criterion statistic to evaluate the contribution of features to the predictive ability of the model. It comprises different categories of probabilities that assess the feature’s proximity to the target class and the complexity of the relationship with the given class. In addition, permutation-based feature importance has been extensively studied in RFs. It has been demonstrated that there is some level of bias in the assignment of feature importance when there exists collinearity between features that are both associated with the target outcome (<xref rid="btae101-B15" ref-type="bibr">Nicodemus <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    <p>Few techniques have been proposed for enhancing feature importance calculations in datasets with highly correlated variables. The Boruta algorithm (<xref rid="btae101-B10" ref-type="bibr">Kursa and Rudnicki 2010</xref>) uses a ‘shadow’ feature approach where it duplicates the original dataset and shuffles the feature values, however, permuting the values it does not take into account local correlations. Boruta trains a classifier on the enhanced dataset and assigns a value of importance to each of the features, those with lower importance than their permuted counterparts are removed before repeated the process with a new random state. Boruta, in reality, combines permutation importance, by shuffling the original features, with recursive feature elimination (<xref rid="btae101-B8" ref-type="bibr">Guyon <italic toggle="yes">et al.</italic> 2002</xref>), by iteratively considering and removing features that do not reach a threshold, but its classifier still considers only individual features and the permutation procedure does not consider local correlations.</p>
    <p>These methods are efficient in removing noisy features that might not reflect real signals, especially by eliminating these through iterations. However, they are not sensitive in picking all relevant features when these are collinear. Addressing relationships between collinear features in high-dimensional datasets is imperative for reducing the number of features that are assigned high importance and thereby making the DR more efficient. Here, we propose a novel method termed LAtent VAriable Stochastic Ensemble of Trees (LAVASET) that derives latent variables based on the distance characteristics of each feature and thereby incorporates the correlation factor in the splitting step. Hence, it inherently groups correlated features and ensures similar importance assignment for these. Distance characteristics for the features can include the feature’s adjacent points in a 1D spectrum, adjacent features of time-series data, or spatial distance in 3D structures among other examples. In this context, LAVASET addresses a major limitation in the interpretation of feature importance of RFs when the data are collinear, such as is the case for spectroscopic and imaging data.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>We demonstrate the LAVASET algorithm (detailed below) on four different datasets with feature importances calculated as a result of a prediction/classification problem between disease and healthy control (HC) groups or simulated groups.</p>
      <sec>
        <title>2.1.1 Irritable bowel syndrome—faecal metabolomics (1D)</title>
        <p>The Maastricht University Irritable Bowel Syndrome (MIBS) cohort includes human faecal water samples analysed with <sup>1</sup>H Nuclear Magnetic Resonance (NMR) spectroscopy for 267 participants (146 IBS patients; 121 HCs). Details on demographics, sample collection, and data acquisition can be found in <xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> (2022)</xref>. Unlike the original publication, we used the full NMR spectrum (digitized to a total of 18 600 features) following the removal of the internal standard and the water region, and baseline correction.</p>
        <p>To test LAVASET’s ability in capturing relevant features, we also created simulated groups from the MIBS cohort dataset. The groups were generated by using two (uncorrelated) compounds that each have two multiplets, with signals spread out across the length of the spectrum. The compounds used are metabolites ethanol, with peaks at 1.17–1.20 and 3.64–3.68 ppm, and uracil with peaks at 5.79–5.81 and 7.53–7.56 ppm.</p>
      </sec>
      <sec>
        <title>2.1.2 Diabetes—urinary metabolomics (1D)</title>
        <p>Human urinary metabolomics data from individuals with type-2 diabetes mellitus (T2DM), freely available from Metabolights (MTBLS1), were used as an additional test cohort. Prior work on this dataset has shown higher classification accuracy compared to IBS data. A total of 84 samples were collected, consisting of 12 healthy volunteers with data at seven time points, and 30 individuals with T2DM with data collected at 1–3 time points (total of 50 spectra). These were analysed by <sup>1</sup>H-NMR spectroscopy to evaluate the urine profiles between T2DM and HCs. Metabolite identification was performed by PLS-DA models previously, as described by the authors in <xref rid="btae101-B17" ref-type="bibr">Salek <italic toggle="yes">et al.</italic> (2007)</xref>. The raw data were downloaded from MTBLS1 and processed to standardize each spectrum to 18 000 data points. The water and internal standard regions were removed from the spectrum with the remaining points used for the modelling.</p>
      </sec>
      <sec>
        <title>2.1.3 Acute myocardial infarction—electrocardiogram (1D)</title>
        <p>Electrocardiogram (ECG) data from the Physikalisch-Technische Bundesanstalt (PTB) dataset (<xref rid="btae101-B2" ref-type="bibr">Bousseljot <italic toggle="yes">et al.</italic> 2009</xref>) were downloaded from PhysioNet (<xref rid="btae101-B7" ref-type="bibr">Goldberger <italic toggle="yes">et al.</italic> 2000</xref>). We extracted ECG data from individuals with acute myocardial infarction (MI) and compared this against no acute MI. We excluded all data without a reason for admission or with an unknown diagnosis. This resulted in 175 control and 346 acute MI ECGs. The individual ECGs were processed to correct signal drifts. An average cardiac cycle was extracted for each individual that was normalized to 750 data points (0.75 s). We used the three Frank leads [vector cardiogram (VCG)] as input to the algorithm and visualize the feature importance in the conventional 12-leads by making use of the (absolute) Kors regression transformation (<xref rid="btae101-B9" ref-type="bibr">Kors <italic toggle="yes">et al.</italic> 1990</xref>) for the eight independent leads.</p>
      </sec>
      <sec>
        <title>2.1.4 Hypertrophic cardiomyopathy—CMR imaging (3D)</title>
        <p>To test LAVASET’s performance on high dimensional, spatial, 3D datasets, we used data meshes derived from cardiac magnetic resonance (CMR) imaging of the human left ventricle. Segmentation of these images (to produce the meshes) was performed using a deep-learning framework developed by collaborators (<xref rid="btae101-B1" ref-type="bibr">Bai <italic toggle="yes">et al.</italic> 2018</xref>). Measurements of myocardial wall thickness were calculated along radial segments that connected the inner endocardial and outer epicardial surfaces (<xref rid="btae101-B6" ref-type="bibr">Duan <italic toggle="yes">et al.</italic> 2019</xref>). This process produced a 46 808 <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mo>×</mml:mo></mml:math></inline-formula> 4 matrix, where for each of the 46 808 points there is a value for the <italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates of the ventricle, and the wall thickness at that point. These segmentations were performed on images in the UK Biobank dataset (<xref rid="btae101-B18" ref-type="bibr">Sudlow <italic toggle="yes">et al.</italic> 2015</xref>) and an in-house Hypertrophic Cardiomyopathy (HCM) cohort [Royal Brompton Hospital Cardiovascular Biobank (<xref rid="btae101-B5" ref-type="bibr">Curran <italic toggle="yes">et al.</italic> 2023</xref>)]. The total number of samples used here was 1273, consisting of 634 HCM patients and 639 demographically-matched HCs.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Approach</title>
      <p>LAVASET operates given a number of prerequisites and hyperparameters that can be optimized (<xref rid="btae101-F1" ref-type="fig">Fig. 1</xref>). A user-specified distance matrix is calculated to select the <italic toggle="yes">k</italic> closest feature points to the feature of interest (FOI), which form the FOI neighbourhood. This FOI neighbourhood sub-matrix is defined as <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">FOIn</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>:</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">M</italic> denotes the matrix containing all the input features and the set <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> represents the indices of the <italic toggle="yes">k</italic> features in <italic toggle="yes">M</italic> that are closest to FOI (based on the user-specified distance matrix), including the index for FOI itself. The user specifies the maximum number of features to consider for each split (with default the square root of the total number of features), and these are randomly selected from the entire dataset in each step. For each selected FOI, the first left singular vector (PC1) of the respective FOI neighbourhood is calculated. We calculate this via Singular Value Decomposition of the sub-matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">FOIn</mml:mi><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mo>Σ</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, FOIn is the scaled FOI neighbourhood for the selected VOI, <italic toggle="yes">U</italic> is the matrix of left singular vectors, <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mo>Σ</mml:mo></mml:math></inline-formula> is a diagonal matrix containing singular values, and <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (or <italic toggle="yes">V</italic> transposed) is the matrix of right singular vectors. The PC1 or first left singular vector is the first vector in matrix <italic toggle="yes">U</italic>, and this is now the latent variable for the FOIn. Loadings for each latent variable are calculated as <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>⋅</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="italic">FOIn</mml:mi></mml:mrow></mml:math></inline-formula>, where the first left singular vector <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is multiplied by the original FOIn sub-matrix. The input matrix for determining the best split will now consist of the latent variable values instead of the original feature values. The best-split variable and value are evaluated by the traditional Gini index method by deducting the sum of the squared probabilities of each class from one. Once the split occurs, the Gini gain is calculated for the selected latent variable and node by subtracting the sum of the Gini index weights of the two child nodes from the parent node. This is repeated recursively until all samples are split into pure leaf nodes, similar to the classic CART algorithm (<xref rid="btae101-B4" ref-type="bibr">Breiman <italic toggle="yes">et al.</italic> 1984</xref>).</p>
      <fig position="float" id="btae101-F1">
        <label>Figure 1.</label>
        <caption>
          <p>LAVASET high-level pipeline indicating the different and novel approach in the node splitting step and feature importance calculation. Model input is customizable and LAVASET can perform on different types of omics data, from 1D to 3D.</p>
        </caption>
        <graphic xlink:href="btae101f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.3 Feature importance calculation</title>
      <p>Feature importance scores are calculated for each feature by weighing its contribution to the PC score (left singular vector). Specifically, for every selected feature where the PC score is calculated, the loadings vector <italic toggle="yes">L</italic> of the score (with a shape equalling the number of neighbours considered) is calculated and multiplied by the Gini gain value assigned to the selected latent variable. This results in a feature importance score not only for the FOI but also for its neighbours.</p>
      <p>The LAVASET algorithm is designed to allow for multiple variations in the calculation of a feature’s importance after model construction. LAVASET outputs for each feature<inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo> </mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> a vector of values consisting of three parts. <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluate</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the summation over all trees from 1 to <italic toggle="yes">T</italic> of the count of times a feature is evaluated in each tree and, similarly, <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lecte</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represent the total counts of times a feature is selected for a split and the accumulated Gini values in each tree, respectively. All features of the original matrix <italic toggle="yes">M</italic> are equally ‘evaluated’ for a split with a frequency that follows a Gaussian distribution. The subset of features ‘selected’ for splitting a node are those assigned a feature importance.</p>
      <p>From the feature importance values, we can calculate a normalized Gini feature importance by dividing by the sum of all importances. We also evaluate the ratio of the number of times a feature is selected over the count of times it is considered for a split, and incorporate this in our feature importance final value. Using the same output, another use case would be to compare the ratio of Gini values over the count of times a feature is selected for split, which can give an idea of the value magnitude assigned to a feature at a given split. Results presented in this article utilise the normalised feature importance multiplied by the ratio of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lecte</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> over the <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluate</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for each feature. This is shown below, where importance(<italic toggle="yes">i</italic>) is the importance of the feature <italic toggle="yes">i</italic>, T is the total number of trees, importance(<italic toggle="yes">i</italic>, t) represents the Gini importance of the feature <italic toggle="yes">i</italic> in the tree <italic toggle="yes">t</italic>, and <italic toggle="yes">F</italic> is the total number of features. The sum in the numerator of the first fraction goes over all the trees from 1 to <italic toggle="yes">T</italic> for the feature <italic toggle="yes">i</italic>. The sum in the denominator of the first fraction goes over all the trees and all the features (<italic toggle="yes">f</italic> represents each feature in the feature set), which normalizes the Gini of the feature <italic toggle="yes">i</italic>. The ratio of the sums in the second fraction measures the frequency with which feature <italic toggle="yes">i</italic> was selected when it was evaluated: <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">importance</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>F</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lected</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluated</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p>
    </sec>
    <sec>
      <title>2.4 Model evaluation</title>
      <p>Standard metrics (accuracy, precision, recall, and <italic toggle="yes">F</italic>1-score) are used to compare the classification performance of RFs and LAVASET. For both the simulated and MIBS cohort inputs, LAVASET and RF were run 20 distinct times (20 run pairs with 100 and 1000 trees, respectively). Identical random state seeds were assigned per run pair for the sample bootstrapping, to account for the randomness between the comparisons. The data were split into training and test sets (80% and 20%, respectively), with the sets always being kept identical across the runs. Mean accuracy, precision, recall, and <italic toggle="yes">F</italic>1-scores are reported for the 20 runs.</p>
      <p>We performed a grid search optimizing the number of trees and neighbours for the MIBS cohort. Tree values ranged from 100 to 10 000 and neighbours from 1 to 50, and all possible combinations were evaluated. The optimal value for the number of trees for LAVASET was 1000, this model is referred to as LAVASET-1K. We compare LAVASET-1K to two RF models: the first is an RF with the same number of 1000 trees, referred to RF-1K hereafter, and the second is an RF that runs for the same amount of computational time as LAVASET. We evaluated the number of RF trees that can be fit in the same amount of time as LAVASET-1K required. LAVASET-1K fits 1000 trees for 18 neighbours (optimal for MIBS cohort) in ∼11 min [on an HP Z6 G4 workstation with 16-core Intel(R) Xeon(R) Silver 4110 CPU @ 2.10 GHz with 128 GB RAM], a classic RF can include ∼41 000 trees in the same amount of time (referred to as the RF-41K model).</p>
      <p>Precision and recall scores are also calculated as metrics for evaluating the peak coverage of the feature importance performance. In the simulated dataset, the peak points used to create the two distinct groups are assigned as the ground truth (positive designation) for the peak coverage. To evaluate the specificity of LAVASET, we include points outside the peak (equal to <italic toggle="yes">k</italic> neighbours assigned) in the calculations of precision and recall. These serve as the true negative designations. The threshold for positive or negative designation in these calculations is whether the point has been assigned a feature importance value (<inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>0) or not important zero.</p>
      <p>The neighbours for the VCG data were calculated on the basis of the time of the cardiac cycle. That is, selecting Frank’s lead <italic toggle="yes">x</italic> for variable (time) <italic toggle="yes">i</italic> also includes the other two leads (<italic toggle="yes">y</italic>, <italic toggle="yes">z</italic>) at time <italic toggle="yes">i</italic>. Including more neighbours takes place in steps of six (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> for both <italic toggle="yes">i</italic> <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 1). Where the first and last time points are also considered neighbours at <italic toggle="yes">i</italic> <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 1.</p>
      <p>Finally, we assessed LAVASET’s performance on feature extraction for DR of the 3D CMR dataset. Due to computational constraints, the 3D dataset was tested on 100 and 200 neighbours and 150K trees. Neighbours were decided by the spatial distance (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates) in an iterative manner by considering the 100 closest points that remain neighbours for over half of the 1273 samples. The most important features (above the 50% importance value threshold) were selected for LAVASET and RF models (both 150K trees). For each set, we performed further DR and clustering to evaluate how the clusters separated HCM and HC samples. Uniform manifold approximation and projection (UMAP) and <italic toggle="yes">k</italic>-means clustering with <italic toggle="yes">k</italic> = 2 (expected number of groups) were used in both cases (<xref rid="btae101-B12" ref-type="bibr">McInnes <italic toggle="yes">et al.</italic> 2018</xref>). UMAP components and <italic toggle="yes">k</italic>-means transformations were evaluated for 20 different random state restarts to ensure robustness. Each restart produced two clusters that were scored by the standard metrics, to determine how closely they matched the true sample labels.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulated NMR dataset</title>
      <p>LAVASET yields a non-inferior prediction accuracy compared with traditional RFs when predicting the two simulated groups in the NMR dataset (accuracy: 0.859<inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.027 LAVASET, 0.823<inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.021 RF, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>, both the Boruta and RF methods [Panels (B), (C), (E), and (F)] fail to identify all individual features relating to the same peak(s) and instead only identify a subset of these. In contrast, LAVASET not only does identify correctly the simulated metabolites, but also assigns appropriate importance values to all or most of the correlated points that encompass a peak. Specifically, for ethanol’s CH<sub>2</sub> peak shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2A</xref>, <italic toggle="yes">F</italic>1-scores for LAVASET are 96% and 85% for the CH<sub>3</sub> peak. For uracil, the second multi-peak metabolite used to create the simulated dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2D</xref>), LAVASET has <italic toggle="yes">F</italic>1-scores at 96% and 89% in the two doublets. In all the metabolite peaks considered here, Boruta and RF underperform in capturing all the points that comprise the peaks (Boruta <italic toggle="yes">F</italic>1-scores: 23%, 52%, 47%, and 60% for each peak, respectively; RF: 31%, 53%, 49%, and 63%).</p>
    </sec>
    <sec>
      <title>3.2 MIBS cohort</title>
      <p>After a grid search evaluation to identify the optimal parameters for the number of neighbours and trees, the highest scoring accuracy was achieved by 1000 trees and 18 neighbours (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). Average accuracy values overall dropped after considering more than 20 neighbours and there were no significant differences when taking more than 1000 trees for the specific dataset. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4A</xref> presents the optimal number of neighbours for the 1000 trees with a clear peak being displayed on the graph, while the drop after 20 neighbours is also evident there. LAVASET yields similar results when classifying IBS versus HC in the MIBS cohort (only for this cohort, losing 1% in mean accuracy in comparison to RF). Across 20 runs the average accuracy score for LAVASET is 0.68<inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02, for RF-1K 0.69<inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, and for RF-41K 0.68<inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4B</xref> boxplots represent these accuracy values, along with precision, recall, and <italic toggle="yes">F</italic>1 score values. The value ranges shown for the RF-41K model suggest that when running 41 000 trees there is potential for over-fitting, given that the values across each of the 20 runs are almost identical. For the four different performance metrics, the error bars of LAVASET versus RF-1K and LAVASET versus RF-41K overlap, indicating LAVASET is non-inferior to either RF model (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4B</xref>).</p>
      <p>The most pronounced differences between LAVASET and RF are evident when looking at feature importances. LAVASET’s ability to capture the entirety of peaks attributed to a metabolite surpasses the RF feature evaluation which merely captures less than half the points that encompass the peak. <xref rid="btae101-F2" ref-type="fig">Figure 2</xref> shows the relevant peaks of previously identified metabolites valine (A, B, and C) and 2-methylproline (D, E, and F). These two metabolites have been previously associated with separating IBS from HC patients, by showing high feature importance in classification models using Support Vector Classifiers (<xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> 2022</xref>). Panels (A) and (D) show clearly how LAVASET is able to assign importance values to all points of the valine and 2-methylproline peaks, respectively. The dashed grey lines indicate the previously identified point ranges for the specific metabolites peaks, which present a ground truth for the peak, but can sometimes be affected by small shifts or missing points on the sides of a given peak. In the case of 2-methylproline, we notice that LAVASET is also capturing and assigning relatively high importance on points to the left side of the peak. These points, however, when visualized on the spectrum appear to be part of the rest of the peak and LAVASET only assigns an importance to the points up to where the next peak is starting, without including that next non-related peak. This can also be seen on the right-side of valine in <xref rid="btae101-F2" ref-type="fig">Fig. 2A</xref>, where it shows a gradual decline in importance as we are reaching the end of the visualized peak.</p>
      <fig position="float" id="btae101-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Comparison of LAVASET-1K to RF-1K and RF-41K feature importance assignments on pre-identified metabolites. Panels (A)–(C) show feature importances [as defined in Section 2] for valine, and panels (D)–(F) for 2-methylproline. Colourbar on the right indicates the feature importance value range (red = higher, blue = lower). Dashed grey lines indicate the previously identified points for the specific metabolites peaks. <italic toggle="yes">X</italic>-axis indicates the chemical shift (in parts per million, <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mo>δ</mml:mo></mml:math></inline-formula>). <italic toggle="yes">Y</italic>-axis shows the average signal intensity.</p>
        </caption>
        <graphic xlink:href="btae101f2" position="float"/>
      </fig>
      <p>RF, on the other hand, assigns feature importance to sporadic points of the peak, with no real continuance as to the values of importance (valine, <xref rid="btae101-F2" ref-type="fig">Fig. 2B</xref>, red point indicating high importance next to light blue point indicating more than half of an importance value). Even in the case of the 41K trees, we see that the points selected remain almost the same as in the 1K trees, suggesting that an RF cannot reach LAVASET’s ability in capturing whole peaks, even if the number of trees increases 41-fold. Overall, LAVASET’s output is quite stable and not affected significantly by small changes in the number of neighbours. Peak coverage is equivalent when looking at 10–16 neighbours, with the main differences occurring in the value of importance to each point (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>).</p>
    </sec>
    <sec>
      <title>3.3 MTBLS1 cohort</title>
      <p>LAVASET was further tested on the MTBLS1 T2DM cohort, as described in Section 2, to ensure that performance stability and feature importance interpretation remain effective in other cohorts. Consistent with previous examples, LAVASET presents non-inferior results to RF (LAVASET accuracy: 0.82<inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, RF accuracy: 0.77<inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>) and manages to capture the metabolites pre-identified by <xref rid="btae101-B17" ref-type="bibr">Salek <italic toggle="yes">et al.</italic> (2007)</xref>. Metabolite peak capturing by LAVASET is again superior to RF, by encompassing if not all, most points and attributing feature importance values more equally. Results are expanded in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>.</p>
    </sec>
    <sec>
      <title>3.4 ECG data</title>
      <p>We assessed LAVASET’s capabilities on more complex data types where it is common practice to use transformations of the raw reading data to infer further information. We transformed ECG readings to VCG inputs. For this task, we used ECG data from the PTB dataset (<xref rid="btae101-B2" ref-type="bibr">Bousseljot <italic toggle="yes">et al.</italic> 2009</xref>), as described in Section 2. LAVASET-1K performed similarly to the RF-1K in this dataset, with accuracy values showing identical results across 20 runs (0.81<inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>) and other metrics having only small differences (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>). <xref rid="btae101-F3" ref-type="fig">Figure 3</xref> shows the results when taking 20 nearest neighbours (across the time axis as described in Section 2) and 1000 trees. LAVASET is able to capture peaks and anomalies across the ECGs that indicate differences between the HC and MI cases. Given the nature of the dataset and the idiosyncrasies of different MI cases based on the location of the infraction, setting a binary classification by incorporating all types of MI as one target will only capture important features related to all these different MI phenotypes.</p>
      <fig position="float" id="btae101-F3">
        <label>Figure 3.</label>
        <caption>
          <p>ECG feature importance (Kors regression back-transformed from VCG feature importance) normalized across the eight independent ECG leads. Subplot titles indicate the respective leads. <italic toggle="yes">X</italic>-axes show time in milliseconds and <italic toggle="yes">y</italic>-axes voltage magnitude in millivolts. The dotted black line indicates a healthy sample and the solid lines represent the 10 MI types (acute, anterior, anteriolateral, anteroseptolateral, anteroseptal, inferior, inferolateral, inferoposterolateral, lateral, and posterior) in this dataset and are coloured by relative feature importance.</p>
        </caption>
        <graphic xlink:href="btae101f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 CMR imaging</title>
      <p>Both the LAVASET and RF models demonstrate equivalent values across all metrics. LAVASET shows an accuracy of 0.878, precision of 0.837, recall of 0.904, and <italic toggle="yes">F</italic>1-score of 0.869. RF shows an accuracy of 0.875, precision of 0.916, recall of 0.851, and <italic toggle="yes">F</italic>1-score of 0.882. Given these high values, we are confident about the use of both models for feature extraction, as means to DR. <xref rid="btae101-F4" ref-type="fig">Figure 4</xref> shows the results on 100 neighbours and 150 000 trees. LAVASET is able to assign importance values to a larger surface area of the left ventricle, while also demonstrating the most important areas. RF, on the other hand, picks patches of the left ventricle as most important, disregarding other anatomical parts that could be important. To test how informative these selected features are, we used them as input in further DR and clustering via UMAP and <italic toggle="yes">k</italic>-means. <xref rid="btae101-T1" ref-type="table">Table 1</xref> shows the clustering performance across 20 iterations of UMAP and <italic toggle="yes">k</italic>-means, indicating that the features selected by LAVASET perform constantly better than those selected by RF. We also highlight that in this specific dataset, feature extraction improves the models considerably, given the significantly lower performance observed when taking all features as input.</p>
      <fig position="float" id="btae101-F4">
        <label>Figure 4.</label>
        <caption>
          <p>The 3D representations of the left ventricle CMR data points (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates). Points represent an averaged template of HCM and HC ventricles. The inner and outer structures formed show the endocardium and epicardium, respectively. Colourbar shows the feature importance gradient, indicating that in panel (A) (LAVASET) the assignment of higher importance is encompassing the entirety of the ventricle structure. In panel (B), assignments are given in a patch-like manner for RF. Panels (C) and (D) show the points in the 80% quantile from a top view to facilitate the distinction between the inner and outer walls of the ventricle. Panels (E) and (F) show six distinct neighbourhoods of FOIs. In panel (D), convex hulls are drawn for each neighbourhood to represent the pattern of points per neighbourhood. Black points indicate the neighbours and the coloured connecting lines emphasize the different neighbourhoods, and the string-like pattern of neighbour points. Panel (C) shows the feature importance for the respective six neighbourhoods.</p>
        </caption>
        <graphic xlink:href="btae101f4" position="float"/>
      </fig>
      <table-wrap position="float" id="btae101-T1">
        <label>Table 1.</label>
        <caption>
          <p>HCM CMR dataset, feature DR performance.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">LAVASET features</th>
              <th rowspan="1" colspan="1">RF features</th>
              <th rowspan="1" colspan="1">All features</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Accuracy</td>
              <td rowspan="1" colspan="1"><bold>0.890</bold><inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01</td>
              <td rowspan="1" colspan="1">0.870<inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.002</td>
              <td rowspan="1" colspan="1">0.797<inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.905<inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.005</td>
              <td rowspan="1" colspan="1"><bold>0.913</bold><inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
              <td rowspan="1" colspan="1">0.817<inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.006</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1"><bold>0.859</bold><inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.009</td>
              <td rowspan="1" colspan="1">0.816<inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 0.003</td>
              <td rowspan="1" colspan="1">0.763<inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.011</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"><italic toggle="yes">F</italic>1-score</td>
              <td rowspan="1" colspan="1"><bold>0.881</bold><inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
              <td rowspan="1" colspan="1">0.862<inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.002</td>
              <td rowspan="1" colspan="1">0.789<inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.005</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>Scores for accuracy, precision, recall, and <italic toggle="yes">F</italic>1-score across 20 iterations of UMAP and <italic toggle="yes">k</italic>-means (<italic toggle="yes">k</italic> = 2) on the selected feature sets by importance in LAVASET, RF, and without selection. Values shown are the mean<inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>standard deviation. Values in bold indicate the highest performances for each metric. </p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>We have presented a novel ensemble learning method aimed at datasets with spatial, spectral or temporally dependent relationships between features that enhances variable importance and ensures that correlated features are evaluated appropriately and not independently. LAVASET produces non-inferior performance results to traditional RFs in all but one of the examples tested above, and in both simulated and real datasets. While not sacrificing performance in most examples, it is able to assign feature importances in a superior way, by not missing features that are as ‘important’ by means of correlation, and ensuring that importance values are correctly distributed. One of the advantages of RFs in comparison to other classification methods is its ability to assign feature importances to the original features; here, LAVASET retains this advantage by directly assigning importances to the original feature sets, using the loadings derived from singular vector decomposition to guide the relative importances. In contrast, we have shown that RF allocates feature importance to isolated points, whether that is peak points in a spectrum or points on a 3D mesh, without any clear consistency of the magnitude of importance. Even when substantially increasing the number of trees in RF, the selection of points and assignment of importance are nearly identical to those selected with the lower number of trees, and still do not capture the points selected by LAVASET. In this scenario, Boruta (<xref rid="btae101-B10" ref-type="bibr">Kursa and Rudnicki 2010</xref>) shows results similar to RFs and LAVASET demonstrates improved feature recovery. Other decision forest methods, such as GrandForest (<xref rid="btae101-B11" ref-type="bibr">Larsen <italic toggle="yes">et al.</italic> 2020</xref>) and DFNet (<xref rid="btae101-B16" ref-type="bibr">Pfeifer <italic toggle="yes">et al.</italic> 2022</xref>), that use a graph-structure as input for creating each tree still consider only single features at each split. LAVASET combines correlated features in the splitting step and uses the distance matrix to select the groups of features. When specifying subgraphs for datasets with spatially coherent features, the trees of GrandForest and DFNet will get stuck in local neighbourhoods (both with connected subgraphs and random walks). These methods work better with sparser graphs, hence splitting data further using related features do not add much predictive ability as these features are correlated and the residual of the initial split will not contain much information that can be explained by features correlated to the initial one.</p>
    <p>The motivation behind developing LAVASET stems from the idea of enhancing traditional RFs, in a manner similar to how Group Lasso enhances the Lasso algorithm. In the main premise of Group Lasso, we also assume that there are groups of features that are expected to have similar effects or are related to each other. By penalizing the sum of the absolute values (L1 norm) of the coefficients within each group, Group Lasso encourages the model to select entire groups of features together or exclude them altogether (<xref rid="btae101-B20" ref-type="bibr">Yuan and Lin 2005</xref>). Like in Group Lasso, LAVASET is particularly useful when dealing with high-dimensional data where groups of features exhibit similar importance or are structured in some meaningful way. This was evident by the variety of datasets we tested, where the number of features ranged from 750 to 46K. In this high-dimensional context, LAVASET exhibits stability in its output and remains relatively unaffected by minor variations in the number of neighbours comprising the groups. However, Group Lasso requires non-overlapped groups of features, whereas in LAVASET this can be varied. In fact, in LAVASET, different FOIs can have different numbers of neighbours to increase flexibility. Likewise, LAVASET emulates the kernel filter in convolutional neural networks (CNNs) in that it combines multiple features into a single output (for splitting in LAVASET), however, it does so without condensing the output and attributing the feature importance across the initial features. Other work has investigated the relations between individual features in terms of the similarity of performance at different splits. This methodology is able to discern correlations between individual features, however the mutual forest impact is constrained to evaluating pairs of features only (<xref rid="btae101-B19" ref-type="bibr">Voges <italic toggle="yes">et al.</italic> 2023</xref>). LAVASET can, in theory, be combined with this to perform <italic toggle="yes">a posteriori</italic> analysis of evaluating correlations between groups of latent variables.</p>
    <p>LAVASET’s main limitation derives from the requirement of defining the aforementioned ‘groups’ (akin to the kernel size in CNNs). This parameter is user-specified and assumes an understanding of the relationship between the variables. In the examples presented here, this relationship is defined and assigned by distance, whether that is 1D distance across a spectrum, 1D across time-series data, or 3D spatial distance. The influence of neighbourhood definition is evident, especially in the 3D CMR example. <xref rid="btae101-F4" ref-type="fig">Figure 4F</xref> shows that the string-like pattern of importances calculated by LAVASET is predominantly driven by the assignment of neighbours for each FOI. This inherent limitation, however, is what enables LAVASET’s flexibility in creating the groups of neighbours. Distance is only one of the metrics that can be employed. Other examples include genomic distance (combine SNPs via linkage disequilibrium), mass spectrometry isotope patterns (proteomics and metabolomics), or hierarchical relationships (i.e. taxonomy of microbiota). This renders LAVASET more versatile than other similar methods, while giving the user the ability to tailor the algorithm to their specific needs. Hence, it is applicable to a wide variety of datasets and biological questions.</p>
    <p>This flexibility is also translated to LAVASET’s code implementation. The algorithm also exploits parallelization in order to speed up computations. The body of the code is written in Python 3.10, while utilizing established C++ scripts for efficiency. Given the nature of the code and algorithm, LAVASET can be run in batches, if needed, or can be easily altered to incorporate additional metrics to distance. Moreover, while beyond the scope of this work, there is potential to explore new hybrid methods; e.g. LAVASETs output and the important features can be used to define new regions of latent features which can then be evaluated in terms of their relations with other regions as part of a graph (and used as input to GrandForest and/or DFNet), and also to consider permuted latent features at each split for simultaneous feature selection (as with Boruta). We have not performed hyperparameter optimization in this work (except for determining the optimal number of neighbours) to allow comparing the different methods like-for-like, however, we envision that in future the number of neighbours in LAVASET is considered in a hyperparameter optimization setting alongside the max depth, number of trees, and others.</p>
    <p>To enhance and expand LAVASET’s capabilities, we are working on incorporating the gradient boosting algorithm as one of our built-in additional components. This will extend LAVASET’s core methodology to other ensemble methods and benefit from iterative learning and the specific advantages of boosting trees.</p>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>We have presented LAVASET, a novel ensemble method capable to improve feature interpretability by selecting relevant groups of features instead of individual features. Its novel functionality is most useful in datasets with correlations between features. In cases where this is missing from the data, then traditional RFs are more appropriate. LAVASET offers interoperability to the user both by the structure of its code and via the neighbour’s parameter. It can be applied to almost all omics data types to identify all relevant known or unknown important features and effectively perform feature extraction for DR.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btae101_Supplementary_Data</label>
      <media xlink:href="btae101_supplementary_data.pdf"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank <xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> (2022)</xref> for providing the raw MIBS cohort NMR data, the DPO’R group for supplying the CMR images, and Sanjay Prasad for the RBH CMR data.</p>
  </ack>
  <sec>
    <title>Author contributions</title>
    <p>Conceptualization: J.M.P. and M.K. Methodology: J.M.P., M.K., and K.X. Investigation: M.K., J.M.P., and K.X. Visualization: M.K. and J.M.P. Writing—original draft: M.K. and J.M.P. Writing—editing: M.K., J.M.P., T.M.D.E., K.X., J.S.W., and D.P.O’R. Supervision: J.M.P., T.M.D.E., and J.S.W.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the UK Biobank Resource [application numbers 47602 to J.S.W., 40616 to D.P.O’R., 18545 to D.P.O’R.]. M.K. is supported by a Wellcome Trust PhD Studentship in Basic Science [220119/Z/20/Z]; J.M.P. is supported by Health Data Research (HDR) UK and the Medical Research Council via a Rutherford Fund Fellowship [MR/S004033/1]; J.S.W. is supported by Medical Research Council (UK), British Heart Foundation [RE/18/4/34215], and the National Institute for Health Research (NIHR) Imperial College Biomedical Research Centre; D.P.O’R. is supported by the Medical Research Council [MC_UP_1605/13], NIHR Imperial College Biomedical Research Centre, and the British Heart Foundation [RG/19/6/34387, RE/18/4/34215]; and T.M.D.E. is supported by UK Research and Innovation (UKRI) Biotechnology and Biological Sciences Research Council (BBSRC) [grants BT/T007974/1, BB/W002345/1] and European Commission (EC) grants [100173062, 101079370]. The views expressed in this work are those of authors and not necessarily those of funders. For the purpose of Open Access, the authors applied a Creative Commons attribution (CC BY) licence to any author accepted manuscript version arising. The data underlying this article are either available in the article and in its online supplementary material or can be shared on request to the corresponding author with permission of the corresponding party.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae101-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bai</surname><given-names>W</given-names></string-name>, <string-name><surname>Sinclair</surname><given-names>M</given-names></string-name>, <string-name><surname>Tarroni</surname><given-names>G</given-names></string-name></person-group><etal>et al</etal><article-title>Automated cardiovascular magnetic resonance image analysis with fully convolutional networks</article-title>. <source>J Cardiovasc Magn Reson</source><year>2018</year>;<volume>20</volume>:<fpage>65</fpage>.<pub-id pub-id-type="pmid">30217194</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bousseljot</surname><given-names>R</given-names></string-name>, <string-name><surname>Kreiseler</surname><given-names>D</given-names></string-name>, <string-name><surname>Schnabel</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Nutzung der EKG-signaldatenbank CARDIODAT der PTB über das internet</article-title>. <source>BMT</source><year>2009</year>;<volume>40</volume>:<fpage>317</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L.</given-names></string-name></person-group><article-title>Random forests</article-title>. <source>Mach Learn</source><year>2001</year>;<volume>45</volume>:<fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L</given-names></string-name>, <string-name><surname>Friedman</surname><given-names>J</given-names></string-name>, <string-name><surname>Olshen</surname><given-names>RA</given-names></string-name></person-group><etal>et al</etal><source>Classification and Regression Trees</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Chapman &amp; Hall</publisher-name>, <year>1984</year>, <fpage>358</fpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Curran</surname><given-names>L</given-names></string-name>, <string-name><surname>de Marvao</surname><given-names>A</given-names></string-name>, <string-name><surname>Inglese</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal> Genotype-phenotype taxonomy of hypertrophic cardiomyopathy. <italic toggle="yes">Circulation: Genomic and Precision Medicine</italic>, <year>2023</year>.</mixed-citation>
    </ref>
    <ref id="btae101-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duan</surname><given-names>J</given-names></string-name>, <string-name><surname>Bello</surname><given-names>G</given-names></string-name>, <string-name><surname>Schlemper</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Automatic 3D bi-ventricular segmentation of cardiac images by a shape-refined multi- task deep learning approach</article-title>. <source>IEEE Trans Med Imaging</source><year>2019</year>;<volume>38</volume>:<fpage>2151</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">30676949</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldberger</surname><given-names>AL</given-names></string-name>, <string-name><surname>Amaral</surname><given-names>LA</given-names></string-name>, <string-name><surname>Glass</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>PhysioBank, PhysioToolkit, and PhysioNet</article-title>. <source>Circulation</source><year>2000</year>;<volume>101</volume>:<fpage>E215</fpage>–<lpage>20</lpage>.<pub-id pub-id-type="pmid">10851218</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guyon</surname><given-names>I</given-names></string-name>, <string-name><surname>Weston</surname><given-names>J</given-names></string-name>, <string-name><surname>Barnhill</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Gene selection for cancer classification using support vector machines</article-title>. <source>Mach Learn</source><year>2002</year>;<volume>46</volume>:<fpage>389</fpage>–<lpage>422</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kors</surname><given-names>JA</given-names></string-name>, <string-name><surname>van Herpen</surname><given-names>G</given-names></string-name>, <string-name><surname>Sittig</surname><given-names>AC</given-names></string-name></person-group><etal>et al</etal><article-title>Reconstruction of the frank vectorcardiogram from standard electrocardiographic leads: diagnostic comparison of different methods</article-title>. <source>Eur Heart J</source><year>1990</year>;<volume>11</volume>:<fpage>1083</fpage>–<lpage>92</lpage>.<pub-id pub-id-type="pmid">2292255</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kursa</surname><given-names>MB</given-names></string-name>, <string-name><surname>Rudnicki</surname><given-names>WR.</given-names></string-name></person-group><article-title>Feature selection with the Boruta package</article-title>. <source>J Stat Soft</source><year>2010</year>;<volume>36</volume>:<fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Larsen</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Schmidt</surname><given-names>HH</given-names></string-name>, <string-name><surname>Baumbach</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>De novo and supervised endophenotyping using network-guided ensemble learning</article-title>. <source>Syst Med</source><year>2020</year>;<volume>3</volume>:<fpage>8</fpage>–<lpage>21</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McInnes</surname><given-names>L</given-names></string-name>, <string-name><surname>Healy</surname><given-names>J</given-names></string-name>, <string-name><surname>Saul</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>UMAP: uniform manifold approximation and projection</article-title>. <source>JOSS</source><year>2018</year>;<volume>3</volume>:<fpage>861</fpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mujagic</surname><given-names>Z</given-names></string-name>, <string-name><surname>Kasapi</surname><given-names>M</given-names></string-name>, <string-name><surname>Jonkers</surname><given-names>DM</given-names></string-name></person-group><etal>et al</etal><article-title>Integrated fecal microbiome–metabolome signatures reflect stress and serotonin metabolism in irritable bowel syndrome</article-title>. <source>Gut Microbes</source><year>2022</year>;<volume>14</volume>:<fpage>2063016</fpage>.<pub-id pub-id-type="pmid">35446234</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname><given-names>J-M</given-names></string-name>, <string-name><surname>Jézéquel</surname><given-names>P</given-names></string-name>, <string-name><surname>Gillois</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>Random forest of perfect trees: concept, performance, applications and perspectives</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2165</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">33523112</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nicodemus</surname><given-names>KK</given-names></string-name>, <string-name><surname>Malley</surname><given-names>JD</given-names></string-name>, <string-name><surname>Strobl</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>The behaviour of random forest permutation-based variable importance measures under predictor correlation</article-title>. <source>BMC Bioinformatics</source><year>2010</year>;<volume>11</volume>:<fpage>110</fpage>–<lpage>3</lpage>.<pub-id pub-id-type="pmid">20187966</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pfeifer</surname><given-names>B</given-names></string-name>, <string-name><surname>Baniecki</surname><given-names>H</given-names></string-name>, <string-name><surname>Saranti</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Multi-omics disease module detection with an explainable greedy decision Forest</article-title>. <source>Sci Rep</source><year>2022</year>;<volume>12</volume>:<fpage>16857</fpage>.<pub-id pub-id-type="pmid">36207536</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salek</surname><given-names>RM</given-names></string-name>, <string-name><surname>Maguire</surname><given-names>ML</given-names></string-name>, <string-name><surname>Bentley</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>A metabolomic comparison of urinary changes in type 2 diabetes in mouse, rat, and human</article-title>. <source>Physiol Genomics</source><year>2007</year>;<volume>29</volume>:<fpage>99</fpage>–<lpage>108</lpage>.<pub-id pub-id-type="pmid">17190852</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sudlow</surname><given-names>C</given-names></string-name>, <string-name><surname>Gallacher</surname><given-names>J</given-names></string-name>, <string-name><surname>Allen</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>UK biobank: an open access resource for identifying the causes of a wide range of complex diseases of Middle and old age</article-title>. <source>PLoS Med</source><year>2015</year>;<volume>12</volume>:<fpage>e1001779</fpage>.<pub-id pub-id-type="pmid">25826379</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Voges</surname><given-names>LF</given-names></string-name>, <string-name><surname>Jarren</surname><given-names>LC</given-names></string-name>, <string-name><surname>Seifert</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Exploitation of surrogate variables in random forests for unbiased analysis of mutual impact and importance of features</article-title>. <source>Bioinformatics</source><year>2023</year>;<volume>39</volume>:<fpage>btad471</fpage>.<pub-id pub-id-type="pmid">37522865</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>M</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y.</given-names></string-name></person-group><article-title>Model selection and estimation in regression with grouped variables</article-title>. <source>J R Stat Soc Series B Stat Methodol</source><year>2005</year>;<volume>68</volume>:<fpage>49</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11212485</article-id>
    <article-id pub-id-type="pmid">38383048</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae101</article-id>
    <article-id pub-id-type="publisher-id">btae101</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>LAVASET: Latent Variable Stochastic Ensemble of Trees. An ensemble method for correlated datasets with spatial, spectral, and temporal dependencies</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1854-1799</contrib-id>
        <name>
          <surname>Kasapi</surname>
          <given-names>Melpomeni</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
        <xref rid="btae101-cor1" ref-type="corresp"/>
        <!--mk218@imperial.ac.uk-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Kexin</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3372-8423</contrib-id>
        <name>
          <surname>Ebbels</surname>
          <given-names>Timothy M D</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>O’Regan</surname>
          <given-names>Declan P</given-names>
        </name>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ware</surname>
          <given-names>James S</given-names>
        </name>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Royal Brompton &amp; Harefield Hospitals, Guy’s and St. Thomas’ NHS Foundation Trust</institution>, London SW3 6NP, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Program in Medical &amp; Population Genetics, Broad Institute of MIT &amp; Harvard</institution>, Cambridge, MA 02142, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4971-9003</contrib-id>
        <name>
          <surname>Posma</surname>
          <given-names>Joram M</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <xref rid="btae101-cor1" ref-type="corresp"/>
        <!--jmp111@ic.ac.uk-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae101-cor1">Corresponding authors. Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London, London W12 0NN, United Kingdom. E-mails: <email>mk218@imperial.ac.uk</email> (M.K.) and <email>jmp111@ic.ac.uk</email> (J.M.P.)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-02-21">
      <day>21</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>3</issue>
    <elocation-id>btae101</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="editorial-decision">
        <day>18</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>07</day>
        <month>3</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae101.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Random forests (RFs) can deal with a large number of variables, achieve reasonable prediction scores, and yield highly interpretable feature importance values. As such, RFs are appropriate models for feature selection and further dimension reduction. However, RFs are often not appropriate for correlated datasets due to their mode of selecting individual features for splitting. Addressing correlation relationships in high-dimensional datasets is imperative for reducing the number of variables that are assigned high importance, hence making the dimension reduction most efficient. Here, we propose the LAtent VAriable Stochastic Ensemble of Trees (LAVASET) method that derives latent variables based on the distance characteristics of each feature and aims to incorporate the correlation factor in the splitting step.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Without compromising on performance in the majority of examples, LAVASET outperforms RF by accurately determining feature importance across all correlated variables and ensuring proper distribution of importance values. LAVASET yields mostly non-inferior prediction accuracies to traditional RFs when tested in simulated and real 1D datasets, as well as more complex and high-dimensional 3D datatypes. Unlike traditional RFs, LAVASET is unaffected by single ‘important’ noisy features (false positives), as it considers the local neighbourhood. LAVASET, therefore, highlights neighbourhoods of features, reflecting real signals that collectively impact the model’s predictive ability.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>LAVASET is freely available as a standalone package from <ext-link xlink:href="https://github.com/melkasapi/LAVASET" ext-link-type="uri">https://github.com/melkasapi/LAVASET</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Biobank Resource</institution>
          </institution-wrap>
        </funding-source>
        <award-id>47602</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Wellcome Trust</institution>
            <institution-id institution-id-type="DOI">10.13039/100010269</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Health Data Research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Medical Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000265</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>British Heart Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000274</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute for Health Research</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000272</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Imperial College Biomedical Research Centre</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIHR Imperial College Biomedical Research Centre</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>British Heart Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000274</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Research and Innovation</institution>
            <institution-id institution-id-type="DOI">10.13039/100014013</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Biotechnology and Biological Sciences Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000268</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Commission</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000780</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Random forest (RF) classifiers are frequently used to analyse biological data for prediction and feature selection tasks. RFs can deal with a large number of variables, achieve reasonable prediction scores, and yield highly interpretable feature importance values (<xref rid="btae101-B3" ref-type="bibr">Breiman 2001</xref>). As such, they are appropriate models for feature selection and further dimension reduction (DR) for integrated datasets. The premise of the original RF algorithm is to assemble an ensemble of trees that complement each other and increase variability of predictor selection (<xref rid="btae101-B14" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic> 2021</xref>). However, each node and subsequent split still only consider one predictor variable, limiting both the predictive ability and correct feature importance assignment in complex biological settings that include correlated features.</p>
    <p><xref rid="btae101-B14" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic> (2021)</xref> have recently developed a new information criterion statistic to evaluate the contribution of features to the predictive ability of the model. It comprises different categories of probabilities that assess the feature’s proximity to the target class and the complexity of the relationship with the given class. In addition, permutation-based feature importance has been extensively studied in RFs. It has been demonstrated that there is some level of bias in the assignment of feature importance when there exists collinearity between features that are both associated with the target outcome (<xref rid="btae101-B15" ref-type="bibr">Nicodemus <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    <p>Few techniques have been proposed for enhancing feature importance calculations in datasets with highly correlated variables. The Boruta algorithm (<xref rid="btae101-B10" ref-type="bibr">Kursa and Rudnicki 2010</xref>) uses a ‘shadow’ feature approach where it duplicates the original dataset and shuffles the feature values, however, permuting the values it does not take into account local correlations. Boruta trains a classifier on the enhanced dataset and assigns a value of importance to each of the features, those with lower importance than their permuted counterparts are removed before repeated the process with a new random state. Boruta, in reality, combines permutation importance, by shuffling the original features, with recursive feature elimination (<xref rid="btae101-B8" ref-type="bibr">Guyon <italic toggle="yes">et al.</italic> 2002</xref>), by iteratively considering and removing features that do not reach a threshold, but its classifier still considers only individual features and the permutation procedure does not consider local correlations.</p>
    <p>These methods are efficient in removing noisy features that might not reflect real signals, especially by eliminating these through iterations. However, they are not sensitive in picking all relevant features when these are collinear. Addressing relationships between collinear features in high-dimensional datasets is imperative for reducing the number of features that are assigned high importance and thereby making the DR more efficient. Here, we propose a novel method termed LAtent VAriable Stochastic Ensemble of Trees (LAVASET) that derives latent variables based on the distance characteristics of each feature and thereby incorporates the correlation factor in the splitting step. Hence, it inherently groups correlated features and ensures similar importance assignment for these. Distance characteristics for the features can include the feature’s adjacent points in a 1D spectrum, adjacent features of time-series data, or spatial distance in 3D structures among other examples. In this context, LAVASET addresses a major limitation in the interpretation of feature importance of RFs when the data are collinear, such as is the case for spectroscopic and imaging data.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>We demonstrate the LAVASET algorithm (detailed below) on four different datasets with feature importances calculated as a result of a prediction/classification problem between disease and healthy control (HC) groups or simulated groups.</p>
      <sec>
        <title>2.1.1 Irritable bowel syndrome—faecal metabolomics (1D)</title>
        <p>The Maastricht University Irritable Bowel Syndrome (MIBS) cohort includes human faecal water samples analysed with <sup>1</sup>H Nuclear Magnetic Resonance (NMR) spectroscopy for 267 participants (146 IBS patients; 121 HCs). Details on demographics, sample collection, and data acquisition can be found in <xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> (2022)</xref>. Unlike the original publication, we used the full NMR spectrum (digitized to a total of 18 600 features) following the removal of the internal standard and the water region, and baseline correction.</p>
        <p>To test LAVASET’s ability in capturing relevant features, we also created simulated groups from the MIBS cohort dataset. The groups were generated by using two (uncorrelated) compounds that each have two multiplets, with signals spread out across the length of the spectrum. The compounds used are metabolites ethanol, with peaks at 1.17–1.20 and 3.64–3.68 ppm, and uracil with peaks at 5.79–5.81 and 7.53–7.56 ppm.</p>
      </sec>
      <sec>
        <title>2.1.2 Diabetes—urinary metabolomics (1D)</title>
        <p>Human urinary metabolomics data from individuals with type-2 diabetes mellitus (T2DM), freely available from Metabolights (MTBLS1), were used as an additional test cohort. Prior work on this dataset has shown higher classification accuracy compared to IBS data. A total of 84 samples were collected, consisting of 12 healthy volunteers with data at seven time points, and 30 individuals with T2DM with data collected at 1–3 time points (total of 50 spectra). These were analysed by <sup>1</sup>H-NMR spectroscopy to evaluate the urine profiles between T2DM and HCs. Metabolite identification was performed by PLS-DA models previously, as described by the authors in <xref rid="btae101-B17" ref-type="bibr">Salek <italic toggle="yes">et al.</italic> (2007)</xref>. The raw data were downloaded from MTBLS1 and processed to standardize each spectrum to 18 000 data points. The water and internal standard regions were removed from the spectrum with the remaining points used for the modelling.</p>
      </sec>
      <sec>
        <title>2.1.3 Acute myocardial infarction—electrocardiogram (1D)</title>
        <p>Electrocardiogram (ECG) data from the Physikalisch-Technische Bundesanstalt (PTB) dataset (<xref rid="btae101-B2" ref-type="bibr">Bousseljot <italic toggle="yes">et al.</italic> 2009</xref>) were downloaded from PhysioNet (<xref rid="btae101-B7" ref-type="bibr">Goldberger <italic toggle="yes">et al.</italic> 2000</xref>). We extracted ECG data from individuals with acute myocardial infarction (MI) and compared this against no acute MI. We excluded all data without a reason for admission or with an unknown diagnosis. This resulted in 175 control and 346 acute MI ECGs. The individual ECGs were processed to correct signal drifts. An average cardiac cycle was extracted for each individual that was normalized to 750 data points (0.75 s). We used the three Frank leads [vector cardiogram (VCG)] as input to the algorithm and visualize the feature importance in the conventional 12-leads by making use of the (absolute) Kors regression transformation (<xref rid="btae101-B9" ref-type="bibr">Kors <italic toggle="yes">et al.</italic> 1990</xref>) for the eight independent leads.</p>
      </sec>
      <sec>
        <title>2.1.4 Hypertrophic cardiomyopathy—CMR imaging (3D)</title>
        <p>To test LAVASET’s performance on high dimensional, spatial, 3D datasets, we used data meshes derived from cardiac magnetic resonance (CMR) imaging of the human left ventricle. Segmentation of these images (to produce the meshes) was performed using a deep-learning framework developed by collaborators (<xref rid="btae101-B1" ref-type="bibr">Bai <italic toggle="yes">et al.</italic> 2018</xref>). Measurements of myocardial wall thickness were calculated along radial segments that connected the inner endocardial and outer epicardial surfaces (<xref rid="btae101-B6" ref-type="bibr">Duan <italic toggle="yes">et al.</italic> 2019</xref>). This process produced a 46 808 <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mo>×</mml:mo></mml:math></inline-formula> 4 matrix, where for each of the 46 808 points there is a value for the <italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates of the ventricle, and the wall thickness at that point. These segmentations were performed on images in the UK Biobank dataset (<xref rid="btae101-B18" ref-type="bibr">Sudlow <italic toggle="yes">et al.</italic> 2015</xref>) and an in-house Hypertrophic Cardiomyopathy (HCM) cohort [Royal Brompton Hospital Cardiovascular Biobank (<xref rid="btae101-B5" ref-type="bibr">Curran <italic toggle="yes">et al.</italic> 2023</xref>)]. The total number of samples used here was 1273, consisting of 634 HCM patients and 639 demographically-matched HCs.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Approach</title>
      <p>LAVASET operates given a number of prerequisites and hyperparameters that can be optimized (<xref rid="btae101-F1" ref-type="fig">Fig. 1</xref>). A user-specified distance matrix is calculated to select the <italic toggle="yes">k</italic> closest feature points to the feature of interest (FOI), which form the FOI neighbourhood. This FOI neighbourhood sub-matrix is defined as <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">FOIn</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>:</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">M</italic> denotes the matrix containing all the input features and the set <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> represents the indices of the <italic toggle="yes">k</italic> features in <italic toggle="yes">M</italic> that are closest to FOI (based on the user-specified distance matrix), including the index for FOI itself. The user specifies the maximum number of features to consider for each split (with default the square root of the total number of features), and these are randomly selected from the entire dataset in each step. For each selected FOI, the first left singular vector (PC1) of the respective FOI neighbourhood is calculated. We calculate this via Singular Value Decomposition of the sub-matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">FOIn</mml:mi><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mo>Σ</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, FOIn is the scaled FOI neighbourhood for the selected VOI, <italic toggle="yes">U</italic> is the matrix of left singular vectors, <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mo>Σ</mml:mo></mml:math></inline-formula> is a diagonal matrix containing singular values, and <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (or <italic toggle="yes">V</italic> transposed) is the matrix of right singular vectors. The PC1 or first left singular vector is the first vector in matrix <italic toggle="yes">U</italic>, and this is now the latent variable for the FOIn. Loadings for each latent variable are calculated as <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>⋅</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="italic">FOIn</mml:mi></mml:mrow></mml:math></inline-formula>, where the first left singular vector <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is multiplied by the original FOIn sub-matrix. The input matrix for determining the best split will now consist of the latent variable values instead of the original feature values. The best-split variable and value are evaluated by the traditional Gini index method by deducting the sum of the squared probabilities of each class from one. Once the split occurs, the Gini gain is calculated for the selected latent variable and node by subtracting the sum of the Gini index weights of the two child nodes from the parent node. This is repeated recursively until all samples are split into pure leaf nodes, similar to the classic CART algorithm (<xref rid="btae101-B4" ref-type="bibr">Breiman <italic toggle="yes">et al.</italic> 1984</xref>).</p>
      <fig position="float" id="btae101-F1">
        <label>Figure 1.</label>
        <caption>
          <p>LAVASET high-level pipeline indicating the different and novel approach in the node splitting step and feature importance calculation. Model input is customizable and LAVASET can perform on different types of omics data, from 1D to 3D.</p>
        </caption>
        <graphic xlink:href="btae101f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.3 Feature importance calculation</title>
      <p>Feature importance scores are calculated for each feature by weighing its contribution to the PC score (left singular vector). Specifically, for every selected feature where the PC score is calculated, the loadings vector <italic toggle="yes">L</italic> of the score (with a shape equalling the number of neighbours considered) is calculated and multiplied by the Gini gain value assigned to the selected latent variable. This results in a feature importance score not only for the FOI but also for its neighbours.</p>
      <p>The LAVASET algorithm is designed to allow for multiple variations in the calculation of a feature’s importance after model construction. LAVASET outputs for each feature<inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo> </mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> a vector of values consisting of three parts. <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluate</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the summation over all trees from 1 to <italic toggle="yes">T</italic> of the count of times a feature is evaluated in each tree and, similarly, <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lecte</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represent the total counts of times a feature is selected for a split and the accumulated Gini values in each tree, respectively. All features of the original matrix <italic toggle="yes">M</italic> are equally ‘evaluated’ for a split with a frequency that follows a Gaussian distribution. The subset of features ‘selected’ for splitting a node are those assigned a feature importance.</p>
      <p>From the feature importance values, we can calculate a normalized Gini feature importance by dividing by the sum of all importances. We also evaluate the ratio of the number of times a feature is selected over the count of times it is considered for a split, and incorporate this in our feature importance final value. Using the same output, another use case would be to compare the ratio of Gini values over the count of times a feature is selected for split, which can give an idea of the value magnitude assigned to a feature at a given split. Results presented in this article utilise the normalised feature importance multiplied by the ratio of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lecte</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> over the <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluate</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for each feature. This is shown below, where importance(<italic toggle="yes">i</italic>) is the importance of the feature <italic toggle="yes">i</italic>, T is the total number of trees, importance(<italic toggle="yes">i</italic>, t) represents the Gini importance of the feature <italic toggle="yes">i</italic> in the tree <italic toggle="yes">t</italic>, and <italic toggle="yes">F</italic> is the total number of features. The sum in the numerator of the first fraction goes over all the trees from 1 to <italic toggle="yes">T</italic> for the feature <italic toggle="yes">i</italic>. The sum in the denominator of the first fraction goes over all the trees and all the features (<italic toggle="yes">f</italic> represents each feature in the feature set), which normalizes the Gini of the feature <italic toggle="yes">i</italic>. The ratio of the sums in the second fraction measures the frequency with which feature <italic toggle="yes">i</italic> was selected when it was evaluated: <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">importance</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>F</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lected</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluated</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p>
    </sec>
    <sec>
      <title>2.4 Model evaluation</title>
      <p>Standard metrics (accuracy, precision, recall, and <italic toggle="yes">F</italic>1-score) are used to compare the classification performance of RFs and LAVASET. For both the simulated and MIBS cohort inputs, LAVASET and RF were run 20 distinct times (20 run pairs with 100 and 1000 trees, respectively). Identical random state seeds were assigned per run pair for the sample bootstrapping, to account for the randomness between the comparisons. The data were split into training and test sets (80% and 20%, respectively), with the sets always being kept identical across the runs. Mean accuracy, precision, recall, and <italic toggle="yes">F</italic>1-scores are reported for the 20 runs.</p>
      <p>We performed a grid search optimizing the number of trees and neighbours for the MIBS cohort. Tree values ranged from 100 to 10 000 and neighbours from 1 to 50, and all possible combinations were evaluated. The optimal value for the number of trees for LAVASET was 1000, this model is referred to as LAVASET-1K. We compare LAVASET-1K to two RF models: the first is an RF with the same number of 1000 trees, referred to RF-1K hereafter, and the second is an RF that runs for the same amount of computational time as LAVASET. We evaluated the number of RF trees that can be fit in the same amount of time as LAVASET-1K required. LAVASET-1K fits 1000 trees for 18 neighbours (optimal for MIBS cohort) in ∼11 min [on an HP Z6 G4 workstation with 16-core Intel(R) Xeon(R) Silver 4110 CPU @ 2.10 GHz with 128 GB RAM], a classic RF can include ∼41 000 trees in the same amount of time (referred to as the RF-41K model).</p>
      <p>Precision and recall scores are also calculated as metrics for evaluating the peak coverage of the feature importance performance. In the simulated dataset, the peak points used to create the two distinct groups are assigned as the ground truth (positive designation) for the peak coverage. To evaluate the specificity of LAVASET, we include points outside the peak (equal to <italic toggle="yes">k</italic> neighbours assigned) in the calculations of precision and recall. These serve as the true negative designations. The threshold for positive or negative designation in these calculations is whether the point has been assigned a feature importance value (<inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>0) or not important zero.</p>
      <p>The neighbours for the VCG data were calculated on the basis of the time of the cardiac cycle. That is, selecting Frank’s lead <italic toggle="yes">x</italic> for variable (time) <italic toggle="yes">i</italic> also includes the other two leads (<italic toggle="yes">y</italic>, <italic toggle="yes">z</italic>) at time <italic toggle="yes">i</italic>. Including more neighbours takes place in steps of six (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> for both <italic toggle="yes">i</italic> <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 1). Where the first and last time points are also considered neighbours at <italic toggle="yes">i</italic> <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 1.</p>
      <p>Finally, we assessed LAVASET’s performance on feature extraction for DR of the 3D CMR dataset. Due to computational constraints, the 3D dataset was tested on 100 and 200 neighbours and 150K trees. Neighbours were decided by the spatial distance (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates) in an iterative manner by considering the 100 closest points that remain neighbours for over half of the 1273 samples. The most important features (above the 50% importance value threshold) were selected for LAVASET and RF models (both 150K trees). For each set, we performed further DR and clustering to evaluate how the clusters separated HCM and HC samples. Uniform manifold approximation and projection (UMAP) and <italic toggle="yes">k</italic>-means clustering with <italic toggle="yes">k</italic> = 2 (expected number of groups) were used in both cases (<xref rid="btae101-B12" ref-type="bibr">McInnes <italic toggle="yes">et al.</italic> 2018</xref>). UMAP components and <italic toggle="yes">k</italic>-means transformations were evaluated for 20 different random state restarts to ensure robustness. Each restart produced two clusters that were scored by the standard metrics, to determine how closely they matched the true sample labels.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulated NMR dataset</title>
      <p>LAVASET yields a non-inferior prediction accuracy compared with traditional RFs when predicting the two simulated groups in the NMR dataset (accuracy: 0.859<inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.027 LAVASET, 0.823<inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.021 RF, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>, both the Boruta and RF methods [Panels (B), (C), (E), and (F)] fail to identify all individual features relating to the same peak(s) and instead only identify a subset of these. In contrast, LAVASET not only does identify correctly the simulated metabolites, but also assigns appropriate importance values to all or most of the correlated points that encompass a peak. Specifically, for ethanol’s CH<sub>2</sub> peak shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2A</xref>, <italic toggle="yes">F</italic>1-scores for LAVASET are 96% and 85% for the CH<sub>3</sub> peak. For uracil, the second multi-peak metabolite used to create the simulated dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2D</xref>), LAVASET has <italic toggle="yes">F</italic>1-scores at 96% and 89% in the two doublets. In all the metabolite peaks considered here, Boruta and RF underperform in capturing all the points that comprise the peaks (Boruta <italic toggle="yes">F</italic>1-scores: 23%, 52%, 47%, and 60% for each peak, respectively; RF: 31%, 53%, 49%, and 63%).</p>
    </sec>
    <sec>
      <title>3.2 MIBS cohort</title>
      <p>After a grid search evaluation to identify the optimal parameters for the number of neighbours and trees, the highest scoring accuracy was achieved by 1000 trees and 18 neighbours (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). Average accuracy values overall dropped after considering more than 20 neighbours and there were no significant differences when taking more than 1000 trees for the specific dataset. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4A</xref> presents the optimal number of neighbours for the 1000 trees with a clear peak being displayed on the graph, while the drop after 20 neighbours is also evident there. LAVASET yields similar results when classifying IBS versus HC in the MIBS cohort (only for this cohort, losing 1% in mean accuracy in comparison to RF). Across 20 runs the average accuracy score for LAVASET is 0.68<inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02, for RF-1K 0.69<inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, and for RF-41K 0.68<inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4B</xref> boxplots represent these accuracy values, along with precision, recall, and <italic toggle="yes">F</italic>1 score values. The value ranges shown for the RF-41K model suggest that when running 41 000 trees there is potential for over-fitting, given that the values across each of the 20 runs are almost identical. For the four different performance metrics, the error bars of LAVASET versus RF-1K and LAVASET versus RF-41K overlap, indicating LAVASET is non-inferior to either RF model (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4B</xref>).</p>
      <p>The most pronounced differences between LAVASET and RF are evident when looking at feature importances. LAVASET’s ability to capture the entirety of peaks attributed to a metabolite surpasses the RF feature evaluation which merely captures less than half the points that encompass the peak. <xref rid="btae101-F2" ref-type="fig">Figure 2</xref> shows the relevant peaks of previously identified metabolites valine (A, B, and C) and 2-methylproline (D, E, and F). These two metabolites have been previously associated with separating IBS from HC patients, by showing high feature importance in classification models using Support Vector Classifiers (<xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> 2022</xref>). Panels (A) and (D) show clearly how LAVASET is able to assign importance values to all points of the valine and 2-methylproline peaks, respectively. The dashed grey lines indicate the previously identified point ranges for the specific metabolites peaks, which present a ground truth for the peak, but can sometimes be affected by small shifts or missing points on the sides of a given peak. In the case of 2-methylproline, we notice that LAVASET is also capturing and assigning relatively high importance on points to the left side of the peak. These points, however, when visualized on the spectrum appear to be part of the rest of the peak and LAVASET only assigns an importance to the points up to where the next peak is starting, without including that next non-related peak. This can also be seen on the right-side of valine in <xref rid="btae101-F2" ref-type="fig">Fig. 2A</xref>, where it shows a gradual decline in importance as we are reaching the end of the visualized peak.</p>
      <fig position="float" id="btae101-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Comparison of LAVASET-1K to RF-1K and RF-41K feature importance assignments on pre-identified metabolites. Panels (A)–(C) show feature importances [as defined in Section 2] for valine, and panels (D)–(F) for 2-methylproline. Colourbar on the right indicates the feature importance value range (red = higher, blue = lower). Dashed grey lines indicate the previously identified points for the specific metabolites peaks. <italic toggle="yes">X</italic>-axis indicates the chemical shift (in parts per million, <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mo>δ</mml:mo></mml:math></inline-formula>). <italic toggle="yes">Y</italic>-axis shows the average signal intensity.</p>
        </caption>
        <graphic xlink:href="btae101f2" position="float"/>
      </fig>
      <p>RF, on the other hand, assigns feature importance to sporadic points of the peak, with no real continuance as to the values of importance (valine, <xref rid="btae101-F2" ref-type="fig">Fig. 2B</xref>, red point indicating high importance next to light blue point indicating more than half of an importance value). Even in the case of the 41K trees, we see that the points selected remain almost the same as in the 1K trees, suggesting that an RF cannot reach LAVASET’s ability in capturing whole peaks, even if the number of trees increases 41-fold. Overall, LAVASET’s output is quite stable and not affected significantly by small changes in the number of neighbours. Peak coverage is equivalent when looking at 10–16 neighbours, with the main differences occurring in the value of importance to each point (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>).</p>
    </sec>
    <sec>
      <title>3.3 MTBLS1 cohort</title>
      <p>LAVASET was further tested on the MTBLS1 T2DM cohort, as described in Section 2, to ensure that performance stability and feature importance interpretation remain effective in other cohorts. Consistent with previous examples, LAVASET presents non-inferior results to RF (LAVASET accuracy: 0.82<inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, RF accuracy: 0.77<inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>) and manages to capture the metabolites pre-identified by <xref rid="btae101-B17" ref-type="bibr">Salek <italic toggle="yes">et al.</italic> (2007)</xref>. Metabolite peak capturing by LAVASET is again superior to RF, by encompassing if not all, most points and attributing feature importance values more equally. Results are expanded in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>.</p>
    </sec>
    <sec>
      <title>3.4 ECG data</title>
      <p>We assessed LAVASET’s capabilities on more complex data types where it is common practice to use transformations of the raw reading data to infer further information. We transformed ECG readings to VCG inputs. For this task, we used ECG data from the PTB dataset (<xref rid="btae101-B2" ref-type="bibr">Bousseljot <italic toggle="yes">et al.</italic> 2009</xref>), as described in Section 2. LAVASET-1K performed similarly to the RF-1K in this dataset, with accuracy values showing identical results across 20 runs (0.81<inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>) and other metrics having only small differences (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>). <xref rid="btae101-F3" ref-type="fig">Figure 3</xref> shows the results when taking 20 nearest neighbours (across the time axis as described in Section 2) and 1000 trees. LAVASET is able to capture peaks and anomalies across the ECGs that indicate differences between the HC and MI cases. Given the nature of the dataset and the idiosyncrasies of different MI cases based on the location of the infraction, setting a binary classification by incorporating all types of MI as one target will only capture important features related to all these different MI phenotypes.</p>
      <fig position="float" id="btae101-F3">
        <label>Figure 3.</label>
        <caption>
          <p>ECG feature importance (Kors regression back-transformed from VCG feature importance) normalized across the eight independent ECG leads. Subplot titles indicate the respective leads. <italic toggle="yes">X</italic>-axes show time in milliseconds and <italic toggle="yes">y</italic>-axes voltage magnitude in millivolts. The dotted black line indicates a healthy sample and the solid lines represent the 10 MI types (acute, anterior, anteriolateral, anteroseptolateral, anteroseptal, inferior, inferolateral, inferoposterolateral, lateral, and posterior) in this dataset and are coloured by relative feature importance.</p>
        </caption>
        <graphic xlink:href="btae101f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 CMR imaging</title>
      <p>Both the LAVASET and RF models demonstrate equivalent values across all metrics. LAVASET shows an accuracy of 0.878, precision of 0.837, recall of 0.904, and <italic toggle="yes">F</italic>1-score of 0.869. RF shows an accuracy of 0.875, precision of 0.916, recall of 0.851, and <italic toggle="yes">F</italic>1-score of 0.882. Given these high values, we are confident about the use of both models for feature extraction, as means to DR. <xref rid="btae101-F4" ref-type="fig">Figure 4</xref> shows the results on 100 neighbours and 150 000 trees. LAVASET is able to assign importance values to a larger surface area of the left ventricle, while also demonstrating the most important areas. RF, on the other hand, picks patches of the left ventricle as most important, disregarding other anatomical parts that could be important. To test how informative these selected features are, we used them as input in further DR and clustering via UMAP and <italic toggle="yes">k</italic>-means. <xref rid="btae101-T1" ref-type="table">Table 1</xref> shows the clustering performance across 20 iterations of UMAP and <italic toggle="yes">k</italic>-means, indicating that the features selected by LAVASET perform constantly better than those selected by RF. We also highlight that in this specific dataset, feature extraction improves the models considerably, given the significantly lower performance observed when taking all features as input.</p>
      <fig position="float" id="btae101-F4">
        <label>Figure 4.</label>
        <caption>
          <p>The 3D representations of the left ventricle CMR data points (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates). Points represent an averaged template of HCM and HC ventricles. The inner and outer structures formed show the endocardium and epicardium, respectively. Colourbar shows the feature importance gradient, indicating that in panel (A) (LAVASET) the assignment of higher importance is encompassing the entirety of the ventricle structure. In panel (B), assignments are given in a patch-like manner for RF. Panels (C) and (D) show the points in the 80% quantile from a top view to facilitate the distinction between the inner and outer walls of the ventricle. Panels (E) and (F) show six distinct neighbourhoods of FOIs. In panel (D), convex hulls are drawn for each neighbourhood to represent the pattern of points per neighbourhood. Black points indicate the neighbours and the coloured connecting lines emphasize the different neighbourhoods, and the string-like pattern of neighbour points. Panel (C) shows the feature importance for the respective six neighbourhoods.</p>
        </caption>
        <graphic xlink:href="btae101f4" position="float"/>
      </fig>
      <table-wrap position="float" id="btae101-T1">
        <label>Table 1.</label>
        <caption>
          <p>HCM CMR dataset, feature DR performance.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">LAVASET features</th>
              <th rowspan="1" colspan="1">RF features</th>
              <th rowspan="1" colspan="1">All features</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Accuracy</td>
              <td rowspan="1" colspan="1"><bold>0.890</bold><inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01</td>
              <td rowspan="1" colspan="1">0.870<inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.002</td>
              <td rowspan="1" colspan="1">0.797<inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.905<inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.005</td>
              <td rowspan="1" colspan="1"><bold>0.913</bold><inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
              <td rowspan="1" colspan="1">0.817<inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.006</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1"><bold>0.859</bold><inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.009</td>
              <td rowspan="1" colspan="1">0.816<inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 0.003</td>
              <td rowspan="1" colspan="1">0.763<inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.011</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"><italic toggle="yes">F</italic>1-score</td>
              <td rowspan="1" colspan="1"><bold>0.881</bold><inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
              <td rowspan="1" colspan="1">0.862<inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.002</td>
              <td rowspan="1" colspan="1">0.789<inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.005</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>Scores for accuracy, precision, recall, and <italic toggle="yes">F</italic>1-score across 20 iterations of UMAP and <italic toggle="yes">k</italic>-means (<italic toggle="yes">k</italic> = 2) on the selected feature sets by importance in LAVASET, RF, and without selection. Values shown are the mean<inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>standard deviation. Values in bold indicate the highest performances for each metric. </p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>We have presented a novel ensemble learning method aimed at datasets with spatial, spectral or temporally dependent relationships between features that enhances variable importance and ensures that correlated features are evaluated appropriately and not independently. LAVASET produces non-inferior performance results to traditional RFs in all but one of the examples tested above, and in both simulated and real datasets. While not sacrificing performance in most examples, it is able to assign feature importances in a superior way, by not missing features that are as ‘important’ by means of correlation, and ensuring that importance values are correctly distributed. One of the advantages of RFs in comparison to other classification methods is its ability to assign feature importances to the original features; here, LAVASET retains this advantage by directly assigning importances to the original feature sets, using the loadings derived from singular vector decomposition to guide the relative importances. In contrast, we have shown that RF allocates feature importance to isolated points, whether that is peak points in a spectrum or points on a 3D mesh, without any clear consistency of the magnitude of importance. Even when substantially increasing the number of trees in RF, the selection of points and assignment of importance are nearly identical to those selected with the lower number of trees, and still do not capture the points selected by LAVASET. In this scenario, Boruta (<xref rid="btae101-B10" ref-type="bibr">Kursa and Rudnicki 2010</xref>) shows results similar to RFs and LAVASET demonstrates improved feature recovery. Other decision forest methods, such as GrandForest (<xref rid="btae101-B11" ref-type="bibr">Larsen <italic toggle="yes">et al.</italic> 2020</xref>) and DFNet (<xref rid="btae101-B16" ref-type="bibr">Pfeifer <italic toggle="yes">et al.</italic> 2022</xref>), that use a graph-structure as input for creating each tree still consider only single features at each split. LAVASET combines correlated features in the splitting step and uses the distance matrix to select the groups of features. When specifying subgraphs for datasets with spatially coherent features, the trees of GrandForest and DFNet will get stuck in local neighbourhoods (both with connected subgraphs and random walks). These methods work better with sparser graphs, hence splitting data further using related features do not add much predictive ability as these features are correlated and the residual of the initial split will not contain much information that can be explained by features correlated to the initial one.</p>
    <p>The motivation behind developing LAVASET stems from the idea of enhancing traditional RFs, in a manner similar to how Group Lasso enhances the Lasso algorithm. In the main premise of Group Lasso, we also assume that there are groups of features that are expected to have similar effects or are related to each other. By penalizing the sum of the absolute values (L1 norm) of the coefficients within each group, Group Lasso encourages the model to select entire groups of features together or exclude them altogether (<xref rid="btae101-B20" ref-type="bibr">Yuan and Lin 2005</xref>). Like in Group Lasso, LAVASET is particularly useful when dealing with high-dimensional data where groups of features exhibit similar importance or are structured in some meaningful way. This was evident by the variety of datasets we tested, where the number of features ranged from 750 to 46K. In this high-dimensional context, LAVASET exhibits stability in its output and remains relatively unaffected by minor variations in the number of neighbours comprising the groups. However, Group Lasso requires non-overlapped groups of features, whereas in LAVASET this can be varied. In fact, in LAVASET, different FOIs can have different numbers of neighbours to increase flexibility. Likewise, LAVASET emulates the kernel filter in convolutional neural networks (CNNs) in that it combines multiple features into a single output (for splitting in LAVASET), however, it does so without condensing the output and attributing the feature importance across the initial features. Other work has investigated the relations between individual features in terms of the similarity of performance at different splits. This methodology is able to discern correlations between individual features, however the mutual forest impact is constrained to evaluating pairs of features only (<xref rid="btae101-B19" ref-type="bibr">Voges <italic toggle="yes">et al.</italic> 2023</xref>). LAVASET can, in theory, be combined with this to perform <italic toggle="yes">a posteriori</italic> analysis of evaluating correlations between groups of latent variables.</p>
    <p>LAVASET’s main limitation derives from the requirement of defining the aforementioned ‘groups’ (akin to the kernel size in CNNs). This parameter is user-specified and assumes an understanding of the relationship between the variables. In the examples presented here, this relationship is defined and assigned by distance, whether that is 1D distance across a spectrum, 1D across time-series data, or 3D spatial distance. The influence of neighbourhood definition is evident, especially in the 3D CMR example. <xref rid="btae101-F4" ref-type="fig">Figure 4F</xref> shows that the string-like pattern of importances calculated by LAVASET is predominantly driven by the assignment of neighbours for each FOI. This inherent limitation, however, is what enables LAVASET’s flexibility in creating the groups of neighbours. Distance is only one of the metrics that can be employed. Other examples include genomic distance (combine SNPs via linkage disequilibrium), mass spectrometry isotope patterns (proteomics and metabolomics), or hierarchical relationships (i.e. taxonomy of microbiota). This renders LAVASET more versatile than other similar methods, while giving the user the ability to tailor the algorithm to their specific needs. Hence, it is applicable to a wide variety of datasets and biological questions.</p>
    <p>This flexibility is also translated to LAVASET’s code implementation. The algorithm also exploits parallelization in order to speed up computations. The body of the code is written in Python 3.10, while utilizing established C++ scripts for efficiency. Given the nature of the code and algorithm, LAVASET can be run in batches, if needed, or can be easily altered to incorporate additional metrics to distance. Moreover, while beyond the scope of this work, there is potential to explore new hybrid methods; e.g. LAVASETs output and the important features can be used to define new regions of latent features which can then be evaluated in terms of their relations with other regions as part of a graph (and used as input to GrandForest and/or DFNet), and also to consider permuted latent features at each split for simultaneous feature selection (as with Boruta). We have not performed hyperparameter optimization in this work (except for determining the optimal number of neighbours) to allow comparing the different methods like-for-like, however, we envision that in future the number of neighbours in LAVASET is considered in a hyperparameter optimization setting alongside the max depth, number of trees, and others.</p>
    <p>To enhance and expand LAVASET’s capabilities, we are working on incorporating the gradient boosting algorithm as one of our built-in additional components. This will extend LAVASET’s core methodology to other ensemble methods and benefit from iterative learning and the specific advantages of boosting trees.</p>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>We have presented LAVASET, a novel ensemble method capable to improve feature interpretability by selecting relevant groups of features instead of individual features. Its novel functionality is most useful in datasets with correlations between features. In cases where this is missing from the data, then traditional RFs are more appropriate. LAVASET offers interoperability to the user both by the structure of its code and via the neighbour’s parameter. It can be applied to almost all omics data types to identify all relevant known or unknown important features and effectively perform feature extraction for DR.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btae101_Supplementary_Data</label>
      <media xlink:href="btae101_supplementary_data.pdf"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank <xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> (2022)</xref> for providing the raw MIBS cohort NMR data, the DPO’R group for supplying the CMR images, and Sanjay Prasad for the RBH CMR data.</p>
  </ack>
  <sec>
    <title>Author contributions</title>
    <p>Conceptualization: J.M.P. and M.K. Methodology: J.M.P., M.K., and K.X. Investigation: M.K., J.M.P., and K.X. Visualization: M.K. and J.M.P. Writing—original draft: M.K. and J.M.P. Writing—editing: M.K., J.M.P., T.M.D.E., K.X., J.S.W., and D.P.O’R. Supervision: J.M.P., T.M.D.E., and J.S.W.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the UK Biobank Resource [application numbers 47602 to J.S.W., 40616 to D.P.O’R., 18545 to D.P.O’R.]. M.K. is supported by a Wellcome Trust PhD Studentship in Basic Science [220119/Z/20/Z]; J.M.P. is supported by Health Data Research (HDR) UK and the Medical Research Council via a Rutherford Fund Fellowship [MR/S004033/1]; J.S.W. is supported by Medical Research Council (UK), British Heart Foundation [RE/18/4/34215], and the National Institute for Health Research (NIHR) Imperial College Biomedical Research Centre; D.P.O’R. is supported by the Medical Research Council [MC_UP_1605/13], NIHR Imperial College Biomedical Research Centre, and the British Heart Foundation [RG/19/6/34387, RE/18/4/34215]; and T.M.D.E. is supported by UK Research and Innovation (UKRI) Biotechnology and Biological Sciences Research Council (BBSRC) [grants BT/T007974/1, BB/W002345/1] and European Commission (EC) grants [100173062, 101079370]. The views expressed in this work are those of authors and not necessarily those of funders. For the purpose of Open Access, the authors applied a Creative Commons attribution (CC BY) licence to any author accepted manuscript version arising. The data underlying this article are either available in the article and in its online supplementary material or can be shared on request to the corresponding author with permission of the corresponding party.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae101-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bai</surname><given-names>W</given-names></string-name>, <string-name><surname>Sinclair</surname><given-names>M</given-names></string-name>, <string-name><surname>Tarroni</surname><given-names>G</given-names></string-name></person-group><etal>et al</etal><article-title>Automated cardiovascular magnetic resonance image analysis with fully convolutional networks</article-title>. <source>J Cardiovasc Magn Reson</source><year>2018</year>;<volume>20</volume>:<fpage>65</fpage>.<pub-id pub-id-type="pmid">30217194</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bousseljot</surname><given-names>R</given-names></string-name>, <string-name><surname>Kreiseler</surname><given-names>D</given-names></string-name>, <string-name><surname>Schnabel</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Nutzung der EKG-signaldatenbank CARDIODAT der PTB über das internet</article-title>. <source>BMT</source><year>2009</year>;<volume>40</volume>:<fpage>317</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L.</given-names></string-name></person-group><article-title>Random forests</article-title>. <source>Mach Learn</source><year>2001</year>;<volume>45</volume>:<fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L</given-names></string-name>, <string-name><surname>Friedman</surname><given-names>J</given-names></string-name>, <string-name><surname>Olshen</surname><given-names>RA</given-names></string-name></person-group><etal>et al</etal><source>Classification and Regression Trees</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Chapman &amp; Hall</publisher-name>, <year>1984</year>, <fpage>358</fpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Curran</surname><given-names>L</given-names></string-name>, <string-name><surname>de Marvao</surname><given-names>A</given-names></string-name>, <string-name><surname>Inglese</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal> Genotype-phenotype taxonomy of hypertrophic cardiomyopathy. <italic toggle="yes">Circulation: Genomic and Precision Medicine</italic>, <year>2023</year>.</mixed-citation>
    </ref>
    <ref id="btae101-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duan</surname><given-names>J</given-names></string-name>, <string-name><surname>Bello</surname><given-names>G</given-names></string-name>, <string-name><surname>Schlemper</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Automatic 3D bi-ventricular segmentation of cardiac images by a shape-refined multi- task deep learning approach</article-title>. <source>IEEE Trans Med Imaging</source><year>2019</year>;<volume>38</volume>:<fpage>2151</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">30676949</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldberger</surname><given-names>AL</given-names></string-name>, <string-name><surname>Amaral</surname><given-names>LA</given-names></string-name>, <string-name><surname>Glass</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>PhysioBank, PhysioToolkit, and PhysioNet</article-title>. <source>Circulation</source><year>2000</year>;<volume>101</volume>:<fpage>E215</fpage>–<lpage>20</lpage>.<pub-id pub-id-type="pmid">10851218</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guyon</surname><given-names>I</given-names></string-name>, <string-name><surname>Weston</surname><given-names>J</given-names></string-name>, <string-name><surname>Barnhill</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Gene selection for cancer classification using support vector machines</article-title>. <source>Mach Learn</source><year>2002</year>;<volume>46</volume>:<fpage>389</fpage>–<lpage>422</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kors</surname><given-names>JA</given-names></string-name>, <string-name><surname>van Herpen</surname><given-names>G</given-names></string-name>, <string-name><surname>Sittig</surname><given-names>AC</given-names></string-name></person-group><etal>et al</etal><article-title>Reconstruction of the frank vectorcardiogram from standard electrocardiographic leads: diagnostic comparison of different methods</article-title>. <source>Eur Heart J</source><year>1990</year>;<volume>11</volume>:<fpage>1083</fpage>–<lpage>92</lpage>.<pub-id pub-id-type="pmid">2292255</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kursa</surname><given-names>MB</given-names></string-name>, <string-name><surname>Rudnicki</surname><given-names>WR.</given-names></string-name></person-group><article-title>Feature selection with the Boruta package</article-title>. <source>J Stat Soft</source><year>2010</year>;<volume>36</volume>:<fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Larsen</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Schmidt</surname><given-names>HH</given-names></string-name>, <string-name><surname>Baumbach</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>De novo and supervised endophenotyping using network-guided ensemble learning</article-title>. <source>Syst Med</source><year>2020</year>;<volume>3</volume>:<fpage>8</fpage>–<lpage>21</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McInnes</surname><given-names>L</given-names></string-name>, <string-name><surname>Healy</surname><given-names>J</given-names></string-name>, <string-name><surname>Saul</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>UMAP: uniform manifold approximation and projection</article-title>. <source>JOSS</source><year>2018</year>;<volume>3</volume>:<fpage>861</fpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mujagic</surname><given-names>Z</given-names></string-name>, <string-name><surname>Kasapi</surname><given-names>M</given-names></string-name>, <string-name><surname>Jonkers</surname><given-names>DM</given-names></string-name></person-group><etal>et al</etal><article-title>Integrated fecal microbiome–metabolome signatures reflect stress and serotonin metabolism in irritable bowel syndrome</article-title>. <source>Gut Microbes</source><year>2022</year>;<volume>14</volume>:<fpage>2063016</fpage>.<pub-id pub-id-type="pmid">35446234</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname><given-names>J-M</given-names></string-name>, <string-name><surname>Jézéquel</surname><given-names>P</given-names></string-name>, <string-name><surname>Gillois</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>Random forest of perfect trees: concept, performance, applications and perspectives</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2165</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">33523112</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nicodemus</surname><given-names>KK</given-names></string-name>, <string-name><surname>Malley</surname><given-names>JD</given-names></string-name>, <string-name><surname>Strobl</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>The behaviour of random forest permutation-based variable importance measures under predictor correlation</article-title>. <source>BMC Bioinformatics</source><year>2010</year>;<volume>11</volume>:<fpage>110</fpage>–<lpage>3</lpage>.<pub-id pub-id-type="pmid">20187966</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pfeifer</surname><given-names>B</given-names></string-name>, <string-name><surname>Baniecki</surname><given-names>H</given-names></string-name>, <string-name><surname>Saranti</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Multi-omics disease module detection with an explainable greedy decision Forest</article-title>. <source>Sci Rep</source><year>2022</year>;<volume>12</volume>:<fpage>16857</fpage>.<pub-id pub-id-type="pmid">36207536</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salek</surname><given-names>RM</given-names></string-name>, <string-name><surname>Maguire</surname><given-names>ML</given-names></string-name>, <string-name><surname>Bentley</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>A metabolomic comparison of urinary changes in type 2 diabetes in mouse, rat, and human</article-title>. <source>Physiol Genomics</source><year>2007</year>;<volume>29</volume>:<fpage>99</fpage>–<lpage>108</lpage>.<pub-id pub-id-type="pmid">17190852</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sudlow</surname><given-names>C</given-names></string-name>, <string-name><surname>Gallacher</surname><given-names>J</given-names></string-name>, <string-name><surname>Allen</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>UK biobank: an open access resource for identifying the causes of a wide range of complex diseases of Middle and old age</article-title>. <source>PLoS Med</source><year>2015</year>;<volume>12</volume>:<fpage>e1001779</fpage>.<pub-id pub-id-type="pmid">25826379</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Voges</surname><given-names>LF</given-names></string-name>, <string-name><surname>Jarren</surname><given-names>LC</given-names></string-name>, <string-name><surname>Seifert</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Exploitation of surrogate variables in random forests for unbiased analysis of mutual impact and importance of features</article-title>. <source>Bioinformatics</source><year>2023</year>;<volume>39</volume>:<fpage>btad471</fpage>.<pub-id pub-id-type="pmid">37522865</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>M</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y.</given-names></string-name></person-group><article-title>Model selection and estimation in regression with grouped variables</article-title>. <source>J R Stat Soc Series B Stat Methodol</source><year>2005</year>;<volume>68</volume>:<fpage>49</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">11212485</article-id>
    <article-id pub-id-type="pmid">38383048</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae101</article-id>
    <article-id pub-id-type="publisher-id">btae101</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>LAVASET: Latent Variable Stochastic Ensemble of Trees. An ensemble method for correlated datasets with spatial, spectral, and temporal dependencies</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1854-1799</contrib-id>
        <name>
          <surname>Kasapi</surname>
          <given-names>Melpomeni</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
        <xref rid="btae101-cor1" ref-type="corresp"/>
        <!--mk218@imperial.ac.uk-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Kexin</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3372-8423</contrib-id>
        <name>
          <surname>Ebbels</surname>
          <given-names>Timothy M D</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>O’Regan</surname>
          <given-names>Declan P</given-names>
        </name>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ware</surname>
          <given-names>James S</given-names>
        </name>
        <aff><institution>Faculty of Medicine, National Heart &amp; Lung Institute, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <aff><institution>MRC London Institute of Medical Sciences, Imperial College London</institution>, London W12 0HS, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Royal Brompton &amp; Harefield Hospitals, Guy’s and St. Thomas’ NHS Foundation Trust</institution>, London SW3 6NP, <country country="GB">United Kingdom</country></aff>
        <aff><institution>Program in Medical &amp; Population Genetics, Broad Institute of MIT &amp; Harvard</institution>, Cambridge, MA 02142, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4971-9003</contrib-id>
        <name>
          <surname>Posma</surname>
          <given-names>Joram M</given-names>
        </name>
        <aff><institution>Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London</institution>, London W12 0NN, <country country="GB">United Kingdom</country></aff>
        <xref rid="btae101-cor1" ref-type="corresp"/>
        <!--jmp111@ic.ac.uk-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae101-cor1">Corresponding authors. Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London, London W12 0NN, United Kingdom. E-mails: <email>mk218@imperial.ac.uk</email> (M.K.) and <email>jmp111@ic.ac.uk</email> (J.M.P.)</corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-02-21">
      <day>21</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>3</issue>
    <elocation-id>btae101</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>9</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>1</month>
        <year>2024</year>
      </date>
      <date date-type="editorial-decision">
        <day>18</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>20</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>07</day>
        <month>3</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae101.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Random forests (RFs) can deal with a large number of variables, achieve reasonable prediction scores, and yield highly interpretable feature importance values. As such, RFs are appropriate models for feature selection and further dimension reduction. However, RFs are often not appropriate for correlated datasets due to their mode of selecting individual features for splitting. Addressing correlation relationships in high-dimensional datasets is imperative for reducing the number of variables that are assigned high importance, hence making the dimension reduction most efficient. Here, we propose the LAtent VAriable Stochastic Ensemble of Trees (LAVASET) method that derives latent variables based on the distance characteristics of each feature and aims to incorporate the correlation factor in the splitting step.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Without compromising on performance in the majority of examples, LAVASET outperforms RF by accurately determining feature importance across all correlated variables and ensuring proper distribution of importance values. LAVASET yields mostly non-inferior prediction accuracies to traditional RFs when tested in simulated and real 1D datasets, as well as more complex and high-dimensional 3D datatypes. Unlike traditional RFs, LAVASET is unaffected by single ‘important’ noisy features (false positives), as it considers the local neighbourhood. LAVASET, therefore, highlights neighbourhoods of features, reflecting real signals that collectively impact the model’s predictive ability.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>LAVASET is freely available as a standalone package from <ext-link xlink:href="https://github.com/melkasapi/LAVASET" ext-link-type="uri">https://github.com/melkasapi/LAVASET</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Biobank Resource</institution>
          </institution-wrap>
        </funding-source>
        <award-id>47602</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Wellcome Trust</institution>
            <institution-id institution-id-type="DOI">10.13039/100010269</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Health Data Research</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Medical Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000265</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>British Heart Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000274</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute for Health Research</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000272</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Imperial College Biomedical Research Centre</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIHR Imperial College Biomedical Research Centre</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>British Heart Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000274</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>UK Research and Innovation</institution>
            <institution-id institution-id-type="DOI">10.13039/100014013</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Biotechnology and Biological Sciences Research Council</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000268</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>European Commission</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000780</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Random forest (RF) classifiers are frequently used to analyse biological data for prediction and feature selection tasks. RFs can deal with a large number of variables, achieve reasonable prediction scores, and yield highly interpretable feature importance values (<xref rid="btae101-B3" ref-type="bibr">Breiman 2001</xref>). As such, they are appropriate models for feature selection and further dimension reduction (DR) for integrated datasets. The premise of the original RF algorithm is to assemble an ensemble of trees that complement each other and increase variability of predictor selection (<xref rid="btae101-B14" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic> 2021</xref>). However, each node and subsequent split still only consider one predictor variable, limiting both the predictive ability and correct feature importance assignment in complex biological settings that include correlated features.</p>
    <p><xref rid="btae101-B14" ref-type="bibr">Nguyen <italic toggle="yes">et al.</italic> (2021)</xref> have recently developed a new information criterion statistic to evaluate the contribution of features to the predictive ability of the model. It comprises different categories of probabilities that assess the feature’s proximity to the target class and the complexity of the relationship with the given class. In addition, permutation-based feature importance has been extensively studied in RFs. It has been demonstrated that there is some level of bias in the assignment of feature importance when there exists collinearity between features that are both associated with the target outcome (<xref rid="btae101-B15" ref-type="bibr">Nicodemus <italic toggle="yes">et al.</italic> 2010</xref>).</p>
    <p>Few techniques have been proposed for enhancing feature importance calculations in datasets with highly correlated variables. The Boruta algorithm (<xref rid="btae101-B10" ref-type="bibr">Kursa and Rudnicki 2010</xref>) uses a ‘shadow’ feature approach where it duplicates the original dataset and shuffles the feature values, however, permuting the values it does not take into account local correlations. Boruta trains a classifier on the enhanced dataset and assigns a value of importance to each of the features, those with lower importance than their permuted counterparts are removed before repeated the process with a new random state. Boruta, in reality, combines permutation importance, by shuffling the original features, with recursive feature elimination (<xref rid="btae101-B8" ref-type="bibr">Guyon <italic toggle="yes">et al.</italic> 2002</xref>), by iteratively considering and removing features that do not reach a threshold, but its classifier still considers only individual features and the permutation procedure does not consider local correlations.</p>
    <p>These methods are efficient in removing noisy features that might not reflect real signals, especially by eliminating these through iterations. However, they are not sensitive in picking all relevant features when these are collinear. Addressing relationships between collinear features in high-dimensional datasets is imperative for reducing the number of features that are assigned high importance and thereby making the DR more efficient. Here, we propose a novel method termed LAtent VAriable Stochastic Ensemble of Trees (LAVASET) that derives latent variables based on the distance characteristics of each feature and thereby incorporates the correlation factor in the splitting step. Hence, it inherently groups correlated features and ensures similar importance assignment for these. Distance characteristics for the features can include the feature’s adjacent points in a 1D spectrum, adjacent features of time-series data, or spatial distance in 3D structures among other examples. In this context, LAVASET addresses a major limitation in the interpretation of feature importance of RFs when the data are collinear, such as is the case for spectroscopic and imaging data.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>We demonstrate the LAVASET algorithm (detailed below) on four different datasets with feature importances calculated as a result of a prediction/classification problem between disease and healthy control (HC) groups or simulated groups.</p>
      <sec>
        <title>2.1.1 Irritable bowel syndrome—faecal metabolomics (1D)</title>
        <p>The Maastricht University Irritable Bowel Syndrome (MIBS) cohort includes human faecal water samples analysed with <sup>1</sup>H Nuclear Magnetic Resonance (NMR) spectroscopy for 267 participants (146 IBS patients; 121 HCs). Details on demographics, sample collection, and data acquisition can be found in <xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> (2022)</xref>. Unlike the original publication, we used the full NMR spectrum (digitized to a total of 18 600 features) following the removal of the internal standard and the water region, and baseline correction.</p>
        <p>To test LAVASET’s ability in capturing relevant features, we also created simulated groups from the MIBS cohort dataset. The groups were generated by using two (uncorrelated) compounds that each have two multiplets, with signals spread out across the length of the spectrum. The compounds used are metabolites ethanol, with peaks at 1.17–1.20 and 3.64–3.68 ppm, and uracil with peaks at 5.79–5.81 and 7.53–7.56 ppm.</p>
      </sec>
      <sec>
        <title>2.1.2 Diabetes—urinary metabolomics (1D)</title>
        <p>Human urinary metabolomics data from individuals with type-2 diabetes mellitus (T2DM), freely available from Metabolights (MTBLS1), were used as an additional test cohort. Prior work on this dataset has shown higher classification accuracy compared to IBS data. A total of 84 samples were collected, consisting of 12 healthy volunteers with data at seven time points, and 30 individuals with T2DM with data collected at 1–3 time points (total of 50 spectra). These were analysed by <sup>1</sup>H-NMR spectroscopy to evaluate the urine profiles between T2DM and HCs. Metabolite identification was performed by PLS-DA models previously, as described by the authors in <xref rid="btae101-B17" ref-type="bibr">Salek <italic toggle="yes">et al.</italic> (2007)</xref>. The raw data were downloaded from MTBLS1 and processed to standardize each spectrum to 18 000 data points. The water and internal standard regions were removed from the spectrum with the remaining points used for the modelling.</p>
      </sec>
      <sec>
        <title>2.1.3 Acute myocardial infarction—electrocardiogram (1D)</title>
        <p>Electrocardiogram (ECG) data from the Physikalisch-Technische Bundesanstalt (PTB) dataset (<xref rid="btae101-B2" ref-type="bibr">Bousseljot <italic toggle="yes">et al.</italic> 2009</xref>) were downloaded from PhysioNet (<xref rid="btae101-B7" ref-type="bibr">Goldberger <italic toggle="yes">et al.</italic> 2000</xref>). We extracted ECG data from individuals with acute myocardial infarction (MI) and compared this against no acute MI. We excluded all data without a reason for admission or with an unknown diagnosis. This resulted in 175 control and 346 acute MI ECGs. The individual ECGs were processed to correct signal drifts. An average cardiac cycle was extracted for each individual that was normalized to 750 data points (0.75 s). We used the three Frank leads [vector cardiogram (VCG)] as input to the algorithm and visualize the feature importance in the conventional 12-leads by making use of the (absolute) Kors regression transformation (<xref rid="btae101-B9" ref-type="bibr">Kors <italic toggle="yes">et al.</italic> 1990</xref>) for the eight independent leads.</p>
      </sec>
      <sec>
        <title>2.1.4 Hypertrophic cardiomyopathy—CMR imaging (3D)</title>
        <p>To test LAVASET’s performance on high dimensional, spatial, 3D datasets, we used data meshes derived from cardiac magnetic resonance (CMR) imaging of the human left ventricle. Segmentation of these images (to produce the meshes) was performed using a deep-learning framework developed by collaborators (<xref rid="btae101-B1" ref-type="bibr">Bai <italic toggle="yes">et al.</italic> 2018</xref>). Measurements of myocardial wall thickness were calculated along radial segments that connected the inner endocardial and outer epicardial surfaces (<xref rid="btae101-B6" ref-type="bibr">Duan <italic toggle="yes">et al.</italic> 2019</xref>). This process produced a 46 808 <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mo>×</mml:mo></mml:math></inline-formula> 4 matrix, where for each of the 46 808 points there is a value for the <italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates of the ventricle, and the wall thickness at that point. These segmentations were performed on images in the UK Biobank dataset (<xref rid="btae101-B18" ref-type="bibr">Sudlow <italic toggle="yes">et al.</italic> 2015</xref>) and an in-house Hypertrophic Cardiomyopathy (HCM) cohort [Royal Brompton Hospital Cardiovascular Biobank (<xref rid="btae101-B5" ref-type="bibr">Curran <italic toggle="yes">et al.</italic> 2023</xref>)]. The total number of samples used here was 1273, consisting of 634 HCM patients and 639 demographically-matched HCs.</p>
      </sec>
    </sec>
    <sec>
      <title>2.2 Approach</title>
      <p>LAVASET operates given a number of prerequisites and hyperparameters that can be optimized (<xref rid="btae101-F1" ref-type="fig">Fig. 1</xref>). A user-specified distance matrix is calculated to select the <italic toggle="yes">k</italic> closest feature points to the feature of interest (FOI), which form the FOI neighbourhood. This FOI neighbourhood sub-matrix is defined as <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">FOIn</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mo>:</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> where <italic toggle="yes">M</italic> denotes the matrix containing all the input features and the set <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> represents the indices of the <italic toggle="yes">k</italic> features in <italic toggle="yes">M</italic> that are closest to FOI (based on the user-specified distance matrix), including the index for FOI itself. The user specifies the maximum number of features to consider for each split (with default the square root of the total number of features), and these are randomly selected from the entire dataset in each step. For each selected FOI, the first left singular vector (PC1) of the respective FOI neighbourhood is calculated. We calculate this via Singular Value Decomposition of the sub-matrix <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">FOIn</mml:mi><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mo>Σ</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, FOIn is the scaled FOI neighbourhood for the selected VOI, <italic toggle="yes">U</italic> is the matrix of left singular vectors, <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mo>Σ</mml:mo></mml:math></inline-formula> is a diagonal matrix containing singular values, and <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (or <italic toggle="yes">V</italic> transposed) is the matrix of right singular vectors. The PC1 or first left singular vector is the first vector in matrix <italic toggle="yes">U</italic>, and this is now the latent variable for the FOIn. Loadings for each latent variable are calculated as <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>⋅</mml:mo><mml:mo> </mml:mo><mml:mi mathvariant="italic">FOIn</mml:mi></mml:mrow></mml:math></inline-formula>, where the first left singular vector <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is multiplied by the original FOIn sub-matrix. The input matrix for determining the best split will now consist of the latent variable values instead of the original feature values. The best-split variable and value are evaluated by the traditional Gini index method by deducting the sum of the squared probabilities of each class from one. Once the split occurs, the Gini gain is calculated for the selected latent variable and node by subtracting the sum of the Gini index weights of the two child nodes from the parent node. This is repeated recursively until all samples are split into pure leaf nodes, similar to the classic CART algorithm (<xref rid="btae101-B4" ref-type="bibr">Breiman <italic toggle="yes">et al.</italic> 1984</xref>).</p>
      <fig position="float" id="btae101-F1">
        <label>Figure 1.</label>
        <caption>
          <p>LAVASET high-level pipeline indicating the different and novel approach in the node splitting step and feature importance calculation. Model input is customizable and LAVASET can perform on different types of omics data, from 1D to 3D.</p>
        </caption>
        <graphic xlink:href="btae101f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.3 Feature importance calculation</title>
      <p>Feature importance scores are calculated for each feature by weighing its contribution to the PC score (left singular vector). Specifically, for every selected feature where the PC score is calculated, the loadings vector <italic toggle="yes">L</italic> of the score (with a shape equalling the number of neighbours considered) is calculated and multiplied by the Gini gain value assigned to the selected latent variable. This results in a feature importance score not only for the FOI but also for its neighbours.</p>
      <p>The LAVASET algorithm is designed to allow for multiple variations in the calculation of a feature’s importance after model construction. LAVASET outputs for each feature<inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo> </mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> a vector of values consisting of three parts. <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluate</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the summation over all trees from 1 to <italic toggle="yes">T</italic> of the count of times a feature is evaluated in each tree and, similarly, <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lecte</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represent the total counts of times a feature is selected for a split and the accumulated Gini values in each tree, respectively. All features of the original matrix <italic toggle="yes">M</italic> are equally ‘evaluated’ for a split with a frequency that follows a Gaussian distribution. The subset of features ‘selected’ for splitting a node are those assigned a feature importance.</p>
      <p>From the feature importance values, we can calculate a normalized Gini feature importance by dividing by the sum of all importances. We also evaluate the ratio of the number of times a feature is selected over the count of times it is considered for a split, and incorporate this in our feature importance final value. Using the same output, another use case would be to compare the ratio of Gini values over the count of times a feature is selected for split, which can give an idea of the value magnitude assigned to a feature at a given split. Results presented in this article utilise the normalised feature importance multiplied by the ratio of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lecte</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> over the <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluate</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for each feature. This is shown below, where importance(<italic toggle="yes">i</italic>) is the importance of the feature <italic toggle="yes">i</italic>, T is the total number of trees, importance(<italic toggle="yes">i</italic>, t) represents the Gini importance of the feature <italic toggle="yes">i</italic> in the tree <italic toggle="yes">t</italic>, and <italic toggle="yes">F</italic> is the total number of features. The sum in the numerator of the first fraction goes over all the trees from 1 to <italic toggle="yes">T</italic> for the feature <italic toggle="yes">i</italic>. The sum in the denominator of the first fraction goes over all the trees and all the features (<italic toggle="yes">f</italic> represents each feature in the feature set), which normalizes the Gini of the feature <italic toggle="yes">i</italic>. The ratio of the sums in the second fraction measures the frequency with which feature <italic toggle="yes">i</italic> was selected when it was evaluated: <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">importance</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>F</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="italic">lected</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi mathvariant="italic">aluated</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p>
    </sec>
    <sec>
      <title>2.4 Model evaluation</title>
      <p>Standard metrics (accuracy, precision, recall, and <italic toggle="yes">F</italic>1-score) are used to compare the classification performance of RFs and LAVASET. For both the simulated and MIBS cohort inputs, LAVASET and RF were run 20 distinct times (20 run pairs with 100 and 1000 trees, respectively). Identical random state seeds were assigned per run pair for the sample bootstrapping, to account for the randomness between the comparisons. The data were split into training and test sets (80% and 20%, respectively), with the sets always being kept identical across the runs. Mean accuracy, precision, recall, and <italic toggle="yes">F</italic>1-scores are reported for the 20 runs.</p>
      <p>We performed a grid search optimizing the number of trees and neighbours for the MIBS cohort. Tree values ranged from 100 to 10 000 and neighbours from 1 to 50, and all possible combinations were evaluated. The optimal value for the number of trees for LAVASET was 1000, this model is referred to as LAVASET-1K. We compare LAVASET-1K to two RF models: the first is an RF with the same number of 1000 trees, referred to RF-1K hereafter, and the second is an RF that runs for the same amount of computational time as LAVASET. We evaluated the number of RF trees that can be fit in the same amount of time as LAVASET-1K required. LAVASET-1K fits 1000 trees for 18 neighbours (optimal for MIBS cohort) in ∼11 min [on an HP Z6 G4 workstation with 16-core Intel(R) Xeon(R) Silver 4110 CPU @ 2.10 GHz with 128 GB RAM], a classic RF can include ∼41 000 trees in the same amount of time (referred to as the RF-41K model).</p>
      <p>Precision and recall scores are also calculated as metrics for evaluating the peak coverage of the feature importance performance. In the simulated dataset, the peak points used to create the two distinct groups are assigned as the ground truth (positive designation) for the peak coverage. To evaluate the specificity of LAVASET, we include points outside the peak (equal to <italic toggle="yes">k</italic> neighbours assigned) in the calculations of precision and recall. These serve as the true negative designations. The threshold for positive or negative designation in these calculations is whether the point has been assigned a feature importance value (<inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>0) or not important zero.</p>
      <p>The neighbours for the VCG data were calculated on the basis of the time of the cardiac cycle. That is, selecting Frank’s lead <italic toggle="yes">x</italic> for variable (time) <italic toggle="yes">i</italic> also includes the other two leads (<italic toggle="yes">y</italic>, <italic toggle="yes">z</italic>) at time <italic toggle="yes">i</italic>. Including more neighbours takes place in steps of six (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> for both <italic toggle="yes">i</italic> <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 1). Where the first and last time points are also considered neighbours at <italic toggle="yes">i</italic> <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 1.</p>
      <p>Finally, we assessed LAVASET’s performance on feature extraction for DR of the 3D CMR dataset. Due to computational constraints, the 3D dataset was tested on 100 and 200 neighbours and 150K trees. Neighbours were decided by the spatial distance (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates) in an iterative manner by considering the 100 closest points that remain neighbours for over half of the 1273 samples. The most important features (above the 50% importance value threshold) were selected for LAVASET and RF models (both 150K trees). For each set, we performed further DR and clustering to evaluate how the clusters separated HCM and HC samples. Uniform manifold approximation and projection (UMAP) and <italic toggle="yes">k</italic>-means clustering with <italic toggle="yes">k</italic> = 2 (expected number of groups) were used in both cases (<xref rid="btae101-B12" ref-type="bibr">McInnes <italic toggle="yes">et al.</italic> 2018</xref>). UMAP components and <italic toggle="yes">k</italic>-means transformations were evaluated for 20 different random state restarts to ensure robustness. Each restart produced two clusters that were scored by the standard metrics, to determine how closely they matched the true sample labels.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulated NMR dataset</title>
      <p>LAVASET yields a non-inferior prediction accuracy compared with traditional RFs when predicting the two simulated groups in the NMR dataset (accuracy: 0.859<inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.027 LAVASET, 0.823<inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.021 RF, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>, both the Boruta and RF methods [Panels (B), (C), (E), and (F)] fail to identify all individual features relating to the same peak(s) and instead only identify a subset of these. In contrast, LAVASET not only does identify correctly the simulated metabolites, but also assigns appropriate importance values to all or most of the correlated points that encompass a peak. Specifically, for ethanol’s CH<sub>2</sub> peak shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2A</xref>, <italic toggle="yes">F</italic>1-scores for LAVASET are 96% and 85% for the CH<sub>3</sub> peak. For uracil, the second multi-peak metabolite used to create the simulated dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2D</xref>), LAVASET has <italic toggle="yes">F</italic>1-scores at 96% and 89% in the two doublets. In all the metabolite peaks considered here, Boruta and RF underperform in capturing all the points that comprise the peaks (Boruta <italic toggle="yes">F</italic>1-scores: 23%, 52%, 47%, and 60% for each peak, respectively; RF: 31%, 53%, 49%, and 63%).</p>
    </sec>
    <sec>
      <title>3.2 MIBS cohort</title>
      <p>After a grid search evaluation to identify the optimal parameters for the number of neighbours and trees, the highest scoring accuracy was achieved by 1000 trees and 18 neighbours (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). Average accuracy values overall dropped after considering more than 20 neighbours and there were no significant differences when taking more than 1000 trees for the specific dataset. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4A</xref> presents the optimal number of neighbours for the 1000 trees with a clear peak being displayed on the graph, while the drop after 20 neighbours is also evident there. LAVASET yields similar results when classifying IBS versus HC in the MIBS cohort (only for this cohort, losing 1% in mean accuracy in comparison to RF). Across 20 runs the average accuracy score for LAVASET is 0.68<inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02, for RF-1K 0.69<inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, and for RF-41K 0.68<inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4B</xref> boxplots represent these accuracy values, along with precision, recall, and <italic toggle="yes">F</italic>1 score values. The value ranges shown for the RF-41K model suggest that when running 41 000 trees there is potential for over-fitting, given that the values across each of the 20 runs are almost identical. For the four different performance metrics, the error bars of LAVASET versus RF-1K and LAVASET versus RF-41K overlap, indicating LAVASET is non-inferior to either RF model (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4B</xref>).</p>
      <p>The most pronounced differences between LAVASET and RF are evident when looking at feature importances. LAVASET’s ability to capture the entirety of peaks attributed to a metabolite surpasses the RF feature evaluation which merely captures less than half the points that encompass the peak. <xref rid="btae101-F2" ref-type="fig">Figure 2</xref> shows the relevant peaks of previously identified metabolites valine (A, B, and C) and 2-methylproline (D, E, and F). These two metabolites have been previously associated with separating IBS from HC patients, by showing high feature importance in classification models using Support Vector Classifiers (<xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> 2022</xref>). Panels (A) and (D) show clearly how LAVASET is able to assign importance values to all points of the valine and 2-methylproline peaks, respectively. The dashed grey lines indicate the previously identified point ranges for the specific metabolites peaks, which present a ground truth for the peak, but can sometimes be affected by small shifts or missing points on the sides of a given peak. In the case of 2-methylproline, we notice that LAVASET is also capturing and assigning relatively high importance on points to the left side of the peak. These points, however, when visualized on the spectrum appear to be part of the rest of the peak and LAVASET only assigns an importance to the points up to where the next peak is starting, without including that next non-related peak. This can also be seen on the right-side of valine in <xref rid="btae101-F2" ref-type="fig">Fig. 2A</xref>, where it shows a gradual decline in importance as we are reaching the end of the visualized peak.</p>
      <fig position="float" id="btae101-F2">
        <label>Figure 2.</label>
        <caption>
          <p>Comparison of LAVASET-1K to RF-1K and RF-41K feature importance assignments on pre-identified metabolites. Panels (A)–(C) show feature importances [as defined in Section 2] for valine, and panels (D)–(F) for 2-methylproline. Colourbar on the right indicates the feature importance value range (red = higher, blue = lower). Dashed grey lines indicate the previously identified points for the specific metabolites peaks. <italic toggle="yes">X</italic>-axis indicates the chemical shift (in parts per million, <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mo>δ</mml:mo></mml:math></inline-formula>). <italic toggle="yes">Y</italic>-axis shows the average signal intensity.</p>
        </caption>
        <graphic xlink:href="btae101f2" position="float"/>
      </fig>
      <p>RF, on the other hand, assigns feature importance to sporadic points of the peak, with no real continuance as to the values of importance (valine, <xref rid="btae101-F2" ref-type="fig">Fig. 2B</xref>, red point indicating high importance next to light blue point indicating more than half of an importance value). Even in the case of the 41K trees, we see that the points selected remain almost the same as in the 1K trees, suggesting that an RF cannot reach LAVASET’s ability in capturing whole peaks, even if the number of trees increases 41-fold. Overall, LAVASET’s output is quite stable and not affected significantly by small changes in the number of neighbours. Peak coverage is equivalent when looking at 10–16 neighbours, with the main differences occurring in the value of importance to each point (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>).</p>
    </sec>
    <sec>
      <title>3.3 MTBLS1 cohort</title>
      <p>LAVASET was further tested on the MTBLS1 T2DM cohort, as described in Section 2, to ensure that performance stability and feature importance interpretation remain effective in other cohorts. Consistent with previous examples, LAVASET presents non-inferior results to RF (LAVASET accuracy: 0.82<inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, RF accuracy: 0.77<inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.02, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>) and manages to capture the metabolites pre-identified by <xref rid="btae101-B17" ref-type="bibr">Salek <italic toggle="yes">et al.</italic> (2007)</xref>. Metabolite peak capturing by LAVASET is again superior to RF, by encompassing if not all, most points and attributing feature importance values more equally. Results are expanded in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>.</p>
    </sec>
    <sec>
      <title>3.4 ECG data</title>
      <p>We assessed LAVASET’s capabilities on more complex data types where it is common practice to use transformations of the raw reading data to infer further information. We transformed ECG readings to VCG inputs. For this task, we used ECG data from the PTB dataset (<xref rid="btae101-B2" ref-type="bibr">Bousseljot <italic toggle="yes">et al.</italic> 2009</xref>), as described in Section 2. LAVASET-1K performed similarly to the RF-1K in this dataset, with accuracy values showing identical results across 20 runs (0.81<inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>) and other metrics having only small differences (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>). <xref rid="btae101-F3" ref-type="fig">Figure 3</xref> shows the results when taking 20 nearest neighbours (across the time axis as described in Section 2) and 1000 trees. LAVASET is able to capture peaks and anomalies across the ECGs that indicate differences between the HC and MI cases. Given the nature of the dataset and the idiosyncrasies of different MI cases based on the location of the infraction, setting a binary classification by incorporating all types of MI as one target will only capture important features related to all these different MI phenotypes.</p>
      <fig position="float" id="btae101-F3">
        <label>Figure 3.</label>
        <caption>
          <p>ECG feature importance (Kors regression back-transformed from VCG feature importance) normalized across the eight independent ECG leads. Subplot titles indicate the respective leads. <italic toggle="yes">X</italic>-axes show time in milliseconds and <italic toggle="yes">y</italic>-axes voltage magnitude in millivolts. The dotted black line indicates a healthy sample and the solid lines represent the 10 MI types (acute, anterior, anteriolateral, anteroseptolateral, anteroseptal, inferior, inferolateral, inferoposterolateral, lateral, and posterior) in this dataset and are coloured by relative feature importance.</p>
        </caption>
        <graphic xlink:href="btae101f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.5 CMR imaging</title>
      <p>Both the LAVASET and RF models demonstrate equivalent values across all metrics. LAVASET shows an accuracy of 0.878, precision of 0.837, recall of 0.904, and <italic toggle="yes">F</italic>1-score of 0.869. RF shows an accuracy of 0.875, precision of 0.916, recall of 0.851, and <italic toggle="yes">F</italic>1-score of 0.882. Given these high values, we are confident about the use of both models for feature extraction, as means to DR. <xref rid="btae101-F4" ref-type="fig">Figure 4</xref> shows the results on 100 neighbours and 150 000 trees. LAVASET is able to assign importance values to a larger surface area of the left ventricle, while also demonstrating the most important areas. RF, on the other hand, picks patches of the left ventricle as most important, disregarding other anatomical parts that could be important. To test how informative these selected features are, we used them as input in further DR and clustering via UMAP and <italic toggle="yes">k</italic>-means. <xref rid="btae101-T1" ref-type="table">Table 1</xref> shows the clustering performance across 20 iterations of UMAP and <italic toggle="yes">k</italic>-means, indicating that the features selected by LAVASET perform constantly better than those selected by RF. We also highlight that in this specific dataset, feature extraction improves the models considerably, given the significantly lower performance observed when taking all features as input.</p>
      <fig position="float" id="btae101-F4">
        <label>Figure 4.</label>
        <caption>
          <p>The 3D representations of the left ventricle CMR data points (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>, and <italic toggle="yes">z</italic> coordinates). Points represent an averaged template of HCM and HC ventricles. The inner and outer structures formed show the endocardium and epicardium, respectively. Colourbar shows the feature importance gradient, indicating that in panel (A) (LAVASET) the assignment of higher importance is encompassing the entirety of the ventricle structure. In panel (B), assignments are given in a patch-like manner for RF. Panels (C) and (D) show the points in the 80% quantile from a top view to facilitate the distinction between the inner and outer walls of the ventricle. Panels (E) and (F) show six distinct neighbourhoods of FOIs. In panel (D), convex hulls are drawn for each neighbourhood to represent the pattern of points per neighbourhood. Black points indicate the neighbours and the coloured connecting lines emphasize the different neighbourhoods, and the string-like pattern of neighbour points. Panel (C) shows the feature importance for the respective six neighbourhoods.</p>
        </caption>
        <graphic xlink:href="btae101f4" position="float"/>
      </fig>
      <table-wrap position="float" id="btae101-T1">
        <label>Table 1.</label>
        <caption>
          <p>HCM CMR dataset, feature DR performance.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">LAVASET features</th>
              <th rowspan="1" colspan="1">RF features</th>
              <th rowspan="1" colspan="1">All features</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Accuracy</td>
              <td rowspan="1" colspan="1"><bold>0.890</bold><inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.01</td>
              <td rowspan="1" colspan="1">0.870<inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.002</td>
              <td rowspan="1" colspan="1">0.797<inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.905<inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.005</td>
              <td rowspan="1" colspan="1"><bold>0.913</bold><inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
              <td rowspan="1" colspan="1">0.817<inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.006</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1"><bold>0.859</bold><inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.009</td>
              <td rowspan="1" colspan="1">0.816<inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula> 0.003</td>
              <td rowspan="1" colspan="1">0.763<inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.011</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"><italic toggle="yes">F</italic>1-score</td>
              <td rowspan="1" colspan="1"><bold>0.881</bold><inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.004</td>
              <td rowspan="1" colspan="1">0.862<inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.002</td>
              <td rowspan="1" colspan="1">0.789<inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>0.005</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>Scores for accuracy, precision, recall, and <italic toggle="yes">F</italic>1-score across 20 iterations of UMAP and <italic toggle="yes">k</italic>-means (<italic toggle="yes">k</italic> = 2) on the selected feature sets by importance in LAVASET, RF, and without selection. Values shown are the mean<inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mo>±</mml:mo></mml:math></inline-formula>standard deviation. Values in bold indicate the highest performances for each metric. </p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>We have presented a novel ensemble learning method aimed at datasets with spatial, spectral or temporally dependent relationships between features that enhances variable importance and ensures that correlated features are evaluated appropriately and not independently. LAVASET produces non-inferior performance results to traditional RFs in all but one of the examples tested above, and in both simulated and real datasets. While not sacrificing performance in most examples, it is able to assign feature importances in a superior way, by not missing features that are as ‘important’ by means of correlation, and ensuring that importance values are correctly distributed. One of the advantages of RFs in comparison to other classification methods is its ability to assign feature importances to the original features; here, LAVASET retains this advantage by directly assigning importances to the original feature sets, using the loadings derived from singular vector decomposition to guide the relative importances. In contrast, we have shown that RF allocates feature importance to isolated points, whether that is peak points in a spectrum or points on a 3D mesh, without any clear consistency of the magnitude of importance. Even when substantially increasing the number of trees in RF, the selection of points and assignment of importance are nearly identical to those selected with the lower number of trees, and still do not capture the points selected by LAVASET. In this scenario, Boruta (<xref rid="btae101-B10" ref-type="bibr">Kursa and Rudnicki 2010</xref>) shows results similar to RFs and LAVASET demonstrates improved feature recovery. Other decision forest methods, such as GrandForest (<xref rid="btae101-B11" ref-type="bibr">Larsen <italic toggle="yes">et al.</italic> 2020</xref>) and DFNet (<xref rid="btae101-B16" ref-type="bibr">Pfeifer <italic toggle="yes">et al.</italic> 2022</xref>), that use a graph-structure as input for creating each tree still consider only single features at each split. LAVASET combines correlated features in the splitting step and uses the distance matrix to select the groups of features. When specifying subgraphs for datasets with spatially coherent features, the trees of GrandForest and DFNet will get stuck in local neighbourhoods (both with connected subgraphs and random walks). These methods work better with sparser graphs, hence splitting data further using related features do not add much predictive ability as these features are correlated and the residual of the initial split will not contain much information that can be explained by features correlated to the initial one.</p>
    <p>The motivation behind developing LAVASET stems from the idea of enhancing traditional RFs, in a manner similar to how Group Lasso enhances the Lasso algorithm. In the main premise of Group Lasso, we also assume that there are groups of features that are expected to have similar effects or are related to each other. By penalizing the sum of the absolute values (L1 norm) of the coefficients within each group, Group Lasso encourages the model to select entire groups of features together or exclude them altogether (<xref rid="btae101-B20" ref-type="bibr">Yuan and Lin 2005</xref>). Like in Group Lasso, LAVASET is particularly useful when dealing with high-dimensional data where groups of features exhibit similar importance or are structured in some meaningful way. This was evident by the variety of datasets we tested, where the number of features ranged from 750 to 46K. In this high-dimensional context, LAVASET exhibits stability in its output and remains relatively unaffected by minor variations in the number of neighbours comprising the groups. However, Group Lasso requires non-overlapped groups of features, whereas in LAVASET this can be varied. In fact, in LAVASET, different FOIs can have different numbers of neighbours to increase flexibility. Likewise, LAVASET emulates the kernel filter in convolutional neural networks (CNNs) in that it combines multiple features into a single output (for splitting in LAVASET), however, it does so without condensing the output and attributing the feature importance across the initial features. Other work has investigated the relations between individual features in terms of the similarity of performance at different splits. This methodology is able to discern correlations between individual features, however the mutual forest impact is constrained to evaluating pairs of features only (<xref rid="btae101-B19" ref-type="bibr">Voges <italic toggle="yes">et al.</italic> 2023</xref>). LAVASET can, in theory, be combined with this to perform <italic toggle="yes">a posteriori</italic> analysis of evaluating correlations between groups of latent variables.</p>
    <p>LAVASET’s main limitation derives from the requirement of defining the aforementioned ‘groups’ (akin to the kernel size in CNNs). This parameter is user-specified and assumes an understanding of the relationship between the variables. In the examples presented here, this relationship is defined and assigned by distance, whether that is 1D distance across a spectrum, 1D across time-series data, or 3D spatial distance. The influence of neighbourhood definition is evident, especially in the 3D CMR example. <xref rid="btae101-F4" ref-type="fig">Figure 4F</xref> shows that the string-like pattern of importances calculated by LAVASET is predominantly driven by the assignment of neighbours for each FOI. This inherent limitation, however, is what enables LAVASET’s flexibility in creating the groups of neighbours. Distance is only one of the metrics that can be employed. Other examples include genomic distance (combine SNPs via linkage disequilibrium), mass spectrometry isotope patterns (proteomics and metabolomics), or hierarchical relationships (i.e. taxonomy of microbiota). This renders LAVASET more versatile than other similar methods, while giving the user the ability to tailor the algorithm to their specific needs. Hence, it is applicable to a wide variety of datasets and biological questions.</p>
    <p>This flexibility is also translated to LAVASET’s code implementation. The algorithm also exploits parallelization in order to speed up computations. The body of the code is written in Python 3.10, while utilizing established C++ scripts for efficiency. Given the nature of the code and algorithm, LAVASET can be run in batches, if needed, or can be easily altered to incorporate additional metrics to distance. Moreover, while beyond the scope of this work, there is potential to explore new hybrid methods; e.g. LAVASETs output and the important features can be used to define new regions of latent features which can then be evaluated in terms of their relations with other regions as part of a graph (and used as input to GrandForest and/or DFNet), and also to consider permuted latent features at each split for simultaneous feature selection (as with Boruta). We have not performed hyperparameter optimization in this work (except for determining the optimal number of neighbours) to allow comparing the different methods like-for-like, however, we envision that in future the number of neighbours in LAVASET is considered in a hyperparameter optimization setting alongside the max depth, number of trees, and others.</p>
    <p>To enhance and expand LAVASET’s capabilities, we are working on incorporating the gradient boosting algorithm as one of our built-in additional components. This will extend LAVASET’s core methodology to other ensemble methods and benefit from iterative learning and the specific advantages of boosting trees.</p>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>We have presented LAVASET, a novel ensemble method capable to improve feature interpretability by selecting relevant groups of features instead of individual features. Its novel functionality is most useful in datasets with correlations between features. In cases where this is missing from the data, then traditional RFs are more appropriate. LAVASET offers interoperability to the user both by the structure of its code and via the neighbour’s parameter. It can be applied to almost all omics data types to identify all relevant known or unknown important features and effectively perform feature extraction for DR.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btae101_Supplementary_Data</label>
      <media xlink:href="btae101_supplementary_data.pdf"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank <xref rid="btae101-B13" ref-type="bibr">Mujagic <italic toggle="yes">et al.</italic> (2022)</xref> for providing the raw MIBS cohort NMR data, the DPO’R group for supplying the CMR images, and Sanjay Prasad for the RBH CMR data.</p>
  </ack>
  <sec>
    <title>Author contributions</title>
    <p>Conceptualization: J.M.P. and M.K. Methodology: J.M.P., M.K., and K.X. Investigation: M.K., J.M.P., and K.X. Visualization: M.K. and J.M.P. Writing—original draft: M.K. and J.M.P. Writing—editing: M.K., J.M.P., T.M.D.E., K.X., J.S.W., and D.P.O’R. Supervision: J.M.P., T.M.D.E., and J.S.W.</p>
  </sec>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the UK Biobank Resource [application numbers 47602 to J.S.W., 40616 to D.P.O’R., 18545 to D.P.O’R.]. M.K. is supported by a Wellcome Trust PhD Studentship in Basic Science [220119/Z/20/Z]; J.M.P. is supported by Health Data Research (HDR) UK and the Medical Research Council via a Rutherford Fund Fellowship [MR/S004033/1]; J.S.W. is supported by Medical Research Council (UK), British Heart Foundation [RE/18/4/34215], and the National Institute for Health Research (NIHR) Imperial College Biomedical Research Centre; D.P.O’R. is supported by the Medical Research Council [MC_UP_1605/13], NIHR Imperial College Biomedical Research Centre, and the British Heart Foundation [RG/19/6/34387, RE/18/4/34215]; and T.M.D.E. is supported by UK Research and Innovation (UKRI) Biotechnology and Biological Sciences Research Council (BBSRC) [grants BT/T007974/1, BB/W002345/1] and European Commission (EC) grants [100173062, 101079370]. The views expressed in this work are those of authors and not necessarily those of funders. For the purpose of Open Access, the authors applied a Creative Commons attribution (CC BY) licence to any author accepted manuscript version arising. The data underlying this article are either available in the article and in its online supplementary material or can be shared on request to the corresponding author with permission of the corresponding party.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae101-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bai</surname><given-names>W</given-names></string-name>, <string-name><surname>Sinclair</surname><given-names>M</given-names></string-name>, <string-name><surname>Tarroni</surname><given-names>G</given-names></string-name></person-group><etal>et al</etal><article-title>Automated cardiovascular magnetic resonance image analysis with fully convolutional networks</article-title>. <source>J Cardiovasc Magn Reson</source><year>2018</year>;<volume>20</volume>:<fpage>65</fpage>.<pub-id pub-id-type="pmid">30217194</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bousseljot</surname><given-names>R</given-names></string-name>, <string-name><surname>Kreiseler</surname><given-names>D</given-names></string-name>, <string-name><surname>Schnabel</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Nutzung der EKG-signaldatenbank CARDIODAT der PTB über das internet</article-title>. <source>BMT</source><year>2009</year>;<volume>40</volume>:<fpage>317</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L.</given-names></string-name></person-group><article-title>Random forests</article-title>. <source>Mach Learn</source><year>2001</year>;<volume>45</volume>:<fpage>5</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B4">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Breiman</surname><given-names>L</given-names></string-name>, <string-name><surname>Friedman</surname><given-names>J</given-names></string-name>, <string-name><surname>Olshen</surname><given-names>RA</given-names></string-name></person-group><etal>et al</etal><source>Classification and Regression Trees</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Chapman &amp; Hall</publisher-name>, <year>1984</year>, <fpage>358</fpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Curran</surname><given-names>L</given-names></string-name>, <string-name><surname>de Marvao</surname><given-names>A</given-names></string-name>, <string-name><surname>Inglese</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal> Genotype-phenotype taxonomy of hypertrophic cardiomyopathy. <italic toggle="yes">Circulation: Genomic and Precision Medicine</italic>, <year>2023</year>.</mixed-citation>
    </ref>
    <ref id="btae101-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duan</surname><given-names>J</given-names></string-name>, <string-name><surname>Bello</surname><given-names>G</given-names></string-name>, <string-name><surname>Schlemper</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Automatic 3D bi-ventricular segmentation of cardiac images by a shape-refined multi- task deep learning approach</article-title>. <source>IEEE Trans Med Imaging</source><year>2019</year>;<volume>38</volume>:<fpage>2151</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">30676949</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldberger</surname><given-names>AL</given-names></string-name>, <string-name><surname>Amaral</surname><given-names>LA</given-names></string-name>, <string-name><surname>Glass</surname><given-names>L</given-names></string-name></person-group><etal>et al</etal><article-title>PhysioBank, PhysioToolkit, and PhysioNet</article-title>. <source>Circulation</source><year>2000</year>;<volume>101</volume>:<fpage>E215</fpage>–<lpage>20</lpage>.<pub-id pub-id-type="pmid">10851218</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guyon</surname><given-names>I</given-names></string-name>, <string-name><surname>Weston</surname><given-names>J</given-names></string-name>, <string-name><surname>Barnhill</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Gene selection for cancer classification using support vector machines</article-title>. <source>Mach Learn</source><year>2002</year>;<volume>46</volume>:<fpage>389</fpage>–<lpage>422</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kors</surname><given-names>JA</given-names></string-name>, <string-name><surname>van Herpen</surname><given-names>G</given-names></string-name>, <string-name><surname>Sittig</surname><given-names>AC</given-names></string-name></person-group><etal>et al</etal><article-title>Reconstruction of the frank vectorcardiogram from standard electrocardiographic leads: diagnostic comparison of different methods</article-title>. <source>Eur Heart J</source><year>1990</year>;<volume>11</volume>:<fpage>1083</fpage>–<lpage>92</lpage>.<pub-id pub-id-type="pmid">2292255</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kursa</surname><given-names>MB</given-names></string-name>, <string-name><surname>Rudnicki</surname><given-names>WR.</given-names></string-name></person-group><article-title>Feature selection with the Boruta package</article-title>. <source>J Stat Soft</source><year>2010</year>;<volume>36</volume>:<fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Larsen</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Schmidt</surname><given-names>HH</given-names></string-name>, <string-name><surname>Baumbach</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>De novo and supervised endophenotyping using network-guided ensemble learning</article-title>. <source>Syst Med</source><year>2020</year>;<volume>3</volume>:<fpage>8</fpage>–<lpage>21</lpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McInnes</surname><given-names>L</given-names></string-name>, <string-name><surname>Healy</surname><given-names>J</given-names></string-name>, <string-name><surname>Saul</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>UMAP: uniform manifold approximation and projection</article-title>. <source>JOSS</source><year>2018</year>;<volume>3</volume>:<fpage>861</fpage>.</mixed-citation>
    </ref>
    <ref id="btae101-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mujagic</surname><given-names>Z</given-names></string-name>, <string-name><surname>Kasapi</surname><given-names>M</given-names></string-name>, <string-name><surname>Jonkers</surname><given-names>DM</given-names></string-name></person-group><etal>et al</etal><article-title>Integrated fecal microbiome–metabolome signatures reflect stress and serotonin metabolism in irritable bowel syndrome</article-title>. <source>Gut Microbes</source><year>2022</year>;<volume>14</volume>:<fpage>2063016</fpage>.<pub-id pub-id-type="pmid">35446234</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname><given-names>J-M</given-names></string-name>, <string-name><surname>Jézéquel</surname><given-names>P</given-names></string-name>, <string-name><surname>Gillois</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><article-title>Random forest of perfect trees: concept, performance, applications and perspectives</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>2165</fpage>–<lpage>74</lpage>.<pub-id pub-id-type="pmid">33523112</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nicodemus</surname><given-names>KK</given-names></string-name>, <string-name><surname>Malley</surname><given-names>JD</given-names></string-name>, <string-name><surname>Strobl</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>The behaviour of random forest permutation-based variable importance measures under predictor correlation</article-title>. <source>BMC Bioinformatics</source><year>2010</year>;<volume>11</volume>:<fpage>110</fpage>–<lpage>3</lpage>.<pub-id pub-id-type="pmid">20187966</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pfeifer</surname><given-names>B</given-names></string-name>, <string-name><surname>Baniecki</surname><given-names>H</given-names></string-name>, <string-name><surname>Saranti</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Multi-omics disease module detection with an explainable greedy decision Forest</article-title>. <source>Sci Rep</source><year>2022</year>;<volume>12</volume>:<fpage>16857</fpage>.<pub-id pub-id-type="pmid">36207536</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salek</surname><given-names>RM</given-names></string-name>, <string-name><surname>Maguire</surname><given-names>ML</given-names></string-name>, <string-name><surname>Bentley</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>A metabolomic comparison of urinary changes in type 2 diabetes in mouse, rat, and human</article-title>. <source>Physiol Genomics</source><year>2007</year>;<volume>29</volume>:<fpage>99</fpage>–<lpage>108</lpage>.<pub-id pub-id-type="pmid">17190852</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sudlow</surname><given-names>C</given-names></string-name>, <string-name><surname>Gallacher</surname><given-names>J</given-names></string-name>, <string-name><surname>Allen</surname><given-names>N</given-names></string-name></person-group><etal>et al</etal><article-title>UK biobank: an open access resource for identifying the causes of a wide range of complex diseases of Middle and old age</article-title>. <source>PLoS Med</source><year>2015</year>;<volume>12</volume>:<fpage>e1001779</fpage>.<pub-id pub-id-type="pmid">25826379</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Voges</surname><given-names>LF</given-names></string-name>, <string-name><surname>Jarren</surname><given-names>LC</given-names></string-name>, <string-name><surname>Seifert</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>Exploitation of surrogate variables in random forests for unbiased analysis of mutual impact and importance of features</article-title>. <source>Bioinformatics</source><year>2023</year>;<volume>39</volume>:<fpage>btad471</fpage>.<pub-id pub-id-type="pmid">37522865</pub-id></mixed-citation>
    </ref>
    <ref id="btae101-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname><given-names>M</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Y.</given-names></string-name></person-group><article-title>Model selection and estimation in regression with grouped variables</article-title>. <source>J R Stat Soc Series B Stat Methodol</source><year>2005</year>;<volume>68</volume>:<fpage>49</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
