<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Comput Math Methods Med</journal-id>
    <journal-id journal-id-type="iso-abbrev">Comput Math Methods Med</journal-id>
    <journal-id journal-id-type="publisher-id">cmmm</journal-id>
    <journal-title-group>
      <journal-title>Computational and Mathematical Methods in Medicine</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1748-670X</issn>
    <issn pub-type="epub">1748-6718</issn>
    <publisher>
      <publisher-name>Hindawi</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9110191</article-id>
    <article-id pub-id-type="doi">10.1155/2022/7818480</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Drug-Drug Interactions Prediction Using Fingerprint Only</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4159-4119</contrib-id>
        <name>
          <surname>Ran</surname>
          <given-names>Bing</given-names>
        </name>
        <xref rid="I1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3068-1583</contrib-id>
        <name>
          <surname>Chen</surname>
          <given-names>Lei</given-names>
        </name>
        <email>chen_lei1@163.com</email>
        <xref rid="I1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3626-9066</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Meijing</given-names>
        </name>
        <xref rid="I1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1395-4247</contrib-id>
        <name>
          <surname>Han</surname>
          <given-names>Yujuan</given-names>
        </name>
        <xref rid="I1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2675-6511</contrib-id>
        <name>
          <surname>Dai</surname>
          <given-names>Qi</given-names>
        </name>
        <email>daiqi@zstu.edu.cn</email>
        <xref rid="I2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="I1"><sup>1</sup>College of Information Engineering, Shanghai Maritime University, Shanghai 201306, China</aff>
    <aff id="I2"><sup>2</sup>College of Life Sciences, Zhejiang Sci-Tech University, Hangzhou 310018, China</aff>
    <author-notes>
      <fn fn-type="other">
        <p>Academic Editor: Leyi Wei</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>9</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <volume>2022</volume>
    <elocation-id>7818480</elocation-id>
    <history>
      <date date-type="received">
        <day>16</day>
        <month>3</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Bing Ran et al.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Combination drug therapy is an efficient way to treat complicated diseases. Drug-drug interaction (DDI) is an important research topic in this therapy as patient safety is a problem when two or more drugs are taken at the same time. Traditionally, in vitro experiments and clinical trials are common ways to determine DDIs. However, these methods cannot meet the requirements of large-scale tests. It is an alternative way to develop computational methods for predicting DDIs. Although several previous methods have been proposed, they always need several types of drug information, limiting their applications. In this study, we proposed a simple computational method to predict DDIs. In this method, drugs were represented by their fingerprint features, which are most widely used in investigating drug-related problems. These features were refined by three models, including addition, subtraction, and Hadamard models, to generate the representation of DDIs. The powerful classification algorithm, random forest, was picked up to build the classifier. The results of two types of tenfold cross-validation on the classifier indicated good performance for discovering novel DDIs among known drugs and acceptable performance for identifying DDIs between known drugs and unknown drugs or among unknown drugs. Although the classifier adopted a sample scheme to represent DDIs, it was still superior to other methods, which adopted features generated by some advanced computer algorithms. Furthermore, a user-friendly web-server, named DDIPF (http://106.14.164.77:5004/DDIPF/), was developed to implement the classifier.</p>
    </abstract>
    <funding-group>
      <award-group>
        <funding-source xlink:href="http://dx.doi.org/10.13039/501100001809">National Natural Science Foundation of China</funding-source>
        <award-id>61911540482</award-id>
        <award-id>61772028</award-id>
      </award-group>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>1. Introduction</title>
    <p>Drugs are deemed as an efficient way to treat different diseases. However, some diseases are so complex that it is almost impossible to treat them with a single drug because several targets are involved. In view of this, combination drug therapy is proposed, which can improve drug efficacy and reduce drug resistance [<xref rid="B1" ref-type="bibr">1</xref>]. This method should be carefully used because some drugs can interact with others when they are taken at the same time. These drug-drug interactions (DDIs) may cause a serious problem in patient safety [<xref rid="B2" ref-type="bibr">2</xref>, <xref rid="B3" ref-type="bibr">3</xref>]. On the other hand, the safety problem caused by unexpected DDIs can lead to the withdrawal of drugs from the market, bringing great risks to pharmaceuticals companies. Thus, the correct determination of DDIs is important in the drug research area. Traditional in vitro experiments and clinical trials can solidly complete this task. However, these methods also have some shortcomings, such as low efficiency and high cost. It is necessary to design quick and reliable methods for predicting DDIs.</p>
    <p>In recent years, with the development of high-throughput methods, more and more properties of drugs have been discovered, which are stored in some online databases, such as DrugBank [<xref rid="B4" ref-type="bibr">4</xref>, <xref rid="B5" ref-type="bibr">5</xref>], KEGG [<xref rid="B6" ref-type="bibr">6</xref>], and STITCH [<xref rid="B7" ref-type="bibr">7</xref>]. By analyzing these abundant properties, investigators can discover novel features of drugs. However, how to analyze such huge properties is a problem. Fortunately, lots of newly proposed computer algorithms provide strong technical support. For predicting DDIs, several computational methods have been proposed. Although these methods cannot output assured results, they can provide new clues for discovering novel DDIs. Most computational methods always deeply analyze current known DDIs and form patterns to predict latent DDIs. To date, several types of computer algorithms have been adopted to design quick and reliable methods for predicting DDIs. Among them, machine learning algorithms play essential roles [<xref rid="B8" ref-type="bibr">8</xref>–<xref rid="B13" ref-type="bibr">13</xref>]. For example, Kastrin et al. [<xref rid="B9" ref-type="bibr">9</xref>] designed topological and semantic feature similarities, which were learnt by five classification algorithms to construct the classifier. Cheng and Zhao [<xref rid="B10" ref-type="bibr">10</xref>] set up a support vector machine (SVM) model to predict DDIs, which adopted features derived from the Simplified Molecular Input Line Entry System (SMILES) and side effect similarities of the two drugs. Chen et al. [<xref rid="B11" ref-type="bibr">11</xref>] proposed a nearest neighbor algorithm- (NNA-) based model to identify DDIs, which designed a scheme to measure the similarity of two drug pairs. Besides the machine learning-based methods, several other methods, such as deep learning-based [<xref rid="B14" ref-type="bibr">14</xref>–<xref rid="B17" ref-type="bibr">17</xref>], network-based [<xref rid="B18" ref-type="bibr">18</xref>–<xref rid="B20" ref-type="bibr">20</xref>], and text mining-based [<xref rid="B21" ref-type="bibr">21</xref>–<xref rid="B23" ref-type="bibr">23</xref>], were also proposed to identify DDIs. Most previous methods adopted several types of drug properties, indicating that they cannot provide the result if these properties of the input drug are not available. This fact limits the applications of these methods.</p>
    <p>In this study, we proposed a simple computational method to predict DDIs. For wide applications of the method, drugs were only represented by their fingerprint features, which can be easily obtained if their SMILES formats are available. Based on drug fingerprint features, three models, including addition, subtraction, and Hadamard models, were designed to generate features of each drug pair. The powerful classification algorithm, random forest (RF) [<xref rid="B24" ref-type="bibr">24</xref>], was used to construct the method. After trying all combinations of features produced by three models, we found the classifier using features generated by addition and subtraction models was the best for predicting DDIs among known drugs, and another classifier using features generated by addition and Hadamard models was proper to identify DDIs between known drugs and unknown ones or among unknown drugs. Although the method adopted the generally used fingerprint features, it was superior to some methods, which used some advanced drug features.</p>
  </sec>
  <sec id="sec2">
    <title>2. Materials and Methods</title>
    <sec id="sec2.1">
      <title>2.1. Materials</title>
      <p>The 6185 experimental validated drugs were retrieved from DrugBank (<ext-link xlink:href="https://go.drugbank.com/" ext-link-type="uri">https://go.drugbank.com/</ext-link>) [<xref rid="B4" ref-type="bibr">4</xref>, <xref rid="B5" ref-type="bibr">5</xref>], a public dataset containing information on drugs and drug targets. Because we used fingerprints of drugs to conduct this investigation, drugs that cannot extract their fingerprints were removed, resulting in 6175 drugs. Then, we downloaded the DDIs involving these 6175 drugs from DrugBank, obtaining 37496 DDIs. These DDIs covered 722 drugs. As the obtained DDIs have been solidly validated, they were termed positive samples in this study.</p>
      <p>To construct a binary classifier, negative samples were also necessary. They were produced in the following manner. From the 772 drugs involved in positive samples, randomly pick up two different drugs. If they cannot comprise a positive sample, they were picked up as a negative sample. This procedure was conducted several times until the number of different negative samples was equal to that of positive samples. The obtained negative samples and above-mentioned positive samples were combined to constitute a dataset, denoted by <italic>D</italic>.</p>
    </sec>
    <sec id="sec2.2">
      <title>2.2. Drug Representation with Its Fingerprints</title>
      <p>It is an essential problem to represent drugs with numbers when constructing efficient models for dealing with drug-related problems. The SMILES [<xref rid="B25" ref-type="bibr">25</xref>] format is the most widely accepted scheme to represent a drug. It is a line notation with ASCII strings to represent molecules and reactions. With this representation, the fingerprints can be extracted for a given fingerprint type. Here, we used RDKit (<ext-link xlink:href="http://www.rdkit.org" ext-link-type="uri">http://www.rdkit.org</ext-link>) to extract ECFP_4 fingerprints [<xref rid="B26" ref-type="bibr">26</xref>] for each investigated drug. Generally, the fingerprints of one drug are represented by a binary vector, where each component denotes one fingerprint. The component is set to one if the drug has the corresponding fingerprint of this component. In this way, each of 772 drugs <italic>d</italic> was encoded into a 1024-D vector, formulated by
<disp-formula id="eq1"><label>(1)</label><mml:math id="M1" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mi>F</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
    </sec>
    <sec id="sec2.3">
      <title>2.3. DDI Representation</title>
      <p>For a DDI <italic>D</italic> = [<italic>d</italic><sub>1</sub>, <italic>d</italic><sub>2</sub>], where <italic>d</italic><sub>1</sub> and <italic>d</italic><sub>2</sub> were two drugs, features can be obtained from their fingerprint vectors <italic>F</italic>(<italic>d</italic><sub>1</sub>) and <italic>F</italic>(<italic>d</italic><sub>2</sub>). Since there was no sequence information in the pair of <italic>d</italic><sub>1</sub> and <italic>d</italic><sub>2</sub>, that is, [<italic>d</italic><sub>1</sub>, <italic>d</italic><sub>2</sub>] = [<italic>d</italic><sub>2</sub>, <italic>d</italic><sub>1</sub>], it was not rigorous by directly combining <italic>F</italic>(<italic>d</italic><sub>1</sub>) and <italic>F</italic>(<italic>d</italic><sub>2</sub>) into one vector because it was a problem of which fingerprint vector should be put in the front of the final vector. In view of this, we adopted the following three schemes to fuse two fingerprint vectors into one vector, while the order information was not involved. To give a clear description, let us denote <italic>F</italic>(<italic>d</italic><sub>1</sub>) and <italic>F</italic>(<italic>d</italic><sub>2</sub>) by <italic>F</italic>(<italic>d</italic><sub>1</sub>) = [<italic>f</italic><sub>1</sub><sup>1</sup>, <italic>f</italic><sub>2</sub><sup>1</sup>, ⋯,<italic>f</italic><sub>1024</sub><sup>1</sup>]<sup><italic>T</italic></sup> and <italic>F</italic>(<italic>d</italic><sub>2</sub>) = [<italic>f</italic><sub>1</sub><sup>2</sup>, <italic>f</italic><sub>2</sub><sup>2</sup>, ⋯,<italic>f</italic><sub>1024</sub><sup>2</sup>]<sup><italic>T</italic></sup>, respectively. The first one was the addition model, which fused <italic>F</italic>(<italic>d</italic><sub>1</sub>) and <italic>F</italic>(<italic>d</italic><sub>2</sub>) into a new vector <italic>V</italic><sub><italic>A</italic></sub>(<italic>D</italic>) using the addition operation, formulated by
<disp-formula id="eq2"><label>(2)</label><mml:math id="M2" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>The second scheme was the subtraction model. <italic>F</italic>(<italic>d</italic><sub>1</sub>) and <italic>F</italic>(<italic>d</italic><sub>2</sub>) were fused into a new vector <italic>V</italic><sub><italic>S</italic></sub>(<italic>D</italic>), defined by
<disp-formula id="eq3"><label>(3)</label><mml:math id="M3" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mfenced open="|" close="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mfenced open="|" close="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where |·| represents the absolute operation. The last scheme was the Hadamard model, which fused <italic>F</italic>(<italic>d</italic><sub>1</sub>) and <italic>F</italic>(<italic>d</italic><sub>2</sub>) as follows:
<disp-formula id="eq4"><label>(4)</label><mml:math id="M4" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>1024</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>Through the above three schemes, each DDI can be represented by three vectors. In this study, we would try each combination to represent DDIs, thereby determining the optimum representation for predicting DDIs.</p>
    </sec>
    <sec id="sec2.4">
      <title>2.4. Random Forest</title>
      <p>Besides efficient features, a proper classification algorithm is also important to construct a powerful classifier. In this study, we selected the classic classification algorithm, RF [<xref rid="B24" ref-type="bibr">24</xref>]. Such an algorithm is always a candidate for building models to tackle different biological or medical problems [<xref rid="B27" ref-type="bibr">27</xref>–<xref rid="B32" ref-type="bibr">32</xref>].</p>
      <p>RF is a type of ensemble algorithm, which contains several decision trees. Two random selection procedures are involved to construct each decision tree. The first random selection is for samples. Given a dataset with <italic>n</italic> samples, randomly select <italic>n</italic> samples, with replacement, to constitute a new dataset, based on which a decision tree is built. The second random selection is for features. Selected features are used to split one node to extend the tree. Although the decision tree is a weak classification algorithm, RF is much more powerful [<xref rid="B33" ref-type="bibr">33</xref>].</p>
      <p>This study used the RF program in scikit-learn (<ext-link xlink:href="https://scikit-learn.org/" ext-link-type="uri">https://scikit-learn.org/</ext-link>) [<xref rid="B34" ref-type="bibr">34</xref>]. Default parameters were used to execute such a program. The number of decision trees was 100.</p>
    </sec>
    <sec id="sec2.5">
      <title>2.5. Cross-Validation Method</title>
      <p>Cross-validation [<xref rid="B35" ref-type="bibr">35</xref>] is a widely used scheme to evaluate the performance of classifiers. This study also adopted such a method. Based on the composition of samples in this study, two types of cross-validation were designed to fully evaluate the performance of all constructed classifiers.</p>
      <p>For the first type of cross-validation, DDIs were equally and randomly divided into <italic>K</italic> parts. Each part was singled out one by one to comprise the test dataset and the rest parts were combined to constitute the training dataset. The model based on the training dataset was applied to the test dataset. Accordingly, each DDI was tested exactly once.</p>
      <p>The second type of cross-validation was quite different. It first divided drugs into <italic>K</italic> parts. Each part was singled out one by one to constitute the drug test dataset, whereas drugs in the rest nine parts were combined as the drug training dataset. From the original dataset, three datasets were constructed in this test, called the training dataset, One Drug In Train (ODIT) test dataset, and No Drug In Train (NDIT) test dataset. The training dataset included DDIs such that two drugs were all in the drug training dataset, the ODIT test dataset contained DDIs that one drug was in the drug training dataset and the other drug was in the drug test dataset, and the NDIT test dataset consisted of DDIs that two drugs were all in the drug test dataset. The model constructed on the training dataset was applied to two test datasets.</p>
      <p>For convenience, the first cross-validation was called entire cross-validation, whereas the second one was termed composition cross-validation. The <italic>K</italic> was set to ten. The procedures of these two types of cross-validation are illustrated in <xref rid="fig1" ref-type="fig">Figure 1</xref>.</p>
    </sec>
    <sec id="sec2.6">
      <title>2.6. Performance Measurement</title>
      <p>For a binary classification problem, the predicted results can be counted as four values, including true positive (TP), false positive (FP), true negative (TN), and false negative (FN). In detail, TP/TN represented the number of correctly predicted positive/negative samples, and FN/FP denoted the number of incorrectly predicted positive/negative samples. Based on these values, some measurements can be computed, such as precision, recall, accuracy, F1-measure, and the Mathews correlation coefficient (MCC) [<xref rid="B36" ref-type="bibr">36</xref>]. They can be computed by
<disp-formula id="EEq1"><label>(5)</label><mml:math id="M5" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Precision</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq5"><label>(6)</label><mml:math id="eq5EDAAADACCA" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Recall</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq6"><label>(7)</label><mml:math id="eq6ECAAADACCA" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>TN</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq7"><label>(8)</label><mml:math id="eq7EBAAADACCA" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>F</mml:mtext><mml:mn>1</mml:mn><mml:mo>‐</mml:mo><mml:mtext>measure</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mtext>Precision</mml:mtext><mml:mo>×</mml:mo><mml:mtext>Recall</mml:mtext></mml:mrow><mml:mrow><mml:mtext>Precision</mml:mtext><mml:mo>+</mml:mo><mml:mtext>Recall</mml:mtext></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="EEq2"><label>(9)</label><mml:math id="EEq2EAAAADACCA" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>MCC</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>×</mml:mo><mml:mtext>TN</mml:mtext><mml:mo>‐</mml:mo><mml:mtext>FP</mml:mtext><mml:mo>×</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfenced></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>The first four measurements were between 0 and 1, and high values meant high performance. The last measurement, MCC, ranged between -1 and 1, where 1 indicated perfect prediction and -1 suggested absolute wrong prediction.</p>
      <p>In addition, to fully evaluate the performance of classifiers under different thresholds, the receiver operating characteristic (ROC) and precision-recall (PR) curve analyses were conducted. Given a threshold for predicting positive samples, the true positive rate (TPR) and false positive rate (FPR) can be computed, where TPR was the same as recall and FPR can be computed by
<disp-formula id="eq8"><label>(10)</label><mml:math id="M6" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>FPR</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>FP</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>After setting a series of thresholds, a group of TPR and FPR can be obtained. The ROC curve was plotted by setting TPR as the <italic>y</italic>-axis and FPR as the <italic>x</italic>-axis. The definition of the PR curve was similar to the ROC curve. It set precision as the <italic>y</italic>-axis and recall as the <italic>x</italic>-axis. The areas under these two curves were important measurements to assess the performance of classifiers. They were called AUROC and AUPR in this study.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>3. Results and Discussion</title>
    <p>In this study, a simple classifier using widely used fingerprints of drugs was proposed to predict DDIs. The whole procedure is illustrated in <xref rid="fig2" ref-type="fig">Figure 2</xref>. Here, detailed evaluation results were provided.</p>
    <sec id="sec3.1">
      <title>3.1. Performance of Classifiers under the Entire Tenfold Cross-Validation</title>
      <p>Based on fingerprint features of drugs, three models were designed to generate three feature types of DDIs. By combining one or more feature types produced by different models, seven representations of DDIs were obtained, which were learnt by RF, respectively, to construct RF classifiers. Each classifier was evaluated by the entire tenfold cross-validation. Predicted results were counted as measurements calculated by Equations (<xref rid="EEq1" ref-type="disp-formula">5</xref>)–(<xref rid="EEq2" ref-type="disp-formula">9</xref>), which are listed in <xref rid="tab1" ref-type="table">Table 1</xref>. It can be observed that classifiers using different combinations of feature types almost provided similar performance, except for the classifier using features produced by the Hadamard model. Relatively speaking, the classifier using features generated by addition and subtraction models and the classifiers using features produced by all three models were better than other classifiers. The classifier using features generated by addition and subtraction models provided the highest performance on precision, F1-measure, and MCC, whereas the classifiers using features produced by all three models yielded the best performance on accuracy and recall.</p>
      <p>To further evaluate the performance of the above RF classifiers, the ROC and PR curves for each classifier were plotted, as shown in <xref rid="fig3" ref-type="fig">Figure 3</xref>. The key measurements AUROC and AUPR are also listed in this figure. Evidently, the classifier using features derived from the Hadamard model still provided the lowest AUROC and AUPR, whereas other classifiers yielded similar values on these two measurements. By careful comparisons, the classifier using features generated by addition and subtraction models provided the highest AUROC and AUPR, 0.9629 and 0.9601, respectively. Thus, it is believed that the classifier using features generated by addition and subtraction models was better than the classifier using features produced by all three models.</p>
      <p>With the above arguments, we can construct the RF classifier using features generated by addition and subtraction models to predict DDIs. This classifier provided good performance under the entire tenfold cross-validation. It can be used to discover novel DDIs among known drugs.</p>
    </sec>
    <sec id="sec3.2">
      <title>3.2. Performance of Classifiers under Composition Tenfold Cross-Validation</title>
      <p>In addition to the entire tenfold cross-validation, we also used composition tenfold cross-validation to assess RF classifiers using different combinations of feature types. As this cross-validation test involved two test datasets, including ODIT and NDIT test datasets, two groups of predicted results can be obtained, which are listed in <xref rid="tab2" ref-type="table">Table 2</xref>. For the ODIT test dataset, the classifier using features produced by the Hadamard model was still evidently inferior to other classifiers. However, when adding the features yielded by the addition model, the classifier became much better, which provided the highest accuracy, precision, F1-measure, and MCC. The classifier using features generated by all models produced the highest recall. Accordingly, it can be concluded that the classifier using features obtained by the addition and Hadamard models gave the best performance on the ONIT test dataset. To further confirm this conclusion, the ROC and PR curves of seven classifiers were plotted, as shown in Figures <xref rid="fig4" ref-type="fig">4(a)</xref> and <xref rid="fig4" ref-type="fig">4(b)</xref>. The classifier using features obtained by addition and Hadamard models yielded the highest AUROC (0.9026) and AUPR (0.8890). Thus, this classifier was better than other classifiers under such a test. Furthermore, it is easy to see that all measurements on the ODIT test dataset under the composition tenfold cross-validation were much lower than those under the entire tenfold cross-validation. For example, the MCC decreased by about 8%-20%. As one drug was not included in the training procedures, it was reasonable that the performance declined.</p>
      <p>As for the NDIT test dataset, we also calculated five measurements described in Equations (<xref rid="EEq1" ref-type="disp-formula">5</xref>)–(<xref rid="EEq2" ref-type="disp-formula">9</xref>), which are also listed in <xref rid="tab2" ref-type="table">Table 2</xref>. It can be observed that the highest value for each measurement was dispersive. The classifier using features obtained by addition and Hadamard models yielded the highest accuracy and MCC. Furthermore, from the ROC and PR curves on the NDIT test dataset, shown in Figures <xref rid="fig4" ref-type="fig">4(c)</xref> and <xref rid="fig4" ref-type="fig">4(d)</xref>, such a classifier produced the highest AUROC and second-highest AUPR. Thus, we still concluded that such a classifier was best under such a test. Compared with the predicted results on the ODIT test dataset, those on NDIT were much lower. As two drugs were all not included in the training procedures, the performance was further declined.</p>
      <p>In this section, we tested the classifiers under the composition tenfold cross-validation. Such a test was more rigid than the entire tenfold cross-validation because less information of the test sample was included in the training procedures. With the above arguments, the classifier using features obtained by the addition and Hadamard models was best, which can be a tool for predicting DDIs between known and unknown drugs or among unknown drugs.</p>
    </sec>
    <sec id="sec3.3">
      <title>3.3. Comparison of Classifiers Based on Support Vector Machine</title>
      <p>We used RF to build the classifier for the prediction of DDIs. In fact, another classic classification algorithm, SVM [<xref rid="B37" ref-type="bibr">37</xref>], was also adopted to construct the classifier. The SVM program was also retrieved from scikit-learn. The kernel was a polynomial function, and the regularization parameter <italic>C</italic> was set to one. Here, we would elaborate that RF was more proper to build the efficient classifier.</p>
      <p>For the best RF classifier under the entire tenfold cross-validation, it adopted the features generated by addition and subtraction models. The SVM classifier was also built by learning such representation of DDIs. The entire tenfold cross-validation was used to assess this SVM classifier. Obtained measurements, including accuracy, precision, recall, F1-measure, and MCC, are listed in <xref rid="tab3" ref-type="table">Table 3</xref>. For easy comparison, the measurements yielded by the RF classifier are also provided in this table. It can be observed that the accuracy, precision, recall, and F1-measure were about 7% lower than those of the RF classifier, whereas the MCC was about 15% lower, indicating the superiority of the RF classifier. Furthermore, the ROC and PR curve analyses were also performed for this SVM classifier, as shown in Figures <xref rid="fig5" ref-type="fig">5(a)</xref> and <xref rid="fig5" ref-type="fig">5(b)</xref>. Clearly, the SVM classifier provided lower AUROC and AUPR, further confirming the superiority of the RF classifier.</p>
      <p>As for the best RF classifier under the composition tenfold cross-validation, the features generated by the addition and Hadamard models were used. The SVM classifier was also built on such representation of DDIs and evaluated by composition tenfold cross-validation. The predicted results on ODIT and NDIT test datasets are listed in <xref rid="tab3" ref-type="table">Table 3</xref>. Likewise, the results of the RF classifier are also provided in this table for easy comparison. On the ODIT test dataset, the RF classifier was greatly superior to SVM classifier. All measurements were 10% higher, even 30% higher for MCC. Furthermore, as shown in Figures <xref rid="fig5" ref-type="fig">5(c)</xref> and <xref rid="fig5" ref-type="fig">5(d)</xref>, the ROC and PR curves of the SVM classifier were always under those of the RF classifier, inducing lower AUROC and AUPR. This argument further confirmed the superiority of the RF classifier on the ODIT test dataset. On the NDIT test dataset, the performance of the SVM classifier was also lower than that of the RF classifier. For example, MCC was about 17% lower. However, the inferiority was smaller than that in the above tests. The SVM classifier even provided a higher performance on precision. The ROC and PR curves, shown in Figures <xref rid="fig5" ref-type="fig">5(e)</xref> and <xref rid="fig5" ref-type="fig">5(f)</xref>, display a similar phenomenon, i.e., the SVM classifier yielded lower AUROC and AUPR. Thus, the RF classifier also provided a better performance on the NDIT test dataset than the SVM classifier.</p>
      <p>Based on the above arguments, the RF classifier was always better than the SVM classifier no matter which cross-validation was adopted. It was reasonable to select RF for building the classifier.</p>
    </sec>
    <sec id="sec3.4">
      <title>3.4. Comparison of Classifiers Using Other Drug Features</title>
      <p>Although the proposed RF classifier only adopted the drug fingerprint features, its performance was satisfied. To further elaborate on the utility of such a classifier, some classifiers using other drug features were constructed and compared with our classifier. To distinguish our classifier and other classifiers, we called our classifier a fingerprint-based classifier in this section.</p>
      <p>The fingerprint-based classifier used the features derived from the binary fingerprint features of drugs. It was deemed to be a simple way. Some advanced schemes can be adopted to generate deep features of drugs. Here, we employed the natural language processing (NLP) method to produce drug features. First, 10763 drugs were retrieved from DrugBank, together with their SMILES. Second, the Morgan fingerprints [<xref rid="B26" ref-type="bibr">26</xref>] of these drugs were extracted by RDKit. 26932 substructures were obtained. Third, these substructures were termed words, and each drug was represented by these words. Such representation was fed into a NLP method, Word2vec [<xref rid="B38" ref-type="bibr">38</xref>], to generate the features of substructures. Finally, for a drug, the feature vectors of its substructures were collected, and their average vector was computed as the feature vector of the drug. Such obtained features were called text features. Based on these features, we generated two representations of DDIs. The first representation used the addition and subtraction models, and the second representation adopted the addition and Hadamard models, which were the best models of the fingerprint-based classifier under the entire and composition tenfold cross-validation, respectively. As the text features were not available for some drugs, we excluded these drugs and corresponding DDIs. Accordingly, the new dataset containing 26309 DDIs (positive samples) and the same number of drug pairs (negative samples) was constructed. Two RF classifiers with the above-mentioned two representations of DDIs were built on such dataset and evaluated by the corresponding tenfold cross-validation. These classifiers were called text-based classifiers. Also, fingerprint-based classifiers were also built and compared with text-based classifiers. The performance of fingerprint-based and text-based classifiers is listed in <xref rid="tab4" ref-type="table">Table 4</xref> and <xref rid="fig6" ref-type="fig">Figure 6</xref>. Under the entire tenfold cross-validation, the fingerprint-based classifier provided a much higher performance on all measurements. The same results occurred under the composition tenfold cross-validation on the ODIT test dataset. For the composition tenfold cross-validation on the NDIT test dataset, the fingerprint-based classifier provided higher values on recall, AUROC, and AUPR, but lower values on other measurements, suggesting the equal performance of these two classifiers. On the whole, the fingerprint-based classifier was superior to the text-based classifier. Although the fingerprint-based classifier used the drug features generated in a simple way, its performance was not low at all.</p>
      <p>In recent years, a network is deemed to be a good form to organize research objects. To date, several studies adopted a network to investigate various drug-related problems [<xref rid="B29" ref-type="bibr">29</xref>, <xref rid="B39" ref-type="bibr">39</xref>, <xref rid="B40" ref-type="bibr">40</xref>]. The hidden information in one or more drug networks was quite different from that extracted from a single drug, giving a new view to investigate drugs. Here, we adopted the drug associations reported in STITCH [<xref rid="B41" ref-type="bibr">41</xref>] and KEGG [<xref rid="B42" ref-type="bibr">42</xref>] (SIMCOMP and SUBCOMP [<xref rid="B43" ref-type="bibr">43</xref>]) to construct three drug networks, where 772 drugs were defined as nodes and obtained associations were defined as edges. From these three networks, we adopted the scheme in a well-known network embedding method, Node2vec [<xref rid="B44" ref-type="bibr">44</xref>], to produce lots of paths. These paths were deemed as sentences, and nodes in paths were considered words, which were fed into Word2vec [<xref rid="B38" ref-type="bibr">38</xref>] to generate drug features. These features were called network features. Likewise, not all 772 drugs had network features as some drugs were isolated in all three networks. These drugs were excluded, and corresponding DDIs were also discarded. 3893 DDIs were accessed, which were put into a new dataset as positive samples. We also generated the same number of drug pairs, termed negative samples, and put them into such a new dataset. Then, two RF classifiers were built on such a dataset. One classifier adopted the features of DDIs derived from network features via addition and subtraction models, and the other classifier used the features of DDIs derived from network features using the addition and Hadamard models. The former classifier was evaluated by the entire tenfold cross-validation, and the late one was assessed by the composition tenfold cross-validation. For convenience, these classifiers were called a network-based classifier. For a fair comparison, two fingerprint-based classifiers were also built on the above-mentioned dataset. The performance of fingerprint-based and network-based classifiers is shown in <xref rid="tab5" ref-type="table">Table 5</xref> and <xref rid="fig7" ref-type="fig">Figure 7</xref>. Evidently, the fingerprint-based classifier was superior to the network-based classifier under the entire tenfold cross-validation. For the composition tenfold cross-validation on the ODIT test dataset, we can obtain the same result. As the results of the composition tenfold cross-validation on the NDIT test dataset, the superiority of the fingerprint-based classifier was not very obvious. On some measurements, the network-based classifier provided higher performance. However, this cannot prevent us from reaching the conclusion that the fingerprint-based classifier was superior to the network-based classifier.</p>
      <p>With the above arguments, the fingerprint-based classifier was better than classifiers using features generated by some advanced computational methods. The simple representation scheme of the fingerprint-based classifier not only made the classifier easy to implement but also provided a satisfactory performance.</p>
    </sec>
    <sec id="sec3.5">
      <title>3.5. User Guide of the Web-Server</title>
      <p>In this study, a RF classifier only using drug fingerprint features was proposed to predict DDIs. For wide applications of such a classifier, a web-server, named DDIPF, was set up. Users can access such web-server at <ext-link xlink:href="http://106.14.164.77:5004/DDIPF/" ext-link-type="uri">http://106.14.164.77:5004/DDIPF/</ext-link>. The home page is illustrated in <xref rid="fig8" ref-type="fig">Figure 8</xref>.</p>
      <p>Three tabs “Read Me,” “Supporting Information,” and “Citation” lie at the top of the home page. The basic information of this web-server can be found by clicking the “Read Me” button. Through the “Supporting Information” button, users can download the DDIs (positive samples) used in this study. The reference of this web-server is listed behind the “Citation” button.</p>
      <p>Users can test the interaction probability of two drugs using the following steps:</p>
      <p>Step1: input the SMILES formats of two drugs at the input boxes. Three examples can be found by clicking the “Example” button above the input boxes.</p>
      <p>Step2: select one model or combination of two or more models at the drop-down box beside the “Feature model.” This can determine the representations of input drug pairs.</p>
      <p>Step3: click the “Submit” button to upload the input drug pair.</p>
      <p>Step4: after a few seconds, the probability is displayed in the box beside the “The probability is.” A high probability indicates two input drugs can interact with high likelihood. Users can click the “Clear” button for another input.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>4. Conclusions</title>
    <p>This study proposed a simple classifier to predict drug-drug interactions. The classifier only adopted the widely used fingerprint features of drugs, which induced it to have wider applications than most previous methods. On the other hand, the classifier provided good performance when one or two drugs in the DDI were used in the training procedure, indicating that it can be a latent tool to predict possible drug-drug interactions. However, if two drugs in the DDI were not included in the training procedure, the classifier was not good enough. In the future, we will improve the classifier in this regard. Furthermore, we set up a web-server (<ext-link xlink:href="http://106.14.164.77:5004/DDIPF/" ext-link-type="uri">http://106.14.164.77:5004/DDIPF/</ext-link>). Users can easily test drug pairs through such web-server. We hope this contribution can improve the research on drug-drug interactions.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>This study was supported by the National Natural Science Foundation of China (61772028 and 61911540482).</p>
  </ack>
  <sec sec-type="data-availability">
    <title>Data Availability</title>
    <p>The original data used to support the findings of this study are available in the DrugBank database.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflicts of Interest</title>
    <p>The authors declare that there is no conflict of interest regarding the publication of this paper.</p>
  </sec>
  <ref-list>
    <ref id="B1" content-type="article">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Ahn</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Novel deep learning model for more accurate prediction of drug-drug interaction effects</article-title>
        <source>
          <italic>BMC Bioinformatics</italic>
        </source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>p. 415</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-3013-0</pub-id>
        <pub-id pub-id-type="other">2-s2.0-85070293223</pub-id>
        <?supplied-pmid 31387547?>
        <pub-id pub-id-type="pmid">31387547</pub-id>
      </element-citation>
    </ref>
    <ref id="B2" content-type="article">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Percha</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Altman</surname>
            <given-names>R. B.</given-names>
          </name>
        </person-group>
        <article-title>Informatics confronts drug-drug interactions</article-title>
        <source>
          <italic>Trends in Pharmacological Sciences</italic>
        </source>
        <year>2013</year>
        <volume>34</volume>
        <issue>3</issue>
        <fpage>178</fpage>
        <lpage>184</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tips.2013.01.006</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84874662621</pub-id>
        <?supplied-pmid 23414686?>
        <pub-id pub-id-type="pmid">23414686</pub-id>
      </element-citation>
    </ref>
    <ref id="B3" content-type="article">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Becker</surname>
            <given-names>M. L.</given-names>
          </name>
          <name>
            <surname>Kallewaard</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Caspers</surname>
            <given-names>P. W. J.</given-names>
          </name>
          <name>
            <surname>Visser</surname>
            <given-names>L. E.</given-names>
          </name>
          <name>
            <surname>Leufkens</surname>
            <given-names>H. G. M.</given-names>
          </name>
          <name>
            <surname>Stricker</surname>
            <given-names>B. H. C.</given-names>
          </name>
        </person-group>
        <article-title>Hospitalisations and emergency department visits due to drug–drug interactions: a literature review</article-title>
        <source>
          <italic>Pharmacoepidemiology and Drug Safety</italic>
        </source>
        <year>2007</year>
        <volume>16</volume>
        <issue>6</issue>
        <fpage>641</fpage>
        <lpage>651</lpage>
        <pub-id pub-id-type="doi">10.1002/pds.1351</pub-id>
        <pub-id pub-id-type="other">2-s2.0-34447255458</pub-id>
        <?supplied-pmid 17154346?>
        <pub-id pub-id-type="pmid">17154346</pub-id>
      </element-citation>
    </ref>
    <ref id="B4" content-type="article">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wishart</surname>
            <given-names>D. S.</given-names>
          </name>
          <name>
            <surname>Knox</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>A. C.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DrugBank: a comprehensive resource for in silico drug discovery and exploration</article-title>
        <source>
          <italic>Nucleic Acids Research</italic>
        </source>
        <year>2006</year>
        <volume>34</volume>
        <issue>90001</issue>
        <fpage>D668</fpage>
        <lpage>D672</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkj067</pub-id>
        <?supplied-pmid 16381955?>
        <pub-id pub-id-type="pmid">16381955</pub-id>
      </element-citation>
    </ref>
    <ref id="B5" content-type="article">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wishart</surname>
            <given-names>D. S.</given-names>
          </name>
          <name>
            <surname>Knox</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>A. C.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DrugBank: a knowledgebase for drugs, drug actions and drug targets</article-title>
        <source>
          <italic>Nucleic Acids Research</italic>
        </source>
        <year>2008</year>
        <volume>36</volume>
        <issue>suppl_1</issue>
        <fpage>D901</fpage>
        <lpage>D906</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm958</pub-id>
        <pub-id pub-id-type="other">2-s2.0-38549151817</pub-id>
        <?supplied-pmid 18048412?>
        <pub-id pub-id-type="pmid">18048412</pub-id>
      </element-citation>
    </ref>
    <ref id="B6" content-type="article">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanehisa</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Furumichi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tanabe</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Morishima</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>KEGG: new perspectives on genomes, pathways, diseases and drugs</article-title>
        <source>
          <italic>Nucleic Acids Research</italic>
        </source>
        <year>2017</year>
        <volume>45</volume>
        <issue>D1</issue>
        <fpage>D353</fpage>
        <lpage>D361</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1092</pub-id>
        <pub-id pub-id-type="other">2-s2.0-85016149190</pub-id>
        <pub-id pub-id-type="pmid">27899662</pub-id>
      </element-citation>
    </ref>
    <ref id="B7" content-type="article">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuhn</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Szklarczyk</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pletscher-Frankild</surname>
            <given-names>S.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>STITCH 4: integration of protein–chemical interactions with user data</article-title>
        <source>
          <italic>Nucleic Acids Research</italic>
        </source>
        <year>2014</year>
        <volume>42</volume>
        <issue>D1</issue>
        <fpage>D401</fpage>
        <lpage>D407</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkt1207</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84891781052</pub-id>
        <?supplied-pmid 24293645?>
        <pub-id pub-id-type="pmid">24293645</pub-id>
      </element-citation>
    </ref>
    <ref id="B8" content-type="article">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yan</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>F. X.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>DDIGIP: predicting drug-drug interactions based on Gaussian interaction profile kernels</article-title>
        <source>
          <italic>BMC Bioinformatics</italic>
        </source>
        <year>2019</year>
        <volume>20</volume>
        <issue>S15</issue>
        <fpage>p. 538</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-3093-x</pub-id>
      </element-citation>
    </ref>
    <ref id="B9" content-type="article">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kastrin</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Ferk</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Leskosek</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Predicting potential drug-drug interactions on topological and semantic similarity features using statistical learning</article-title>
        <source>
          <italic>PLoS One</italic>
        </source>
        <year>2018</year>
        <volume>13</volume>
        <issue>5, article e196865</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0196865</pub-id>
        <pub-id pub-id-type="other">2-s2.0-85046698403</pub-id>
      </element-citation>
    </ref>
    <ref id="B10" content-type="article">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>F. X.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Z. M.</given-names>
          </name>
        </person-group>
        <article-title>Machine learning-based prediction of drug-drug interactions by integrating drug phenotypic, therapeutic, chemical, and genomic properties</article-title>
        <source>
          <italic>Journal of the American Medical Informatics Association</italic>
        </source>
        <year>2014</year>
        <volume>21</volume>
        <issue>E2</issue>
        <fpage>E278</fpage>
        <lpage>E286</lpage>
        <pub-id pub-id-type="doi">10.1136/amiajnl-2013-002512</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84908145917</pub-id>
        <?supplied-pmid 24644270?>
        <pub-id pub-id-type="pmid">24644270</pub-id>
      </element-citation>
    </ref>
    <ref id="B11" content-type="article">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Chu</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y. H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Identification of drug-drug interactions using chemical interactions</article-title>
        <source>
          <italic>Current Bioinformatics</italic>
        </source>
        <year>2017</year>
        <volume>12</volume>
        <issue>6</issue>
        <fpage>526</fpage>
        <lpage>534</lpage>
        <pub-id pub-id-type="doi">10.2174/1574893611666160618094219</pub-id>
        <pub-id pub-id-type="other">2-s2.0-85011579957</pub-id>
      </element-citation>
    </ref>
    <ref id="B12" content-type="article">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gottlieb</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Stein</surname>
            <given-names>G. Y.</given-names>
          </name>
          <name>
            <surname>Oron</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Ruppin</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Sharan</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>INDI: a computational framework for inferring drug interactions and their associated recommendations</article-title>
        <source>
          <italic>Molecular Systems Biology</italic>
        </source>
        <year>2012</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>p. 592</fpage>
        <pub-id pub-id-type="doi">10.1038/msb.2012.26</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84864231551</pub-id>
        <?supplied-pmid 22806140?>
        <pub-id pub-id-type="pmid">22806140</pub-id>
      </element-citation>
    </ref>
    <ref id="B13" content-type="article">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cami</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Manzi</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Arnold</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Reis</surname>
            <given-names>B. Y.</given-names>
          </name>
        </person-group>
        <article-title>Pharmacointeraction network models predict unknown drug-drug interactions</article-title>
        <source>
          <italic>PLoS One</italic>
        </source>
        <year>2013</year>
        <volume>8</volume>
        <issue>4, article e61468</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0061468</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84876431695</pub-id>
        <?supplied-pmid 23620757?>
        <pub-id pub-id-type="pmid">23620757</pub-id>
      </element-citation>
    </ref>
    <ref id="B14" content-type="article">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>S. Y.</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>Drug-drug interaction extraction via convolutional neural networks</article-title>
        <source>
          <italic>Computational and Mathematical Methods in Medicine</italic>
        </source>
        <year>2016</year>
        <volume>2016</volume>
        <fpage>8</fpage>
        <pub-id pub-id-type="publisher-id">6918381</pub-id>
        <pub-id pub-id-type="doi">10.1155/2016/6918381</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84959449121</pub-id>
      </element-citation>
    </ref>
    <ref id="B15" content-type="article">
      <label>15</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>L.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Drug-drug interaction extraction via recurrent hybrid convolutional neural networks with an improved focal loss</article-title>
        <source>
          <italic>Entropy</italic>
        </source>
        <year>2019</year>
        <volume>21</volume>
        <issue>1</issue>
        <fpage>p. 37</fpage>
        <pub-id pub-id-type="doi">10.3390/e21010037</pub-id>
        <pub-id pub-id-type="other">2-s2.0-85060395260</pub-id>
        <?supplied-pmid 33266753?>
        <pub-id pub-id-type="pmid">33266753</pub-id>
      </element-citation>
    </ref>
    <ref id="B16" content-type="article">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W.</given-names>
          </name>
        </person-group>
        <article-title>Predicting drug-drug interactions using multi-modal deep auto-encoders based network embedding and positive-unlabeled learning</article-title>
        <source>
          <italic>Methods</italic>
        </source>
        <year>2020</year>
        <volume>179</volume>
        <fpage>37</fpage>
        <lpage>46</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ymeth.2020.05.007</pub-id>
        <?supplied-pmid 32497603?>
        <pub-id pub-id-type="pmid">32497603</pub-id>
      </element-citation>
    </ref>
    <ref id="B17" content-type="article">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fatehifar</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Karshenas</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Drug-drug interaction extraction using a position and similarity fusion-based attention mechanism</article-title>
        <source>
          <italic>Journal of Biomedical Informatics</italic>
        </source>
        <year>2021</year>
        <volume>115</volume>
        <fpage>p. 103707</fpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2021.103707</pub-id>
        <?supplied-pmid 33571676?>
        <pub-id pub-id-type="pmid">33571676</pub-id>
      </element-citation>
    </ref>
    <ref id="B18" content-type="article">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>C. D.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Mei</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>J. D. J.</given-names>
          </name>
        </person-group>
        <article-title>Systematic prediction of pharmacodynamic drug-drug interactions through protein-protein-interaction network</article-title>
        <source>
          <italic>PLoS Computational Biology</italic>
        </source>
        <year>2013</year>
        <volume>9</volume>
        <issue>3, article e1002998</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1002998</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84875992866</pub-id>
        <?supplied-pmid 23555229?>
        <pub-id pub-id-type="pmid">23555229</pub-id>
      </element-citation>
    </ref>
    <ref id="B19" content-type="article">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guimera</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Sales-Pardo</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>A network inference method for large-scale unsupervised identification of novel drug-drug interactions</article-title>
        <source>
          <italic>PLoS Computational Biology</italic>
        </source>
        <year>2013</year>
        <volume>9</volume>
        <issue>12, article e1003374</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003374</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84892778654</pub-id>
        <?supplied-pmid 24339767?>
        <pub-id pub-id-type="pmid">24339767</pub-id>
      </element-citation>
    </ref>
    <ref id="B20" content-type="article">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Takarabe</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Shigemizu</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Kotera</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kanehisa</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Network-based analysis and characterization of adverse drug–drug interactions</article-title>
        <source>
          <italic>Journal of Chemical Information and Modeling</italic>
        </source>
        <year>2011</year>
        <volume>51</volume>
        <issue>11</issue>
        <fpage>2977</fpage>
        <lpage>2985</lpage>
        <pub-id pub-id-type="doi">10.1021/ci200367w</pub-id>
        <pub-id pub-id-type="other">2-s2.0-82355160710</pub-id>
        <?supplied-pmid 21942936?>
        <pub-id pub-id-type="pmid">21942936</pub-id>
      </element-citation>
    </ref>
    <ref id="B21" content-type="article">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>C. B.</given-names>
          </name>
          <name>
            <surname>Kumara</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Semi-supervised learning algorithm for identifying high-priority drug–drug interactions through adverse event reports</article-title>
        <source>
          <italic>IEEE Journal of Biomedical and Health Informatics</italic>
        </source>
        <year>2020</year>
        <volume>24</volume>
        <issue>1</issue>
        <fpage>57</fpage>
        <lpage>68</lpage>
        <pub-id pub-id-type="doi">10.1109/JBHI.2019.2932740</pub-id>
        <?supplied-pmid 31395567?>
        <pub-id pub-id-type="pmid">31395567</pub-id>
      </element-citation>
    </ref>
    <ref id="B22" content-type="article">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Asada</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Miwa</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Sasaki</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Using drug descriptions and molecular structures for drug–drug interaction extraction from literature</article-title>
        <source>
          <italic>Bioinformatics</italic>
        </source>
        <year>2020</year>
        <volume>37</volume>
        <issue>12</issue>
        <fpage>1739</fpage>
        <lpage>1746</lpage>
      </element-citation>
    </ref>
    <ref id="B23" content-type="article">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>KMR: knowledge-oriented medicine representation learning for drug–drug interaction and similarity computation</article-title>
        <source>
          <italic>Journal of Cheminformatics</italic>
        </source>
        <year>2019</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>p. 22</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-019-0342-y</pub-id>
        <?supplied-pmid 30874969?>
        <pub-id pub-id-type="pmid">30874969</pub-id>
      </element-citation>
    </ref>
    <ref id="B24" content-type="article">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>
          <italic>Machine Learning</italic>
        </source>
        <year>2001</year>
        <volume>45</volume>
        <issue>1</issue>
        <fpage>5</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
        <pub-id pub-id-type="other">2-s2.0-0035478854</pub-id>
      </element-citation>
    </ref>
    <ref id="B25" content-type="article">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weininger</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>SMILES, A chemical language and information system. 1. Introduction to methodology and encoding rules</article-title>
        <source>
          <italic>Journal of Chemical Information and Computer Sciences</italic>
        </source>
        <year>1988</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>31</fpage>
        <lpage>36</lpage>
        <pub-id pub-id-type="doi">10.1021/ci00057a005</pub-id>
        <pub-id pub-id-type="other">2-s2.0-0023965741</pub-id>
      </element-citation>
    </ref>
    <ref id="B26" content-type="article">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rogers</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Hahn</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Extended-connectivity fingerprints</article-title>
        <source>
          <italic>Journal of Chemical Information and Modeling</italic>
        </source>
        <year>2010</year>
        <volume>50</volume>
        <issue>5</issue>
        <fpage>742</fpage>
        <lpage>754</lpage>
        <pub-id pub-id-type="doi">10.1021/ci100050t</pub-id>
        <pub-id pub-id-type="other">2-s2.0-77952772341</pub-id>
        <pub-id pub-id-type="pmid">20426451</pub-id>
      </element-citation>
    </ref>
    <ref id="B27" content-type="article">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q.</given-names>
          </name>
        </person-group>
        <article-title>Using recursive feature selection with random forest to improve protein structural class prediction for low-similarity sequences</article-title>
        <source>
          <italic>Computational and Mathematical Methods in Medicine</italic>
        </source>
        <year>2021</year>
        <volume>2021</volume>
        <fpage>9</fpage>
        <pub-id pub-id-type="publisher-id">5529389</pub-id>
        <pub-id pub-id-type="doi">10.1155/2021/5529389</pub-id>
      </element-citation>
    </ref>
    <ref id="B28" content-type="article">
      <label>28</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>Q.</given-names>
          </name>
        </person-group>
        <article-title>iMPT-FDNPL: identification of membrane protein types with functional domains and a natural language processing approach</article-title>
        <source>
          <italic>Computational and Mathematical Methods in Medicine</italic>
        </source>
        <year>2021</year>
        <volume>2021</volume>
        <fpage>10</fpage>
        <pub-id pub-id-type="publisher-id">7681497</pub-id>
        <pub-id pub-id-type="doi">10.1155/2021/7681497</pub-id>
      </element-citation>
    </ref>
    <ref id="B29" content-type="article">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Identification of drug–disease associations by using multiple drug and disease networks</article-title>
        <source>
          <italic>Current Bioinformatics</italic>
        </source>
        <year>2022</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>48</fpage>
        <lpage>59</lpage>
        <pub-id pub-id-type="doi">10.2174/1574893616666210825115406</pub-id>
      </element-citation>
    </ref>
    <ref id="B30" content-type="article">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baranwal</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Magner</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Elvati</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Saldinger</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Violi</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hero</surname>
            <given-names>A. O.</given-names>
          </name>
        </person-group>
        <article-title>A deep learning architecture for metabolic pathway prediction</article-title>
        <source>
          <italic>Bioinformatics</italic>
        </source>
        <year>2020</year>
        <volume>36</volume>
        <issue>8</issue>
        <fpage>2547</fpage>
        <lpage>2553</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz954</pub-id>
        <?supplied-pmid 31879763?>
        <pub-id pub-id-type="pmid">31879763</pub-id>
      </element-citation>
    </ref>
    <ref id="B31" content-type="article">
      <label>31</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Carlos</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zoran</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Juan</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Predicting non-deposition sediment transport in sewer pipes using random forest</article-title>
        <source>
          <italic>Water Research</italic>
        </source>
        <year>2021</year>
        <volume>189</volume>
        <fpage>p. 116639</fpage>
        <pub-id pub-id-type="doi">10.1016/j.watres.2020.116639</pub-id>
      </element-citation>
    </ref>
    <ref id="B32" content-type="article">
      <label>32</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Casanova</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Saldana</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Chew</surname>
            <given-names>E. Y.</given-names>
          </name>
          <name>
            <surname>Danis</surname>
            <given-names>R. P.</given-names>
          </name>
          <name>
            <surname>Greven</surname>
            <given-names>C. M.</given-names>
          </name>
          <name>
            <surname>Ambrosius</surname>
            <given-names>W. T.</given-names>
          </name>
        </person-group>
        <article-title>Application of random forests methods to diabetic retinopathy classification analyses</article-title>
        <source>
          <italic>PLoS One</italic>
        </source>
        <year>2014</year>
        <volume>9</volume>
        <issue>6, article e98587</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0098587</pub-id>
        <pub-id pub-id-type="other">2-s2.0-84903126428</pub-id>
        <?supplied-pmid 24940623?>
        <pub-id pub-id-type="pmid">24940623</pub-id>
      </element-citation>
    </ref>
    <ref id="B33" content-type="article">
      <label>33</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fernandez-Delgado</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Cernadas</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Barro</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Amorim</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Do we need hundreds of classifiers to solve real world classification problems?</article-title>
        <source>
          <italic>Journal of Machine Learning Research</italic>
        </source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>3133</fpage>
        <lpage>3181</lpage>
      </element-citation>
    </ref>
    <ref id="B34" content-type="article">
      <label>34</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: machine learning in python</article-title>
        <source>
          <italic>Journal of Machine Learning Research</italic>
        </source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="B35" content-type="inproceedings">
      <label>35</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Kohavi</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection</article-title>
        <year>1995</year>
        <conf-name>International joint Conference on artificial intelligence</conf-name>
        <publisher-name>Lawrence Erlbaum Associates Ltd.</publisher-name>
      </element-citation>
    </ref>
    <ref id="B36" content-type="article">
      <label>36</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Matthews</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Comparison of the predicted and observed secondary structure of T4 phage lysozyme</article-title>
        <source>
          <italic>Structure</italic>
        </source>
        <year>1975</year>
        <volume>405</volume>
        <issue>2</issue>
        <fpage>442</fpage>
        <lpage>451</lpage>
        <pub-id pub-id-type="doi">10.1016/0005-2795(75)90109-9</pub-id>
        <pub-id pub-id-type="other">2-s2.0-0016772212</pub-id>
      </element-citation>
    </ref>
    <ref id="B37" content-type="article">
      <label>37</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cortes</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Vapnik</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Support-vector networks</article-title>
        <source>
          <italic>Machine Learning</italic>
        </source>
        <year>1995</year>
        <volume>20</volume>
        <issue>3</issue>
        <fpage>273</fpage>
        <lpage>297</lpage>
        <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id>
      </element-citation>
    </ref>
    <ref id="B38" content-type="article">
      <label>38</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Church</surname>
            <given-names>K. W.</given-names>
          </name>
        </person-group>
        <article-title>Word2Vec</article-title>
        <source>
          <italic>Natural Language Engineering</italic>
        </source>
        <year>2017</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>155</fpage>
        <lpage>162</lpage>
        <pub-id pub-id-type="doi">10.1017/S1351324916000334</pub-id>
        <pub-id pub-id-type="other">2-s2.0-85006306812</pub-id>
      </element-citation>
    </ref>
    <ref id="B39" content-type="article">
      <label>39</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A network integration approach for drug-target interaction prediction and computational drug repositioning from heterogeneous information</article-title>
        <source>
          <italic>Nature Communications</italic>
        </source>
        <year>2017</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>p. 573</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-017-00680-8</pub-id>
        <pub-id pub-id-type="other">2-s2.0-85029583555</pub-id>
        <?supplied-pmid 28924171?>
        <pub-id pub-id-type="pmid">28924171</pub-id>
      </element-citation>
    </ref>
    <ref id="B40" content-type="article">
      <label>40</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>J.-P.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>Z.-H.</given-names>
          </name>
        </person-group>
        <article-title>iATC-NRAKEL: an efficient multi-label classifier for recognizing anatomical therapeutic chemical classes of drugs</article-title>
        <source>
          <italic>Bioinformatics</italic>
        </source>
        <year>2020</year>
        <volume>36</volume>
        <issue>5</issue>
        <fpage>1391</fpage>
        <lpage>1396</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz757</pub-id>
        <?supplied-pmid 31593226?>
        <pub-id pub-id-type="pmid">31593226</pub-id>
      </element-citation>
    </ref>
    <ref id="B41" content-type="article">
      <label>41</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuhn</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>von Mering</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Campillos</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Jensen</surname>
            <given-names>L. J.</given-names>
          </name>
          <name>
            <surname>Bork</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>STITCH: interaction networks of chemicals and proteins</article-title>
        <source>
          <italic>Nucleic Acids Research</italic>
        </source>
        <year>2007</year>
        <volume>36</volume>
        <issue>Database</issue>
        <fpage>D684</fpage>
        <lpage>D688</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm795</pub-id>
        <pub-id pub-id-type="other">2-s2.0-38549130733</pub-id>
        <?supplied-pmid 18084021?>
        <pub-id pub-id-type="pmid">18084021</pub-id>
      </element-citation>
    </ref>
    <ref id="B42" content-type="article">
      <label>42</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanehisa</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>KEGG: Kyoto Encyclopedia of Genes and Genomes</article-title>
        <source>
          <italic>Nucleic Acids Research</italic>
        </source>
        <year>2000</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>27</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.27</pub-id>
        <?supplied-pmid 10592173?>
        <pub-id pub-id-type="pmid">10592173</pub-id>
      </element-citation>
    </ref>
    <ref id="B43" content-type="article">
      <label>43</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hattori</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tanaka</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Kanehisa</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Goto</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>SIMCOMP/SUBCOMP: chemical structure search servers for network analyses</article-title>
        <source>
          <italic>Nucleic Acids Research</italic>
        </source>
        <year>2010</year>
        <volume>38</volume>
        <issue>Web Server</issue>
        <fpage>W652</fpage>
        <lpage>W656</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkq367</pub-id>
        <pub-id pub-id-type="other">2-s2.0-77954288984</pub-id>
        <?supplied-pmid 20460463?>
        <pub-id pub-id-type="pmid">20460463</pub-id>
      </element-citation>
    </ref>
    <ref id="B44" content-type="inproceedings">
      <label>44</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Grover</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Leskovec</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>node2vec: scalable feature learning for networks</article-title>
        <conf-name>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</conf-name>
        <conf-date>2016</conf-date>
        <conf-loc>San Francisco, California, USA</conf-loc>
        <fpage>855</fpage>
        <lpage>864</lpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="fig1">
    <label>Figure 1</label>
    <caption>
      <p>Procedures of two types of cross-validation. (a) Entire cross-validation; (b) Composition cross-validation.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.001" position="float"/>
  </fig>
  <fig position="float" id="fig2">
    <label>Figure 2</label>
    <caption>
      <p>Whole construction procedures of the classifier for predicting drug-drug interactions (DDIs). Validated DDIs are retrieved from DrugBank, which are termed positive samples. Drugs involved in positive samples are used to randomly generate negative samples. Drugs are represented by fingerprint features, which are further refined as DDI features using three models. Random forest is adopted to build the classifier, which is evaluated by two types of tenfold cross-validation.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.002" position="float"/>
  </fig>
  <fig position="float" id="fig3">
    <label>Figure 3</label>
    <caption>
      <p>Performance of the classifiers using different combinations of feature types under the entire tenfold cross-validation evaluated by ROC and PR curves. (a) ROC curves. (b) PR curves.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.003" position="float"/>
  </fig>
  <fig position="float" id="fig4">
    <label>Figure 4</label>
    <caption>
      <p>Performance of the classifiers using different combinations of feature types under the composition tenfold cross-validation evaluated by ROC and PR curves. (a) The ROC curves on the ODIT test dataset. (b) The PR curves on the ODIT test dataset. (c) ROC curves on the NDIT test dataset. (d) The PR curves on the NDIT test dataset.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.004" position="float"/>
  </fig>
  <fig position="float" id="fig5">
    <label>Figure 5</label>
    <caption>
      <p>Performance of the RF and SVM classifiers under two types of tenfold cross-validation evaluated by ROC and PR curves. (a) The ROC curve under the entire tenfold cross-validation. (b) The PR curve under the entire tenfold cross-validation. (c) The ROC curve on the ODIT test dataset under the composition tenfold cross-validation. (d) The PR curve on the ODIT test dataset under the composition tenfold cross-validation. (e) The ROC curve on the NDIT test dataset under the composition tenfold cross-validation. (f) The PR curve on the NDIT test dataset under the composition tenfold cross-validation.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.005" position="float"/>
  </fig>
  <fig position="float" id="fig6">
    <label>Figure 6</label>
    <caption>
      <p>Performance of the fingerprint- and text-based classifiers (random forest) under two types of tenfold cross-validation evaluated by the ROC and PR curves. (a) The ROC curve under the entire tenfold cross-validation; (b) the PR curve under the entire tenfold cross-validation; (c) the ROC curve on the ODIT test dataset under the composition tenfold cross-validation; (d) the PR curve on the ODIT test dataset under the composition tenfold cross-validation; (e) the ROC curve on the NDIT test dataset under the composition tenfold cross-validation; (f) the PR curve on the NDIT test dataset under the composition tenfold cross-validation.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.006" position="float"/>
  </fig>
  <fig position="float" id="fig7">
    <label>Figure 7</label>
    <caption>
      <p>Performance of the fingerprint- and network-based classifiers (random forest) under two types of tenfold cross-validation evaluated by the ROC and PR curves. (a) The ROC curve under the entire tenfold cross-validation; (b) the PR curve under the entire tenfold cross-validation; (c) the ROC curve on the ODIT test dataset under the composition tenfold cross-validation; (d) the PR curve on the ODIT test dataset under composition tenfold cross-validation; (e) the ROC curve on the NDIT test dataset under the composition tenfold cross-validation; (f) the PR curve on the NDIT test dataset under the composition tenfold cross-validation.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.007" position="float"/>
  </fig>
  <fig position="float" id="fig8">
    <label>Figure 8</label>
    <caption>
      <p>Homepage of the web-server DDIPF.</p>
    </caption>
    <graphic xlink:href="CMMM2022-7818480.008" position="float"/>
  </fig>
  <table-wrap position="float" id="tab1">
    <label>Table 1</label>
    <caption>
      <p>Performance of RF classifiers with different combinations of feature types under the entire tenfold cross-validation<sup>#</sup>.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Model</th>
          <th align="center" rowspan="1" colspan="1">Accuracy</th>
          <th align="center" rowspan="1" colspan="1">Precision</th>
          <th align="center" rowspan="1" colspan="1">Recall</th>
          <th align="center" rowspan="1" colspan="1">F1-measure</th>
          <th align="center" rowspan="1" colspan="1">MCC<sup>a</sup></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="1" colspan="1">Addition</td>
          <td align="center" rowspan="1" colspan="1">89.26%</td>
          <td align="center" rowspan="1" colspan="1">92.53%</td>
          <td align="center" rowspan="1" colspan="1">86.85%</td>
          <td align="center" rowspan="1" colspan="1">89.60%</td>
          <td align="center" rowspan="1" colspan="1">78.69%</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Subtraction</td>
          <td align="center" rowspan="1" colspan="1">88.84%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>92.31%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">86.32%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>89.22%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">77.88%</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Hadamard</td>
          <td align="center" rowspan="1" colspan="1">73.63%</td>
          <td align="center" rowspan="1" colspan="1">74.71%</td>
          <td align="center" rowspan="1" colspan="1">73.13%</td>
          <td align="center" rowspan="1" colspan="1">73.91%</td>
          <td align="center" rowspan="1" colspan="1">47.27%</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Addition + subtraction</td>
          <td align="center" rowspan="1" colspan="1">89.33%</td>
          <td align="center" rowspan="1" colspan="1">92.70%</td>
          <td align="center" rowspan="1" colspan="1">87.20%</td>
          <td align="center" rowspan="1" colspan="1">89.86%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>79.25%</italic>
          </td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">88.51%</td>
          <td align="center" rowspan="1" colspan="1">92.14%</td>
          <td align="center" rowspan="1" colspan="1">86.64%</td>
          <td align="center" rowspan="1" colspan="1">89.30%</td>
          <td align="center" rowspan="1" colspan="1">78.09%</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Subtraction + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">88.81%</td>
          <td align="center" rowspan="1" colspan="1">92.01%</td>
          <td align="center" rowspan="1" colspan="1">86.48%</td>
          <td align="center" rowspan="1" colspan="1">89.16%</td>
          <td align="center" rowspan="1" colspan="1">77.78%</td>
        </tr>
        <tr>
          <td align="left" rowspan="1" colspan="1">Addition + subtraction + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>89.47%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">92.34%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>87.33%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">89.76%</td>
          <td align="center" rowspan="1" colspan="1">79.08%</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn>
        <p><sup>#</sup>Numbers in italics indicate the highest values in the corresponding column. <sup>a</sup>The Mathews correlation coefficient.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
  <table-wrap position="float" id="tab2">
    <label>Table 2</label>
    <caption>
      <p>Performance of RF classifiers with different combinations of feature types under the composition tenfold cross-validation<sup>#</sup>.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" rowspan="1" colspan="1">Test set</th>
          <th align="center" rowspan="1" colspan="1">Model</th>
          <th align="center" rowspan="1" colspan="1">Accuracy</th>
          <th align="center" rowspan="1" colspan="1">Precision</th>
          <th align="center" rowspan="1" colspan="1">Recall</th>
          <th align="center" rowspan="1" colspan="1">F1-measure</th>
          <th align="center" rowspan="1" colspan="1">MCC<sup>a</sup></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" rowspan="7" colspan="1">ODIT<sup>b</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Addition</td>
          <td align="center" rowspan="1" colspan="1">79.62%</td>
          <td align="center" rowspan="1" colspan="1">74.27%</td>
          <td align="center" rowspan="1" colspan="1">83.18%</td>
          <td align="center" rowspan="1" colspan="1">78.46%</td>
          <td align="center" rowspan="1" colspan="1">59.61%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Subtraction</td>
          <td align="center" rowspan="1" colspan="1">78.60%</td>
          <td align="center" rowspan="1" colspan="1">72.65%</td>
          <td align="center" rowspan="1" colspan="1">82.46%</td>
          <td align="center" rowspan="1" colspan="1">77.23%</td>
          <td align="center" rowspan="1" colspan="1">57.63%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Hadamard</td>
          <td align="center" rowspan="1" colspan="1">69.19%</td>
          <td align="center" rowspan="1" colspan="1">65.84%</td>
          <td align="center" rowspan="1" colspan="1">70.56%</td>
          <td align="center" rowspan="1" colspan="1">68.10%</td>
          <td align="center" rowspan="1" colspan="1">38.49%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Addition + subtraction</td>
          <td align="center" rowspan="1" colspan="1">79.07%</td>
          <td align="center" rowspan="1" colspan="1">72.71%</td>
          <td align="center" rowspan="1" colspan="1">83.32%</td>
          <td align="center" rowspan="1" colspan="1">77.63%</td>
          <td align="center" rowspan="1" colspan="1">58.65%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>79.86%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">
            <italic>75.20%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">82.99%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>78.89%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">
            <italic>60.06%</italic>
          </td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Subtraction + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">79.63%</td>
          <td align="center" rowspan="1" colspan="1">74.74%</td>
          <td align="center" rowspan="1" colspan="1">82.84%</td>
          <td align="center" rowspan="1" colspan="1">78.57%</td>
          <td align="center" rowspan="1" colspan="1">59.56%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Addition + subtraction + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">79.39%</td>
          <td align="center" rowspan="1" colspan="1">73.49%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>83.33%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">78.08%</td>
          <td align="center" rowspan="1" colspan="1">59.21%</td>
        </tr>
        <tr>
          <td align="left" rowspan="7" colspan="1">NDIT<sup>c</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Addition</td>
          <td align="center" rowspan="1" colspan="1">63.58%</td>
          <td align="center" rowspan="1" colspan="1">37.60%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>78.53%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">50.56%</td>
          <td align="center" rowspan="1" colspan="1">31.88%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Subtraction</td>
          <td align="center" rowspan="1" colspan="1">63.56%</td>
          <td align="center" rowspan="1" colspan="1">39.66%</td>
          <td align="center" rowspan="1" colspan="1">76.27%</td>
          <td align="center" rowspan="1" colspan="1">52.01%</td>
          <td align="center" rowspan="1" colspan="1">30.99%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Hadamard</td>
          <td align="center" rowspan="1" colspan="1">62.40%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>54.91%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">64.56%</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>59.21%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">25.15%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Addition + subtraction</td>
          <td align="center" rowspan="1" colspan="1">63.41%</td>
          <td align="center" rowspan="1" colspan="1">37.72%</td>
          <td align="center" rowspan="1" colspan="1">77.78%</td>
          <td align="center" rowspan="1" colspan="1">50.50%</td>
          <td align="center" rowspan="1" colspan="1">31.34%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">
            <italic>64.49%</italic>
          </td>
          <td align="center" rowspan="1" colspan="1">41.56%</td>
          <td align="center" rowspan="1" colspan="1">76.82%</td>
          <td align="center" rowspan="1" colspan="1">53.73%</td>
          <td align="center" rowspan="1" colspan="1">32.64%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Subtraction + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">64.39%</td>
          <td align="center" rowspan="1" colspan="1">42.04%</td>
          <td align="center" rowspan="1" colspan="1">76.18%</td>
          <td align="center" rowspan="1" colspan="1">53.99%</td>
          <td align="center" rowspan="1" colspan="1">32.26%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Addition + subtraction + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">63.92%</td>
          <td align="center" rowspan="1" colspan="1">39.72%</td>
          <td align="center" rowspan="1" colspan="1">77.16%</td>
          <td align="center" rowspan="1" colspan="1">52.21%</td>
          <td align="center" rowspan="1" colspan="1">31.88%</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn>
        <p><sup>#</sup>Numbers in italics indicate the highest values in the corresponding column. <sup>a</sup>MCC: Mathews correlation coefficient. <sup>b</sup>ODIT: One Drug In Train set. <sup>c</sup>NDIT: No Drug In Train set.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
  <table-wrap position="float" id="tab3">
    <label>Table 3</label>
    <caption>
      <p>Comparison of RF and SVM classifiers under the two types of tenfold cross-validation.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" colspan="2" rowspan="1">Cross-validation</th>
          <th align="center" rowspan="1" colspan="1">Classification algorithm</th>
          <th align="center" rowspan="1" colspan="1">Model</th>
          <th align="center" rowspan="1" colspan="1">Accuracy</th>
          <th align="center" rowspan="1" colspan="1">Precision</th>
          <th align="center" rowspan="1" colspan="1">Recall</th>
          <th align="center" rowspan="1" colspan="1">F1-measure</th>
          <th align="center" rowspan="1" colspan="1">MCC<sup>a</sup></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" colspan="2" rowspan="2">Entire tenfold cross-validation</td>
          <td align="center" rowspan="1" colspan="1">Random forest</td>
          <td align="center" rowspan="2" colspan="1">Addition + subtraction</td>
          <td align="center" rowspan="1" colspan="1">89.54%</td>
          <td align="center" rowspan="1" colspan="1">92.70%</td>
          <td align="center" rowspan="1" colspan="1">87.20%</td>
          <td align="center" rowspan="1" colspan="1">89.86%</td>
          <td align="center" rowspan="1" colspan="1">79.25%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Support vector machine</td>
          <td align="center" rowspan="1" colspan="1">81.92%</td>
          <td align="center" rowspan="1" colspan="1">85.92%</td>
          <td align="center" rowspan="1" colspan="1">79.57%</td>
          <td align="center" rowspan="1" colspan="1">82.62%</td>
          <td align="center" rowspan="1" colspan="1">64.06%</td>
        </tr>
        <tr>
          <td align="left" rowspan="4" colspan="1">Composition tenfold cross-validation</td>
          <td align="center" rowspan="2" colspan="1">ODIT<sup>b</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Random forest</td>
          <td align="center" rowspan="2" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">79.86%</td>
          <td align="center" rowspan="1" colspan="1">75.20%</td>
          <td align="center" rowspan="1" colspan="1">82.99%</td>
          <td align="center" rowspan="1" colspan="1">78.89%</td>
          <td align="center" rowspan="1" colspan="1">60.06%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Support vector machine</td>
          <td align="center" rowspan="1" colspan="1">64.65%</td>
          <td align="center" rowspan="1" colspan="1">61.20%</td>
          <td align="center" rowspan="1" colspan="1">65.53%</td>
          <td align="center" rowspan="1" colspan="1">63.06%</td>
          <td align="center" rowspan="1" colspan="1">29.51%</td>
        </tr>
        <tr>
          <td align="center" rowspan="2" colspan="1">NDIT<sup>c</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Random forest</td>
          <td align="center" rowspan="2" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">64.49%</td>
          <td align="center" rowspan="1" colspan="1">41.56%</td>
          <td align="center" rowspan="1" colspan="1">76.82%</td>
          <td align="center" rowspan="1" colspan="1">53.73%</td>
          <td align="center" rowspan="1" colspan="1">32.64%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Support vector machine</td>
          <td align="center" rowspan="1" colspan="1">57.45%</td>
          <td align="center" rowspan="1" colspan="1">48.26%</td>
          <td align="center" rowspan="1" colspan="1">58.41%</td>
          <td align="center" rowspan="1" colspan="1">52.46%</td>
          <td align="center" rowspan="1" colspan="1">15.07%</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn>
        <p><sup>a</sup>MCC: Mathews correlation coefficient. <sup>b</sup>ODIT: One Drug In Train set. <sup>c</sup>NDIT: No Drug In Train set.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
  <table-wrap position="float" id="tab4">
    <label>Table 4</label>
    <caption>
      <p>Comparison of fingerprint- and text-based classifiers under two types of tenfold cross-validation.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" colspan="2" rowspan="1">Cross-validation</th>
          <th align="center" rowspan="1" colspan="1">Classifier</th>
          <th align="center" rowspan="1" colspan="1">Model</th>
          <th align="center" rowspan="1" colspan="1">Accuracy</th>
          <th align="center" rowspan="1" colspan="1">Precision</th>
          <th align="center" rowspan="1" colspan="1">Recall</th>
          <th align="center" rowspan="1" colspan="1">F1-measure</th>
          <th align="center" rowspan="1" colspan="1">MCC<sup>a</sup></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" colspan="2" rowspan="2">Entire tenfold cross-validation</td>
          <td align="center" rowspan="1" colspan="1">Fingerprint-based classifier (random forest)</td>
          <td align="center" rowspan="2" colspan="1">Addition + subtraction</td>
          <td align="center" rowspan="1" colspan="1">89.55%</td>
          <td align="center" rowspan="1" colspan="1">92.25%</td>
          <td align="center" rowspan="1" colspan="1">87.53%</td>
          <td align="center" rowspan="1" colspan="1">89.83%</td>
          <td align="center" rowspan="1" colspan="1">79.23%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Text-based classifier (random forest)</td>
          <td align="center" rowspan="1" colspan="1">84.16%</td>
          <td align="center" rowspan="1" colspan="1">87.52%</td>
          <td align="center" rowspan="1" colspan="1">82.01%</td>
          <td align="center" rowspan="1" colspan="1">84.67%</td>
          <td align="center" rowspan="1" colspan="1">68.48%</td>
        </tr>
        <tr>
          <td align="left" rowspan="4" colspan="1">Composition tenfold cross-validation</td>
          <td align="center" rowspan="2" colspan="1">ODIT<sup>b</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Fingerprint-based classifier (random forest)</td>
          <td align="center" rowspan="2" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">80.01%</td>
          <td align="center" rowspan="1" colspan="1">75.80%</td>
          <td align="center" rowspan="1" colspan="1">82.81%</td>
          <td align="center" rowspan="1" colspan="1">79.07%</td>
          <td align="center" rowspan="1" colspan="1">60.33%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Text-based classifier (random forest)</td>
          <td align="center" rowspan="1" colspan="1">77.55%</td>
          <td align="center" rowspan="1" colspan="1">72.92%</td>
          <td align="center" rowspan="1" colspan="1">80.37%</td>
          <td align="center" rowspan="1" colspan="1">76.42%</td>
          <td align="center" rowspan="1" colspan="1">55.39%</td>
        </tr>
        <tr>
          <td align="center" rowspan="2" colspan="1">NDIT<sup>c</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Fingerprint-based classifier (random forest)</td>
          <td align="center" rowspan="2" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">65.06%</td>
          <td align="center" rowspan="1" colspan="1">42.58%</td>
          <td align="center" rowspan="1" colspan="1">77.55%</td>
          <td align="center" rowspan="1" colspan="1">54.49%</td>
          <td align="center" rowspan="1" colspan="1">33.81%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Text-based classifier (random forest)</td>
          <td align="center" rowspan="1" colspan="1">66.97%</td>
          <td align="center" rowspan="1" colspan="1">54.38%</td>
          <td align="center" rowspan="1" colspan="1">72.80%</td>
          <td align="center" rowspan="1" colspan="1">61.73%</td>
          <td align="center" rowspan="1" colspan="1">35.26%</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn>
        <p><sup>a</sup>Mathews correlation coefficient. <sup>b</sup>ODIT: One Drug In Train set. <sup>c</sup>NDIT: No Drug In Train set.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
  <table-wrap position="float" id="tab5">
    <label>Table 5</label>
    <caption>
      <p>Comparison of fingerprint- and network-based classifiers under two types of tenfold cross-validation.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" colspan="2" rowspan="1">Cross-validation</th>
          <th align="center" rowspan="1" colspan="1">Classifier</th>
          <th align="center" rowspan="1" colspan="1">Model</th>
          <th align="center" rowspan="1" colspan="1">Accuracy</th>
          <th align="center" rowspan="1" colspan="1">Precision</th>
          <th align="center" rowspan="1" colspan="1">Recall</th>
          <th align="center" rowspan="1" colspan="1">F1-measure</th>
          <th align="center" rowspan="1" colspan="1">MCC<sup>a</sup></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" colspan="2" rowspan="2">Entire tenfold cross-validation</td>
          <td align="center" rowspan="1" colspan="1">Fingerprint-based classifier (random forest)</td>
          <td align="center" rowspan="2" colspan="1">Addition + subtraction</td>
          <td align="center" rowspan="1" colspan="1">86.86%</td>
          <td align="center" rowspan="1" colspan="1">89.21%</td>
          <td align="center" rowspan="1" colspan="1">85.23%</td>
          <td align="center" rowspan="1" colspan="1">87.16%</td>
          <td align="center" rowspan="1" colspan="1">73.82%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Network-based classifier (random forest)</td>
          <td align="center" rowspan="1" colspan="1">77.88%</td>
          <td align="center" rowspan="1" colspan="1">77.60%</td>
          <td align="center" rowspan="1" colspan="1">78.06%</td>
          <td align="center" rowspan="1" colspan="1">77.81%</td>
          <td align="center" rowspan="1" colspan="1">55.79%</td>
        </tr>
        <tr>
          <td align="left" rowspan="4" colspan="1">Composition tenfold cross-validation</td>
          <td align="center" rowspan="2" colspan="1">ODIT<sup>b</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Fingerprint-based classifier (random forest)</td>
          <td align="center" rowspan="2" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">74.31%</td>
          <td align="center" rowspan="1" colspan="1">72.43%</td>
          <td align="center" rowspan="1" colspan="1">75.46%</td>
          <td align="center" rowspan="1" colspan="1">73.77%</td>
          <td align="center" rowspan="1" colspan="1">48.83%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Network-based classifier (random forest)</td>
          <td align="center" rowspan="1" colspan="1">70.79%</td>
          <td align="center" rowspan="1" colspan="1">66.72%</td>
          <td align="center" rowspan="1" colspan="1">72.65%</td>
          <td align="center" rowspan="1" colspan="1">69.31%</td>
          <td align="center" rowspan="1" colspan="1">41.94%</td>
        </tr>
        <tr>
          <td align="center" rowspan="2" colspan="1">NDIT<sup>c</sup> test dataset</td>
          <td align="center" rowspan="1" colspan="1">Fingerprint-based classifier (random forest)</td>
          <td align="center" rowspan="2" colspan="1">Addition + Hadamard</td>
          <td align="center" rowspan="1" colspan="1">59.99%</td>
          <td align="center" rowspan="1" colspan="1">33.23%</td>
          <td align="center" rowspan="1" colspan="1">70.80%</td>
          <td align="center" rowspan="1" colspan="1">43.48%</td>
          <td align="center" rowspan="1" colspan="1">23.34%</td>
        </tr>
        <tr>
          <td align="center" rowspan="1" colspan="1">Network-based classifier (random forest)</td>
          <td align="center" rowspan="1" colspan="1">57.53%</td>
          <td align="center" rowspan="1" colspan="1">41.20%</td>
          <td align="center" rowspan="1" colspan="1">62.17%</td>
          <td align="center" rowspan="1" colspan="1">48.49%</td>
          <td align="center" rowspan="1" colspan="1">16.42%</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn>
        <p><sup>a</sup>Mathews Correlation Coefficient. <sup>b</sup>ODIT: One Drug In Train set. <sup>c</sup>NDIT: No Drug In Train set.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
</floats-group>
