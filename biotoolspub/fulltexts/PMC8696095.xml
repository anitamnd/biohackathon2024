<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8696095</article-id>
    <article-id pub-id-type="pmid">34398224</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab545</article-id>
    <article-id pub-id-type="publisher-id">btab545</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepSec: a deep learning framework for secreted protein discovery in human body fluids</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1050-2808</contrib-id>
        <name>
          <surname>Shao</surname>
          <given-names>Dan</given-names>
        </name>
        <aff><institution>Key laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University</institution>, Changchun 130012, <country country="CN">China</country></aff>
        <aff><institution>College of Computer Science and Technology, Changchun University</institution>, Changchun 130022, <country country="CN">China</country></aff>
        <aff><institution>Department of Computer Science and Engineering, University of Nebraska-Lincoln</institution>, Lincoln, NE 68588, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Huang</surname>
          <given-names>Lan</given-names>
        </name>
        <aff><institution>Key laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University</institution>, Changchun 130012, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4751-0708</contrib-id>
        <name>
          <surname>Wang</surname>
          <given-names>Yan</given-names>
        </name>
        <xref rid="btab545-cor1" ref-type="corresp"/>
        <aff><institution>Key laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University</institution>, Changchun 130012, <country country="CN">China</country></aff>
        <aff><institution>School of Artificial Intelligence, Jilin University</institution>, Changchun 130012, <country country="CN">China</country></aff>
        <!--wy6868@jlu.edu.cn-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>He</surname>
          <given-names>Kai</given-names>
        </name>
        <aff><institution>Key laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University</institution>, Changchun 130012, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cui</surname>
          <given-names>Xueteng</given-names>
        </name>
        <aff><institution>College of Computer Science and Technology, Changchun University</institution>, Changchun 130022, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Yao</given-names>
        </name>
        <aff><institution>Key laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University</institution>, Changchun 130012, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ma</surname>
          <given-names>Qin</given-names>
        </name>
        <aff><institution>Department of Biomedical Informatics, College of Medicine, The Ohio State University</institution>, Columbus, OH 43210, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6581-6850</contrib-id>
        <name>
          <surname>Cui</surname>
          <given-names>Juan</given-names>
        </name>
        <xref rid="btab545-cor1" ref-type="corresp"/>
        <!--jcui@unl.edu-->
        <aff><institution>Department of Computer Science and Engineering, University of Nebraska-Lincoln</institution>, Lincoln, NE 68588, <country country="US">USA</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wren</surname>
          <given-names>Jonathan</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab545-cor1">To whom correspondence should be addressed. <email>wy6868@jlu.edu.cn</email> or <email>jcui@unl.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-08-16">
      <day>16</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <volume>38</volume>
    <issue>1</issue>
    <fpage>228</fpage>
    <lpage>235</lpage>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>17</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>15</day>
        <month>7</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>19</day>
        <month>8</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab545.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Human proteins that are secreted into different body fluids from various cells and tissues can be promising disease indicators. Modern proteomics research empowered by both qualitative and quantitative profiling techniques has made great progress in protein discovery in various human fluids. However, due to the large number of proteins and diverse modifications present in the fluids, as well as the existing technical limits of major proteomics platforms (e.g. mass spectrometry), large discrepancies are often generated from different experimental studies. As a result, a comprehensive proteomics landscape across major human fluids are not well determined.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>To bridge this gap, we have developed a deep learning framework, named DeepSec, to identify secreted proteins in 12 types of human body fluids. DeepSec adopts an end-to-end sequence-based approach, where a Convolutional Neural Network is built to learn the abstract sequence features followed by a Bidirectional Gated Recurrent Unit with fully connected layer for protein classification. DeepSec has demonstrated promising performances with average area under the ROC curves of 0.85–0.94 on testing datasets in each type of fluids, which outperforms existing state-of-the-art methods available mostly on blood proteins. As an illustration of how to apply DeepSec in biomarker discovery research, we conducted a case study on kidney cancer by using genomics data from the cancer genome atlas and have identified 104 possible marker proteins.</p>
      </sec>
      <sec id="s3">
        <title>Availability</title>
        <p>DeepSec is available at <ext-link xlink:href="https://bmbl.bmi.osumc.edu/deepsec/" ext-link-type="uri">https://bmbl.bmi.osumc.edu/deepsec/</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62072212</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Development Project of Jilin Province of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>20200401083GX</award-id>
        <award-id>2020C003</award-id>
        <award-id>2020LY500L06</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Guangdong Key Project for Applied Fundamental Research</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2018KZDXM076</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Jilin Province Key Laboratory of Big Data Intelligent Computing</institution>
          </institution-wrap>
        </funding-source>
        <award-id>20180622002JC]</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Human body fluids, such as blood, saliva and urine, are primary clinical specimens, which hold considerable promises in presenting molecular biomarkers for disease diagnosis and therapeutic monitoring (<xref rid="btab545-B2" ref-type="bibr">Anderson, 2010</xref>; <xref rid="btab545-B8" ref-type="bibr">Lathrop <italic toggle="yes">et al.</italic>, 2003</xref>). Since the first study of serum globulin was reported in 1937 (<xref rid="btab545-B18" ref-type="bibr">Tiselius, 1937</xref>), several large-scale research efforts have been made to profile proteomes in various types of human body fluids, mostly in blood, using different proteomic technologies, such as two-dimensional gel electrophoresis (<xref rid="btab545-B11" ref-type="bibr">Margolis and Kenrick, 1969</xref>), mass spectrometry (<xref rid="btab545-B17" ref-type="bibr">Thomson, 1914</xref>) and liquid chromatography (<xref rid="btab545-B25" ref-type="bibr">Zhao and Lin, 2014</xref>). As a result, a large number of protein species were identified in different body fluids, which have been documented in a large volume of research papers and archived in several community-based proteomic databases such as Human Plasma Proteome Project (<xref rid="btab545-B9" ref-type="bibr">Legrain <italic toggle="yes">et al.</italic>, 2011</xref>), Plasma Proteome Database (<xref rid="btab545-B12" ref-type="bibr">Nanjappa <italic toggle="yes">et al.</italic>, 2014</xref>) and Human Plasma PeptideAtlas (<xref rid="btab545-B15" ref-type="bibr">Schwenk <italic toggle="yes">et al.</italic>, 2017</xref>).</p>
    <p>Due to the large complexity of protein content and post-modifications involved in different body fluids, protein identification using conventional proteomics techniques remains a challenging research topic in the past decade. To facilitate this research, several computational attempts have been made to predict secreted proteins in human body fluids, mostly based on machine learning methods, such as Support Vector Machine (SVM) (<xref rid="btab545-B4" ref-type="bibr">Cui <italic toggle="yes">et al.</italic>, 2008</xref>; <xref rid="btab545-B5" ref-type="bibr">Hong <italic toggle="yes">et al.</italic>, 2011</xref>; <xref rid="btab545-B16" ref-type="bibr">Sun <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btab545-B20" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2013</xref>, <xref rid="btab545-B21" ref-type="bibr">2016b</xref>). These models often used common protein features such as amino acid flexibility index, surface tension and solubility as input and predict secreted proteins associated with a specific body fluid. Although the performances of those methods were promising, featured-based models generally suffered from common limitations such as the blind manual collection of features that might be incomplete and biased and feature selection procedures that need manual intervention. To this end, automatic feature extraction using end-to-end model can dispense with the initial feature selection step and possibly improve the prediction performance.</p>
    <p>Deep learning (DL) has been successfully applied in protein research to study new protein functions, structures and interactions (<xref rid="btab545-B7" ref-type="bibr">Jain <italic toggle="yes">et al.</italic>, 2021</xref>). Among different DL models, Convolutional Neural Network (CNN) has been one of the most frequently used methods and has attained remarkable performances in several classification applications, especially when combined with Gated Recurrent Unit (GRU) (<xref rid="btab545-B24" ref-type="bibr">Wilaiprasitporn <italic toggle="yes">et al.</italic>, 2020</xref>). GRU, as a new class of Recurrent Neural Networks (RNNs), can effectviely solve the vanishing gradient problem by introducing memory cells and a gating mechanism for holding information from the prior inputs in a well-behaved way. Compared to Long Short-Term Memory, GRU has a relatively simple structure, which ensures reduced complexity and faster convergence. Recent successes with GRU on the basis of protein sequences include DeepSig (a model to detect signal peptides of proteins) (<xref rid="btab545-B14" ref-type="bibr">Savojardo <italic toggle="yes">et al.</italic>, 2018</xref>) and DeepLoc (a model for predicting protein subcellular localization) (<xref rid="btab545-B3" ref-type="bibr">Armenteros <italic toggle="yes">et al.</italic>, 2017</xref>). The high performances from both studies indicate that protein sequences must carry important characteristics related to protein sorting.</p>
    <p>In this study, we present a new DL-framework, named DeepSec, to facilitate body-fluid secreted protein prediction. DeepSec adopts an end-to-end sequence-based approach and employs CNN as a feature extractor and Bidirectional Gated Recurrent Unit (BGRU) with fully connected dense layer as a classifier to predict secreted proteins. We have employed DeepSec on 12 different types of common human body fluids (one model for each body fluid), which include blood, saliva, urine, cerebrospinal fluid, seminal fluid, amniotic fluid, tear fluid, bronchoalveolar lavage fluid, milk, nipple aspirate fluid, pleural effusion and sputum. At last, we demonstrate possible applications of DeepSec in biomarker discovery by a kidney cancer case study.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>The positive datasets of DeepSec were collected from our previous work (<xref rid="btab545-B6" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2021</xref>). For negative dataset generation, we employed a similar method that is proposed by <xref rid="btab545-B4" ref-type="bibr">Cui <italic toggle="yes">et al.</italic> (2008)</xref>, where the Pfam family annotation was used to select proteins that are potential non-body-fluid-secretory proteins. We chose negative samples from Pfam families (Pfam release 33.1) (<xref rid="btab545-B13" ref-type="bibr">Sara <italic toggle="yes">et al.</italic>, 2018</xref>) which do not contain any proteins in the positive dataset. According to the size of the positive dataset varies in different fluid type, the selection of negative samples is carried out as follows. For a specific body fluid, if the count of positive-related Pfam families is greater than 30% of the total number of human-related Pfam families, all proteins in the remaining Pfam families were collected as the negative set. In contrast, if the count is &lt;30%, we randomly chose one member from each remaining Pfam families to construct the negative data.</p>
      <p>Using the above procedure, we have collected both positive and negative datasets for each of the 12 body fluids (<xref rid="btab545-F1" ref-type="fig">Fig. 1</xref>), including 8203 and 2739 proteins in blood, 4072 and 3291 proteins in saliva, 8048 and 5136 proteins in urine, 6260 and 5787 proteins in cerebrospinal fluid, 5576 and 2624 proteins in seminal fluid, 3212 and 3722 proteins in amniotic fluid, 1490 and 4184 proteins in tear fluid, 1117 and 4436 proteins in bronchoalveolar lavage fluid, 2171 and 3887 proteins in milk, 2234 and 4009 proteins in nipple aspirate fluid, 1373 and 4328 proteins in pleural effusion, and 2341 and 3967 proteins in sputum.</p>
      <fig position="float" id="btab545-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>The distribution of 12 types of body fluids that are analyzed in this study</p>
        </caption>
        <graphic xlink:href="btab545f1" position="float"/>
      </fig>
      <p>Training DL models generally benefits from datasets with a balanced size. To address the imbalance problem, a random under-sampling process is adopted in this study, which is advantageous over the procedure of eliminating proteins from the over-sized larger dataset to match the size of smaller dataset that may lead to information loss. We randomly partitioned the larger dataset into smaller subsets with similar size of the smaller dataset. For a size ratio <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula> between the positive and negative datasets, <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi mathvariant="normal">round</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> subsets are created randomly. Each generated new subset and the original smaller dataset are resampled together to generate independent datasets for model evaluation. At last, bagging algorithm is employed to calculate the overall performance of the model, i.e. the average performance across all sample model denoted as <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfrac bevelled="true"><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo> </mml:mo><mml:mo>≤</mml:mo><mml:mo> </mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> refers to the performance based on one sample set.</p>
      <p>Furthermore, the sample space of each body fluid is divided into training, validation and testing datasets according to the proportion of 60%, 20% and 20%, respectively.</p>
    </sec>
    <sec>
      <title>2.2 Neural network model</title>
      <p>DeepSec takes protein sequences as input and performs a binary classification in terms of secretion into a specific body fluid or not. <xref rid="btab545-F2" ref-type="fig">Figure 2</xref> summarizes the architecture of DeepSec, which comprises three basic components: input sequences, feature extraction and classification.</p>
      <fig position="float" id="btab545-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>The architecture of DeepSec which supports input as PSI-profiles based on protein sequences, feature extraction through CNN, classification based on BGRU with fully connected dense layer, and the outputs as the probability of being secreted protein</p>
        </caption>
        <graphic xlink:href="btab545f2" position="float"/>
      </fig>
      <sec>
        <title>2.2.1 Input sequence generation</title>
        <p>We first create a Position-Specific Score Matrix (PSSM) for each protein sequence to enable subsequent convolution operations. The protein sequence is embodied into a PSSM by position-specific iterative basic local alignment search (PSI-BLAST) (<xref rid="btab545-B1" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic>, 1997</xref>) against UniRef 90 (released in 2020_01) database with inclusion 0.001 and 3 iterations. For each protein with sequence length <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi mathvariant="normal">L</mml:mi></mml:math></inline-formula>, a PSSM of dimensionality <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi mathvariant="normal">L</mml:mi><mml:mo> </mml:mo><mml:mo>×</mml:mo><mml:mo> </mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula> is obtained. The columns of PSSM represent the presence of 20 amino acids in each position. We then transform the PSSM described in <xref rid="btab545-B21" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> (2016a</xref>) by the Sigmoid function <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:math></inline-formula> where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi>x</mml:mi></mml:math></inline-formula> represents a single entry of the PSSM.</p>
        <p>Since variable sequence length [from tens to thousands of amino acids (aa) in this case] represents another challenge for building the prediction model, we decide to use a fixed size (1000aa) window to process protein sequences. It has been shown that N-terminus or C-terminus of the sequence carry the most useful signaling information. For instance, N-terminal modifications have a pivotal role in protein regulation and cellular signaling (<xref rid="btab545-B19" ref-type="bibr">Varland <italic toggle="yes">et al.</italic>, 2015</xref>), and the identity of the C-terminal amino acids has a strong influence on protein expression levels (<xref rid="btab545-B23" ref-type="bibr">Weber <italic toggle="yes">et al.</italic>, 2020</xref>). Therefore, if a protein’s length exceeds 1000, we will keep 500 aa from N-terminus and C-terminus, respectively, and remove the middle sequence. This method of fixed size window has achieved remarkable performances in protein localization prediction (<xref rid="btab545-B3" ref-type="bibr">Armenteros <italic toggle="yes">et al.</italic>, 2017</xref>). In the training dataset, 11.7% of the proteins are truncated using this rule. If a protein sequence is &lt;1000aa, the missing part is filled with 0. As a result, the input representation of each protein is a matrix with size [sequence length (<inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mi>L</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1000</mml:mn></mml:math></inline-formula>) <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mo>×</mml:mo></mml:math></inline-formula> size of amino acid vocabulary (<inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mi>c</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula>)].</p>
      </sec>
      <sec>
        <title>2.2.2 Feature extraction</title>
        <p>To reveal hidden knowledge from the observed PSSM, a CNN model is trained to extract a complex feature representation of the input sequence. Specifically, the input PSSM matrix is fed into CNN to learn the weight parameters of the convolution filters. The filters are set to calculate the feature map <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi mathvariant="normal">C</mml:mi></mml:math></inline-formula>. The convolution layer outputs the matrix inner product between the input matrix and the filters. The rectified linear unit (ReLU) was applied as the activation function to sparsify the output of the convolution layer:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="italic">max</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mi>X</mml:mi></mml:math></inline-formula> is the PSSM matrix, <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula>th the weight matrix of the convolution kernels, <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the offset vector, <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo/><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the results of feature extraction. Then, <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo/><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is used as input to feed into the next layer.</p>
      </sec>
      <sec>
        <title>2.2.3 Classification</title>
        <p>For memorizing the residue presence in the C-terminus and N-terminus, respectively, we use the forwards and backwards GRU to capture possible long-range dependencies between the sequence and the prediction. Bidirectional GRU sweeps from both C-terminus to N-terminus and N-terminus to C-terminus, and concatenates the outputs of individual directions before feeding them into the fully connected layer. The hidden states are updated recursively from the convolutional features and the previous value of the hidden states (<xref rid="btab545-F3" ref-type="fig">Fig. 3</xref>).</p>
        <fig position="float" id="btab545-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>The forwards and backwards GRU capturing possible long-range dependencies between the input sequence and the predicted class</p>
          </caption>
          <graphic xlink:href="btab545f3" position="float"/>
        </fig>
        <p>The recurrent calculation at each sequence position <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula> is denoted as:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>←</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula>
 <disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>⊙</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula>
 <disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula>
 <disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula>
 <disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>σ</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula>where <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mi>c</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the input features of <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mi>c</mml:mi></mml:math></inline-formula> at position <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mi>h</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the hidden states of BGRU, where <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a vector of 2-time size of the number of hidden units in the individual direction GRU, <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula>,<inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula>,<inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula> are the weight metrics and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:math></inline-formula> are the bias. The calculation of <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>←</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is similar to <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mi mathvariant="normal">tanh</mml:mi></mml:math></inline-formula> function is a non-linear activation function taking the form of <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">tan</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>.</p>
        <p>Then, the subsequence classification is performed by a fully connected layer comprised hidden-layers and an output layer. The hidden layer computes a non-linear transformation, defined as follows:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">max</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:mo>μ</mml:mo><mml:mo>+</mml:mo><mml:mo>ν</mml:mo></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mo>μ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mo>ν</mml:mo></mml:math></inline-formula> are the weight vector and bias respectively, <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mi>h</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the learned hidden states of BGRU, ReLU activation is used.</p>
        <p>Finally, the output layer computes the probability distribution <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, defined as follow:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>f</mml:mi><mml:mo>·</mml:mo><mml:mo>γ</mml:mo><mml:mo>+</mml:mo><mml:mo>τ</mml:mo></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mo>γ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mo>τ</mml:mo></mml:math></inline-formula> are the weight vector and the bias respectively, and the function <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mo>σ</mml:mo></mml:math></inline-formula> is the softmax function, denoted as <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mo>σ</mml:mo><mml:msub><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:math></inline-formula>, for <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mi>j</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:math></inline-formula>.</p>
        <p>A cross-entropy loss function is used to quantify how ‘far away’ our prediction is from the ground truth. Network parameters are optimized by minimizing the training errors. The backward pass uses the chain rule to back-propagate error signals and computes gradients with respect to all weights throughout the neural network. Given a training set <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mo>θ</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mo>χ</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mo>χ</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>}</mml:mo></mml:math></inline-formula>, <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of samples and <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mi>y</mml:mi></mml:math></inline-formula> is the true output targets, the cross-entropy loss function is defined as:
<disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mi>L</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>θ</mml:mo></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>-</mml:mo><mml:mo>[</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mi mathvariant="italic">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Performance assessment</title>
      <p>The prediction performance is measured based on both training and validation sets. Specifically, accuracy, Matthew’s correlation coefficient (MCC) and the Area under the ROC Curve (AUC) are applied. Considering the unbalanced cases in this study, we also include additional measures including precision, recall and F-measure. Note that higher values indicate better classification performance for all those measures.</p>
      <p>Accuracy represents how many predictions of the classifier are in fact correct, defined as:
<disp-formula id="E10"><label>(10)</label><mml:math id="M10" display="block" overflow="scroll"><mml:mi mathvariant="normal">Accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mi mathvariant="normal"> </mml:mi></mml:math></disp-formula>where <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mi mathvariant="normal">TP</mml:mi></mml:math></inline-formula> and <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mi mathvariant="normal">TN</mml:mi></mml:math></inline-formula> are the true predictions in positives and negatives, respectively, and <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mi mathvariant="normal">FP</mml:mi></mml:math></inline-formula> and <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mi mathvariant="normal">FN</mml:mi></mml:math></inline-formula> are the false predictions in positives and negatives, respectively.</p>
      <p>Recall (or sensitivity) shows how many positive examples are correctly identified by the classifier. In this case, this is the percentage of secreted proteins identified as such, defined as:
<disp-formula id="E11"><label>(11)</label><mml:math id="M11" display="block" overflow="scroll"><mml:mi mathvariant="italic">Recall</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mi mathvariant="normal"> </mml:mi></mml:math></disp-formula></p>
      <p>Precision represents the proportion of the correctly predicted positive cases relative to all the predicted positive ones. In this case, this is the percentage of proteins identified as secreted proteins that actually secreted proteins, defined as:
<disp-formula id="E12"><label>(12)</label><mml:math id="M12" display="block" overflow="scroll"><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mi mathvariant="normal"> </mml:mi></mml:math></disp-formula></p>
      <p>F-measure is the harmonic mean of precision and recall, and better reflects the performance of a classifier of unbalanced classes, defined as:
<disp-formula id="E13"><label>(13)</label><mml:math id="M13" display="block" overflow="scroll"><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="italic">measure</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">precision</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="italic">recall</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">precision</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">recall</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mi mathvariant="normal"> </mml:mi></mml:math></disp-formula></p>
      <p>MCC is a correlation coefficient between the observed and predicted binary classifications, defined as:
<disp-formula id="E14"><label>(14)</label><mml:math id="M14" display="block" overflow="scroll"><mml:mi mathvariant="italic">MCC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo></mml:msqrt></mml:mrow></mml:mfrac><mml:mi mathvariant="normal"> </mml:mi></mml:math></disp-formula></p>
    </sec>
    <sec>
      <title>2.4 Comparison with other models based on protein features</title>
      <p>Since SVM has been previously applied for secreted protein prediction, we first compare DeepSec with SVM models based on reported protein features. In addition, two other state-of-the-art models, including Decision Tree (DT) and Deep Neural Network (DNN), are benchmarked together with DeepSec. To do this, we use the same datasets to evaluate the performance to ensure a fairy comparison. We examine features used in the previous studies and also add a few newly reported features, which can be grouped into four categories: (i) sequence properties; (ii) physicochemical properties; (iii) domains/motifs properties; and (iv) structural properties. In total, a total of 1610 protein features are collected (as detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). Then, feature selection is performed in a similar workflow as documented in our previous publication (<xref rid="btab545-B6" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2021</xref>), where <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>-test (<inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mi>P</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">value</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>≤</mml:mo><mml:mn>0.005</mml:mn></mml:math></inline-formula>) and false discovery rate (FDR, <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mi>q</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">value</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mo>≤</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula>) are employed to rank the features. The top 50 features are selected into the final model for 12 body fluids, respectively (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>). Feature normalization is performed using Z-score method. Finally, these models are evaluated in terms of accuracy, recall, precision, F-measure, MCC and AUC.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Model performance of DeepSec in 12 types of body fluid</title>
      <p>All classification models on 12 body fluids were built and evaluated using Pytorch 1.7.1, running python 3.8 and using Scikit-learn library version 0.23.2. In DeepSec, the input representation of each protein is a <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mn>1000</mml:mn><mml:mo> </mml:mo><mml:mo>×</mml:mo><mml:mo> </mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula> matrix. Referring to Deeploc (<xref rid="btab545-B3" ref-type="bibr">Armenteros <italic toggle="yes">et al.</italic>, 2017</xref>), our model has 50 filters at the convolution layer with three different sizes <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mi mathvariant="normal">w</mml:mi></mml:math></inline-formula>=<inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mn>7</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>, which has led to a total of 150 filters and <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mn>1000</mml:mn><mml:mo> </mml:mo><mml:mo>×</mml:mo><mml:mo> </mml:mo><mml:mn>150</mml:mn></mml:math></inline-formula> feature maps. Next, GRU scanned the sequence using 32 hidden units in each individual direction, leading to a total of <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mn>1000</mml:mn><mml:mo> </mml:mo><mml:mo>×</mml:mo><mml:mo> </mml:mo><mml:mn>64</mml:mn></mml:math></inline-formula> outputs. The fully connected layer comprised a single hidden-layer with 16 units and an output layer with two units. The parameters were optimized by Adam optimizer with learning rate as 0.0001 and a dropout probability as 0.1 prior to fully connected layer. We chose 0.5 as the prediction threshold, which means that a probability <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mo>≥</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula> indicates a positive class associated with secretion into a specific body fluid. Finally, the performances on 12 body fluids were evaluated based on testing dataset (<xref rid="btab545-T1" ref-type="table">Table 1</xref>) and all datasets (<xref rid="btab545-T2" ref-type="table">Table 2</xref>), respectively.</p>
      <table-wrap position="float" id="btab545-T1">
        <label>Table 1.</label>
        <caption>
          <p>The performance evaluation on 12 body fluids based on testing dataset, grouped by several evaluation measures</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Body fluids</th>
              <th rowspan="1" colspan="1">Accuracy</th>
              <th rowspan="1" colspan="1">Recall</th>
              <th rowspan="1" colspan="1">Precision</th>
              <th rowspan="1" colspan="1">F-measure</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">AUC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Blood</td>
              <td rowspan="1" colspan="1">
                <bold>0.871139</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.872120</bold>
              </td>
              <td rowspan="1" colspan="1">0.868200</td>
              <td rowspan="1" colspan="1">
                <bold>0.910294</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.691481</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.940572</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Saliva</td>
              <td rowspan="1" colspan="1">0.824650</td>
              <td rowspan="1" colspan="1">0.810522</td>
              <td rowspan="1" colspan="1">0.835108</td>
              <td rowspan="1" colspan="1">0.797251</td>
              <td rowspan="1" colspan="1">0.643117</td>
              <td rowspan="1" colspan="1">0.898319</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Urine</td>
              <td rowspan="1" colspan="1">0.845857</td>
              <td rowspan="1" colspan="1">0.805017</td>
              <td rowspan="1" colspan="1">0.883817</td>
              <td rowspan="1" colspan="1">0.834207</td>
              <td rowspan="1" colspan="1">0.692125</td>
              <td rowspan="1" colspan="1">0.918341</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Cerebrospinal fluid</td>
              <td rowspan="1" colspan="1">0.835470</td>
              <td rowspan="1" colspan="1">0.667881</td>
              <td rowspan="1" colspan="1">0.931376</td>
              <td rowspan="1" colspan="1">0.747156</td>
              <td rowspan="1" colspan="1">0.637556</td>
              <td rowspan="1" colspan="1">0.900955</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Seminal fluid</td>
              <td rowspan="1" colspan="1">0.821891</td>
              <td rowspan="1" colspan="1">0.834073</td>
              <td rowspan="1" colspan="1">
                <underline>0.810378</underline>
              </td>
              <td rowspan="1" colspan="1">0.819841</td>
              <td rowspan="1" colspan="1">0.644204</td>
              <td rowspan="1" colspan="1">0.894597</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Amniotic fluid</td>
              <td rowspan="1" colspan="1">0.828476</td>
              <td rowspan="1" colspan="1">0.747795</td>
              <td rowspan="1" colspan="1">0.889995</td>
              <td rowspan="1" colspan="1">0.790455</td>
              <td rowspan="1" colspan="1">0.649091</td>
              <td rowspan="1" colspan="1">0.905148</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Tear fluid</td>
              <td rowspan="1" colspan="1">0.830080</td>
              <td rowspan="1" colspan="1">0.572529</td>
              <td rowspan="1" colspan="1">0.926077</td>
              <td rowspan="1" colspan="1">0.646611</td>
              <td rowspan="1" colspan="1">0.545096</td>
              <td rowspan="1" colspan="1">0.856645</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Bronchoalveolar lavage fluid</td>
              <td rowspan="1" colspan="1">0.859257</td>
              <td rowspan="1" colspan="1">
                <underline>0.432043</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.966373</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>0.551724</underline>
              </td>
              <td rowspan="1" colspan="1">
                <underline>0.502859</underline>
              </td>
              <td rowspan="1" colspan="1">0.857458</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Milk</td>
              <td rowspan="1" colspan="1">
                <underline>0.811124</underline>
              </td>
              <td rowspan="1" colspan="1">0.677016</td>
              <td rowspan="1" colspan="1">0.885655</td>
              <td rowspan="1" colspan="1">0.719173</td>
              <td rowspan="1" colspan="1">0.580265</td>
              <td rowspan="1" colspan="1">0.871808</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Nipple aspirate fluid</td>
              <td rowspan="1" colspan="1">0.816795</td>
              <td rowspan="1" colspan="1">0.565002</td>
              <td rowspan="1" colspan="1">0.956554</td>
              <td rowspan="1" colspan="1">0.687654</td>
              <td rowspan="1" colspan="1">0.594120</td>
              <td rowspan="1" colspan="1">0.887423</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pleural effusion</td>
              <td rowspan="1" colspan="1">0.837814</td>
              <td rowspan="1" colspan="1">0.571637</td>
              <td rowspan="1" colspan="1">0.922045</td>
              <td rowspan="1" colspan="1">0.62887</td>
              <td rowspan="1" colspan="1">0.530781</td>
              <td rowspan="1" colspan="1">
                <underline>0.848811</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Sputum</td>
              <td rowspan="1" colspan="1">0.823529</td>
              <td rowspan="1" colspan="1">0.822089</td>
              <td rowspan="1" colspan="1">0.824375</td>
              <td rowspan="1" colspan="1">0.775122</td>
              <td rowspan="1" colspan="1">0.633483</td>
              <td rowspan="1" colspan="1">0.891406</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: The highest scores are in bold, and the lowest scores are underlined.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap position="float" id="btab545-T2">
        <label>Table 2.</label>
        <caption>
          <p>The performance evaluation on 12 kinds of body fluids based on all datasets, grouped by different evaluation measures</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Body fluids</th>
              <th rowspan="1" colspan="1">Accuracy</th>
              <th rowspan="1" colspan="1">Recall</th>
              <th rowspan="1" colspan="1">Precision</th>
              <th rowspan="1" colspan="1">F-measure</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">AUC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Blood</td>
              <td rowspan="1" colspan="1">
                <bold>0.871345</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.887427</bold>
              </td>
              <td rowspan="1" colspan="1">0.855263</td>
              <td rowspan="1" colspan="1">
                <bold>0.873381</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.743075</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.941104</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Saliva</td>
              <td rowspan="1" colspan="1">0.769029</td>
              <td rowspan="1" colspan="1">0.666667</td>
              <td rowspan="1" colspan="1">0.844749</td>
              <td rowspan="1" colspan="1">0.710526</td>
              <td rowspan="1" colspan="1">0.522890</td>
              <td rowspan="1" colspan="1">0.855485</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Urine</td>
              <td rowspan="1" colspan="1">0.825711</td>
              <td rowspan="1" colspan="1">0.810127</td>
              <td rowspan="1" colspan="1">0.840196</td>
              <td rowspan="1" colspan="1">0.817456</td>
              <td rowspan="1" colspan="1">0.650832</td>
              <td rowspan="1" colspan="1">0.899171</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Cerebrospinal fluid</td>
              <td rowspan="1" colspan="1">0.819790</td>
              <td rowspan="1" colspan="1">0.700608</td>
              <td rowspan="1" colspan="1">0.887924</td>
              <td rowspan="1" colspan="1">0.738782</td>
              <td rowspan="1" colspan="1">0.603938</td>
              <td rowspan="1" colspan="1">0.869243</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Seminal fluid</td>
              <td rowspan="1" colspan="1">0.782139</td>
              <td rowspan="1" colspan="1">0.802020</td>
              <td rowspan="1" colspan="1">
                <underline>0.763359</underline>
              </td>
              <td rowspan="1" colspan="1">0.781496</td>
              <td rowspan="1" colspan="1">0.565294</td>
              <td rowspan="1" colspan="1">0.853547</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Amniotic fluid</td>
              <td rowspan="1" colspan="1">0.806870</td>
              <td rowspan="1" colspan="1">0.839506</td>
              <td rowspan="1" colspan="1">0.781965</td>
              <td rowspan="1" colspan="1">0.790041</td>
              <td rowspan="1" colspan="1">0.616044</td>
              <td rowspan="1" colspan="1">0.893354</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Tear fluid</td>
              <td rowspan="1" colspan="1">0.800349</td>
              <td rowspan="1" colspan="1">0.443730</td>
              <td rowspan="1" colspan="1">0.933014</td>
              <td rowspan="1" colspan="1">0.546535</td>
              <td rowspan="1" colspan="1">0.446769</td>
              <td rowspan="1" colspan="1">
                <underline>0.793570</underline>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Bronchoalveolar lavage fluid</td>
              <td rowspan="1" colspan="1">0.832130</td>
              <td rowspan="1" colspan="1">
                <underline>0.364865</underline>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.949210</bold>
              </td>
              <td rowspan="1" colspan="1">
                <underline>0.465517</underline>
              </td>
              <td rowspan="1" colspan="1">
                <underline>0.395991</underline>
              </td>
              <td rowspan="1" colspan="1">0.792717</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Milk</td>
              <td rowspan="1" colspan="1">
                <underline>0.766363</underline>
              </td>
              <td rowspan="1" colspan="1">0.661253</td>
              <td rowspan="1" colspan="1">0.824742</td>
              <td rowspan="1" colspan="1">0.669014</td>
              <td rowspan="1" colspan="1">0.488595</td>
              <td rowspan="1" colspan="1">0.810696</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Nipple aspirate fluid</td>
              <td rowspan="1" colspan="1">0.787149</td>
              <td rowspan="1" colspan="1">0.592342</td>
              <td rowspan="1" colspan="1">0.895131</td>
              <td rowspan="1" colspan="1">0.664981</td>
              <td rowspan="1" colspan="1">0.520782</td>
              <td rowspan="1" colspan="1">0.837818</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pleural effusion</td>
              <td rowspan="1" colspan="1">0.824978</td>
              <td rowspan="1" colspan="1">0.439560</td>
              <td rowspan="1" colspan="1">0.946759</td>
              <td rowspan="1" colspan="1">0.546697</td>
              <td rowspan="1" colspan="1">0.467328</td>
              <td rowspan="1" colspan="1">0.823116</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Sputum</td>
              <td rowspan="1" colspan="1">0.781225</td>
              <td rowspan="1" colspan="1">0.759140</td>
              <td rowspan="1" colspan="1">0.794192</td>
              <td rowspan="1" colspan="1">0.719674</td>
              <td rowspan="1" colspan="1">0.543051</td>
              <td rowspan="1" colspan="1">0.849145</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic toggle="yes">Note</italic>: The highest scores are in bold, and the lowest scores are underlined.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We have applied DeepSec to screen against all human proteins (20 394 unique proteins) in the UniProtKB/Swiss-Prot database (UniProt release 2020_06) in each of body fluids. As shown in <xref rid="btab545-F4" ref-type="fig">Figure 4</xref>, DeepSec predicted 12 364 proteins (60.6% of the 20 394) as blood-secreted proteins, and 9491 (46.5%), 6877 (33.7%) and 6713 (32.9%) proteins to be secreted into urine, cerebrospinal fluid and saliva, respectively.</p>
      <fig position="float" id="btab545-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Results of predicted human proteins secreted in 12 body fluids by screening against all human proteins reported in Swiss-Prot. The orange bar depicts number of predicted proteins against all human proteins in Swiss-Prot and blue bar depicts the experimental identified proteins</p>
        </caption>
        <graphic xlink:href="btab545f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 DeepSec outperforms feature-based classifiers</title>
      <p>We compared the performances between the DeepSec model and aforementioned feature-based models based on average AUC on testing datasets. Here the feature-based DT model, SVM model and DNN model are termed DTf, SVMf and DNNf, respectively. As shown in <xref rid="btab545-F5" ref-type="fig">Figure 5</xref>, for all 12 fluid types, DeepSec reported the best performances with average AUC ranged in 0.85–0.94. Especially, DeepSec was 4–17% higher than other models.</p>
      <fig position="float" id="btab545-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>The ROC curves for body-fluid protein prediction differentiation of DeepSec versus other models in 12 kinds of body fluids on testing datasets</p>
        </caption>
        <graphic xlink:href="btab545f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 A close-look at the blood secreted protein prediction</title>
      <p>In the blood protein case, the positive dataset consists of 8203 proteins while 2739 human proteins were generated in negative dataset. Considering the count ratio (<inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula>) between positive and negative dataset is <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mi mathvariant="normal">round</mml:mi><mml:mfenced open="（" close="）" separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mn>8203</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>2739</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:math></inline-formula>, we repeated <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mn>3</mml:mn></mml:math></inline-formula> times the random sampling processing and obtained 3 positive subsets. In the end, three datasets, each containing 2734 positive samples and 2739 negative samples, were used to train and evaluate DeepSec classifier.</p>
      <p>To select the most appropriate model, we compared different model architectures including CNN, BGRU and DeepSec. Each model architecture was evaluated based on testing dataset and all datasets in terms of accuracy, recall, precision, F-measure, MCC and AUC (<xref rid="btab545-T3" ref-type="table">Table 3</xref>). The average ROCs are plotted in <xref rid="btab545-F6" ref-type="fig">Figure 6</xref>. Note that DeepSec classifier achieved the highest overall performance on both testing dataset (average AUC: 0.94) and all datasets (average AUC: 0.94), respectively. In the meantime, it also attained the highest average values of accuracy (0.87/0.87), F-measure (0.91/0.87) and MCC (0.69/0.74) on testing dataset and all datasets.</p>
      <fig position="float" id="btab545-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>The ROC curves of various model architectures. (<bold>a</bold>) Evaluation on testing dataset. (<bold>b</bold>) Evaluation on all datasets</p>
        </caption>
        <graphic xlink:href="btab545f6" position="float"/>
      </fig>
      <table-wrap position="float" id="btab545-T3">
        <label>Table 3.</label>
        <caption>
          <p>Prediction performance of various model architectures evaluated based on testing dataset and all datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Measures</th>
              <th colspan="3" rowspan="1">Testing dataset<hr/></th>
              <th colspan="3" rowspan="1">All datasets<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">BGRU</th>
              <th rowspan="1" colspan="1">DeepSec</th>
              <th rowspan="1" colspan="1">CNN</th>
              <th rowspan="1" colspan="1">BGRU</th>
              <th rowspan="1" colspan="1">DeepSec</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Accuracy</td>
              <td rowspan="1" colspan="1">0.806068</td>
              <td rowspan="1" colspan="1">0.855145</td>
              <td rowspan="1" colspan="1">
                <bold>0.871139</bold>
              </td>
              <td rowspan="1" colspan="1">0.825292</td>
              <td rowspan="1" colspan="1">0.811404</td>
              <td rowspan="1" colspan="1">
                <bold>0.871345</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">0.782884</td>
              <td rowspan="1" colspan="1">
                <bold>0.911252</bold>
              </td>
              <td rowspan="1" colspan="1">0.872120</td>
              <td rowspan="1" colspan="1">0.777778</td>
              <td rowspan="1" colspan="1">
                <bold>0.931287</bold>
              </td>
              <td rowspan="1" colspan="1">0.887427</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">
                <bold>0.875502</bold>
              </td>
              <td rowspan="1" colspan="1">0.687112</td>
              <td rowspan="1" colspan="1">0.868200</td>
              <td rowspan="1" colspan="1">
                <bold>0.872807</bold>
              </td>
              <td rowspan="1" colspan="1">0.691520</td>
              <td rowspan="1" colspan="1">0.855263</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F-measure</td>
              <td rowspan="1" colspan="1">0.858212</td>
              <td rowspan="1" colspan="1">0.904143</td>
              <td rowspan="1" colspan="1">
                <bold>0.910294</bold>
              </td>
              <td rowspan="1" colspan="1">0.816577</td>
              <td rowspan="1" colspan="1">0.831593</td>
              <td rowspan="1" colspan="1">
                <bold>0.873381</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MCC</td>
              <td rowspan="1" colspan="1">0.587026</td>
              <td rowspan="1" colspan="1">0.608209</td>
              <td rowspan="1" colspan="1">
                <bold>0.691481</bold>
              </td>
              <td rowspan="1" colspan="1">0.653542</td>
              <td rowspan="1" colspan="1">0.64152</td>
              <td rowspan="1" colspan="1">
                <bold>0.743075</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AUC</td>
              <td rowspan="1" colspan="1">0.912392</td>
              <td rowspan="1" colspan="1">0.897955</td>
              <td rowspan="1" colspan="1">
                <bold>0.940572</bold>
              </td>
              <td rowspan="1" colspan="1">0.906867</td>
              <td rowspan="1" colspan="1">0.903960</td>
              <td rowspan="1" colspan="1">
                <bold>0.941104</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic toggle="yes">Note</italic>: The highest scores are in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The results showed that the DeepSec model is more effective in capturing sequence information for predicting secreted proteins and reveals relationships between amino acid sequences and secretion status. This is not surprising as BGRU is capable of learning long-term dependencies between sequence and secreted proteins, which may contribute to an improved performance by updating the weight of each hidden state.</p>
    </sec>
  </sec>
  <sec>
    <title>4 An application case study on kidney cancer biomarker discovery</title>
    <p>To illustrate possible applications of DeepSec, we explored potential kidney cancer biomarkers in blood by using public genomics data and DeepSec prediction. To do that, we first collected gene expression profiles of 72 paired kidney cancer tissues and adjacent control tissues samples from kidney renal clear cell carcinoma (KIRC) via the cancer genome atlas (TCGA) Data Portal. Each gene-expression dataset covered 19 804 human genes measured using RNA-seq. Note the paired samples helps reduce the impact of individual variability in differential expression analysis.</p>
    <p>Two-tailed <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mi mathvariant="normal">t</mml:mi></mml:math></inline-formula>-test (<xref rid="btab545-B10" ref-type="bibr">Liang <italic toggle="yes">et al.</italic>, 2019</xref>) was performed to identify genes that have significant differential expression between kidney cancer and control samples. The test statistic <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for the <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>th feature between case and control is given by
<disp-formula id="E15"><label>(15)</label><mml:math id="M15" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean difference and the standard error of the <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>th feature across <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mi mathvariant="normal">n</mml:mi></mml:math></inline-formula> paired samples, denoted as
<disp-formula id="E16"><label>(16)</label><mml:math id="M16" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E17"><label>(17)</label><mml:math id="M17" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>∕</mml:mo><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:math></disp-formula>where <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the differential between the paired case and control for the <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula>th feature of the <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>th sample, given as
<disp-formula id="E18"><label>(18)</label><mml:math id="M18" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula><inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi mathvariant="normal">FC</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> and adjusted <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mi>P</mml:mi><mml:mo> </mml:mo><mml:mo>&lt;</mml:mo><mml:mo> </mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula> were used to identified differentially expressed genes between cancer group and normal control. Overall, 138 and 261 genes (<xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S3 and S4</xref>) were found to be up- and down-regulated in kidney cancer versus control tissues, respectively, hence making them as potential maker candidates in kidney cancer. </p>
    <p>Based on all the differentially expressed genes (138 up-regulated and 261 down-regulated) (<xref rid="btab545-F7" ref-type="fig">Fig. 7</xref>) in kidney cancer versus control, we applied DeepSec and further inferred that 261 of these biomarkers may be secreted into blood. Since 157 proteins have been included in our positive dataset, the remaining 104 proteins are considered novel marker proteins identified by this prediction model. Despite of the discordance between gene expression and protein abundance, proteins that show significantly elevated gene expression in kidney cancer tissues versus control can be more promising marker candidates compared to those repressed ones. The detailed prediction results about up- and down-regulated protein markers of kidney cancer in blood are listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref>.</p>
    <fig position="float" id="btab545-F7">
      <label>Fig. 7.</label>
      <caption>
        <p>The significant differential expression between kidney cancer and control samples, including up- and down-regulated results</p>
      </caption>
      <graphic xlink:href="btab545f7" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>5 Discussion</title>
    <p>DeepSec represents the first generalized computational model that can predict secreted proteins in multiple human body fluids. Specifically, this end-to-end model is built based on sequence features extracted via CNN followed by bidirectional GRU. Compared to other models based on proteins features, DeepSec has demonstrated improved prediction accuracy and better generalizability (<xref rid="btab545-F5" ref-type="fig">Fig. 5</xref>), which indicates the advantage of sequence-based method as compared to feature-based algorithms. In the blood protein case, the model shows reasonably high AUC (0.94/0.94) and high F-measure (0.91/0.87) on testing dataset and all datasets, as compared to other model architectures (<xref rid="btab545-T3" ref-type="table">Table 3</xref>), which also suggests that DeepSec has good representation of the relevant proteins across the whole protein space.</p>
    <p>However, there might be some concerns about the limitations of DeepSec. First, due to the lack of clear knowledge about non-body-fluid secretory proteins, this study generates negative dataset based on Pfam family information. It means that the negative datasets may not adequately include the whole space of the non-body-fluid secretory proteins. Indeed, with larger number of positive instances being identified by wet lab experiments, this model can be better tuned, as demonstrated in <xref rid="btab545-B4" ref-type="bibr">Cui <italic toggle="yes">et al.</italic> (2008)</xref>. Second, since the protein sequences are compressed into a fixed size vector, there is a risk of information loss. Note that 11.7% (1990 proteins) of human proteins have been influenced by the truncation rule. However, when analyzing the physical properties of those proteins, we understand that the probability of the secreted proteins having long anomic acid sequences is very low, which implies a minimal negative impact on the DeepSec’s performance if there is any. Last, since we addressed the imbalance problem by sampling multiple smaller subsets and recalculates the probabilities based on the same small dataset during the training process, there is a certain likelihood that it introduces risks of overfitting while yielding significantly improved performance. However, when evaluating the performance of DeepSec on all datasets (<xref rid="btab545-T2" ref-type="table">Table 2</xref>), it appears confidently that DeepSec doesn’t overly fit the data.</p>
  </sec>
  <sec>
    <title>6 Conclusion</title>
    <p>In summary, we propose a DL method, DeepSec, to predict secreted proteins in 12 kinds of human body fluids based on protein sequences. To the best of our knowledge, DeepSec is the first system that fully capture the sequence features related to protein secretion automatically using CNN with BGRU architecture. The BGRU network is able to capture possible long-range dependencies between sequence and secreted status of proteins, which contributes to the improved performance. DeepSec is able to predict the secreted protein with higher accuracy than existing state-of-the-art methods. Moreover, DeepSec is useful for discovering novel candidates of blood biomarkers in kidney cancer that have been experimentally verified. Our future effort will focus on including more types of human body fluids into the system and improve the performance toward biomarker discovery in complex human diseases and physiological phenotypes.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Natural Science Foundation of China [62072212], the Development Project of Jilin Province of China [20200401083GX, 2020C003, 2020LY500L06], Guangdong Key Project for Applied Fundamental Research [2018KZDXM076]. This work was also supported by Jilin Province Key Laboratory of Big Data Intelligent Computing [20180622002JC].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab545_Supplementary_Data</label>
      <media xlink:href="btab545_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab545-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>S.F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1997</year>) <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anderson</surname><given-names>N.L.</given-names></string-name></person-group> (<year>2010</year>) <article-title>The clinical plasma proteome: a survey of clinical assays for proteins in plasma and serum</article-title>. <source>Clin. Chem</source>., <volume>56</volume>, <fpage>177</fpage>–<lpage>185</lpage>.<pub-id pub-id-type="pmid">19884488</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Armenteros</surname><given-names>J.J.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>DeepLoc: prediction of protein subcellular localization using deep learning</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>3387</fpage>–<lpage>3395</lpage>.<pub-id pub-id-type="pmid">29036616</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cui</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Computational prediction of human proteins that can be secreted into the bloodstream</article-title>. <source>Bioinformatics</source>, <volume>24</volume>, <fpage>2370</fpage>–<lpage>2375</lpage>.<pub-id pub-id-type="pmid">18697770</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname><given-names>C.S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>A computational method for prediction of excretory proteins and application to identification of gastric cancer markers in urine</article-title>. <source>PLoS One</source>, <volume>6</volume>, <fpage>e16875</fpage>.<pub-id pub-id-type="pmid">21365014</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Human body-fluid proteome: quantitative profiling and computational prediction</article-title>. <source>Brief. Bioinf</source>., <volume>22</volume>, <fpage>315</fpage>–<lpage>333</lpage>.</mixed-citation>
    </ref>
    <ref id="btab545-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jain</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Analyzing effect of quadruple multiple sequence alignments on deep learning based protein inter-residue distance prediction</article-title>. <source>Sci. Rep</source>., <volume>11</volume>, <fpage>7574</fpage>.<pub-id pub-id-type="pmid">33828153</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lathrop</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2003</year>) <article-title>Therapeutic potential of the plasma proteome</article-title>. <source>Curr. Opin. Mol. Ther</source>., <volume>5</volume>, <fpage>250</fpage>–<lpage>257</lpage>.<pub-id pub-id-type="pmid">12870434</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Legrain</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>The human proteome project: current state and future direction</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>10</volume>, <fpage>M111.009993</fpage>.</mixed-citation>
    </ref>
    <ref id="btab545-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liang</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>A Novel Matched-pairs feature selection method considering with tumor purity for differential gene expression analyses</article-title>. <source>Math. Biosci</source>., <volume>311</volume>, <fpage>39</fpage>–<lpage>48</lpage>.<pub-id pub-id-type="pmid">30825482</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Margolis</surname><given-names>J.</given-names></string-name>, <string-name><surname>Kenrick</surname><given-names>K.G.</given-names></string-name></person-group> (<year>1969</year>) <article-title>Two-dimensional resolution of plasma proteins by combination of polyacrylamide disc and gradient gel electrophoresis</article-title>. <source>Nature</source>, <volume>221</volume>, <fpage>1056</fpage>–<lpage>1057</lpage>.<pub-id pub-id-type="pmid">5774398</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nanjappa</surname><given-names>V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Plasma Proteome Database as a resource for proteomics research: 2014 update</article-title>. <source>Nucleic Acids Res</source>., <volume>42</volume>, <fpage>D959</fpage>–<lpage>965</lpage>.<pub-id pub-id-type="pmid">24304897</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sara</surname><given-names>E.G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>The Pfam protein families database in 2019</article-title>. <source>Nuclc Acids Res</source>., <volume>47</volume>, <fpage>D427</fpage>–<lpage>432</lpage>.</mixed-citation>
    </ref>
    <ref id="btab545-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Savojardo</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DeepSig: deep learning improves signal peptide detection in proteins</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>1690</fpage>–<lpage>1696</lpage>.<pub-id pub-id-type="pmid">29280997</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwenk</surname><given-names>J.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>The human plasma proteome draft of 2017: building on the human plasma PeptideAtlas from mass spectrometry and complementary assays</article-title>. <source>J. Proteome Res</source>., <volume>16</volume>, <fpage>4299</fpage>–<lpage>4310</lpage>.<pub-id pub-id-type="pmid">28938075</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>A computational method for prediction of saliva-secretory proteins and its application to identification of head and neck cancer biomarkers for salivary diagnosis</article-title>. <source>IEEE Trans. Nanobiosci</source>., <volume>14</volume>, <fpage>167</fpage>–<lpage>174</lpage>.</mixed-citation>
    </ref>
    <ref id="btab545-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thomson</surname><given-names>J.J.</given-names></string-name></person-group> (<year>1914</year>) <article-title>Rays of positive electricity and their application to chemical analyses</article-title>. <source>Nature</source>, <volume>92</volume>, <fpage>549</fpage>–<lpage>550</lpage>.</mixed-citation>
    </ref>
    <ref id="btab545-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tiselius</surname><given-names>A.</given-names></string-name></person-group> (<year>1937</year>) <article-title>Electrophoresis of serum globulin: electrophoretic analysis of normal and immune sera</article-title>. <source>Biochem. J</source>., <volume>31</volume>, <fpage>313</fpage>–<lpage>317</lpage>.<pub-id pub-id-type="pmid">16746340</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Varland</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>N-terminal modifications of cellular proteins: the enzymes involved, their substrate specificities and biological effects</article-title>. <source>Proteomics</source>, <volume>15</volume>, <fpage>2385</fpage>–<lpage>2401</lpage>.<pub-id pub-id-type="pmid">25914051</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J.X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Computational prediction of human salivary proteins from blood circulation and application to diagnostic biomarker identification</article-title>. <source>PLoS One</source>, <volume>8</volume>, <fpage>e80211</fpage>.<pub-id pub-id-type="pmid">24324552</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016a</year>) <article-title>Protein secondary structure prediction using deep convolutional neural fields</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>18962</fpage>.<pub-id pub-id-type="pmid">26752681</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B22">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016b</year>) <source>PUEPro: A Computational Pipeline for Prediction of Urine Excretory Proteins. Advanced Data Mining and Applications (ADMA)</source>. <publisher-name>Gold Coast</publisher-name>, <publisher-loc>QLD, Australia</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btab545-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weber</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Impact of C-terminal amino acid composition on protein expression in bacteria</article-title>. <source>Mol. Syst. Biol</source>., <volume>16</volume>, <fpage>e9208</fpage>.<pub-id pub-id-type="pmid">32449593</pub-id></mixed-citation>
    </ref>
    <ref id="btab545-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilaiprasitporn</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Affective EEG-based person identification using the deep learning approach</article-title>. <source>IEEE Trans. Cognit. Dev. Syst</source>., <volume>12</volume>, <fpage>486</fpage>–<lpage>496</lpage>.</mixed-citation>
    </ref>
    <ref id="btab545-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>Y.Y.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>R.C.</given-names></string-name></person-group> (<year>2014</year>) <article-title>UPLC–MS<sup>E</sup> application in disease biomarker discovery: the discoveries in proteomics to metabolomics</article-title>. <source>Chem. Biol. Interact</source>., <volume>215</volume>, <fpage>7</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">24631021</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
