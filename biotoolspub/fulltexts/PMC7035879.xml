<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD with OASIS Tables v1.0 20120330//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing-oasis-article1.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName jpoasis-nisons2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Neurophotonics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Neurophotonics</journal-id>
    <journal-id journal-id-type="coden">NEUROW</journal-id>
    <journal-id journal-id-type="publisher-id">NPh</journal-id>
    <journal-title-group>
      <journal-title>Neurophotonics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">2329-423X</issn>
    <issn pub-type="epub">2329-4248</issn>
    <publisher>
      <publisher-name>Society of Photo-Optical Instrumentation Engineers</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7035879</article-id>
    <article-id pub-id-type="pmid">32118085</article-id>
    <article-id pub-id-type="doi">10.1117/1.NPh.7.1.015008</article-id>
    <article-id pub-id-type="publisher-manuscript">NPh-19012RRR</article-id>
    <article-id pub-id-type="publisher-id">19012RRR</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Papers</subject>
      </subj-group>
      <subj-group subj-group-type="SPIE-art-type">
        <subject>Paper</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Improving model-based functional near-infrared spectroscopy analysis using mesh-based anatomical and light-transport models</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6712-7602</contrib-id>
        <name>
          <surname>Tran</surname>
          <given-names>Anh Phong</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">a</xref>
        <xref ref-type="author-notes" rid="fn1">†</xref>
        <xref ref-type="other" rid="b1"/>
        <email>tran.anh@HUSKY.NEU.EDU</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1983-4625</contrib-id>
        <name>
          <surname>Yan</surname>
          <given-names>Shijie</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">b</xref>
        <xref ref-type="author-notes" rid="fn1">†</xref>
        <xref ref-type="other" rid="b2"/>
        <email>yan.shiji@husky.neu.edu</email>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0805-935X</contrib-id>
        <name>
          <surname>Fang</surname>
          <given-names>Qianqian</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">c</xref>
        <xref ref-type="aff" rid="aff2">b</xref>
        <xref ref-type="corresp" rid="cor1">*</xref>
        <xref ref-type="other" rid="b3"/>
        <email>q.fang@neu.edu</email>
      </contrib>
      <aff id="aff1"><label>a</label><institution>Northeastern University</institution>, Department of Chemical Engineering, Boston, Massachusetts, <country>United States</country></aff>
      <aff id="aff2"><label>b</label><institution>Northeastern University</institution>, Department of Electrical and Computer Engineering, Boston, Massachusetts, <country>United States</country></aff>
      <aff id="aff3"><label>c</label><institution>Northeastern University</institution>, Department of Bioengineering, Boston, Massachusetts, <country>United States</country></aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>*</label>Address all correspondence to Qianqian Fang, E-mail: <email>q.fang@neu.edu</email></corresp>
      <fn id="fn1">
        <label>†</label>
        <p>Equal contribution</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>1</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>22</day>
      <month>2</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>7</volume>
    <issue>1</issue>
    <elocation-id>015008</elocation-id>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>2</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>5</day>
        <month>2</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2020 The Authors</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>The Authors</copyright-holder>
      <license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
        <license-p>Published by SPIE under a Creative Commons Attribution 4.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.</license-p>
      </license>
    </permissions>
    <self-uri xlink:title="pdf" xlink:href="NPH_7_1_015008.pdf"/>
    <abstract>
      <title>Abstract.</title>
      <p><bold>Significance</bold>: Functional near-infrared spectroscopy (fNIRS) has become an important research tool in studying human brains. Accurate quantification of brain activities via fNIRS relies upon solving computational models that simulate the transport of photons through complex anatomy.</p>
      <p><bold>Aim</bold>: We aim to highlight the importance of accurate anatomical modeling in the context of fNIRS and propose a robust method for creating high-quality brain/full-head tetrahedral mesh models for neuroimaging analysis.</p>
      <p><bold>Approach</bold>: We have developed a surface-based brain meshing pipeline that can produce significantly better brain mesh models, compared to conventional meshing techniques. It can convert segmented volumetric brain scans into multilayered surfaces and tetrahedral mesh models, with typical processing times of only a few minutes and broad utilities, such as in Monte Carlo or finite-element-based photon simulations for fNIRS studies.</p>
      <p><bold>Results</bold>: A variety of high-quality brain mesh models have been successfully generated by processing publicly available brain atlases. In addition, we compare three brain anatomical models—the voxel-based brain segmentation, tetrahedral brain mesh, and layered-slab brain model—and demonstrate noticeable discrepancies in brain partial pathlengths when using approximated brain anatomies, ranging between <inline-formula><mml:math id="math1"><mml:mrow><mml:mo form="prefix">−</mml:mo><mml:mn>1.5</mml:mn><mml:mo form="postfix">%</mml:mo></mml:mrow></mml:math></inline-formula> to 23% with the voxelated brain and 36% to 166% with the layered-slab brain.</p>
      <p><bold>Conclusion</bold>: The generation and utility of high-quality brain meshes can lead to more accurate brain quantification in fNIRS studies. Our open-source meshing toolboxes “Brain2Mesh” and “Iso2Mesh” are freely available at <ext-link ext-link-type="uri" xlink:href="http://mcx.space/brain2mesh">http://mcx.space/brain2mesh</ext-link>.</p>
    </abstract>
    <kwd-group>
      <title>Keywords:</title>
      <kwd>functional near-infrared spectroscopy</kwd>
      <kwd>tetrahedral mesh generation</kwd>
      <kwd>brain atlas</kwd>
      <kwd>Monte Carlo method</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="sp1">
        <funding-source>National Institute of General Medical Sciences<named-content content-type="fundref:id">https://doi.org/10.13039/100000057</named-content></funding-source>
        <award-id>R01-GM114365</award-id>
      </award-group>
      <award-group id="sp2">
        <funding-source>National Cancer Institute<named-content content-type="fundref:id">https://doi.org/10.13039/100000054</named-content></funding-source>
        <award-id>R01-CA0204443</award-id>
      </award-group>
      <award-group id="sp3">
        <funding-source>National Institute of Biomedical Imaging and Bioengineering<named-content content-type="fundref:id">https://doi.org/10.13039/100000070</named-content></funding-source>
        <award-id>R01-EB026998</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="10"/>
      <table-count count="1"/>
      <ref-count count="62"/>
      <page-count count="18"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>running-head</meta-name>
        <meta-value>Tran, Yan, and Fang: Improving model-based functional near-infrared spectroscopy analysis…</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <label>1</label>
    <title>Introduction</title>
    <p>Functional near-infrared spectroscopy (fNIRS) has played an increasingly important role in functional neuroimaging.<xref rid="r1" ref-type="bibr"><sup>1</sup></xref> Using light in the red and near-infrared range, the hemodynamic response of the brain is probed through careful placement of sources and detectors on the scalp surface at multiple wavelengths. Relative changes in oxygenated (<inline-formula><mml:math id="math2"><mml:mrow><mml:msub><mml:mi>HbO</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) and deoxygenated hemoglobin (HbR) concentrations, as a result of neural activities, lead to variations in light intensities at the detectors that are used to infer the locations of these activities. The accuracy of this inference depends greatly not only upon an accurate representation of the complex human brain anatomy but also on the surrounding tissues that affect the migrations of photons from the sources to the detectors. Using the anatomical scans of the patient’s head or a resembling atlas, Monte Carlo (MC) simulations are often used in conjunction with tissue optical properties to approximate the photon pathlengths that are used to reconstruct the changes in HbR and <inline-formula><mml:math id="math3"><mml:mrow><mml:msub><mml:mi>HbO</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. While much simplified brain models, such as planar<xref rid="r2" ref-type="bibr"><sup>2</sup></xref><sup>,</sup><xref rid="r3" ref-type="bibr"><sup>3</sup></xref> or spherical layers,<xref rid="r4" ref-type="bibr"><sup>4</sup></xref> as well as approximated photon propagation models, such as the diffusion approximation (DA),<xref rid="r5" ref-type="bibr"><sup>5</sup></xref> have been widely utilized by the research community, their limitations are recognized by a number of studies.<xref rid="r3" ref-type="bibr"><sup>3</sup></xref><sup>,</sup><xref rid="r6" ref-type="bibr"><sup>6</sup></xref> In addition, modeling brain anatomy accurately also plays important roles in other quantitative neuroimaging modalities, such as electroencephalography (EEG)<xref rid="r7" ref-type="bibr"><sup>7</sup></xref> and magnetoencephalography.<xref rid="r8" ref-type="bibr"><sup>8</sup></xref></p>
    <p>Whereas a voxelated brain representation has been dominantly used for acquiring and storing a three-dimensional (3-D) neuroanatomical volume, the terraced boundary shape in a voxelated space has difficulty in representing a smooth and curved boundary that typically delineates human tissues, resulting in a loss of accuracy, especially when modeling complex cortical surfaces with limited resolution. In addition, the uniform grid structure of the voxel space also demands a large number of cells in order to store brain anatomy without losing spatial details. This can cause prohibitive memory allocation and runtime in applications where solving sophisticated numerical models is necessary. Another approach—octree—uses nested voxel refinement near curved boundaries. This improves memory efficiency significantly but still suffers from terraced mesh boundaries.<xref rid="r9" ref-type="bibr"><sup>9</sup></xref><named-content content-type="online"><xref rid="r10" ref-type="bibr"/></named-content><named-content content-type="print"><sup>–</sup></named-content><xref rid="r11" ref-type="bibr"><sup>11</sup></xref></p>
    <p>Mesh-based brain/head models made of triangular surfaces or tetrahedral elements have advantages in both improved boundary accuracy and high flexibility compared to voxelated domains. Mesh-based models are not only the most common choice in computer graphics and 3-D visualization of brain structures, but they are also the primary format for finite element analysis (FEA) and image reconstructions in many neuroimaging studies.<xref rid="r12" ref-type="bibr"><sup>12</sup></xref><sup>,</sup><xref rid="r13" ref-type="bibr"><sup>13</sup></xref> In fNIRS, tetrahedral meshes have been reported in several studies to model light propagation and recover brain hemodynamic activation using the finite-element<xref rid="r14" ref-type="bibr"><sup>14</sup></xref><sup>,</sup><xref rid="r15" ref-type="bibr"><sup>15</sup></xref> or mesh-based Monte Carlo (MMC) method.<xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>,</sup><xref rid="r17" ref-type="bibr"><sup>17</sup></xref> Despite its importance for quantitative fNIRS analysis, the available mesh-based brain models remain limited<xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>,</sup><xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>,</sup><xref rid="r19" ref-type="bibr"><sup>19</sup></xref> in part due to the difficulties in generating accurate brain tetrahedral meshes.</p>
    <p>The importance of creating high-quality brain mesh models is not limited to fNIRS. EEG relies on surface and volumetric head/brain meshes to quantitatively estimate the brain cortical activities.<xref rid="r20" ref-type="bibr"><sup>20</sup></xref> The effects of transcranial magnetic stimulation and transcranial direct current stimulation (tDCS) can also be simulated on realistic mesh models to evaluate brain damages<xref rid="r13" ref-type="bibr"><sup>13</sup></xref><sup>,</sup><xref rid="r21" ref-type="bibr"><sup>21</sup></xref> or by measuring tDCS effects on major brain disorders.<xref rid="r22" ref-type="bibr"><sup>22</sup></xref> In addition, FEA of brain tissue deformation using mesh models can assist neurosurgeons in the study of traumatic brain injuries or surgical planning.<xref rid="r23" ref-type="bibr"><sup>23</sup></xref></p>
    <p>On the other hand, while it has been generally agreed that mesh-based light transport models are more accurate than those using a voxel-based domain, there has not been a systematic study to investigate such difference and its impact on fNIRS. The shape differences between a voxelated and a mesh-based boundary not only influence how photons get absorbed by tissue, thus altering fluence distributions, but also greatly impact photon reflection/transmission characteristics near a tissue/air boundary. Such error could also be amplified with the presence of low-scattering/low-absorption tissue, such as cerebrospinal fluid (CSF) in the brain, and result in inaccurate estimations in fNIRS. To quantify the impact of brain anatomical models in light modeling using the state-of-the-art voxel and MMC simulators could be greatly beneficial for the community to design more efficient study protocols and instruments.</p>
    <p>Despite the broad awareness of anatomical model differences, fNIRS studies utilizing mesh brain models are quite limited, largely due to the challenges to create brain meshes and lack of publicly available meshing tools. A large portion of these studies rely on previously created meshes<xref rid="r24" ref-type="bibr"><sup>24</sup></xref> or using general-purpose tetrahedral mesh generators that are not optimized for meshing the brain. For example, a voxel conforming mesh generation approach,<xref rid="r25" ref-type="bibr"><sup>25</sup></xref><sup>,</sup><xref rid="r26" ref-type="bibr"><sup>26</sup></xref> the marching cubes algorithm<xref rid="r27" ref-type="bibr"><sup>27</sup></xref><sup>,</sup><xref rid="r28" ref-type="bibr"><sup>28</sup></xref> and the “Cleaver” software<xref rid="r29" ref-type="bibr"><sup>29</sup></xref> can achieve good surface accuracy but at the cost of highly dense elements near the boundaries due to the octree-like refinement. A general-purpose 3-D mesh generation pipeline was proposed alongside with an open-source meshing software BioMesh3D.<xref rid="r30" ref-type="bibr"><sup>30</sup></xref> This approach makes use of physics-based optimizations to obtain a high-quality multimaterial feature-preserving tetrahedral mesh models but at the expense of lengthy runtime, on the order of several hours. In another Delaunay-based meshing pipeline provided in the Computational Geometry Algorithms Library (CGAL), also supported in “Iso2Mesh”<xref rid="r31" ref-type="bibr"><sup>31</sup></xref> in 2009 and NIRFAST in 2013,<xref rid="r32" ref-type="bibr"><sup>32</sup></xref> the tetrahedral mesh is generated from a random point set that is iteratively refined.<xref rid="r33" ref-type="bibr"><sup>33</sup></xref><sup>,</sup><xref rid="r34" ref-type="bibr"><sup>34</sup></xref> This procedure is relatively fast, parallelizable, and robust. However, nonsmooth boundaries are often observed between tissue regions (example shown below). Commercially available tools, such as Mimics (Materialise, Leuven, Belgium) and ScanIP (Simpleware, Exeter, UK), offer integrated interfaces for image segmentation and mesh generation but often require manual mesh editing. A streamlined high-quality mesh-processing pipeline from neuroanatomical scans remains a challenge.</p>
    <p>Meshing tools specifically optimized for brain mesh generation are very limited. In 2010, we reported a surface-based brain meshing approach.<xref rid="r16" ref-type="bibr"><sup>16</sup></xref> In 2013, a similar approach was reported,<xref rid="r35" ref-type="bibr"><sup>35</sup></xref> in which an automated meshing pipeline “mri2mesh” was reported, incorporating FreeSurfer surface models and the scalp, skull, and CSF segmentations from FMRIB Software Library (FSL) with the assistance of a surface decoupling step.<xref rid="r36" ref-type="bibr"><sup>36</sup></xref> Although mri2mesh yielded smooth boundaries and high-quality tetrahedral elements, the reported meshing times are on the order of 3 to 4 h, in addition to the time for segmentation. Moreover, mri2mesh can only process FreeSurfer and FSL outputs, limiting its integration with other segmentation tools.</p>
    <p>In this work, we address two challenges in model-based neuroimaging analysis. First, we report a fully automated, surface-based brain/full head 3-D meshing pipeline “Brain2Mesh”—a specialized wrapper built upon our widely adopted mesh generation toolbox, Iso2Mesh, dedicated toward high-quality brain mesh generation. A major difference separating this work from the more conventional CGAL-based volumetric meshing approach<xref rid="r32" ref-type="bibr"><sup>32</sup></xref><sup>,</sup><xref rid="r33" ref-type="bibr"><sup>33</sup></xref> is the use of surface-based meshing workflow. This allows it to produce brain mesh models with significantly higher quality. It is also much more flexible, processing data conveniently from multilabel (discrete) or probabilistic (continuous) segmentations and surface models of the brain. Second, this work quantitatively demonstrates that by utilizing an accurate mesh-based brain representation, one can potentially improve the accuracy in fNIRS data analysis. We analyze the errors in both fluence and photon partial pathlengths in the MC simulation outputs comparing between a layered-slab, a voxel-based, and a mesh-based brain model.</p>
    <p>In the remainder of this paper, we first detail the brain mesh generation pipeline that we have developed to create high-quality brain mesh models. In Sec. <xref ref-type="sec" rid="sec3">3</xref>, we show a variety of examples of the brain/full head meshes created using different types of neuroanatomical data inputs, including an open-source brain mesh libraries created based on the recently published Neurodevelopmental Magnetic Resonance Imaging (MRI) Database.<xref rid="r37" ref-type="bibr"><sup>37</sup></xref> In addition, we also perform MMC simulation using the produced mesh model and compare the results with those from voxelated and layered-slab brain models. We highlight the modeling errors of using a voxelated model in both fluence and partial pathlength in comparison with a mesh-based brain.</p>
  </sec>
  <sec id="sec2">
    <label>2</label>
    <title>Material and Methods</title>
    <sec id="sec2.1">
      <label>2.1</label>
      <title>High-Quality Three-Dimensional Brain Mesh Generation Pipeline</title>
      <sec id="sec2.1.1">
        <label>2.1.1</label>
        <title>Brain segmentation</title>
        <p>The brain anatomical modeling pipeline reported in this work starts from a presegmented brain. Here, we want to particularly highlight that brain segmentation is outside the scope of this paper. As noted below, there is an array of dedicated brain segmentation tools, extensively developed and validated over the past several decades. Advanced statistical and template-based segmentation methods have been investigated and rigorously implemented in these tools. It is not in our interests to develop a new segmentation method but to convert these presegmented anatomies into accurate meshes for subsequent computational modeling.</p>
        <p>A diagram summarizing the common pathways in segmenting a neuroanatomical scan using popular neuroimaging analysis tools is shown in <xref ref-type="fig" rid="f1">Fig. 1</xref>. In most cases, a tissue probability or multilabel volume is obtained for the white matter (WM), gray matter (GM), and CSF. Some segmentation tools, such as Statistical Parametric Mapping (SPM), allow the use of a matching T2-weighted MRI to improve the CSF segmentation. Utilities such as the FSL brain extraction tool and SPM can provide additional information on the scalp and skull. In this work, we primarily focus on six tissue types—WM, GM, CSF, skull, scalp, and air cavities. Additional classes of tissue (e.g., dura, vessels, fatty tissues, skin, and muscle) are also available in some segmentation outputs, which can be incorporated to our mesh generation pipeline. However, one should be aware that adding additional segmentations may result in increased node numbers and surface complexity, including disconnected surface components.</p>
        <fig id="f1" orientation="portrait" position="float">
          <label>Fig. 1</label>
          <caption>
            <p>Segmentation pathways from anatomical head and brain MRI scans. The common neuroimaging tools/extensions (left) and the corresponding outputs (right, shaded) are listed.</p>
          </caption>
          <graphic xlink:href="NPh-007-015008-g001"/>
        </fig>
      </sec>
      <sec id="sec2.1.2">
        <label>2.1.2</label>
        <title>Segmentation pre-preprocessing</title>
        <p>The segmented brain or full-head volume, represented by either a multilabel 3-D mask or a set of probability maps (in floating-point 0 to 1 values), is preprocessed to ensure a layered tissue model—i.e., the WM, GM, CSF, skull, and scalp are incrementally enclosed by or share a common boundary with the later tissue layers; the scalp surface is the outermost layer and the WM is the innermost layer. In previous publications, two adjacent layers must be separated by a nonzero gap.<xref rid="r35" ref-type="bibr"><sup>35</sup></xref><sup>,</sup><xref rid="r38" ref-type="bibr"><sup>38</sup></xref> In this work, we have overcome this limitation by initially inserting a small gap between successive layers and then applying a postprocessing step to recover the merged boundaries. Moreover, we also consider air cavities, which can be located between two tissue surfaces, for example, inside or outside skull surfaces. In <xref ref-type="fig" rid="f2">Fig. 2</xref>, the workflow to create different brain tissue boundaries is outlined.</p>
        <fig id="f2" orientation="portrait" position="float">
          <label>Fig. 2</label>
          <caption>
            <p>Illustration of the layered tissue model and the segmentation preprocessing workflow. Multiple air cavities are allowed. An arrow represents a thinning (<inline-formula><mml:math id="math4"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) or thickening (<inline-formula><mml:math id="math5"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) operation between two adjacent regions. Two sample pathways are indicated, shown by black and blue arrows, respectively. The circled numbers indicate the processing order. The gaps inserted between layers can be removed in the postprocessing step to recover shared boundaries (such as the CSF/GM/WM surfaces here).</p>
          </caption>
          <graphic xlink:href="NPh-007-015008-g002"/>
        </fig>
        <p>To avoid intersecting triangles in the generated multilayered surface model, we first insert a small gap between adjacent brain tissue layers (only in the regions where tissues have shared boundaries). This is achieved using either a 3-D image “thickening” or “thinning” operator in the segmented volume. In the case of a thickening operator (<inline-formula><mml:math id="math6"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>), the outer layer tissue segmentation (<inline-formula><mml:math id="math7"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) is modified as <disp-formula id="e001"><mml:math id="math8"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mi>max</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(1)</label></disp-formula>where <inline-formula><mml:math id="math9"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="math10"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>out</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> represent the inner and outer tissue probabilistic segmentations, respectively; <inline-formula><mml:math id="math11"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula> denotes a “max-filter,” i.e., a volumetric dilation operator defined by replacing each voxel with the maximum value in a cubic neighboring region with a half-edge length of <inline-formula><mml:math id="math12"><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:math></inline-formula>, i.e., <disp-formula id="e002"><mml:math id="math13"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>←</mml:mo><mml:mi>max</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>ε</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(2)</label></disp-formula>Similarly, a thinning operator (<inline-formula><mml:math id="math14"><mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>) is defined as <disp-formula id="e003"><mml:math id="math15"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>in</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>out</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>in</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mi>min</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>in</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>out</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math><label>(3)</label></disp-formula>where <inline-formula><mml:math id="math16"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>ε</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>out</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is an “erosion” operator of width <inline-formula><mml:math id="math17"><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:math></inline-formula>, defined by a “min-filter” as <disp-formula id="e004"><mml:math id="math18"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>←</mml:mo><mml:mi>min</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>ε</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math><label>(4)</label></disp-formula></p>
        <p>The <inline-formula><mml:math id="math19"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> operator effectively shrinks the inner layer mask at the intersecting regions with the outer layer. We note here that the above <inline-formula><mml:math id="math20"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="math21"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mo>−</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> operators work for both probabilistic and binary segmentations. We also highlight that the above operators only alter tissue segmentations in the regions where the inner tissue boundaries “merge” or intersect with the outer boundaries. Such regions only account for a small fraction of the brain tissue boundaries generated from realistic data. An optional postprocessing step is applied to “relabel” the elements in the expanded regions to recover the shared tissue boundaries (see below).</p>
      </sec>
      <sec id="sec2.1.3">
        <label>2.1.3</label>
        <title>Tissue surface extraction and surface-mesh processing</title>
        <p>If the input data are given in the form of a multilabeled volume or tissue probability maps (see <xref ref-type="fig" rid="f1">Fig. 1</xref>), the next step of the mesh generation is to create a triangular surface mesh for each tissue layer. This is achieved using the “<inline-formula><mml:math id="math22"><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:math></inline-formula>-sample” algorithm using the CGAL Surface Mesh Generation library.<xref rid="r39" ref-type="bibr"><sup>39</sup></xref> For each extracted tissue surface, independent mesh quality and density criteria can be defined. In general, a surface mesh extracted from a probabilistic segmentation (grayscale) is smoother than the one derived from a binary segmentation. In addition, we also provide three surface smoothing algorithms, including the Laplacian, Laplacian+HC, and low-pass filters.<xref rid="r40" ref-type="bibr"><sup>40</sup></xref> Moreover, a surface Boolean operation using on a customized Cork 3-D surface Boolean library<xref rid="r41" ref-type="bibr"><sup>41</sup></xref> is used to avoid surface intersections.</p>
        <p>If the segmentation tool directly outputs the surface meshes of GM and WM, such as FreeSurfer, additional surface preprocessing is often required. For example, the FreeSurfer GM/WM surfaces are typically very dense. A surface simplification algorithm using the Lindstrom–Turk algorithm is applied<xref rid="r42" ref-type="bibr"><sup>42</sup></xref><sup>,</sup><xref rid="r43" ref-type="bibr"><sup>43</sup></xref> to decimate the surface nodes. In another example, if the pial and WM surfaces contain a separate surface for each brain hemisphere, a merge operation is applied to combine them into one closed surface. In addition, the FreeSurfer and FSL pial/WM surfaces do not cover the cerebellum and brainstem regions. To add those two anatomical regions, we first rasterize the pial/WM surfaces and then subtract those from the GW/WM probabilistic segmentations. From the subtracted probability maps, we extract the brainstem and cerebellum WM and GM surfaces and subsequently merge these meshes with the cerebral GM/WM surfaces. A diagram summarizing our surface-based brain mesh generation pipeline is shown in <xref ref-type="fig" rid="f3">Fig. 3</xref>.</p>
        <fig id="f3" orientation="portrait" position="float">
          <label>Fig. 3</label>
          <caption>
            <p>Processing steps for a surface-based mesh generation workflow. The left side shows the steps for processing tissue probability maps and multilabel volumes, and the right side shows additional steps to incorporate precreated pial and WM surfaces. The specific algorithm used in each step is indicated in red, and dashed boxes and arrows indicate optional processing steps.</p>
          </caption>
          <graphic xlink:href="NPh-007-015008-g003"/>
        </fig>
      </sec>
      <sec id="sec2.1.4">
        <label>2.1.4</label>
        <title>Volumetric mesh generation and postprocessing</title>
        <p>With the above-derived combined multilayer head surface model, a full head tetrahedral mesh can be finally generated using a constrained Delaunay tetrahedralization algorithm, achieved using an open-source meshing utility TetGen.<xref rid="r44" ref-type="bibr"><sup>44</sup></xref> The output mesh quality and density are fully controlled by a set of user-defined meshing criteria. An un-normalized radius-edge ratio (<inline-formula><mml:math id="math23"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula>) lower bound (see below) can be specified to control the overall quality of the tetrahedral elements. In addition, one can set an upper bound for the tetrahedral element volume globally for the entire mesh or for a particular tissue label. Spatially varying mesh density is also supported via user-defined “sizing field.”<xref rid="r44" ref-type="bibr"><sup>44</sup></xref> After tessellation, each enclosed region in a multilayered brain surface model is filled by tetrahedral elements and is assigned with a unique region label to distinguish different tissue types.</p>
        <p>If the small gaps inserted by the aforementioned thickening and thinning operations are not desired, an optional “relabeling” step is performed to recover the originally merged tissue boundaries. To do this, we use the centroids of the tetrahedral mesh elements in each unique region to determine the innermost surface that encloses this region volumes, based on which we can retag these elements using the correct tissue labels.</p>
      </sec>
    </sec>
    <sec id="sec2.2">
      <label>2.2</label>
      <title>Assessing Impact of Anatomical Models in Light Transport Modeling</title>
      <p>The ability to generate high-quality brain mesh models alongside the in-depth understandings to the state-of-the-art voxel and MMC photon transport modeling tools allow us to investigate the impact of brain anatomical models on fNIRS data analysis. Here, we are interested in quantitatively comparing various brain anatomical models in terms of light transport modeling and quantify their differences in the optical parameters essential to fNIRS measurements. The three brain anatomical models that we are evaluating include (1) mesh-based brain models,<xref rid="r6" ref-type="bibr"><sup>6</sup></xref><sup>,</sup><xref rid="r16" ref-type="bibr"><sup>16</sup></xref> (2) voxel-based brain segmentations,<xref rid="r45" ref-type="bibr"><sup>45</sup></xref> and (3) simple layered-slab brain models often found in literature.<xref rid="r3" ref-type="bibr"><sup>3</sup></xref><sup>,</sup><xref rid="r46" ref-type="bibr"><sup>46</sup></xref> We apply our widely adopted and cross-validated MC light transport simulators—MMC<xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>,</sup><xref rid="r17" ref-type="bibr"><sup>17</sup></xref>—for mesh- and layered-slab brain simulations, and Monte Carlo eXtreme (MCX)<xref rid="r31" ref-type="bibr"><sup>31</sup></xref><sup>,</sup><xref rid="r47" ref-type="bibr"><sup>47</sup></xref> for voxel-based brain simulations. Furthermore, a number of publications applied the DA to fNIRS modeling by utilizing an approximated scattering coefficient for CSF,<xref rid="r5" ref-type="bibr"><sup>5</sup></xref><sup>,</sup><xref rid="r48" ref-type="bibr"><sup>48</sup></xref> as it has very low scattering. It is beneficial to the community to understand the errors caused by such model approximation.</p>
      <p>To ensure that the mesh model is “equivalent” to the original segmentation, we calculate the volumetric ratios, denoted as <inline-formula><mml:math id="math24"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>rel</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, between the enclosed volume of the tissue boundary over those derived from the corresponding segmentation for a given tissue. A <inline-formula><mml:math id="math25"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>rel</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> value close to 1 suggests excellent volume conservation. From all MC simulations, we compute important light transport parameters, such as the average partial pathlengths<xref rid="r49" ref-type="bibr"><sup>49</sup></xref> in the GM/WM regions (<inline-formula><mml:math id="math26"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in millimeters), the fraction of the partial pathlengths in the brain (<inline-formula><mml:math id="math27"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), as well as the optical fluence spatial distributions. In addition, we also compute the percentage fractions of the total energy deposition in the brain regions using both mesh and voxel-based simulations. Such parameter is strongly relevant to photobiomodulation (PBM) applications.<xref rid="r50" ref-type="bibr"><sup>50</sup></xref></p>
    </sec>
  </sec>
  <sec id="sec3">
    <label>3</label>
    <title>Results and Discussion</title>
    <p>In the below sections, we first showcase the robustness and flexibility of our aforementioned brain meshing pipeline by processing a wide range of complex brain anatomical scans. Various meshing pathways of our meshing pipeline are validated by using publicly available brain atlas datasets, including the Neurodevelopmental MRI database.<xref rid="r37" ref-type="bibr"><sup>37</sup></xref><sup>,</sup><xref rid="r51" ref-type="bibr"><sup>51</sup></xref> In addition, we use a sample full-head mesh generated from the MRI database and report their differences in key optical parameters by performing 3-D mesh-, voxel- and layered-domain MC transport simulations at a range of source–detector (SD) separations. All computational times were benchmarked on an Intel i7-8700K processor using a single thread.</p>
    <sec id="sec3.1">
      <label>3.1</label>
      <title>High-Quality Tetrahedral Meshes of Human Head and Brain Models</title>
      <p>In <xref ref-type="fig" rid="f4">Fig. 4</xref>, a sample full-head mesh model is generated from an SPM segmentation with tissue priors from the Laboratory for Research in Neuroimaging.<xref rid="r52" ref-type="bibr"><sup>52</sup></xref> The generated mesh contains 181,026 nodes and 1,060,051 tetrahedral elements. A T1-weighted MRI scan of an average head for the 40 to 44 years old age group from the University of South Carolina (USC) Neurodevelopmental MRI database (in the following sections, we will use “USC age group” to refer to an atlas from this database; for example, the atlas used in this example is USC 40 to 44) was used as the input. The segmentation yields five tissue classes that are used in the mesh generation: WM, GM, CSF, skull, and scalp.</p>
      <fig id="f4" orientation="portrait" position="float">
        <label>Fig. 4</label>
        <caption>
          <p>A five-layered full head tetrahedral mesh derived from an atlas head of the USC 40 to 44 atlas. It contains (a) WM, (b) GM, (c) CSF, (d) skull, and (e) scalp layers. (f) A cross-cut view of the tetrahedral mesh is shown.</p>
        </caption>
        <graphic xlink:href="NPh-007-015008-g004"/>
      </fig>
      <p>The mesh density for each tissue surface and volumetric region is fully customizable by setting the following three parameters: </p>
      <list list-type="simple">
        <list-item>
          <label>•</label>
          <p><inline-formula><mml:math id="math28"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: The maximum radius of the Delaunay sphere<xref rid="r39" ref-type="bibr"><sup>39</sup></xref> (in voxel unit) that bounds each of the triangles in a given surface mesh. For example, setting <inline-formula><mml:math id="math29"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> requires that the circumscribed sphere of each surface triangle in the generated mesh must have a radius less than 2 (voxel length). A smaller <inline-formula><mml:math id="math30"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> value is generally needed when meshing objects with sharp features.</p>
        </list-item>
        <list-item>
          <label>•</label>
          <p><inline-formula><mml:math id="math31"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: The maximum tetrahedral element volume<xref rid="r44" ref-type="bibr"><sup>44</sup></xref> (in cubic voxel-length unit). For example, setting <inline-formula><mml:math id="math32"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to 4 means no tetrahedral element in the generated mesh can exceed 4 cubic voxels in volume.</p>
        </list-item>
        <list-item>
          <label>•</label>
          <p><inline-formula><mml:math id="math33"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula>: The lower bound of the radius-to-edge ratio<xref rid="r44" ref-type="bibr"><sup>44</sup></xref> (measuring mesh quality), defined by <inline-formula><mml:math id="math34"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mi>min</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="math35"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the radius of the circumsphere of the <inline-formula><mml:math id="math36"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>’th tetrahedron and <inline-formula><mml:math id="math37"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the shortest edge length of that tetrahedron.</p>
        </list-item>
      </list>
      <p>Each surface of the brain tissue layer is extracted using a layer-specific <inline-formula><mml:math id="math38"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> value: <inline-formula><mml:math id="math39"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1.7</mml:mn><mml:mtext>  </mml:mtext><mml:mi>mm</mml:mi></mml:mrow></mml:math></inline-formula> for pial and WM, 2 mm for CSF, 2.5 mm for skull, and 3.5 mm for scalp. The <inline-formula><mml:math id="math40"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> value was defined as <inline-formula><mml:math id="math41"><mml:mrow><mml:mn>30</mml:mn><mml:mtext>  </mml:mtext><mml:msup><mml:mi>mm</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="math42"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> was set to 1.414. The probability threshold for surface extraction was set to 0.5 for each of the tissues. The entire mesh takes 53.47 s to generate using a single CPU thread. The <inline-formula><mml:math id="math43"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>rel</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> values computed from the generated mesh layers for WM, GM, CSF, skull, and scalp are 0.9924, 0.9989, 0.9921, 1.0088, and 1.0037, respectively. The excellent match of the volumes is a strong indication that our meshing pipeline preserves the tissue shapes accurately.</p>
      <p>The tissue surfaces shown in <xref ref-type="fig" rid="f4">Fig. 4</xref> are visually smooth with an average Joe–Liu quality metric<xref rid="r53" ref-type="bibr"><sup>53</sup></xref> of 0.74, indicating excellent element shape quality. Overall, no degenerated element is found. The element volumes in <xref ref-type="fig" rid="f4">Fig. 4</xref> are well distributed (not shown) with only a small portion of relatively small elements. The significant improvement in mesh quality is demonstrated in the side-by-side comparison shown in <xref ref-type="fig" rid="f5">Fig. 5</xref>. Here we compare the full head meshes created using the conventional CGAL-based direct meshing approach<xref rid="r32" ref-type="bibr"><sup>32</sup></xref> and the results from our surface-based meshing pipeline. As shown in <xref ref-type="fig" rid="f5">Fig. 5(a)</xref>–<xref ref-type="fig" rid="f5">5(c)</xref>, there are several notable limitations from the conventional approach, namely (1) the tissue boundaries are not smooth (also evident from Fig. 2 in Ref. <xref rid="r32" ref-type="bibr">32</xref>), (2) it has difficulty processing thin-layered tissue such as CSF [see <xref ref-type="fig" rid="f5">Fig. 5(b)</xref>], and (3) it can produce small isolated “islands” [see <xref ref-type="fig" rid="f5">Fig. 5(c)</xref>] due to the noise present in the volumetric image. In comparison, our surface-based meshing pipeline produces smooth and well-shaped surfaces with correct topological order. We also want to highlight that the CGAL-generated mesh contains over 268,000 nodes, whereas the mesh from our approach has only 158,211 nodes.</p>
      <fig id="f5" orientation="portrait" position="float">
        <label>Fig. 5</label>
        <caption>
          <p>Comparison between (a)–(c) conventional CGAL-based volumetric meshing and (d)–(f) the new surface-based meshing approaches. From left to right, we show sample meshes for (a), (d) GM; (b), (e) CSF; and (c), (f) WM/scalp.</p>
        </caption>
        <graphic xlink:href="NPh-007-015008-g005"/>
      </fig>
      <p>In <xref ref-type="fig" rid="f6">Fig. 6</xref>, we show that users can generate tetrahedral meshes of different densities, by conveniently setting <inline-formula><mml:math id="math44"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the sizing-field (<inline-formula><mml:math id="math45"><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula>) parameters. The set values are <inline-formula><mml:math id="math46"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="math47"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, shown in <xref ref-type="fig" rid="f6">Fig. 6(b)</xref>, and <inline-formula><mml:math id="math48"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2.5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="math49"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:math></inline-formula> shown in <xref ref-type="fig" rid="f6">Fig. 6(c)</xref>. In the case of <xref ref-type="fig" rid="f6">Fig. 6(c)</xref>, we also reduced <inline-formula><mml:math id="math50"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>max</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to 1.4 (in voxel length unit) for WM and GM, 1.7 for CSF, 2.0 for skull, and 2.5 for scalp.</p>
      <fig id="f6" orientation="portrait" position="float">
        <label>Fig. 6</label>
        <caption>
          <p>Demonstration of mesh density control. (a) The mesh contains 181,026 nodes, 1,060,051 elements, with a runtime of 53.47 s. (b) The mesh includes 499,134 nodes, 3,009,706 elements, with runtime 76.03 s, and (c) the mesh has 1,023,739 nodes, 6,220,187 elements, and 135 s runtime. The five layers of brain tissues are, in order from outer to inner: scalp (apricot), skull (light-yellow), CSF (blue), GM (gray), and WM (white).</p>
        </caption>
        <graphic xlink:href="NPh-007-015008-g006"/>
      </fig>
    </sec>
    <sec id="sec3.2">
      <label>3.2</label>
      <title>Hybrid Meshing Pipeline Combining Volumetric Segmentations with Tissue Surface Models</title>
      <p>In this subsection, we demonstrate our “hybrid” meshing pathway (described in the right-half of <xref ref-type="fig" rid="f3">Fig. 3</xref>). This approach combines tissue surfaces extracted from probabilistic segmentations with the pial and WM surfaces generated by dedicated neuroanatomical analysis tools, such as FreeSurfer and FSL. In the case of FreeSurfer, the raw pial and WM surfaces are very dense. A mesh simplification algorithm is performed to “downsample” the surface to the desired density. In <xref ref-type="fig" rid="f7">Fig. 7</xref>, we characterize the trade-offs between mesh size and the surface error<xref rid="r54" ref-type="bibr"><sup>54</sup></xref> at various resampling ratios of the dense FreeSurfer-generated pial surface for the USC 30 to 34 atlas.<xref rid="r43" ref-type="bibr"><sup>43</sup></xref> The surface error is computed as the absolute value of the Euclidean distance (in millimeters) between each node of the downsampled surface to the closest node on the original surface.<xref rid="r54" ref-type="bibr"><sup>54</sup></xref> As shown in <xref ref-type="fig" rid="f7">Fig. 7</xref>, at resampling ratio values below 0.1 (i.e., decimating over 90% edges), both gyri and sulci show a surface error above 0.5 mm. When the resampling ratio value is increased to 0.15, the observed error at the gyri becomes minimal. Only a few regions show errors above 1 mm. A resampling ratio of 0.2 is selected in this example, giving a mean surface error below 0.2 mm.</p>
      <fig id="f7" orientation="portrait" position="float">
        <label>Fig. 7</label>
        <caption>
          <p>Box plots of surface errors as a function of resampling ratio (percentage of edges that are preserved) when downsampling a FreeSurfer-generated pial surface. Spatial distributions of the errors are shown as insets.</p>
        </caption>
        <graphic xlink:href="NPh-007-015008-g007"/>
      </fig>
      <p>As we illustrate in <xref ref-type="fig" rid="f3">Fig. 3</xref>, a number of additional step have been taken to process the FreeSurfer pial/WM surfaces. These include the merging of the left- and right-hemisphere surfaces, addition of the CSF ventricles, and the addition of cerebellum and brainstem using SPM segmentations. The final mesh, as shown in <xref ref-type="fig" rid="f8">Fig. 8</xref>, contains 150,999 nodes and 917,212 elements. The mesh generation time was 158.44 s. This meshing time is significantly lower than the reported 3 to 4 h required for creating a similar mesh using mri2mesh.<xref rid="r35" ref-type="bibr"><sup>35</sup></xref> While not shown here, this hybrid workflow also accepts probabilistic segmentations produced by FSL or pial/WM surfaces created by BrainSuite and similar combinations.</p>
      <fig id="f8" orientation="portrait" position="float">
        <label>Fig. 8</label>
        <caption>
          <p>Tetrahedral mesh generated from a hybrid meshing pathway combining FreeSurfer surfaces with SPM segmentation outputs for the USC 30 to 34 atlas. The (a) sagittal and (b) coronal views are shown. The tissue layers include scalp (apricot), skull (light-yellow), CSF (blue), GM (gray), and WM (white).</p>
        </caption>
        <graphic xlink:href="NPh-007-015008-g008"/>
      </fig>
    </sec>
    <sec id="sec3.3">
      <label>3.3</label>
      <title>Brain Mesh Library Generated from Public Brain Databases</title>
      <p>To test the robustness of our meshing workflow described above, we successfully processed many of the publicly available brain segmentation datasets, including the BrainWeb database<xref rid="r55" ref-type="bibr"><sup>55</sup></xref> and the recently published Neurodevelopmental MRI database.<xref rid="r37" ref-type="bibr"><sup>37</sup></xref> For the BrainWeb atlas database, we created the corresponding mesh models directly from the available brain segmentations. For neurodevelopmental atlases, the WM and GM segmentations provided as part of the database were used. However, the CSF and skull segmentations were not directly included by the database because they are generally more difficult to create. For these missing tissues, separate segmentations for CSF and skull were created using SPM. In addition, the scalp surface was extracted from the raw MRI image using an intensity thresholding approach followed by three iterations of Laplacian+HC smoothing.<xref rid="r40" ref-type="bibr"><sup>40</sup></xref> In <xref ref-type="fig" rid="f9">Fig. 9</xref>, we show nine sample USC atlas brain meshes derived from adult and adolescent scans. In all processed MRI scans, the proposed meshing workflow worked smoothly. The average processing time is less than a minute per mesh when the voxel resolution is <inline-formula><mml:math id="math51"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mtext>  </mml:mtext><mml:msup><mml:mrow><mml:mi>mm</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and about 3 min per mesh when the resolution is <inline-formula><mml:math id="math52"><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo><mml:mn>0.5</mml:mn><mml:mtext>  </mml:mtext><mml:msup><mml:mrow><mml:mi>mm</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. It is important to note that the CSF and skull segmentations in <xref ref-type="fig" rid="f9">Fig. 9</xref> have not been validated and are shown only for illustration purposes.</p>
      <fig id="f9" orientation="portrait" position="float">
        <label>Fig. 9</label>
        <caption>
          <p>Illustrative brain mesh examples (coronal views) produced using the Neurodevelopmental MRI Database, including (a) 16 years, (b) 17.5 years, (c) 25 to 29 years, (d) 30 to 34 years, (e) 35 to 39 years, (f) 40 to 44 years, (g) 50 to 54 years, (h) 60 to 64 years, and (i) 70 to 74 years old. The tissue layers include scalp (apricot), skull (light-yellow), CSF (blue), GM (gray), and WM (white).</p>
        </caption>
        <graphic xlink:href="NPh-007-015008-g009"/>
      </fig>
    </sec>
    <sec id="sec3.4">
      <label>3.4</label>
      <title>Comparing Mesh-, Voxel-, and Layer-Based Brain Models in Light Transport Simulations</title>
      <p>Next, we demonstrate the impact of different brain anatomical models, particularly between the mesh, voxel, and layered-slab brain representations and highlight their discrepancies in optical parameters estimated from 3-D MC light transport simulations. Here we use our in-house dual-grid mesh-based Monte Carlo (DMMC) simulator<xref rid="r17" ref-type="bibr"><sup>17</sup></xref> for mesh- and layer-based MC simulations and MCX<xref rid="r31" ref-type="bibr"><sup>31</sup></xref> for voxel-based simulation. An MRI brain atlas (19.5 year group<xref rid="r51" ref-type="bibr"><sup>51</sup></xref>) was selected for this comparison, although our methods are readily applicable to other brain models. The SPM segmentation (<inline-formula><mml:math id="math53"><mml:mrow><mml:mn>166</mml:mn><mml:mo>×</mml:mo><mml:mn>209</mml:mn><mml:mo>×</mml:mo><mml:mn>223</mml:mn></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="math54"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mtext>  </mml:mtext><mml:msup><mml:mi>mm</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> resolution) of the selected atlas and the generated tetrahedron mesh from this segmentation are used for this comparison.</p>
      <p>In this case, a tetrahedral mesh with 442,035 nodes and 2,596,064 elements is used for the DMMC simulations. The mesh was created using our aforementioned meshing pipeline with maximum volume size <inline-formula><mml:math id="math55"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>30</mml:mn><mml:mtext>  </mml:mtext><mml:msup><mml:mi>mm</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and maximum Delaunay sphere radii <inline-formula><mml:math id="math56"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn><mml:mtext>  </mml:mtext><mml:mi>mm</mml:mi></mml:mrow></mml:math></inline-formula> for all tissue layers. In comparison, a much simplified layered-slab brain model is made of slabs of the same five tissue layers with the layer thicknesses calculated based on the mesh model: scalp: 7.25 mm, skull: 4.00 mm, CSF: 2.73 mm, and GM: 3.29 mm. WM tissue fills the remaining space. To minimize boundary effect, the layered-slab brain model has a dimension of <inline-formula><mml:math id="math57"><mml:mrow><mml:mn>200</mml:mn><mml:mo>×</mml:mo><mml:mn>200</mml:mn><mml:mo>×</mml:mo><mml:mn>50</mml:mn><mml:mtext>  </mml:mtext><mml:msup><mml:mi>mm</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
      <p>For the two anatomically derived (voxel and mesh) brain simulations, an inward-pointing pencil beam source is placed at an EEG 10-5 landmark<xref rid="r56" ref-type="bibr"><sup>56</sup></xref>—“C4h”—selected using the “Mesh2EEG” toolbox.<xref rid="r57" ref-type="bibr"><sup>57</sup></xref> Within the same coronal plane, five 1.5-mm-radius detectors are placed on either side of the source along the scalp, 8.4, 20, 25, 30, and 35 mm from the source [in geodesic distance, see <xref ref-type="fig" rid="f10">Fig. 10(a)</xref>], respectively, determined based on typical fNIRS system settings.<xref rid="r18" ref-type="bibr"><sup>18</sup></xref><sup>,</sup><xref rid="r58" ref-type="bibr"><sup>58</sup></xref> Similarly, for the simulations with the layered-slab brain model, a pencil beam source pointing down is placed at (99.5, 100, 0) mm. A similar set of detectors are placed on one side of the source due to symmetry [see <xref ref-type="fig" rid="f10">Fig. 10(b)</xref>].</p>
      <fig id="f10" orientation="portrait" position="float">
        <label>Fig. 10</label>
        <caption>
          <p>Comparisons of fluence distributions in an MRI brain atlas (19.5 years) using three different brain models: (a) MC fluence maps using anatomically derived mesh (computed using DMMC) and voxel (computed using MCX) brain representations, and (b) fluence maps computed using the MC and DA in a simple layered-slab brain model. Contour plots, in log-10 scale, are shown along the coronal planes with each brain tissue layer labeled and delineated by black dashed lines. In (a), the “L” and “R” markings (red) indicate the left brain and the right brain, respectively. The comparisons between the mesh and voxel tissue boundaries are shown in the inset of (a).</p>
        </caption>
        <graphic xlink:href="NPh-007-015008-g010"/>
      </fig>
      <p>The 3-D MC photon simulations are performed on all three brain models, where DMMC is used for both the mesh-based and the layered-slab brain models and MCX is used for the voxel-based brain model. The output fluence distributions along the SD plane are compared in <xref ref-type="fig" rid="f10">Fig. 10(a)</xref>. From these MC simulations, we also report the average partial pathlengths in the brain regions (<inline-formula><mml:math id="math58"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), average total pathlengths (<inline-formula><mml:math id="math59"><mml:mrow><mml:mi>TPL</mml:mi></mml:mrow></mml:math></inline-formula>) and their percentage ratios <inline-formula><mml:math id="math60"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>TPL</mml:mi></mml:mrow></mml:math></inline-formula> in <xref rid="t001" ref-type="table">Table 1</xref>. Moreover, we also computed the percentage fraction of the energy deposition in the GM region with respect to the total simulated energy. In addition to MC-based photon modeling, we have also applied the DA, frequently seen in the literature,<xref rid="r5" ref-type="bibr"><sup>5</sup></xref> to the layered-slab brain model and compared the results with those derived from the MC method in <xref ref-type="fig" rid="f10">Fig. 10(b)</xref>. For solving the diffusion equation, we used our in-house diffusion solver, Redbird.<xref rid="r59" ref-type="bibr"><sup>59</sup></xref> The reduced scattering coefficient of the CSF region is set to <inline-formula><mml:math id="math61"><mml:mrow><mml:mn>0.3</mml:mn><mml:mtext>  </mml:mtext><mml:msup><mml:mi>mm</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> as suggested in Refs. <xref rid="r5" ref-type="bibr">5</xref> and <xref rid="r48" ref-type="bibr">48</xref>. The Redbird solution matches excellently with that from NIRFAST<xref rid="r15" ref-type="bibr"><sup>15</sup></xref> (not shown).</p>
      <table-wrap id="t001" orientation="portrait" position="float">
        <label>Table 1</label>
        <caption>
          <p>Comparison of key optical parameters derived from MC simulations from an MRI brain atlas (19.5 years): for each detector, we compare the average photon partial pathlengths in the brain region (<inline-formula><mml:math id="math62"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), total-pathlengths (TPL), and their percentage ratios (<inline-formula><mml:math id="math63"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) derived from mesh-based (DMMC), voxel-based (MCX), and layered-slab (DMMC) brain representations at various source–detector (SD) separations.</p>
        </caption>
        <!--OASIS TABLE HERE-->
        <table frame="hsides" rules="groups">
          <colgroup>
            <col/>
            <col/>
            <col/>
            <col/>
            <col/>
            <col/>
            <col/>
            <col/>
            <col/>
            <col/>
            <col/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" valign="top">Det. <inline-formula><mml:math id="math64"><mml:mrow><mml:mi>#</mml:mi></mml:mrow></mml:math></inline-formula></th>
              <th rowspan="2" valign="top">SD (mm)</th>
              <th colspan="3" valign="top">Mesh-based brain model (DMMC)</th>
              <th colspan="3" valign="top">Voxel-based brain model (MCX)</th>
              <th colspan="3" valign="top">Layered-slab brain model (DMMC)</th>
            </tr>
            <tr>
              <th valign="top"><inline-formula><mml:math id="math65"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (mm)</th>
              <th valign="top">TPL (mm)</th>
              <th valign="top"><inline-formula><mml:math id="math66"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (%)</th>
              <th valign="top"><inline-formula><mml:math id="math67"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (mm)</th>
              <th valign="top">TPL (mm)</th>
              <th valign="top"><inline-formula><mml:math id="math68"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (%)</th>
              <th valign="top"><inline-formula><mml:math id="math69"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (mm)</th>
              <th valign="top">TPL (mm)</th>
              <th valign="top"><inline-formula><mml:math id="math70"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>1</td>
              <td>8.4</td>
              <td>0.05</td>
              <td>34.37</td>
              <td>0.14</td>
              <td>0.06</td>
              <td>33.91</td>
              <td>0.17</td>
              <td>0.13</td>
              <td>36.52</td>
              <td>0.35</td>
            </tr>
            <tr>
              <td>2</td>
              <td>20</td>
              <td>1.55</td>
              <td>92.96</td>
              <td>1.66</td>
              <td>1.90</td>
              <td>93.53</td>
              <td>2.03</td>
              <td>3.03</td>
              <td>101.9</td>
              <td>2.97</td>
            </tr>
            <tr>
              <td>3</td>
              <td>25</td>
              <td>4.33</td>
              <td>122.4</td>
              <td>3.54</td>
              <td>5.33</td>
              <td>123.6</td>
              <td>4.31</td>
              <td>7.05</td>
              <td>133.4</td>
              <td>5.28</td>
            </tr>
            <tr>
              <td>4</td>
              <td>30</td>
              <td>8.74</td>
              <td>150.1</td>
              <td>5.82</td>
              <td>9.73</td>
              <td>150.1</td>
              <td>6.48</td>
              <td>12.5</td>
              <td>163.5</td>
              <td>7.64</td>
            </tr>
            <tr>
              <td>5</td>
              <td>35</td>
              <td>12.8</td>
              <td>169.6</td>
              <td>7.56</td>
              <td>14.4</td>
              <td>170.5</td>
              <td>8.44</td>
              <td>17.4</td>
              <td>186.5</td>
              <td>9.34</td>
            </tr>
            <tr>
              <td>6</td>
              <td>8.4</td>
              <td>0.04</td>
              <td>36.06</td>
              <td>0.11</td>
              <td>0.05</td>
              <td>36.10</td>
              <td>0.14</td>
              <td>—</td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td>7</td>
              <td>20</td>
              <td>1.20</td>
              <td>95.47</td>
              <td>1.26</td>
              <td>1.38</td>
              <td>97.16</td>
              <td>1.42</td>
              <td>—</td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td>8</td>
              <td>25</td>
              <td>3.48</td>
              <td>125.5</td>
              <td>2.78</td>
              <td>3.70</td>
              <td>126.4</td>
              <td>2.92</td>
              <td>—</td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td>9</td>
              <td>30</td>
              <td>7.77</td>
              <td>157.0</td>
              <td>4.95</td>
              <td>7.90</td>
              <td>158.0</td>
              <td>5.00</td>
              <td>—</td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td>10</td>
              <td>35</td>
              <td>12.2</td>
              <td>179.5</td>
              <td>6.78</td>
              <td>12.0</td>
              <td>180.1</td>
              <td>6.68</td>
              <td>—</td>
              <td>—</td>
              <td>—</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>In <xref ref-type="fig" rid="f10">Fig. 10(a)</xref>, the fluence contour plots produced by MCX (orange dashed-line) and DMMC (white dashed-line) agree excellently in the vicinity of the source, whereas noticeable discrepancies are observed when moving away from the source. We believe this is a combined result of (1) photon energy deposition variations due to the small disagreement between a terraced tissue boundary and the smooth surface boundary, and (2) the distinct photon reflection behaviors between a voxel- and a mesh-based surface due to the differences in the orientations of surface facets. The effect from the first cause is largely depicted by the deviation between the two solutions in the depth direction near the source. Such difference is particularly prominent near highly curved boundaries or near boundaries with high absorption/scattering contrasts, such as the CSF region beneath detectors #7, #8, and #9 in this plot. The effect from the second cause is highlighted by the worsened discrepancy when moving away from the source along the scalp layer, for example, the scalp region to the left of detector #10. Overall, the second source of error is noticeably prominent than the mismatch resulted from the first cause. This observation is further validated by disabling the refractive index mismatch calculations in both of our simulations (results not shown): the error along the scalp surface was largely removed, but the deviations in the deep-brain regions remain.</p>
      <p>In <xref ref-type="fig" rid="f10">Fig. 10(b)</xref>, the DA (orange dashed-line) and MC (white dashed-line) produce well-matched fluence contour plots near the source but show significant difference in the regions distal to the source. The difference is particularly noticeable within the CSF and GM regions and above 30-mm SD separation on the scalp surface. We believe it is largely due to the error introduced by the approximated CSF reduced scattering coefficient.<xref rid="r48" ref-type="bibr"><sup>48</sup></xref></p>
      <p>To further quantify the differences caused by different brain representations and their impact on fNIRS brain measurements, in <xref rid="t001" ref-type="table">Table 1</xref>, we also compare several key photon parameters derived from MC simulations. Here we use the parameters derived from MMC as the reference. This is because MC solutions are typically used as gold standard, and mesh-based shape representations are known to be more accurate than voxelated domains.<xref rid="r16" ref-type="bibr"><sup>16</sup></xref> We observe that simulations using voxel-based and layered-slab brain models tend to overestimate <inline-formula><mml:math id="math71"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> compared to the mesh models. For detectors #6 to #10, the voxel-based simulation gives a 21% overestimation at the shortest SD separation (8.4 mm). Such discrepancy is reduced to within <inline-formula><mml:math id="math72"><mml:mrow><mml:mo form="prefix">±</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix">%</mml:mo></mml:mrow></mml:math></inline-formula> at the largest two separations (30 and 35 mm). The <inline-formula><mml:math id="math73"><mml:mrow><mml:mi>TPL</mml:mi></mml:mrow></mml:math></inline-formula> values are less susceptible to anatomical model accuracy, reporting a percentage difference between 0.1% and 1.8%. As a result, the difference in <inline-formula><mml:math id="math74"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is largely modulated by that of <inline-formula><mml:math id="math75"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, ranging between −1.5% and 21%. However, for detectors #1 to #5 located on a different brain region where the superficial layers are shallower than those under detectors #6 to #10, more pronounced overestimations of <inline-formula><mml:math id="math76"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for all SD separations, ranging from 12% to 23%, are observed, resulting in an <inline-formula><mml:math id="math77"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> percentage difference between 12% and 24%. Similarly, compared to mesh-based model, the layered-slab brain MC simulations report significant overestimation of <inline-formula><mml:math id="math78"><mml:mrow><mml:msub><mml:mi>PPL</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (36% to 166% with the highest difference at the shortest separation) and <inline-formula><mml:math id="math79"><mml:mrow><mml:mi>TPL</mml:mi></mml:mrow></mml:math></inline-formula> (6.3% to 10%), resulting in significant variation in <inline-formula><mml:math id="math80"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: 151% at the shortest SD separation and 78% to 24% for four long separations. Furthermore, we have also computed the percentage fraction of the energy deposition within the GM. This fraction is 1.69% when using mesh-based brain model, and 1.42% when using a voxel-based brain model, resulting in a 16% reduction in brain energy deposition. This result could have some implications to many PBM applications.<xref rid="r50" ref-type="bibr"><sup>50</sup></xref></p>
    </sec>
  </sec>
  <sec id="sec4">
    <label>4</label>
    <title>Conclusion</title>
    <p>In this work, we address the increasing needs for accurate and high-quality brain/head anatomical models that arise in fNIRS and many other neuroimaging modalities for brain function quantification, image reconstruction, multiphysics modeling, and visualization. Combined with the advance in light transport simulators,<xref rid="r16" ref-type="bibr"><sup>16</sup></xref><sup>,</sup><xref rid="r17" ref-type="bibr"><sup>17</sup></xref><sup>,</sup><xref rid="r47" ref-type="bibr"><sup>47</sup></xref> our proposed brain mesh generation pipeline enables fNIRS research community to utilize more accurate anatomical representations of the human brain to improve quantification accuracy and make atlas-based as well as subject-specific fNIRS analysis more feasible. This also gives us an opportunity to systematically investigate how neuroanatomical models—ranging from the simple layered-slab brain model to voxel-based and mesh-based models—impact the estimations of optical parameters that are essential to fNIRS imaging.</p>
    <p>Specifically, we first described a fast and robust brain mesh generation algorithm and demonstrated that our MATLAB-based open-source toolbox, Brain2Mesh, can produce high-quality brain and full-head tetrahedral meshes from multilabel or probabilistic segmentations with full automation. The abilities to create tissue boundaries from grayscale probabilistic maps and incorporate detailed surface models from FreeSurfer/FSL ensure smoothness and high accuracy in representing brain tissue boundaries. The output meshes generally exhibit excellent shape quality without needing to generate excessive number of small elements, such as in many existing mesh generators. For most of the included examples, the processing time ranges between 1 and a few minutes using only a single CPU thread. This is dramatically faster than most previously published brain meshing tools.<xref rid="r30" ref-type="bibr"><sup>30</sup></xref><sup>,</sup><xref rid="r35" ref-type="bibr"><sup>35</sup></xref><sup>,</sup><xref rid="r60" ref-type="bibr"><sup>60</sup></xref> Moreover, the entire meshing pipeline was developed based on our open-source meshing toolbox, Iso2Mesh, and other open-source meshing utilities such as CGAL, TetGen, and Cork. This ensures excellent accessibility of this tool to the community. In addition to developing this brain mesh generation toolkit, we have also produced a set of high-quality brain atlas mesh models, including the widely used BrainWeb, Colin27, and MNI atlases. We believe these ready-to-use brain/full head models will be valuable resources for the broad neuroimaging community.</p>
    <p>Another important aspect of this study is that we demonstrate how tissue boundary representations, especially layered-, voxel- and mesh-based anatomical models, could impact light transport simulations in fNIRS data analysis. While the modeling error caused by voxelization in MC simulations has been previously reported,<xref rid="r61" ref-type="bibr"><sup>61</sup></xref> we believe this is the first time such discrepancy has been quantified, particularly in the context of brain imaging, enabled by our unique access to high-quality brain meshes and highly accurate MMC simulation tools. We believe such findings could provide guidance for advancing fNIRS toward improved accuracy and broad utility. Our open-source meshing software and the brain mesh library are freely available at Ref. <xref rid="r62" ref-type="bibr">62</xref>.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>The authors wish to thank the funding supports from the National Institutes of Health under Grant Nos. R01-GM114365, R01-CA0204443, and R01-EB026998. They also acknowledge the valuable inputs from Dr. Hang Si on the use of TetGen, as well as the instructive conversation with Dr. John Richards and Dr. Katherine Perdue on brain segmentation.</p>
  </ack>
  <notes notes-type="conflict-of-interest">
    <title>Disclosures</title>
    <p>No conflicts of interest, financial or otherwise, are declared by the authors.</p>
  </notes>
  <ref-list>
    <title>References</title>
    <ref id="r1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrari</surname><given-names>M.</given-names></name><name><surname>Quaresima</surname><given-names>V.</given-names></name></person-group>, “<article-title>A brief review on the history of human functional near-infrared spectroscopy (fNIRS) development and fields of application</article-title>,” <source>NeuroImage</source>
<volume>63</volume>, <fpage>921</fpage>–<lpage>935</lpage> (<year>2012</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.049</pub-id><pub-id pub-id-type="pmid">22510258</pub-id></mixed-citation>
    </ref>
    <ref id="r2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pucci</surname><given-names>O.</given-names></name><name><surname>Toronov</surname><given-names>V.</given-names></name><name><surname>Lawrence</surname><given-names>K. S.</given-names></name></person-group>, “<article-title>Measurement of the optical properties of a two-layer model of the human head using broadband near-infrared spectroscopy</article-title>,” <source>Appl. Opt.</source>
<volume>49</volume>, <fpage>6324</fpage>–<lpage>6332</lpage> (<year>2010</year>).<pub-id pub-id-type="coden">APOPAI</pub-id><issn>0003-6935</issn><pub-id pub-id-type="doi">10.1364/AO.49.006324</pub-id><pub-id pub-id-type="pmid">21068864</pub-id></mixed-citation>
    </ref>
    <ref id="r3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Selb</surname><given-names>J.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Comparison of a layered slab and an atlas head model for Monte Carlo fitting of time-domain near-infrared spectroscopy data of the adult head</article-title>,” <source>J. Biomed. Opt.</source>
<volume>19</volume>, <fpage>016010</fpage> (<year>2014</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.19.1.016010</pub-id></mixed-citation>
    </ref>
    <ref id="r4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shang</surname><given-names>Y.</given-names></name><name><surname>Yu</surname><given-names>G.</given-names></name></person-group>, “<article-title>A Nth-order linear algorithm for extracting diffuse correlation spectroscopy blood flow indices in heterogeneous tissues</article-title>,” <source>Appl. Phys. Lett.</source>
<volume>105</volume>, <fpage>133702</fpage> (<year>2014</year>).<pub-id pub-id-type="coden">APPLAB</pub-id><issn>0003-6951</issn><pub-id pub-id-type="doi">10.1063/1.4896992</pub-id><pub-id pub-id-type="pmid">25378708</pub-id></mixed-citation>
    </ref>
    <ref id="r5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eggebrecht</surname><given-names>A. T.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Mapping distributed brain function and networks with diffuse optical tomography</article-title>,” <source>Nat. Photonics</source>
<volume>8</volume>, <fpage>448</fpage>–<lpage>454</lpage> (<year>2014</year>).<pub-id pub-id-type="coden">NPAHBY</pub-id><issn>1749-4885</issn><pub-id pub-id-type="doi">10.1038/nphoton.2014.107</pub-id><pub-id pub-id-type="pmid">25083161</pub-id></mixed-citation>
    </ref>
    <ref id="r6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perdue</surname><given-names>K. L.</given-names></name><name><surname>Fang</surname><given-names>Q.</given-names></name><name><surname>Diamond</surname><given-names>S. G.</given-names></name></person-group>, “<article-title>Quantitative assessment of diffuse optical tomography sensitivity to the cerebral cortex using a whole-head probe</article-title>,” <source>Phys. Med. Biol.</source>
<volume>57</volume>, <fpage>2857</fpage>–<lpage>2872</lpage> (<year>2012</year>).<pub-id pub-id-type="coden">PHMBA7</pub-id><issn>0031-9155</issn><pub-id pub-id-type="doi">10.1088/0031-9155/57/10/2857</pub-id><pub-id pub-id-type="pmid">22513789</pub-id></mixed-citation>
    </ref>
    <ref id="r7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallez</surname><given-names>H.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Review on solving the forward problem in EEG source analysis</article-title>,” <source>J. NeuroEng. Rehabil.</source>
<volume>4</volume>, <fpage>46</fpage> (<year>2007</year>).<pub-id pub-id-type="doi">10.1186/1743-0003-4-46</pub-id><pub-id pub-id-type="pmid">18053144</pub-id></mixed-citation>
    </ref>
    <ref id="r8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolters</surname><given-names>C.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Influence of tissue conductivity anisotropy on EEG/MEG field and return current computation in a realistic head model: a simulation and visualization study using high-resolution finite element modeling</article-title>,” <source>NeuroImage</source>
<volume>30</volume>, <fpage>813</fpage>–<lpage>826</lpage> (<year>2006</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.10.014</pub-id><pub-id pub-id-type="pmid">16364662</pub-id></mixed-citation>
    </ref>
    <ref id="r9">
      <label>9.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>P. J.</given-names></name><name><surname>George</surname><given-names>P.-L.</given-names></name></person-group>, <source>Mesh Generation: Application to Finite Elements</source>, <publisher-name>ISTE Publishing Company</publisher-name> (<year>2007</year>).</mixed-citation>
    </ref>
    <ref id="r10">
      <label>10.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Owen</surname><given-names>S. J.</given-names></name></person-group>, “<article-title>A survey of unstructured mesh generation technology</article-title>,” in <conf-name>IMR</conf-name>, pp. <fpage>239</fpage>–<lpage>267</lpage> (<year>1998</year>).</mixed-citation>
    </ref>
    <ref id="r11">
      <label>11.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Weatherill</surname><given-names>N.</given-names></name><name><surname>Soni</surname><given-names>B.</given-names></name><name><surname>Thompson</surname><given-names>J.</given-names></name></person-group>, <source>Handbook of Grid Generation</source>, <publisher-name>CRC Press</publisher-name>, <publisher-loc>Boca Raton</publisher-loc> (<year>1998</year>).</mixed-citation>
    </ref>
    <ref id="r12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tadel</surname><given-names>F.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Brainstorm: a user-friendly application for MEG/EEG analysis</article-title>,” <source>Intell. Neurosci.</source>
<volume>2011</volume>, <fpage>1</fpage>–<lpage>13</lpage> (<year>2011</year>).<pub-id pub-id-type="doi">10.1155/2011/879716</pub-id></mixed-citation>
    </ref>
    <ref id="r13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horn</surname><given-names>A.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Connectivity predicts deep brain stimulation outcome in Parkinson disease</article-title>,” <source>Ann. Neurol.</source>
<volume>82</volume>, <fpage>67</fpage>–<lpage>78</lpage> (<year>2017</year>).<pub-id pub-id-type="doi">10.1002/ana.24974</pub-id><pub-id pub-id-type="pmid">28586141</pub-id></mixed-citation>
    </ref>
    <ref id="r14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>A.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Radiative transport-based frequency-domain fluorescence tomography</article-title>,” <source>Phys. Med. Biol.</source>
<volume>53</volume>, <fpage>2069</fpage>–<lpage>2088</lpage> (<year>2008</year>).<pub-id pub-id-type="coden">PHMBA7</pub-id><issn>0031-9155</issn><pub-id pub-id-type="doi">10.1088/0031-9155/53/8/005</pub-id><pub-id pub-id-type="pmid">18364555</pub-id></mixed-citation>
    </ref>
    <ref id="r15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehghani</surname><given-names>H.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Near infrared optical tomography using NIRFAST: algorithm for numerical model and image reconstruction</article-title>,” <source>Commun. Numer. Methods Eng.</source>
<volume>25</volume>(<issue>6</issue>), <fpage>711</fpage>–<lpage>732</lpage> (<year>2009</year>).<pub-id pub-id-type="coden">CANMER</pub-id><issn>0748-8025</issn><pub-id pub-id-type="doi">10.1002/cnm.1162</pub-id></mixed-citation>
    </ref>
    <ref id="r16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>Q.</given-names></name></person-group>, “<article-title>Mesh-based Monte Carlo method using fast ray-tracing in Plücker coordinates</article-title>,” <source>Biomed. Opt. Express</source>
<volume>1</volume>, <fpage>165</fpage> (<year>2010</year>).<pub-id pub-id-type="coden">BOEICL</pub-id><issn>2156-7085</issn><pub-id pub-id-type="doi">10.1364/BOE.1.000165</pub-id><pub-id pub-id-type="pmid">21170299</pub-id></mixed-citation>
    </ref>
    <ref id="r17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>S.</given-names></name><name><surname>Tran</surname><given-names>A. P.</given-names></name><name><surname>Fang</surname><given-names>Q.</given-names></name></person-group>, “<article-title>Dual-grid mesh-based Monte Carlo algorithm for efficient photon transport simulations in complex three-dimensional media</article-title>,” <source>J. Biomed. Opt.</source>
<volume>24</volume>, <fpage>020503</fpage> (<year>2019</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.24.2.020503</pub-id></mixed-citation>
    </ref>
    <ref id="r18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brigadoi</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>A 4D neonatal head model for diffuse optical imaging of pre-term to term infants</article-title>,” <source>NeuroImage</source>
<volume>100</volume>, <fpage>385</fpage>–<lpage>394</lpage> (<year>2014</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.028</pub-id><pub-id pub-id-type="pmid">24954280</pub-id></mixed-citation>
    </ref>
    <ref id="r19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watté</surname><given-names>R.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Modeling the propagation of light in realistic tissue structures with MMC-fpf: a meshed Monte Carlo method with free phase function</article-title>,” <source>Opt. Express</source>
<volume>23</volume>(<issue>13</issue>), <fpage>17467</fpage>–<lpage>17486</lpage> (<year>2015</year>).<pub-id pub-id-type="coden">OPEXFF</pub-id><issn>1094-4087</issn><pub-id pub-id-type="doi">10.1364/OE.23.017467</pub-id><pub-id pub-id-type="pmid">26191756</pub-id></mixed-citation>
    </ref>
    <ref id="r20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramon</surname><given-names>C.</given-names></name><name><surname>Schimpf</surname><given-names>P. H.</given-names></name><name><surname>Haueisen</surname><given-names>J.</given-names></name></person-group>, “<article-title>Influence of head models on EEG simulations and inverse source localizations</article-title>,” <source>Biomed. Eng. Online</source>
<volume>5</volume>(<issue>1</issue>), <fpage>10</fpage> (<year>2006</year>).<pub-id pub-id-type="doi">10.1186/1475-925X-5-10</pub-id><pub-id pub-id-type="pmid">16466570</pub-id></mixed-citation>
    </ref>
    <ref id="r21">
      <label>21.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>K. H.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Modeling of the brain for injury prevention</article-title>,” in <source>Neural Tissue Biomechanics</source>, <person-group person-group-type="editor"><name><surname>Bilston</surname><given-names>L.</given-names></name></person-group>, Ed., pp. <fpage>69</fpage>–<lpage>120</lpage>, <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc> (<year>2011</year>).</mixed-citation>
    </ref>
    <ref id="r22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rampersad</surname><given-names>S. M.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Simulating transcranial direct current stimulation with a detailed anisotropic human head model</article-title>,” <source>IEEE Trans. Neural Syst. Rehabil. Eng.</source>
<volume>22</volume>, <fpage>441</fpage>–<lpage>452</lpage> (<year>2014</year>).<pub-id pub-id-type="doi">10.1109/TNSRE.2014.2308997</pub-id><pub-id pub-id-type="pmid">24760939</pub-id></mixed-citation>
    </ref>
    <ref id="r23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warfield</surname><given-names>S. K.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Real-time registration of volumetric brain MRI by biomechanical simulation of deformation during image guided neurosurgery</article-title>,” <source>Comput. Visualization Sci.</source>
<volume>5</volume>, <fpage>3</fpage>–<lpage>11</lpage> (<year>2002</year>).<pub-id pub-id-type="doi">10.1007/s00791-002-0083-7</pub-id></mixed-citation>
    </ref>
    <ref id="r24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cassidy</surname><given-names>J.</given-names></name><etal>et al.</etal></person-group>, “<article-title>High-performance, robustly verified Monte Carlo simulation with FullMonte</article-title>,” <source>J. Biomed. Opt.</source>
<volume>23</volume>, <fpage>085001</fpage> (<year>2018</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.23.8.085001</pub-id></mixed-citation>
    </ref>
    <ref id="r25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lederman</surname><given-names>C.</given-names></name><etal>et al.</etal></person-group>, “<article-title>The generation of tetrahedral mesh models for neuroanatomical MRI</article-title>,” <source>NeuroImage</source>
<volume>55</volume>, <fpage>153</fpage>–<lpage>164</lpage> (<year>2011</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.11.013</pub-id><pub-id pub-id-type="pmid">21073968</pub-id></mixed-citation>
    </ref>
    <ref id="r26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montenegro</surname><given-names>R.</given-names></name><etal>et al.</etal></person-group>, “<article-title>An automatic strategy for adaptive tetrahedral mesh generation</article-title>,” <source>Appl. Numer. Math.</source>
<volume>59</volume>, <fpage>2203</fpage>–<lpage>2217</lpage> (<year>2009</year>).<pub-id pub-id-type="coden">ANMAEL</pub-id><issn>0168-9274</issn><pub-id pub-id-type="doi">10.1016/j.apnum.2008.12.010</pub-id></mixed-citation>
    </ref>
    <ref id="r27">
      <label>27.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lorensen</surname><given-names>W. E.</given-names></name><name><surname>Cline</surname><given-names>H. E.</given-names></name></person-group>, “<article-title>Marching cubes: a high resolution 3D surface construction algorithm</article-title>,” in <conf-name>Proc. 14th Annu. Conf. Comput. Graphics and Interact. Tech.</conf-name>, <publisher-name>ACM Press</publisher-name> (<year>1987</year>).</mixed-citation>
    </ref>
    <ref id="r28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Sullivan</surname><given-names>J. M.</given-names></name></person-group>, “<article-title>Multiple material marching cubes algorithm</article-title>,” <source>Int. J. Numer. Methods Eng.</source>
<volume>58</volume>(<issue>2</issue>), <fpage>189</fpage>–<lpage>207</lpage> (<year>2003</year>).<pub-id pub-id-type="coden">IJNMBH</pub-id><issn>0029-5981</issn><pub-id pub-id-type="doi">10.1002/nme.775</pub-id></mixed-citation>
    </ref>
    <ref id="r29">
      <label>29.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bronson</surname><given-names>J. R.</given-names></name><name><surname>Levine</surname><given-names>J. A.</given-names></name><name><surname>Whitaker</surname><given-names>R. T.</given-names></name></person-group>, “<article-title>Lattice cleaving: conforming tetrahedral meshes of multimaterial domains with bounded quality</article-title>,” in <conf-name>Proc. 21st Int. Meshing Roundtable</conf-name>, <person-group person-group-type="editor"><name><surname>Jiao</surname><given-names>X.</given-names></name><name><surname>Weill</surname><given-names>J.-C.</given-names></name></person-group>, Eds., pp. <fpage>191</fpage>–<lpage>209</lpage>, <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc> (<year>2013</year>).</mixed-citation>
    </ref>
    <ref id="r30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Callahan</surname><given-names>M.</given-names></name><etal>et al.</etal></person-group>, “<article-title>A meshing pipeline for biomedical computing</article-title>,” <source>Eng. Comput.</source>
<volume>25</volume>, <fpage>115</fpage>–<lpage>130</lpage> (<year>2009</year>).<pub-id pub-id-type="coden">ENGCE7</pub-id><issn>0177-0667</issn><pub-id pub-id-type="doi">10.1007/s00366-008-0106-1</pub-id></mixed-citation>
    </ref>
    <ref id="r31">
      <label>31.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>Q.</given-names></name><name><surname>Boas</surname><given-names>D. A.</given-names></name></person-group>, “<article-title>Tetrahedral mesh generation from volumetric binary and grayscale images</article-title>,” in <conf-name>IEEE Int. Symp. Biomed. Imaging: From Nano to Macro</conf-name>, <publisher-name>IEEE</publisher-name> (<year>2009</year>).<pub-id pub-id-type="doi">10.1109/ISBI.2009.5193259</pub-id></mixed-citation>
    </ref>
    <ref id="r32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jermyn</surname><given-names>M.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Fast segmentation and high-quality three-dimensional volume mesh creation from medical images for diffuse optical tomography</article-title>,” <source>J. Biomed. Opt.</source>
<volume>18</volume>, <fpage>086007</fpage> (<year>2013</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.18.8.086007</pub-id></mixed-citation>
    </ref>
    <ref id="r33">
      <label>33.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boltcheva</surname><given-names>D.</given-names></name><name><surname>Yvinec</surname><given-names>M.</given-names></name><name><surname>Boissonnat</surname><given-names>J.-D.</given-names></name></person-group>, “<article-title>Mesh generation from 3D multi-material images</article-title>,” <source>Lect. Notes Comput. Sci.</source>
<volume>5762</volume>, <fpage>283</fpage>–<lpage>290</lpage> (<year>2009</year>).<pub-id pub-id-type="coden">LNCSD9</pub-id><issn>0302-9743</issn><pub-id pub-id-type="doi">10.1007/978-3-642-04271-3_35</pub-id></mixed-citation>
    </ref>
    <ref id="r34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pons</surname><given-names>J. P.</given-names></name><etal>et al.</etal></person-group>, “<article-title>High-quality consistent meshing of multi-label datasets</article-title>,” <source>Lect. Notes Comput. Sci.</source>
<volume>4584</volume>, <fpage>198</fpage>–<lpage>210</lpage> (<year>2007</year>).<pub-id pub-id-type="coden">LNCSD9</pub-id><issn>0302-9743</issn><pub-id pub-id-type="doi">10.1007/978-3-540-73273-0_17</pub-id></mixed-citation>
    </ref>
    <ref id="r35">
      <label>35.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Windhoff</surname><given-names>M.</given-names></name><name><surname>Opitz</surname><given-names>A.</given-names></name><name><surname>Thielscher</surname><given-names>A.</given-names></name></person-group>, “<article-title>Electric field calculations in brain stimulation based on finite elements: an optimized processing pipeline for the generation and usage of accurate individual head models</article-title>,” <source>Hum. Brain Mapping</source>
<volume>34</volume>, <fpage>923</fpage>–<lpage>935</lpage> (<year>2013</year>).<pub-id pub-id-type="doi">10.1002/hbm.21479</pub-id></mixed-citation>
    </ref>
    <ref id="r36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attene</surname><given-names>M.</given-names></name></person-group>, “<article-title>A lightweight approach to repairing digitized polygon meshes</article-title>,” <source>Visual Comput.</source>
<volume>26</volume>, <fpage>1393</fpage>–<lpage>1406</lpage> (<year>2010</year>).<pub-id pub-id-type="coden">VICOE5</pub-id><issn>0178-2789</issn><pub-id pub-id-type="doi">10.1007/s00371-010-0416-3</pub-id></mixed-citation>
    </ref>
    <ref id="r37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fillmore</surname><given-names>P. T.</given-names></name><name><surname>Phillips-Meek</surname><given-names>M. C.</given-names></name><name><surname>Richards</surname><given-names>J. E.</given-names></name></person-group>, “<article-title>Age-specific MRI brain and head templates for healthy adults from 20 through 89 years of age</article-title>,” <source>Front. Aging Neurosci.</source>
<volume>7</volume>, <fpage>44</fpage> (<year>2015</year>).<pub-id pub-id-type="doi">10.3389/fnagi.2015.00044</pub-id><pub-id pub-id-type="pmid">25904864</pub-id></mixed-citation>
    </ref>
    <ref id="r38">
      <label>38.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Burguet</surname><given-names>J.</given-names></name><name><surname>Gadi</surname><given-names>N.</given-names></name><name><surname>Bloch</surname><given-names>I.</given-names></name></person-group>, “<article-title>Realistic models of children heads from 3D-MRI segmentation and tetrahedral mesh construction</article-title>,” in <conf-name>Proc. 2nd Int. Symp. 3D Data Process. Visualization and Transm.</conf-name>, <publisher-name>IEEE</publisher-name> (<year>2004</year>).<pub-id pub-id-type="doi">10.1109/TDPVT.2004.1335298</pub-id></mixed-citation>
    </ref>
    <ref id="r39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boissonnat</surname><given-names>J.-D.</given-names></name><name><surname>Oudot</surname><given-names>S.</given-names></name></person-group>, “<article-title>Provably good sampling and meshing of surfaces</article-title>,” <source>Graphical Models</source>
<volume>67</volume>, <fpage>405</fpage>–<lpage>451</lpage> (<year>2005</year>).<pub-id pub-id-type="doi">10.1016/j.gmod.2005.01.004</pub-id></mixed-citation>
    </ref>
    <ref id="r40">
      <label>40.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bade</surname><given-names>R.</given-names></name><name><surname>Haase</surname><given-names>J.</given-names></name><name><surname>Preim</surname><given-names>B.</given-names></name></person-group>, “<article-title>Comparison of fundamental mesh smoothing algorithms for medical surface models</article-title>,” in <conf-name>Simulation und Visualisierung</conf-name>, Vol. <volume>6</volume>, pp. <fpage>289</fpage>–<lpage>304</lpage>, Citeseer (<year>2006</year>).</mixed-citation>
    </ref>
    <ref id="r41">
      <label>41.</label>
      <mixed-citation publication-type="web"><person-group person-group-type="author"><name><surname>Bernstein</surname><given-names>G.</given-names></name></person-group>, “<article-title>Cork: a 3D Boolean/CSG Library</article-title>,” <ext-link ext-link-type="uri" xlink:href="https://github.com/gilbo/cork">https://github.com/gilbo/cork</ext-link> (accessed <month>8</month>
<year>2016</year>).</mixed-citation>
    </ref>
    <ref id="r42">
      <label>42.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lindstrom</surname><given-names>P.</given-names></name><name><surname>Turk</surname><given-names>G.</given-names></name></person-group>, “<article-title>Fast and memory efficient polygonal simplification</article-title>,” in <conf-name>Proc. of the Conf. on Visualization’98</conf-name>, <publisher-name>IEEE</publisher-name>, <fpage>279</fpage>–<lpage>286</lpage> (<year>1998</year>).<pub-id pub-id-type="doi">10.1109/VISUAL.1998.745314</pub-id></mixed-citation>
    </ref>
    <ref id="r43">
      <label>43.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Garland</surname><given-names>M.</given-names></name><name><surname>Heckbert</surname><given-names>P. S.</given-names></name></person-group>, “<article-title>Surface simplification using quadric error metrics</article-title>,” in <conf-name>Proc. 24th Annu. Conf. Comput. Graphics and Interact. Tech.</conf-name>, <publisher-name>ACM Press</publisher-name> (<year>1997</year>).</mixed-citation>
    </ref>
    <ref id="r44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Si</surname><given-names>H.</given-names></name></person-group>, “<article-title>TetGen, a Delaunay-based quality tetrahedral mesh generator</article-title>,” <source>ACM Trans. Math. Software</source>
<volume>41</volume>, <fpage>1</fpage>–<lpage>36</lpage> (<year>2015</year>).<pub-id pub-id-type="coden">ACMSCU</pub-id><issn>0098-3500</issn><pub-id pub-id-type="doi">10.1145/2732672</pub-id></mixed-citation>
    </ref>
    <ref id="r45">
      <label>45.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>R.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Validating atlas-guided dot: a comparison of diffuse optical tomography informed by atlas and subject-specific anatomies</article-title>,” <source>NeuroImage</source>
<volume>62</volume>, <fpage>1999</fpage>–<lpage>2006</lpage> (<year>2012</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.05.031</pub-id><pub-id pub-id-type="pmid">22634215</pub-id></mixed-citation>
    </ref>
    <ref id="r46">
      <label>46.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Influence of extracerebral layers on estimates of optical properties with continuous wave near infrared spectroscopy: analysis based on multi-layered brain tissue architecture and Monte Carlo simulation</article-title>,” <source>Comput. Assisted Surg.</source>
<volume>24</volume>(<issue>Suppl. 1</issue>), <fpage>144</fpage>–<lpage>150</lpage> (<year>2019</year>).<pub-id pub-id-type="doi">10.1080/24699322.2018.1557902</pub-id></mixed-citation>
    </ref>
    <ref id="r47">
      <label>47.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>L.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Scalable and massively parallel Monte Carlo photon transport simulations for heterogeneous computing platforms</article-title>,” <source>J. Biomed. Opt.</source>
<volume>23</volume>, <fpage>010504</fpage> (<year>2018</year>).<pub-id pub-id-type="coden">JBOPFO</pub-id><issn>1083-3668</issn><pub-id pub-id-type="doi">10.1117/1.JBO.23.1.010504</pub-id></mixed-citation>
    </ref>
    <ref id="r48">
      <label>48.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Custo</surname><given-names>A.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Effective scattering coefficient of the cerebral spinal fluid in adult head models for diffuse optical imaging</article-title>,” <source>Appl. Opt.</source>
<volume>45</volume>, <fpage>4747</fpage>–<lpage>4755</lpage> (<year>2006</year>).<pub-id pub-id-type="coden">APOPAI</pub-id><issn>0003-6935</issn><pub-id pub-id-type="doi">10.1364/AO.45.004747</pub-id><pub-id pub-id-type="pmid">16799690</pub-id></mixed-citation>
    </ref>
    <ref id="r49">
      <label>49.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strangman</surname><given-names>G.</given-names></name><name><surname>Franceschini</surname><given-names>M. A.</given-names></name><name><surname>Boas</surname><given-names>D. A.</given-names></name></person-group>, “<article-title>Factors affecting the accuracy of near-infrared spectroscopy concentration calculations for focal changes in oxygenation parameters</article-title>,” <source>Neuroimage</source>
<volume>18</volume>(<issue>4</issue>), <fpage>865</fpage>–<lpage>879</lpage> (<year>2003</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00021-1</pub-id><pub-id pub-id-type="pmid">12725763</pub-id></mixed-citation>
    </ref>
    <ref id="r50">
      <label>50.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cassano</surname><given-names>P.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Selective photobiomodulation for emotion regulation: model-based dosimetry study</article-title>,” <source>Neurophotonics</source>
<volume>6</volume>, <fpage>015004</fpage> (<year>2019</year>).<pub-id pub-id-type="doi">10.1117/1.NPh.6.1.015004</pub-id><pub-id pub-id-type="pmid">30796882</pub-id></mixed-citation>
    </ref>
    <ref id="r51">
      <label>51.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez</surname><given-names>C. E.</given-names></name><name><surname>Richards</surname><given-names>J. E.</given-names></name><name><surname>Almli</surname><given-names>C. R.</given-names></name></person-group>, “<article-title>Age-specific MRI templates for pediatric neuroimaging</article-title>,” <source>Dev. Neuropsychol.</source>
<volume>37</volume>, <fpage>379</fpage>–<lpage>399</lpage> (<year>2012</year>).<pub-id pub-id-type="coden">DENEE8</pub-id><pub-id pub-id-type="doi">10.1080/87565641.2012.688900</pub-id><pub-id pub-id-type="pmid">22799759</pub-id></mixed-citation>
    </ref>
    <ref id="r52">
      <label>52.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorio</surname><given-names>S.</given-names></name><etal>et al.</etal></person-group>, “<article-title>New tissue priors for improved automated classification of subcortical brain structures on MRI</article-title>,” <source>NeuroImage</source>
<volume>130</volume>, <fpage>157</fpage>–<lpage>166</lpage> (<year>2016</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.01.062</pub-id><pub-id pub-id-type="pmid">26854557</pub-id></mixed-citation>
    </ref>
    <ref id="r53">
      <label>53.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>A.</given-names></name><name><surname>Joe</surname><given-names>B.</given-names></name></person-group>, “<article-title>Relationship between tetrahedron shape measures</article-title>,” <source>BIT</source>
<volume>34</volume>, <fpage>268</fpage>–<lpage>287</lpage> (<year>1994</year>).<pub-id pub-id-type="coden">BITTEL</pub-id><issn>0006-3835</issn><pub-id pub-id-type="doi">10.1007/BF01955874</pub-id></mixed-citation>
    </ref>
    <ref id="r54">
      <label>54.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cignoni</surname><given-names>P.</given-names></name><name><surname>Rocchini</surname><given-names>C.</given-names></name><name><surname>Scopigno</surname><given-names>R.</given-names></name></person-group>, “<article-title>Metro: measuring error on simplified surfaces</article-title>,” <source>Comput. Graphics Forum</source>
<volume>17</volume>(<issue>2</issue>), <fpage>167</fpage>–<lpage>174</lpage> (<year>1998</year>).<pub-id pub-id-type="coden">CGFODY</pub-id><issn>0167-7055</issn><pub-id pub-id-type="doi">10.1111/cgf.1998.17.issue-2</pub-id></mixed-citation>
    </ref>
    <ref id="r55">
      <label>55.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aubert-Broche</surname><given-names>B.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Twenty new digital brain phantoms for creation of validation image data bases</article-title>,” <source>IEEE Trans. Med. Imaging</source>
<volume>25</volume>, <fpage>1410</fpage>–<lpage>1416</lpage> (<year>2006</year>).<pub-id pub-id-type="coden">ITMID4</pub-id><issn>0278-0062</issn><pub-id pub-id-type="doi">10.1109/TMI.2006.883453</pub-id><pub-id pub-id-type="pmid">17117770</pub-id></mixed-citation>
    </ref>
    <ref id="r56">
      <label>56.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jurcak</surname><given-names>V.</given-names></name><name><surname>Tsuzuki</surname><given-names>D.</given-names></name><name><surname>Dan</surname><given-names>I.</given-names></name></person-group>, “<article-title>10/20, 10/10, and 10/5 systems revisited: their validity as relative head-surface-based positioning systems</article-title>,” <source>NeuroImage</source>
<volume>34</volume>(<issue>4</issue>), <fpage>1600</fpage>–<lpage>1611</lpage> (<year>2007</year>).<pub-id pub-id-type="coden">NEIMEF</pub-id><issn>1053-8119</issn><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.09.024</pub-id><pub-id pub-id-type="pmid">17207640</pub-id></mixed-citation>
    </ref>
    <ref id="r57">
      <label>57.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giacometti</surname><given-names>P.</given-names></name><name><surname>Perdue</surname><given-names>K. L.</given-names></name><name><surname>Diamond</surname><given-names>S. G.</given-names></name></person-group>, “<article-title>Algorithm to find high density EEG scalp coordinates and analysis of their correspondence to structural and functional regions of the brain</article-title>,” <source>J. Neurosci. Methods</source>
<volume>229</volume>, <fpage>84</fpage>–<lpage>96</lpage> (<year>2014</year>).<pub-id pub-id-type="coden">JNMEDT</pub-id><issn>0165-0270</issn><pub-id pub-id-type="doi">10.1016/j.jneumeth.2014.04.020</pub-id><pub-id pub-id-type="pmid">24769168</pub-id></mixed-citation>
    </ref>
    <ref id="r58">
      <label>58.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamran</surname><given-names>M. A.</given-names></name><name><surname>Mannan</surname><given-names>M. M. N.</given-names></name><name><surname>Jeong</surname><given-names>M. Y.</given-names></name></person-group>, “<article-title>Cortical signal analysis and advances in functional near-infrared spectroscopy signal: a review</article-title>,” <source>Front. Hum. Neurosci.</source>
<volume>10</volume>, <fpage>261</fpage> (<year>2016</year>).<pub-id pub-id-type="doi">10.3389/fnhum.2016.00261</pub-id><pub-id pub-id-type="pmid">27375458</pub-id></mixed-citation>
    </ref>
    <ref id="r59">
      <label>59.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>Q.</given-names></name><etal>et al.</etal></person-group>, “<article-title>A multi-modality image reconstruction platform for diffuse optical tomography</article-title>,” in <conf-name>Biomed. Opt.</conf-name>, BMD24, <publisher-name>Optical Society of America</publisher-name> (<year>2008</year>).</mixed-citation>
    </ref>
    <ref id="r60">
      <label>60.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Automated MRI segmentation for individualized modeling of current flow in the human head</article-title>,” <source>J. Neural Eng.</source>
<volume>10</volume>, <fpage>066004</fpage> (<year>2013</year>).<issn>1741-2560</issn><pub-id pub-id-type="doi">10.1088/1741-2560/10/6/066004</pub-id><pub-id pub-id-type="pmid">24099977</pub-id></mixed-citation>
    </ref>
    <ref id="r61">
      <label>61.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binzoni</surname><given-names>T.</given-names></name><etal>et al.</etal></person-group>, “<article-title>Light transport in tissue by 3D Monte Carlo: influence of boundary voxelization</article-title>,” <source>Comput. Meth. Programs Biomed.</source>
<volume>89</volume>, <fpage>14</fpage>–<lpage>23</lpage> (<year>2008</year>).<pub-id pub-id-type="doi">10.1016/j.cmpb.2007.10.008</pub-id></mixed-citation>
    </ref>
    <ref id="r62">
      <label>62.</label>
      <mixed-citation publication-type="web"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>Q.</given-names></name><name><surname>Tran</surname><given-names>A. P.</given-names></name></person-group>, “<article-title>Brain2Mesh: a one-liner brain mesh generator</article-title>,” <ext-link ext-link-type="uri" xlink:href="http://mcx.space/brain2mesh">http://mcx.space/brain2mesh</ext-link> (accessed <month>2</month>
<year>2020</year>).</mixed-citation>
    </ref>
  </ref-list>
  <bio id="b1">
    <p><bold>Anh Phong Tran</bold> is a PhD student in chemical engineering and MS student in electrical and computer engineering at Northeastern University in Boston, Massachusetts. He received his BS degree in chemical engineering from Tufts University in 2013. His current research interests include optics, medical imaging, control theory, and systems biology.</p>
  </bio>
  <bio id="b2">
    <p><bold>Shijie Yan</bold> is a doctoral candidate at Northeastern University. He received his BE degree from Southeast University, China, in 2013 and MS degree from Northeastern University in 2017. His research interests include Monte Carlo photon transport simulation algorithms, parallel computing, and GPU programming and optimization.</p>
  </bio>
  <bio id="b3">
    <p><bold>Qianqian Fang</bold>, PhD, is currently an assistant professor in the Bioengineering Department of Northeastern University, Boston, USA. He received his PhD from Dartmouth College in 2005. He then joined Massachusetts General Hospital and became an instructor of radiology in 2009 and an assistant professor of radiology in 2012, before he joined Northeastern University in 2015. His research interests include translational medical imaging devices, multimodal imaging, image reconstruction algorithms, and high-performance computing tools to facilitate the development of next-generation imaging platforms.</p>
  </bio>
</back>
