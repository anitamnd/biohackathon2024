<?DTDIdentifier.IdentifierValue http://null/schema/dtds/document/fulltext/xcr/xocs-article.xsd?>
<?DTDIdentifier.IdentifierType schema?>
<?SourceDTD.DTDName xocs-article.xsd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName ftrr2jats.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Inform Med Unlocked</journal-id>
    <journal-id journal-id-type="iso-abbrev">Inform Med Unlocked</journal-id>
    <journal-title-group>
      <journal-title>Informatics in Medicine Unlocked</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2352-9148</issn>
    <publisher>
      <publisher-name>The Author(s). Published by Elsevier Ltd.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7901302</article-id>
    <article-id pub-id-type="pii">S2352-9148(21)00030-7</article-id>
    <article-id pub-id-type="doi">10.1016/j.imu.2021.100540</article-id>
    <article-id pub-id-type="publisher-id">100540</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>COVIDC: An expert system to diagnose COVID-19 and predict its severity using chest CT scans: Application in radiology</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Abbasi</surname>
          <given-names>Wajid Arshad</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Abbas</surname>
          <given-names>Syed Ali</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au3">
        <name>
          <surname>Andleeb</surname>
          <given-names>Saiqa</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au4">
        <name>
          <surname>ul Islam</surname>
          <given-names>Ghafoor</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au5">
        <name>
          <surname>Ajaz</surname>
          <given-names>Syeda Adin</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au6">
        <name>
          <surname>Arshad</surname>
          <given-names>Kinza</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au7">
        <name>
          <surname>Khalil</surname>
          <given-names>Sadia</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au8">
        <name>
          <surname>Anjam</surname>
          <given-names>Asma</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au9">
        <name>
          <surname>Ilyas</surname>
          <given-names>Kashif</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au10">
        <name>
          <surname>Saleem</surname>
          <given-names>Mohsib</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au11">
        <name>
          <surname>Chughtai</surname>
          <given-names>Jawad</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au12">
        <name>
          <surname>Abbas</surname>
          <given-names>Ayesha</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">a</xref>
      </contrib>
      <aff id="aff1"><label>a</label>Computational Biology and Data Analysis Lab., Department of Computer Science &amp; Information Technology, King Abdullah Campus, University of Azad Jammu &amp; Kashmir, Muzaffarabad, AJ&amp;K, 13100, Pakistan</aff>
      <aff id="aff2"><label>b</label>Biotechnology Lab., Department of Zoology, King Abdullah Campus, University of Azad Jammu &amp; Kashmir, Muzaffarabad, AJ&amp;K, 13100, Pakistan</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>∗</label>Corresponding author.</corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="ppub">
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>23</day>
      <month>2</month>
      <year>2021</year>
    </pub-date>
    <volume>23</volume>
    <fpage>100540</fpage>
    <lpage>100540</lpage>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>12</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>17</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>2</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 The Author(s)</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <license-p>Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.</license-p>
      </license>
    </permissions>
    <abstract id="abs0010">
      <p>Early diagnosis of Coronavirus disease 2019 (COVID-19) is significantly important, especially in the absence or inadequate provision of a specific vaccine, to stop the surge of this lethal infection by advising quarantine. This diagnosis is challenging as most of the patients having COVID-19 infection stay asymptomatic while others showing symptoms are hard to distinguish from patients having different respiratory infections such as severe flu and Pneumonia. Due to cost and time-consuming wet-lab diagnostic tests for COVID-19, there is an utmost requirement for some alternate, non-invasive, rapid, and discounted automatic screening system. A chest CT scan can effectively be used as an alternative modality to detect and diagnose the COVID-19 infection. In this study, we present an automatic COVID-19 diagnostic and severity prediction system called COVIDC (COVID-19 detection using CT scans) that uses deep feature maps from the chest CT scans for this purpose. Our newly proposed system not only detects COVID-19 but also predicts its severity by using a two-phase classification approach (COVID vs non-COVID, and COVID-19 severity) with deep feature maps and different shallow supervised classification algorithms such as SVMs and random forest to handle data scarcity. We performed a stringent COVIDC performance evaluation not only through 10-fold cross-validation and an external validation dataset but also in a real setting under the supervision of an experienced radiologist. In all the evaluation settings, COVIDC outperformed all the existing state-of-the-art methods designed to detect COVID-19 with an F1 score of 0.94 on the validation dataset and justified its use to diagnose COVID-19 effectively in the real setting by classifying correctly 9 out of 10 COVID-19 CT scans. We made COVIDC openly accessible through a cloud-based webserver and python code available at <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/view/wajidarshad/software" id="PC_link1IUx9tPSBs">https://sites.google.com/view/wajidarshad/software</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/wajidarshad/covidc" id="PC_linkRRfvJUMby2">https://github.com/wajidarshad/covidc</ext-link>.</p>
    </abstract>
    <abstract abstract-type="graphical" id="abs0015">
      <title>Graphical abstract</title>
      <p>
        <fig id="undfig1" position="anchor">
          <alt-text id="alttext0010">Image 1</alt-text>
          <graphic xlink:href="fx1_lrg"/>
        </fig>
      </p>
    </abstract>
    <kwd-group id="kwrds0010">
      <title>Keywords</title>
      <kwd>COVID-19</kwd>
      <kwd>CT imaging</kwd>
      <kwd>Expert system</kwd>
      <kwd>Early diagnosis</kwd>
      <kwd>SARS-COV-2</kwd>
      <kwd>Pandemic</kwd>
      <kwd>Radiology</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0025">Coronavirus disease 2019 (COVID-19) is a contagious infection caused by a family of viruses called coronaviridea. Since its identification at the end of 2019 in Wuhan, a city in the Hubei Province of China, this viral disease has spread rapidly around the globe [<xref rid="bib1" ref-type="bibr">1</xref>]. The World Health Organization (WHO) has already declared this pandemic as a global health calamity and it has infected and killed millions of people worldwide [<xref rid="bib2" ref-type="bibr">2</xref>]. Physicians say this is a viral infection that mainly infects the human respiratory system and antibiotics do not cure this disease [<xref rid="bib3" ref-type="bibr">3</xref>,<xref rid="bib4" ref-type="bibr">4</xref>]. Meanwhile, currently, there is an inadequate provision of an effective vaccine or medication to prevent or cure this lethal infection.</p>
    <p id="p0030">In the absence or insufficient supply of effective medication or vaccines to cure or prevent COVID-19 infection, early diagnosis of the disease is fundamental to avoid its further surge by advising or adopting quarantine or isolation. Most of the patients having COVID-19 infection stay asymptomatic while others show mild to moderate symptoms such as fever or cough, shortness of breath, and signs such as oxygen saturation or lung auscultation [<xref rid="bib5" ref-type="bibr">5</xref>,<xref rid="bib6" ref-type="bibr">6</xref>]. Signs and symptoms have the utmost importance to identify any infection and to perform further diagnostic tests. However, even symptomatic COVID-19 infection does not show any particular symptoms which distinguish this from other respiratory infections such as severe flu and Pneumonia [<xref rid="bib6" ref-type="bibr">6</xref>]. In this situation, all the suspected patients require screening and have to pass through the adopted diagnostic tests.</p>
    <p id="p0035">Currently, there are two types of tests to detect COVID-19: diagnostic tests and antibody tests [<xref rid="bib7" ref-type="bibr">7</xref>]. A diagnostic test such as Reverse transcription-polymerase chain reaction (RT-PCR) can be used to detect an active coronavirus infection whereas, the antibody test looks for antibodies created in your body in the response to the disease. RT-PCR is currently the gold standard diagnostic practice to detect viral infection [<xref rid="bib8" ref-type="bibr">8</xref>]. However, the standard confirmatory clinical RT-PCR test to detect COVID-19 is manual, complex, laborious, costly, and ineffective [<xref rid="bib9" ref-type="bibr">9</xref>,<xref rid="bib10" ref-type="bibr">10</xref>]. Moreover, the limited availability of test kits and domain experts further hamper the situation. Meanwhile, antibody tests cannot be used to diagnose COVID-19 as after infection, antibodies can take numerous days or weeks to develop and may stay in your blood a bit longer after recovery [<xref rid="bib7" ref-type="bibr">7</xref>]. Keeping in view the limitation of prevailing diagnostic techniques and a rapid surge of infected patients, there is an utmost requirement for some alternate automatic screening systems that can be used by the physicians to swiftly identify and isolate the COVID-19 infected patients.</p>
    <p id="p0040">X-ray and Computed Tomography (CT) imaging modalities are the most common noninvasive diagnostic techniques that help medical practitioners to diagnose and treat many diseases. In the current framework, chest X-ray (CXR) and chest Computed Tomography (CCT) can also effectively be used to diagnose COVID-19 [<xref rid="bib11" ref-type="bibr">11</xref>,<xref rid="bib12" ref-type="bibr">12</xref>]. However, CCT due to 3D image and contrast dyes shows a significantly improved performance in COVID-19 diagnosis in comparison to simple 2D CXR [<xref rid="bib9" ref-type="bibr">9</xref>]. In the meanwhile, CT scans of COVID-19 infected patients show diverse features and manual interpretation of these scans with subtle variations is quite challenging [<xref rid="bib13" ref-type="bibr">13</xref>]. Moreover, the current enormous upsurge of infected patients makes it a challenging task for the domain experts to complete a timely diagnosis [<xref rid="bib14" ref-type="bibr">14</xref>,<xref rid="bib15" ref-type="bibr">15</xref>]. Therefore, some Computer-Aided Diagnostic (CAD) systems are required to better manipulate and understand the CCT images.</p>
    <p id="p0045">In Computer-Aided Diagnostic (CAD) system design using CT scans, machine learning in the form of deep learning has successfully been applied in diagnosing lung diseases [<xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib17" ref-type="bibr">[17]</xref>, <xref rid="bib18" ref-type="bibr">[18]</xref>, <xref rid="bib19" ref-type="bibr">[19]</xref>]. Also to diagnose COVID-19 using CCT images, several machine learning-based methods with varying sources and amount of training data have been proposed in the literature (for details please see “Related Works” in the next section). Most of these previously proposed methods in the literature are based on Convolution Neural Network (CNN) deep learning approach [<xref rid="bib20" ref-type="bibr">20</xref>]. However, for the deep learning approaches to perform effectively, a healthy amount of data is usually required for parameter tuning which is not readily available so far. Moreover, all the published studies focused only to diagnose COVID-19 whereas, its severity prediction still requires an efficient method. Therefore, to address the issues of data scarcity in deep learning and the absence of an efficient method for COVID-19 severity prediction, in this article we have proposed a method called COVIDC (COVID-19 detection using CT scans) to diagnose and predict the severity of the COVID-19 infection with CCT images. Our proposed method is different from previously proposed methods for the diagnosis of the COVID-19 and its severity prediction in that it uses a combination of transfer and shallow learning. Using this method, we can extract efficient feature representation of CT scans by using transfer learning with off-the-shelf pre-trained models on ImageNET and still be able to avoid the curse of dimensionality by engaging shallow learning algorithms such as Support Vector Machines (SVMs) [<xref rid="bib21" ref-type="bibr">21</xref>]. This has led to improved accuracy in comparison to methods that rely only on the deep learning paradigm.</p>
  </sec>
  <sec id="sec2">
    <label>2</label>
    <title>Related Works</title>
    <p id="p0050">Since COVID-19 identification at the end of 2019, several studies have been proposed in the literature to diagnose COVID-19 with chest computed tomography (CT) by using artificial intelligence (AI) techniques. We have searched existing techniques in the online literature using different keywords such as “Machine learning and COVID-19”, “COVID-19 diagnosis with CT scans”, and “COVID-19 diagnosis with CT scans and machine learning”. While going through the online existing literature (peer-reviewed) published in reputed journals, we found a plethora of machine learning techniques to diagnose COVID-19 using chest CT scans with varying sources and amount of training data [<xref rid="bib22" ref-type="bibr">[22]</xref>, <xref rid="bib23" ref-type="bibr">[23]</xref>, <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib25" ref-type="bibr">[25]</xref>, <xref rid="bib26" ref-type="bibr">[26]</xref>, <xref rid="bib27" ref-type="bibr">[27]</xref>, <xref rid="bib28" ref-type="bibr">[28]</xref>, <xref rid="bib29" ref-type="bibr">[29]</xref>, <xref rid="bib30" ref-type="bibr">[30]</xref>, <xref rid="bib31" ref-type="bibr">[31]</xref>, <xref rid="bib32" ref-type="bibr">[32]</xref>, <xref rid="bib33" ref-type="bibr">[33]</xref>, <xref rid="bib34" ref-type="bibr">[34]</xref>, <xref rid="bib35" ref-type="bibr">[35]</xref>, <xref rid="bib36" ref-type="bibr">[36]</xref>, <xref rid="bib37" ref-type="bibr">[37]</xref>]. All these previously published techniques can be categorized into three main classes as follows: Deep learning-based, transfer learning with fine-tuning a customized fully connected layer, shallow learning with handcrafted textured features.</p>
    <p id="p0055">Previously published studies employing deep learning-based machine learning techniques to detect COVID-19 mostly used Convolution Neural Network (CNN) [<xref rid="bib20" ref-type="bibr">20</xref>] based architectures in their proposed design [<xref rid="bib23" ref-type="bibr">[23]</xref>, <xref rid="bib24" ref-type="bibr">[24]</xref>, <xref rid="bib25" ref-type="bibr">[25]</xref>,<xref rid="bib29" ref-type="bibr">29</xref>,<xref rid="bib31" ref-type="bibr">[31]</xref>, <xref rid="bib32" ref-type="bibr">[32]</xref>, <xref rid="bib33" ref-type="bibr">[33]</xref>, <xref rid="bib34" ref-type="bibr">[34]</xref>, <xref rid="bib35" ref-type="bibr">[35]</xref>, <xref rid="bib36" ref-type="bibr">[36]</xref>, <xref rid="bib37" ref-type="bibr">[37]</xref>]. However, deep learning approaches to generalize well normally require an enormous amount of data which is not readily available right now [<xref rid="bib22" ref-type="bibr">22</xref>].</p>
    <p id="p0060">Due to data scarcity issues in CNN-based deep learning, some studies have also been proposed in the literature using transfer learning [<xref rid="bib22" ref-type="bibr">22</xref>,<xref rid="bib28" ref-type="bibr">28</xref>,<xref rid="bib30" ref-type="bibr">30</xref>]. Ahuja et al. used data augmentation and transfer learning with ResNet18, ResNet50, ResNet101, and SqueezeNet pretrained networks to classify COVID-19 images. Ahuja et al. concluded that ResNet18 outperformed other models by obtaining a 0.97 AUC score [<xref rid="bib22" ref-type="bibr">22</xref>]. Ko et al. proposed a fast-track COVID-19 classification model network based on transfer learning with VGG16, ResNet-50, InceptionV3, and Xception as backbone pre-trained models to diagnose COVID-19. They considered 1194 COVID-19, 264 low-quality COVID-19 (only for testing), and 2239 pneumonia, normal, and other disease CT scans in their study. They also used rotation and zoom data augmentation procedures to maximize the number of training samples. It was concluded that FCONet based on ResNet-50 outperformed other pre-trained models and achieved 96.97% of accuracy in the external validation data set of COVID-19 pneumonia images [<xref rid="bib28" ref-type="bibr">28</xref>,<xref rid="bib38" ref-type="bibr">38</xref>]. Pathak et al. proposed a transfer learning-based system to detect COVID-19 in CT scans with the ResNet50 to extract the features and a 2D convolutional neural network for the classification [<xref rid="bib30" ref-type="bibr">30</xref>]. The proposed system achieved a 93.01% of accuracy with 10-fold cross-validation on 413 COVID and 439 non-COVID scans. These previously published methods to detect COVID-19 using transfer learning still have room for improvement because in transfer learning, fine-tuning the customized fully connected layer requires a healthy amount of data due to high dimensional features space generated by the off-the-shelf pre-trained models.</p>
    <p id="p0065">To solve data scarcity issues in deep learning, Kang et al. proposed a shallow learning technique for COVID-19 classification using different types of handcrafted features extracted from CT images [<xref rid="bib27" ref-type="bibr">27</xref>]. They used 2522 CT images (1495 are from COVID-19 patients, and 1027 are from community-acquired pneumonia) for the classification purpose. The proposed method achieved an overall accuracy of 95.5%. However, even after learning multiple representations of CT scans, the method proposed by Kang et al. still has room for performance improvement because it is often hard to represent subtle variations in CT scans using handcrafted texture descriptors [<xref rid="bib39" ref-type="bibr">39</xref>]. Moreover, almost all the above studies have been proposed only to diagnose COVID-19 but its efficient severity detection is still an open research question. Furthermore, to the best of our knowledge, all of the above-discussed studies only discussed the technical details of their proposed methodology without providing any easily accessible interface to end-users. To overcome these shortcomings and to deal with the issues of data scarcity in deep/transfer learning and handcrafted textured features, in this study we have proposed a novel COVID-19 diagnosis and its severity predictor called COVIDC (COVID-19 detection using CT scans) by employing a combination of transfer and shallow learning.</p>
  </sec>
  <sec id="sec3">
    <label>3</label>
    <title>Methods</title>
    <p id="p0070">In the following sections, we give the detail of our experimental procedure to design and test the generalization performance of COVIDC (COVID-19 diagnosis using CT images).</p>
    <sec id="sec3.1">
      <label>3.1</label>
      <title>Dataset and preprocessing</title>
      <p id="p0075">In this study, we have collected three different datasets of Chest Computed Tomography (CCT) images from publicly open online repositories [<xref rid="bib40" ref-type="bibr">[40]</xref>, <xref rid="bib41" ref-type="bibr">[41]</xref>, <xref rid="bib42" ref-type="bibr">[42]</xref>]. For COVID-19 diagnosis, we have used two datasets: i) training set (1433 COVID and 1229 non-COVID CT images) [<xref rid="bib41" ref-type="bibr">41</xref>], ii) external validation set (349 COVID and 397 non-COVID) [<xref rid="bib42" ref-type="bibr">42</xref>]. For COVID-19 severity prediction, we have used a dataset of 141 CT images of severe COVID-19 patients and 135 CT images of less-severe [<xref rid="bib40" ref-type="bibr">40</xref>]. All the images in these datasets have gone through the essential preprocessing required for feature extraction including image resizing (313 × 313 pixels), de-noising, and contrast stretching [<xref rid="bib43" ref-type="bibr">43</xref>].</p>
    </sec>
    <sec id="sec3.2">
      <label>3.2</label>
      <title>Proposed methodology</title>
      <p id="p0080">The methodology we have adopted for this study has been shown in <xref rid="fig1" ref-type="fig">Fig. 1</xref>
. We give the detail of our proposed methodology to design and develop CT image-based COVID-19 diagnosis and its severity predictor using machine learning as follows.<fig id="fig1"><label>Fig. 1</label><caption><p>A proposed methodology for the development of computer-aided COVID-19 diagnosis and its severity prediction system (COVIDC) using Machine learning and chest CT images. This system has been trained using shallow learning algorithms such as SVMs with chest CT scans by extracting feature maps involving pre-trained off-the-shelf models. COVIDC can be used to predict whether a novel test CT image has COVID-19 or not.</p></caption><alt-text id="alttext0015">Fig. 1</alt-text><graphic xlink:href="gr1_lrg"/></fig></p>
    </sec>
    <sec id="sec3.3">
      <label>3.3</label>
      <title>Features extraction and preprocessing</title>
      <p id="p0085">Deep learning, where we learn automatically an efficient feature representation of an image, is very famous and has successfully been used in different image classification and analysis tasks. However, to apply deep learning efficiently, we normally require an extensive amount of data to better learn the actual distribution of the image samples. This data hunger is a challenge so far to apply the deep learning approach efficiently in our case to diagnose and predict the severity of COVID-19 where we face data scarcity. Therefore, to overcome this challenge, we have used the transfer learning strategy for feature extraction. Using transfer learning, feature extraction from the available CT images in our datasets has been performed using different off-the-shelf CNN based pre-trained models on ImageNet. For this purpose, we have used different off-the-shelf CNN based pre-trained models such as Resnet50 [<xref rid="bib44" ref-type="bibr">44</xref>], InceptionV3 [<xref rid="bib45" ref-type="bibr">45</xref>], Xception [<xref rid="bib46" ref-type="bibr">46</xref>], VGG16 [<xref rid="bib47" ref-type="bibr">47</xref>], NASNetLarge [<xref rid="bib48" ref-type="bibr">48</xref>], DenseNet121 [<xref rid="bib49" ref-type="bibr">49</xref>]. We have used these models for feature extraction by simply loading a pre-trained model without its classifier part by specifying the “<italic>include_top</italic>” argument as “<italic>False</italic>”. The selection of these pre-trained CNN based models was based on their reported accuracy. Preprocessing and resizing required by these pre-trained models have been applied before extracting the features map.</p>
    </sec>
    <sec id="sec3.4">
      <label>3.4</label>
      <title>Classification algorithms</title>
      <p id="p0090">Most of the machine learning studies involved in COVID-19 diagnosis have used pure deep learning strategies or transfer learning with a customized fully connected layer to be fine-tuned. However, to train deep neural networks from scratch or to fine-tune the parameters of the customized fully connected layers on the top of a pre-trained model, we need an extensive amount of data and high-performance computational resources, which is mostly impractical [<xref rid="bib50" ref-type="bibr">50</xref>]. Therefore, we have proposed a different machine learning-based approach for the preliminary diagnosis of COVID-19 and its severity prediction using digital chest CT images. The novelty of the proposed approach is that it uses a blend of pre-trained CNN based models to extract features and shallow learning algorithms such as SVMs for the classification purpose. The proposed scheme is somehow based on the paradigm of transfer learning.</p>
      <p id="p0095">In this work, our dataset consists of examples of the form <inline-formula><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="M2" altimg="si2.svg"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a chest CT image and <inline-formula><mml:math id="M3" altimg="si3.svg"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mo linebreak="badbreak">+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is its associated label. For COVID-19 identification, <inline-formula><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> indicate whether <inline-formula><mml:math id="M5" altimg="si2.svg"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> belongs to a COVID-19 patient (+1) or not (−1) and for COVID-19 severity prediction <inline-formula><mml:math id="M6" altimg="si4.svg"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> indicate severe (+1) or mild (−1). For a given chest CT image <inline-formula><mml:math id="M7" altimg="si2.svg"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, we extract deep feature maps denoted by <inline-formula><mml:math id="M8" altimg="si5.svg"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Our objective is to learn two separate functions for the diagnosis and severity prediction of COVID-19. For this purpose, we have used three different machine learning-based classification algorithms: classical Support Vector Machine (SVM), Random Forest (RF), and Gradient Boosting Machine (XGBoost) [<xref rid="bib51" ref-type="bibr">[51]</xref>, <xref rid="bib52" ref-type="bibr">[52]</xref>, <xref rid="bib53" ref-type="bibr">[53]</xref>]. The detail of these shallow machine learning algorithms is as follows.</p>
      <sec id="sec3.4.1">
        <label>3.4.1</label>
        <title>Support Vector classification (SVC)</title>
        <p id="p0100">We used SVM for the diagnosis of COVID-19 and its severity prediction by learning a function <inline-formula><mml:math id="M9" altimg="si6.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="M10" altimg="si7.svg"><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:math></inline-formula> as parameters to be learned from the training data <inline-formula><mml:math id="M11" altimg="si8.svg"><mml:mrow><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> The optimal value of the <inline-formula><mml:math id="M12" altimg="si7.svg"><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:math></inline-formula> is obtained in SVM by solving the following optimization problem [<xref rid="bib52" ref-type="bibr">52</xref>].<disp-formula id="fd1"><label>(1)</label><mml:math id="M13" altimg="si9.svg" alttext="Equation 1."><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>λ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo linebreak="badbreak">+</mml:mo><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>S</mml:mi><mml:mi>u</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.25em"/><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">≥</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
</p>
        <p id="p0105">The objective function in Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref> maximizes the margin while minimizing margin violations (or slacks ξ) [<xref rid="bib52" ref-type="bibr">52</xref>]. The hyperparameter <inline-formula><mml:math id="M14" altimg="si10.svg"><mml:mrow><mml:mi>λ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula> controls the tradeoff between margin maximization and margin violation. We used both linear and radial basis function (RBF) kernels and coarsely optimized the values of λ and γ using grid search with scikit-learn (version:0.23) [<xref rid="bib54" ref-type="bibr">54</xref>].</p>
      </sec>
      <sec id="sec3.4.2">
        <label>3.4.2</label>
        <title>Random Forest Classification (RFC)</title>
        <p id="p0110">Random Forest Classification (RFC) uses an ensemble learning technique based on bagging. A random forest operates by constructing several decision trees in parallel during training and outputs the mean of the classes as the prediction of all trees [<xref rid="bib51" ref-type="bibr">51</xref>]. It usually performs better on problems having features with non-linear relationships. Each classification tree in the RF is constructed on randomly sampled subsets of input features. In this study, we have optimized RF for the number of decision trees in the forest, the maximum number of features considered for splitting a node, the maximum number of levels in each decision tree, and a minimum number of samples required to split. We have also seen this classification technique effectively in action in many other studies [<xref rid="bib55" ref-type="bibr">[55]</xref>, <xref rid="bib56" ref-type="bibr">[56]</xref>, <xref rid="bib57" ref-type="bibr">[57]</xref>, <xref rid="bib58" ref-type="bibr">[58]</xref>].</p>
      </sec>
      <sec id="sec3.4.3">
        <label>3.4.3</label>
        <title>XGBoost calssification (XGBC)</title>
        <p id="p0115">XGBoost is also an ensemble learning technique based on the boosting that combines weak learners into a strong learner in an iterative fashion [<xref rid="bib53" ref-type="bibr">53</xref>,<xref rid="bib59" ref-type="bibr">59</xref>]. We have used trees as default base learners in XGBoost ensembles. In this study, we have optimized XGBoost in terms of the learning rate, maximum depth, the number of boosting iterations, booster, and subsample ratio with a grid search and using a python-based package xgboost 0.7 [<xref rid="bib59" ref-type="bibr">59</xref>].</p>
      </sec>
    </sec>
    <sec id="sec3.5">
      <label>3.5</label>
      <title>Online access to COVIDC</title>
      <p id="p0120">We have developed and deployed a webserver of COVIDC which uses the optimal machine learning model for COVID-19 diagnosis and its severity prediction. This webserver takes a chest CT image and performs COVID-19 diagnosis and its severity prediction for it. After the successful submission of a CT image, users get COVIDC predictions in the form of COVID-19 identification and its severity prediction. This process has broken into two steps: 1) whether the uploaded image represents a COVID-19 patient or not (COVID vs non-COVID), 2) if it is a COVID-19 infection then how severe it is. The webserver is available at <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/view/wajidarshad/software" id="intref0010">https://sites.google.com/view/wajidarshad/software</ext-link>.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <label>4</label>
    <title>Results</title>
    <sec id="sec4.1">
      <label>4.1</label>
      <title>Experimental setup</title>
      <p id="p0125">We have used two different datasets for COVID-19 diagnosis: train-test set (1433 COVID and 1229 non-COVID CT images) <xref rid="bib41" ref-type="bibr">[41]</xref>, ii) external validation set (349 COVID and 397 non-COVID) <xref rid="bib42" ref-type="bibr">[42]</xref>, and reported performance metrics on both the datasets. For the train-test set, we have used 10-fold cross-validation (CV). In a 10-fold CV, we have shuffled images in our datasets and then split them into 10 groups. Ten models have been trained and evaluated with each group given a chance to be held out as the test set <xref rid="bib60" ref-type="bibr">[60]</xref>. Average performance metrics across folds have been reported. For the external validation set, we trained the classification models using the whole train-test set and tested them on the validation set. We have used the area under the ROC curve (ROC), the area under the precision-recall curve (PR), and F-measure (F1: Harmonic mean of the model's precision and recall) as performance measures for model evaluation and performance assessment <xref rid="bib60" ref-type="bibr">[60]</xref>, <xref rid="bib61" ref-type="bibr">[61]</xref>, <xref rid="bib62" ref-type="bibr">[62]</xref>. We used grid search over training data to find the optimal values of hyper-parameters of different classification models. The detailed discussion of results showing the predictive performance of our proposed method over cross-validation and also on an external validation dataset is given as follows.</p>
    </sec>
    <sec id="sec4.2">
      <label>4.2</label>
      <title>Classification results of COVID versus non-COVID CT images</title>
      <p id="p0130">We have trained various shallow machine learning models for the classification of COVID versus non-COVID CT scan images with a range of deep learning-based feature maps and evaluated using both 10-fold cross-validation (CV) and on an external validation dataset. The results of our evaluation in both settings are shown in <xref rid="tbl1" ref-type="table">Table 1</xref>, <xref rid="tbl2" ref-type="table">Table 2</xref>
and <xref rid="fig2" ref-type="fig">Fig. 2</xref>
. Using 10-fold CV, we observed a maximum F1-score of 0.98 along with 0.99, and 0.99 as the area under the ROC curve, and the area under the PR curve, respectively with Support Vector Classifier and DenseNet121 feature map (<xref rid="tbl1" ref-type="table">Table 1</xref>). The F1-score of 0.98 and area under the PR curve of 0.99 show the perfect sensitivity and precision of our proposed method while classifying COVID and non-COVID CT scans efficiently. Higher values of sensitivity show that our trained model produces fewer false negatives (classifying COVID as non-COVID) which is a genuine requirement in this case.<table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>Predictive performance for COVID-19 diagnosis across different classification models and feature maps using 10-fold CV (COVID vs non-COVID).</p></caption><alt-text id="alttext0030">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Feature Map</th><th colspan="3">SVC<hr/></th><th colspan="3">RFC<hr/></th><th colspan="3">XGBC<hr/></th></tr><tr><th>ROC</th><th>PR</th><th>F1</th><th>ROC</th><th>PR</th><th>F1</th><th>ROC</th><th>PR</th><th>F1</th></tr></thead><tbody><tr><td align="left"><bold>Resnet50</bold></td><td align="left">0.98 ± 0.03</td><td align="left">0.98 ± 0.03</td><td align="left">0.95</td><td align="left">0.96 ± 0.03</td><td align="left">0.96 ± 0.03</td><td align="left">0.90</td><td align="left">0.97 ± 0.01</td><td align="left">0.97 ± 0.01</td><td align="left">0.92</td></tr><tr><td align="left"><bold>Xception</bold></td><td align="left">0.98 ± 0.04</td><td align="left">0.98 ± 0.04</td><td align="left">0.96</td><td align="left">0.96 ± 0.03</td><td align="left">0.96 ± 0.03</td><td align="left">0.89</td><td align="left">0.97 ± 0.01</td><td align="left">0.97 ± 0.01</td><td align="left">0.92</td></tr><tr><td align="left"><bold>InceptionV3</bold></td><td align="left">0.98 ± 0.03</td><td align="left">0.98 ± 0.03</td><td align="left">0.96</td><td align="left">0.96 ± 0.03</td><td align="left">0.96 ± 0.03</td><td align="left">0.89</td><td align="left">0.97 ± 0.01</td><td align="left">0.97 ± 0.01</td><td align="left">0.92</td></tr><tr><td align="left"><bold>VGG16</bold></td><td align="left">0.98 ± 0.03</td><td align="left">0.98 ± 0.03</td><td align="left">0.95</td><td align="left">0.96 ± 0.03</td><td align="left">0.96 ± 0.03</td><td align="left">0.90</td><td align="left">0.96 ± 0.01</td><td align="left">0.96 ± 0.01</td><td align="left">0.88</td></tr><tr><td align="left"><bold>NASNetLarge</bold></td><td align="left">0.97 ± 0.04</td><td align="left">0.97 ± 0.04</td><td align="left">0.94</td><td align="left">0.95 ± 0.03</td><td align="left">0.95 ± 0.03</td><td align="left">0.88</td><td align="left">0.97 ± 0.01</td><td align="left">0.97 ± 0.01</td><td align="left">0.90</td></tr><tr><td align="left"><bold>DenseNet121</bold></td><td align="left"><bold>0.99</bold> ± <bold>0.03</bold></td><td align="left"><bold>0.99</bold> ± <bold>0.03</bold></td><td align="left"><bold>0.98</bold></td><td align="left"><bold>0.96</bold> ± <bold>0.01</bold></td><td align="left"><bold>0.96</bold>± <bold>0.01</bold></td><td align="left"><bold>0.90</bold></td><td align="left"><bold>0.98</bold> ± <bold>0.03</bold></td><td align="left"><bold>0.98</bold> ± <bold>0.03</bold></td><td align="left"><bold>0.94</bold></td></tr></tbody></table><table-wrap-foot><fn><p>ROC (Area under the ROC curve), PR (Area under the precision-recall curve), F1 (F1 Score), SVC (Support Vector classifier), RF (Random Forest classifier), XGBC (XGBoost classifier). Bold-faced values indicate the best performance for each model.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Predictive performance for COVID-19 diagnosis across different classification models and feature maps on external validation dataset (COVID vs non-COVID).</p></caption><alt-text id="alttext0035">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Feature Map</th><th colspan="3">SVC<hr/></th><th colspan="3">RFC<hr/></th><th colspan="3">XGBC<hr/></th></tr><tr><th>ROC</th><th>PR</th><th>F1</th><th>ROC</th><th>PR</th><th>F1</th><th>ROC</th><th>PR</th><th>F1</th></tr></thead><tbody><tr><td align="left"><bold>Resnet50</bold></td><td align="left">0.96</td><td align="left">0.96</td><td align="left">0.90</td><td align="left">0.92</td><td align="left">0.92</td><td align="left">0.83</td><td align="left">0.90</td><td align="left">0.91</td><td align="left">0.82</td></tr><tr><td align="left"><bold>Xception</bold></td><td align="left">0.96</td><td align="left">0.96</td><td align="left">0.90</td><td align="left">0.90</td><td align="left">0.90</td><td align="left">0.82</td><td align="left">0.90</td><td align="left">0.91</td><td align="left">0.82</td></tr><tr><td align="left"><bold>InceptionV3</bold></td><td align="left">0.96</td><td align="left">0.96</td><td align="left">0.90</td><td align="left">0.90</td><td align="left">0.90</td><td align="left">0.83</td><td align="left">0.90</td><td align="left">0.91</td><td align="left">0.82</td></tr><tr><td align="left"><bold>VGG16</bold></td><td align="left">0.96</td><td align="left">0.96</td><td align="left">0.89</td><td align="left">0.90</td><td align="left">0.90</td><td align="left">0.82</td><td align="left">0.90</td><td align="left">0.91</td><td align="left">0.82</td></tr><tr><td align="left"><bold>NASNetLarge</bold></td><td align="left">0.94</td><td align="left">0.94</td><td align="left">0.88</td><td align="left">0.88</td><td align="left">0.88</td><td align="left">0.80</td><td align="left">0.87</td><td align="left">0.88</td><td align="left">0.80</td></tr><tr><td align="left"><bold>DenseNet121</bold></td><td align="left"><bold>0.98</bold></td><td align="left"><bold>0.98</bold></td><td align="left"><bold>0.94</bold></td><td align="left"><bold>0.92</bold></td><td align="left"><bold>0.92</bold></td><td align="left"><bold>0.83</bold></td><td align="left"><bold>0.93</bold></td><td align="left"><bold>0.93</bold></td><td align="left"><bold>0.84</bold></td></tr></tbody></table><table-wrap-foot><fn><p>ROC (Area under the ROC curve), PR (Area under the precision-recall curve), F1 (F1 Score), SVC (Support Vector classifier), RF (Random Forest classifier), XGBC (XGBoost classifier). Bold-faced values indicate the best performance for each model.</p></fn></table-wrap-foot></table-wrap><fig id="fig2"><label>Fig. 2</label><caption><p>Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves showing predictive performance of COVIDC for the classification of chest CT images across different classifiers (SVM, RF, XGB) and DenseNet feature map on an external validation dataset. <bold>COVID vs non-COVID: ROC(A), PR(B)</bold>.</p></caption><alt-text id="alttext0020">Fig. 2</alt-text><graphic xlink:href="gr2_lrg"/></fig></p>
      <p id="p0135">Meanwhile, using an external validation dataset for the evaluation of our machine learning models trained on the training set, we observed a similar trend of performance with an F1-score of 0.94 along with 0.98, and 0.98 as the area under the ROC curve, and the area under the PR curve, respectively with Support Vector Classifier and DenseNet121 features map (<xref rid="tbl2" ref-type="table">Table 2</xref>, <xref rid="fig2" ref-type="fig">Fig. 2</xref>(A) and <xref rid="fig2" ref-type="fig">(B)</xref>). As our external validation dataset is completely different (collected in a different country with different settings) and images have huge variations with our training set. Therefore, achieving an F1-score of 0.94 shows a significant consistent generalization performance of our proposed method in diverse CT imaging environments. Moreover, the significantly better performance of SVM in comparison to Random Forest (RF) and Extreme Boosting Machine (XGB) is attributed to its ability to deal well with high dimensional features with fewer examples as in our case. Moreover, features extracted through pre-trained deep learning models perform better than handcrafted ones as in the case of the study performed by Chandra et al., [<xref rid="bib15" ref-type="bibr">15</xref>].</p>
    </sec>
    <sec id="sec4.3">
      <label>4.3</label>
      <title>Classification results of COVID-19 severity prediction with CT images</title>
      <p id="p0140">Along with COVID-19 diagnosis using CT images, we have also tried to predict the severity of COVID-19 infection using the same image modality. For this purpose, we have trained several shallow machine learning models for the classification of severe versus mild COVID-19 infection using chest CT scans of COVID-19 infected patients with a range of deep learning-based feature maps and evaluated using 10-fold cross-validation (CV). To the best of our knowledge, this is the first study on COVID-19 severity prediction posed as a classification problem using machine learning with CT image modality. The results of our evaluation are shown in <xref rid="tbl3" ref-type="table">Table 3</xref>
. Using 10-fold CV, we observed a maximum F1-score of 1.0 along with 1.00, and 0.99 as the area under the ROC curve, and the area under the PR curve, respectively with Support Vector Classifier and DenseNet121 feature map (<xref rid="tbl3" ref-type="table">Table 3</xref>). The F score of 1.0 with an area under the PR of 0.99 shows that our proposed classification model produces almost zero false positives (classifying mild COVID-19 as severe) and false negatives (classifying severe COVID-19 as mild). These results show that we have been able to classify the severe and mild COVID-19 patients with perfect accuracy using our proposed method called COVIDC.<table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>Predictive performance for COVID-19 severity prediction across different classification models and feature maps using 10-fold CV.</p></caption><alt-text id="alttext0040">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Feature Map</th><th colspan="3">SVC<hr/></th><th colspan="3">RFC<hr/></th><th colspan="3">XGBC<hr/></th></tr><tr><th>ROC</th><th>PR</th><th>F1</th><th>ROC</th><th>PR</th><th>F1</th><th>ROC</th><th>PR</th><th>F1</th></tr></thead><tbody><tr><td align="left"><bold>Resnet50</bold></td><td align="left">0.99 ± 0.01</td><td align="left">0.99 ± 0.01</td><td align="left">0.98</td><td align="left">0.97 ± 0.03</td><td align="left">0.97 ± 0.03</td><td align="left">0.96</td><td align="left">0.98 ± 0.01</td><td align="left">0.98 ± 0.01</td><td align="left">0.95</td></tr><tr><td align="left"><bold>Xception</bold></td><td align="left">0.99 ± 0.01</td><td align="left">0.99 ± 0.01</td><td align="left">0.98</td><td align="left">0.96 ± 0.03</td><td align="left">0.96 ± 0.03</td><td align="left">0.96</td><td align="left">0.98 ± 0.01</td><td align="left">0.98 ± 0.01</td><td align="left">0.96</td></tr><tr><td align="left"><bold>InceptionV3</bold></td><td align="left">0.99 ± 0.01</td><td align="left">0.99 ± 0.01</td><td align="left">0.99</td><td align="left"><bold>0.99</bold> ± <bold>0.01</bold></td><td align="left"><bold>0.99</bold> ± <bold>0.01</bold></td><td align="left"><bold>0.98</bold></td><td align="left"><bold>0.98</bold> ± <bold>0.01</bold></td><td align="left"><bold>0.98</bold> ± <bold>0.01</bold></td><td align="left"><bold>0.98</bold></td></tr><tr><td align="left"><bold>VGG16</bold></td><td align="left">0.99 ± 0.01</td><td align="left">0.99 ± 0.01</td><td align="left">0.98</td><td align="left">0.95 ± 0.03</td><td align="left">0.94 ± 0.03</td><td align="left">0.94</td><td align="left">0.98 ± 0.01</td><td align="left">0.98 ± 0.01</td><td align="left">0.97</td></tr><tr><td align="left"><bold>NASNetLarge</bold></td><td align="left">0.98 ± 0.01</td><td align="left">0.98 ± 0.01</td><td align="left">0.97</td><td align="left">0.96 ± 0.03</td><td align="left">0.96 ± 0.03</td><td align="left">0.92</td><td align="left">0.97 ± 0.01</td><td align="left">0.97 ± 0.01</td><td align="left">0.95</td></tr><tr><td align="left"><bold>DenseNet121</bold></td><td align="left"><bold>1.00</bold> ± <bold>0.01</bold></td><td align="left"><bold>0.99</bold> ± <bold>0.01</bold></td><td align="left"><bold>1.00</bold></td><td align="left">0.98 ± 0.01</td><td align="left">0.98 ± 0.01</td><td align="left">0.97</td><td align="left">0.98 ± 0.05</td><td align="left">0.98 ± 0.05</td><td align="left">0.97</td></tr></tbody></table><table-wrap-foot><fn><p>ROC (Area under the ROC curve), PR (Area under the precision-recall curve), F1 (F1 Score), SVC (Support Vector classifier), RF (Random Forest classifier), XGBC (XGBoost classifier). Bold-faced values indicate the best performance for each model.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec4.4">
      <label>4.4</label>
      <title>Predictive performance of COVIDC in its real use</title>
      <p id="p0145">The real generalization performance of our optimal trained models (COVIDC) has been evaluated under the supervision of an experienced radiologist at Abbas Institute of Medical Sciences (AIMS) hospital located in Muzaffarabad, Azad Jammu &amp; Kashmir, Pakistan. For this purpose, 20 CT scans for COVID-19 diagnosis (10 COVID and 10 non-COVID) and 20 CT scans for severity (10 severe and 10 milds) have been used. These scans were used as novel input CT scans to our proposed method called COVIDC in raw digital form as these were not included in the training set. Results obtained through this evaluation are shown as confusion matrices in <xref rid="fig3" ref-type="fig">Fig. 3</xref>
. For COVID vs non-COVID, our proposed system (COVIDC) has been able to classify correctly 9 out of 10 provided COVID CT images as COVID and 1 as non-COVID (<xref rid="fig3" ref-type="fig">Fig. 3</xref>(A)). Similarly, for the provided non-COVID CT images, our system classified correctly 8 out of 10 images as non-COVID, and 2 as COVID (<xref rid="fig3" ref-type="fig">Fig. 3</xref>(A)). This performance is reasonably good as we have less misclassification rate for COVID and this is ideally required to isolate the infected patients. These results help us to interpret that this system can reliably be used to advise isolation or quartine while suspecting COVID-19 infection.<fig id="fig3"><label>Fig. 3</label><caption><p>Confusion matrices: Showing COVIDC performance in real setting. <bold>A)</bold> COVID vs non-COVID; <bold>B)</bold> COVID severity prediction.</p></caption><alt-text id="alttext0025">Fig. 3</alt-text><graphic xlink:href="gr3_lrg"/></fig></p>
      <p id="p0150">Over severe vs mild COVID-19 classification task, our proposed system (COVIDC) has been able to classify correctly10 out of 10 provided COVID CT images as severe (<xref rid="fig3" ref-type="fig">Fig. 3</xref>(B)). Similarly, for the provided mild COVID CT images, our system classified correctly 9 out of 10 images as mild, and 1 as severe (<xref rid="fig3" ref-type="fig">Fig. 3</xref>(B)). This performance of our proposed system in severity prediction shows that this system can reliably be used to advise intensive care during COVID-19 infection. Overall these results justify the use of our proposed system in real settings.</p>
    </sec>
  </sec>
  <sec id="sec5">
    <label>5</label>
    <title>Discussion</title>
    <p id="p0155">In the absence or inadequate provision of specific drugs or vaccines for the treatment or prevention of COVID-19 its quick and automatic diagnosis and severity prediction is crucial. After the successful application of CT scans with machine learning in many clinical and radiological studies, it has become an important avenue to be explored to detect and severity prediction of COVID-19. Several machine learning methods have been proposed which use digital CT scans along with deep learning or transfer learning by fine-tuning the customized fully connected layer. These deep and transfer learning-based approaches face data scarcity issues. Meanwhile, studies based on shallow learning with handcrafted features do not achieve an ideal accuracy. Furthermore, all the existing methods are proposed only to detect COVID-19 and its severity prediction was still an open research question. To knob these issues and to get the best of both worlds, we have proposed a novel approach that uses a combination of transfer and shallow learning to detect COVID-19 and predict its severity. In this approach, we have used various off-the-shelf CNN based pre-trained models on ImageNet to get feature maps and shallow learning algorithms such as SVMs to get the final trained model. We have used various feature maps and shallow machine learning algorithms along with different valuation techniques to come up with a model having improved generalization performance with an F1 score of 0.94 along with are under the PR curve of 0.98. Direct performance comparison of our proposed method with existing methods is not possible due to variations in the amount of training data and performance metrics. However, we give a brief comparison based on learning strategies. In this regard, the performance of our proposed method is comparable to a transfer learning-based method proposed by Ahuja et al. with an F1 score even without using image augmentation to increase the dataset [<xref rid="bib22" ref-type="bibr">22</xref>]. If we compare our method with existing shallow learning-based methods, our method gives improved performance in comparison to a method proposed by Kang et al. trained using handcrafted features with an overall accuracy of 86%. Improved performance of our COVIDC over the existing state-of-the-art methods [<xref rid="bib22" ref-type="bibr">22</xref>,<xref rid="bib27" ref-type="bibr">27</xref>] and in a real setting suggests that the proposed method can effectively be used to diagnose COVID-19 and to predict its severity.</p>
  </sec>
  <sec id="sec6">
    <label>6</label>
    <title>Conclusions</title>
    <p id="p0160">In this study, we have proposed a system called COVIDC for the preliminary diagnosis and severity prediction of COVID-19 infection using chest CT scans. The stringent performance evaluation through 10-fold CV, on an external validation dataset, and in a use under real setting shows that our proposed system can effectively be used not only to diagnose COVID-19 infection but also its severity prediction. The use of our proposed system can help to reduce the surge of COVID-19 by advising timely isolation and further diagnostic tests such as RT-PCR to the suspected patients. This system can also aid in avoiding massive casualties by deciding on intensive care in case of severe COVID-19 infection. The key findings of the study are listed as follows:<list list-type="simple" id="ulist0015"><list-item id="u0025"><label>•</label><p id="p0165">Our proposed system performed significantly better in comparison to the state-of-the-art existing systems during the rigorous adopted evaluation criteria even in the presence of substantial variations in the used CT images.</p></list-item><list-item id="u0030"><label>•</label><p id="p0170">Our proposed system not only diagnose COVID-19 but also predict its severity.</p></list-item><list-item id="u0035"><label>•</label><p id="p0175">We have made our proposed system accessible through a publicly open cloud-based webserver and open-source code.</p></list-item></list>
</p>
  </sec>
  <sec sec-type="data-availability" id="sec7">
    <title>Availability of data and materials</title>
    <p id="p0180">All data generated or analyzed during this study are included in this paper or available at online repositories. A Python implementation of the proposed method together with a webserver is available at <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/view/wajidarshad/software" id="intref0015">https://sites.google.com/view/wajidarshad/software</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/wajidarshad/covidc" id="intref0020">https://github.com/wajidarshad/covidc</ext-link>.</p>
  </sec>
  <sec id="sec8">
    <title>Authors’ contributions</title>
    <p id="p0185">WAA conceived the idea, developed the scientific workflow, performed the experiments, analyzed and interpreted the results, and was a major contributor in manuscript writing. SAA contributed to the analysis of the results and writing of the manuscript. SA, GI, SAA, KA, SK, AA, KI, MS, JC, and AA helped in results interpretation and validation, formal analysis, and manuscript writing. All authors have read and approved the final manuscript.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of competing interest</title>
    <p id="p0190">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="other" id="sref1">
        <person-group person-group-type="author">
          <name>
            <surname>WHO</surname>
          </name>
        </person-group>
        <article-title>Director-General’s remarks at the media briefing on COVID-19</article-title>
        <ext-link ext-link-type="uri" xlink:href="https://www.who.int/director-general/speeches/detail/who-director-general-s-remarks-at-the-media-briefing-on-2019-ncov-on-11-february-2020" id="intref0025">https://www.who.int/director-general/speeches/detail/who-director-general-s-remarks-at-the-media-briefing-on-2019-ncov-on-11-february-2020</ext-link>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Dong</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Gardner</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>An interactive web-based dashboard to track COVID-19 in real time</article-title>
        <source>Lancet Infect Dis</source>
        <volume>20</volume>
        <year>2020</year>
        <fpage>533</fpage>
        <lpage>534</lpage>
        <pub-id pub-id-type="doi">10.1016/S1473-3099(20)30120-1</pub-id>
        <pub-id pub-id-type="pmid">32087114</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>S.-C.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>Y.-C.</given-names>
          </name>
          <name>
            <surname>Fan Chiang</surname>
            <given-names>Y.-L.</given-names>
          </name>
          <name>
            <surname>Chien</surname>
            <given-names>Y.-C.</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>C.-H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>First case of coronavirus disease 2019 (COVID-19) pneumonia in taiwan</article-title>
        <source>J Formos Med Assoc</source>
        <volume>119</volume>
        <year>2020</year>
        <fpage>747</fpage>
        <lpage>751</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jfma.2020.02.007</pub-id>
        <pub-id pub-id-type="pmid">32113824</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>Y.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China</article-title>
        <source>Lancet</source>
        <volume>395</volume>
        <year>2020</year>
        <fpage>497</fpage>
        <lpage>506</lpage>
        <pub-id pub-id-type="doi">10.1016/S0140-6736(20)30183-5</pub-id>
        <pub-id pub-id-type="pmid">31986264</pub-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Niazkar</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Niazkar</surname>
            <given-names>H.R.</given-names>
          </name>
        </person-group>
        <article-title>COVID-19 outbreak: application of multi-gene genetic programming to country-based prediction models</article-title>
        <source>ELECTRON J GEN MED</source>
        <volume>17</volume>
        <year>2020</year>
        <fpage>em247</fpage>
        <pub-id pub-id-type="doi">10.29333/ejgm/8232</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sref6">
        <person-group person-group-type="author">
          <name>
            <surname>Struyf</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Deeks</surname>
            <given-names>J.J.</given-names>
          </name>
          <name>
            <surname>Dinnes</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Takwoingi</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Davenport</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Leeflang</surname>
            <given-names>M.M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Signs and symptoms to determine if a patient presenting in primary care or hospital outpatient settings has COVID‐19 disease</article-title>
        <source>Cochrane Database Syst Rev</source>
        <volume>2020</volume>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1002/14651858.CD013665</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="book" id="sref7">
        <person-group person-group-type="author">
          <name>
            <surname>Commissioner</surname>
            <given-names>O.</given-names>
          </name>
        </person-group>
        <part-title>Coronavirus disease 2019 testing basics</part-title>
        <year>2020</year>
        <publisher-name>FDA</publisher-name>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>Sheikhzadeh</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Eissa</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Ismail</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Zourob</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Diagnostic techniques for COVID-19 and new developments</article-title>
        <source>Talanta</source>
        <volume>220</volume>
        <year>2020</year>
        <fpage>121392</fpage>
        <pub-id pub-id-type="doi">10.1016/j.talanta.2020.121392</pub-id>
        <pub-id pub-id-type="pmid">32928412</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sref9">
        <person-group person-group-type="author">
          <name>
            <surname>Borakati</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Perera</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Johnson</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sood</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Diagnostic accuracy of X-ray versus CT in COVID-19: a propensity-matched database study</article-title>
        <source>BMJ Open</source>
        <volume>10</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e042946</object-id>
        <pub-id pub-id-type="doi">10.1136/bmjopen-2020-042946</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sref10">
        <person-group person-group-type="author">
          <name>
            <surname>Chowdhury</surname>
            <given-names>M.E.H.</given-names>
          </name>
          <name>
            <surname>Rahman</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Khandakar</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Mazhar</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Kadir</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>Mahbub</surname>
            <given-names>Z.B.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Can AI help in screening Viral and COVID-19 pneumonia?</article-title>
        <source>IEEE Access</source>
        <volume>8</volume>
        <year>2020</year>
        <fpage>132665</fpage>
        <lpage>132676</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2020.3010287</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sref11">
        <person-group person-group-type="author">
          <name>
            <surname>Ai</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Zhan</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lv</surname>
            <given-names>W.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Correlation of chest CT and RT-PCR testing for coronavirus disease 2019 (COVID-19) in China: a report of 1014 cases</article-title>
        <source>Radiology</source>
        <volume>296</volume>
        <year>2020</year>
        <fpage>E32</fpage>
        <lpage>E40</lpage>
        <pub-id pub-id-type="doi">10.1148/radiol.2020200642</pub-id>
        <pub-id pub-id-type="pmid">32101510</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sref12">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Chest CT for typical coronavirus disease 2019 (COVID-19) pneumonia: relationship to negative RT-PCR testing</article-title>
        <source>Radiology</source>
        <volume>296</volume>
        <year>2020</year>
        <fpage>E41</fpage>
        <lpage>E45</lpage>
        <pub-id pub-id-type="doi">10.1148/radiol.2020200343</pub-id>
        <pub-id pub-id-type="pmid">32049601</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sref13">
        <person-group person-group-type="author">
          <name>
            <surname>Kwee</surname>
            <given-names>T.C.</given-names>
          </name>
          <name>
            <surname>Kwee</surname>
            <given-names>R.M.</given-names>
          </name>
        </person-group>
        <article-title>Chest CT in COVID-19: what the radiologist needs to know</article-title>
        <source>Radiographics</source>
        <volume>40</volume>
        <year>2020</year>
        <fpage>1848</fpage>
        <lpage>1865</lpage>
        <pub-id pub-id-type="doi">10.1148/rg.2020200159</pub-id>
        <pub-id pub-id-type="pmid">33095680</pub-id>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sref14">
        <person-group person-group-type="author">
          <name>
            <surname>Asnaoui</surname>
            <given-names>K.E.</given-names>
          </name>
          <name>
            <surname>Chawki</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Idri</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Automated methods for detection and classification pneumonia based on X-ray images using deep learning</article-title>
        <source>ArXiv:2003.14363</source>
        <year>2020</year>
        <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2003.14363" id="intref0010f">https://arxiv.org/abs/2003.14363</ext-link>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sref15">
        <person-group person-group-type="author">
          <name>
            <surname>Chandra</surname>
            <given-names>T.B.</given-names>
          </name>
          <name>
            <surname>Verma</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>B.K.</given-names>
          </name>
          <name>
            <surname>Jain</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Netam</surname>
            <given-names>S.S.</given-names>
          </name>
        </person-group>
        <article-title>Coronavirus disease (COVID-19) detection in Chest X-Ray images using majority voting based classifier ensemble</article-title>
        <source>Expert Syst Appl</source>
        <volume>165</volume>
        <year>2021</year>
        <fpage>113909</fpage>
        <pub-id pub-id-type="doi">10.1016/j.eswa.2020.113909</pub-id>
        <pub-id pub-id-type="pmid">32868966</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sref16">
        <person-group person-group-type="author">
          <name>
            <surname>Angelini</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Dahan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shah</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Unravelling machine learning – insights in respiratory medicine</article-title>
        <source>Eur Respir J</source>
        <volume>54</volume>
        <issue>6</issue>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">1901216</object-id>
        <pub-id pub-id-type="doi">10.1183/13993003.01216-2019</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sref17">
        <person-group person-group-type="author">
          <name>
            <surname>Walsh</surname>
            <given-names>S.L.F.</given-names>
          </name>
          <name>
            <surname>Humphries</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Wells</surname>
            <given-names>A.U.</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>K.K.</given-names>
          </name>
        </person-group>
        <article-title>Imaging research in fibrotic lung disease; applying deep learning to unsolved problems</article-title>
        <source>The Lancet Respiratory Medicine</source>
        <volume>8</volume>
        <year>2020</year>
        <fpage>1144</fpage>
        <lpage>1153</lpage>
        <pub-id pub-id-type="doi">10.1016/S2213-2600(20)30003-5</pub-id>
        <pub-id pub-id-type="pmid">32109428</pub-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sref18">
        <person-group person-group-type="author">
          <name>
            <surname>Walsh</surname>
            <given-names>S.L.F.</given-names>
          </name>
          <name>
            <surname>Calandriello</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Silva</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Sverzellati</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for classifying fibrotic lung disease on high-resolution computed tomography: a case-cohort study</article-title>
        <source>The Lancet Respiratory Medicine</source>
        <volume>6</volume>
        <year>2018</year>
        <fpage>837</fpage>
        <lpage>845</lpage>
        <pub-id pub-id-type="doi">10.1016/S2213-2600(18)30286-8</pub-id>
        <pub-id pub-id-type="pmid">30232049</pub-id>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sref19">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Gu</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Zang</surname>
            <given-names>Y.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Central focused convolutional neural networks: developing a data-driven model for lung nodule segmentation</article-title>
        <source>Med Image Anal</source>
        <volume>40</volume>
        <year>2017</year>
        <fpage>172</fpage>
        <lpage>183</lpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2017.06.014</pub-id>
        <pub-id pub-id-type="pmid">28688283</pub-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="book" id="sref20">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Haffner</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <part-title>Object recognition with gradient-based learning</part-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Forsyth</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Mundy</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>di Gesú</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Cipolla</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <source>Shape, contour and grouping in computer vision</source>
        <year>1999</year>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Berlin, Heidelberg</publisher-loc>
        <fpage>319</fpage>
        <lpage>345</lpage>
        <pub-id pub-id-type="doi">10.1007/3-540-46805-6_19</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sref21">
        <person-group person-group-type="author">
          <name>
            <surname>Debie</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Shafi</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Implications of the curse of dimensionality for supervised learning classifier systems: theoretical and empirical analyses</article-title>
        <source>Pattern Anal Appl</source>
        <volume>22</volume>
        <year>2019</year>
        <fpage>519</fpage>
        <lpage>536</lpage>
        <pub-id pub-id-type="doi">10.1007/s10044-017-0649-0</pub-id>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sref22">
        <person-group person-group-type="author">
          <name>
            <surname>Ahuja</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Panigrahi</surname>
            <given-names>B.K.</given-names>
          </name>
          <name>
            <surname>Dey</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Rajinikanth</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Gandhi</surname>
            <given-names>T.K.</given-names>
          </name>
        </person-group>
        <article-title>Deep transfer learning-based automated detection of COVID-19 from lung CT scan slices</article-title>
        <source>Appl Intell</source>
        <year>2020</year>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1007/s10489-020-01826-w</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sref23">
        <person-group person-group-type="author">
          <name>
            <surname>Bai</surname>
            <given-names>H.X.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Hsieh</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Halsey</surname>
            <given-names>K.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Artificial intelligence augmentation of radiologist performance in distinguishing COVID-19 from pneumonia of other origin at chest CT</article-title>
        <source>Radiology</source>
        <volume>296</volume>
        <year>2020</year>
        <fpage>E156</fpage>
        <lpage>E165</lpage>
        <pub-id pub-id-type="doi">10.1148/radiol.2020201491</pub-id>
        <pub-id pub-id-type="pmid">32339081</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sref24">
        <person-group person-group-type="author">
          <name>
            <surname>Han</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Hong</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Cong</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>X.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Accurate screening of COVID-19 using attention-based deep 3D multiple instance learning</article-title>
        <source>IEEE Trans Med Imag</source>
        <volume>39</volume>
        <year>2020</year>
        <fpage>2584</fpage>
        <lpage>2594</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2020.2996256</pub-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sref25">
        <person-group person-group-type="author">
          <name>
            <surname>Harmon</surname>
            <given-names>S.A.</given-names>
          </name>
          <name>
            <surname>Sanford</surname>
            <given-names>T.H.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Turkbey</surname>
            <given-names>E.B.</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Z.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets</article-title>
        <source>Nat Commun</source>
        <volume>11</volume>
        <year>2020</year>
        <fpage>4080</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-17971-2</pub-id>
        <pub-id pub-id-type="pmid">32796848</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sref26">
        <person-group person-group-type="author">
          <name>
            <surname>Javor</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Kaplan</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Kaplan</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Puchner</surname>
            <given-names>S.B.</given-names>
          </name>
          <name>
            <surname>Krestan</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Baltzer</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning analysis provides accurate COVID-19 diagnosis on chest computed tomography</article-title>
        <source>Eur J Radiol</source>
        <volume>133</volume>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1016/j.ejrad.2020.109402</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sref27">
        <person-group person-group-type="author">
          <name>
            <surname>Kang</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Wan</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Diagnosis of coronavirus disease 2019 (COVID-19) with structured latent multi-view representation learning</article-title>
        <source>IEEE Trans Med Imag</source>
        <volume>39</volume>
        <year>2020</year>
        <fpage>2606</fpage>
        <lpage>2614</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2020.2992546</pub-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sref28">
        <person-group person-group-type="author">
          <name>
            <surname>Ko</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Chung</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>W.S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>K.W.</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>S.J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>COVID-19 pneumonia diagnosis using a simple 2D deep learning framework with a single chest CT image: model development and validation</article-title>
        <source>J Med Internet Res</source>
        <volume>22</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e19569</object-id>
        <pub-id pub-id-type="doi">10.2196/19569</pub-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="journal" id="sref29">
        <person-group person-group-type="author">
          <name>
            <surname>Mishra</surname>
            <given-names>A.K.</given-names>
          </name>
          <name>
            <surname>Das</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Roy</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Bandyopadhyay</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Identifying COVID19 from chest CT images: a deep convolutional neural networks based approach</article-title>
        <source>Journal of Healthcare Engineering</source>
        <volume>2020</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e8843664</object-id>
        <pub-id pub-id-type="doi">10.1155/2020/8843664</pub-id>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sref30">
        <person-group person-group-type="author">
          <name>
            <surname>Pathak</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Shukla</surname>
            <given-names>P.K.</given-names>
          </name>
          <name>
            <surname>Tiwari</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Stalin</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shukla</surname>
            <given-names>P.K.</given-names>
          </name>
        </person-group>
        <article-title>Deep transfer learning based classification model for COVID-19 disease</article-title>
        <source>IRBM</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1016/j.irbm.2020.05.003</pub-id>
        <comment>In press</comment>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sref31">
        <person-group person-group-type="author">
          <name>
            <surname>Qian</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Shan</surname>
            <given-names>F.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Lung-sys: a deep learning system for multi-class lung pneumonia screening from CT imaging</article-title>
        <source>IEEE Journal of Biomedical and Health Informatics</source>
        <volume>24</volume>
        <year>2020</year>
        <fpage>3539</fpage>
        <lpage>3550</lpage>
        <pub-id pub-id-type="doi">10.1109/JBHI.2020.3030853</pub-id>
        <pub-id pub-id-type="pmid">33048773</pub-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sref32">
        <person-group person-group-type="author">
          <name>
            <surname>Shah</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Keniya</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Shridharani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Punjabi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Shah</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mehendale</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Diagnosis of COVID-19 using CT scan images and deep learning techniques</article-title>
        <source>Emergency Radiology</source>
        <year>2021</year>
        <pub-id pub-id-type="doi">10.1007/s10140-020-01886-y</pub-id>
        <comment>In press</comment>
      </element-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="journal" id="sref33">
        <person-group person-group-type="author">
          <name>
            <surname>Silva</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Luz</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Silva</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Moreira</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Silva</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Lucio</surname>
            <given-names>D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>COVID-19 detection in CT images with deep learning: a voting-based scheme and cross-datasets analysis</article-title>
        <source>Inform Med Unlocked</source>
        <volume>20</volume>
        <year>2020</year>
        <fpage>100427</fpage>
        <pub-id pub-id-type="doi">10.1016/j.imu.2020.100427</pub-id>
        <pub-id pub-id-type="pmid">32953971</pub-id>
      </element-citation>
    </ref>
    <ref id="bib34">
      <label>34</label>
      <element-citation publication-type="journal" id="sref34">
        <person-group person-group-type="author">
          <name>
            <surname>Singh</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Vaishali</surname>
          </name>
          <name>
            <surname>Kaur</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Classification of COVID-19 patients from chest CT images using multi-objective differential evolution–based convolutional neural networks</article-title>
        <source>Eur J Clin Microbiol Infect Dis</source>
        <volume>39</volume>
        <year>2020</year>
        <fpage>1379</fpage>
        <lpage>1389</lpage>
        <pub-id pub-id-type="doi">10.1007/s10096-020-03901-z</pub-id>
        <pub-id pub-id-type="pmid">32337662</pub-id>
      </element-citation>
    </ref>
    <ref id="bib35">
      <label>35</label>
      <element-citation publication-type="journal" id="sref35">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Zha</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A fully automatic deep learning system for COVID-19 diagnostic and prognostic analysis</article-title>
        <source>Eur Respir J</source>
        <volume>56</volume>
        <issue>2</issue>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">2000775</object-id>
        <pub-id pub-id-type="doi">10.1183/13993003.00775-2020</pub-id>
      </element-citation>
    </ref>
    <ref id="bib36">
      <label>36</label>
      <element-citation publication-type="journal" id="sref36">
        <person-group person-group-type="author">
          <name>
            <surname>X</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>X</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Q</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Q</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>J</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>H</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A weakly-supervised framework for COVID-19 classification and lesion localization from chest CT</article-title>
        <source>IEEE Trans Med Imag</source>
        <volume>39</volume>
        <year>2020</year>
        <fpage>2615</fpage>
        <lpage>2625</lpage>
        <pub-id pub-id-type="doi">10.1109/tmi.2020.2995965</pub-id>
      </element-citation>
    </ref>
    <ref id="bib37">
      <label>37</label>
      <element-citation publication-type="journal" id="sref37">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Lv</surname>
            <given-names>S.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A deep learning system to screen novel coronavirus disease 2019 pneumonia</article-title>
        <source>Engineering</source>
        <volume>6</volume>
        <year>2020</year>
        <fpage>1122</fpage>
        <lpage>1129</lpage>
        <pub-id pub-id-type="doi">10.1016/j.eng.2020.04.010</pub-id>
        <pub-id pub-id-type="pmid">32837749</pub-id>
      </element-citation>
    </ref>
    <ref id="bib38">
      <label>38</label>
      <element-citation publication-type="journal" id="sref38">
        <person-group person-group-type="author">
          <name>
            <surname>Ozsahin</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Sekeroglu</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Musa</surname>
            <given-names>M.S.</given-names>
          </name>
          <name>
            <surname>Mustapha</surname>
            <given-names>M.T.</given-names>
          </name>
          <name>
            <surname>Uzun Ozsahin</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Review on diagnosis of COVID-19 from chest CT images using artificial intelligence</article-title>
        <source>Computational and Mathematical Methods in Medicine</source>
        <volume>2020</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e9756518</object-id>
        <pub-id pub-id-type="doi">10.1155/2020/9756518</pub-id>
      </element-citation>
    </ref>
    <ref id="bib39">
      <label>39</label>
      <element-citation publication-type="book" id="sref39">
        <person-group person-group-type="author">
          <name>
            <surname>Zare</surname>
            <given-names>M.R.</given-names>
          </name>
          <name>
            <surname>Alebiosu</surname>
            <given-names>D.O.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.L.</given-names>
          </name>
          <name>
            <surname>Comparison of Handcrafted Features and Deep Learning in Classification of Medical X-ray Images</surname>
          </name>
        </person-group>
        <series>Fourth international conference on information retrieval and knowledge management (CAMP)</series>
        <volume>vol. 2018</volume>
        <year>2018</year>
        <fpage>1</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1109/INFRKM.2018.8464688</pub-id>
      </element-citation>
    </ref>
    <ref id="bib40">
      <label>40</label>
      <element-citation publication-type="journal" id="sref40">
        <person-group person-group-type="author">
          <name>
            <surname>Cohen</surname>
            <given-names>J.P.</given-names>
          </name>
          <name>
            <surname>Morrison</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Dao</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Duong</surname>
            <given-names>T.Q.</given-names>
          </name>
          <name>
            <surname>Ghassemi</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>COVID-19 image data collection: prospective predictions are the future</article-title>
        <source>arXiv:2006.11988</source>
        <year>2020</year>
        <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2006.11988" id="intref0040">https://arxiv.org/abs/2006.11988</ext-link>
      </element-citation>
    </ref>
    <ref id="bib41">
      <label>41</label>
      <element-citation publication-type="journal" id="sref41">
        <person-group person-group-type="author">
          <name>
            <surname>Soares</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Angelov</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Biaso</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Froes</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Abe</surname>
            <given-names>D.K.</given-names>
          </name>
        </person-group>
        <article-title>SARS-CoV-2 CT-scan dataset: a large dataset of real patients CT scans for SARS-CoV-2 identification</article-title>
        <source>MedRxiv</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1101/2020.04.24.20078584</pub-id>
      </element-citation>
    </ref>
    <ref id="bib42">
      <label>42</label>
      <element-citation publication-type="journal" id="sref42">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>COVID-CT-dataset: a CT scan dataset about COVID-19</article-title>
        <source>arXiv:2003.13865</source>
        <year>2020</year>
        <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2003.13865" id="intref0030">https://arxiv.org/abs/2003.13865</ext-link>
      </element-citation>
    </ref>
    <ref id="bib43">
      <label>43</label>
      <element-citation publication-type="journal" id="sref43">
        <person-group person-group-type="author">
          <name>
            <surname>Chandra</surname>
            <given-names>T.B.</given-names>
          </name>
          <name>
            <surname>Verma</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Analysis of quantum noise-reducing filters on chest X-ray images: a review</article-title>
        <source>Measurement</source>
        <volume>153</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">107426</object-id>
        <pub-id pub-id-type="doi">10.1016/j.measurement.2019.107426</pub-id>
      </element-citation>
    </ref>
    <ref id="bib44">
      <label>44</label>
      <element-citation publication-type="journal" id="sref44">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Deep residual learning for image recognition</article-title>
        <source>arXiv:1512.03385</source>
        <year>2015</year>
        <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1512.03385" id="intref0020d">https://arxiv.org/abs/1512.03385</ext-link>
      </element-citation>
    </ref>
    <ref id="bib45">
      <label>45</label>
      <element-citation publication-type="book" id="sref45">
        <person-group person-group-type="author">
          <name>
            <surname>Szegedy</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Vanhoucke</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Ioffe</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shlens</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wojna</surname>
            <given-names>Z.</given-names>
          </name>
        </person-group>
        <part-title>Rethinking the inception architecture for computer vision</part-title>
        <year>2015</year>
        <comment>ArXiv:151200567 [Cs]</comment>
      </element-citation>
    </ref>
    <ref id="bib46">
      <label>46</label>
      <element-citation publication-type="book" id="sref46">
        <person-group person-group-type="author">
          <name>
            <surname>Chollet</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <part-title>Xception: deep learning with depthwise separable convolutions</part-title>
        <year>2017</year>
        <comment>ArXiv:161002357 [Cs]</comment>
      </element-citation>
    </ref>
    <ref id="bib47">
      <label>47</label>
      <element-citation publication-type="book" id="sref47">
        <person-group person-group-type="author">
          <name>
            <surname>Simonyan</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Zisserman</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <part-title>Very deep convolutional networks for large-scale image recognition</part-title>
        <year>2015</year>
        <publisher-name>ArXive</publisher-name>
        <object-id pub-id-type="publisher-id">arXiv:1409.1556</object-id>
      </element-citation>
    </ref>
    <ref id="bib48">
      <label>48</label>
      <element-citation publication-type="book" id="sref48">
        <person-group person-group-type="author">
          <name>
            <surname>Zoph</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Vasudevan</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Shlens</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>Q.V.</given-names>
          </name>
        </person-group>
        <part-title>Learning transferable architectures for scalable image recognition</part-title>
        <year>2018</year>
        <publisher-name>ArXiv</publisher-name>
        <object-id pub-id-type="publisher-id">1707.07012</object-id>
      </element-citation>
    </ref>
    <ref id="bib49">
      <label>49</label>
      <element-citation publication-type="book" id="sref49">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>van der Maaten</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Weinberger</surname>
            <given-names>K.Q.</given-names>
          </name>
        </person-group>
        <part-title>Densely connected convolutional networks</part-title>
        <year>2018</year>
        <publisher-name>Arxiv</publisher-name>
        <object-id pub-id-type="publisher-id">1608.06993</object-id>
      </element-citation>
    </ref>
    <ref id="bib50">
      <label>50</label>
      <element-citation publication-type="journal" id="sref50">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Mo</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>An efficient mixture of deep and machine learning models for COVID-19 diagnosis in chest X-ray images</article-title>
        <source>PloS One</source>
        <volume>15</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e0242535</object-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0242535</pub-id>
      </element-citation>
    </ref>
    <ref id="bib51">
      <label>51</label>
      <element-citation publication-type="journal" id="sref51">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>Mach Learn</source>
        <volume>45</volume>
        <year>2001</year>
        <fpage>5</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
      </element-citation>
    </ref>
    <ref id="bib52">
      <label>52</label>
      <element-citation publication-type="journal" id="sref52">
        <person-group person-group-type="author">
          <name>
            <surname>Cortes</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Vapnik</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Support-vector networks</article-title>
        <source>Mach Learn</source>
        <volume>20</volume>
        <year>1995</year>
        <fpage>273</fpage>
        <lpage>297</lpage>
        <pub-id pub-id-type="doi">10.1023/A:1022627411411</pub-id>
      </element-citation>
    </ref>
    <ref id="bib53">
      <label>53</label>
      <element-citation publication-type="journal" id="sref53">
        <person-group person-group-type="author">
          <name>
            <surname>Friedman</surname>
            <given-names>J.H.</given-names>
          </name>
        </person-group>
        <article-title>Greedy function approximation: a gradient boosting machine</article-title>
        <source>Ann Stat</source>
        <volume>29</volume>
        <year>2001</year>
        <fpage>1189</fpage>
        <lpage>1232</lpage>
        <pub-id pub-id-type="doi">10.1214/aos/1013203451</pub-id>
      </element-citation>
    </ref>
    <ref id="bib54">
      <label>54</label>
      <element-citation publication-type="journal" id="sref54">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Thirion</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Grisel</surname>
            <given-names>O.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: machine learning in Python</article-title>
        <source>J Mach Learn Res</source>
        <volume>12</volume>
        <year>2011</year>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="bib55">
      <label>55</label>
      <element-citation publication-type="journal" id="sref55">
        <person-group person-group-type="author">
          <name>
            <surname>Abbasi</surname>
            <given-names>W.A.</given-names>
          </name>
          <name>
            <surname>Yaseen</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hassan</surname>
            <given-names>F.U.</given-names>
          </name>
          <name>
            <surname>Andleeb</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Minhas</surname>
            <given-names>F.U.A.A.</given-names>
          </name>
        </person-group>
        <article-title>ISLAND: in-silico proteins binding affinity prediction using sequence information</article-title>
        <source>BioData Min</source>
        <volume>13</volume>
        <year>2020</year>
        <fpage>20</fpage>
        <pub-id pub-id-type="doi">10.1186/s13040-020-00231-w</pub-id>
        <pub-id pub-id-type="pmid">33292419</pub-id>
      </element-citation>
    </ref>
    <ref id="bib56">
      <label>56</label>
      <element-citation publication-type="journal" id="sref56">
        <person-group person-group-type="author">
          <name>
            <surname>Ballester</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>Mitchell</surname>
            <given-names>J.B.O.</given-names>
          </name>
        </person-group>
        <article-title>A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking</article-title>
        <source>Bioinformatics</source>
        <volume>26</volume>
        <year>2010</year>
        <fpage>1169</fpage>
        <lpage>1175</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq112</pub-id>
        <pub-id pub-id-type="pmid">20236947</pub-id>
      </element-citation>
    </ref>
    <ref id="bib57">
      <label>57</label>
      <element-citation publication-type="journal" id="sref57">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Leung</surname>
            <given-names>K.-S.</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>M.-H.</given-names>
          </name>
          <name>
            <surname>Ballester</surname>
            <given-names>P.J.</given-names>
          </name>
        </person-group>
        <article-title>Substituting random forest for multiple linear regression improves binding affinity prediction of scoring functions: cyscore as a case study</article-title>
        <source>BMC Bioinf</source>
        <volume>15</volume>
        <year>2014</year>
        <fpage>291</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-15-291</pub-id>
      </element-citation>
    </ref>
    <ref id="bib58">
      <label>58</label>
      <element-citation publication-type="journal" id="sref58">
        <person-group person-group-type="author">
          <name>
            <surname>Moal</surname>
            <given-names>I.H.</given-names>
          </name>
          <name>
            <surname>Agius</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Bates</surname>
            <given-names>P.A.</given-names>
          </name>
        </person-group>
        <article-title>Protein-protein binding affinity prediction on a diverse set of structures</article-title>
        <source>Bioinformatics</source>
        <volume>27</volume>
        <issue>21</issue>
        <year>2011</year>
        <fpage>3002</fpage>
        <lpage>3009</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr513</pub-id>
        <pub-id pub-id-type="pmid">21903632</pub-id>
      </element-citation>
    </ref>
    <ref id="bib59">
      <label>59</label>
      <element-citation publication-type="book" id="sref59">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Guestrin</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <part-title>XGBoost: a scalable tree boosting system</part-title>
        <source>Proceedings of the 22Nd ACM SIGKDD international conference on knowledge discovery and data mining</source>
        <year>2016</year>
        <publisher-name>ACM</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <fpage>785</fpage>
        <lpage>794</lpage>
        <pub-id pub-id-type="doi">10.1145/2939672.2939785</pub-id>
      </element-citation>
    </ref>
    <ref id="bib60">
      <label>60</label>
      <element-citation publication-type="journal" id="optDyr3aBHqjM">
        <person-group person-group-type="author">
          <name>
            <surname>Abbasi</surname>
            <given-names>WA</given-names>
          </name>
          <name>
            <surname>Minhas</surname>
            <given-names>FUAA</given-names>
          </name>
        </person-group>
        <article-title>Issues in performance evaluation for host–pathogen protein interaction prediction</article-title>
        <source>J Bioinform Comput Biol</source>
        <volume>14</volume>
        <year>2016</year>
        <object-id pub-id-type="publisher-id">1650011</object-id>
      </element-citation>
    </ref>
    <ref id="bib61">
      <label>61</label>
      <element-citation publication-type="journal" id="optVqY6qVkhsU">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Goadrich</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>The Relationship Between Precision-Recall and ROC Curves</article-title>
        <source>Proceedings of the 23rd International Conference on Machine Learning, New York, NY, USA</source>
        <year>2006</year>
        <fpage>233</fpage>
        <lpage>240</lpage>
        <pub-id pub-id-type="doi">10.1145/1143844.1143874</pub-id>
      </element-citation>
    </ref>
    <ref id="bib62">
      <label>62</label>
      <element-citation publication-type="book" id="optPNREqXnfVP">
        <person-group person-group-type="author">
          <name>
            <surname>Tharwat</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <source>Classification assessment methods</source>
        <year>2020</year>
        <publisher-name>Emerald Publishing Limited</publisher-name>
        <object-id pub-id-type="publisher-id">10.1016/j.aci.2018.08.003</object-id>
      </element-citation>
    </ref>
  </ref-list>
  <ack id="ack0010">
    <title>Acknowledgments</title>
    <p id="p0195">The authors would like to acknowledge the services of all those who have provided CT scans data as open access repositories. We also thank the reviewers and the editor for their valuable feedback and suggestions to improve the presentation of this work.</p>
  </ack>
</back>
