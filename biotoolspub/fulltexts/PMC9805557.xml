<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9805557</article-id>
    <article-id pub-id-type="pmid">36342186</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac715</article-id>
    <article-id pub-id-type="publisher-id">btac715</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>sAMPpred-GAT: prediction of antimicrobial peptide by graph attention network and predicted peptide structure</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Ke</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lv</surname>
          <given-names>Hongwu</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guo</surname>
          <given-names>Yichen</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Peng</surname>
          <given-names>Wei</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3685-9469</contrib-id>
        <name>
          <surname>Liu</surname>
          <given-names>Bin</given-names>
        </name>
        <aff><institution>School of Computer Science and Technology, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
        <aff><institution>Advanced Research Institute of Multidisciplinary Science, Beijing Institute of Technology</institution>, Beijing 100081, <country country="CN">China</country></aff>
        <xref rid="btac715-cor1" ref-type="corresp"/>
        <!--bliu@bliulab.net-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac715-cor1">To whom correspondence should be addressed. Email: <email>bliu@bliulab.net</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-11-07">
      <day>07</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>07</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <volume>39</volume>
    <issue>1</issue>
    <elocation-id>btac715</elocation-id>
    <history>
      <date date-type="received">
        <day>05</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>24</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>26</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>04</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>17</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac715.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Antimicrobial peptides (AMPs) are essential components of therapeutic peptides for innate immunity. Researchers have developed several computational methods to predict the potential AMPs from many candidate peptides. With the development of artificial intelligent techniques, the protein structures can be accurately predicted, which are useful for protein sequence and function analysis. Unfortunately, the predicted peptide structure information has not been applied to the field of AMP prediction so as to improve the predictive performance.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>In this study, we proposed a computational predictor called sAMPpred-GAT for AMP identification. To the best of our knowledge, sAMPpred-GAT is the first approach based on the predicted peptide structures for AMP prediction. The sAMPpred-GAT predictor constructs the graphs based on the predicted peptide structures, sequence information and evolutionary information. The Graph Attention Network (GAT) is then performed on the graphs to learn the discriminative features. Finally, the full connection networks are utilized as the output module to predict whether the peptides are AMP or not. Experimental results show that sAMPpred-GAT outperforms the other state-of-the-art methods in terms of AUC, and achieves better or highly comparable performance in terms of the other metrics on the eight independent test datasets, demonstrating that the predicted peptide structure information is important for AMP prediction.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>A user-friendly webserver of sAMPpred-GAT can be accessed at <ext-link xlink:href="http://bliulab.net/sAMPpred-GAT" ext-link-type="uri">http://bliulab.net/sAMPpred-GAT</ext-link> and the source code is available at <ext-link xlink:href="https://github.com/HongWuL/sAMPpred-GAT/" ext-link-type="uri">https://github.com/HongWuL/sAMPpred-GAT/</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>62102030</award-id>
        <award-id>U22A2039</award-id>
        <award-id>62271049</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Beijing Natural Science Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/501100004826</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>JQ19019</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Due to the development of drug-resistant microbes, several alternative treatments have gained attention for treating multi-drug-resistant microbes caused by these diseases (<xref rid="btac715-B41" ref-type="bibr">Saxena and Gomber, 2010</xref>). Antimicrobial peptides (AMPs) as biomolecules have therapeutic functions. AMPs sequences have broad antibiotic-resistant activity against Gram-negative bacteria, cancer cells, fungi, etc. (<xref rid="btac715-B47" ref-type="bibr">Thomas <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac715-B68" ref-type="bibr">Zasloff, 2002</xref>). Compared with the traditional antibiotic, AMPs interact with microbial membranes and penetration to promote the death of the target microbe and reduce the development of drug-resistant (<xref rid="btac715-B16" ref-type="bibr">Gaspar <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btac715-B57" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2021a</xref>,<xref rid="btac715-B58" ref-type="bibr">b</xref>). Therefore, AMPs identification and investigation are important for understanding the mechanism of new drug design (<xref rid="btac715-B11" ref-type="bibr">de la Fuente-Nunez <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac715-B63" ref-type="bibr">Yan <italic toggle="yes">et al.</italic>, 2022a</xref>,<xref rid="btac715-B64" ref-type="bibr">b</xref>).</p>
    <p>Several studies have been proposed to recognize and design new AMPs with different functional activities. AMPs are typically small proteins with a length of &lt;100 amino acids, and have low homology with other peptide sequences (<xref rid="btac715-B2" ref-type="bibr">Bahar and Ren, 2013</xref>; <xref rid="btac715-B22" ref-type="bibr">Jenssen <italic toggle="yes">et al.</italic>, 2006</xref>). Identifying AMPs is a more challenging task. The computational methods developed to identify novel AMPs contain two parts, including databases construction and machine learning predictors (<xref rid="btac715-B3" ref-type="bibr">Barreto-Santamaria <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac715-B36" ref-type="bibr">Pang <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
    <p>Many databases have been constructed to store the experimental validation AMP sequences. APD (<xref rid="btac715-B54" ref-type="bibr">Wang and Wang, 2004</xref>) is one of the earliest AMP databases, and APD3 (<xref rid="btac715-B53" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2016</xref>) is its third version. APD3 database contains 2747 sequences with annotated AMPs and their functionary activity. ADAM (<xref rid="btac715-B31" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2015</xref>) mainly concentrates on the relationship between AMP sequences and structures. SATPdb (<xref rid="btac715-B43" ref-type="bibr">Singh <italic toggle="yes">et al.</italic>, 2016</xref>) provides a large number of AMP structures, a majority of which are predicted by computational tools. Several high-throughput AMP databases have been proposed to evaluate the functionary activity and specific physicochemical information of the collection sequences, such as DRAMP 3.0 (<xref rid="btac715-B42" ref-type="bibr">Shi <italic toggle="yes">et al.</italic>, 2022</xref>), dbAMP 2.0 (<xref rid="btac715-B24" ref-type="bibr">Jhong <italic toggle="yes">et al.</italic>, 2022</xref>), etc.</p>
    <p>Some machine learning methods have been developed for identifying different functional activities of AMP. These approaches can be divided into two categories based on the machine learning algorithm. First, the predictors constructed based on conventional methodologies. Among those methods, Support Vector Machine (SVM), Random Forest (RF), decision tree (DT) and ensemble learning methods are the widely used methods, such as TP-MV (<xref rid="btac715-B63" ref-type="bibr">Yan <italic toggle="yes">et al.</italic>, 2022a</xref>,<xref rid="btac715-B64" ref-type="bibr">b</xref>), iProt-Sub (<xref rid="btac715-B44" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2019</xref>), etc. AVPpred (<xref rid="btac715-B46" ref-type="bibr">Thakur <italic toggle="yes">et al.</italic>, 2012</xref>) is the first attempt to predict the anti-virus peptides by integrating amino acid composition and physicochemical features with SVM. Second, the predictors utilize the deep learning framework to distinguish AMPs and non-AMPs. <xref rid="btac715-B51" ref-type="bibr">Veltri <italic toggle="yes">et al.</italic> (2018)</xref> utilized the deep neural network (DNN) architecture to identify AMPs. AMPlify (<xref rid="btac715-B32" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2022</xref>) utilizes a bidirectional long short-term memory (Bi-LSTM) layer to distinguish AMPs from non-AMPs. In addition to the aforementioned machine learning methods, the appropriate peptide features are important factors to improve the prediction performance (<xref rid="btac715-B4" ref-type="bibr">Bhadra <italic toggle="yes">et al.</italic>, 2018</xref>). The sequence order, composition, physicochemical properties and structure features have been widely used to predict AMPs. For example, amino acid composition (AAC) and dipeptide composition are two widely used peptide descriptors (<xref rid="btac715-B19" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac715-B55" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2018</xref>). The composition, transition and distribution (CTD) feature and the pseudo amino acid composition (PseAAC) feature integrate the sequence property with the physical-chemical property (<xref rid="btac715-B4" ref-type="bibr">Bhadra <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
    <p>In the last decade, graph neural network (GNN) methods have been widely used in addressing many tasks in computational biology (<xref rid="btac715-B9" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac715-B17" ref-type="bibr">GligorijeviÄ <italic toggle="yes">et al.</italic>, 2021</xref>). GNN methods are able to extract the task-specific features directly from the contact map or the protein sequence, overcoming the limitations of the handcrafted features. Graph convolutional network (GCN) is one of the most frequently used GNN methods. Most of protein function predictors based on the GCN construct the generalizing convolutional framework by utilizing the effectively graph-like molecular representations, and convert them into complex features by using multiple convolution layers. Compared with GCN treating all neighbor nodes equally, Graph Attention Network (GAT) aggregates the neighbor information based on the attention mechanism (<xref rid="btac715-B29" ref-type="bibr">Lai and Xu, 2022</xref>). GAT methods have been successful applied for predicting the protein structures (<xref rid="btac715-B56" ref-type="bibr">Wei, 2019</xref>), biochemical activity of drug identification (<xref rid="btac715-B69" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2021</xref>), etc.</p>
    <p>Previous studies have showed that the predicted structures of proteins are useful for protein function prediction (<xref rid="btac715-B59" ref-type="bibr">Xia <italic toggle="yes">et al.</italic>, 2021</xref>). The peptide structures can be accurately predicted by the computational methods only based on their peptide sequences (<xref rid="btac715-B26" ref-type="bibr">Jumper <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac715-B65" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>), providing an opportunity to improve the performance of AMP prediction by making full use of the predicted structure information. In this regard, we make an attempt to use the predicted peptide structures to predict the AMPs based on the GAT. The GAT framework captures the structure information and the spatial relationships among the residues along with the peptide. Experimental results show that the sAMPpred-GAT outperforms the other state-of-the-art methods in terms of AUC, and achieves better or highly comparable performance in terms of the other metrics on the eight independent test datasets. The hierarchical cluster analysis validated that the data-driven features learned by the sAMPpred-GAT are specific for AMP, which provided more information for further analysis. Furthermore, a user-friendly web server has been established at <ext-link xlink:href="http://bliulab.net/sAMPpred-GAT" ext-link-type="uri">http://bliulab.net/sAMPpred-GAT</ext-link>.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Independent test datasets</title>
      <p>To objectively evaluate the performance of our sAMPpred-GAT and the other prediction methods, we use seven independent test AMP datasets from <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>, including XUAMP (<xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), APD3 (<xref rid="btac715-B53" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), DRAMP (<xref rid="btac715-B12" ref-type="bibr">Fan <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac715-B27" ref-type="bibr">Kang <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), LAMP (<xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac715-B66" ref-type="bibr">Ye <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac715-B70" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2013</xref>), CAMP (<xref rid="btac715-B47" ref-type="bibr">Thomas <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac715-B52" ref-type="bibr">Waghu <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), dbAMP (<xref rid="btac715-B23" ref-type="bibr">Jhong <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>) and YADAMP (<xref rid="btac715-B37" ref-type="bibr">Piotto <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>). For detailed information of these seven datasets, please referred to <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>. Following the process employed by (<xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), we construct an additional non-redundant independent test dataset named DBAASP, whose positive samples are extracted from an updated database (<xref rid="btac715-B38" ref-type="bibr">Pirtskhalava <italic toggle="yes">et al.</italic>, 2021</xref>) sharing &lt;90% similarities, and the negative samples are downloaded from <xref rid="btac715-B48" ref-type="bibr">UniProt Consortium (2015)</xref> sharing &lt;40% similarities.</p>
      <p>The statistical information of all eight independent test datasets is listed in <xref rid="btac715-T1" ref-type="table">TableÂ 1</xref> and the relationship among these eight independent test datasets is shown in <xref rid="btac715-F1" ref-type="fig">FigureÂ 1</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. <xref rid="btac715-F1" ref-type="fig">FigureÂ 1</xref> shows that for the eight independent test datasets, most of the positive samples are unique, and there are some overlapping positive samples among these independent datasets. The reason is that some recent independent datasets are constructed based on the previous ones. For example, XUAMP is constructed based on the DRAMP, LAMP, YADAMP, etc. (<xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>). These eight independent test datasets have unique positive samples, and many existing predictors are evaluated on them. Therefore, all these eight independent test datasets are selected to evaluate our method, and compare with the other existing methods. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref> shows that the sequence length distributions between positive and negative samples are similar in XUAMP and DRAMP, while the distributions are different in the other six independent test datasets. Furthermore, XUAMP and DRAMP are the top two largest test datasets (see <xref rid="btac715-T1" ref-type="table">TableÂ 1</xref>). Therefore, XUAMP and DRAMP are used as the main test datasets to evaluate the performance of different methods. In order to comprehensively evaluate the performance of sAMPpred-GAT, it is also evaluated on the six test datasets with different distributions.</p>
      <fig position="float" id="btac715-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>The number of overlapping positive samples among the eight independent test positive datasets. There are two parts in this figure. The upper part shows the number of positive samples in each intersection subset. Only the intersection subsets with more than two positive samples are shown. The bottom part shows the detailed information of the eight independent test positive datasets, where the black spots indicate that the corresponding independent test positive datasets listed in the <italic toggle="yes">y</italic>-axis share the intersection subset listed in the same column in the upper part. For examples, for column 11, there are 2 black spots in the bottom part, indicating that the independent test datasets LAMP and DRAMP share the intersection subset with 103 positive samples. In other words, LAMP and DRAMP share 103 common positive samples</p>
        </caption>
        <graphic xlink:href="btac715f1" position="float"/>
      </fig>
      <table-wrap position="float" id="btac715-T1">
        <label>Table 1.</label>
        <caption>
          <p>Statistical information of the eight independent test datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Independent test datasets<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></th>
              <th rowspan="1" colspan="1">Positive</th>
              <th rowspan="1" colspan="1">Negative</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">XUAMP</td>
              <td align="char" char="." rowspan="1" colspan="1">1536</td>
              <td align="char" char="." rowspan="1" colspan="1">1536</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">APD3</td>
              <td align="char" char="." rowspan="1" colspan="1">494</td>
              <td align="char" char="." rowspan="1" colspan="1">494</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DRAMP</td>
              <td align="char" char="." rowspan="1" colspan="1">1408</td>
              <td align="char" char="." rowspan="1" colspan="1">1408</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">LAMP</td>
              <td align="char" char="." rowspan="1" colspan="1">1054</td>
              <td align="char" char="." rowspan="1" colspan="1">1054</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CAMP</td>
              <td align="char" char="." rowspan="1" colspan="1">203</td>
              <td align="char" char="." rowspan="1" colspan="1">203</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">dbAMP</td>
              <td align="char" char="." rowspan="1" colspan="1">522</td>
              <td align="char" char="." rowspan="1" colspan="1">522</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">YADAMP</td>
              <td align="char" char="." rowspan="1" colspan="1">324</td>
              <td align="char" char="." rowspan="1" colspan="1">324</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DBAASP</td>
              <td align="char" char="." rowspan="1" colspan="1">178</td>
              <td align="char" char="." rowspan="1" colspan="1">178</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <label>a</label>
            <p>The relationship among the eight independent test datasets is shown in <xref rid="btac715-F1" ref-type="fig">FigureÂ 1</xref>. We adopt CD-HIT (<xref rid="btac715-B21" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2010</xref>) to remove the redundancy between the independent datasets and the training sets. Following (<xref rid="btac715-B51" ref-type="bibr">Veltri <italic toggle="yes">et al.</italic>, 2018</xref>), the similarity between positive training samples and positive independent test samples is &lt;90%, and the similarity between negative training samples and negative independent test samples is &lt;40%.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>2.2 Benchmark datasets</title>
      <p>In this study, we construct a pretraining dataset, and based on which a benchmark dataset is constructed. The pretraining dataset is used for pretraining the proposed method to initialize the GAT framework, and the benchmark dataset is utilized for training and predicting the proposed method. The pretraining dataset containing 5536 AMPs and 5536 non-AMPs was constructed based on SATPdb (<xref rid="btac715-B43" ref-type="bibr">Singh <italic toggle="yes">et al.</italic>, 2016</xref>), ADAM (<xref rid="btac715-B31" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2015</xref>), AMPfun (<xref rid="btac715-B10" ref-type="bibr">Chung <italic toggle="yes">et al.</italic>, 2019</xref>), APD3 (<xref rid="btac715-B53" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2016</xref>), CAMP (<xref rid="btac715-B47" ref-type="bibr">Thomas <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac715-B52" ref-type="bibr">Waghu <italic toggle="yes">et al.</italic>, 2016</xref>), LAMP (<xref rid="btac715-B66" ref-type="bibr">Ye <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac715-B70" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2013</xref>), DRAMP (<xref rid="btac715-B12" ref-type="bibr">Fan <italic toggle="yes">et al.</italic>, 2016</xref>), dbAMP (<xref rid="btac715-B23" ref-type="bibr">Jhong <italic toggle="yes">et al.</italic>, 2019</xref>) and <xref rid="btac715-B48" ref-type="bibr">UniProt Consortium (2015)</xref> databases. The sequence similarity between any two AMPs is &lt;90%, and the sequence similarity between any two non-AMPs is &lt;40% (<xref rid="btac715-B51" ref-type="bibr">Veltri <italic toggle="yes">et al.</italic>, 2018</xref>). Then, a benchmark dataset is constructed to avoid the misleading model prediction caused by the length distribution gap between AMPs and non-AMPs. We selected the positive samples and negative samples with the lengths in the range of 40â100 residues from the pretraining dataset to construct the benchmark dataset. The sequence length distributions of the samples in the benchmark dataset are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>.</p>
      <p>For model training, 80% of the samples in the benchmark dataset are randomly selected as the training dataset, and the remaining 20% are used as a validation dataset to optimize the parameters. The detailed steps of the dataset construction are described in <xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>.</p>
    </sec>
    <sec>
      <title>2.3 Overview of sAMPpred-GAT</title>
      <p>The framework of sAMPpred-GAT is shown in <xref rid="btac715-F2" ref-type="fig">FigureÂ 2</xref>. The sAMPpred-GAT predictor extracts the residue-level features from the sequence information and the spatial relationships among the residues from the predicted structural information. Then the graphs are constructed to integrate the information of peptides, where the edges represent the structural information and the nodes represent the residue information, including sequence information and evolutionary information. Subsequently, we utilize the GAT to extract the features from the graphs-based data. Finally, we use the linear layer to predict whether a new peptide is an AMP or not.</p>
      <fig position="float" id="btac715-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>The framework of sAMPpred-GAT. (<bold>a</bold>) The flowchart of feature extraction and graph construction process. For the residue-level features, we extract four different features, including one-hot features, position encoding features, PSSM features and HMM features. For structure features, we extract the contact maps by using trRosetta (<xref rid="btac715-B65" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>). The four residue-level features represented as the nodes and the adjacency matrix information represented as the edges are fed into the GAT framework. (<bold>b</bold>) The neural network architecture of sAMPpred-GAT. We use three GAT layers with multi-head attention to capture the information from the neighbors. The GAT module utilizes both the contact map information and four residue-level features as described above, and outputs the sequence-level features in the last layer. Then we utilize the top <italic toggle="yes">k</italic> pooling to transform the graphs into vectors with fixed length, which is the graph level representation. The linear layers are used to make the final prediction. The methods with suffix * indicate that they are not used in the last layer</p>
        </caption>
        <graphic xlink:href="btac715f2" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.4 Sequence feature extraction and graph construction module</title>
      <p>In this section, we represent the sequences from two perspectives information, including residue-level features and structural features. Specifically, the residue-level features are represented by the amino acid composition information, amino acid position information and evolutionary information. The structural information is extracted by the trRosetta (<xref rid="btac715-B65" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>), which is converted the raw sequences into the corresponding structures, which contain the distances and orientations between all the amino acid pairs along the sequence.</p>
      <sec>
        <label>2.4.1</label>
        <title>Residual level features encoding</title>
        <p>The proposed method utilizes four comprehensive features to represent residue-level features, including One-hot encoding features, Position encoding features, Position Specific Scoring Matrix (PSSM) features, and Hidden Markov Models (HMM) features.</p>
        <p>One-hot encoding: to represent the composition information, we use one-hot to encode 20 standard amino acids. One-hot is a binary vector with only one position having a value of 1, representing the current acid amino, and the rest are set as 0. For example, amino acid A is coded as <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1,0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>â¦</mml:mo><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. The dimension of the one-hot feature is <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>L</mml:mi><mml:mo>Ã</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>-D.</p>
        <p>Position encoding: position encoding is claimed as an effective descriptor in many applications calculated by <xref rid="btac715-B49" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic> (2017)</xref>:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>â¡</mml:mo><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>â¡</mml:mo><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where the <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi mathvariant="italic">pos</mml:mi></mml:math></inline-formula> indicates the position of the amino acid in the sequence (<inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mn>0</mml:mn><mml:mo>â¤</mml:mo><mml:mi mathvariant="italic">pos</mml:mi><mml:mo>â¤</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>). <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi>L</mml:mi></mml:math></inline-formula> represents the length of the peptide sequence. The variable <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>Â </mml:mo><mml:mi mathvariant="italic">and</mml:mi><mml:mo>Â </mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>Â </mml:mo><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>â¤</mml:mo><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>10</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> represent each position of the vector. It can be seen from <xref rid="E1" ref-type="disp-formula">Equations (1</xref> and <xref rid="E2" ref-type="disp-formula">2)</xref> that the values of odd positions and even positions are distinct. The <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>b</mml:mi></mml:math></inline-formula> and <italic toggle="yes">d</italic> are constants, and their values are set to 1000 and 20 in this study, respectively. The dimension of the position encoding feature is <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>L</mml:mi><mml:mo>Ã</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>-D.</p>
        <p>PSSM encoding: PSSM is one of the widely used evolutionary profiles, which is generated through the multiple sequence alignment (MSA) by running PSI-BLAST(<xref rid="btac715-B1" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic>, 1997</xref>) (â-num_ iterations 3 -evalue 0.01â). The query sequence is searched by the PSI-BLAST tool through the nrdb90 database (<xref rid="btac715-B20" ref-type="bibr">Holm and Sander, 1998</xref>). Because the length of AMP sequences is &lt;100, the alignments of several peptides cannot be generated. For these peptides, their PSSMs are produced by the PSI-BLAST to search the NR database (<xref rid="btac715-B35" ref-type="bibr">O'Leary <italic toggle="yes">et al.</italic>, 2016</xref>) instead of the nrdb90 database (<xref rid="btac715-B20" ref-type="bibr">Holm and Sander, 1998</xref>). The dimension of the PSSM feature is <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>L</mml:mi><mml:mo>Ã</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>-D.</p>
        <p>HMM encoding: in this study, the HMM profile is obtained by searching the query sequence against the Uniclust30 database using HHblits (<xref rid="btac715-B39" ref-type="bibr">Remmert <italic toggle="yes">et al.</italic>, 2012</xref>) with parameters â-n 3 -e 0.01â. The dimension of HMM is <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mi>L</mml:mi><mml:mo>Ã</mml:mo><mml:mn>30</mml:mn></mml:math></inline-formula>, where the first 20 columns represent the amino acids match state frequencies, and the rest 10 columns represent seven translation frequencies and three local diversities. In this study, the first 20 columns are used as the residue-level features, which are similar to the PSSM profile (<xref rid="btac715-B62" ref-type="bibr">Yan <italic toggle="yes">et al.</italic>, 2019</xref>). According to the HHblits manual (<xref rid="btac715-B39" ref-type="bibr">Remmert <italic toggle="yes">et al.</italic>, 2012</xref>), <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the HMM profile is calculated by <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mo>-</mml:mo><mml:mn>1000</mml:mn><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>â²</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>â²</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denotes the amino acid match state frequency. Therefore, each score <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>â²</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is converted as (<xref rid="btac715-B62" ref-type="bibr">Yan <italic toggle="yes">et al.</italic>, 2019</xref>):
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">'</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.001</mml:mn><mml:mo>Ã</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>â</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>â</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1,20</mml:mn></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:math></disp-formula></p>
        <p>Finally, the residue-level features are represented by integrating four descriptors, including one-hot encoding, position encoding, PSSM encoding and HMM encoding. The dimension of the residue-level feature is <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>L</mml:mi><mml:mo>Ã</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>-D.</p>
      </sec>
      <sec>
        <label>2.4.2</label>
        <title>Structure feature encoding</title>
        <p>The study shows that the AMP sequences have low sequence homology, but the corresponding structures of the AMPs may have high similarity (<xref rid="btac715-B57" ref-type="bibr">Wei <italic toggle="yes">et al.</italic>, 2021a</xref>,<xref rid="btac715-B58" ref-type="bibr">b</xref>). Therefore, the structural properties are able to effectively predict the AMPs and non-AMPs. Because the peptide structures validated by the experimental method are limited, their structures are predicted by computational methods, such as trRosetta (<xref rid="btac715-B65" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2020</xref>), etc.</p>
        <p>The trRosetta predicts the protein structures based on the predicted contact maps. The predicted contact map contains distance information and angles of all residue pairs. In this study, we utilize the distance information between pairs of <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> atoms in contact map to represent the spatial relationship of the residues. The distance information <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>Ã</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a binary matrix, where <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula> denotes the number of amino acids, and the element <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is defined as (<xref rid="btac715-B17" ref-type="bibr">GligorijeviÄ <italic toggle="yes">et al.</italic>, 2021</xref>):
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{" close="" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">if</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â¤</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">or</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">otherwise</mml:mi><mml:mtable><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd/></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the distance between atoms <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mi>u</mml:mi></mml:math></inline-formula> and <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>, <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the threshold distance. In this study, <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">th</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is set as 20 â«, which is optimized on the validation dataset. The input MSA of the peptide sequence is constructed by the HHblits, and the other parameters of trRosetta are set as default values.</p>
      </sec>
      <sec>
        <label>2.4.3</label>
        <title>Graph construction</title>
        <p>In this section, we utilize the graph to represent the peptide sequence, where the nodes consist of the residues-level information, and the edges are constructed according to the distance of the inter-residue pairs based on the structural information.</p>
        <p>For discussion convenience, a graph is defined as <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mi mathvariant="normal">G</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>â</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:math></inline-formula> is the set of nodes, and <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a node feature represented by the residue-level feature with the dimension of <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula>. <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> stands for the edge set of the graph.</p>
      </sec>
    </sec>
    <sec>
      <title>2.5 Neural network architecture module</title>
      <p>After constructing the graphs based on structural features and sequence features, a neural network based on GAT is designed to integrate information from the neighbor nodes and performs the prediction. It consists of three main modules, including (i) graph attention layers, (ii) top <italic toggle="yes">k</italic> pooling and (iii) output layers. The graph attention layers are utilized to extract the structural information from the graph of the sequence. The top <italic toggle="yes">k</italic> pooling can adaptively select the top <italic toggle="yes">k</italic> most informative nodes to generate the graph-level representation of the peptide. Finally, the output layers utilize the graph-level context vector to predict whether a peptide is an AMP or not.</p>
      <sec>
        <label>2.5.1</label>
        <title>Graph attention layers</title>
        <p>In this section, we utilize the GAT (<xref rid="btac715-B50" ref-type="bibr">VeliÄkoviÄ <italic toggle="yes">et al.</italic>, 2017</xref>) to extract the structural information from the graph constructed based on the predicted structures. It leverages masked self-attention mechanism to automatically assign weights to neighbor nodes along the edges. The larger the weight is, the more important the neighbor node is. Therefore, GAT captures the local associations between amino acids and their neighbors. In addition, GAT is robust for predicted structure data. Due to a large gap between the real pairwise distance and the predicted pairwise distance caused by the structural prediction noise, GAT can adaptively assign smaller weights to those noisy data to reduce the negative impact of noisy data on the prediction results. The process is shown in <xref rid="btac715-F3" ref-type="fig">FigureÂ 3</xref>.</p>
        <fig position="float" id="btac715-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Visualization of converting the process AMP structure into a complex graph. The ball and stick model in the left subfigure represent the substructure of the peptide, where the center ball represents the central amino acid <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> atom and the other balls are the <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> atoms of amino acids within the threshold <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>Â </mml:mo></mml:math></inline-formula>predicted by trRosetta. The right subfigure represents the process of updating the central node features using GAT. The characters âKâ, âTâ, âVâ, âNâ, âPâ and âCâ represent the corresponding amino acids of the target <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mo>Î²</mml:mo></mml:mrow></mml:msub><mml:mi mathvariant="normal">Â </mml:mi></mml:math></inline-formula>atoms</p>
          </caption>
          <graphic xlink:href="btac715f3" position="float"/>
        </fig>
        <p>Let <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> denotes the representation of node <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> with a dimension <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the layer <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mi>t</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mo>Â </mml:mo><mml:mn>1</mml:mn><mml:mo>â¤</mml:mo><mml:mi>t</mml:mi><mml:mo>â¤</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>. <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the feature of node <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> constructed in Section 2.4. <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:math></inline-formula> is the feature of node <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> after the last GAT layer. The neighborhood of a node <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> is defined as <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mi>N</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>u</mml:mi><mml:mo>â</mml:mo><mml:mi>V</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mi>E</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula>. GAT updates the node representation in an iterative way by using the following rule (<xref rid="btac715-B50" ref-type="bibr">VeliÄkoviÄ <italic toggle="yes">et al.</italic>, 2017</xref>):
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">â</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>â</mml:mo><mml:mi>N</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced><mml:mo>âª</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mo>Î±</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>Ã</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> is the projection transformation matrix in the layer <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>. Compared with the GCN utilizing the fixed weights based on the degrees of the respective nodes, GAT aggregates the neighboring features with the self-attention-based weights. The attention coefficients <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mo>Î±</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is computed by (<xref rid="btac715-B50" ref-type="bibr">VeliÄkoviÄ <italic toggle="yes">et al.</italic>, 2017</xref>):
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mo>Î±</mml:mo></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mo>â¡</mml:mo><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>]</mml:mo><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">â</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>â</mml:mo><mml:mi>N</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced><mml:mo>âª</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mo>â¡</mml:mo><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>]</mml:mo><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:math></disp-formula>where<inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mo>Â </mml:mo><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mo>Â·</mml:mo><mml:mo>)</mml:mo><mml:mo>Â </mml:mo></mml:math></inline-formula>is a LeakyReLU activation function and <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> is a vector of learnable parameters. <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mo>â¥</mml:mo></mml:math></inline-formula> represents concatenation.</p>
        <p>Besides, multi-head attention mechanism (<xref rid="btac715-B49" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>) is used in this study for the polysemous phenomenon. GAT with <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mi>H</mml:mi></mml:math></inline-formula> heads is equivalent to integrate <italic toggle="yes">H</italic> single GAT layers in parallel. Moreover, except for the last layer, <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mi mathvariant="italic">ReLU</mml:mi></mml:math></inline-formula> (<xref rid="btac715-B34" ref-type="bibr">Nair and Hinton, 2010</xref>) and <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mi mathvariant="italic">dropout</mml:mi></mml:math></inline-formula> (<xref rid="btac715-B45" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2014</xref>) are used after each GAT layer to enhance the ability of non-linear learning and generalization, respectively.</p>
      </sec>
      <sec>
        <label>2.5.2</label>
        <title>Top <italic toggle="yes">k</italic> pooling</title>
        <p>Top <italic toggle="yes">k</italic> pooling is an module to adaptively select a certain number of nodes (<xref rid="btac715-B15" ref-type="bibr">Gao and Ji, 2019</xref>). In this task, it converts the variable length amino acid sequence features into a fixed-length vector by selecting the top <italic toggle="yes">k</italic> residues (nodes) with the highest score.</p>
        <p>Top <italic toggle="yes">k</italic> pooling computes the scalar projection score <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for a node <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> with feature <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, which measures how much information of node <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mi>v</mml:mi></mml:math></inline-formula> reserves when projected onto the direction of a learnable vector <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mi>p</mml:mi></mml:math></inline-formula>. Then the new representation <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>â²</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is calculated based on the indices corresponding to the top <italic toggle="yes">k</italic> nodes. The calculation process is as follows (<xref rid="btac715-B15" ref-type="bibr">Gao and Ji, 2019</xref>):
<disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>â¥</mml:mo><mml:mi>p</mml:mi><mml:msub><mml:mrow><mml:mo>â¥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>v</mml:mi><mml:mo>â</mml:mo><mml:mi>V</mml:mi></mml:math></disp-formula><disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mi mathvariant="italic">idx</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">to</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula><disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">'</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">tanh</mml:mi></mml:mrow><mml:mo>â¡</mml:mo><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mi mathvariant="italic">idx</mml:mi></mml:math></disp-formula>where <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>v</mml:mi><mml:mo>â</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula> is the vector set of projection score; <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mi mathvariant="normal">to</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mo>Â·</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula> is used to select the top <italic toggle="yes">k</italic> most informative nodes and returns their indices set <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mi mathvariant="italic">idx</mml:mi></mml:math></inline-formula>. <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mi mathvariant="normal">tanh</mml:mi><mml:mo>â¡</mml:mo><mml:mo>(</mml:mo><mml:mo>Â·</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula> is a non-linear function and <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mo>â</mml:mo></mml:math></inline-formula> is the elementwise product.</p>
        <p>Finally, we obtain the graph representation <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mi>z</mml:mi></mml:math></inline-formula> by concatenating them linearly:
<disp-formula id="E10"><label>(10)</label><mml:math id="M10" display="block" overflow="scroll"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:msub><mml:mrow><mml:mo>â¥</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mi mathvariant="italic">idx</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">'</mml:mi></mml:mrow></mml:msubsup></mml:math></disp-formula></p>
      </sec>
      <sec>
        <label>2.5.3</label>
        <title>Output layers</title>
        <p>To predict whether the input sequence is an AMP or not, the linear layers are needed to learn a more discriminative representation, defined as (<xref rid="btac715-B18" ref-type="bibr">Goodfellow <italic toggle="yes">et al.</italic>, 2016</xref>):
<disp-formula id="E11"><label>(11)</label><mml:math id="M11" display="block" overflow="scroll"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math></disp-formula>where <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> are the input vector and output vector in the <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>th linear layer, respectively. <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="italic">flatten</mml:mi><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> denotes the weight matrix and <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is the bias of <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mi>t</mml:mi></mml:math></inline-formula>th linear layer. <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mi mathvariant="italic">ReLU</mml:mi></mml:math></inline-formula> and <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mi mathvariant="italic">dropout</mml:mi></mml:math></inline-formula> are used following each linear layer except the last one. After the last layer, a <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mi mathvariant="italic">softmax</mml:mi></mml:math></inline-formula> function (<xref rid="btac715-B18" ref-type="bibr">Goodfellow <italic toggle="yes">et al.</italic>, 2016</xref>) is added to perform the final prediction.
<disp-formula id="E12"><label>(12)</label><mml:math id="M12" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>â¡</mml:mo><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="false">â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>â</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>â¡</mml:mo><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>Â </mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula> denotes the binary label. Here AMP is labeled as 1, while non-AMP is labeled as 0. <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>Â </mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula> denotes the negative or positive probabilistic. <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mi>M</mml:mi></mml:math></inline-formula> is the total number of linear layers.</p>
      </sec>
      <sec>
        <label>2.5.4</label>
        <title>The model implementation</title>
        <p>We utilized the PyTorch (<ext-link xlink:href="https://pytorch.org/" ext-link-type="uri">https://pytorch.org/</ext-link>) and PyTorch Geometric (<xref rid="btac715-B13" ref-type="bibr">Fey and Lenssen, 2019</xref>) to implement sAMPpred-GAT. The negative log-likelihood loss function is used to measure the gap between predicted labels and truth labels. The ADAM algorithm (<xref rid="btac715-B28" ref-type="bibr">Kingma and Ba, 2014</xref>) is adopted to optimize GAT with a batch size of 512 during the training process. The initial learning rate of pretraining is set as 0.001, which is decayed to 95% for every 5 epochs. A total of 50 epochs are iterated. Then a smaller learning rate of 0.0001 and fewer epochs 20 are adapted to train the model. The other parameters are the same in both the two stages. The hyperparameters are optimized based on the grid search strategy according to the maximum AUC. Please refer to <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S1 and S2</xref> for more information.</p>
      </sec>
    </sec>
    <sec>
      <title>2.6 Evaluation metrics</title>
      <p>In this study, we utilize five metrics to evaluate the proposed method, which are calculated by:
<disp-formula id="E13"><label>(13)</label><mml:math id="M13" display="block" overflow="scroll"><mml:mfenced open="{" close="" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">CC</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">CC</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>Ã</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>Ã</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced></mml:msqrt></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">UC</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">Area</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">under</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">the</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">ROC</mml:mi><mml:mi mathvariant="normal">Â </mml:mi><mml:mi mathvariant="normal">Curve</mml:mi><mml:mi mathvariant="normal">Â </mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula>where <italic toggle="yes">TP</italic>, <italic toggle="yes">FP</italic>, <italic toggle="yes">TN</italic> and <italic toggle="yes">FN</italic> are the number of true positives, false positives, true negatives and false negatives, respectively (<xref rid="btac715-B6" ref-type="bibr">Charoenkwan <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac715-B8" ref-type="bibr">Chen and Shi, 2019</xref>; <xref rid="btac715-B25" ref-type="bibr">Jin <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <sec>
      <title>3.1 Performance on XUAMP independent test dataset</title>
      <p>In this section, we compare the proposed method with nine state-of-the-art methods on the independent test XUAMP dataset, including amPEPpy (<xref rid="btac715-B30" ref-type="bibr">Lawrence <italic toggle="yes">et al.</italic>, 2021</xref>), AMPfun (<xref rid="btac715-B10" ref-type="bibr">Chung <italic toggle="yes">et al.</italic>, 2019</xref>), AMPEP (<xref rid="btac715-B4" ref-type="bibr">Bhadra <italic toggle="yes">et al.</italic>, 2018</xref>), ADAM-HMM (<xref rid="btac715-B31" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2015</xref>), ampir (<xref rid="btac715-B14" ref-type="bibr">Fingerhut <italic toggle="yes">et al.</italic>, 2021</xref>), AMPScannerV2 (<xref rid="btac715-B51" ref-type="bibr">Veltri <italic toggle="yes">et al.</italic>, 2018</xref>), AMPGram (<xref rid="btac715-B5" ref-type="bibr">Burdukiewicz <italic toggle="yes">et al.</italic>, 2020</xref>), Deep-AMPEP30 (<xref rid="btac715-B61" ref-type="bibr">Yan <italic toggle="yes">et al.</italic>, 2020</xref>) and CAMP-ANN (<xref rid="btac715-B52" ref-type="bibr">Waghu <italic toggle="yes">et al.</italic>, 2016</xref>). For the sake of avoiding overestimating the performance of sAMPpred-GAT, the positive samples in the benchmark dataset sharing more than 90% similarities with any positive sample in the XUAMP independent test dataset are removed following (<xref rid="btac715-B51" ref-type="bibr">Veltri <italic toggle="yes">et al.</italic>, 2018</xref>). The negative samples in the benchmark dataset sharing more than 40% similarities with any negative sample in the XUAMP independent test dataset are removed as well. To avoid the randomness of the initialization parameters, the proposed method sAMPpred-GAT is run 10 times with random seeds.</p>
      <p>The experimental results of different methods are shown in <xref rid="btac715-F4" ref-type="fig">FigureÂ 4</xref> and <xref rid="btac715-T2" ref-type="table">TableÂ 2</xref>, from which we can observe that sAMPpred-GAT achieves the best performance in terms of AUC, ACC, MCC and Sn, and achieves highly comparable Sp. The results show that the proposed method achieves the highest AUC with fewer false positives. Therefore, sAMPpred-GAT is a useful predictor for identifying AMPs.</p>
      <fig position="float" id="btac715-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>ROC curves of sAMPpred-GAT and the other state-of-the-art methods on the XUAMP test dataset. The results of the other nine predictors are from <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref></p>
        </caption>
        <graphic xlink:href="btac715f4" position="float"/>
      </fig>
      <table-wrap position="float" id="btac715-T2">
        <label>Table 2.</label>
        <caption>
          <p>The performance of sAMPpred-GAT and the other existing predictors on the independent test XUAMP dataset in terms of ACC, MCC, Sn and Sp<xref rid="tblfn2" ref-type="table-fn"><sup>a</sup></xref></p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Method</th>
              <th align="left" rowspan="1" colspan="1">ACC</th>
              <th align="left" rowspan="1" colspan="1">MCC</th>
              <th align="left" rowspan="1" colspan="1">Sn</th>
              <th align="left" rowspan="1" colspan="1">Sp</th>
              <th align="center" rowspan="1" colspan="1">Source</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">amPEPpy</td>
              <td align="char" char="." rowspan="1" colspan="1">0.679</td>
              <td align="char" char="." rowspan="1" colspan="1">0.431</td>
              <td align="char" char="." rowspan="1" colspan="1">0.400</td>
              <td align="char" char="." rowspan="1" colspan="1">0.958</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AMPfun</td>
              <td align="char" char="." rowspan="1" colspan="1">0.674</td>
              <td align="char" char="." rowspan="1" colspan="1">0.414</td>
              <td align="char" char="." rowspan="1" colspan="1">0.406</td>
              <td align="char" char="." rowspan="1" colspan="1">0.943</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AMPEP</td>
              <td align="char" char="." rowspan="1" colspan="1">0.661</td>
              <td align="char" char="." rowspan="1" colspan="1">0.429</td>
              <td align="char" char="." rowspan="1" colspan="1">0.330</td>
              <td align="char" char="." rowspan="1" colspan="1">0.992</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ADAM-HMM</td>
              <td align="char" char="." rowspan="1" colspan="1">0.684</td>
              <td align="char" char="." rowspan="1" colspan="1">0.390</td>
              <td align="char" char="." rowspan="1" colspan="1">0.521</td>
              <td align="char" char="." rowspan="1" colspan="1">0.847</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Ampir</td>
              <td align="char" char="." rowspan="1" colspan="1">0.563</td>
              <td align="char" char="." rowspan="1" colspan="1">0.156</td>
              <td align="char" char="." rowspan="1" colspan="1">0.266</td>
              <td align="char" char="." rowspan="1" colspan="1">0.859</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AMPScannerV2</td>
              <td align="char" char="." rowspan="1" colspan="1">0.568</td>
              <td align="char" char="." rowspan="1" colspan="1">0.137</td>
              <td align="char" char="." rowspan="1" colspan="1">0.523</td>
              <td align="char" char="." rowspan="1" colspan="1">0.613</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AmpGram</td>
              <td align="char" char="." rowspan="1" colspan="1">0.564</td>
              <td align="char" char="." rowspan="1" colspan="1">0.131</td>
              <td align="char" char="." rowspan="1" colspan="1">0.445</td>
              <td align="char" char="." rowspan="1" colspan="1">0.682</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Deep-AMPEP30</td>
              <td align="char" char="." rowspan="1" colspan="1">0.533</td>
              <td align="char" char="." rowspan="1" colspan="1">0.183</td>
              <td align="char" char="." rowspan="1" colspan="1">0.065</td>
              <td rowspan="1" colspan="1">
                <bold>1.0</bold>
              </td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">CAMP-ANN</td>
              <td align="char" char="." rowspan="1" colspan="1">0.584</td>
              <td align="char" char="." rowspan="1" colspan="1">0.182</td>
              <td align="char" char="." rowspan="1" colspan="1">0.385</td>
              <td align="char" char="." rowspan="1" colspan="1">0.782</td>
              <td rowspan="1" colspan="1">
                <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">sAMPpred-GAT<xref rid="tblfn3" ref-type="table-fn"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">
                <bold>0.715âÂ±â0.01</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.464âÂ±â0.011</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.530âÂ±â0.038</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">0.9âÂ±â0.02</td>
              <td rowspan="1" colspan="1">This study</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <label>a</label>
            <p>The ACC, MCC, Sn and Sp values of nine compared methods are calculated based on the detailed prediction results of these predictors reported in Xu <italic toggle="yes">et al.</italic> (2021), which can be downloaded from <ext-link xlink:href="http://bliulab.net/sAMPpred-GAT/data/" ext-link-type="uri">http://bliulab.net/sAMPpred-GAT/data/</ext-link>.</p>
          </fn>
          <fn id="tblfn3">
            <label>b</label>
            <p>The reported results of the proposed method are the average and standard deviation after performing the randomness initialization parameters 10 times.</p>
          </fn>
          <fn id="tblfn4">
            <p><italic toggle="yes">Note</italic>: The best performance of each metric is highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.2 Performance on the other independent test datasets</title>
      <p>In this section, we comprehensively evaluate the performance of sAMPpred-GAT on the seven independent test datasets, including APD3 (<xref rid="btac715-B53" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), DRAMP (<xref rid="btac715-B12" ref-type="bibr">Fan <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac715-B27" ref-type="bibr">Kang <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), LAMP (<xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac715-B66" ref-type="bibr">Ye <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac715-B70" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2013</xref>), CAMP (<xref rid="btac715-B47" ref-type="bibr">Thomas <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac715-B52" ref-type="bibr">Waghu <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), dbAMP (<xref rid="btac715-B23" ref-type="bibr">Jhong <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), YADAMP (<xref rid="btac715-B37" ref-type="bibr">Piotto <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>) and DBAASP.</p>
      <p>For the sake of avoiding overestimating the performance of sAMPpred-GAT, for each target independent test dataset, the positive samples in the benchmark dataset sharing more than 90% similarities with any positive sample in the target independent test dataset are removed following (<xref rid="btac715-B51" ref-type="bibr">Veltri <italic toggle="yes">et al.</italic>, 2018</xref>). The negative samples in the benchmark dataset sharing more than 40% similarities with any negative sample in the target independent test dataset are removed (<xref rid="btac715-B51" ref-type="bibr">Veltri <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
      <p>We evaluate the performance of sAMPpred-GAT and the other state-of-the-art methods on the following independent test datasets: APD3 (<xref rid="btac715-B53" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2016</xref>), DRAMP (<xref rid="btac715-B12" ref-type="bibr">Fan <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btac715-B27" ref-type="bibr">Kang <italic toggle="yes">et al.</italic>, 2019</xref>), LAMP (<xref rid="btac715-B66" ref-type="bibr">Ye <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac715-B70" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic>, 2013</xref>), CAMP (<xref rid="btac715-B47" ref-type="bibr">Thomas <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btac715-B52" ref-type="bibr">Waghu <italic toggle="yes">et al.</italic>, 2016</xref>), dbAMP (<xref rid="btac715-B23" ref-type="bibr">Jhong <italic toggle="yes">et al.</italic>, 2019</xref>) and YADAMP (<xref rid="btac715-B37" ref-type="bibr">Piotto <italic toggle="yes">et al.</italic>, 2012</xref>). The results are listed in <xref rid="btac715-F5" ref-type="fig">FigureÂ 5</xref>, <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S3 and S4</xref>. Although sAMPpred-GAT outperforms most of the compared methods, it achieves similar performance as amPEPpy (<xref rid="btac715-B30" ref-type="bibr">Lawrence <italic toggle="yes">et al.</italic>, 2021</xref>), AMPfun (<xref rid="btac715-B10" ref-type="bibr">Chung <italic toggle="yes">et al.</italic>, 2019</xref>) and AMPEP (<xref rid="btac715-B4" ref-type="bibr">Bhadra <italic toggle="yes">et al.</italic>, 2018</xref>) on these six independent test datasets. However, we found that many samples in the six independent test datasets already exist in the corresponding training sets of amPEPpy, AMPfun and AMPEP (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref>). Therefore, the performance of these three methods on the six independent test datasets would be overestimated. In order to validate this point, we removed all these overlapping samples from the six independent test datasets to make sure that there is no overlapping sample between the training sets of the three compared methods and the six independent test datasets, and then the sAMPpred-GAT, amPEPpy, AMPfun and AMPEP were re-evaluated on these six non-redundant independent test datasets (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S6âS8</xref>). From these tables, we can see that the performance of amPEPpy, AMPfun and AMPEP decreases obviously, and sAMPpred-GAT outperforms all these three compared methods. Therefore, we conclude that the performance of amPEPpy, AMPfun and AMPEP on the six independent test datasets is indeed overestimated, and sAMPpred-GAT outperforms all the compared methods. Moreover, we further evaluate the performance of sAMPpred-GAT on the independent test dataset DBAASP, and its performance is compared with amPEPpy, AMPfun and AMPEP (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). The results further confirm the better of sAMPpred-GAT.</p>
      <fig position="float" id="btac715-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>ROC curves of sAMPpred-GAT and the other nine predictors on the six independent test datasets. The results of the other nine predictors are from <xref rid="btac715-B60" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref></p>
        </caption>
        <graphic xlink:href="btac715f5" position="float"/>
      </fig>
      <p>The sAMPpred-GAT predictor captures more discriminative features, while most of the existing methods utilized the hand-crafted features based on the experience. Therefore, the sAMPpred-GAT method is a useful tool for AMPs prediction.</p>
    </sec>
    <sec>
      <title>3.3 Effectiveness of structural features</title>
      <p>In this section, we analyze the effectiveness of structural features and the different numbers of GAT layers on the performance of sAMPpred-GAT on XUAMP dataset (see <xref rid="btac715-T3" ref-type="table">TableÂ 3</xref>). The results show that when the number of GAT layers is set as three, which obtains the best performance in terms of AUC. The performance of sAMPpred-GAT decreases when the layer number is higher than three, caused by the problem of over-smoothing in GNNs (<xref rid="btac715-B7" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2020</xref>). Moreover, when the number of GAT layers is 0, we only utilize the residue-level sequence features. The corresponding performance of sAMPpred-GAT is low, indicating that the structural features are discriminative and can improve the predictive performance. Therefore, the proposed method utilizes the GAT framework to extract the discriminative features from the structural properties of peptides so as to improve the predictive performance.</p>
      <table-wrap position="float" id="btac715-T3">
        <label>Table 3.</label>
        <caption>
          <p>The predictive performance of sAMPpred-GAT with different GAT layers on independent test XUAMP dataset</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">#Layers</th>
              <th align="left" rowspan="1" colspan="1">AUC</th>
              <th align="left" rowspan="1" colspan="1">ACC</th>
              <th align="left" rowspan="1" colspan="1">MCC</th>
              <th align="left" rowspan="1" colspan="1">Sn</th>
              <th align="left" rowspan="1" colspan="1">Sp</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">0</td>
              <td align="char" char="." rowspan="1" colspan="1">0.671</td>
              <td align="char" char="." rowspan="1" colspan="1">0.627</td>
              <td align="char" char="." rowspan="1" colspan="1">0.258</td>
              <td align="char" char="." rowspan="1" colspan="1">0.547</td>
              <td align="char" char="." rowspan="1" colspan="1">0.707</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1</td>
              <td align="char" char="." rowspan="1" colspan="1">0.737</td>
              <td align="char" char="." rowspan="1" colspan="1">0.684</td>
              <td align="char" char="." rowspan="1" colspan="1">0.392</td>
              <td align="char" char="." rowspan="1" colspan="1">0.517</td>
              <td align="char" char="." rowspan="1" colspan="1">0.852</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2</td>
              <td align="char" char="." rowspan="1" colspan="1">0.767</td>
              <td align="char" char="." rowspan="1" colspan="1">0.709</td>
              <td align="char" char="." rowspan="1" colspan="1">0.440</td>
              <td rowspan="1" colspan="1">
                <bold>0.551</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">0.866</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>3</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.777</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.715</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.464</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">0.530</td>
              <td rowspan="1" colspan="1">
                <bold>0.9</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4</td>
              <td align="char" char="." rowspan="1" colspan="1">0.772</td>
              <td align="char" char="." rowspan="1" colspan="1">0.711</td>
              <td align="char" char="." rowspan="1" colspan="1">0.451</td>
              <td align="char" char="." rowspan="1" colspan="1">0.538</td>
              <td align="char" char="." rowspan="1" colspan="1">0.884</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn5">
            <p><italic toggle="yes">Note</italic>: The best performance of each metric is highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.4 Analysis of sequential features</title>
      <p>In this section, we conduct an ablation experiment to evaluate the contribution of different residue-level sequential features to the performance of the sAMPpred-GAT predictor on the independent test XUAMP dataset. The results are shown in <xref rid="btac715-T4" ref-type="table">TableÂ 4</xref>, from which we see that when residue-level features with different properties are linearly combined, the performance of sAMPpred-GAT improves steadily. When we utilize the position encoding residue-level features, the performance of the proposed method improves obviously. Specifically, the position features improve the predictive performance by 4.3% and 4.5% in terms of AUC and ACC, respectively. The reason is that the machine learning predictors based on the GNN fail to capture the position information (<xref rid="btac715-B33" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac715-B67" ref-type="bibr">You <italic toggle="yes">et al.</italic>, 2019</xref>). As a result, the features associated with the position information is able to improve the prediction performance of sAMPpred-GAT. In addition, the proposed method extracts the evolutionary information by using neural networks, which can better distinguish the AMPs. Therefore, sAMPpred-GAT accurately predicts the AMPs by integrating the position and evolution information via using the GAT.</p>
      <table-wrap position="float" id="btac715-T4">
        <label>Table 4.</label>
        <caption>
          <p>The influence of different features and their combinations on the performance of sAMPpred-GAT evaluated on the XUAMP dataset</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Features</th>
              <th rowspan="1" colspan="1">AUC</th>
              <th rowspan="1" colspan="1">ACC</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Sn</th>
              <th rowspan="1" colspan="1">Sp</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">One-hot</td>
              <td align="char" char="." rowspan="1" colspan="1">0.705</td>
              <td align="char" char="." rowspan="1" colspan="1">0.650</td>
              <td align="char" char="." rowspan="1" colspan="1">0.323</td>
              <td align="char" char="." rowspan="1" colspan="1">0.470</td>
              <td align="char" char="." rowspan="1" colspan="1">0.831</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">One-hot + position</td>
              <td align="char" char="." rowspan="1" colspan="1">0.748</td>
              <td align="char" char="." rowspan="1" colspan="1">0.695</td>
              <td align="char" char="." rowspan="1" colspan="1">0.416</td>
              <td align="char" char="." rowspan="1" colspan="1">0.523</td>
              <td align="char" char="." rowspan="1" colspan="1">0.867</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">One-hot + position + PSSM</td>
              <td align="char" char="." rowspan="1" colspan="1">0.766</td>
              <td align="char" char="." rowspan="1" colspan="1">0.709</td>
              <td align="char" char="." rowspan="1" colspan="1">0.452</td>
              <td align="char" char="." rowspan="1" colspan="1">0.518</td>
              <td align="char" char="." rowspan="1" colspan="1">0.899</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">One-hot + position + PSSM + HMM</td>
              <td rowspan="1" colspan="1">
                <bold>0.777</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.715</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.464</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.530</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.9</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn6">
            <p><italic toggle="yes">Note</italic>: The best performance of each metric is highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.5 Visualization of the features extracted by sAMPpred-GAT</title>
      <p>The sAMPpred-GAT predictor mainly utilizes the GAT framework to automatically learn the inherent features from the structural information, sequence information and evolutionary information. To intuitively demonstrate the effectiveness of the learned features, we utilize the agglomerative clustering algorithm (<xref rid="btac715-B40" ref-type="bibr">Rokach and Maimon, 2005</xref>) to hierarchically cluster the learned features of the peptides from the XUAMP dataset. The results are shown in <xref rid="btac715-F6" ref-type="fig">FigureÂ 6</xref>, from which we can observe that: (i) the learned features with high values form the blocks, which indicates that peptides with similar functions have similar characteristics, and the peptides with different functions have different features. (ii) The peptides from the same function were groups into the same cluster. The learned features are more clearly to distinguish the AMP and non-AMP in feature space distribution. Therefore, the learned features extracted by sAMPpred-GAT are discriminative, contributing to the performance of sAMPpred-GAT for predicting AMPs.</p>
      <fig position="float" id="btac715-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Analysis of the learned features extracted by the sAMPpred-GAT by running agglomerative clustering over 40 peptides from XUAMP dataset. The learned features are extracted from the penultimate full connection layer with 64-D</p>
        </caption>
        <graphic xlink:href="btac715f6" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>AMPs are essential biomolecules of therapeutic peptides for the immune system of organisms. In this study, we proposed a sAMPpred-GAT predictor based on the predicted peptide structure information for AMPs recognition. The proposed method utilizes structural information, evolutionary profiles and sequence features to construct the graphs. Then the proposed method extracts the discriminative features from the graph by using the GAT framework. Finally, the optimized features are fed into the output layer to predict the AMPs. Experimental results show that the sAMPpred-GAT outperforms the other state-of-the-art methods in terms of AUC, and achieves better or highly comparable performance in terms of the other metrics on the eight independent test datasets. The framework using structural features and GAT layers can learn the inherent features with more discriminative power so as to improve the predictive performance. The GAT would have many other potential applications in bioinformatics, such as non-coding RNA and disease association identification, peptide prediction, etc.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac715_Supplementary_Data</label>
      <media xlink:href="btac715_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgments</title>
    <p>The authors were very much indebted to the three anonymous reviewers, whose constructive comments are very helpful for strengthening the presentation of this article.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the National Natural Science Foundation of China [62102030, U22A2039 and 62271049] and the Beijing Natural Science Foundation [JQ19019].</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac715-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>S.F.</given-names></string-name></person-group><etal>et al</etal> (<year>1997</year>) <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>â<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bahar</surname><given-names>A.A.</given-names></string-name>, <string-name><surname>Ren</surname><given-names>D.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Antimicrobial peptides</article-title>. <source>Pharmaceuticals (Basel)</source>, <volume>6</volume>, <fpage>1543</fpage>â<lpage>1575</lpage>.<pub-id pub-id-type="pmid">24287494</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barreto-Santamaria</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Designing and optimizing new antimicrobial peptides: all targets are not the same</article-title>. <source>Crit. Rev. Clin. Lab. Sci</source>., <volume>56</volume>, <fpage>351</fpage>â<lpage>373</lpage>.<pub-id pub-id-type="pmid">31397205</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bhadra</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>AmPEP: sequence-based prediction of antimicrobial peptides using distribution patterns of amino acid properties and random Forest</article-title>. <source>Sci. Rep</source>., <volume>8</volume>, <fpage>1697</fpage>.<pub-id pub-id-type="pmid">29374199</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burdukiewicz</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Proteomic screening for prediction and design of antimicrobial peptides with AmpGram</article-title>. <source>Int. J. Mol. Sci</source>., <volume>21</volume>, <fpage>4310</fpage>.<pub-id pub-id-type="pmid">32560350</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charoenkwan</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>StackIL6: a stacking ensemble model for improving the prediction of IL-6 inducing peptides</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>bbab172</fpage>.<pub-id pub-id-type="pmid">33963832</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Measuring and relieving the over-smoothing problem for graph neural networks from the topological view</article-title>. <source>Proc. AAAI Conf. Artif. Intell</source>., <volume>34</volume>, <fpage>3438</fpage>â<lpage>3445</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>J.</given-names></string-name>, <string-name><surname>Shi</surname><given-names>X.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Sparse convolutional denoising autoencoders for genotype imputation</article-title>. <source>Genes (Basel)</source>, <volume>10</volume>, <fpage>652</fpage>.<pub-id pub-id-type="pmid">31466333</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) PAR-GAN: improving the generalization of generative adversarial networks against membership inference attacks. In: <italic toggle="yes">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</italic>, <italic toggle="yes">Virtual Event, Singapore</italic>. Vol. <bold>11</bold>, <fpage>127</fpage>â<lpage>137</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chung</surname>,<given-names>C.-R.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Characterization and identification of antimicrobial peptides with different functional activities</article-title>. <source>Brief. Bioinform.</source>, <volume>21</volume>, <fpage>1098</fpage>â<lpage>1114</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de la Fuente-Nunez</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Antimicrobial peptides: role in human disease and potential as immunotherapies</article-title>. <source>Pharmacol. Ther</source>., <volume>178</volume>, <fpage>132</fpage>â<lpage>140</lpage>.<pub-id pub-id-type="pmid">28435091</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>DRAMP: a comprehensive data repository of antimicrobial peptides</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>24482</fpage>.<pub-id pub-id-type="pmid">27075512</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Fey</surname><given-names>M.</given-names></string-name>, <string-name><surname>Lenssen</surname><given-names>J.</given-names></string-name></person-group> (<year>2019</year>) <italic toggle="yes">Fast Graph Representation Learning with PyTorch Geometric</italic>.arXiv preprint arXiv:1903.02428.</mixed-citation>
    </ref>
    <ref id="btac715-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fingerhut</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Ampir: an R package for fast genome-wide prediction of antimicrobial peptides</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>5262</fpage>â<lpage>5263</lpage>.<pub-id pub-id-type="pmid">32683445</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>H.</given-names></string-name>, <string-name><surname>Ji</surname><given-names>S.</given-names></string-name></person-group> (<year>2019</year>) Graph u-nets. In: <italic toggle="yes">International Conference on Machine Learning</italic>. PMLR. pp. <fpage>2083</fpage>â<lpage>2092</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gaspar</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>From antimicrobial to anticancer peptides</article-title>. <source>Front. Microbiol</source>., <volume>4</volume>, <fpage>294</fpage>.<pub-id pub-id-type="pmid">24101917</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>GligorijeviÄ</surname><given-names>V.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Structure-based protein function prediction using graph convolutional networks</article-title>. <source>Nat. Commun</source>., <volume>12</volume>, <fpage>3168</fpage>.<pub-id pub-id-type="pmid">34039967</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Goodfellow</surname><given-names>I.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <source>Deep Learning</source>. <publisher-name>MIT Press</publisher-name>, Cambridge, MA, USA.</mixed-citation>
    </ref>
    <ref id="btac715-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>PreTP-EL: prediction of therapeutic peptides based on ensemble learning</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>bbab358</fpage>.<pub-id pub-id-type="pmid">34459488</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holm</surname><given-names>L.</given-names></string-name>, <string-name><surname>Sander</surname><given-names>C.J.B.</given-names></string-name></person-group> (<year>1998</year>) <article-title>Removing near-neighbour redundancy from large protein sequence collections</article-title>. <source>Bioinformatics</source>, <volume>14</volume>, <fpage>423</fpage>â<lpage>429</lpage>.<pub-id pub-id-type="pmid">9682055</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>CD-HIT suite: a web server for clustering and comparing biological sequences</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>680</fpage>â<lpage>682</lpage>.<pub-id pub-id-type="pmid">20053844</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jenssen</surname><given-names>H.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) <article-title>Peptide antimicrobial agents</article-title>. <source>Clin. Microbiol. Rev</source>., <volume>19</volume>, <fpage>491</fpage>â<lpage>511</lpage>.<pub-id pub-id-type="pmid">16847082</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jhong</surname><given-names>J.H.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>dbAMP: an integrated resource for exploring antimicrobial peptides with functional activities and physicochemical properties on transcriptome and proteome data</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D285</fpage>â<lpage>D297</lpage>.<pub-id pub-id-type="pmid">30380085</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jhong</surname><given-names>J.-H.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>dbAMP 2.0: updated resource for antimicrobial peptides with an enhanced scanning method for genomic and proteomic data</article-title>. <source>Nucleic Acids Res</source>., <volume>50</volume>, <fpage>D460</fpage>â<lpage>D470</lpage>.<pub-id pub-id-type="pmid">34850155</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jin</surname><given-names>Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>RA-UNet: a hybrid deep attention-aware network to extract liver and tumor in CT scans</article-title>. <source>Front. Bioeng. Biotechnol</source>., <volume>8</volume>, <fpage>605132</fpage>.<pub-id pub-id-type="pmid">33425871</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>, <volume>596</volume>, <fpage>583</fpage>â<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kang</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>DRAMP 2.0, an updated data repository of antimicrobial peptides</article-title>. <source>Sci. Data</source>, <volume>6</volume>, <fpage>148</fpage>.<pub-id pub-id-type="pmid">31409791</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B28">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.J.</given-names></string-name></person-group> (<year>2014</year>) <italic toggle="yes">Adam: A Method for Stochastic Optimization</italic>. In: <italic toggle="yes">Proceedings of the 3rd International Conference on Learning Representations (ICLR), San Diego, CA</italic>.</mixed-citation>
    </ref>
    <ref id="btac715-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lai</surname><given-names>B.</given-names></string-name>, <string-name><surname>Xu</surname><given-names>J.</given-names></string-name></person-group> (<year>2022</year>) <article-title>Accurate protein function prediction via graph attention networks with predicted structure information</article-title>. <source>Brief. Bioinform</source>., <volume>23</volume>, <fpage>bbab502</fpage>.<pub-id pub-id-type="pmid">34882195</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lawrence</surname><given-names>T.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>amPEPpy 1.0: a portable and accurate antimicrobial peptide prediction tool</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>2058</fpage>â<lpage>2060</lpage>.<pub-id pub-id-type="pmid">33135060</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>H.T.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>A large-scale structural classification of antimicrobial peptides</article-title>. <source>Biomed Res. Int</source>., <volume>2015</volume>, <fpage>475062</fpage>.<pub-id pub-id-type="pmid">26000295</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>AMPlify: attentive deep learning model for discovery of novel antimicrobial peptides effective against WHO priority pathogens</article-title>. <source>BMC Genomics</source>, <volume>23</volume>, <fpage>1</fpage>â<lpage>15</lpage>.<pub-id pub-id-type="pmid">34979896</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B33">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Deep learning of high-order interactions for protein interface prediction. In: <italic toggle="yes">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</italic>, pp. <fpage>679</fpage>â<lpage>687</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>V.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.E.</given-names></string-name></person-group> (<year>2010</year>) Rectified linear units improve restricted boltzmann machines. In: <italic toggle="yes">ICML</italic>.</mixed-citation>
    </ref>
    <ref id="btac715-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O'Leary</surname><given-names>N.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Reference sequence (RefSeq) database at NCBI: current status, taxonomic expansion, and functional annotation</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D733</fpage>â<lpage>D745</lpage>.<pub-id pub-id-type="pmid">26553804</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pang</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Identifying anti-coronavirus peptides by incorporating different negative datasets and imbalanced learning strategies</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>1085</fpage>â<lpage>1095</lpage>.<pub-id pub-id-type="pmid">33497434</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piotto</surname><given-names>S.P.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>YADAMP: yet another database of antimicrobial peptides</article-title>. <source>Int. J. Antimicrob. Agents</source>, <volume>39</volume>, <fpage>346</fpage>â<lpage>351</lpage>.<pub-id pub-id-type="pmid">22325123</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pirtskhalava</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>DBAASP v3: database of antimicrobial/cytotoxic activity and structure of peptides as a resource for development of new therapeutics</article-title>. <source>Nucleic Acids Res</source>., <volume>49</volume>, <fpage>D288</fpage>â<lpage>D297</lpage>.<pub-id pub-id-type="pmid">33151284</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Remmert</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>HHblits: lightning-fast iterative protein sequence searching by HMM-HMM alignment</article-title>. <volume>9</volume>, <fpage>173</fpage>â<lpage>175</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B40">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Rokach</surname><given-names>L.</given-names></string-name>, <string-name><surname>Maimon</surname><given-names>O.</given-names></string-name></person-group> (<year>2005</year>) <part-title>Clustering methods</part-title>. In: <source>Data Mining and Knowledge Discovery Handbook</source>, pp. <fpage>321</fpage>â<lpage>352</lpage>. <publisher-name>Springer</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac715-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saxena</surname><given-names>S.</given-names></string-name>, <string-name><surname>Gomber</surname><given-names>C.</given-names></string-name></person-group> (<year>2010</year>) <article-title>Surmounting antimicrobial resistance in the millennium superbug: staphylococcus aureus</article-title>. <source>Open Med</source>., <volume>5</volume>, <fpage>12</fpage>â<lpage>29</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shi</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>DRAMP 3.0: an enhanced comprehensive data repository of antimicrobial peptides</article-title>. <source>Nucleic Acids Res</source>., <volume>50</volume>, <fpage>D488</fpage>â<lpage>D496</lpage>.<pub-id pub-id-type="pmid">34390348</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>SATPdb: a database of structurally annotated therapeutic peptides</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D1119</fpage>â<lpage>1126</lpage>.<pub-id pub-id-type="pmid">26527728</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>iProt-Sub: a comprehensive package for accurately mapping and predicting protease-specific substrates and cleavage sites</article-title>. <source>Brief. Bioinform</source>., <volume>20</volume>, <fpage>638</fpage>â<lpage>658</lpage>.<pub-id pub-id-type="pmid">29897410</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Srivastava</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>BibSonomy</source>, <volume>15</volume>, <fpage>1929</fpage>â<lpage>1958</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thakur</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>AVPpred: collection and prediction of highly effective antiviral peptides</article-title>. <source>Nucleic Acids Res</source>., <volume>40</volume>, <fpage>W199</fpage>â<lpage>W204</lpage>.<pub-id pub-id-type="pmid">22638580</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thomas</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>CAMP: a useful resource for research on antimicrobial peptides</article-title>. <source>Nucleic Acids Res</source>., <volume>38</volume>, <fpage>D774</fpage>â<lpage>D780</lpage>.<pub-id pub-id-type="pmid">19923233</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B48">
      <mixed-citation publication-type="journal"><collab>UniProt Consortium</collab>. (<year>2015</year>) <article-title>UniProt: a hub for protein information</article-title>. <source>Nucleic Acids Res</source>., <volume>43</volume>, <fpage>D204</fpage>â<lpage>D212</lpage>.<pub-id pub-id-type="pmid">25348405</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Attention is all you need</article-title>. <source>Adv. Neural Inf. Process. Syst</source>., <bold>30</bold>, <fpage>5998</fpage>â<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B50">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>VeliÄkoviÄ</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <italic toggle="yes">Graph Attention Networks</italic>.</mixed-citation>
    </ref>
    <ref id="btac715-B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Veltri</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Deep learning improves antimicrobial peptide recognition</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2740</fpage>â<lpage>2747</lpage>.<pub-id pub-id-type="pmid">29590297</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Waghu</surname><given-names>F.H.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>CAMPR3: a database on sequences, structures and signatures of antimicrobial peptides</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D1094</fpage>â<lpage>1097</lpage>.<pub-id pub-id-type="pmid">26467475</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>APD3: the antimicrobial peptide database as a tool for research and education</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D1087</fpage>â<lpage>1093</lpage>.<pub-id pub-id-type="pmid">26602694</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>G.</given-names></string-name></person-group> (<year>2004</year>) <article-title>APD: the antimicrobial peptide database</article-title>, <source>Nucleic Acids Res</source>., <volume>32</volume>, <fpage>D590</fpage>â<lpage>D592</lpage>.<pub-id pub-id-type="pmid">14681488</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>ACPred-FL: a sequence-based predictor using effective feature representation to improve the prediction of anti-cancer peptides</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>4007</fpage>â<lpage>4016</lpage>.<pub-id pub-id-type="pmid">29868903</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>G.-W.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Protein structure prediction beyond AlphaFold</article-title>. <source>Nat. Mach. Intell</source>., <volume>1</volume>, <fpage>336</fpage>â<lpage>337</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2021a</year>) <article-title>Computational prediction and interpretation of cell-specific replication origin sites from multiple eukaryotes by exploiting stacking framework</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>bbaa275</fpage>.<pub-id pub-id-type="pmid">33152766</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wei</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2021b</year>) <article-title>ATSE: a peptide toxicity predictor by exploiting structural and evolutionary information based on graph neural network and attention mechanism</article-title>. <source>Brief. Bioinform.</source>, <volume>22</volume>, <fpage>bbab041</fpage>.<pub-id pub-id-type="pmid">33822870</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xia</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>GraphBind: protein structural context embedded rules learned by hierarchical graph neural networks for recognizing nucleic-acid-binding residues</article-title>. <source>Nucleic Acids Res</source>., <volume>49</volume>, <fpage>e51</fpage>.<pub-id pub-id-type="pmid">33577689</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Comprehensive assessment of machine learning-based methods for predicting antimicrobial peptides</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>bbab08</fpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Deep-AmPEP30: improve short antimicrobial peptides prediction with deep learning</article-title>. <source>Mol. Ther. Nucleic Acids</source>, <volume>20</volume>, <fpage>882</fpage>â<lpage>894</lpage>.<pub-id pub-id-type="pmid">32464552</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Protein fold recognition based on multi-view modeling</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2982</fpage>â<lpage>2990</lpage>.<pub-id pub-id-type="pmid">30668845</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2022a</year>) <article-title>TPpred-ATMV: therapeutic peptides prediction by adaptive multi-view tensor learning model</article-title>. <source>Bioinformatics</source>, <volume>38</volume>, <fpage>2712</fpage>â<lpage>2718</lpage>.<pub-id pub-id-type="pmid">35561206</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B64">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yan</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2022b</year>) <article-title>TP-MV: therapeutic peptides prediction by multi-view learning</article-title>. <source>Curr. Bioinform</source>., <volume>17</volume>, <fpage>174</fpage>â<lpage>183</lpage>.</mixed-citation>
    </ref>
    <ref id="btac715-B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Improved protein structure prediction using predicted interresidue orientations</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>117</volume>, <fpage>1496</fpage>â<lpage>1503</lpage>.<pub-id pub-id-type="pmid">31896580</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B66">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ye</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>LAMP2: a major update of the database linking antimicrobial peptides</article-title>. <source>Database (Oxford)</source>, <volume>2020</volume>, baaa061.</mixed-citation>
    </ref>
    <ref id="btac715-B67">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>You</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) Position-aware graph neural networks. In: <italic toggle="yes">International Conference on Machine Learning</italic>, pp. <fpage>7134</fpage>â<lpage>7143</lpage>. PMLR.</mixed-citation>
    </ref>
    <ref id="btac715-B68">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zasloff</surname><given-names>M.</given-names></string-name></person-group> (<year>2002</year>) <article-title>Antimicrobial peptides of multicellular organisms</article-title>. <source>Nature</source>, <volume>415</volume>, <fpage>389</fpage>â<lpage>395</lpage>.<pub-id pub-id-type="pmid">11807545</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B69">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Identifying drug-target interactions based on graph convolutional network and deep neural network</article-title>. <source>Brief. Bioinform</source>., <volume>22</volume>, <fpage>2141</fpage>â<lpage>2150</lpage>.<pub-id pub-id-type="pmid">32367110</pub-id></mixed-citation>
    </ref>
    <ref id="btac715-B70">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>LAMP: a database linking antimicrobial peptides</article-title>. <source>PLoS One</source>, <volume>8</volume>, <fpage>e66557</fpage>.<pub-id pub-id-type="pmid">23825543</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
