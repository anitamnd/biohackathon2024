<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9761970</article-id>
    <article-id pub-id-type="publisher-id">5096</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-05096-w</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>JCBIE: a joint continual learning neural network for biomedical information extraction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>He</surname>
          <given-names>Kai</given-names>
        </name>
        <address>
          <email>hk52025804@stu.xjtu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mao</surname>
          <given-names>Rui</given-names>
        </name>
        <address>
          <email>rui.mao@ntu.edu.sg</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gong</surname>
          <given-names>Tieliang</given-names>
        </name>
        <address>
          <email>gongtl@xjtu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cambria</surname>
          <given-names>Erik</given-names>
        </name>
        <address>
          <email>cambria@ntu.edu.sg</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Li</surname>
          <given-names>Chen</given-names>
        </name>
        <address>
          <email>cli@xjtu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.43169.39</institution-id><institution-id institution-id-type="ISNI">0000 0001 0599 1243</institution-id><institution>School of Computer Science and Technology, </institution><institution>Xi’an Jiaotong University, </institution></institution-wrap>Xi’an, Shaanxi China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.43169.39</institution-id><institution-id institution-id-type="ISNI">0000 0001 0599 1243</institution-id><institution>Shaanxi Provincial Key Laboratory of Big Data Knowledge Engineering, </institution><institution>Xi’an Jiaotong University, </institution></institution-wrap>Xi’an, Shaanxi China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.43169.39</institution-id><institution-id institution-id-type="ISNI">0000 0001 0599 1243</institution-id><institution>National Engineering Lab for Big Data Analytics, </institution><institution>Xi’an Jiaotong University, </institution></institution-wrap>Xi’an, Shaanxi China </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.59025.3b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2224 0361</institution-id><institution>School of Computer Science and Engineering, </institution><institution>Nanyang Technological University, </institution></institution-wrap>Singapore, Singapore </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>19</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>19</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>549</elocation-id>
    <history>
      <date date-type="received">
        <day>11</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>5</day>
        <month>12</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Extracting knowledge from heterogeneous data sources is fundamental for the construction of structured biomedical knowledge graphs (BKGs), where entities and relations are represented as nodes and edges in the graphs, respectively. Previous biomedical knowledge extraction methods simply considered limited entity types and relations by using a task-specific training set, which is insufficient for large-scale BKGs development and downstream task applications in different scenarios. To alleviate this issue, we propose a joint continual learning biomedical information extraction (JCBIE) network to extract entities and relations from different biomedical information datasets. By empirically studying different joint learning and continual learning strategies, the proposed JCBIE can learn and expand different types of entities and relations from different datasets. JCBIE uses two separated encoders in joint-feature extraction, hence can effectively avoid the feature confusion problem comparing with using one hard-parameter sharing encoder. Specifically, it allows us to adopt entity augmented inputs to establish the interaction between named entity recognition and relation extraction. Finally, a novel evaluation mechanism is proposed for measuring cross-corpus generalization errors, which was ignored by traditional evaluation methods. Our empirical studies show that JCBIE achieves promising performance when continual learning strategy is adopted with multiple corpora.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Biomedical information extraction</kwd>
      <kwd>Continual learning</kwd>
      <kwd>Joint learning</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Key Research and Development Program of Shaanxi Province</institution>
        </funding-source>
        <award-id>021GXLH-Z-095</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Innovative Research Group of the National Natural Science Foundation of China</institution>
        </funding-source>
        <award-id>61721002</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Innovation Research Team of the Ministry of Education, Project of China Knowledge Centre for Engineering Science and Technology</institution>
        </funding-source>
        <award-id>IRT_17R86</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Key Research and Development Program of Ningxia Hui Nationality Autonomous Region</institution>
        </funding-source>
        <award-id>2022BEG02025</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par12">The rapid increasing of biomedical knowledge from biomedical experiments and clinical practice provides considerable resources for biomedical information extraction [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR3">3</xref>]. Biomedical knowledge graphs (BKGs) organize biomedical entities and relations in the form of nodes and edges. Extracting entities, such as chemical/drug, protein/gene, and phenotype/disease, and their relations from unstructured text data is the foundation of developing large-scale biomedical BKGs [<xref ref-type="bibr" rid="CR4">4</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. In this work, we study Named Entity Recognition (NER) [<xref ref-type="bibr" rid="CR8">8</xref>] and Relation Extraction (RE) [<xref ref-type="bibr" rid="CR9">9</xref>] techniques to extract biomedical information. We further divide NER as entity span detection (SP) and entity type detection (ET) sub-tasks in our experiments for gaining better results in the RE task.<fig id="Fig1"><label>Fig. 1</label><caption><p>The difference between multiple-model learning and continual learning in biomedical information extraction. <bold>a</bold> Multi-models for extracting knowledge from multi-corpora. <bold>b</bold> A continual learning model. The input subscript with different numbers denotes different subsets in b. ADE, adverse drug events; DDI, drug–drug interaction; CPR, chemical protein reaction; KNWL, knowledge</p></caption><graphic xlink:href="12859_2022_5096_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par13">Typical biomedical NER and RE tasks include the detecting of drug–drug interaction (DDI) [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>], adverse drug events (ADE) [<xref ref-type="bibr" rid="CR12">12</xref>], chemical protein reaction (CPR) [<xref ref-type="bibr" rid="CR13">13</xref>], protein–protein interaction (PPI) [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>], and mutation mining [<xref ref-type="bibr" rid="CR16">16</xref>]. Each dataset only contains limited entity types and relation types, hence cannot support the understanding and inferring of entities and relations across tasks. For example, the ADE corpus only annotated drugs, diseases, and their interactions, and the CPR corpus only annotated the reaction relations and the entities of chemicals and proteins. However, sometimes we may require knowledge from both ADE and CPR to establish semantic interconnections between diseases of ADE and proteins of CPR by drug entities. Thus, traditional practices [<xref ref-type="bibr" rid="CR17">17</xref>–<xref ref-type="bibr" rid="CR19">19</xref>] developed multi-models to obtain knowledge from different datasets and learning tasks (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>a). The limit of using multi-models is that the learning of common entity types (e.g., both ADE and CPR contain drug entities) cannot be shared across tasks and models. Besides, given a new corpus, extracting knowledge with multi-models is computationally expensive. In real-world practices, it is common to expand the size of an existing dataset, or learn new types of entities and relations from a new dataset over time. It is inconvenient to train a new model and maintain previous multiple trained models with every dataset update.</p>
    <p id="Par14">To solve the above problems, we propose a Joint Continual Learning Biomedical Information Extraction (JCBIE) network to jointly extract biomedical entities and relations based on a continual multi-corpora learning framework (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>b). In order to learn new entity types and relation types over time by only one model, we use multi-head binary classifiers instead of a typical multi-class single-head classifier for ET and RE tasks. Thus, the size of pre-defined label set of entities and relations can be expanded by continually learning new datasets. Our method aims to support the constructions of extensible biomedical knowledge graphs with an extraction neural model.</p>
    <p id="Par15">We compare JCBIE (no-parameter sharing, multi-head classifier) with a traditional hard parameter-sharing and single-head classification method that was commonly used in current works [<xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR23">23</xref>], based on the same multi-corpora learning paradigm. JCBIE achieves an average gain of 2.77% micro-F1 scores over four different dataset fusion setups. We also examine the generalization abilities of traditional continual learning, multi-corpora learning, and our proposed continual multi-corpora learning approaches, based on different dataset feeding order setups and a different testing set. Our proposed learning paradigm yields average gains of 2.39% and 1.89% micro-F1 scores in a novel corpus-adaptation evaluation task over the two baseline learning paradigms, respectively.</p>
    <p id="Par16">We conduct systematic empirical studies for analyzing different variations in parameter-sharing mechanisms (Sect. <xref rid="Sec16" ref-type="sec">5.2</xref>), feature augmentation methods (Sect. <xref rid="Sec17" ref-type="sec">5.3</xref>), learning paradigms (Sect. <xref rid="Sec18" ref-type="sec">5.4</xref>), output-side classifier head types (Sect. <xref rid="Sec19" ref-type="sec">5.5</xref>), to answer the following questions: (1) What encoder parameter-sharing method is more suitable for learning SP, ET, and RE, simultaneously? (2) What feature augmentation method is more supportive for the RE task after identifying ET and SP of the NER task? (3) What is the difference between continual learning, multi-corpora learning, and continual multi-corpora learning? (4) Does a multi-class classifier (single-head) on the output side surpasses multiple binary classifiers (multi-head) in identifying multiple relation classes?</p>
    <p id="Par17">The contribution of this work can be summarized as twofold:<list list-type="order"><list-item><p id="Par18">We propose a continual multi-corpora learning paradigm and an associated model with multi-head classifiers for ET and RE. The multi-head classifiers allow the model to expand the label vocabulary of entity types and relation types over time by feeding new datasets and introducing new label-oriented heads.</p></list-item><list-item><p id="Par19">We conduct systematic empirical studies for analyzing different variations in model framework, feature augmentation methods, and learning paradigms. The results demonstrate the efficiency of the proposed method under different conditions.</p></list-item></list><table-wrap id="Tab1"><label>Table 1</label><caption><p>The example labels for exacting information from ADE, DDI and CPR</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" rowspan="4">ADE</td><td align="left">Input:</td><td align="left" colspan="8">Two cases of mequitazine induced photosensitivity reactions</td></tr><tr><td align="left">SP:</td><td align="left">O</td><td align="left">O</td><td align="left">O</td><td align="left">S</td><td align="left">O</td><td align="left">B</td><td align="left">E</td><td align="left">O</td></tr><tr><td align="left">ET:</td><td align="left"/><td align="left"/><td align="left"/><td align="left">Drug</td><td align="left"/><td align="left">Disease</td><td align="left">Disease</td><td align="left"/></tr><tr><td align="left">RE:</td><td align="left"/><td align="left"/><td align="left"/><td align="left">ADE</td><td align="left"/><td align="left">ADE</td><td align="left">ADE</td><td align="left"/></tr><tr><td align="left" rowspan="4">DDI</td><td align="left">Input:</td><td align="left" colspan="8">Thyroid may potentiate toxic effects of digitalis</td></tr><tr><td align="left">SP:</td><td align="left">S</td><td align="left">O</td><td align="left">O</td><td align="left">O</td><td align="left">O</td><td align="left">O</td><td align="left">S</td><td align="left">O</td></tr><tr><td align="left">ET:</td><td align="left">Drug</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">Drug</td><td align="left"/></tr><tr><td align="left">RE:</td><td align="left">DDI</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left">DDI</td><td align="left"/></tr><tr><td align="left" rowspan="4">CPR</td><td align="left">Input:</td><td align="left" colspan="8">… methyl rosmarinate activities against matrix metalloproteinase-1 …</td></tr><tr><td align="left">SP:</td><td align="left"/><td align="left">B</td><td align="left">E</td><td align="left">O</td><td align="left">O</td><td align="left">O</td><td align="left">S</td><td align="left"/></tr><tr><td align="left">ET:</td><td align="left"/><td align="left">Chemical</td><td align="left">Chemical</td><td align="left"/><td align="left"/><td align="left"/><td align="left">Gene</td><td align="left"/></tr><tr><td align="left">RE:</td><td align="left"/><td align="left">CPR</td><td align="left">CPR</td><td align="left"/><td align="left"/><td align="left"/><td align="left">CPR</td><td align="left"/></tr></tbody></table><table-wrap-foot><p>SP denotes entity spans, employing BIOES tagging scheme (Beginning-Inside-Outside-End-Single). ET, entity type; RE, relation extraction</p></table-wrap-foot></table-wrap></p>
  </sec>
  <sec id="Sec2">
    <title>Related work</title>
    <p id="Par20">Joint extraction is a popular solution to biomedical datasets in DDI, ADE, CPR, and PPI [<xref ref-type="bibr" rid="CR11">11</xref>–<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. The basic assumption of joint extraction is that joint models can enhance the interactions between NER and RE [<xref ref-type="bibr" rid="CR24">24</xref>], and alleviating the error propagation problem through sharing a common encoder [<xref ref-type="bibr" rid="CR25">25</xref>–<xref ref-type="bibr" rid="CR27">27</xref>]. Miwa and Bansal [<xref ref-type="bibr" rid="CR20">20</xref>] firstly utilized a shared Bi-LSTM layer to encode input tokens, passing the word representations into NER and RE classifiers with dependency parsing features. Sun et al. [<xref ref-type="bibr" rid="CR22">22</xref>] developed a joint extraction model based on a common graph convolutional network (GCN) encoder to perform a joint inference on entity types and relation types. These works are based on the assumption that the trained model is dataset-specific, which only needs to deal with the biomedical entity and relation types that have been defined in advance in a dataset. However, the data used to learn the same types of entities and relations are possibly supplemented over time in real-world practices. New entity types and relations are also gradually introduced in the biomedical research domain. Then, those dataset-specific models have to be retrained with new data and labels. Thus, a robust continual learning model is more fitting for the real-world applications.</p>
    <p id="Par21">The recent novel joint extraction research can be grouped into three sets. (1) The table filling strategy extracts information by labeling input tokens in a table. Miwa and Sasaki [<xref ref-type="bibr" rid="CR28">28</xref>] utilized token lists of sentences to form rows and columns. Then, they extracted entities using the diagonal elements and classified relations with a lower triangular matrix of the table. Zhang et al. [<xref ref-type="bibr" rid="CR29">29</xref>] integrated a global optimization technique and syntax information into the table-filling strategy to jointly train NER and RE. (2) Tagging scheme based methods jointly train NER and RE by designing customized tagging schemes. Zheng et al. [<xref ref-type="bibr" rid="CR30">30</xref>] firstly proposed a novel tagging scheme that converts joint extraction to a tagging task. Yu et al. [<xref ref-type="bibr" rid="CR31">31</xref>] decomposed the joint extraction into two sub-tasks. They first distinguished all head-entities, and then identifying tail-entities and relations jointly. (3) Seq2seq based methods regard NER and RE as a seq2seq generating task. Zeng et al. [<xref ref-type="bibr" rid="CR32">32</xref>] proposed a CopyRE model, firstly introducing a Seq2Seq model for jointly extracting entities and relations to overcome the overlapped relation issue. Following, Zeng et al. [<xref ref-type="bibr" rid="CR33">33</xref>] pointed out the CopyRE model could not distinguish head and tail entities. Then, they upgraded it to a CopyMTL model by adding a non-linear layer.</p>
    <p id="Par22">However, nearly all the above studies typically hypothesize that sharing parameters can provide better representations for joint NER and RE, failing to account for the differences between the two tasks. By utilizing different language models (LMs), model structures, and extraction strategies, these studies obtained state-of-the-art results. However, these methods did not properly control necessary variables for benchmarking. For example, a recent study [<xref ref-type="bibr" rid="CR34">34</xref>] indicated that most joint extraction studies did not compare their joint methods with pipeline-based methods (e.g., comparing NER performance first, then RE) and compare different joint extraction methods with different pre-trained LMs. In such a condition, it is unsure whether empirical gains mainly come from joint model structures or different pre-trained LMs. Thus, we are motivated to conduct a systematic empirical study to demonstrate the utilities of different components of a typical NER and RE jointly learning model.</p>
    <p id="Par23">For continual learning, the main problem is catastrophic forgetting [<xref ref-type="bibr" rid="CR35">35</xref>], which means a model forgets learnt knowledge after learning a new task. To alleviate this problem, ExtendNER [<xref ref-type="bibr" rid="CR36">36</xref>] took the advantage of knowledge distillation to achieve continual NER tasks by transferring old knowledge in a teacher model to a new student model when new types occurred. Based on ExtendNER, L&amp;R [<xref ref-type="bibr" rid="CR37">37</xref>] supplemented synthetic samples which contained old type information to the knowledge distillation process, and found that such data replay process can boost performance for NER tasks. The research of [<xref ref-type="bibr" rid="CR38">38</xref>] proposed a novel experimental framework that incorporated multiple tasks without explicit task identifiers. Also, this study proposed a benchmark and a new metric for continual learning, and concluded that replay models are better than memory-based solutions in a general continual learning setup. Different from the previous studies [<xref ref-type="bibr" rid="CR36">36</xref>, <xref ref-type="bibr" rid="CR37">37</xref>], JCBIE only adopts a data replay method combined with multi-head classifiers to achieve continual learning and obtains satisfying results.</p>
  </sec>
  <sec id="Sec3">
    <title>Methodology</title>
    <p id="Par24">The learning target is formalized as joint NER and RE under continual learning setups. Unlike traditional approaches that consider NER as a single task in biomedical information extraction [<xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR39">39</xref>], we divide the NER task as SP and ET tasks, respectively (seen Table <xref rid="Tab1" ref-type="table">1</xref>). The SP task employs BIOES tagging scheme [<xref ref-type="bibr" rid="CR30">30</xref>], where B, I, O, E, and S denote beginning, inside, outside, end, and single, respectively. Our JCBIE model continually learns SP, ET, and RE labels on token-level over different entity types and relation types from different datasets (ADE, DDI, and CPR).</p>
    <p id="Par25">We demonstrate the overall framework of JCBIE in Sect. <xref rid="Sec4" ref-type="sec">3.1</xref>. Our proposed method means to address the following challenges: Sect. <xref rid="Sec5" ref-type="sec">3.2</xref>. Efficient encoding for learning NER and RE tasks, simultaneously; Sect. <xref rid="Sec6" ref-type="sec">3.3</xref>. Efficient hidden state augmentation for learning RE; Sect. <xref rid="Sec7" ref-type="sec">3.4</xref>. A scalable classifier for continually learning new labels; Sect. <xref rid="Sec8" ref-type="sec">3.5</xref>. An efficient continual learning paradigm for learning dataset pipelines. To sum up, JCBIE employs non-parameter sharing encoders, entity marker augmented RE hidden state representations, multi-head classifiers, and a continual multi-corpora learning paradigm to fit the context of continual learning biomedical information extraction. The details of our proposed techniques (marked as <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bigstar$$\end{document}</tex-math><mml:math id="M2"><mml:mi>★</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq1.gif"/></alternatives></inline-formula> in Sects. <xref rid="Sec5" ref-type="sec">3.2</xref>–<xref rid="Sec8" ref-type="sec">3.5</xref>) and alternatives are shown in the following subsections.</p>
    <sec id="Sec4">
      <title>JCBIE</title>
      <p id="Par26">As seen in Fig. <xref rid="Fig2" ref-type="fig">2</xref>a, JCBIE includes five technical components, namely Bio-BERT [<xref ref-type="bibr" rid="CR40">40</xref>] based NER and RE encoders, SP, ET, and RE classifiers. In the training process, SP, ET, and RE are trained, simultaneously. In the inferring process, ET prediction is conditioned on SP results, and the relation prediction of two entities (RE) is conditioned on SP and ET results.</p>
      <p id="Par27">Given an input sentence <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$sent=\{x_1, x_2, ... x_i, ... x_n\}$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq2.gif"/></alternatives></inline-formula>, where <italic>sent</italic> is randomly sampled from a used dataset, <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq3.gif"/></alternatives></inline-formula> (<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1 \le i \le n$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq4.gif"/></alternatives></inline-formula>) is a natural language token, and <italic>n</italic> is the length of <italic>sent</italic>, JCBIE employs two Bio-BERT encoders for NER and RE, respectively. The output hidden states of each encoder are given by<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} h_{i}^{NER}=Encoder^{NER}\left( x_i\right) \end{aligned}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} h_{i}^{RE}=Encoder^{RE}\left( x_i\right) . \end{aligned}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>Noticeably, <inline-formula id="IEq5"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{i}^{NER} \in {\mathbb {R}}^{1 \times d}$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq5.gif"/></alternatives></inline-formula> is used for learning SP and ET labels for each token in a <italic>sent</italic>. <inline-formula id="IEq6"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{i}^{RE}$$\end{document}</tex-math><mml:math id="M16"><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq6.gif"/></alternatives></inline-formula> has the same shape with <inline-formula id="IEq7"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{i}^{NER}$$\end{document}</tex-math><mml:math id="M18"><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq7.gif"/></alternatives></inline-formula>. <italic>d</italic> is the dimension of hidden states. Next, we employ three two-layer feed-forward networks as the classifiers (<inline-formula id="IEq8"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T^{SP}(\cdot ),T^{ET}(\cdot ),T^{RE}(\cdot )$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq8.gif"/></alternatives></inline-formula>) upon the encoders, where a predicted SP label (<inline-formula id="IEq9"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}_{i}^{SP}$$\end{document}</tex-math><mml:math id="M22"><mml:msubsup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq9.gif"/></alternatives></inline-formula>) is given by Eq. (<xref rid="Equ3" ref-type="">3</xref>). <inline-formula id="IEq10"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y^{SP}$$\end{document}</tex-math><mml:math id="M24"><mml:msup><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq10.gif"/></alternatives></inline-formula> (<inline-formula id="IEq11"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{i}^{SP} \in Y^{SP}$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq11.gif"/></alternatives></inline-formula>) denotes the ground-truth span of multiple entity mentions (<inline-formula id="IEq12"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[e1,e2,...,e_{j},...,e_{k},...]$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>e</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq12.gif"/></alternatives></inline-formula>) in a sentence. We define the span of an entity mention <inline-formula id="IEq13"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq13.gif"/></alternatives></inline-formula> covers the token indices from <inline-formula id="IEq14"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi _{j}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq14.gif"/></alternatives></inline-formula> to <inline-formula id="IEq15"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon _{j}$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq15.gif"/></alternatives></inline-formula>.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\hat{y}}_{i}^{SP} = T^{SP} (h_{i}^{NER}). \end{aligned}$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>Then, the ET prediction of <inline-formula id="IEq16"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_{j}$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq16.gif"/></alternatives></inline-formula> (<inline-formula id="IEq17"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}^{ET}_{e_j}$$\end{document}</tex-math><mml:math id="M40"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq17.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq18"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}^{ET}_{e_j} \in {\hat{Y}}^{ET}$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq18.gif"/></alternatives></inline-formula>) is given by<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\hat{y}}^{ET}_{e_j}=T^{ET} \left( \sum _{i=\xi _j}^{\epsilon _j} h_{i}^{NER} \right) . \end{aligned}$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>The predicted RE label (<inline-formula id="IEq19"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}^{RE}_{e_j,e_k}$$\end{document}</tex-math><mml:math id="M46"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq19.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq20"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}^{RE}_{e_j,e_k} \in {\hat{Y}}^{RE}$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq20.gif"/></alternatives></inline-formula>) of two random paired entities (<inline-formula id="IEq21"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq21.gif"/></alternatives></inline-formula> and <inline-formula id="IEq22"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_k$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq22.gif"/></alternatives></inline-formula>) is given by<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\hat{y}}^{RE}_{e_j,e_k}=T^{RE} \left( v^{RE}_{e_j,e_k}\right) . \end{aligned}$$\end{document}</tex-math><mml:math id="M54" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq23"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v^{RE}_{e_j,e_k}$$\end{document}</tex-math><mml:math id="M56"><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq23.gif"/></alternatives></inline-formula> denotes the joint vector representation of RE hidden states, co-responding to <inline-formula id="IEq24"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq24.gif"/></alternatives></inline-formula> and <inline-formula id="IEq25"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_k$$\end{document}</tex-math><mml:math id="M60"><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq25.gif"/></alternatives></inline-formula>. We will show the details of <inline-formula id="IEq26"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v^{RE}_{e_j,e_k}$$\end{document}</tex-math><mml:math id="M62"><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq26.gif"/></alternatives></inline-formula> later (the proposed <inline-formula id="IEq27"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v^{RE}_{e_j,e_k}$$\end{document}</tex-math><mml:math id="M64"><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq27.gif"/></alternatives></inline-formula> is given by Eq. (<xref rid="Equ11" ref-type="">11</xref>) in Sect. <xref rid="Sec6" ref-type="sec">3.3</xref>).<fig id="Fig2"><label>Fig. 2</label><caption><p>The framework and component variations for jointly learning NER and RE. <bold>a</bold> The overall framework. <bold>b</bold> Single-head classifier. <bold>c</bold> Multi-head classifier. <bold>d</bold> Hard-parameter sharing encoder. <bold>e</bold> Soft-parameter sharing encoder. <bold>f</bold> no-parameter sharing encoder. <bold>g</bold> Continual learning multi-datasets. <bold>h</bold> Multi-corpora learning. <bold>i</bold> Continual multi-corpora learning. Figure indices with <inline-formula id="IEq28"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bigstar$$\end{document}</tex-math><mml:math id="M66"><mml:mi>★</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq28.gif"/></alternatives></inline-formula> (<bold>c</bold>, <bold>f</bold>, <bold>i</bold>) denote the proposed methods in JCBIE. The same components have the same color. SP denotes entity span; ET denotes entity type; CLS denotes classifier; ADE, DDI, and CPR denote different datasets, containing different entity types and relation types</p></caption><graphic xlink:href="12859_2022_5096_Fig2_HTML" id="MO7"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>Parameter sharing in encoding</title>
      <p id="Par28">Previous studies claimed that information extraction models can benefit from a sharing encoder, because common parameters can enhance interactions between NER and RE [<xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR30">30</xref>]. These methods can be categorized as hard parameter sharing and soft parameter sharing. Besides, we propose a no parameter sharing method.</p>
      <p id="Par29"><italic>Hard parameter sharing</italic> As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>d, NER and RE use a sharing encoder. The encoder learns the hidden states (parameters) for both NER and RE tasks across layers.</p>
      <p id="Par30"><italic>Soft parameter sharing</italic> As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>e, NER and RE have their private encoders, while the parameters of the last layer (<italic>L</italic>) of the NER encoder are shared for the learning of RE encoder layers. We employ a cross-attention mechanism [<xref ref-type="bibr" rid="CR41">41</xref>] to constrain the parameter sharing. The post-fusion hidden states (<inline-formula id="IEq29"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {H}}$$\end{document}</tex-math><mml:math id="M68"><mml:mi mathvariant="script">H</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq29.gif"/></alternatives></inline-formula>) of layer <italic>l</italic> in the RE encoder are given by<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {H}}^{RE}_{l} = Softmax\left( \frac{H^{RE}_{l} \cdot {H^{NER}_{L}}^{\mathrm{T}} }{\sqrt{d}} \right) H^{NER}_{L} \cdot H^{RE}_{l}. \end{aligned}$$\end{document}</tex-math><mml:math id="M70" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">H</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msup><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mfrac></mml:mfenced><mml:msubsup><mml:mi>H</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq30"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H^{NER} \in {\mathbb {R}}^{n \times d}$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mi mathvariant="italic">NER</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq30.gif"/></alternatives></inline-formula> and <inline-formula id="IEq31"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H^{RE} \in {\mathbb {R}}^{n \times d}$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq31.gif"/></alternatives></inline-formula> are representations of a <italic>sent</italic>, which come from their private encoders.</p>
      <p id="Par31"><inline-formula id="IEq32"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\bigstar }$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:mi mathvariant="bold-italic">★</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq32.gif"/></alternatives></inline-formula><italic>No parameter sharing</italic> As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>f, it employs two separated encoders for NER and RE. There is no interaction between NER and RE, which is the proposed encoding method in JCBIE.</p>
    </sec>
    <sec id="Sec6">
      <title>RE hidden state augmentation</title>
      <p id="Par32">We develop four augmentation methods, fusing the output hidden states (<inline-formula id="IEq33"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v^{RE}_{e_j,e_k}$$\end{document}</tex-math><mml:math id="M78"><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq33.gif"/></alternatives></inline-formula>, mentioned in Eq. (<xref rid="Equ5" ref-type="">5</xref>)) of RE encoders with NER features to enhance the learning of RE.</p>
      <p id="Par33"><italic>Vanilla augmentation</italic> A vanilla RE hidden state augmentation method is to concatenate ([; ]) the sum of NER and RE hidden states, corresponding to the same entity mentions, e.g., <inline-formula id="IEq34"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M80"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq34.gif"/></alternatives></inline-formula> and <inline-formula id="IEq35"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_k$$\end{document}</tex-math><mml:math id="M82"><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq35.gif"/></alternatives></inline-formula>.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} v^{RE}_{e_j,e_k} = \left[ \sum _{i=\xi _j}^{\epsilon _j}{h_{i}^{RE}};\sum _{i'=\xi _k}^{\epsilon _k}{h_{i'}^{RE}}\right] , \end{aligned}$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq36"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v^{RE}_{e_j,e_k} \in {\mathbb {R}}^{1 \times 2d}$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq36.gif"/></alternatives></inline-formula>, <inline-formula id="IEq37"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi _j$$\end{document}</tex-math><mml:math id="M88"><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq37.gif"/></alternatives></inline-formula> and <inline-formula id="IEq38"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon _j$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq38.gif"/></alternatives></inline-formula> denote the start and the end indices of <inline-formula id="IEq39"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M92"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq39.gif"/></alternatives></inline-formula>, respectively; <inline-formula id="IEq40"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi _k$$\end{document}</tex-math><mml:math id="M94"><mml:msub><mml:mi>ξ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq40.gif"/></alternatives></inline-formula> and <inline-formula id="IEq41"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon _k$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq41.gif"/></alternatives></inline-formula> denote the start and the end indices of <inline-formula id="IEq42"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_k$$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq42.gif"/></alternatives></inline-formula>.</p>
      <p id="Par34"><italic>Additional entity type embedding augmentation</italic> We employ an linear embedding layer (<inline-formula id="IEq43"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Linear(\cdot )$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq43.gif"/></alternatives></inline-formula>) to learn the embedding representations (<italic>emb</italic>) of entity types as the additional RE hidden state augmentation, where <inline-formula id="IEq44"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${emb}_{e_j} =Linear(y^{ET}_{e_j})$$\end{document}</tex-math><mml:math id="M102"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">emb</mml:mi></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq44.gif"/></alternatives></inline-formula>; <inline-formula id="IEq45"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${emb}_{e_k} =Linear(y^{ET}_{e_k})$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">emb</mml:mi></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq45.gif"/></alternatives></inline-formula>. In the RE training process, we use the true label (<inline-formula id="IEq46"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}_{e_j}$$\end{document}</tex-math><mml:math id="M106"><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq46.gif"/></alternatives></inline-formula>) of an entity type that corresponds to the entity span <inline-formula id="IEq47"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M108"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq47.gif"/></alternatives></inline-formula>. In the RE inferring process, we use the predicted entity type label (<inline-formula id="IEq48"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}^{ET}_{e_j}$$\end{document}</tex-math><mml:math id="M110"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq48.gif"/></alternatives></inline-formula>). Then, the augmented RE hidden states are given by the concatenation of entity type embeddings and the vanilla hidden state augmentation<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} v^{RE}_{e_j,e_k} = \left[ \sum _{i=\xi _j}^{\epsilon _j}{h_{i}^{RE}};{emb}_{e_j};\sum _{i'=\xi _k}^{\epsilon _k}{h_{i'}^{RE}};{emb}_{e_k}\right] , \end{aligned}$$\end{document}</tex-math><mml:math id="M112" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">emb</mml:mi></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub><mml:mo>;</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">emb</mml:mi></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq49"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${emb}_{e} \in {\mathbb {R}}^{1 \times 50}$$\end{document}</tex-math><mml:math id="M114"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">emb</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq49.gif"/></alternatives></inline-formula> and <inline-formula id="IEq50"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v^{RE}_{e_j,e_k} \in {\mathbb {R}}^{1 \times (2*d+2*50)}$$\end{document}</tex-math><mml:math id="M116"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mrow/><mml:mo>∗</mml:mo><mml:mn>50</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq50.gif"/></alternatives></inline-formula>.</p>
      <p id="Par35"><italic>Additional entity type prototype augmentation</italic> An entity-type prototype representation is given by the original Bio-BERT encoder (<inline-formula id="IEq51"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$BioBERT(\cdot )$$\end{document}</tex-math><mml:math id="M118"><mml:mrow><mml:mi>B</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq51.gif"/></alternatives></inline-formula>) output before training. We first collect all entity mentions from the training set, and categorize the entity mentions according to their entity types. The set of entity mentions (<inline-formula id="IEq52"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {S}}$$\end{document}</tex-math><mml:math id="M120"><mml:mi mathvariant="script">S</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq52.gif"/></alternatives></inline-formula>) with a specific entity type (<inline-formula id="IEq53"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}$$\end{document}</tex-math><mml:math id="M122"><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq53.gif"/></alternatives></inline-formula>) is defined as <inline-formula id="IEq54"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {S}}^{y^{ET}} = [X^{y^{ET}}_{1}, X^{y^{ET}}_{2},...,X^{y^{ET}}_{t}]$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">S</mml:mi></mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mn>1</mml:mn><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mn>2</mml:mn><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:msubsup><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq54.gif"/></alternatives></inline-formula>, where <italic>X</italic> is a token of the entity mentions. Totally, <italic>t</italic> tokens in <inline-formula id="IEq55"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {S}}$$\end{document}</tex-math><mml:math id="M126"><mml:mi mathvariant="script">S</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq55.gif"/></alternatives></inline-formula>. Then, the prototype representation (<italic>proto</italic>) of an entity type (<inline-formula id="IEq56"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}$$\end{document}</tex-math><mml:math id="M128"><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq56.gif"/></alternatives></inline-formula>) is given by<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} proto^{y^{ET}}=\frac{1}{t}\sum _{q=1}^{t} Maxpooling(BioBERT(X_{q})), \end{aligned}$$\end{document}</tex-math><mml:math id="M130" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mi>o</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>t</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mi>T</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq57"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$proto^{y^{ET}} \in {\mathbb {R}}^{1 \times 50}$$\end{document}</tex-math><mml:math id="M132"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mi>o</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq57.gif"/></alternatives></inline-formula>. In the RE training process, we look up to the prototype representations (<inline-formula id="IEq58"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$proto^{y^{ET}_{e_j}}$$\end{document}</tex-math><mml:math id="M134"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mi>o</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq58.gif"/></alternatives></inline-formula> and <inline-formula id="IEq59"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$proto^{y^{ET}_{e_k}}$$\end{document}</tex-math><mml:math id="M136"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mi>o</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq59.gif"/></alternatives></inline-formula>) of a pair of entity mentions (<inline-formula id="IEq60"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M138"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq60.gif"/></alternatives></inline-formula> and <inline-formula id="IEq61"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_k$$\end{document}</tex-math><mml:math id="M140"><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq61.gif"/></alternatives></inline-formula>), based on their true entity type labels (<inline-formula id="IEq62"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}_{e_j}$$\end{document}</tex-math><mml:math id="M142"><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq62.gif"/></alternatives></inline-formula> and <inline-formula id="IEq63"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}_{e_k}$$\end{document}</tex-math><mml:math id="M144"><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq63.gif"/></alternatives></inline-formula>). The augmented RE hidden states are given by<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} v^{RE}_{e_j,e_k} = \left[ \sum _{i=\xi _j}^{\epsilon _j}{h_{i}^{RE}};proto^{y^{ET}_{e_j}};\sum _{i'=\xi _k}^{\epsilon _k}{h_{i'}^{RE}};proto^{y^{ET}_{e_k}}\right] . \end{aligned}$$\end{document}</tex-math><mml:math id="M146" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mi>o</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:msup><mml:mo>;</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mi>o</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:msup></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>In the RE inferring process, we use the predicted entity type labels (<inline-formula id="IEq64"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}^{ET}_{e_j}$$\end{document}</tex-math><mml:math id="M148"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq64.gif"/></alternatives></inline-formula> and <inline-formula id="IEq65"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{y}}^{ET}_{e_k}$$\end{document}</tex-math><mml:math id="M150"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq65.gif"/></alternatives></inline-formula>) to obtain prototype representations of <inline-formula id="IEq66"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M152"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq66.gif"/></alternatives></inline-formula> and <inline-formula id="IEq67"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_k$$\end{document}</tex-math><mml:math id="M154"><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq67.gif"/></alternatives></inline-formula>, instead of gold labels (<inline-formula id="IEq68"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}_{e_j}$$\end{document}</tex-math><mml:math id="M156"><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq68.gif"/></alternatives></inline-formula> and <inline-formula id="IEq69"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}_{e_k}$$\end{document}</tex-math><mml:math id="M158"><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq69.gif"/></alternatives></inline-formula>).</p>
      <p id="Par36"><inline-formula id="IEq70"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\bigstar }$$\end{document}</tex-math><mml:math id="M160"><mml:mrow><mml:mi mathvariant="bold-italic">★</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq70.gif"/></alternatives></inline-formula><italic>Entity marker augmentation</italic> Inspired by a recent mask language model [<xref ref-type="bibr" rid="CR42">42</xref>] and the work of [<xref ref-type="bibr" rid="CR43">43</xref>], we augment the raw input sentence with extra special tokens (entity markers) to highlight the positions of entities and the entity types. For each entity mention (<inline-formula id="IEq71"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M162"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq71.gif"/></alternatives></inline-formula>) in type <inline-formula id="IEq72"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y^{ET}_{e_j}$$\end{document}</tex-math><mml:math id="M164"><mml:msubsup><mml:mi>y</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq72.gif"/></alternatives></inline-formula>, a start marker <inline-formula id="IEq73"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[y^{ET}_{e_j\_start}]$$\end{document}</tex-math><mml:math id="M166"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>_</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq73.gif"/></alternatives></inline-formula> and an end marker <inline-formula id="IEq74"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[y^{ET}_{e_j\_end}]$$\end{document}</tex-math><mml:math id="M168"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>_</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq74.gif"/></alternatives></inline-formula> are introduced into the raw sentence before and after the mention <inline-formula id="IEq75"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M170"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq75.gif"/></alternatives></inline-formula>. The example of an augmented sentence is “<inline-formula id="IEq76"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[Drug_{\_start}]$$\end{document}</tex-math><mml:math id="M172"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>_</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq76.gif"/></alternatives></inline-formula> Pravastatin <inline-formula id="IEq77"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[Drug_{\_end}]$$\end{document}</tex-math><mml:math id="M174"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>_</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq77.gif"/></alternatives></inline-formula> is associated with <inline-formula id="IEq78"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[Disease_{\_start}]$$\end{document}</tex-math><mml:math id="M176"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>_</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq78.gif"/></alternatives></inline-formula> myotonia <inline-formula id="IEq79"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[Disease_{\_end}]$$\end{document}</tex-math><mml:math id="M178"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>_</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq79.gif"/></alternatives></inline-formula> in animals”. We concatenate the RE encoder output hidden states of start markers of two entity mentions (<inline-formula id="IEq80"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_j$$\end{document}</tex-math><mml:math id="M180"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq80.gif"/></alternatives></inline-formula> and <inline-formula id="IEq81"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_k$$\end{document}</tex-math><mml:math id="M182"><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq81.gif"/></alternatives></inline-formula>) as the RE hidden state augmentation<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} v^{RE}_{e_j,e_k}= \left[ h_{e_j marker}^{RE};h_{e_k marker}^{RE}\right] , \end{aligned}$$\end{document}</tex-math><mml:math id="M184" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq82"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v^{RE}_{e_j,e_k} \in {\mathbb {R}}^{1 \times 2d}$$\end{document}</tex-math><mml:math id="M186"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq82.gif"/></alternatives></inline-formula>. In the training process, NER encoder that is used for SP and ET learning takes an original raw sentence as input. The RE encoder takes the sequence with markers as input, where the entity spans and types are obtained, based on their true labels. In the inferring process, we predict entity spans (SP) and types (ET) with a raw sentence first, then insert the markers according to the SP and ET predictions for RE predictions.</p>
    </sec>
    <sec id="Sec7">
      <title>Single-head and multi-head classifiers</title>
      <p id="Par37"><italic>Single-head classifier</italic> As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>b (the ET and RE classifiers are in grey and pink, respectively), single-head classifiers have two separated classifiers to predict multiple classes for ET and RE, respectively. In ET classification, e.g., a single-head classifier projects the prediction space into the vocabulary size (M classes) of all ET in a dataset. Then, the loss (<inline-formula id="IEq83"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {L}}^{total}_{s}$$\end{document}</tex-math><mml:math id="M188"><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">total</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq83.gif"/></alternatives></inline-formula>) of a sing-head (<italic>s</italic>) based model is the weighted sum of the cross-entropy losses of SP, ET, and RE<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {L}}^{total}_{s} = \alpha ^{SP}{\mathcal {L}}^{SP}_{s} + \alpha ^{ET}{\mathcal {L}}^{ET}_{s} + \alpha ^{RE}{\mathcal {L}}^{RE}_{s}, \end{aligned}$$\end{document}</tex-math><mml:math id="M190" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">total</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq84"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha ^{SP}$$\end{document}</tex-math><mml:math id="M192"><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq84.gif"/></alternatives></inline-formula>,<inline-formula id="IEq85"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha ^{ET}$$\end{document}</tex-math><mml:math id="M194"><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq85.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq86"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha ^{RE}$$\end{document}</tex-math><mml:math id="M196"><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq86.gif"/></alternatives></inline-formula> are hyperparameters. The limit of using single-head classifier is that the vocabulary of predicted labels cannot be expand after training.</p>
      <p id="Par38"><inline-formula id="IEq87"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\bigstar }$$\end{document}</tex-math><mml:math id="M198"><mml:mrow><mml:mi mathvariant="bold-italic">★</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq87.gif"/></alternatives></inline-formula><italic>Multi-head classifier</italic> Inspired by prompt learning that uses multiple prompts to infer labels for different tasks [<xref ref-type="bibr" rid="CR44">44</xref>], JCBIE employs multi-head classifiers for ET and RE to fit the context of continual learning that entity types (ET) and relations (RE) can be expanded over time. The SP of JCBIE still uses a single-head classifier, because the vocabulary of SP labels is defined by the BIOES tagging scheme, regardless of dataset domains. As seen in Fig. <xref rid="Fig2" ref-type="fig">2</xref>c, ET and RE have <italic>M</italic> and <italic>N</italic> binary classifiers, learning <italic>M</italic> entity types and <italic>N</italic> relations, respectively. In ET classification, e.g., each binary classifier classifies whether an entity mention belongs to a specific type. Thus, JCBIE can expand the vocabulary of predicted labels over time by learning new datasets with new binary classifiers. The loss (<inline-formula id="IEq88"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {L}}^{total}_{m}$$\end{document}</tex-math><mml:math id="M200"><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>m</mml:mi><mml:mrow><mml:mi mathvariant="italic">total</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq88.gif"/></alternatives></inline-formula>) of a multi-head classifier (<italic>m</italic>) based model is given by<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {L}}^{total}_{m} = \alpha ^{SP}{\mathcal {L}}^{SP}_{s} + \alpha ^{ET}\sum _{\iota =1}^{M}{\mathcal {L}}^{ET}_{m,\iota } + \alpha ^{RE}\sum _{\kappa =1}^{N}{\mathcal {L}}^{RE}_{m,\kappa }, \end{aligned}$$\end{document}</tex-math><mml:math id="M202" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>m</mml:mi><mml:mrow><mml:mi mathvariant="italic">total</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ι</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>ι</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2022_5096_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>where the binary classifiers employ cross-entropy losses. If there are more than two binary classifiers that predict positive, JCBIE will take the result from the most confident classifier as the final prediction.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Statistics of the employed datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Corpus</th><th align="left" rowspan="2">Sent. count</th><th align="left" colspan="3">Entity mention counts</th><th align="left" colspan="3">Relations counts</th></tr><tr><th align="left">Ch./Dr.</th><th align="left">Ph./Di.</th><th align="left">Pr./Ge.</th><th align="left">ADE</th><th align="left">DDI</th><th align="left">CPR</th></tr></thead><tbody><tr><td align="left" colspan="2">Training set</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"><inline-formula id="IEq89"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{1}$$\end{document}</tex-math><mml:math id="M204"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq89.gif"/></alternatives></inline-formula></td><td align="left">800</td><td align="left">969</td><td align="left">1144</td><td align="left">–</td><td align="left">1171</td><td align="left">–</td><td align="left">–</td></tr><tr><td align="left"><inline-formula id="IEq90"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{2}$$\end{document}</tex-math><mml:math id="M206"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq90.gif"/></alternatives></inline-formula></td><td align="left">3418</td><td align="left">4063</td><td align="left">4585</td><td align="left">–</td><td align="left">5422</td><td align="left">–</td><td align="left">–</td></tr><tr><td align="left">DDI</td><td align="left">5002</td><td align="left">13,276</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">3607</td><td align="left">–</td></tr><tr><td align="left">CPR</td><td align="left">8471</td><td align="left">11,369</td><td align="left">–</td><td align="left">12,572</td><td align="left">–</td><td align="left">–</td><td align="left">6044</td></tr><tr><td align="left">Total</td><td align="left">17,691</td><td align="left">29,677</td><td align="left">5729</td><td align="left">12,572</td><td align="left">6593</td><td align="left">3607</td><td align="left">6044</td></tr><tr><td align="left" colspan="2">Validation set</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"><inline-formula id="IEq91"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{1}$$\end{document}</tex-math><mml:math id="M208"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq91.gif"/></alternatives></inline-formula></td><td align="left">100</td><td align="left">124</td><td align="left">129</td><td align="left">–</td><td align="left">140</td><td align="left">–</td><td align="left">–</td></tr><tr><td align="left"><inline-formula id="IEq92"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{2}$$\end{document}</tex-math><mml:math id="M210"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq92.gif"/></alternatives></inline-formula></td><td align="left">427</td><td align="left">493</td><td align="left">592</td><td align="left">–</td><td align="left">667</td><td align="left">–</td><td align="left">–</td></tr><tr><td align="left">DDI</td><td align="left">557</td><td align="left">1487</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">413</td><td align="left">–</td></tr><tr><td align="left">CPR</td><td align="left">1022</td><td align="left">1490</td><td align="left">–</td><td align="left">1385</td><td align="left">–</td><td align="left">–</td><td align="left">694</td></tr><tr><td align="left">Total</td><td align="left">2106</td><td align="left">3594</td><td align="left">721</td><td align="left">1385</td><td align="left">807</td><td align="left">413</td><td align="left">694</td></tr><tr><td align="left" colspan="2">Testing set</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"><inline-formula id="IEq93"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{1}$$\end{document}</tex-math><mml:math id="M212"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq93.gif"/></alternatives></inline-formula></td><td align="left">100</td><td align="left">115</td><td align="left">144</td><td align="left">–</td><td align="left">142</td><td align="left">–</td><td align="left">–</td></tr><tr><td align="left"><inline-formula id="IEq94"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{2}$$\end{document}</tex-math><mml:math id="M214"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq94.gif"/></alternatives></inline-formula></td><td align="left">427</td><td align="left">506</td><td align="left">597</td><td align="left">–</td><td align="left">732</td><td align="left">–</td><td align="left">–</td></tr><tr><td align="left">DDI</td><td align="left">543</td><td align="left">1480</td><td align="left">–</td><td align="left">–</td><td align="left">–</td><td align="left">475</td><td align="left">–</td></tr><tr><td align="left">CPR</td><td align="left">1117</td><td align="left">1715</td><td align="left">–</td><td align="left">1520</td><td align="left">–</td><td align="left">–</td><td align="left">1016</td></tr><tr><td align="left">Total</td><td align="left">2187</td><td align="left">3816</td><td align="left">741</td><td align="left">1520</td><td align="left">874</td><td align="left">475</td><td align="left">1016</td></tr><tr><td align="left" colspan="3">Corpus-adaption evaluation</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"><inline-formula id="IEq95"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{3}$$\end{document}</tex-math><mml:math id="M216"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq95.gif"/></alternatives></inline-formula></td><td align="left">4638</td><td align="left">9517</td><td align="left">2334</td><td align="left">–</td><td align="left">4767</td><td align="left">–</td><td align="left">–</td></tr></tbody></table><table-wrap-foot><p>Ch./Dr., chemicals or drug; Ph./Di., phenotype or disease; Pr./Ge., protein or gene</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec8">
      <title>Continual multi-corpora learning paradigm</title>
      <p id="Par39"><italic>Continual learning</italic> In order to extract different knowledge from different corpora to develop large-scale BKGs, continual learning was commonly used by recent works [<xref ref-type="bibr" rid="CR45">45</xref>, <xref ref-type="bibr" rid="CR46">46</xref>]. The corpora are organized as a pipeline style for model learning sequentially (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>g). When learning a new corpus, the parameters of a continual learning model are initialized as the parameters that were given by the learning of the last corpus. Thus, the initialized model is supposed to have remembered previous knowledge. However, [<xref ref-type="bibr" rid="CR47">47</xref>] argued that such a continual learning method may result in the catastrophic forgetting of previously learnt knowledge. We will verify this in the later experiments.</p>
      <p id="Par40"><italic>Multi-corpora learning</italic> The ideal situation for training a model is to prepare an annotated corpus that contains all domain information. The model can learn the real world distribution of data from the omnipotent corpus. However, such a condition does not exist. We hypothesize that the collection of our prepared datasets is omnipotent in reflecting the real world data distribution; We do not need additional data to process ADE, DDI, and CPR datasets in the future (Hypothesis 1). A model trained with the combination of shuffled datasets (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>h) shows the upper bond of learning performance, based on Hypothesis 1. We will demonstrate this later in empirical studies (Sect. <xref rid="Sec18" ref-type="sec">5.4</xref>). We will also show the result when Hypothesis 1 does not hold.</p>
      <p id="Par41"><inline-formula id="IEq96"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\bigstar }$$\end{document}</tex-math><mml:math id="M218"><mml:mrow><mml:mi mathvariant="bold-italic">★</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq96.gif"/></alternatives></inline-formula><italic>Continual multi-corpora learning</italic> Actually, datasets are continually expending in a research domain. For example, ADE<inline-formula id="IEq97"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_1$$\end{document}</tex-math><mml:math id="M220"><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq97.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR48">48</xref>], DDI [<xref ref-type="bibr" rid="CR49">49</xref>], ADE<inline-formula id="IEq98"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_2$$\end{document}</tex-math><mml:math id="M222"><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq98.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR50">50</xref>], CPR [<xref ref-type="bibr" rid="CR13">13</xref>], and ADE<inline-formula id="IEq99"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_3$$\end{document}</tex-math><mml:math id="M224"><mml:msub><mml:mrow/><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq99.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR12">12</xref>] were developed in 2012, 2013, 2017, 2017, and 2019, respectively.</p>
      <p id="Par42">We mean to use a continual multi-corpora learning paradigm to mitigate the bias of a model continually learning data distribution, improving the corpus-adaption capacity of the model (see Sect. <xref rid="Sec18" ref-type="sec">5.4</xref> later). As seen in Fig. <xref rid="Fig2" ref-type="fig">2</xref>i, we use the portion of an early dataset, e.g., ADE (here, <inline-formula id="IEq100"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_1$$\end{document}</tex-math><mml:math id="M226"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq100.gif"/></alternatives></inline-formula> and <inline-formula id="IEq101"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_2$$\end{document}</tex-math><mml:math id="M228"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq101.gif"/></alternatives></inline-formula> are combined, termed ADE) subset 1 (<inline-formula id="IEq102"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{\mathrm{sub1}}$$\end{document}</tex-math><mml:math id="M230"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq102.gif"/></alternatives></inline-formula>) to train the model at Step 1. Then, the combination of <inline-formula id="IEq103"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{\mathrm{sub2}}$$\end{document}</tex-math><mml:math id="M232"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq103.gif"/></alternatives></inline-formula> and <inline-formula id="IEq104"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {DDI}}_{\mathrm{sub1}}$$\end{document}</tex-math><mml:math id="M234"><mml:msub><mml:mtext>DDI</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq104.gif"/></alternatives></inline-formula> is used to continually train the model in Step 2. Finally, the rest of ADE and DDI data (<inline-formula id="IEq105"><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{\mathrm{sub3}}$$\end{document}</tex-math><mml:math id="M236"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq105.gif"/></alternatives></inline-formula> and <inline-formula id="IEq106"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {DDI}}_{\mathrm{sub2}}$$\end{document}</tex-math><mml:math id="M238"><mml:msub><mml:mtext>DDI</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq106.gif"/></alternatives></inline-formula>) combines CPR data to continually train the model at Step 3. In our experiments, ADE is divided into three equal parts (<inline-formula id="IEq107"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{\mathrm{sub1}}$$\end{document}</tex-math><mml:math id="M240"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq107.gif"/></alternatives></inline-formula>, <inline-formula id="IEq108"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{\mathrm{sub2}}$$\end{document}</tex-math><mml:math id="M242"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq108.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq109"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{\mathrm{sub3}}$$\end{document}</tex-math><mml:math id="M244"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq109.gif"/></alternatives></inline-formula>). DDI dataset is divided into two equal parts (<inline-formula id="IEq110"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {DDI}}_{\mathrm{sub1}}$$\end{document}</tex-math><mml:math id="M246"><mml:msub><mml:mtext>DDI</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq110.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq111"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {DDI}}_{\mathrm{sub2}}$$\end{document}</tex-math><mml:math id="M248"><mml:msub><mml:mtext>DDI</mml:mtext><mml:mrow><mml:mi mathvariant="normal">sub</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq111.gif"/></alternatives></inline-formula>).</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Experiment</title>
    <sec id="Sec10">
      <title>Datasets</title>
      <p id="Par43">Chemical/drug, protein/gene, and phenotype/disease are three fundamental entity type classes to form complicated BKGs. We choose four biomedical corpus, including <inline-formula id="IEq112"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_1$$\end{document}</tex-math><mml:math id="M250"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq112.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR48">48</xref>], <inline-formula id="IEq113"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_2$$\end{document}</tex-math><mml:math id="M252"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq113.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR50">50</xref>], DDI [<xref ref-type="bibr" rid="CR49">49</xref>], and CPR [<xref ref-type="bibr" rid="CR13">13</xref>] for normal training and testing, and using <inline-formula id="IEq114"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_3$$\end{document}</tex-math><mml:math id="M254"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq114.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR12">12</xref>] for corpus-adaptation evaluation. These corpora contain compatible definitions for the above entity types and relations. Table <xref rid="Tab2" ref-type="table">2</xref> shows the statistics of each dataset.</p>
      <p id="Par44">For a better compatibility, we normalize the entity types and relations in different corpora. E.g., entity type “Drug” in the DDI corpus is described as “any chemical agent used in the treatment, cure, prevention, or diagnosis of a disease that has been approved for human use”. Another type is “Drug_n” which is defined as “any chemical agent that affects living organisms”. However, these two entity types are not differentiated in the CPR corpus. Thus, we normalized “Drug_n” as “Drug”. For relation normalization, the original DDI corpus varies four fine-grained DDI relations. We normalize them as the same one. Finally, the employed entity type labels are chemical/drug, protein/gene, and phenotype/disease. Three relation labels are ADE, DDI, and CPR.</p>
    </sec>
    <sec id="Sec11">
      <title>Evaluation and measure</title>
      <p id="Par45">The reported testing results are given by the model and the training epoch, which yields the best performance on the associated validation sets. All results are reported by a five-time running averaged micro-F1 measure, where RE results are the main measure. SP is regarded as a sequence-labeling task, in which all tokens are labeled for calculating micro-F1 (see Table <xref rid="Tab1" ref-type="table">1</xref>). The performance of ET depends on the predictions of SP. Recognized entities from ET are counted as true-positive (TP), if both its boundary (from SP) and type are correct. If a gold entity is missing, it will be counted as a false-negative (FN) instance. If an entity with wrong boundary or type, it is counted as one false-positive (FP) instance. RE task depends on the SP and ET results, because the errors of SP and ET are propagated to the RE model. Only if two entities and related relation types are the exact same as gold labels is counted as TP in RE. Missing triples are counted as FN instances. If RE predicts a relation label that is not the same as the gold label, it is FP. When it comes to multi-corpus learning, we regard all data as one corpus for the measure of micro F1.</p>
      <p id="Par46">Additionally, we introduce a corpus-adaptation evolution task, which evaluates the generalization of a model in the continual learning context. <inline-formula id="IEq115"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_3$$\end{document}</tex-math><mml:math id="M256"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq115.gif"/></alternatives></inline-formula> is used to evaluate JCBIE after training on <inline-formula id="IEq116"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{1}$$\end{document}</tex-math><mml:math id="M258"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq116.gif"/></alternatives></inline-formula>, <inline-formula id="IEq117"><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{2}$$\end{document}</tex-math><mml:math id="M260"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq117.gif"/></alternatives></inline-formula>, DDI and CPR. Noticeably, There are deviations in the annotation guidelines of these corpora. Their data sources are also different. Although a model has been well-trained by the corpora <inline-formula id="IEq118"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{1}$$\end{document}</tex-math><mml:math id="M262"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq118.gif"/></alternatives></inline-formula> and <inline-formula id="IEq119"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{2}$$\end{document}</tex-math><mml:math id="M264"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq119.gif"/></alternatives></inline-formula>, e.g., its performance may drop in <inline-formula id="IEq120"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{3}$$\end{document}</tex-math><mml:math id="M266"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq120.gif"/></alternatives></inline-formula>. This evaluation aims at simulating real application scenarios. When a neural network tries to learn similar concepts with no exact definition (the problem also may be introduced by the different understanding from different annotators), how does the model perform with such huge noised data. The following results demonstrate that JCBIE can effectively alleviate the problem.</p>
    </sec>
    <sec id="Sec12">
      <title>Baseline</title>
      <p id="Par47">(1) <italic>ExtendNER</italic> [<xref ref-type="bibr" rid="CR36">36</xref>] is a knowledge distillation-based framework, which transfers old knowledge from a teacher encoder into a new student encoder with an extended linear classifier. When ExtendNER needs to recognize new entity types, the parameters of teacher encoder layers are copied to initialize the new student encoder, and the linear classifier built on the top of the student encoder is expanded with the additional dimensions for the new entity types.</p>
      <p id="Par48">(2) <italic>L &amp;R</italic> [<xref ref-type="bibr" rid="CR37">37</xref>] is a two-stage framework, which consists of a learning stage and a reviewing stage. At the learning stage, L&amp;R follows ExtendNER to distill old knowledge from a teacher model into a student model. At the reviewing stage, L&amp;R generates synthetic samples with old entity types for jointly training, aiming to alleviate the inter-type confusion [<xref ref-type="bibr" rid="CR51">51</xref>].</p>
      <p id="Par49">The original ExtendNER and L&amp;R were designed only for NER, and we re-implement the methods for joint SP, ET, and RE tasks. When only <inline-formula id="IEq121"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ADE_1$$\end{document}</tex-math><mml:math id="M268"><mml:mrow><mml:mi>A</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq121.gif"/></alternatives></inline-formula> is employed, ExtendNER, L&amp;R, and Typical Joint Extraction are equal, because they do not start to distill at the first step. For L&amp;R, it should notice that we randomly sample 20 instances rather than generating synthesized data in the reviewing stage. The reason is the reviewing stage of L&amp;R was designed for only one NER task, and it is hard to ensure generate appropriate instances for joint SP, ET, and RE tasks.</p>
      <p id="Par50">(3) <italic>Typical joint extraction</italic> The above two studies are knowledge distill-based methods. Considering JCBIE are data replay-based method, we design another replay-based method named Typical Joint Extraction for more comprehensive comparison. According to the most recent works [<xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR23">23</xref>], a common practice about jointly extracting entity spans, entity types and the relations between two entities is based on a hard-parameter sharing encoder (Fig. <xref rid="Fig2" ref-type="fig">2</xref>d) and a single-head classifier (Fig. <xref rid="Fig2" ref-type="fig">2</xref>b). We compare our proposed no-parameter sharing (Fig. <xref rid="Fig2" ref-type="fig">2</xref>f) and multi-head classifier (Fig. <xref rid="Fig2" ref-type="fig">2</xref>c) with this baseline method. For a fair comparison, other variables e.g., pre-trained language models (Bio-BERT), multi-corpora learning learning paradigms (Fig. <xref rid="Fig2" ref-type="fig">2</xref>h), and datasets are controlled.</p>
    </sec>
    <sec id="Sec13">
      <title>Hyper-parameter setups</title>
      <p id="Par51">For all experiments, batch size is 8. Learning rate is 5e−4 for AdamW optimizer [<xref ref-type="bibr" rid="CR52">52</xref>]. <inline-formula id="IEq122"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha _{SP},\alpha _{ET},\alpha _{RE}$$\end{document}</tex-math><mml:math id="M270"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">SP</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">ET</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi mathvariant="italic">RE</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq122.gif"/></alternatives></inline-formula> in Eqs. (<xref rid="Equ12" ref-type="">12</xref>) and (<xref rid="Equ13" ref-type="">13</xref>) are 0.4, 0.25, and 0.35, respectively. The dimension of <italic>emb</italic> is 50 in Eq. (<xref rid="Equ8" ref-type="">8</xref>). The max pooling size of <italic>proto</italic> is also set to 50 in Eq. (<xref rid="Equ10" ref-type="">10</xref>). We employ Bio-BERT-base.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Comparison between typical joint extraction and JCBIE, based on a multi-corpora learning paradigm</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method\Dataset</th><th align="left"/><th align="left"><inline-formula id="IEq126"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm {ADE_1}$$\end{document}</tex-math><mml:math id="M272"><mml:msub><mml:mi mathvariant="normal">ADE</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq126.gif"/></alternatives></inline-formula></th><th align="left">ADE</th><th align="left">DDI + ADE</th><th align="left">ADE + DDI + CPR</th><th align="left">Avg.</th></tr></thead><tbody><tr><td align="left" rowspan="3">ExtendNER</td><td align="left">SP</td><td align="left">82.56</td><td align="left">86.64</td><td align="left">88.24</td><td align="left">86.35</td><td align="left">85.95</td></tr><tr><td align="left">ET</td><td align="left">84.79</td><td align="left">87.99</td><td align="left">89.85</td><td align="left">84.45</td><td align="left">86.77</td></tr><tr><td align="left">RE</td><td align="left">68.70</td><td align="left">76.94</td><td align="left">77.50</td><td align="left">68.20</td><td align="left">72.84</td></tr><tr><td align="left" rowspan="3">L &amp;R</td><td align="left">SP</td><td align="left">82.56</td><td align="left">89.07</td><td align="left">90.04</td><td align="left">90.58</td><td align="left">88.06</td></tr><tr><td align="left">ET</td><td align="left">84.79</td><td align="left">90.02</td><td align="left">93.25</td><td align="left">89.64</td><td align="left">89.43</td></tr><tr><td align="left">RE</td><td align="left">68.70</td><td align="left">81.12</td><td align="left">79.12</td><td align="left">70.01</td><td align="left">74.74</td></tr><tr><td align="left" rowspan="3">Typical joint extraction</td><td align="left">SP</td><td align="left">82.56</td><td align="left">88.77</td><td align="left">92.41</td><td align="left">89.35</td><td align="left">88.27</td></tr><tr><td align="left">ET</td><td align="left">84.79</td><td align="left">89.13</td><td align="left">92.09</td><td align="left">88.05</td><td align="left">88.52</td></tr><tr><td align="left">RE</td><td align="left">68.70</td><td align="left">79.53</td><td align="left">78.32</td><td align="left">70.16</td><td align="left">74.18</td></tr><tr><td align="left" rowspan="3">JCBIE</td><td align="left">SP</td><td align="left">87.80</td><td align="left">89.17</td><td align="left">91.98</td><td align="left">91.12</td><td align="left"><bold>90.02</bold></td></tr><tr><td align="left">ET</td><td align="left">87.77</td><td align="left">89.65</td><td align="left">92.07</td><td align="left">90.38</td><td align="left"><bold>89.97</bold></td></tr><tr><td align="left">RE</td><td align="left">74.18</td><td align="left">80.56</td><td align="left">80.09</td><td align="left">72.97</td><td align="left"><bold>76.95</bold></td></tr></tbody></table><table-wrap-foot><p>The bold means the best results</p><p>The results are measured by micro-F1. NB: Without a subscript specification, ADE is the combination of ADE<inline-formula id="IEq123"><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${_1}$$\end{document}</tex-math><mml:math id="M274"><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq123.gif"/></alternatives></inline-formula> and ADE<inline-formula id="IEq124"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${_2}$$\end{document}</tex-math><mml:math id="M276"><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq124.gif"/></alternatives></inline-formula>. When only <inline-formula id="IEq125"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ADE_1$$\end{document}</tex-math><mml:math id="M278"><mml:mrow><mml:mi>A</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq125.gif"/></alternatives></inline-formula> is employed, ExtendNER, L&amp;R, and Typical Joint Extraction are equal, because they do not start to distill at the first step</p></table-wrap-foot></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparison between different RE hidden state augmentations</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Corpus</th><th align="left">Vanilla</th><th align="left">Entity marker</th><th align="left">Entity type embedding</th><th align="left">Entity type prototype</th></tr></thead><tbody><tr><td align="left"><inline-formula id="IEq127"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_{1}$$\end{document}</tex-math><mml:math id="M280"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq127.gif"/></alternatives></inline-formula></td><td align="left">74.61</td><td char="." align="char">74.18</td><td align="left">72.78</td><td char="." align="char"><bold>74.69</bold></td></tr><tr><td align="left">ADE</td><td align="left">79.37</td><td char="." align="char"><bold>80.56</bold></td><td align="left">80.25</td><td char="." align="char">79.66</td></tr><tr><td align="left">DDI + ADE</td><td align="left">79.58</td><td char="." align="char"><bold>80.09</bold></td><td align="left">79.88</td><td char="." align="char">78.57</td></tr><tr><td align="left">ADE + DDI + CPR</td><td align="left">71.83</td><td char="." align="char"><bold>72.97</bold></td><td align="left">71.51</td><td char="." align="char">71.43</td></tr><tr><td align="left">Avg.</td><td align="left">76.35</td><td char="." align="char"><bold>76.95</bold></td><td align="left">76.10</td><td char="." align="char">76.09</td></tr></tbody></table><table-wrap-foot><p>The bold means the best results</p><p>The results are measured by RE micro-F1</p></table-wrap-foot></table-wrap><table-wrap id="Tab5"><label>Table 5</label><caption><p>Within-corpora evaluation by different learning paradigms</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Corpus</th><th align="left">Continual</th><th align="left">Multi-corpora</th><th align="left">Conti. multi-corp.</th></tr></thead><tbody><tr><td align="left">ADE</td><td char="." align="char">79.91</td><td char="." align="char"><bold>80.56</bold></td><td align="left">80.40</td></tr><tr><td align="left">ADE-DDI</td><td char="." align="char"><bold>80.32</bold></td><td char="." align="char">80.09</td><td align="left">80.01</td></tr><tr><td align="left">DDI-CPR-ADE</td><td char="." align="char">72.18</td><td char="." align="char"><bold>72.97</bold></td><td align="left">72.58</td></tr><tr><td align="left">ADE-DDI-CPR</td><td char="." align="char">70.78</td><td char="." align="char"><bold>72.97</bold></td><td align="left">71.93</td></tr><tr><td align="left">Avg.</td><td char="." align="char">75.80</td><td char="." align="char"><bold>76.65</bold></td><td align="left">76.23</td></tr></tbody></table><table-wrap-foot><p>The bold means the best results</p><p>The results are measured by RE micro-F1</p></table-wrap-foot></table-wrap><table-wrap id="Tab6"><label>Table 6</label><caption><p>Cross-corpora evaluation by continual learning (CL), multi-corpora learning (ML), and continual multi-corpora learning (CML), single-head classifier (S), and multi-head classifier (M)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Training methods</th><th align="left">CLS</th><th align="left">ADE</th><th align="left">DDI- ADE</th><th align="left">DDI- CPR- ADE</th><th align="left">ADE- DDI</th><th align="left">ADE- DDI- CPR</th><th align="left">Avg.</th></tr></thead><tbody><tr><td align="left" rowspan="2">CL</td><td align="left">S</td><td char="." align="char">29.99</td><td char="." align="char">33.69</td><td char="." align="char">31.95</td><td char="." align="char">1.04</td><td char="." align="char">0.01</td><td char="." align="char">19.34</td></tr><tr><td align="left">M</td><td char="." align="char">30.06</td><td char="." align="char">34.13</td><td char="." align="char">32.04</td><td char="." align="char">26.73</td><td char="." align="char">23.21</td><td char="." align="char">29.23</td></tr><tr><td align="left" rowspan="2">ML</td><td align="left">S</td><td char="." align="char">29.41</td><td char="." align="char">28.88</td><td char="." align="char">25.62</td><td char="." align="char">28.88</td><td char="." align="char">25.62</td><td char="." align="char">27.68</td></tr><tr><td align="left">M</td><td char="." align="char"><bold>30.76</bold></td><td char="." align="char">32.29</td><td char="." align="char">26.66</td><td char="." align="char"><bold>32.29</bold></td><td char="." align="char">26.66</td><td char="." align="char">29.73</td></tr><tr><td align="left" rowspan="2">CML</td><td align="left">S</td><td char="." align="char">25.21</td><td char="." align="char">36.46</td><td char="." align="char">27.08</td><td char="." align="char">20.13</td><td char="." align="char">22.51</td><td char="." align="char">26.28</td></tr><tr><td align="left">M</td><td char="." align="char">28.16</td><td char="." align="char"><bold>38.95</bold></td><td char="." align="char"><bold>33.83</bold></td><td char="." align="char">28.01</td><td char="." align="char"><bold>29.18</bold></td><td char="." align="char"><bold>31.63</bold></td></tr><tr><td align="left" rowspan="2">Avg.</td><td align="left">S</td><td char="." align="char">28.20</td><td char="." align="char">33.01</td><td char="." align="char">28.22</td><td char="." align="char">16.68</td><td char="." align="char">16.05</td><td char="." align="char">24.43</td></tr><tr><td align="left">M</td><td char="." align="char">29.66</td><td char="." align="char">35.12</td><td char="." align="char">30.84</td><td char="." align="char">29.01</td><td char="." align="char">26.35</td><td char="." align="char">30.20</td></tr></tbody></table><table-wrap-foot><p>The bold means the best results</p><p>The performance is measured by RE micro-F1 on ADE<inline-formula id="IEq128"><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_{3}$$\end{document}</tex-math><mml:math id="M282"><mml:msub><mml:mrow/><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq128.gif"/></alternatives></inline-formula> corpus</p></table-wrap-foot></table-wrap></p>
      <p id="Par52">
        <fig id="Fig3">
          <label>Fig. 3</label>
          <caption>
            <p>Comparison between different encoder parameter sharing methods. The performance is measured by micro-F1 on ET and RE tasks</p>
          </caption>
          <graphic xlink:href="12859_2022_5096_Fig3_HTML" id="MO16"/>
        </fig>
      </p>
    </sec>
  </sec>
  <sec id="Sec14">
    <title>Results</title>
    <p id="Par53">In this section, we first demonstrate the improvements of JCBIE compared with a typical parameter sharing based joint extraction model and two other related baselines, then conducting empirical studies by comparing different encoding methods, RE hidden state augmentations, learning paradigms, classifiers, and finally discussing the NER tagging schemes and bottleneck factors in jointly learning NER and RE. </p>
    <sec id="Sec15">
      <title>Proposed method versus baseline methods</title>
      <p id="Par54">In Table <xref rid="Tab3" ref-type="table">3</xref>, all the compared models employ multi-corpora learning that shuffles data of all employed corpora as input. Compared with knowledge distillation-based ExtendNER and L&amp;R, data replay-based methods (JCBIE and typical joint model) perform better. Besides, JCBIE performs better than the typical joint model in all four RE evaluations by different dataset combinations, yielding an average gain of 2.27%. JCBIE also achieves better performance on SP and ET tasks, yielding averaged gains of 1.75% and 1.45%, respectively. It shows the efficiency of JCBIE in a conventional multi-corpora learning paradigm overall.</p>
    </sec>
    <sec id="Sec16">
      <title>Different parameter sharing methods</title>
      <p id="Par55">Three types of encoding methods, including hard-parameter, soft-parameter, and no-parameter sharing are compared on ET and RE tasks in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. For controlling variables, all compared models adopt multi-head classifiers (Fig. <xref rid="Fig2" ref-type="fig">2</xref>c) and multi-corpora learning (Fig. <xref rid="Fig2" ref-type="fig">2</xref>h). The results show that the soft-parameter sharing method is generally worse than the other two in RE task when more datasets, e.g., ADE, DDI + ADE, ADE + DDI + CPR are used for learning. Namely, the last hidden state of NER is not helpful for RE by cross-attention. This is probably because the ET information may mess up the RE learning when more labels are incorporated. By comparing hard-parameter sharing and no-parameter sharing setups, we find that no-parameter sharing outperforms hard-parameter sharing by 5.72% micro-F1 on <inline-formula id="IEq129"><alternatives><tex-math id="M283">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_1$$\end{document}</tex-math><mml:math id="M284"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq129.gif"/></alternatives></inline-formula>, while the performance of the two methods are close in the rest of dataset combinations. It shows that no-parameter sharing is particularly effective in single-corpus learning with the limited number of entities and relations. By comparing ET and RE, generally, RE task is more difficult because RE labels are more than that of ET.</p>
    </sec>
    <sec id="Sec17">
      <title>Different augmentation methods</title>
      <p id="Par56">Four different RE hidden state augmentation methods are compared in Table <xref rid="Tab4" ref-type="table">4</xref>. All the results are given by a model armed with multi-head classifier (Fig. <xref rid="Fig2" ref-type="fig">2</xref>c), no-parameter sharing encoders (Fig. <xref rid="Fig2" ref-type="fig">2</xref>f), and multi-corpora learning (Fig. <xref rid="Fig2" ref-type="fig">2</xref>h). Apart from the <inline-formula id="IEq130"><alternatives><tex-math id="M285">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_1$$\end{document}</tex-math><mml:math id="M286"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq130.gif"/></alternatives></inline-formula> evaluation task, adding entity markers is the optimal augmentation method for RE learning (76.95% micro-F1 on average). It helps a model to learn more diverse RE labels and tasks. For limited RE label learning in <inline-formula id="IEq131"><alternatives><tex-math id="M287">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_1$$\end{document}</tex-math><mml:math id="M288"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq131.gif"/></alternatives></inline-formula>, the vanilla augmentation method is slightly better. Establishing interactions between NER and RE from the input side (entity markers) is more useful than the fusing of hidden states on the encoder output side (other augmentation methods), because the Bio-BERT encoder delivers additional information fusion ability in modeling the interactions of two different tasks.</p>
    </sec>
    <sec id="Sec18">
      <title>Different training paradigms</title>
      <p id="Par57">We compare different learning paradigms, e.g., continual learning, multi-corpora learning and continual multi-corpora learning in two scenarios: (1) The testing and training sets are from the same corpora (within-corpora); (2) The testing and training sets are from different corpora (cross-corpora). The within-corpora evaluation analyses the ideal learning situation based on Hypothesis 1 (see Sect. <xref rid="Sec8" ref-type="sec">3.5</xref>). The cross-corpora evaluation is more close to the real-world situation, where Hypothesis 1 does not hold. The within-corpora evaluation is based on a model that has single-head classifiers (Fig. <xref rid="Fig2" ref-type="fig">2</xref>b), no-parameter sharing encoders (Fig. <xref rid="Fig2" ref-type="fig">2</xref>f) and entity marker augmentation methods. In the cross-domain evaluation task, we control encoder and augmentation methods, comparing classifier types (single-head and multi-head) and different learning paradigms. The dataset feeding pipeline in continual learning and continual multi-corpora learning is ordered. The datasets in multi-corpora learning is disordered, because all the datasets are combined as a whole dataset for training and testing.</p>
      <p id="Par58">As seen in Table <xref rid="Tab5" ref-type="table">5</xref>, the three data learning paradigms yield similar performance, based on Hypothesis 1 and within-corpora evaluation. The multi-corpora learning achieves the highest micro-F1 across the four dataset setups, because it uses all datasets at once, learning the data distribution globally. The average gap between multi-corpora and continual multi-corpora learning paradigms is just 0.41%. It shows that continual multi-corpora learning also achieves comparable performance, based on Hypothesis 1.</p>
      <p id="Par59">In Table <xref rid="Tab6" ref-type="table">6</xref>, we use an independent evaluation dataset (<inline-formula id="IEq132"><alternatives><tex-math id="M289">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_3$$\end{document}</tex-math><mml:math id="M290"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq132.gif"/></alternatives></inline-formula>) for the cross-corpora evaluation to evaluate the corpus-adaptation ability of different learning paradigms and classifier types when Hypothesis 1 does not hold. By comparing different learning paradigms, multi-head classifier-based continual multi-corpora learning achieves the highest micro-F1 on average (31.63%), outperforming other learning paradigms by at least 1.9%. This shows that our proposed continual multi-corpora learning method tasks the complementary strength of continual learning and multi-corpora learning in cross-corpora evaluation. In contrast, continual learning models suffer catastrophic forgetting and tend to fit the last feeding corpus. E.g., when models are evaluated by <inline-formula id="IEq133"><alternatives><tex-math id="M291">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_3$$\end{document}</tex-math><mml:math id="M292"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq133.gif"/></alternatives></inline-formula>, they always perform better, if ADE is trained lastly (see the results in DDI-ADE vs. ADE-DDI; DDI-CPR-ADE vs. ADE-DDI-CPR). This observed phenomena is consistent with the study of [<xref ref-type="bibr" rid="CR53">53</xref>].</p>
      <p id="Par60">Noticeably, micro-F1 values in cross-corpora evaluation in Table <xref rid="Tab6" ref-type="table">6</xref> are lower than within-corpora evaluation in Table <xref rid="Tab5" ref-type="table">5</xref>. We list two major reasons here. Firstly, the boundaries between biomedical entities and other tokens are indistinguishable. E.g., “3-[(2-methyl-1, 3-thiazol-4-yl) ethynyl] pyridine” and “1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine” are two drug entities in our data. Recognizing such entities without special training data is challenging. Secondly, certain annotation deviations exist in different corpora due to different annotation guidelines. For example, all kinds of inhibitors are regarded as Drug entity in <inline-formula id="IEq134"><alternatives><tex-math id="M293">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_3$$\end{document}</tex-math><mml:math id="M294"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>3</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq134.gif"/></alternatives></inline-formula>, but not in <inline-formula id="IEq135"><alternatives><tex-math id="M295">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_1$$\end{document}</tex-math><mml:math id="M296"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq135.gif"/></alternatives></inline-formula> and <inline-formula id="IEq136"><alternatives><tex-math id="M297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_2$$\end{document}</tex-math><mml:math id="M298"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq136.gif"/></alternatives></inline-formula>. Different genres can also lead to different performance for a supervised learning model [<xref ref-type="bibr" rid="CR54">54</xref>].</p>
    </sec>
    <sec id="Sec19">
      <title>Single-head versus multi-head classifiers</title>
      <p id="Par61">We demonstrate the advantage of using multi-head classifiers based on different learning paradigms. As seen in Table <xref rid="Tab6" ref-type="table">6</xref>, a multi-head classifier brings extra gains across all learning paradigms. This clearly demonstrates that a multi-head classifier surpasses a single-head classifier in cross-corpora evaluation. Multi-head classifiers also mitigate the impact of dataset-stream orders, reducing the gap between “DDI-CPR-ADE” (S: 28.22%, M: 30.84%) and “ADE-DDI-CPR” (S: 16.05%, M: 26.35%), e.g., from 12.17% to 4.49% on average. Thus, multi-head classifiers are more fitting for continual learning than single-head classifiers in robustness.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Model performance on each corpus, measured by micro-F1</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Corpus</th><th align="left">NER</th><th align="left">SP</th><th align="left">ET</th><th align="left"><inline-formula id="IEq137"><alternatives><tex-math id="M299">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ET}}^+$$\end{document}</tex-math><mml:math id="M300"><mml:msup><mml:mrow><mml:mtext>ET</mml:mtext></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq137.gif"/></alternatives></inline-formula></th><th align="left">RE</th><th align="left"><inline-formula id="IEq138"><alternatives><tex-math id="M301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {RE}}^+$$\end{document}</tex-math><mml:math id="M302"><mml:msup><mml:mrow><mml:mtext>RE</mml:mtext></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq138.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left"><inline-formula id="IEq139"><alternatives><tex-math id="M303">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_1$$\end{document}</tex-math><mml:math id="M304"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq139.gif"/></alternatives></inline-formula></td><td align="left">86.58</td><td align="left">88.40</td><td align="left">87.16</td><td align="left">99.82</td><td align="left">72.14</td><td align="left">91.75</td></tr><tr><td align="left"><inline-formula id="IEq140"><alternatives><tex-math id="M305">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text {ADE}}_2$$\end{document}</tex-math><mml:math id="M306"><mml:msub><mml:mtext>ADE</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq140.gif"/></alternatives></inline-formula></td><td align="left">90.66</td><td align="left">92.18</td><td align="left">90.72</td><td align="left">99.81</td><td align="left">83.37</td><td align="left">98.64</td></tr><tr><td align="left">DDI</td><td align="left">95.48</td><td align="left">96.74</td><td align="left">96.42</td><td align="left">100</td><td align="left">80.00</td><td align="left">84.26</td></tr><tr><td align="left">CPR</td><td align="left">88.58</td><td align="left">90.59</td><td align="left">89.19</td><td align="left">97.97</td><td align="left">65.36</td><td align="left">74.27</td></tr><tr><td align="left">Avg.</td><td align="left">90.32</td><td align="left">91.98</td><td align="left">90.87</td><td align="left">99.40</td><td align="left">75.22</td><td align="left">87.23</td></tr></tbody></table><table-wrap-foot><p>NB: NER means SP and ET labels are combined as a single label. ET and ET<inline-formula id="IEq141"><alternatives><tex-math id="M307">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{+}$$\end{document}</tex-math><mml:math id="M308"><mml:msup><mml:mrow/><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq141.gif"/></alternatives></inline-formula> denote the ET predictions depending on SP-predicted labels and gold labels, respectively. RE and RE<inline-formula id="IEq142"><alternatives><tex-math id="M309">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{+}$$\end{document}</tex-math><mml:math id="M310"><mml:msup><mml:mrow/><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq142.gif"/></alternatives></inline-formula> denote the RE predictions depending on SP and ET predicted labels and gold labels, respectively</p></table-wrap-foot></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec20">
    <title>Discussion</title>
    <p id="Par62">In this section, we discuss (1) the impact of different NER annotation methods (united and separated tags), and (2) the impact of SP and ET errors on RE (bottleneck factors). We train JCBIE on ADE<inline-formula id="IEq143"><alternatives><tex-math id="M311">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_1$$\end{document}</tex-math><mml:math id="M312"><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq143.gif"/></alternatives></inline-formula>, ADE<inline-formula id="IEq144"><alternatives><tex-math id="M313">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$_2$$\end{document}</tex-math><mml:math id="M314"><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq144.gif"/></alternatives></inline-formula>, DDI, and CPR datasets, individually. The JCBIE model is based on multi-head classifiers (Fig. <xref rid="Fig2" ref-type="fig">2</xref>c), no-parameter sharing encoders (Fig. <xref rid="Fig2" ref-type="fig">2</xref>f), and entity marker augmentation. The experiments do not involve continual learning and multi-corpora learning.</p>
    <p id="Par63">Traditional NER tagging scheme denotes both entity position and type information with a united label, such as “B_location, I_location, and E_location” [<xref ref-type="bibr" rid="CR55">55</xref>, <xref ref-type="bibr" rid="CR56">56</xref>]. In contrast, we divide the NER label system as two separated SP and ET labels (see Table <xref rid="Tab1" ref-type="table">1</xref> for examples). In the inferring process, the ET prediction is conditioned on the SP results, which introduces an additional inference step. However, such a modification can reduce the label types in each task, improving model performance. Additionally, accurate predictions of SP and ET can improve the final predictions of RE, because the positions of entity markers are given by SP. The types of entity markers are given by ET. As seen in Table <xref rid="Tab7" ref-type="table">7</xref>, by comparing ET and NER columns, JCBIE yields better performance in identifying entity types and positions based on SP-ET separated tagging scheme (90.87% micro-F1 on average) than the model trained with the traditional NER united tagging scheme (90.32%).</p>
    <p id="Par64">On the other hand, the errors introduced in SP and ET finally lower the RE performance. We first evaluate the error impacts of SP on ET. The ET<inline-formula id="IEq145"><alternatives><tex-math id="M315">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{+}$$\end{document}</tex-math><mml:math id="M316"><mml:msup><mml:mrow/><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq145.gif"/></alternatives></inline-formula> column in Table <xref rid="Tab7" ref-type="table">7</xref> shows the ET performance based on gold SP labels. By comparing ET and ET<inline-formula id="IEq146"><alternatives><tex-math id="M317">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{+}$$\end{document}</tex-math><mml:math id="M318"><mml:msup><mml:mrow/><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq146.gif"/></alternatives></inline-formula>, we observe a drop of 8.53% in micro-F1 on average. ET<inline-formula id="IEq147"><alternatives><tex-math id="M319">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{+}$$\end{document}</tex-math><mml:math id="M320"><mml:msup><mml:mrow/><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq147.gif"/></alternatives></inline-formula> yielding 99.4% average micro-F1 highlights that the SP task performance is the bottleneck factor in NER task. We will explore a more accurate method for SP learning in the future. By using gold SP and gold ET labels, we observe RE<inline-formula id="IEq148"><alternatives><tex-math id="M321">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{+}$$\end{document}</tex-math><mml:math id="M322"><mml:msup><mml:mrow/><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_5096_Article_IEq148.gif"/></alternatives></inline-formula> achieves 87.23%, exceeding RE by 12.01% on average. It shows that RE task is difficult. Although entity types and spans can be perfectly identified, there is still a huge space for improving RE performance. Thus, we will fuse additional knowledge for improving RE identification upon SP and ET in future work.</p>
  </sec>
  <sec id="Sec21">
    <title>Conclusion and future work</title>
    <p id="Par65">This paper explores JCBIE, jointly and continually learning biomedical information extraction from different corpora. We aim at establishing a more general biomedical information extraction neural network with continual learning ability. The ultimate goal is to get rid of limited entity types and relations to extract more knowledge, improving the generalization ability of a model. There are three summing-ups: Firstly, using two separated encoders without parameter sharing is better than using a hard-parameter sharing encoder or soft-parameter sharing encoders in learning NER and RE tasks; Secondly, apart from the ability of continually learning new entity types and relations, multi-head classifiers can also deliver better generalization on a new dataset; Finally, the dataset feeding orders have impacts on a cross-corpora inferring model. Using continual multi-corpora learning paradigm can somewhat mitigate the impacts, yielding robust performance.</p>
    <p id="Par66">In the future, we would further explore how to enhance the ability to continual learning. For example, utilizing a distillation-based method [<xref ref-type="bibr" rid="CR36">36</xref>, <xref ref-type="bibr" rid="CR37">37</xref>] to transfer knowledge or using fuzzy clustering [<xref ref-type="bibr" rid="CR57">57</xref>, <xref ref-type="bibr" rid="CR58">58</xref>] to filter features are both promising technologies to improve model performance. Besides, data replay-based continual learning is limited when previous data cannot access. We also try to explore methods that totally need no previous data while still can keep promising performance.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>JCBIE</term>
        <def>
          <p id="Par2">Joint continual learning biomedical information extraction</p>
        </def>
      </def-item>
      <def-item>
        <term>NER</term>
        <def>
          <p id="Par3">Named entity recognition</p>
        </def>
      </def-item>
      <def-item>
        <term>RE</term>
        <def>
          <p id="Par4">Relation extraction</p>
        </def>
      </def-item>
      <def-item>
        <term>SP</term>
        <def>
          <p id="Par5">Entity span detection</p>
        </def>
      </def-item>
      <def-item>
        <term>ET</term>
        <def>
          <p id="Par6">Entity type detection</p>
        </def>
      </def-item>
      <def-item>
        <term>DDI</term>
        <def>
          <p id="Par7">Drug–drug interaction</p>
        </def>
      </def-item>
      <def-item>
        <term>ADE</term>
        <def>
          <p id="Par8">Adverse drug events</p>
        </def>
      </def-item>
      <def-item>
        <term>CPR</term>
        <def>
          <p id="Par9">Chemical protein reaction</p>
        </def>
      </def-item>
      <def-item>
        <term>PPI</term>
        <def>
          <p id="Par10">Protein–protein interaction</p>
        </def>
      </def-item>
      <def-item>
        <term>LM</term>
        <def>
          <p id="Par11">Language models</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>KH: conceptualization, writing-original draft preparation, software; RM: investigation, validation; TG: supervision; EC: writing- reviewing and editing; CL: methodology. All auhtors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work has been supported by the Key Research and Development Program of Ningxia Hui Nationality Autonomous Region (2022BEG02025); The Key Research and Development Program of Shaanxi Province (2021GXLH-Z-095); The Innovative Research Group of the National Natural Science Foundation of China (61721002); The consulting research project of the Chinese Academy of Engineering (The Online and Offline Mixed Educational Service System for The Belt and Road Training in MOOC China); Project of China Knowledge Centre for Engineering Science and Technology; The innovation team from the Ministry of Education (IRT_17R86).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets and codes used during the current study are available from GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/KaiHe-better/JCBIE.git">https://github.com/KaiHe-better/JCBIE.git</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par67">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par68">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par69">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <mixed-citation publication-type="other">Wu J, Zhang R, Gong T, Liu Y, Wang C, Li C. BIOIE: biomedical information extraction with multi-head attention enhanced graph convolutional network. In: IEEE international conference on bioinformatics and biomedicine (BIBM). IEEE; 2021. p. 2080–87.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">Wu J, Tang K, Zhang H, Wang C, Li C. Structured information extraction of pathology reports with attention-based graph convolutional network. In: IEEE international conference on bioinformatics and biomedicine (BIBM). IEEE; 2020. p. 2395–402.</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <mixed-citation publication-type="other">He K, Wu J, Ma X, Zhang C, Huang M, Li C, Yao L. Extracting kinship from obituary to enhance electronic health records for genetic research. In: Proceedings of the Fourth social media mining for health applications (# SMM4H) workshop &amp; shared task. 2019. p. 1–10.</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Hong</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Unsupervised representation learning for tissue segmentation in histopathological images: from global to local contrast</article-title>
        <source>IEEE Trans Med Imaging</source>
        <year>2022</year>
        <volume>41</volume>
        <fpage>3611</fpage>
        <lpage>3623</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2022.3191398</pub-id>
        <pub-id pub-id-type="pmid">35839184</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Construction of genealogical knowledge graphs from obituaries: multitask neural network extraction system</article-title>
        <source>J Med Internet Res</source>
        <year>2021</year>
        <volume>23</volume>
        <issue>8</issue>
        <fpage>25670</fpage>
        <pub-id pub-id-type="doi">10.2196/25670</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ji</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cambria</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Marttinen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Philip</surname>
            <given-names>SY</given-names>
          </name>
        </person-group>
        <article-title>A survey on knowledge graphs: representation, acquisition, and applications</article-title>
        <source>IEEE Trans Neural Netw Learn Syst</source>
        <year>2021</year>
        <volume>33</volume>
        <fpage>494</fpage>
        <lpage>514</lpage>
        <pub-id pub-id-type="doi">10.1109/TNNLS.2021.3070843</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hewett</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Oliver</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Rubin</surname>
            <given-names>DL</given-names>
          </name>
          <name>
            <surname>Easton</surname>
            <given-names>KL</given-names>
          </name>
          <name>
            <surname>Stuart</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Altman</surname>
            <given-names>RB</given-names>
          </name>
          <name>
            <surname>Klein</surname>
            <given-names>TE</given-names>
          </name>
        </person-group>
        <article-title>PharmGKB: the pharmacogenetics knowledge base</article-title>
        <source>Nucleic Acids Res</source>
        <year>2002</year>
        <volume>30</volume>
        <issue>1</issue>
        <fpage>163</fpage>
        <lpage>165</lpage>
        <pub-id pub-id-type="doi">10.1385/1-59259-957-5:179</pub-id>
        <pub-id pub-id-type="pmid">11752281</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">Huang Y, He K, Wang Y, Zhang X, Gong T, Mao R, Li C. Copner: Contrastive learning with prompt guiding for few-shot named entity recognition. In: Proceedings of the 29th International conference on computational linguistics. 2022. p. 2515–27.</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kai</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yucheng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rui</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tieliang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Erik</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Virtual prompt pre-training for prototype-based few-shot relation extraction</article-title>
        <source>Expert Syst Appl</source>
        <year>2023</year>
        <volume>213</volume>
        <fpage>118927</fpage>
        <pub-id pub-id-type="doi">10.1016/j.eswa.2022.118927</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>A multimodal deep learning framework for predicting drug-drug interaction events</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>15</issue>
        <fpage>4316</fpage>
        <lpage>4322</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa501</pub-id>
        <pub-id pub-id-type="pmid">32407508</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>HINGRL: predicting drug-disease associations with graph representation learning on heterogeneous information networks</article-title>
        <source>Brief Bioinform</source>
        <year>2022</year>
        <pub-id pub-id-type="doi">10.1093/bib/bbab515</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Demner-Fushman D, Fung KW, Do P, Boyce RD, Goodwin TR. Overview of the TAC 2018 drug–drug interaction extraction from drug labels track. In: TAC. 2019.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krallinger</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rabal</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Lourenço</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Oyarzabal</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Valencia</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Information retrieval and text mining technologies for chemistry</article-title>
        <source>Chem Rev</source>
        <year>2017</year>
        <volume>117</volume>
        <issue>12</issue>
        <fpage>7673</fpage>
        <lpage>7761</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.chemrev.6b00851</pub-id>
        <pub-id pub-id-type="pmid">28475312</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Faessler E, Modersohn L, Lohr C, Hahn U. ProGene: a large-scale, high-quality protein-gene annotated benchmark corpus. In: Proceedings of the 12th Language resources and evaluation conference. Marseille: European Language Resources Association; 2020. p. 4585–96. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/2020.lrec-1.564">https://www.aclweb.org/anthology/2020.lrec-1.564</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>A survey on computational models for predicting protein-protein interactions</article-title>
        <source>Brief Bioinform</source>
        <year>2021</year>
        <pub-id pub-id-type="doi">10.1093/bib/bbab036</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Yepes A.J, MacKinlay A, Gunn N, Schieber C, Faux N, Downton M, Goudey B, Martin RL. A hybrid approach for automated mutation annotation of the extended human mutation landscape in scientific literature. In: AMIA annual symposium proceedings, vol. 2018. San Francisco: American Medical Informatics Association; 2018. p. 616.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Hong</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A semi-supervised multi-task learning framework for cancer classification with weak annotation in whole-slide images</article-title>
        <source>Med Image Anal</source>
        <year>2022</year>
        <volume>83</volume>
        <fpage>102652</fpage>
        <pub-id pub-id-type="doi">10.1016/j.media.2022.102652</pub-id>
        <pub-id pub-id-type="pmid">36327654</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Alsentzer E, Murphy JR, Boag W, Weng W-H, Jin D, Naumann T, McDermott MBA. Publicly available clinical BERT embeddings. 2019. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1904.03323">arxiv:1904.03323</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Wu J, Qian B, Li Y, Gao Z, Ju M, Yang Y, Zheng Y, Gong T, Li C, Zhang X. Leveraging multiple types of domain knowledge for safe and effective drug recommendation. In: Proceedings of the 31st ACM international conference on information &amp; knowledge management. 2022. p. 2169–78.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Miwa M, Bansal M. End-to-end relation extraction using LSTMs on sequences and tree structures. In: 54th Annual meeting of the association for computational linguistics, ACL 2016-long papers, vol. 2. 2016. p. 1105–16. 10.18653/v1/p16-1105. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1601.00770">arxiv:1601.00770</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Fu TJ, Li PH, Ma WY. Graphrel: modeling text as relational graphs for joint entity and relation extraction. In: Proceedings of the 57th Annual meeting of the association for computational linguistics. Florence: Association for Computational Linguistics; 2019. p. 1409–18. 10.18653/v1/p19-1136. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/P19-1136">https://aclanthology.org/P19-1136</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Sun C, Gong Y, Wu Y, Gong M, Jiang D, Lan M, Sun S, Duan N. Joint type inference on entities and relations via graph convolutional networks. In: Proceedings of the 57th Annual meeting of the association for computational linguistics. Florence: Association for Computational Linguistics; 2019. p. 1361–70. 10.18653/v1/p19-1131.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>A neural joint model for entity and relation extraction from biomedical text</article-title>
        <source>BMC Bioinform</source>
        <year>2017</year>
        <volume>18</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="doi">10.1186/s12859-017-1609-9</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Pawar S, Bhattacharyya P, Palshikar GK. Techniques for jointly extracting entities and relations: a survey. 2021. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2103.06118">arxiv:2103.06118</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Wang S, Zhang Y, Che W, Liu T. Joint extraction of entities and relations based on a novel graph scheme. In: IJCAI international joint conference on artificial intelligence. 2018. p. 4461–67. 10.24963/ijcai.2018/620. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1706.05075">arxiv:1706.05075</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Bridging towers of multi-task learning with a gating mechanism for aspect-based sentiment analysis and sequential metaphor identification</article-title>
        <source>Proc AAAI Conf Artif Intell</source>
        <year>2021</year>
        <volume>35</volume>
        <issue>15</issue>
        <fpage>13534</fpage>
        <lpage>13542</lpage>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ge</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Cambria</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>MetaPro: a computational metaphor processing model for text pre-processing</article-title>
        <source>Inform Fusion</source>
        <year>2022</year>
        <volume>86–87</volume>
        <fpage>30</fpage>
        <lpage>43</lpage>
        <pub-id pub-id-type="doi">10.1016/j.inffus.2022.06.002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Miwa M, Sasaki Y. Modeling joint entity and relation extraction with table representation. In: Proceedings of the conference on empirical methods in natural language processing (EMNLP). Doha: Association for Computational Linguistics; 2014. p. 1858–69. 10.3115/v1/D14-1200. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/D14-1200">https://aclanthology.org/D14-1200</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Zhang M, Zhang Y, Fu G. End-to-end neural relation extraction with global optimization. In: Proceedings of the conference on empirical methods in natural language processing. Copenhagen: Association for Computational Linguistics; 2017. p. 1730–40. 10.18653/v1/D17-1182. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/D17-1182">https://aclanthology.org/D17-1182</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bao</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hao</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Joint entity and relation extraction based on a hybrid neural network</article-title>
        <source>Neurocomputing</source>
        <year>2017</year>
        <volume>257</volume>
        <fpage>59</fpage>
        <lpage>66</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2016.12.075</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Joint extraction of entities and relations based on a novel decomposition strategy</article-title>
        <source>Front Artif Intell Appl</source>
        <year>2020</year>
        <volume>325</volume>
        <fpage>2282</fpage>
        <lpage>2289</lpage>
        <pub-id pub-id-type="doi">10.3233/FAIA200356</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Zeng X, Zeng D, He S, Liu K, Zhao J. Extracting relational facts by an end-to-end neural model with copy mechanism. In: 56th Annual meeting of the association for computational linguistics, proceedings of the conference (long papers), ACL 2018, vol. 1. 2018. p. 506–10. 10.18653/v1/p18-1047.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zeng</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Copymtl: copy mechanism for joint extraction of entities and relations with multi-task learning</article-title>
        <source>Proc AAAI Conf Artif Intell</source>
        <year>2020</year>
        <volume>34</volume>
        <issue>05</issue>
        <fpage>9507</fpage>
        <lpage>9514</lpage>
        <pub-id pub-id-type="doi">10.1609/aaai.v34i05.6495</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Taillé B, Guigue V, Scoutheeten G, Gallinari P. Let’s stop incorrect comparisons in end-to-end relation extraction! 2021. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2009.10684">arxiv:2009.10684</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">McCloskey M, Cohen NJ. Catastrophic interference in connectionist networks: the sequential learning problem. In: Psychology of learning and motivation, vol. 24. Amsterdam: Elsevier; 1989. p. 109–65.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Monaikul N, Castellucci G, Filice S, Rokhlenko O. Continual learning for named entity recognition. In: Thirty-fifth AAAI conference on artificial intelligence, AAAI 2021; Thirty-third conference on innovative applications of artificial intelligence, IAAI 2021; The eleventh symposium on educational advances in artificial intelligence, EAAI 2021, virtual event, February 2–9, 2021. AAAI Press; 2021. p. 13570–77. <ext-link ext-link-type="uri" xlink:href="https://ojs.aaai.org/index.php/AAAI/article/view/17600">https://ojs.aaai.org/index.php/AAAI/article/view/17600</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Xia Y, Wang Q, Lyu Y, Zhu Y, Wu W, Li S, Dai D. Learn and review: enhancing continual named entity recognition via reviewing synthetic samples. In: Muresan S, Nakov P, Villavicencio A, editors. Findings of the association for computational linguistics: ACL 2022, Dublin, Ireland, May 22–27, 2022. Association for Computational Linguistics; 2022. p. 2291–300. 10.18653/v1/2022.findings-acl.179. <pub-id pub-id-type="doi">10.18653/v1/2022.findings-acl.179</pub-id>.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Hussain A, Holla N, Mishra P, Yannakoudakis H, Shutova E. Towards a robust experimental framework and benchmark for lifelong language learning. In: Vanschoren J, Yeung S, editors. Proceedings of the neural information processing systems track on datasets and benchmarks 1, NeurIPS datasets and benchmarks 2021, December 2021, Virtual. 2021. <ext-link ext-link-type="uri" xlink:href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/b3e3e393c77e35a4a3f3cbd1e429b5dc-Abstract-round1.html">https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/b3e3e393c77e35a4a3f3cbd1e429b5dc-Abstract-round1.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>A neural network-based joint learning approach for biomedical entity and relation extraction from biomedical literature</article-title>
        <source>J Biomed Inform</source>
        <year>2020</year>
        <volume>103</volume>
        <fpage>103384</fpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2020.103384</pub-id>
        <pub-id pub-id-type="pmid">32032717</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yoon</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>So</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>4</issue>
        <fpage>1234</fpage>
        <lpage>1240</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id>
        <pub-id pub-id-type="pmid">31501885</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Hao Y, Zhang Y, Liu K, He S, Liu Z, Wu H, Zhao J. An end-to-end model for question answering over knowledge base with cross-attention combining global knowledge. In: Proceedings of the 55th annual meeting of the association for computational linguistics. Association for Computational Linguistics, Vancouver. 2017. p. 221–31.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Devlin J, Chang M-W, Lee K, Toutanova K. BERT: pre-training of deep bidirectional transformers for language understanding. 2019. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1810.04805">arxiv:1810.04805</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Zhong Z, Chen D. A frustratingly easy approach for entity and relation extraction. In: Proceedings of the 2021 conference of the North American chapter of the association for computational linguistics: human language technologies. Association for Computational Linguistics; 2021. p. 50–61. 10.18653/v1/2021.naacl-main.5. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/2021.naacl-main.5">https://aclanthology.org/2021.naacl-main.5</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Cambria</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>The biases of pre-trained language models: an empirical study on prompt-based sentiment analysis and emotion detection</article-title>
        <source>IEEE Trans Affect Comput</source>
        <year>2022</year>
        <pub-id pub-id-type="doi">10.1109/TAFFC.2022.3204972</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Parisi</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Kemker</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Part</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Kanan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Wermter</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Continual lifelong learning with neural networks: a review</article-title>
        <source>Neural Netw</source>
        <year>2019</year>
        <volume>113</volume>
        <fpage>54</fpage>
        <lpage>71</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neunet.2019.01.012</pub-id>
        <pub-id pub-id-type="pmid">30780045</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Ernie 2.0: a continual pre-training framework for language understanding</article-title>
        <source>Proc AAAI Conf Artif Intell</source>
        <year>2020</year>
        <volume>34</volume>
        <issue>05</issue>
        <fpage>8968</fpage>
        <lpage>8975</lpage>
        <pub-id pub-id-type="doi">10.1609/aaai.v34i05.6428</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Delange</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Aljundi</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Masana</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Parisot</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Leonardis</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Slabaugh</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Tuytelaars</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>A continual learning survey: defying forgetting in classification tasks</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2021</year>
        <volume>01</volume>
        <fpage>1</fpage>
        <lpage>1</lpage>
        <pub-id pub-id-type="doi">10.1109/tpami.2021.3057446</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gurulingappa</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rajput</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Roberts</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fluck</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hofmann-Apitius</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Toldo</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports</article-title>
        <source>J Biomed Inform</source>
        <year>2012</year>
        <volume>45</volume>
        <issue>5</issue>
        <fpage>885</fpage>
        <lpage>892</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2012.04.008</pub-id>
        <pub-id pub-id-type="pmid">22554702</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Herrero-Zazo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Segura-Bedmar</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Martínez</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Declerck</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>The DDI corpus: an annotated corpus with pharmacological substances and drug–drug interactions</article-title>
        <source>J Biomed Inform</source>
        <year>2013</year>
        <volume>46</volume>
        <issue>5</issue>
        <fpage>914</fpage>
        <lpage>920</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jbi.2013.07.011</pub-id>
        <pub-id pub-id-type="pmid">23906817</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alvaro</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Miyao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Collier</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>TwiMed: Twitter and PubMed comparable corpus of drugs, diseases, symptoms, and their relations</article-title>
        <source>JMIR Public Health Surveill</source>
        <year>2017</year>
        <volume>3</volume>
        <issue>2</issue>
        <fpage>24</fpage>
        <pub-id pub-id-type="doi">10.2196/publichealth.6396</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Masana</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Twardowski</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Menta</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bagdanov</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>van de Weijer</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Class-incremental learning: survey and performance evaluation on image classification</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2022</year>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2022.3213473</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Kingma DP, Ba J. Adam: a method for stochastic optimization. 2017. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1412.6980">arxiv:1412.6980</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Qin C, Joty S. LFPT5: a unified framework for lifelong few-shot language learning based on prompt tuning of t5. In: International conference on learning representations. 2022. <ext-link ext-link-type="uri" xlink:href="https://openreview.net/forum?id=HCRVf71PMF">https://openreview.net/forum?id=HCRVf71PMF</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Mao R, Lin C, Guerin F. End-to-end sequential metaphor identification inspired by linguistic theories. In: Proceedings of the 57th Annual meeting of the association for computational linguistics (ACL). Florence: Association for Computational Linguistics; 2019. p. 3888–98. 10.18653/v1/P19-1378. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/P19-1378">https://aclanthology.org/P19-1378</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <mixed-citation publication-type="other">Yadav V, Bethard S. A survey on recent advances in named entity recognition from deep learning models. In: Proceedings of the 27th international conference on computational linguistics. New Mexico: Association for Computational Linguistics; 2018. p. 2145–58. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/C18-1182">https://aclanthology.org/C18-1182</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Akbik A, Bergmann T, Vollgraf R. Pooled contextualized embeddings for named entity recognition. In: Proceedings of the conference of the North American chapter of the association for computational linguistics: human language technologies, vol. 1 (long and short papers). Minnesota: Association for Computational Linguistics; 2019. p. 724–8. 10.18653/v1/N19-1078. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/N19-1078">https://aclanthology.org/N19-1078</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>A fast fuzzy clustering algorithm for complex networks via a generalized momentum method</article-title>
        <source>IEEE Trans Fuzzy Syst</source>
        <year>2022</year>
        <volume>30</volume>
        <issue>9</issue>
        <fpage>3473</fpage>
        <lpage>3485</lpage>
        <pub-id pub-id-type="doi">10.1109/TFUZZ.2021.3117442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>HiSCF: leveraging higher-order structures for clustering analysis in biological networks</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <issue>4</issue>
        <fpage>542</fpage>
        <lpage>550</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa775</pub-id>
        <pub-id pub-id-type="pmid">32931549</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
