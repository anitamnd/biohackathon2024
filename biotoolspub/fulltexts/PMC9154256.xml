<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9154256</article-id>
    <article-id pub-id-type="pmid">35536192</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac304</article-id>
    <article-id pub-id-type="publisher-id">btac304</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>deepSimDEF: deep neural embeddings of gene products and gene ontology terms for functional analysis of genes</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Pesaranghader</surname>
          <given-names>Ahmad</given-names>
        </name>
        <xref rid="btac304-cor1" ref-type="corresp"/>
        <aff><institution>Montreal Heart Institute</institution>, Research Center, Montreal H1T 1C8, <country country="CA">Canada</country></aff>
        <aff><institution>Faculty of Medicine, University of Montreal</institution>, Montreal H3T 1J4, <country country="CA">Canada</country></aff>
        <aff><institution>Mila—Quebec Artificial Intelligence Institute</institution>, Montreal H2S 3H1, <country country="CA">Canada</country></aff>
        <aff><institution>Department of Computer Science and Operations Research, University of Montreal</institution>, Montreal H3T 1J4, <country country="CA">Canada</country></aff>
        <!--ahmadpgh@gmail.com-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Matwin</surname>
          <given-names>Stan</given-names>
        </name>
        <aff><institution>Faculty of Computer Science, Dalhousie University</institution>, Halifax B3H 4R2, <country country="CA">Canada</country></aff>
        <aff><institution>Institute for Big Data Analytics, Dalhousie University</institution>, Halifax B3H 4R2, <country country="CA">Canada</country></aff>
        <aff><institution>Institute of Computer Science, Polish Academy of Sciences</institution>, Warsaw, <country country="PL">Poland</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sokolova</surname>
          <given-names>Marina</given-names>
        </name>
        <aff><institution>Institute for Big Data Analytics, Dalhousie University</institution>, Halifax B3H 4R2, <country country="CA">Canada</country></aff>
        <aff><institution>Faculty of Medicine and Faculty of Engineering, University of Ottawa</institution>, Ottawa K1H 8M5, <country country="CA">Canada</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Grenier</surname>
          <given-names>Jean-Christophe</given-names>
        </name>
        <aff><institution>Montreal Heart Institute</institution>, Research Center, Montreal H1T 1C8, <country country="CA">Canada</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Beiko</surname>
          <given-names>Robert G</given-names>
        </name>
        <aff><institution>Faculty of Computer Science, Dalhousie University</institution>, Halifax B3H 4R2, <country country="CA">Canada</country></aff>
        <aff><institution>Institute for Big Data Analytics, Dalhousie University</institution>, Halifax B3H 4R2, <country country="CA">Canada</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4295-3339</contrib-id>
        <name>
          <surname>Hussin</surname>
          <given-names>Julie</given-names>
        </name>
        <xref rid="btac304-cor1" ref-type="corresp"/>
        <!--julie.hussin@umontreal.ca-->
        <aff><institution>Montreal Heart Institute</institution>, Research Center, Montreal H1T 1C8, <country country="CA">Canada</country></aff>
        <aff><institution>Faculty of Medicine, University of Montreal</institution>, Montreal H3T 1J4, <country country="CA">Canada</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Birol</surname>
          <given-names>Inanc</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac304-cor1">To whom correspondence should be addressed. <email>ahmadpgh@gmail.com</email> or <email>julie.hussin@umontreal.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>6</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-05-10">
      <day>10</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>11</issue>
    <fpage>3051</fpage>
    <lpage>3061</lpage>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>9</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>12</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>06</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac304.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>There is a plethora of measures to evaluate functional similarity (FS) of genes based on their co-expression, protein–protein interactions and sequence similarity. These measures are typically derived from hand-engineered and application-specific metrics to quantify the degree of shared information between two genes using their Gene Ontology (GO) annotations.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We introduce deepSimDEF, a deep learning method to automatically learn FS estimation of gene pairs given a set of genes and their GO annotations. deepSimDEF’s key novelty is its ability to learn low-dimensional embedding vector representations of GO terms and gene products and then calculate FS using these learned vectors. We show that deepSimDEF can predict the FS of new genes using their annotations: it outperformed all other FS measures by &gt;5–10% on yeast and human reference datasets on protein–protein interactions, gene co-expression and sequence homology tasks. Thus, deepSimDEF offers a powerful and adaptable deep neural architecture that can benefit a wide range of problems in genomics and proteomics, and its architecture is flexible enough to support its extension to any organism.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Source code and data are available at <ext-link xlink:href="https://github.com/ahmadpgh/deepSimDEF" ext-link-type="uri">https://github.com/ahmadpgh/deepSimDEF</ext-link></p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Institute for Data Valorization (IVADO)/Genome Quebec</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PRF-2017-023</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSERC CREATE</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Poland’s National Scientific Center</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSERC Discovery</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Fonds de la Recherche du Québec en Santé (FRQS) Junior 1 Scholar</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Canada Research Chairs program</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="11"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>In the past decades, a wide array of biological networks such as protein–protein interaction (PPI) and gene co-expression networks have come into existence. However, despite their utility, such networks are often incomplete or under-represented meaning they miss a lot of real associations and interactions. Given the fact that laboratory-based experiments are time-consuming and labor-intensive, computational algorithms have been seen as a viable solution. Many of such algorithms integrate curated ontologies, such as Gene Ontology (GO) (<xref rid="btac304-B3" ref-type="bibr">Ashburner <italic toggle="yes">et al.</italic>, 2000</xref>), into the original biological networks to predict missing associations. GO-based semantic similarity (SS) measures allow the comparison of GO terms by leveraging GO properties and on annotation corpora which, in turn, leads to functional similarity (FS) measurement of genes. These measures have been applied to important biological problems such as PPI prediction (<xref rid="btac304-B58" ref-type="bibr">Yu <italic toggle="yes">et al.</italic>, 2017</xref>), analysis of gene co-expression (<xref rid="btac304-B26" ref-type="bibr">Makrodimitris <italic toggle="yes">et al.</italic>, 2020</xref>), protein subcellular localization prediction (<xref rid="btac304-B6" ref-type="bibr">Cao <italic toggle="yes">et al.</italic>, 2018</xref>), among others, showing the vast utility of GO for the characterization of genomic and proteomic entities. For instance, <xref rid="btac304-B57" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> (2018)</xref> proposed a new method to measure the GO-based functional similarity for miRNAs providing the community with the largest similarity matrix of human miRNAs. These similarity scores can serve as a basic feature in various prediction tasks related to miRNA functions. <xref rid="btac304-B44" ref-type="bibr">Schaefer and Serrano (2016)</xref> demonstrated the importance of using GO semantic similarities on pairs of genes for characterizing gene groups in cancer research, arguing that general cancer genes tend to show a higher pairwise similarity as compared to genes implicated in specific types of cancer. <xref rid="btac304-B20" ref-type="bibr">Kim <italic toggle="yes">et al.</italic> (2019)</xref> used GO similarity of drug-target and disease-related genes to address drug repositioning of herbal compounds. Despite these recent advances, current GO-based FS measures still depend on slow FS computation and empirical SS metric engineering. To address this inadequacy, the employment of advanced feature learning techniques offered by deep neural networks seems inevitable.</p>
    <p>With the revival of deep neural networks around 2006 (<xref rid="btac304-B17" ref-type="bibr">Hinton <italic toggle="yes">et al.</italic>, 2006</xref>), deep learning methods have become prevalent in the research community. Such methods are representation learning techniques that combine multiple non-linear modules to obtain multiple levels of representation (<xref rid="btac304-B21" ref-type="bibr">LeCun <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btac304-B19" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2017</xref>). One key advantage of deep learning is that human researchers do not design the layers of features, hence, minimal feature engineering is needed. For their promising performance, deep learning methods are increasingly being applied in the medical field including bioinformatics (<xref rid="btac304-B4" ref-type="bibr">Ben Ali <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac304-B38" ref-type="bibr">Pesaranghader <italic toggle="yes">et al.</italic>, 2021a</xref>,<xref rid="btac304-B39" ref-type="bibr">b</xref>). For example, BioVec (<xref rid="btac304-B2" ref-type="bibr">Asgari and Mofrad, 2015</xref>), inspired by the Word2Vec (<xref rid="btac304-B28" ref-type="bibr">Mikolov <italic toggle="yes">et al.</italic>, 2013</xref>) widely used in natural language processing, is an initiative in bioinformatics to offer a solution for an unsupervised data-driven vector representation of biological sequences. It is becoming increasingly clear that these powerful approaches can help the mining of ontologies such as GO to extract meaningful insights about genes and proteins’ biological functions and interactions.</p>
    <p>There exist two computational classes of GO-based FS measurements. <italic toggle="yes">Ontology-based</italic> methods take advantage of the GO structure by computing SS of GO terms prior to drawing on them for FS estimation. The SS measures revolve around the idea of shared Information Content (IC) (<xref rid="btac304-B43" ref-type="bibr">Resnik, 1995</xref>) of GO terms annotating genes. The IC-based FS measures of <xref rid="btac304-B43" ref-type="bibr">Resnik (1995)</xref>, <xref rid="btac304-B23" ref-type="bibr">Lin (1998)</xref>, <xref rid="btac304-B18" ref-type="bibr">Jiang and Conrath (1997)</xref>, GraSM (<xref rid="btac304-B8" ref-type="bibr">Couto and Silva, 2011</xref>) and AIC (<xref rid="btac304-B47" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2014</xref>) depend on these engineered SS measures. Recently, <xref rid="btac304-B12" ref-type="bibr">Dutta <italic toggle="yes">et al.</italic> (2018)</xref> presented a new approach (which we call clusteredGO in our evaluation) that utilized IC of the GO terms and the GO graph to do GO term clustering. In contrast to these pair-wise FS measures, group-wise FS measures such as simUI (<xref rid="btac304-B14" ref-type="bibr">Falcon and Gentleman, 2007</xref>), simGIC (<xref rid="btac304-B40" ref-type="bibr">Pesquita <italic toggle="yes">et al.</italic>, 2007</xref>) and SORA (<xref rid="btac304-B51" ref-type="bibr">Teng <italic toggle="yes">et al.</italic>, 2013</xref>) directly calculate FS by measuring the distance between two sets of GO term annotations. Based on Jaccard distance (<xref rid="btac304-B22" ref-type="bibr">Levandowsky and Winter, 1971</xref>), the group-wise measures are less computationally intensive; however, this occurs at the cost of accuracy. This process of FS estimation is executed and then reported for every GO sub-ontology separately.</p>
    <p><italic toggle="yes">Distributional-based</italic> FS measures are based on <xref rid="btac304-B15" ref-type="bibr">Firth’s idea (1957)</xref>, characterizing one natural language word by its surrounding words in a given context. Our previous works (<xref rid="btac304-B35" ref-type="bibr">Pesaranghader <italic toggle="yes">et al.</italic>, 2014</xref>, <xref rid="btac304-B36" ref-type="bibr">2016</xref>; <xref rid="btac304-B32" ref-type="bibr">Pesaranghader, 2019</xref>), proposing the simDEF model which compared the text definitions of two GO terms, were inspired by this notion to address several drawbacks of the ontology-based methods. Recently, <xref rid="btac304-B11" ref-type="bibr">Duong <italic toggle="yes">et al.</italic> (2019)</xref> introduced AicInferSentGO, a definition-based model that aimed to improve simDEF by proposing a new approach for vector representation of GO terms. Even though simDEF and AicInferSentGO demonstrated the significant advantage of vector representation of GO terms, they suffered from important shortcomings, some of which are still shared with even the recent FS measures: manual metric and feature engineering for aggregating GO-term SS scores prior to the computation of gene FS; large dimensions of GO-term vectors; and, separate consideration of each sub-ontology of GO for a biological task in hand due to uncertainty on how the downstream biological attributes from those sub-ontologies should be combined.</p>
    <p>In this work, we introduce deepSimDEF, a paired neural network that attempts to address the above-mentioned shortcomings. Supervised deepSimDEF neural networks are designed to address the biological tasks; hence, the main output of deepSimDEF is a prediction model, where GO-term and gene-product embeddings are the by-products of the training process. Prior to training, deepSimDEF networks are typically initialized with pretrained GO-term embeddings that we compute in advance. deepSimDEF can be run in two settings: <italic toggle="yes">single channel</italic> considering sub-ontologies separately, and <italic toggle="yes">multi-channel</italic> with sub-ontologies combined. Evaluated on both yeast and human reference datasets, we demonstrate the performance of deepSimDEF against the FS measures of Resnik, Lin, Jiang and Conrath, GraSM, AIC, clusteredGO, simGIC, simDEF and AicInferSentGO (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S1</xref> for their details). We also show in contrast to previous FS measures in which the estimation results hinged upon the choice of hand-engineered metrics such as Maximum (MAX), Average or Best-Match Average (BMA) to aggregate the SS scores of the two underlying GO annotation sets, a deepSimDEF network automatically learns this quantification regarding a biological application of interest, and later, measures FS of new genes and gene products.</p>
  </sec>
  <sec>
    <title>2 Results</title>
    <sec>
      <title>2.1 Experimental design and data overview</title>
      <p><xref rid="btac304-T1" ref-type="table">Table 1</xref> provides an overview of the datasets prepared for the evaluation in the study (see Evaluation and validation datasets section for details). In order to include all available proteins of every experiment of the study (i.e. PPI, protein sequence homology or gene expression) in the testing phase, we used a 10-fold cross-validation approach by randomly dividing the total number of proteins into 10 non-overlapping sets. In each of 10 separate runs we held out one of those sets and all the protein pairs made of that set for testing; the rest of the protein pairs, devoid of any protein in the test set, were employed for network training. For example, in the PPI experiment on human data, out of the total number of 14 096 proteins in that experiment a test split consisted of 1410 proteins (their available pairs with PPI values); the rest of the proteins were used in training phase. After the model hyper-parameters were selected using 10% of the training set as a validation set, the final network in that fold was trained on the whole training set and then was evaluated on the held-out test set of protein pairs (for detailed hyper-parameters see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S4</xref>). This design insured no interconnection between the pairs of gene products in the training and test data (i.e. no direct transitive inference between the protein pairs) while all protein pairs were tested. Despite the negligible variance in the results, for a solid conclusion, we repeated the permutation of proteins in every experiment 10 times and the average of all 100 runs was considered as the final result of that experiment.deepSimDEF networks learn low-dimensional vectors of GO terms and gene products, and then learn how to calculate the functional similarity of their pairs using these embedding vectors. The low-dimensional vectors of GO terms can be trained in advance by relying on natural language definitions of the GO terms and statistical measures of pointwise mutual information (PMI) and latent semantic analysis (LSA) applied to their result definition vectors (see Section 3 and <xref rid="btac304-B34" ref-type="bibr">Pesaranghader <italic toggle="yes">et al.</italic> (2013b</xref>, <xref rid="btac304-B37" ref-type="bibr">2019</xref>)). Once GO term LSA embeddings are pretrained, a deepSimDEF network can be initialized by these vectors and then be fine-tuned on training data of biological application of interest. The network design of the deepSimDEF model also takes into account multi-channel and single-channel architectures for combined and separate consideration of GO sub-ontologies respectively.</p>
      <table-wrap position="float" id="btac304-T1">
        <label>Table 1.</label>
        <caption>
          <p>Experiments and datasets used for the evaluation of FS measures</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="2" rowspan="1">Yeast dataset<hr/></th>
              <th colspan="2" rowspan="1">Human dataset<hr/></th>
              <th rowspan="1" colspan="1">Task</th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">No. of gene pairs</th>
              <th rowspan="1" colspan="1">No. of genes</th>
              <th rowspan="1" colspan="1">No. of gene pairs</th>
              <th rowspan="1" colspan="1">No. of genes</th>
              <th rowspan="1" colspan="1"/>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">PPI</td>
              <td rowspan="1" colspan="1">50 154</td>
              <td rowspan="1" colspan="1">4591</td>
              <td rowspan="1" colspan="1">65 542</td>
              <td rowspan="1" colspan="1">14 096</td>
              <td rowspan="1" colspan="1">PPI classification</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Sequence homology</td>
              <td rowspan="1" colspan="1">26 757</td>
              <td rowspan="1" colspan="1">3972</td>
              <td rowspan="1" colspan="1">381 379</td>
              <td rowspan="1" colspan="1">13 626</td>
              <td rowspan="1" colspan="1">Sequence similarity estimation</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Gene expression</td>
              <td rowspan="1" colspan="1">37 405</td>
              <td rowspan="1" colspan="1">2239</td>
              <td rowspan="1" colspan="1">62 470</td>
              <td rowspan="1" colspan="1">2361</td>
              <td rowspan="1" colspan="1">Level of co-expression redection</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>GO annotations that lack curation or experimental validation have the ‘Inferred from Electronic Annotation (IEA)’ evidence code that is assumed to be the lowest confidence (<xref rid="btac304-B27" ref-type="bibr">Mazandu <italic toggle="yes">et al.</italic>, 2017</xref>). In the context of GO semantic similarity measures, however, the use of all evidence codes including IEA has been shown to yield improved prediction accuracy (<xref rid="btac304-B52" ref-type="bibr">Tian <italic toggle="yes">et al.</italic>, 2020</xref>) as IEA annotations are becoming more and more accurate. Hence, following what is common in the literature, we explored both cases of including and excluding IEAs (IEA+ and IEA–, respectively) in our FS model evaluation. Additionally, we conducted negative control experiments (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S1</xref>) to investigate the effect of incorrect annotations of proteins on deepSimDEF model training.</p>
    </sec>
    <sec>
      <title>2.2 Semantic similarity of pretrained GO-term embeddings</title>
      <p>Our definition-based pretraining method organizes embeddings of the GO terms within the Euclidean space. Once initializing a network, these embeddings have the potential of putting the network in a proper state for model optimization, leading to faster convergence and more accurate predictions. For three random quarry GO terms from a pool of ∼30 000 pretrained biological process (BP) terms, <xref rid="btac304-T2" ref-type="table">Table 2</xref> shows the 5 top-most similar GO terms in terms of cosine similarity; and as expected, the returned GO terms are very close semantically. For cellular component (CC) and molecular function (MF), we observed the same behavior (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S2</xref>).</p>
      <table-wrap position="float" id="btac304-T2">
        <label>Table 2.</label>
        <caption>
          <p>Sense similarity results for three BP terms over pretrained embeddings</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Query</th>
              <th rowspan="1" colspan="1">GO term ID</th>
              <th rowspan="1" colspan="1">GO term name</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>Q#1</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>GO: 0072521</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>Purine-containing compound metabolic process</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">GO: 0072523</td>
              <td rowspan="1" colspan="1">Purine-containing compound catabolic process</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">GO: 0072527</td>
              <td rowspan="1" colspan="1">Pyrimidine-containing compound metabolic process</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">GO: 0072529</td>
              <td rowspan="1" colspan="1">Pyrimidine-containing compound catabolic process</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4</td>
              <td rowspan="1" colspan="1">GO: 0052803</td>
              <td rowspan="1" colspan="1">Imidazole-containing compound metabolic process</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">GO: 0046453</td>
              <td rowspan="1" colspan="1">Dipyrrin metabolic process</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>Q #2</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>GO: 0045292</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>mRNA cis splicing, via spliceosome</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">GO: 0000398</td>
              <td rowspan="1" colspan="1">mRNA splicing, via spliceosome</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">GO: 0048024</td>
              <td rowspan="1" colspan="1">Regulation of mRNA splicing, via spliceosome</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">GO: 0000380</td>
              <td rowspan="1" colspan="1">Alternative mRNA splicing, via spliceosome</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4</td>
              <td rowspan="1" colspan="1">GO: 0090615</td>
              <td rowspan="1" colspan="1">Mitochondrial mRNA processing</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">GO: 0000395</td>
              <td rowspan="1" colspan="1">mRNA 5′-splice site recognition</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">
                <bold>Q #3</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>GO: 0001116</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>Protein-DNA–RNA complex assembly</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">GO: 0001115</td>
              <td rowspan="1" colspan="1">Protein–DNA–RNA complex subunit organization</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">GO: 0001117</td>
              <td rowspan="1" colspan="1">Protein–DNA–RNA complex disassembly</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">GO: 0071165</td>
              <td rowspan="1" colspan="1">GINS complex assembly</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4</td>
              <td rowspan="1" colspan="1">GO: 0071824</td>
              <td rowspan="1" colspan="1">Protein–DNA complex subunit organization</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">GO: 0032986</td>
              <td rowspan="1" colspan="1">Protein–DNA complex disassembly</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>2.3 Prediction of PPIs</title>
      <p>Protein–protein interactions play a key role in various aspects of the structural and functional organization of the cell and their knowledge provides insights into the molecular mechanisms of biological processes that lead to rational drug design (<xref rid="btac304-B29" ref-type="bibr">Murakami <italic toggle="yes">et al.</italic>, 2017</xref>). It has been shown that the FS values can be employed as an indicator for the plausibility of putative PPIs (<xref rid="btac304-B59" ref-type="bibr">Zhang and Tang, 2016</xref>).</p>
      <p>Similar to other studies, we formulated this as a classification problem and examined how well a deepSimDEF network predicted true PPIs. We directly interpreted FS values as the classification probability of ‘Interaction’ and ‘No Interaction’. <xref rid="btac304-T3" ref-type="table">Table 3</xref> for yeast PPI data and <xref rid="btac304-T4" ref-type="table">Table 4</xref> for human PPI data demonstrate the results of predictions for deepSimDEF and other FS similarity measures with respect to F1-scores. Among the SS aggregation metrics used in the previous studies, MAX yielded the highest PPI prediction results, so we considered this metric in our evaluation.</p>
      <table-wrap position="float" id="btac304-T3">
        <label>Table 3.</label>
        <caption>
          <p>PPI F1-score prediction of the yeast data (FS aggregation uses MAX)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="4" align="center" rowspan="1">Including IEA (%)<hr/></th>
              <th colspan="4" align="center" rowspan="1">Excluding IEA (%)<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Resnik</td>
              <td rowspan="1" colspan="1">87.29</td>
              <td rowspan="1" colspan="1">85.65</td>
              <td rowspan="1" colspan="1">81.57</td>
              <td rowspan="1" colspan="1">74.06</td>
              <td rowspan="1" colspan="1">86.91</td>
              <td rowspan="1" colspan="1">83.28</td>
              <td rowspan="1" colspan="1">79.96</td>
              <td rowspan="1" colspan="1">72.00</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Lin</td>
              <td rowspan="1" colspan="1">78.75</td>
              <td rowspan="1" colspan="1">85.53</td>
              <td rowspan="1" colspan="1">79.12</td>
              <td rowspan="1" colspan="1">73.37</td>
              <td rowspan="1" colspan="1">81.24</td>
              <td rowspan="1" colspan="1">82.68</td>
              <td rowspan="1" colspan="1">77.44</td>
              <td rowspan="1" colspan="1">73.47</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Jiang and Conrath</td>
              <td rowspan="1" colspan="1">78.75</td>
              <td rowspan="1" colspan="1">84.77</td>
              <td rowspan="1" colspan="1">79.06</td>
              <td rowspan="1" colspan="1">72.26</td>
              <td rowspan="1" colspan="1">80.79</td>
              <td rowspan="1" colspan="1">81.27</td>
              <td rowspan="1" colspan="1">76.65</td>
              <td rowspan="1" colspan="1">74.11</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GraSM</td>
              <td rowspan="1" colspan="1">87.55</td>
              <td rowspan="1" colspan="1">85.33</td>
              <td rowspan="1" colspan="1">81.35</td>
              <td rowspan="1" colspan="1">74.16</td>
              <td rowspan="1" colspan="1">86.83</td>
              <td rowspan="1" colspan="1">83.26</td>
              <td rowspan="1" colspan="1">80.08</td>
              <td rowspan="1" colspan="1">72.16</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AIC</td>
              <td rowspan="1" colspan="1">78.39</td>
              <td rowspan="1" colspan="1">85.71</td>
              <td rowspan="1" colspan="1">79.13</td>
              <td rowspan="1" colspan="1">72.99</td>
              <td rowspan="1" colspan="1">81.18</td>
              <td rowspan="1" colspan="1">82.40</td>
              <td rowspan="1" colspan="1">77.70</td>
              <td rowspan="1" colspan="1">73.73</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">clusteredGO</td>
              <td rowspan="1" colspan="1">78.98</td>
              <td rowspan="1" colspan="1">84.70</td>
              <td rowspan="1" colspan="1">78.93</td>
              <td rowspan="1" colspan="1">72.68</td>
              <td rowspan="1" colspan="1">80.92</td>
              <td rowspan="1" colspan="1">81.13</td>
              <td rowspan="1" colspan="1">76.59</td>
              <td rowspan="1" colspan="1">74.59</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simGIC</td>
              <td rowspan="1" colspan="1">68.22</td>
              <td rowspan="1" colspan="1">63.31</td>
              <td rowspan="1" colspan="1">61.56</td>
              <td rowspan="1" colspan="1">59.27</td>
              <td rowspan="1" colspan="1">67.84</td>
              <td rowspan="1" colspan="1">62.52</td>
              <td rowspan="1" colspan="1">61.22</td>
              <td rowspan="1" colspan="1">58.62</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simDEF</td>
              <td rowspan="1" colspan="1">88.56</td>
              <td rowspan="1" colspan="1">86.74</td>
              <td rowspan="1" colspan="1">82.67</td>
              <td rowspan="1" colspan="1">75.42</td>
              <td rowspan="1" colspan="1">88.38</td>
              <td rowspan="1" colspan="1">84.45</td>
              <td rowspan="1" colspan="1">81.43</td>
              <td rowspan="1" colspan="1">74.31</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AicInferSentGO</td>
              <td rowspan="1" colspan="1">88.61</td>
              <td rowspan="1" colspan="1">86.71</td>
              <td rowspan="1" colspan="1">82.75</td>
              <td rowspan="1" colspan="1">75.47</td>
              <td rowspan="1" colspan="1">88.31</td>
              <td rowspan="1" colspan="1">84.38</td>
              <td rowspan="1" colspan="1">81.28</td>
              <td rowspan="1" colspan="1">74.36</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (random emb.)</td>
              <td rowspan="1" colspan="1">90.05</td>
              <td rowspan="1" colspan="1">88.88</td>
              <td rowspan="1" colspan="1">88.08</td>
              <td rowspan="1" colspan="1">84.77</td>
              <td rowspan="1" colspan="1">90.07</td>
              <td rowspan="1" colspan="1">86.71</td>
              <td rowspan="1" colspan="1">86.45</td>
              <td rowspan="1" colspan="1">83.57</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (LSA emb.)</td>
              <td rowspan="1" colspan="1">92.78</td>
              <td rowspan="1" colspan="1">91.57</td>
              <td rowspan="1" colspan="1">89.58</td>
              <td rowspan="1" colspan="1">87.64</td>
              <td rowspan="1" colspan="1">92.99</td>
              <td rowspan="1" colspan="1">91.68</td>
              <td rowspan="1" colspan="1">89.35</td>
              <td rowspan="1" colspan="1">86.69</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap position="float" id="btac304-T4">
        <label>Table 4.</label>
        <caption>
          <p>PPI F1-score prediction of the human data (FS aggregation uses MAX)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th colspan="4" align="center" rowspan="1">Including IEA (%)<hr/></th>
              <th colspan="4" align="center" rowspan="1">Excluding IEA (%)<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Resnik</td>
              <td rowspan="1" colspan="1">88.02</td>
              <td rowspan="1" colspan="1">86.59</td>
              <td rowspan="1" colspan="1">81.70</td>
              <td rowspan="1" colspan="1">75.14</td>
              <td rowspan="1" colspan="1">87.96</td>
              <td rowspan="1" colspan="1">84.33</td>
              <td rowspan="1" colspan="1">80.60</td>
              <td rowspan="1" colspan="1">73.31</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Lin</td>
              <td rowspan="1" colspan="1">79.02</td>
              <td rowspan="1" colspan="1">85.69</td>
              <td rowspan="1" colspan="1">79.62</td>
              <td rowspan="1" colspan="1">73.88</td>
              <td rowspan="1" colspan="1">81.88</td>
              <td rowspan="1" colspan="1">82.87</td>
              <td rowspan="1" colspan="1">77.58</td>
              <td rowspan="1" colspan="1">73.57</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Jiang and Conrath</td>
              <td rowspan="1" colspan="1">79.48</td>
              <td rowspan="1" colspan="1">85.47</td>
              <td rowspan="1" colspan="1">79.72</td>
              <td rowspan="1" colspan="1">72.82</td>
              <td rowspan="1" colspan="1">81.35</td>
              <td rowspan="1" colspan="1">81.45</td>
              <td rowspan="1" colspan="1">77.57</td>
              <td rowspan="1" colspan="1">74.81</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GraSM</td>
              <td rowspan="1" colspan="1">87.97</td>
              <td rowspan="1" colspan="1">86.58</td>
              <td rowspan="1" colspan="1">81.83</td>
              <td rowspan="1" colspan="1">75.12</td>
              <td rowspan="1" colspan="1">87.59</td>
              <td rowspan="1" colspan="1">83.53</td>
              <td rowspan="1" colspan="1">80.38</td>
              <td rowspan="1" colspan="1">73.02</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AIC</td>
              <td rowspan="1" colspan="1">79.78</td>
              <td rowspan="1" colspan="1">86.05</td>
              <td rowspan="1" colspan="1">79.37</td>
              <td rowspan="1" colspan="1">74.10</td>
              <td rowspan="1" colspan="1">81.52</td>
              <td rowspan="1" colspan="1">83.50</td>
              <td rowspan="1" colspan="1">77.66</td>
              <td rowspan="1" colspan="1">73.69</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">clusteredGO</td>
              <td rowspan="1" colspan="1">79.15</td>
              <td rowspan="1" colspan="1">84.94</td>
              <td rowspan="1" colspan="1">80.05</td>
              <td rowspan="1" colspan="1">72.53</td>
              <td rowspan="1" colspan="1">81.03</td>
              <td rowspan="1" colspan="1">82.21</td>
              <td rowspan="1" colspan="1">76.96</td>
              <td rowspan="1" colspan="1">74.45</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simGIC</td>
              <td rowspan="1" colspan="1">69.33</td>
              <td rowspan="1" colspan="1">64.19</td>
              <td rowspan="1" colspan="1">62.34</td>
              <td rowspan="1" colspan="1">60.66</td>
              <td rowspan="1" colspan="1">69.16</td>
              <td rowspan="1" colspan="1">63.56</td>
              <td rowspan="1" colspan="1">62.47</td>
              <td rowspan="1" colspan="1">59.32</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simDEF</td>
              <td rowspan="1" colspan="1">88.74</td>
              <td rowspan="1" colspan="1">87.12</td>
              <td rowspan="1" colspan="1">82.72</td>
              <td rowspan="1" colspan="1">76.19</td>
              <td rowspan="1" colspan="1">88.53</td>
              <td rowspan="1" colspan="1">85.12</td>
              <td rowspan="1" colspan="1">81.24</td>
              <td rowspan="1" colspan="1">74.21</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AicInferSentGO</td>
              <td rowspan="1" colspan="1">88.83</td>
              <td rowspan="1" colspan="1">87.14</td>
              <td rowspan="1" colspan="1">82.04</td>
              <td rowspan="1" colspan="1">75.96</td>
              <td rowspan="1" colspan="1">88.31</td>
              <td rowspan="1" colspan="1">84.54</td>
              <td rowspan="1" colspan="1">81.04</td>
              <td rowspan="1" colspan="1">74.45</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (random emb.)</td>
              <td rowspan="1" colspan="1">90.69</td>
              <td rowspan="1" colspan="1">87.63</td>
              <td rowspan="1" colspan="1">86.71</td>
              <td rowspan="1" colspan="1">85.13</td>
              <td rowspan="1" colspan="1">89.91</td>
              <td rowspan="1" colspan="1">87.12</td>
              <td rowspan="1" colspan="1">86.51</td>
              <td rowspan="1" colspan="1">84.54</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (LSA emb.)</td>
              <td rowspan="1" colspan="1">93.68</td>
              <td rowspan="1" colspan="1">90.60</td>
              <td rowspan="1" colspan="1">89.12</td>
              <td rowspan="1" colspan="1">87.80</td>
              <td rowspan="1" colspan="1">93.12</td>
              <td rowspan="1" colspan="1">90.19</td>
              <td rowspan="1" colspan="1">88.26</td>
              <td rowspan="1" colspan="1">87.38</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>In yeast PPI prediction, single-channel BP deepSimDEF, when initialized with LSA embeddings, achieved an F1-score improvement of ∼5% compared to the second-best methods, AicInferSentGO and simDEF (∼8.5% on average for BP, CC, and MF). With multi-channel deepSimDEF architecture, we observed a further increase of ∼1.25% compared to a single-channel deepSimDEF network of BP, which yielded the best results among the three single channels. This indicates consideration of all three sub-ontologies together increases PPI predictability. clusteredGO did not improve the results of Resnik or any other earlier IC-based FS measures, whereas the group-wise simGIC represented the worst performance among the evaluated FS measures. Comparing vector-based simDEF with AicInferSentGO, we observed similar results as expected due to their definition-based nature. Additionally, including IEA GO term annotations did not improve yeast PPI prediction.</p>
      <p>For human PPI prediction, we observed slight improvements for almost all cases when including IEAs. The other results were consistent with our observations from the yeast PPI prediction; for example, working with single GO ontologies, BP showed better predictive power compared to CC and MF. However, when BP was combined with the other two we achieved higher F1-scores; the multi-channel deepSimDEF outperformed all FS measures including AicInferSentGO, the second-best model (93.68% versus 88.83%). Compared to random initialization of deepSimDEF we obtained a ∼3% improvement in F1-score when the embedding layer was initialized with our LSA embeddings. deepSimDEF with random weights, however, outperformed all baselines in the same category.</p>
      <p>In order to verify that the method uses GO term vector similarities that are highly indicative of functional similarity, we further investigated if the characterization of proteins with low-level GO terms leads to better FS prediction of proteins. For this purpose, in separate experiments, we replaced the GO annotation of the proteins with their higher-level GO terms such as their parents and their grandparents, and then trained and tested the networks. For human data, when only MF was considered, the PPI prediction decreased from 87.80% to 85.36% and 82.97% for parent and grandparent considerations, respectively. This could be explained by the underspecification of given pairs with broader terms. For instance, the deepSimDEF network was able to correctly predict the interaction of P27695 and HMGB2 proteins with their original low-level GO-term annotations of GO: 0003691 (double-stranded telomeric DNA binding) and GO: 0000976 (transcription cis-regulatory region binding). Once these annotations were replaced by the broader GO terms such as GO: 0003677 (DNA binding) the networks estimated a lower probability of their interaction. We observed similar behavior for other sub-ontologies.</p>
    </sec>
    <sec>
      <title>2.4 Correlation with sequence similarity</title>
      <p>Proteins with similar sequences are usually homologous and tend to have similar functions (<xref rid="btac304-B9" ref-type="bibr">Cozzetto and Jones, 2017</xref>). For that reason, proteins in a newly sequenced genome are routinely annotated using the sequences of similar proteins in genomes of other species. Even though not always functional and sequence similarity tracks well (<xref rid="btac304-B45" ref-type="bibr">Schlicker <italic toggle="yes">et al.</italic>, 2007</xref>) information from sequence-similarity networks offers a powerful way to highlight where a potential manual or electronic GO misannotation may occur (<xref rid="btac304-B10" ref-type="bibr">Dessimoz and Škunca, 2017</xref>). Hence, correlation with sequence similarity data sets a benchmark for the evaluation of GO-based FS measures (<xref rid="btac304-B25" ref-type="bibr">Lord <italic toggle="yes">et al.</italic>, 2003</xref>).</p>
      <p>Every gene pair in our sequence homology data is accompanied by the log-reciprocal (LRBS) and relative reciprocal (RRBS) BLAST scores indicating the level of sequence similarity of their component genes (see Evaluation and validation datasets section for the LRBS and RRBS details). <xref rid="btac304-B41" ref-type="bibr">Pesquita <italic toggle="yes">et al.</italic> (2008)</xref> noted that the relationship between semantically derived shared information from GO and RRBS is non-linear. Therefore, in our experiment with sequence data, the results of non-linear Spearman’s correlations were primarily considered for the evaluation of the FS measures (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S3</xref> for Pearson’s correlation). Additionally, in the baseline FS measures, MAX and BMA metrics showed inconsistency in their correlation with sequence homology data as depending on the measure and sub-ontology of choice one metric worked better than the other, therefore both of these aggregation metrics were considered in our evaluation.</p>
      <p><xref rid="btac304-T5" ref-type="table">Table 5</xref> shows deepSimDEF outperformed other FS measures in the correlation task with the yeast sequence homology data: on average, the initialized single-channel deepSimDEF improved the correlation results by ∼5.5% for LRBS, and &gt;7% for RRBS. Compared to IC-based measures, distributional definition-based measures consistently showed higher accuracy. When all sub-ontologies were combined, the multi-channel deepSimDEF improved the FS results even more by at least 3% (&gt;7% and &gt;8% compared to the second-best measures from AicInferSentGO and simDEF in BP for LRBS and RRBS, respectively). In baseline models, in contrast to PPI experiments, the combination of sub-ontologies for the correlation computation between FS measures and sequence homology data reduced the correlation results. For deepSimDEF, however, it was otherwise indicating that the gating mechanism in the highway layer of the network (described in Section 3, Highway layer subsection) helps to learn how the shared information of two proteins should be computed (see additional results in <xref rid="sup1" ref-type="supplementary-material">Supplementary material S1</xref>). Similar to PPI experiments still, initialization of the networks with LSA embeddings improved the correlation results (∼6% improvement for LRBS and ∼2.5% for RRBS on average, when compared with random weight initialization).</p>
      <table-wrap position="float" id="btac304-T5">
        <label>Table 5.</label>
        <caption>
          <p>Spearman correlation of FS measures versus yeast sequence homology</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1"/>
              <th rowspan="2" colspan="1"/>
              <th colspan="4" rowspan="1">LRBS<hr/></th>
              <th colspan="4" rowspan="1">RRBS<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Resnik</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.7089</td>
              <td rowspan="1" colspan="1">0.7269</td>
              <td rowspan="1" colspan="1">0.5337</td>
              <td rowspan="1" colspan="1">0.4743</td>
              <td rowspan="1" colspan="1">0.6088</td>
              <td rowspan="1" colspan="1">0.6378</td>
              <td rowspan="1" colspan="1">0.5132</td>
              <td rowspan="1" colspan="1">0.3514</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.6066</td>
              <td rowspan="1" colspan="1">0.5862</td>
              <td rowspan="1" colspan="1">0.4771</td>
              <td rowspan="1" colspan="1">0.5193</td>
              <td rowspan="1" colspan="1">0.5236</td>
              <td rowspan="1" colspan="1">0.5312</td>
              <td rowspan="1" colspan="1">0.4752</td>
              <td rowspan="1" colspan="1">0.4278</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Lin</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3831</td>
              <td rowspan="1" colspan="1">0.6463</td>
              <td rowspan="1" colspan="1">0.3763</td>
              <td rowspan="1" colspan="1">0.6026</td>
              <td rowspan="1" colspan="1">0.2512</td>
              <td rowspan="1" colspan="1">0.4900</td>
              <td rowspan="1" colspan="1">0.2892</td>
              <td rowspan="1" colspan="1">0.4085</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.5952</td>
              <td rowspan="1" colspan="1">0.5756</td>
              <td rowspan="1" colspan="1">0.4490</td>
              <td rowspan="1" colspan="1">0.5866</td>
              <td rowspan="1" colspan="1">0.4862</td>
              <td rowspan="1" colspan="1">0.4919</td>
              <td rowspan="1" colspan="1">0.4048</td>
              <td rowspan="1" colspan="1">0.4478</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Jiang and Conrath</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3500</td>
              <td rowspan="1" colspan="1">0.6504</td>
              <td rowspan="1" colspan="1">0.2997</td>
              <td rowspan="1" colspan="1">0.4975</td>
              <td rowspan="1" colspan="1">0.1814</td>
              <td rowspan="1" colspan="1">0.5030</td>
              <td rowspan="1" colspan="1">0.2325</td>
              <td rowspan="1" colspan="1">0.2845</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.6190</td>
              <td rowspan="1" colspan="1">0.6298</td>
              <td rowspan="1" colspan="1">0.4733</td>
              <td rowspan="1" colspan="1">0.5595</td>
              <td rowspan="1" colspan="1">0.4958</td>
              <td rowspan="1" colspan="1">0.5317</td>
              <td rowspan="1" colspan="1">0.4126</td>
              <td rowspan="1" colspan="1">0.3978</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GraSM</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3465</td>
              <td rowspan="1" colspan="1">0.6584</td>
              <td rowspan="1" colspan="1">0.2978</td>
              <td rowspan="1" colspan="1">0.4895</td>
              <td rowspan="1" colspan="1">0.1799</td>
              <td rowspan="1" colspan="1">0.5002</td>
              <td rowspan="1" colspan="1">0.2231</td>
              <td rowspan="1" colspan="1">0.2911</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.6277</td>
              <td rowspan="1" colspan="1">0.6258</td>
              <td rowspan="1" colspan="1">0.4659</td>
              <td rowspan="1" colspan="1">0.5651</td>
              <td rowspan="1" colspan="1">0.4990</td>
              <td rowspan="1" colspan="1">0.5240</td>
              <td rowspan="1" colspan="1">0.4154</td>
              <td rowspan="1" colspan="1">0.3944</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AIC</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3434</td>
              <td rowspan="1" colspan="1">0.6423</td>
              <td rowspan="1" colspan="1">0.3094</td>
              <td rowspan="1" colspan="1">0.5044</td>
              <td rowspan="1" colspan="1">0.1873</td>
              <td rowspan="1" colspan="1">0.5099</td>
              <td rowspan="1" colspan="1">0.2275</td>
              <td rowspan="1" colspan="1">0.2927</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.6197</td>
              <td rowspan="1" colspan="1">0.6215</td>
              <td rowspan="1" colspan="1">0.4727</td>
              <td rowspan="1" colspan="1">0.5694</td>
              <td rowspan="1" colspan="1">0.5028</td>
              <td rowspan="1" colspan="1">0.5348</td>
              <td rowspan="1" colspan="1">0.4047</td>
              <td rowspan="1" colspan="1">0.3920</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">clusteredGO</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3591</td>
              <td rowspan="1" colspan="1">0.6449</td>
              <td rowspan="1" colspan="1">0.3027</td>
              <td rowspan="1" colspan="1">0.4970</td>
              <td rowspan="1" colspan="1">0.1720</td>
              <td rowspan="1" colspan="1">0.5061</td>
              <td rowspan="1" colspan="1">0.2277</td>
              <td rowspan="1" colspan="1">0.2865</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.6198</td>
              <td rowspan="1" colspan="1">0.6282</td>
              <td rowspan="1" colspan="1">0.4784</td>
              <td rowspan="1" colspan="1">0.5504</td>
              <td rowspan="1" colspan="1">0.4998</td>
              <td rowspan="1" colspan="1">0.5237</td>
              <td rowspan="1" colspan="1">0.4081</td>
              <td rowspan="1" colspan="1">0.3917</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simGIC</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.3140</td>
              <td rowspan="1" colspan="1">0.6036</td>
              <td rowspan="1" colspan="1">0.2519</td>
              <td rowspan="1" colspan="1">0.4404</td>
              <td rowspan="1" colspan="1">0.1237</td>
              <td rowspan="1" colspan="1">0.4643</td>
              <td rowspan="1" colspan="1">0.1703</td>
              <td rowspan="1" colspan="1">0.2296</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simDEF</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.4505</td>
              <td rowspan="1" colspan="1">0.7339</td>
              <td rowspan="1" colspan="1">0.4082</td>
              <td rowspan="1" colspan="1">0.5946</td>
              <td rowspan="1" colspan="1">0.2770</td>
              <td rowspan="1" colspan="1">0.6126</td>
              <td rowspan="1" colspan="1">0.3396</td>
              <td rowspan="1" colspan="1">0.3845</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.7252</td>
              <td rowspan="1" colspan="1">0.7308</td>
              <td rowspan="1" colspan="1">0.5661</td>
              <td rowspan="1" colspan="1">0.6637</td>
              <td rowspan="1" colspan="1">0.5974</td>
              <td rowspan="1" colspan="1">0.6418</td>
              <td rowspan="1" colspan="1">0.5079</td>
              <td rowspan="1" colspan="1">0.4880</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AicInferSentGO</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.4499</td>
              <td rowspan="1" colspan="1">0.7314</td>
              <td rowspan="1" colspan="1">0.4073</td>
              <td rowspan="1" colspan="1">0.6018</td>
              <td rowspan="1" colspan="1">0.2886</td>
              <td rowspan="1" colspan="1">0.5996</td>
              <td rowspan="1" colspan="1">0.3289</td>
              <td rowspan="1" colspan="1">0.3841</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.7252</td>
              <td rowspan="1" colspan="1">0.7354</td>
              <td rowspan="1" colspan="1">0.5775</td>
              <td rowspan="1" colspan="1">0.6681</td>
              <td rowspan="1" colspan="1">0.6049</td>
              <td rowspan="1" colspan="1">0.6412</td>
              <td rowspan="1" colspan="1">0.5220</td>
              <td rowspan="1" colspan="1">0.5076</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (random emb.)</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.7590</td>
              <td rowspan="1" colspan="1">0.6600</td>
              <td rowspan="1" colspan="1">0.5918</td>
              <td rowspan="1" colspan="1">0.7102</td>
              <td rowspan="1" colspan="1">0.6813</td>
              <td rowspan="1" colspan="1">0.6050</td>
              <td rowspan="1" colspan="1">0.5438</td>
              <td rowspan="1" colspan="1">0.6846</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (LSA emb.)</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.8078</td>
              <td rowspan="1" colspan="1">0.7532</td>
              <td rowspan="1" colspan="1">0.6077</td>
              <td rowspan="1" colspan="1">0.7844</td>
              <td rowspan="1" colspan="1">0.7255</td>
              <td rowspan="1" colspan="1">0.6498</td>
              <td rowspan="1" colspan="1">0.5409</td>
              <td rowspan="1" colspan="1">0.6943</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p><xref rid="btac304-T6" ref-type="table">Table 6</xref> shows Spearman correlation results between human LRBS and RRBS and FS measures. While the results were generally consistent with the yeast experiment findings, including that deepSimDEF outperformed all baselines with considerable margins of improvement (&gt;7% and ∼6% compared to the second-best measure simDEF in MF for LRBS and RRBS, respectively), correlation values were less than what we achieved in the yeast experiment, which is not surprising considering the extent of the human genome and the complexity of human sequence homology data. Also, while in the yeast experiment BP yielded better results for the baseline measures, we observed that for human data it was the MF that was superior. For deepSimDEF, in both human and yeast, MF outperformed the other two sub-ontologies, yet fell short when they were combined. That is explainable as homologs are more likely to have similar functions (e.g. catalyze similar reactions) than participate in the same biological process. Also for both yeast and human sequence homology data, for Spearman’s correlation, FS measures correlated with LRBS better than RRBS.</p>
      <table-wrap position="float" id="btac304-T6">
        <label>Table 6.</label>
        <caption>
          <p>Spearman correlation of FS measures versus human sequence homology</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1"/>
              <th rowspan="2" colspan="1"/>
              <th colspan="4" rowspan="1">LRBS<hr/></th>
              <th colspan="4" rowspan="1">RRBS<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
              <th rowspan="1" colspan="1">ALL</th>
              <th rowspan="1" colspan="1">BP</th>
              <th rowspan="1" colspan="1">CC</th>
              <th rowspan="1" colspan="1">MF</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Resnik</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.4941</td>
              <td rowspan="1" colspan="1">0.4768</td>
              <td rowspan="1" colspan="1">0.2531</td>
              <td rowspan="1" colspan="1">0.5834</td>
              <td rowspan="1" colspan="1">0.4530</td>
              <td rowspan="1" colspan="1">0.4605</td>
              <td rowspan="1" colspan="1">0.2962</td>
              <td rowspan="1" colspan="1">0.5222</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.5095</td>
              <td rowspan="1" colspan="1">0.4606</td>
              <td rowspan="1" colspan="1">0.3288</td>
              <td rowspan="1" colspan="1">0.5262</td>
              <td rowspan="1" colspan="1">0.5196</td>
              <td rowspan="1" colspan="1">0.4525</td>
              <td rowspan="1" colspan="1">0.4212</td>
              <td rowspan="1" colspan="1">0.5332</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Lin</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3087</td>
              <td rowspan="1" colspan="1">0.5149</td>
              <td rowspan="1" colspan="1">0.3500</td>
              <td rowspan="1" colspan="1">0.3231</td>
              <td rowspan="1" colspan="1">0.2820</td>
              <td rowspan="1" colspan="1">0.5065</td>
              <td rowspan="1" colspan="1">0.3374</td>
              <td rowspan="1" colspan="1">0.2789</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.5052</td>
              <td rowspan="1" colspan="1">0.5081</td>
              <td rowspan="1" colspan="1">0.3970</td>
              <td rowspan="1" colspan="1">0.3777</td>
              <td rowspan="1" colspan="1">0.5278</td>
              <td rowspan="1" colspan="1">0.5035</td>
              <td rowspan="1" colspan="1">0.4618</td>
              <td rowspan="1" colspan="1">0.4194</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Jiang and Conrath</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.2933</td>
              <td rowspan="1" colspan="1">0.4981</td>
              <td rowspan="1" colspan="1">0.2884</td>
              <td rowspan="1" colspan="1">0.3734</td>
              <td rowspan="1" colspan="1">0.2153</td>
              <td rowspan="1" colspan="1">0.4865</td>
              <td rowspan="1" colspan="1">0.2531</td>
              <td rowspan="1" colspan="1">0.2730</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.4847</td>
              <td rowspan="1" colspan="1">0.5418</td>
              <td rowspan="1" colspan="1">0.3995</td>
              <td rowspan="1" colspan="1">0.3714</td>
              <td rowspan="1" colspan="1">0.5280</td>
              <td rowspan="1" colspan="1">0.5492</td>
              <td rowspan="1" colspan="1">0.4506</td>
              <td rowspan="1" colspan="1">0.3894</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GraSM</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.2841</td>
              <td rowspan="1" colspan="1">0.3787</td>
              <td rowspan="1" colspan="1">0.2909</td>
              <td rowspan="1" colspan="1">0.5071</td>
              <td rowspan="1" colspan="1">0.2148</td>
              <td rowspan="1" colspan="1">0.2713</td>
              <td rowspan="1" colspan="1">0.2617</td>
              <td rowspan="1" colspan="1">0.4876</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.4884</td>
              <td rowspan="1" colspan="1">0.3636</td>
              <td rowspan="1" colspan="1">0.3907</td>
              <td rowspan="1" colspan="1">0.5449</td>
              <td rowspan="1" colspan="1">0.5311</td>
              <td rowspan="1" colspan="1">0.3992</td>
              <td rowspan="1" colspan="1">0.4517</td>
              <td rowspan="1" colspan="1">0.5403</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AIC</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.2931</td>
              <td rowspan="1" colspan="1">0.3650</td>
              <td rowspan="1" colspan="1">0.2797</td>
              <td rowspan="1" colspan="1">0.4952</td>
              <td rowspan="1" colspan="1">0.2146</td>
              <td rowspan="1" colspan="1">0.2655</td>
              <td rowspan="1" colspan="1">0.2449</td>
              <td rowspan="1" colspan="1">0.4941</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.4875</td>
              <td rowspan="1" colspan="1">0.3737</td>
              <td rowspan="1" colspan="1">0.4089</td>
              <td rowspan="1" colspan="1">0.5514</td>
              <td rowspan="1" colspan="1">0.5247</td>
              <td rowspan="1" colspan="1">0.3923</td>
              <td rowspan="1" colspan="1">0.4483</td>
              <td rowspan="1" colspan="1">0.5563</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">clusteredGO</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.2944</td>
              <td rowspan="1" colspan="1">0.3830</td>
              <td rowspan="1" colspan="1">0.2788</td>
              <td rowspan="1" colspan="1">0.4927</td>
              <td rowspan="1" colspan="1">0.2101</td>
              <td rowspan="1" colspan="1">0.2735</td>
              <td rowspan="1" colspan="1">0.2589</td>
              <td rowspan="1" colspan="1">0.4840</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.4918</td>
              <td rowspan="1" colspan="1">0.3731</td>
              <td rowspan="1" colspan="1">0.3960</td>
              <td rowspan="1" colspan="1">0.5330</td>
              <td rowspan="1" colspan="1">0.5271</td>
              <td rowspan="1" colspan="1">0.3801</td>
              <td rowspan="1" colspan="1">0.4575</td>
              <td rowspan="1" colspan="1">0.5561</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simGIC</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.2356</td>
              <td rowspan="1" colspan="1">0.3296</td>
              <td rowspan="1" colspan="1">0.2307</td>
              <td rowspan="1" colspan="1">0.4472</td>
              <td rowspan="1" colspan="1">0.1530</td>
              <td rowspan="1" colspan="1">0.2279</td>
              <td rowspan="1" colspan="1">0.2013</td>
              <td rowspan="1" colspan="1">0.4281</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">simDEF</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3505</td>
              <td rowspan="1" colspan="1">0.4383</td>
              <td rowspan="1" colspan="1">0.3578</td>
              <td rowspan="1" colspan="1">0.5528</td>
              <td rowspan="1" colspan="1">0.2850</td>
              <td rowspan="1" colspan="1">0.3374</td>
              <td rowspan="1" colspan="1">0.3129</td>
              <td rowspan="1" colspan="1">0.5412</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.5541</td>
              <td rowspan="1" colspan="1">0.4335</td>
              <td rowspan="1" colspan="1">0.4320</td>
              <td rowspan="1" colspan="1">0.6011</td>
              <td rowspan="1" colspan="1">0.5823</td>
              <td rowspan="1" colspan="1">0.4446</td>
              <td rowspan="1" colspan="1">0.4956</td>
              <td rowspan="1" colspan="1">0.5944</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">AicInferSentGO</td>
              <td rowspan="1" colspan="1">MAX</td>
              <td rowspan="1" colspan="1">0.3574</td>
              <td rowspan="1" colspan="1">0.4387</td>
              <td rowspan="1" colspan="1">0.3428</td>
              <td rowspan="1" colspan="1">0.5515</td>
              <td rowspan="1" colspan="1">0.2723</td>
              <td rowspan="1" colspan="1">0.3288</td>
              <td rowspan="1" colspan="1">0.3138</td>
              <td rowspan="1" colspan="1">0.5430</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">BMA</td>
              <td rowspan="1" colspan="1">0.5440</td>
              <td rowspan="1" colspan="1">0.4250</td>
              <td rowspan="1" colspan="1">0.4383</td>
              <td rowspan="1" colspan="1">0.6011</td>
              <td rowspan="1" colspan="1">0.5897</td>
              <td rowspan="1" colspan="1">0.4522</td>
              <td rowspan="1" colspan="1">0.4956</td>
              <td rowspan="1" colspan="1">0.5927</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (random emb.)</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.6437</td>
              <td rowspan="1" colspan="1">0.5241</td>
              <td rowspan="1" colspan="1">0.4232</td>
              <td rowspan="1" colspan="1">0.6268</td>
              <td rowspan="1" colspan="1">0.6425</td>
              <td rowspan="1" colspan="1">0.5222</td>
              <td rowspan="1" colspan="1">0.4986</td>
              <td rowspan="1" colspan="1">0.6346</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">deepSimDEF (LSA emb.)</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">0.6723</td>
              <td rowspan="1" colspan="1">0.5300</td>
              <td rowspan="1" colspan="1">0.4480</td>
              <td rowspan="1" colspan="1">0.6623</td>
              <td rowspan="1" colspan="1">0.6514</td>
              <td rowspan="1" colspan="1">0.5306</td>
              <td rowspan="1" colspan="1">0.5126</td>
              <td rowspan="1" colspan="1">0.6432</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>2.5 Correlation with gene expression</title>
      <p>Highly correlated gene expression levels are often seen when genes are functionally related and participate in the same biological processes. Previous studies evaluated the performance of their FS measures by calculating the correlation between their estimations and gene-expression data (<xref rid="btac304-B5" ref-type="bibr">Bible <italic toggle="yes">et al.</italic>, 2017</xref>).</p>
      <p><xref rid="btac304-B55" ref-type="bibr">Wu <italic toggle="yes">et al.</italic> (2013)</xref> achieved poor correlations between their GO-based FS measure and gene expression from microarray data of yeast and human. They argued that the inconsistent results experienced in the previous studies indicate the correlations between GO-based FS measures and gene co-expression data are sensitive to the source of data and method of evaluation. Similar to <xref rid="btac304-B54" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> (2007)</xref>, however, we argue that this inconsistency stems from the inherent complexity of the gene expression datasets, and the fact that there exists no direct correlation between GO annotations and co-expression levels that one ideal GO-based FS measure can completely discover. We hypothesize though that deep neural networks have the potential to accommodate this non-linear complexity and discover the underlying inner dependency to the greatest degree possible.</p>
      <p>In our evaluation (shown in <xref rid="btac304-F1" ref-type="fig">Fig. 1</xref> for yeast experiment and <xref rid="btac304-F2" ref-type="fig">Fig. 2</xref> for human experiment), the Pearson’s correlation coefficients between the GO-based FS measures and the actual gene co-expression data were studied (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S3</xref> for the exact values including Spearman’s correlation). We considered both MAX and BMA aggregation metrics in our evaluation.</p>
      <fig position="float" id="btac304-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Pearson’s correlation results for the prediction of gene–gene co-expressions in yeast data</p>
        </caption>
        <graphic xlink:href="btac304f1" position="float"/>
      </fig>
      <fig position="float" id="btac304-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Pearson’s correlation results for the prediction of gene–gene co-expressions in human data</p>
        </caption>
        <graphic xlink:href="btac304f2" position="float"/>
      </fig>
      <p>We observed significantly higher correlation results for the prediction of yeast gene co-expression values relative to human values across all FS measures, which was expected given the differences in organism complexity (unicellular versus multi-cellular eukaryotes). This could also be explained by the smaller number of yeast genes leading to less complexity of co-expression patterns to discover and learn from in the training phase.</p>
      <p>For the yeast experiment, initialized deepSimDEF was the best-performing FS measure. Single-channel deepSimDEF networks improved Pearson’s correlation with the co-expression data by &gt;11% (average over all three GO sub-ontologies’) compared to the second-best results achieved by simDEF and AicInferSentGO (0.7238 versus 0.6146/0.6128). Regarding GO sub-ontologies, for almost all FS measures, BP showed better prediction power compared to CC and MF; for deepSimDEF this improvement over CC was much smaller. In the multi-channel deepSimDEF, we also observed a negligible increase in the Pearson correlation result over the single-channel model results in BP and CC; however, compared to MF this improvement was &gt;3%. The multi-channel deepSimDEF outperformed simDEF, the second-best-performing measure, by ∼9% (0.7336 versus 0.6432). The inclusion of IEA also helped deepSimDEF, while for the other FS measures it was not always the case.</p>
      <p>For the human experiment, initialized deepSimDEF was the best-performing FS measure. deepSimDEF, with the single-channel networks, improved Pearson’s correlation with the co-expression data by &gt;6.5% compared to the second-best results achieved by simDEF (0.2442 versus 0.1774). Regarding GO sub-ontologies, similar to the yeast experiment, for almost all FS measures, BP showed better prediction power compared to CC and MF. In the multi-channel architecture also, we observed a ∼2.5% increase in Pearson correlation over the single-channel result in BP; compared to CC and MF this improvement was ∼9% and ∼11%, respectively. Additionally, the multi-channel deepSimDEF outperformed simDEF, the second-best performing measure, by ∼6% (0.2873 versus 0.2313). In contrast to the yeast experiment, however, the inclusion of IEA annotations did not always improve deepSimDEF’s results. In the baseline measures, AicInferSentGO showed comparable results to simDEF.</p>
      <p>Similar to the PPI and sequence homology experiments, the initialization of deepSimDEF networks with our embeddings (versus random) increased the correlation results in all experiments (e.g. 0.2873 versus 0.2741 in IEA+ multi-channel deepSimDEF). deepSimDEF also outperformed other measures regarding Spearman correlation in all settings (see <xref rid="sup1" ref-type="supplementary-material">Supplementary material S3</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Materials and Methods</title>
    <sec>
      <title>3.1 Experimental data</title>
      <sec>
        <title>GO and GO annotations</title>
        <p>In GO, GO terms are structured in three mutually exclusive sub-ontologies of <italic toggle="yes">biological process</italic> (BP), <italic toggle="yes">cellular component</italic> (CC) and <italic toggle="yes">molecular function</italic> (MF). Each GO annotation consists of an association between a gene and a GO term with an evidence code that shows how a given annotation is supported. Out of all the evidence codes, Inferred from Electronic Annotation (IEA) is the least reliable. In this study, the latest GO and the GO annotations of yeast and human genes were downloaded from the Gene Ontology website (<ext-link xlink:href="http://www.geneontology.org/page/download-ontology" ext-link-type="uri">http://www.geneontology.org/page/download-ontology</ext-link> (March 2021)). All genes and proteins that do not have GO annotations will be removed from our datasets, meaning that, for example, hypothetical proteins will not be investigated.</p>
      </sec>
      <sec>
        <title>MEDLINE abstracts</title>
        <p>MEDLINE (<ext-link xlink:href="https://www.nlm.nih.gov/databases/download/pubmed_medline.html" ext-link-type="uri">https://www.nlm.nih.gov/databases/download/pubmed_medline.html</ext-link>) includes &gt;20 million citations of life sciences and biomedical articles from 1966 to the present. Combined with the GO term definitions, we employed the MEDLINE bigram list (<ext-link xlink:href="https://www.nlm.nih.gov/databases/download/data_distrib_main.html" ext-link-type="uri">https://www.nlm.nih.gov/databases/download/data_distrib_main.html</ext-link>) to build our pretrained GO-term embeddings. These pretrained GO-term embeddings initialize the first layers of the deepSimDEF networks to facilitate network optimization.</p>
      </sec>
      <sec>
        <title>Evaluation and validation datasets</title>
        <p><bold><italic toggle="yes">Protein–</italic><italic toggle="yes">protein</italic> <italic toggle="yes">interaction.</italic></bold> From the STRING database (<ext-link xlink:href="https://string-db.org/cgi/download.pl" ext-link-type="uri">https://string-db.org/cgi/download.pl</ext-link>), we collected two lists of experimentally supported interactions for yeast and human. For negative interactions, following what is common in the literature, we independently generated random selection of pairs that were absent from the lists of positive PPIs. After removing proteins that had no GO term annotations from all three sub-ontologies (not considering IEAs), each pair of interacting proteins was labeled 1 indicating a positive interaction, or 0 offering no interaction. Our final balanced PPI datasets contained 50 154 interactions for yeast and 65 542 interactions for human proteins.</p>
        <p><bold><italic toggle="yes">Protein</italic> <italic toggle="yes">sequence</italic> <italic toggle="yes">homology.</italic></bold> For our sequence homology datasets, we first collected the sequences of yeast and human proteins from the UniProt database in FASTA format (For the yeast: <ext-link xlink:href="https://www.uniprot.org/proteomes/UP000002311" ext-link-type="uri">https://www.uniprot.org/proteomes/UP000002311</ext-link>; For human: <ext-link xlink:href="https://www.uniprot.org/proteomes/UP000005640" ext-link-type="uri">https://www.uniprot.org/proteomes/UP000005640</ext-link> (March. 2021)). We used bitscores from the Basic Local Alignment Search Tool (BLAST) algorithm <xref rid="btac304-B1" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic> (1990)</xref> when performing an all-versus-all comparison of proteins for each organism with an expectation-value threshold of 0.1. Although this threshold is liberal, the corresponding bitscores associated with e-values near this threshold will be very low and have a minimal effect on our analysis. Since a bitscore for query and subject proteins is not symmetrical, we computed log-reciprocal BLAST score (LRBS) <xref rid="E1" ref-type="disp-formula">Eq. (1)</xref> and relative reciprocal BLAST score (RRBS) <xref rid="E2" ref-type="disp-formula">Eq. (2)</xref> to express the general sequence similarity of yeast protein pairs. After computation of LRBS and RRBS, for the yeast organism, we had a dataset of 26 757 protein pairs along with their LRBS and RRBS sequence similarity scores. This number for human protein pairs was 381 379. All proteins in these final datasets had GO annotations from the BP, CC and MF sub-ontologies (non-IEA and non-ND annotations).
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">LRBS</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>Bitscore</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>Bitscore</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">RRBS</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>Bitscore</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>Bitscore</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>Bitscore</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>Bitscore</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p><bold><italic toggle="yes">Gene</italic> <italic toggle="yes">expression-</italic><italic toggle="yes">Yeast</italic></bold>. From the microarray gene expression data from <xref rid="btac304-B13" ref-type="bibr">Eisen <italic toggle="yes">et al.</italic> (1998)</xref>, our gene expression dataset was built by integrating their data constructed for 2465 yeast genes under 79 biological conditions (four experiments on cell cycle, sporulation, temperature shock and diauxic shift processes). We first computed the absolute Pearson correlation of all possible gene–gene pairs based on the expression values regardless of their sign as we focused on the strength of co-expression, and then applied Fisher’s <italic toggle="yes">z</italic> transformation to these results to convert them into normally distributed variables suitable for parametric statistical testing. After removing those genes that had no GO annotations, all the genes in the result set had their own GO annotations from all three sub-ontologies (without considering IEAs and NDs). Due to sub-sampling from this large set, since the final dataset could be easily over-represented with co-expressed gene pairs that have small correlations, we considered a binning strategy with which the absolute Pearson correlations of pairs could fall into one of five non-overlapping bins of size 0.2 between 0 and 1. In our random sub-sampling process, we allowed only an equal number of gene pairs within the bins. The final dataset contained 37 405 gene–gene pairs along with the transformed Pearson’s correlation of their expressions.</p>
        <p><bold><italic toggle="yes">Gene</italic> <italic toggle="yes">expression-</italic><italic toggle="yes">Human</italic> (<italic toggle="yes">Homo sapiens</italic>).</bold> In order to demonstrate the utility of the approach in human genomics, we used data coming from the Genotype-Tissue Expression (GTEx) portal (<ext-link xlink:href="https://gtexportal.org/" ext-link-type="uri">https://gtexportal.org/</ext-link>), which is a comprehensive public resource to study tissue-specific human gene expression and regulation <xref rid="btac304-B7" ref-type="bibr">Ardlie <italic toggle="yes">et al.</italic> (2015)</xref>. Although their samples are collected from 54 non-diseased tissue sites across nearly 1000 individuals, as a proof of concept we limited our experiment to whole blood tissue gene expression available for 754 individuals. A total of 2361 genes had complete GO annotations and were retained for further analysis. The absolute Pearson correlation value was calculated between their pairs to infer the strength of the relationship; this was followed by Fisher’s <italic toggle="yes">z</italic> transformation. Similar to yeast data, due to the large size of the calculated correlation set, by executing our binning strategy, a subset of this computed set was employed for our experiments and for the evaluation of gene FS measures. This process resulted in a co-expression dataset of 62 470 gene-gene pairs.</p>
      </sec>
    </sec>
    <sec>
      <title>3.2 Pretraining of GO-term embeddings</title>
      <p>Initialization of a neural network with pretrained embeddings has proven to be effective in a variety of applications (<xref rid="btac304-B56" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2015</xref>). Our GO term pretraining approach consists of six steps depicted in <xref rid="btac304-F3" ref-type="fig">Figure 3</xref>. In essence, the second-order computation of vector representation of GO terms based on their text definitions and co-occurrence vector of their content words in MEDLINE abstracts prevents the issue of the sparsity of word features in the first-order vector representation of the definitions (<xref rid="btac304-B33" ref-type="bibr">Pesaranghader <italic toggle="yes">et al.</italic>, 2013a</xref>); Pointwise Mutual Information statistically defines the degree of association between each GO term and its second-order word features, and Latent Semantic Analysis condenses the final high-dimensional vectors to a size tractable by deep neural networks. Theses pretraining steps are thoroughly detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary material S1</xref>.</p>
      <fig position="float" id="btac304-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Definition-based embedding model of the Gene Ontology terms</p>
        </caption>
        <graphic xlink:href="btac304f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 deepSimDEF network definition</title>
      <p>deepSimDEF offers <italic toggle="yes">single-channel</italic> and <italic toggle="yes">multi-channel</italic> network architectures that learn and represent the shared information of two proteins based on their GO annotations, and then measure FS of genes for an application of interest. While a single-channel network only considers annotations of one sub-ontology, as depicted in <xref rid="btac304-F4" ref-type="fig">Figure 4</xref> for the BP sub-ontology, the multi-channel architecture, with more layers shown in <xref rid="btac304-F5" ref-type="fig">Figure 5</xref>, takes into account all the three GO sub-ontologies together. The 8 layers fundamental to both deepSimDEF architectures are described as follows.</p>
      <fig position="float" id="btac304-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Paired single-channel deepSimDEF network architecture for BP</p>
        </caption>
        <graphic xlink:href="btac304f4" position="float"/>
      </fig>
      <fig position="float" id="btac304-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Paired multi-channel deepSimDEF network architecture</p>
        </caption>
        <graphic xlink:href="btac304f5" position="float"/>
      </fig>
      <p><bold><italic toggle="yes">GO-term</italic> <italic toggle="yes">embedding</italic> <italic toggle="yes">layer.</italic></bold> The GO term annotations of two proteins are fed to the model as indexes taken from three fixed sets of GO<sub>BP,</sub> GO<sub>CC</sub> or/and GO<sub>MF.</sub> These sets contain the indexed GO terms of a particular database from the sub-ontologies of BP, CC and MF. Each set is also associated with a 100-row <italic toggle="yes">look-up table</italic>. These tables, ideally initialized with our pretrained GO-term embeddings, are parameters of the model. First, for every protein, its GO term indexes transform into vectors by looking up their GO-term embeddings. Then, within the embedding layer, for each sub-ontology, the two input proteins are represented as two lists of fixed length <italic toggle="yes">t</italic><sub>0</sub>, each list containing the 100-dimensional GO embeddings of those two genes’ annotations looked up already (<xref rid="E3" ref-type="disp-formula">Eq. (3)</xref>). In the architectures, for consistency across GO annotations of all genes, whenever the annotation sets of a gene had the length of less than <italic toggle="yes">t</italic><sub>0</sub>, we padded the annotation list with a generic vector of a large negative value (padding was repeated whenever needed); subsequent Max-pooling Layer later suppressed the effect of this generic vector, and the final estimations were calculated only based on the actual annotations. For yeast database, when IEA–, inferred from the largest number of annotation for a gene, the fixed annotation length for BP, CC and MF were 50, 22 and 24, respectively.
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ebm</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>100</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the GO-term embedding of the <italic toggle="yes">i</italic>th BP GO annotation of a gene. An embedding layer is denoted by <italic toggle="yes">eb</italic><italic toggle="yes">m</italic><italic toggle="yes">(100, t<sub>0</sub>)</italic> in the figures.</p>
      <p><bold><italic toggle="yes">Max-pooling</italic> <italic toggle="yes">layer.</italic></bold> Generally, a max-pooling layer aggregates the input vectors by taking the maximum over a set of intervals. Here, for the output of an embedding layer, the max operation is applied over all column features, which is denoted by <italic toggle="yes">maxpool(t<sub>0</sub>)</italic>. We also considered <italic toggle="yes">flattening</italic> of the resulting pooled column-vector into a row feature-vector representation as an integrated part of the max-pooling layer prior to passing the results of the layer to a higher fully connected layer. After max-pooling, proteins with different lengths of GO annotations are represented with 100-dimensional global feature vectors each for one sub-ontology.</p>
      <p><bold><italic toggle="yes">Merge</italic> <italic toggle="yes">layer.</italic></bold> For a single-channel architecture, we have only one merge layer at the gene-product similarity level due to the paired nature of the input data. That means prior to the extraction and representation of the shared information between two gene products, their individual feature vectors need to be merged through <italic toggle="yes">concatenation</italic>. For the multi-channel architecture, however, besides having a merge layer at the gene-product level, we have an earlier merge layer at the GO term annotations level. For a given gene product of an input gene pair, this extra merge layer is used to concatenate the three 100-dimensional feature vectors of the BP, CC and MF annotations from the max-pooling layer. In the multi-channel architecture, at the GO term annotation level, <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="italic">multi</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>300</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the result of the merge layer. At the gene-product level, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>p</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="italic">single</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>p</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="italic">multi</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are the results of the merge layers for the paired single-channel and paired multi-channel architectures, respectively. Merge layers are denoted by <italic toggle="yes">merge(‘concat’)</italic>.</p>
      <p><bold><italic toggle="yes">Fully</italic></bold> <bold><italic toggle="yes">connected</italic> <italic toggle="yes">layer.</italic></bold> The fully connected layer takes a <italic toggle="yes">d</italic><sub>0</sub>-dimensional input vector <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">fch</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to learn higher level feature representations of the underneath layers (In the equations, <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mo>·</mml:mo></mml:math></inline-formula> denotes matrix multiplication.) with:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">ReLU</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">fch</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">hid</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">n</italic><sub>hid</sub> is the size of the fully connected hidden layer, <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">hid</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the bias vector, and ReLU is the rectified linear activation function (<xref rid="btac304-B30" ref-type="bibr">Nair and Hinton, 2010</xref>). The output of the first fully connected layer can be seen as the embeddings of the input gene products. Depending on whether the single-channel or multi-channel network is employed, this embedding size can be 100-dimensional or 300-dimensional. The fully connected hidden layers are denoted by <italic toggle="yes">dense(n<sub>hid</sub>, ‘relu’)</italic>. At the similarity level, the fully connected layer improves representation of the shared information between two genes.</p>
      <p><bold><italic toggle="yes">Highway</italic> <italic toggle="yes">layer.</italic></bold> In the previous measures including simDEF, for FS estimation of two input gene products, human-engineered aggregation metrics were used—while the SS scores of their pair-wise GO annotations made the inputs of these metrics. However, there is no consensus in the literature on what metric is the best choice for the aggregation of the shared information, as from one biological experiment to another the results vary, and even sometimes, the conclusions contradict each other (<xref rid="btac304-B16" ref-type="bibr">Guzzi <italic toggle="yes">et al.</italic>, 2012</xref>). In the deepSimDEF model, the highway layer (<xref rid="btac304-B50" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2015</xref>) is devised to let the model itself properly learn an adaptive representation of the provided information of the two input genes encoded in the lower layer for the comparison of those genes’ biological traits including their molecular functions (see also <xref rid="sup1" ref-type="supplementary-material">Supplementary material S1</xref>). This representation uses a <italic toggle="yes">gating mechanism</italic> that controls the flow of information from the two gene products into an aggregated high-level representation. This adaptive representation of the shared information strengthens an affine transformation—similar to what is presented in <xref rid="E4" ref-type="disp-formula">Eq. (4)</xref>—with a non-linear transform function <bold><italic toggle="yes">T</italic></bold>. We refer to the vector <bold><italic toggle="yes">T</italic></bold> as the transform gate since it expresses how the output is produced through <italic toggle="yes">transforming</italic> or <italic toggle="yes">carrying</italic> the input. If we consider the size of the concatenated feature vectors of two input genes to be <italic toggle="yes">d</italic><sub>1</sub>-dimensional, <bold><italic toggle="yes">T</italic></bold> can be formulated as:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">fch</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">hid</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the weight matrix, <italic toggle="yes">n</italic><sub>hid</sub> is the size of the fully connected hidden layer and here is equal to <italic toggle="yes">d</italic><sub>1</sub> since we do not want to expand or shrink the representation result at this stage, <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">hid</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the bias vector, and <italic toggle="yes">σ</italic> is a <italic toggle="yes">sigmoid function</italic> employed in the original paper as the transform function (<xref rid="btac304-B50" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2015</xref>). If we want to represent two extreme cases which apply either transform state or block (or carry) state on the input data, <xref rid="E6" ref-type="disp-formula">Eq. (6)</xref> formulates that for us:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>′</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">fch</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">fch</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>Therefore, depending on the output of the transform gates, a highway layer should smoothly vary its behavior between that of a plain layer with a non-linear activation of interest (if <bold><italic toggle="yes">T </italic></bold>=<bold><italic toggle="yes"> </italic></bold>1; in deepSimDEF we achieved better results with sigmoid function) and that of a layer which simply passes its inputs through (if <bold><italic toggle="yes">T </italic></bold>=<bold><italic toggle="yes"> </italic></bold>0). <xref rid="E7" ref-type="disp-formula">Equation (7)</xref> formulates this favorable behavior (In the equation, <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mo>⊙</mml:mo></mml:math></inline-formula> implies element-wise multiplication.):
<disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>′</mml:mo><mml:mo>=</mml:mo><mml:mo>σ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">fch</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⊙</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">fch</mml:mi></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p>
      <p>The transform gate—which is the principal component in the deepSimDEF network(s) for a high-level representation of the shared information of two input genes, and all the weights in the highway layer, will be learned during the training phase. The highway layer is denoted by <italic toggle="yes">highway(‘sigmoid’)</italic>.</p>
      <p><bold><italic toggle="yes">Classification/r</italic><italic toggle="yes">egression</italic> <italic toggle="yes">layer.</italic></bold> Whether an experiment conducted in a study is a classification problem or a regression problem, the output of the last dense layer is fully connected to either a <italic toggle="yes">sigmoid classification</italic> layer (e.g. for our PPI experiment) or a <italic toggle="yes">linear regression</italic> layer (for the gene expression and sequence homology experiments). After the lower layer processing, a fixed dimensional feature vector <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> or <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the input to the classification/regression layer, with a sigmoid or linear activation, whose output is the FS estimation of the genes. For a classification task we have:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> outputs probability distribution over labels, <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">n</italic><sub>out</sub> is the size of the classification layer (for the PPI prediction it is equal to two types), <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> is the bias vector, and <italic toggle="yes">d</italic><sub>2</sub> is either 100-dimensional (for single-channel) or 300-dimensional (for multi-channel architecture). The classification layer is denoted by <italic toggle="yes">dense(1, ‘sigmoid’)</italic>. For a regression task:
<disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> outputs a scalar value, <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">d</italic><sub>2</sub> is either 100- or 300-dimensional depending on the architecture, and <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> is the bias vector. The regression layer is denoted by <italic toggle="yes">dense(1, ‘linear’)</italic>.</p>
      <p>Since a deepSimDEF network needs to be symmetric to produce the same result for the two input pairs of [<italic toggle="yes">g</italic><sub>1</sub>, <italic toggle="yes">g</italic><sub>2</sub>] and [<italic toggle="yes">g</italic><sub>2</sub>, <italic toggle="yes">g</italic><sub>1</sub>], all equivalent layers of the paired networks, including embedding layers, must share the same weights [similar to Siamese network (Siamese network is an artificial neural network that uses the same weights while working in tandem on two different input vectors to compute comparable output vectors.)]. Meaning, for each sub-ontology, we only have one look-up table (initialized randomly or with the pretrained GO-term embeddings). In the training phase and during back-propagation, this table(s) will be updated simultaneously for every gene product in a training gene product pair. We also used dropout (<xref rid="btac304-B49" ref-type="bibr">Srivastava <italic toggle="yes">et al.</italic>, 2014</xref>) of 0.3 on the fully connected and highway layers to allow a more accurate generalization. The parameters of the networks are optimized to maximize the correlation between the estimated FS of gene products predicted by the models and the target scores in the training datasets. This selection was done in a 10-fold cross-validation manner where validation splits chose the best parameters using an early stopping strategy (<xref rid="btac304-B42" ref-type="bibr">Prechelt, 1998</xref>). Additionally, since the weight matrices of the highway layer for the concatenated feature-vectors of the paired networks are not symmetric and do not update symmetrically, we not only trained the networks on ([<italic toggle="yes">g</italic><sub>1</sub>, <italic toggle="yes">g</italic><sub>2</sub>], <italic toggle="yes">score</italic>) instances, we also trained them on ([<italic toggle="yes">g</italic><sub>2</sub>, <italic toggle="yes">g</italic><sub>1</sub>], <italic toggle="yes">score</italic>) instances. See <xref rid="sup1" ref-type="supplementary-material">Supplementary material S4</xref> for further details and the exact hyper-parameters of the networks.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>In comparison to baseline FS measures, validation of deepSimDEF on yeast and human reference datasets yielded increases in PPI predictability by &gt;4.5% and ∼5%, respectively; a correlation improvement of ∼9% and ∼6% with yeast and human gene co-expression values; and improved correlation with sequence homology by up to 6% for both organisms. Unsurprisingly, we observed significantly better results for the predictions in yeast than in human, especially for the co-expression analysis. This is likely due to the fact that our human data came from whole blood samples (the largest dataset available in GTEx), which is a mix of several cell types regulated in different ways, inevitably creating noise in co-expression networks, whereas the information available from yeast co-expression networks is likely more complete given its unicellular nature.</p>
    <p>One important aspect regarding the hyper-parameter setting of the deepSimDEF networks was that for all the experiments, one set of hyper-parameters always helped to get the optimal results for the networks (multi- or single-channel). For example, if we changed the embedding size in one experiment and observed a decline or an improvement in the results, for other experiments, we observed the same trend in the results applying the same changes to their networks. This allowed us to maintain a consistent structure across all experiments, which will be very beneficial as deepSimDEF can be extended to less well-characterized datasets than the yeast and human examples we show here. Regarding computational complexity of the deepSimDEF model, since the networks are trained in advance, prediction of FS for batches of new proteins will be very fast at inference time while this is not true for the pair-wise FS measures. deepSimDEF networks were trained and tested on NVIDIA Quadro RTX 6000 GPUs. Depending on the experiment and deepSimDEF network architecture the training time varied from a few hours to almost a day.</p>
    <p>Future work with deepSimDEF can involve extension to other problems where FS and SS measures have been applied, including microRNA function analysis (<xref rid="btac304-B31" ref-type="bibr">Peng <italic toggle="yes">et al.</italic>, 2017</xref>), co-expression network construction (<xref rid="btac304-B53" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>), drug discovery (<xref rid="btac304-B48" ref-type="bibr">Sridhar <italic toggle="yes">et al.</italic>, 2016</xref>) and cancer treatment studies (<xref rid="btac304-B44" ref-type="bibr">Schaefer and Serrano, 2016</xref>). deepSimDEF needs to be tested on species other than yeast and human as well, and, in humans, on different tissues. Indeed, co-expression and PPI patterns will vary according to tissue type, and future work should focus on integrating multiple tissues to derive tissue-specific predictions.</p>
    <p>Finally, we emphasize that our result derived from IEA should be taken with a grain of salt as such annotations are typically assigned on the basis of homology or domain content, meaning that if two proteins are similar in the sequence they are likely to obtain similar inferred GO annotations. There may thus be an influence of data circularity in the behavior of the results derived from IEA (<xref rid="btac304-B41" ref-type="bibr">Pesquita <italic toggle="yes">et al.</italic>, 2008</xref>), and it is possible that we are partly measuring the sensitivity of the electronically inferred GO annotations. However, by excluding IEA annotations in our experiments, we could not identify any significant change in the prediction power of deepSimDEF networks. On the other hand, IEA annotations can produce erroneous results when key functional residues are mutated, when genes are duplicated to acquire additional functions, or when the alignment does not span the whole length of the proteins possibly indicating changes in domain architecture. As a result, the computational assignment of GO terms demands more advanced techniques which go beyond homologous sequences. Such techniques are the topic of many recent studies (<xref rid="btac304-B24" ref-type="bibr">Littmann <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac304-B46" ref-type="bibr">Seyyedsalehi <italic toggle="yes">et al.</italic>, 2021</xref>). While we considered IEA+ and IEA− in our experiments (as commonly done in the previous studies), sensitivity to other evidence codes employed in the GO annotations pipeline can be the subject of further studies. Last but not least, in the context of transfer learning, more studies are needed to be done to discover how the learned information from a biological task for an organism can be transferred to another organism.</p>
  </sec>
  <sec>
    <title>5 Conclusions</title>
    <p>Many important applications in computational molecular biology such as gene clustering, protein function prediction, protein interaction evaluation, and disease gene prioritization require functional similarity of genes. deepSimDEF offers a novel deep neural network-based tool for functional similarity prediction of genes and gene products. It results in valuable low-dimensional embeddings of GO terms and gene products and provides powerful, flexible, easily transferable deep neural architectures applicable to a wide range of problems in genomics and proteomics. When evaluated on the yeast and human databases, deepSimDEF single-channel and multi-channel networks outperformed the well-known functional similarity measures in the tasks of PPI prediction, correlation with gene expression as well as correlation with sequence homology data by gaining large margins of improvement. Also, in contrast to previous measures which are computationally expensive, once a deepSimDEF network is trained, its functional similarity prediction of batches of genes is reasonably fast which could be substantially helpful for real-life applications.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the Institute for Data Valorization (IVADO)/Genome Quebec grant [PRF-2017-023 to J.H.]; by NSERC CREATE Grant and the grant from Poland’s National Scientific Center available to S.M.; and by NSERC Discovery Grants available to S.M. J.H is a Fonds de la Recherche du Québec en Santé (FRQS) Junior 1 Scholar. M.S. as well. S.M. and R.G.B. were supported by the Canada Research Chairs program.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac304_Supplementary_Data</label>
      <media xlink:href="btac304_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac304-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>S.F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1990</year>) <article-title>Basic local alignment search tool</article-title>. <source>J. Mol. Biol</source>., <volume>215</volume>, <fpage>403</fpage>–<lpage>410</lpage>.<pub-id pub-id-type="pmid">2231712</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Asgari</surname><given-names>E.</given-names></string-name>, <string-name><surname>Mofrad</surname><given-names>M.R.</given-names></string-name></person-group> (<year>2015</year>) <article-title>Continuous distributed representation of biological sequences for deep proteomics and genomics</article-title>. <source>PLoS One</source>, <volume>10</volume>, <fpage>e0141287</fpage>.<pub-id pub-id-type="pmid">26555596</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ashburner</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2000</year>) <article-title>Gene ontology: tool for the unification of biology</article-title>. <source>Nat. Genet</source>., <volume>25</volume>, <fpage>25</fpage>–<lpage>29</lpage>.<pub-id pub-id-type="pmid">10802651</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ben Ali</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Implementing machine learning in interventional cardiology: the benefits are worth the trouble</article-title>. <source>Front. Cardiovasc. Med</source>., <bold>8</bold>, 711401. https://doi.org/10.3389/fcvm.2021.711401.</mixed-citation>
    </ref>
    <ref id="btac304-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bible</surname><given-names>P.W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>The effects of shared information on semantic calculations in the gene ontology</article-title>. <source>Comput. Struct. Biotechnol. J</source>., <volume>15</volume>, <fpage>195</fpage>–<lpage>211</lpage>.<pub-id pub-id-type="pmid">28217262</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>The lncLocator: a subcellular localization predictor for long non-coding RNAs based on a stacked ensemble classifier</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2185</fpage>–<lpage>2194</lpage>.<pub-id pub-id-type="pmid">29462250</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ardlie</surname><given-names>K.G.</given-names></string-name></person-group>  <etal>et al</etal>; The GTEx Consortium. (<year>2015</year>) <article-title>The genotype-tissue expression (GTEx) pilot analysis: multitissue gene regulation in humans</article-title>. <source>Science</source>, <volume>348</volume>, <fpage>648</fpage>–<lpage>660</lpage>.<pub-id pub-id-type="pmid">25954001</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Couto</surname><given-names>F.M.</given-names></string-name>, <string-name><surname>Silva</surname><given-names>M.J.</given-names></string-name></person-group> (<year>2011</year>) <article-title>Disjunctive shared information between ontology concepts: application to gene ontology</article-title>. <source>J. Biomed. Semantics</source>, <volume>2</volume>, <fpage>5</fpage>.<pub-id pub-id-type="pmid">21884591</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cozzetto</surname><given-names>D.</given-names></string-name>, <string-name><surname>Jones</surname><given-names>D.</given-names></string-name></person-group> (<year>2017</year>) <article-title>Computational methods for annotation transfers from sequence</article-title>. <source>Methods Mol. Biol. (Clifton, NJ)</source>, <volume>1446</volume>, <fpage>55</fpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Dessimoz</surname><given-names>C.</given-names></string-name>, <string-name><surname>Škunca</surname><given-names>N.</given-names></string-name></person-group> (<year>2017</year>). <source>The Gene Ontology Handbook</source>. <publisher-name>Humana, New York, NY</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac304-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duong</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Word and sentence embedding tools to measure semantic similarity of gene ontology terms by their definitions</article-title>. <source>J. Comput. Biol</source>., <bold>26</bold>, 38–52. http://doi.org/10.1089/cmb.2018.0093.</mixed-citation>
    </ref>
    <ref id="btac304-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dutta</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Assessment of semantic similarity between proteins using information content and topological properties of the gene ontology graph</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinform</source>., <volume>15</volume>, <fpage>839</fpage>–<lpage>849</lpage>.<pub-id pub-id-type="pmid">28371781</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eisen</surname><given-names>M.B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>1998</year>) <article-title>Cluster analysis and display of genome-wide expression patterns</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>95</volume>, <fpage>14863</fpage>–<lpage>14868</lpage>.<pub-id pub-id-type="pmid">9843981</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Falcon</surname><given-names>S.</given-names></string-name>, <string-name><surname>Gentleman</surname><given-names>R.</given-names></string-name></person-group> (<year>2007</year>) <article-title>Using GOstats to test gene lists for go term association</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>257</fpage>–<lpage>258</lpage>.<pub-id pub-id-type="pmid">17098774</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Firth</surname><given-names>J.R.</given-names></string-name></person-group> (<year>1957</year>) A synopsis of linguistic theory, 1930-1955. In: <italic toggle="yes">Studies in Linguistic Analysis</italic>. Philological Society, Oxford.</mixed-citation>
    </ref>
    <ref id="btac304-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guzzi</surname><given-names>P.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>Semantic similarity analysis of protein data: assessment with biological features and issues</article-title>. <source>Brief. Bioinform</source>., <volume>13</volume>, <fpage>569</fpage>–<lpage>585</lpage>.<pub-id pub-id-type="pmid">22138322</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hinton</surname><given-names>G.E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2006</year>) <article-title>A fast learning algorithm for deep belief nets</article-title>. <source>Neural Comput</source>., <volume>18</volume>, <fpage>1527</fpage>–<lpage>1554</lpage>.<pub-id pub-id-type="pmid">16764513</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>J.J.</given-names></string-name>, <string-name><surname>Conrath</surname><given-names>D.W.</given-names></string-name></person-group> (<year>1997</year>). Semantic similarity based on corpus statistics and lexical taxonomy. In: <italic toggle="yes">Proceedings of the 10th Research on Computational Linguistics International Conference, Taipei, Taiwan</italic>. The Association for Computational Linguistics and Chinese Language Processing (ACLCLP), pp. 19–33<italic toggle="yes">.</italic></mixed-citation>
    </ref>
    <ref id="btac304-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>). Trajectorynet: an embedded GPS trajectory representation for point-based classification using recurrent neural networks. In: <italic toggle="yes">Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering<italic toggle="yes">.</italic></italic></mixed-citation>
    </ref>
    <ref id="btac304-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Drug repositioning of herbal compounds via a machine-learning approach</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <fpage>33</fpage>–<lpage>43</lpage>.<pub-id pub-id-type="pmid">30717672</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>LeCun</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Deep learning</article-title>. <source>Nature</source>, <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Levandowsky</surname><given-names>M.</given-names></string-name>, <string-name><surname>Winter</surname><given-names>D.</given-names></string-name></person-group> (<year>1971</year>) <article-title>Distance between sets</article-title>. <source>Nature</source>, <volume>234</volume>, <fpage>34</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>D.</given-names></string-name></person-group> (<year>1998</year>). <part-title>An information-theoretic definition of similarity</part-title>. In: <source>ICML</source>, vol. <volume>98</volume>. <publisher-name>Citeseer</publisher-name>, pp. <fpage>296</fpage>–<lpage>304</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Littmann</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Embeddings from deep learning transfer go annotations beyond homology</article-title>. <source>Sci. Rep</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lord</surname><given-names>P.W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2003</year>) <article-title>Investigating semantic similarity measures across the gene ontology: the relationship between sequence and annotation</article-title>. <source>Bioinformatics</source>, <volume>19</volume>, <fpage>1275</fpage>–<lpage>1283</lpage>.<pub-id pub-id-type="pmid">12835272</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Makrodimitris</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Metric learning on expression data for gene function prediction</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>1182</fpage>–<lpage>1190</lpage>.<pub-id pub-id-type="pmid">31562759</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mazandu</surname><given-names>G.K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Gene ontology semantic similarity tools: survey on features and challenges for biological knowledge discovery</article-title>. <source>Brief. Bioinform</source>., <volume>18</volume>, <fpage>886</fpage>–<lpage>901</lpage>.<pub-id pub-id-type="pmid">27473066</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mikolov</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Distributed representations of words and phrases and their compositionality</article-title>. In: <source>Advances in Neural Information Processing Systems</source>. pp. <fpage>3111</fpage>–<lpage>3119</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murakami</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Network analysis and in silico prediction of protein–protein interactions with applications in drug discovery</article-title>. <source>Curr. Opin. Struct. Biol</source>., <volume>44</volume>, <fpage>134</fpage>–<lpage>142</lpage>.<pub-id pub-id-type="pmid">28364585</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B30">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Nair</surname><given-names>V.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.E.</given-names></string-name></person-group> (<year>2010</year>). Rectified linear units improve restricted Boltzmann machines. In: <italic toggle="yes">Proceedings of the 27th International Conference on Machine Learning (ICML-10).</italic> pp. <fpage>807</fpage>–<lpage>814</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Cross disease analysis of co-functional microRNA pairs on a reconstructed network of disease-gene-microRNA tripartite</article-title>. <source>BMC Bioinformatics</source>, <volume>18</volume>, <fpage>193</fpage>.<pub-id pub-id-type="pmid">28340554</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B32">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group> (<year>2019</year>). <italic toggle="yes">Concept embedding for deep neural functional analysis of genes and deep neural word sense disambiguation of biomedical text</italic>. Dalhousie University, Halifax, NS.</mixed-citation>
    </ref>
    <ref id="btac304-B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013a</year>). <part-title>Adapting gloss vector semantic relatedness measure for semantic similarity estimation: an evaluation in the biomedical domain</part-title>. In: Kim,W. <italic toggle="yes">et al.</italic> (eds) <source>Joint International Semantic Technology Conference</source>. <publisher-name>Springer, Cham</publisher-name>, pp. <fpage>129</fpage>–<lpage>145</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013b</year>). Improving gloss vector semantic relatedness measure by integrating pointwise mutual information: optimizing second-order co-occurrence vectors computed from biomedical corpus and UMLS. In: <italic toggle="yes">2013 International Conference on Informatics and Creative Multimedia</italic>. IEEE, pp. <fpage>196</fpage>–<lpage>201</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B35">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>). <part-title>Gene functional similarity analysis by definition-based semantic similarity measurement of go terms</part-title>. In: Sokolova,M. and Beek,P. (eds) <source>Canadian Conference on Artificial Intelligence</source>. <publisher-name>Springer, Cham</publisher-name>, pp. <fpage>203</fpage>–<lpage>214</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>simDEF: definition-based semantic similarity measure of gene ontology terms for functional similarity analysis of genes</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>1380</fpage>–<lpage>1387</lpage>.<pub-id pub-id-type="pmid">26708333</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>deepBioWSD: effective deep neural word sense disambiguation of biomedical text data</article-title>. <source>J. Am. Med. Inform. Assoc</source>., <volume>26</volume>, <fpage>438</fpage>–<lpage>446</lpage>.<pub-id pub-id-type="pmid">30811548</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B38">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021a</year>). <part-title>CT-SGAN: computed tomography synthesis GAN</part-title>. In: Deep Generative Models, and Data Augmentation, Labelling, and Imperfections. Springer, pp. <fpage>67</fpage>–<lpage>79</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B39">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Pesaranghader</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021b</year>). <article-title>ImputeCoVNet: 2D ResNet Autoencoder for imputation of SARS-CoV-2 sequences</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2021.08.13.456305</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac304-B40">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Pesquita</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>). Evaluating go-based semantic similarity measures. In: <italic toggle="yes">Proceedings of the 10th Annual Bio-Ontologies Meeting</italic>, vol. 37. p. <fpage>38</fpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pesquita</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Metrics for go based protein semantic similarity: a systematic evaluation</article-title>. <source>BMC Bioinformatics</source>, <volume>9</volume>, <fpage>S4</fpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prechelt</surname><given-names>L.</given-names></string-name></person-group> (<year>1998</year>) <article-title>Automatic early stopping using cross validation: quantifying the criteria</article-title>. <source>Neural Netw</source>., <volume>11</volume>, <fpage>761</fpage>–<lpage>767</lpage>.<pub-id pub-id-type="pmid">12662814</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Resnik</surname><given-names>P.</given-names></string-name></person-group> (<year>1995</year>). <article-title>Using information content to evaluate semantic similarity in a taxonomy</article-title>. <source>arXiv preprint cmp-lg/9511007</source>. <pub-id pub-id-type="doi">10.48550/arXiv.cmp-lg/9511007</pub-id>.</mixed-citation>
    </ref>
    <ref id="btac304-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schaefer</surname><given-names>M.H.</given-names></string-name>, <string-name><surname>Serrano</surname><given-names>L.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Cell type-specific properties and environment shape tissue specificity of cancer genes</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>20707</fpage>–<lpage>20714</lpage>.<pub-id pub-id-type="pmid">26856619</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schlicker</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>) <article-title>GOTax: investigating biological processes and biochemical activities along the taxonomic tree</article-title>. <source>Genome Biol</source>., <volume>8</volume>, <fpage>R33</fpage>.<pub-id pub-id-type="pmid">17346342</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seyyedsalehi</surname><given-names>S.F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>PFP-WGAN: protein function prediction by discovering gene ontology term correlations with generative adversarial networks</article-title>. <source>PLoS One</source>, <volume>16</volume>, <fpage>e0244430</fpage>.<pub-id pub-id-type="pmid">33630862</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Measure the semantic similarity of go terms using aggregate information content</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinform</source>., <volume>11</volume>, <fpage>468</fpage>–<lpage>476</lpage>.<pub-id pub-id-type="pmid">26356015</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sridhar</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>A probabilistic approach for collective similarity-based drug–drug interaction prediction</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3175</fpage>–<lpage>3182</lpage>.<pub-id pub-id-type="pmid">27354693</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Srivastava</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>J. Mach. Learn. Res</source>., <volume>15</volume>, <fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B50">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Srivastava</surname><given-names>R.K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>Training very deep networks</article-title>. In: Advances in Neural Information Processing Systems. pp. <fpage>2377</fpage>–<lpage>2385</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Teng</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Measuring gene functional similarity based on group-wise comparison of go terms</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>1424</fpage>–<lpage>1432</lpage>.<pub-id pub-id-type="pmid">23572412</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B52">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Tian</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>). SWE: a novel method with semantic-weighted edge for measuring gene functional similarity. In: <italic toggle="yes">2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM).</italic> IEEE, pp. <fpage>1672</fpage>–<lpage>1678</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Proteome profiling outperforms transcriptome profiling for coexpression based gene function prediction</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>16</volume>, <fpage>121</fpage>–<lpage>134</lpage>.<pub-id pub-id-type="pmid">27836980</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>J.Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>) <article-title>A new method to measure the semantic similarity of go terms</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>1274</fpage>–<lpage>1281</lpage>.<pub-id pub-id-type="pmid">17344234</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Improving the measurement of semantic similarity between gene ontology terms and gene products: insights from an edge-and IC-based hybrid method</article-title>. <source>PLoS One</source>, <volume>8</volume>, <fpage>e66745</fpage>.<pub-id pub-id-type="pmid">23741529</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B56">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>K.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>). Show, attend and tell: neural image caption generation with visual attention. In: <italic toggle="yes">International Conference on Machine Learning.</italic> pp. <fpage>2048</fpage>–<lpage>2057</lpage>.</mixed-citation>
    </ref>
    <ref id="btac304-B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>MiRGOFS: a GO-based functional similarity measurement for miRNAs, with applications to the prediction of miRNA subcellular localization and miRNA–disease association</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>3547</fpage>–<lpage>3556</lpage>.<pub-id pub-id-type="pmid">29718114</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Prediction of protein structural class for low-similarity sequences using Chou’s pseudo amino acid composition and wavelet denoising</article-title>. <source>J. Mol. Graph. Model</source>., <volume>76</volume>, <fpage>260</fpage>–<lpage>273</lpage>.<pub-id pub-id-type="pmid">28743071</pub-id></mixed-citation>
    </ref>
    <ref id="btac304-B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>S.-B.</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Q.-R.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Protein–protein interaction inference based on semantic similarity of gene ontology terms</article-title>. <source>J. Theor. Biol</source>., <volume>401</volume>, <fpage>30</fpage>–<lpage>37</lpage>.<pub-id pub-id-type="pmid">27117309</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
