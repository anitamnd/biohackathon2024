<?DTDIdentifier.IdentifierValue -//IEEE//DTD IEEE Journals JATS-based DTD v1.7//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journals.dtd?>
<?SourceDTD.Version 1-7?>
<?ConverterInfo.XSLTName ieee2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">IEEE Trans Big Data</journal-id>
    <journal-id journal-id-type="iso-abbrev">IEEE Trans Big Data</journal-id>
    <journal-id journal-id-type="publisher-id">0068800</journal-id>
    <journal-id journal-id-type="publisher-id">TBDATA</journal-id>
    <journal-id journal-id-type="coden">ITBDAX</journal-id>
    <journal-title-group>
      <journal-title>Ieee Transactions on Big Data</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2332-7790</issn>
    <publisher>
      <publisher-name>IEEE</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8117951</article-id>
    <article-id pub-id-type="pmid">33997112</article-id>
    <article-id pub-id-type="doi">10.1109/TBDATA.2020.3035935</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>COVID-19-CT-CXR: A Freely Accessible and Weakly Labeled Chest X-Ray and CT Image Collection on COVID-19 From Biomedical Literature</article-title>
    </title-group>
    <contrib-group>
      <contrib id="contrib1" contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9309-8331</contrib-id>
        <name-alternatives>
          <name content-type="display">
            <surname>Peng</surname>
            <given-names>Yifan</given-names>
          </name>
          <name content-type="index">
            <surname>Peng</surname>
            <given-names>Yifan</given-names>
          </name>
        </name-alternatives>
        <xref rid="aff1" ref-type="aff"/>
        <xref rid="bio1" ref-type="bio"/>
        <email>yip4002@med.cornell.edu</email>
      </contrib>
      <contrib id="contrib2" contrib-type="author">
        <name-alternatives>
          <name content-type="display">
            <surname>Tang</surname>
            <given-names>Yuxing</given-names>
          </name>
          <name content-type="index">
            <surname>Tang</surname>
            <given-names>Yuxing</given-names>
          </name>
        </name-alternatives>
        <xref rid="aff2" ref-type="aff"/>
        <xref rid="bio2" ref-type="bio"/>
        <email>ytang.cv@hotmail.com</email>
      </contrib>
      <contrib id="contrib3" contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1684-2996</contrib-id>
        <name-alternatives>
          <name content-type="display">
            <surname>Lee</surname>
            <given-names>Sungwon</given-names>
          </name>
          <name content-type="index">
            <surname>Lee</surname>
            <given-names>Sungwon</given-names>
          </name>
        </name-alternatives>
        <xref rid="aff2" ref-type="aff"/>
        <xref rid="bio3" ref-type="bio"/>
        <email>sungwon.lee@nih.gov</email>
      </contrib>
      <contrib id="contrib4" contrib-type="author">
        <name-alternatives>
          <name content-type="display">
            <surname>Zhu</surname>
            <given-names>Yingying</given-names>
          </name>
          <name content-type="index">
            <surname>Zhu</surname>
            <given-names>Yingying</given-names>
          </name>
        </name-alternatives>
        <xref rid="aff2" ref-type="aff"/>
        <xref rid="aff3" ref-type="aff"/>
        <xref rid="bio4" ref-type="bio"/>
        <email>yingying.zhu@nih.gov</email>
      </contrib>
      <contrib id="contrib5" contrib-type="author">
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8081-7376</contrib-id>
        <name-alternatives>
          <name content-type="display">
            <surname>Summers</surname>
            <given-names>Ronald M.</given-names>
          </name>
          <name content-type="index">
            <surname>Summers</surname>
            <given-names>Ronald M.</given-names>
          </name>
        </name-alternatives>
        <xref rid="aff2" ref-type="aff"/>
        <xref rid="bio5" ref-type="bio"/>
        <email>rsummers@cc.nih.gov</email>
      </contrib>
      <contrib id="contrib6" contrib-type="author">
        <name-alternatives>
          <name content-type="display">
            <surname>Lu</surname>
            <given-names>Zhiyong</given-names>
          </name>
          <name content-type="index">
            <surname>Lu</surname>
            <given-names>Zhiyong</given-names>
          </name>
        </name-alternatives>
        <xref rid="aff4" ref-type="aff"/>
        <xref rid="bio6" ref-type="bio"/>
        <email>zhiyong.lu@nih.gov</email>
      </contrib>
      <author-comment>
        <p>(Corresponding author: Zhiyong Lu.)</p>
        <p>Recommended for acceptance by XXXX.</p>
      </author-comment>
    </contrib-group>
    <aff id="aff1">
      <institution-wrap>
        <institution content-type="division">NCBI/NLM/NIH and Department of Population Health Sciences</institution>
        <institution content-type="institution">Weill Cornell Medicine</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">12295</institution-id>
      </institution-wrap>
      <city>New York</city>
      <state>NY</state>
      <postal-code>10065</postal-code>
      <country>USA</country>
    </aff>
    <aff id="aff2">
      <institution-wrap>
        <institution content-type="division">Imaging Biomarkers and Computer-Aided Diagnosis Laboratory</institution>
        <institution content-type="department">Radiology and Imaging Sciences Department</institution>
        <institution content-type="institution">National Institutes of Health (NIH) Clinical Center</institution>
      </institution-wrap>
      <city>Bethesda</city>
      <state>MD</state>
      <postal-code>20892</postal-code>
      <country>USA</country>
    </aff>
    <aff id="aff3">
      <institution-wrap>
        <institution content-type="division">Department of Computer Science and Engineering</institution>
        <institution content-type="institution">University of Texas at Arlington</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">12329</institution-id>
      </institution-wrap>
      <city>Arlington</city>
      <state>TX</state>
      <postal-code>76019</postal-code>
      <country>USA</country>
    </aff>
    <aff id="aff4">
      <institution-wrap>
        <institution content-type="division">National Center for Biotechnology Information (NCBI)</institution>
        <institution content-type="department">National Library of Medicine (NLM)</institution>
        <institution content-type="institution">National Institutes of Health (NIH)</institution>
        <institution-id content-type="institution" institution-id-type="ringgold">2511</institution-id>
      </institution-wrap>
      <city>Bethesda</city>
      <state>MD</state>
      <postal-code>20894</postal-code>
      <country>USA</country>
    </aff>
    <pub-date pub-type="collection" iso-8601-date="2021-03-01">
      <day>01</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-11-04">
      <day>04</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <volume>7</volume>
    <issue>1</issue>
    <fpage>3</fpage>
    <lpage>12</lpage>
    <history>
      <date date-type="received" iso-8601-date="2020-06-29">
        <day>29</day>
        <month>6</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd" iso-8601-date="2020-10-09">
        <day>09</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="accepted" iso-8601-date="2020-10-19">
        <day>19</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="currentversion" iso-8601-date="2021-03-01">
        <day>01</day>
        <month>3</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder content-type="Author">Author</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link></license-p>
      </license>
      <ali:free_to_read xmlns:ali="http://www.niso.org/schemas/ali/1.0/" content-type="COVID-19" end_date="nulldate" specific-use="promo" start_date="nulldate"/>
    </permissions>
    <self-uri content-type="xml">tbdata-peng-3035935</self-uri>
    <self-uri content-type="print">tbdata-peng-3035935.pdf</self-uri>
    <self-uri content-type="online">tbdata-peng-3035935.pdf</self-uri>
    <self-uri content-type="NIH-pdf">tbdata-peng-3035935.pdf</self-uri>
    <abstract>
      <p>The latest threat to global health is the COVID-19 outbreak. Although there exist large datasets of chest X-rays (CXR) and computed tomography (CT) scans, few COVID-19 image collections are currently available due to patient privacy. At the same time, there is a rapid growth of COVID-19-relevant articles in the biomedical literature, including those that report findings on radiographs. Here, we present COVID-19-CT-CXR, a public database of COVID-19 CXR and CT images, which are automatically extracted from COVID-19-relevant articles from the PubMed Central Open Access (PMC-OA) Subset. We extracted figures, associated captions, and relevant figure descriptions in the article and separated compound figures into subfigures. Because a large portion of figures in COVID-19 articles are not CXR or CT, we designed a deep-learning model to distinguish them from other figure types and to classify them accordingly. The final database includes 1,327 CT and 263 CXR images (as of May 9, 2020) with their relevant text. To demonstrate the utility of COVID-19-CT-CXR, we conducted four case studies. (1) We show that COVID-19-CT-CXR, when used as additional training data, is able to contribute to improved deep-learning (DL) performance for the classification of COVID-19 and non-COVID-19 CT. (2) We collected CT images of influenza, another common infectious respiratory illness that may present similarly to COVID-19, and fine-tuned a baseline deep neural network to distinguish a diagnosis of COVID-19, influenza, or normal or other types of diseases on CT. (3) We fine-tuned an unsupervised one-class classifier from non-COVID-19 CXR and performed anomaly detection to detect COVID-19 CXR. (4) From text-mined captions and figure descriptions, we compared 15 clinical symptoms and 20 clinical findings of COVID-19 versus those of influenza to demonstrate the disease differences in the scientific publications. Our database is unique, as the figures are retrieved along with relevant text with fine-grained descriptions, and it can be extended easily in the future. We believe that our work is complementary to existing resources and hope that it will contribute to medical image analysis of the COVID-19 pandemic. The dataset, code, and DL models are publicly available at <uri xlink:href="https://github.com/ncbi-nlp/COVID-19-CT-CXR">https://github.com/ncbi-nlp/COVID-19-CT-CXR</uri>.</p>
    </abstract>
    <kwd-group kwd-group-type="AuthorFree">
      <kwd>COVID-19</kwd>
      <kwd>chest X-ray</kwd>
      <kwd>CT</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">Intramural Research Programs of the National Library of Medicine</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">National Institutes of Health</institution>
            <institution-id institution-id-type="fundref">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">NLM</institution>
          </institution-wrap>
        </funding-source>
        <award-id>4R00LM013001</award-id>
      </award-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution content-type="institution">Google Cloud</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <funding-statement>This work was supported in part by the Intramural Research Programs of the National Library of Medicine (NLM) and National Institutes of Health (NIH) Clinical Center. This work also was supported by NLM under Grant 4R00LM013001. This material is also based upon the work supported by Google Cloud.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="10"/>
      <ref-count count="48"/>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <label>1</label>
    <title>Introduction</title>
    <p>The latest threat to global health is the ongoing outbreak of the COVID-19 caused by SARS-CoV-2 <xref rid="ref1" ref-type="bibr">[1]</xref>. So far, pneumonia appears to be the most frequent and serious manifestation, and major complications, such as acute respiratory distress syndrome (ARDS), can present shortly after the onset of symptoms, contributing to the high mortality rate of COVID-19 <xref rid="ref2" ref-type="bibr">[2]</xref>, <xref rid="ref3" ref-type="bibr">[3]</xref>, <xref rid="ref4" ref-type="bibr">[4]</xref>. Chest X-rays (CXR) and chest computed tomography (CT) scans are playing a major part in the detection and monitoring of these respiratory manifestations. In some cases, CT scans have shown abnormal findings in patients prior to the development of symptoms and even before the detection of the viral RNA <xref rid="ref5" ref-type="bibr">[5]</xref>, <xref rid="ref6" ref-type="bibr">[6]</xref>, <xref rid="ref7" ref-type="bibr">[7]</xref>.</p>
    <p>With the shortage of specialists who have been trained to accumulate experiences with COVID-19 diagnosis, there has been a concerted move toward the adoption of artificial intelligence (AI), particularly deep-learning-based methods, in COVID-19 pandemic diagnosis and prognosis, in which well-annotated data always play a critical role <xref rid="ref8" ref-type="bibr">[8]</xref>. Although there exist large public datasets of CXR <xref rid="ref9" ref-type="bibr">[9]</xref>, <xref rid="ref10" ref-type="bibr">[10]</xref>, <xref rid="ref11" ref-type="bibr">[11]</xref> and CT <xref rid="ref12" ref-type="bibr">[12]</xref>, there are few collections of COVID-19 images to effectively train a deep neural network <xref rid="ref13" ref-type="bibr">[13]</xref>, <xref rid="ref14" ref-type="bibr">[14]</xref>, <xref rid="ref15" ref-type="bibr">[15]</xref>. Nevertheless, we have seen a growing number of COVID-19 relevant articles in PubMed <xref rid="ref16" ref-type="bibr">[16]</xref>, <xref rid="ref17" ref-type="bibr">[17]</xref>. In addition, there is a recent COVID-19 initiative to expand access via PubMed Central Open Access (PMC-OA) Subset to coronavirus-related publications and associated data (<uri xlink:href="https://www.ncbi.nlm.nih.gov/pmc/about/covid-19-faq/">https://www.ncbi.nlm.nih.gov/pmc/about/covid-19-faq/</uri>). As a result, more articles (<inline-formula><tex-math notation="LaTeX" id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$&gt;10,000$\end{document}</tex-math><alternatives><mml:math id="M2"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="peng-ieq1-3035935.jpg"/></alternatives></inline-formula> as of May 9, 2020) relevant to the COVID-19 pandemic or prior coronavirus research were added through PMC-OA with a free-reuse license for secondary analysis.</p>
    <p>Non-textual components (e.g., figures and tables) provide key information in many scientific documents and are considered in many tasks, including search engine and knowledge base construction <xref rid="ref18" ref-type="bibr">[18]</xref>, <xref rid="ref19" ref-type="bibr">[19]</xref>. As such, we have recently seen a growing interest in mining figures within scientific documents <xref rid="ref20" ref-type="bibr">[20]</xref>, <xref rid="ref21" ref-type="bibr">[21]</xref>, <xref rid="ref22" ref-type="bibr">[22]</xref>. In the medical domain, figures also are a topical interest because they often contain graphical images, such as CXR and CT <xref rid="ref23" ref-type="bibr">[23]</xref>, <xref rid="ref24" ref-type="bibr">[24]</xref>. Extracting CXR and CT from biomedical publications, however, is neither well studied nor well addressed.</p>
    <p>For the above reasons, there is an unmet need to construct the COVID-19 image dataset from PMC-OA to allow researchers to freely access the images along with a description of the text. In this paper, we thus introduce an effective framework to construct a CXR and CT database from PMC-OA and propose a public database, termed COVID-19-CT-CXR. In contrast to previous approaches that relied solely on the manual submission of medical images to the repository, in this work, figures are automatically collected by using the integration of medical imaging and natural- language processing with limited human annotation efforts. In addition, figures in this database are partnered with text that describes these cases with details, a feature not found in other such datasets.</p>
    <p>The framework consists of three steps. First, we extracted figures, associated captions, and relevant figure descriptions in the PMC-OA article. Such extraction is non-trivial due to the diverse layout and large volume of articles in the PMC-OA subset. Second, we separated compound figures into subfigures, as medical figures often comprise multiple image panels <xref rid="ref21" ref-type="bibr">[21]</xref>, <xref rid="ref24" ref-type="bibr">[24]</xref>. Third, we classified subfigures into CXR, CT, or others because a large portion of figures in COVID-19 articles are not CXR or CT. To this end, we designed a deep-learning model to distinguish them from other figure types and to classify them accordingly.</p>
    <p>We further demonstrate the utility of COVID-19-CT-CXR through a series of case studies. First, using this database as additional training data, we show that existing deep neural networks can receive benefits in the task of COVID-19/non-COVID-19 classification of CT images. Second, we demonstrate that the database can be used to develop a baseline model to distinguish COVID-19, influenza, and other CT, a less-studied topic. Third, we train an unsupervised one-class classifier from non-COVID-19 CXRs and performed anomaly detection to detect COVID-19 CXRs. Fourth, we extract symptoms and clinical findings from the text, using the natural language-processing methods. The symptoms and clinical findings not only confirm the results that radiologists have found but also potentially identify other findings that may have been overlooked.</p>
    <p>The remainder of the paper is organized as follows. <xref rid="sec2" ref-type="sec">Section 2</xref> presents the material and methods to build the dataset. <xref rid="sec3" ref-type="sec">Section 3</xref> contains the details of the statistics of the dataset, results of the image type classification, and the use cases. Finally, <xref rid="sec4" ref-type="sec">Sections 4</xref> and <xref rid="sec5" ref-type="sec">5</xref> provide the discussion, conclusions, and recommendations for future work.</p>
  </sec>
  <sec id="sec2">
    <label>2</label>
    <title>Material and Methods</title>
    <sec id="sec2.1">
      <label>2.1</label>
      <title>COVID-19 Relevant Articles on PMC-OA</title>
      <p>Articles in this study were collected from the PMC-OA Subset. PubMed Central<sup>®</sup> (PMC) is a free, full-text archive of biomedical and life sciences journal literature (<uri xlink:href="https://www.ncbi.nlm.nih.gov/pmc/">https://www.ncbi.nlm.nih.gov/pmc/</uri>). PMC-OA is a well-known portion of the PMC articles under a Creative Commons license (or custom license of the Public Health Emergency COVID-19 Initiative in PMC due to the COVID pandemic) that allows for text mining, secondary analysis, and other types of reuse (<uri xlink:href="https://www.ncbi.nlm.nih.gov/pmc/about/covid-19-faq/">https://www.ncbi.nlm.nih.gov/pmc/about/covid-19-faq/</uri>). In this study, we collected COVID-19 relevant articles using LitCovid <xref rid="ref16" ref-type="bibr">[16]</xref>, a curated literature hub for tracking up-to-date scientific information about the 2019 novel coronavirus. LitCovid screens the search results of the PubMed query: <monospace>”coronavirus”[All Fields] ”ncov”[All Fields] OR ”cov”[All Fields] OR ”2019-nCoV”[All Fields] OR ”COVID-19”[All Fields] OR ”SARS-CoV-2”[All Fields]</monospace>. Relevant articles are identified and curated with assistance from an automated machine-learning and text-classification algorithm. As of May 9, 2020, there were 5,381 PMC-OA articles in the collection (<xref rid="table1" ref-type="table">Table 1</xref>). The topics of articles ranged from diagnosis to treatment to case reports.</p>
      <table-wrap position="float" id="table1">
        <label>TABLE 1</label>
        <caption>
          <title>An Overview of the COVID-19 Relevant Articles as of May 9, 2020</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peng.t1-3035935" position="float"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col span="5"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Characteristics</th>
                <th colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math notation="LaTeX" id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math>
                    <alternatives>
                      <mml:math id="M4">
                        <mml:mi>n</mml:mi>
                      </mml:math>
                      <inline-graphic xlink:href="peng-ieq2-3035935.jpg"/>
                    </alternatives>
                  </inline-formula>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="1" rowspan="1">COVID-19 relevant articles in PMC-OA</td>
                <td colspan="1" rowspan="1">5,381</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Prevention</td>
                <td colspan="1" rowspan="1">2,089</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Mechanism</td>
                <td colspan="1" rowspan="1">577</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Diagnosis</td>
                <td colspan="1" rowspan="1">546</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Case Report</td>
                <td colspan="1" rowspan="1">355</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Transmission</td>
                <td colspan="1" rowspan="1">354</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">General</td>
                <td colspan="1" rowspan="1">238</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Epidemic Forecasting</td>
                <td colspan="1" rowspan="1">64</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Others</td>
                <td colspan="1" rowspan="1">1,158</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Journals</td>
                <td colspan="1" rowspan="1">1,145</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Figures</td>
                <td colspan="1" rowspan="1">4,407</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec2.2">
      <label>2.2</label>
      <title>Overview of the COVID-19-CT-CXR Construction</title>
      <p><xref rid="fig1" ref-type="fig">Fig. 1</xref> shows the overview pipeline of the development. For a given PMC-OA article, we first extract figures, associated captions, and relevant figure descriptions in the PMC-OA article. Then, if figures are compound, we separate them into subfigures. We further classify the individual figures into CT, CXR, or other types of scientific images, using a deep-learning model. The final database includes figures with their types and relevant descriptions in the manuscript.</p>
      <fig position="float" id="fig1">
        <label>Fig. 1.</label>
        <caption>
          <p>The overview of the pipeline to collect the images with text.</p>
        </caption>
        <graphic xlink:href="peng1-3035935" position="float"/>
      </fig>
    </sec>
    <sec id="sec2.3">
      <label>2.3</label>
      <title>Text Extraction</title>
      <p>In this step, we identify figure captions and relevant text with the referenced figures. To facilitate the automated processing of full-text articles in PMC-OA, <xref rid="ref25" ref-type="bibr">[25]</xref> convert PMC articles to BioC format, a data structure in XML for text sharing and processing. Each article in BioC format is encoded in UTF-8, and Unicode characters are converted to strings of ASCII characters. The article also includes section types, figures, tables, and references <xref rid="ref26" ref-type="bibr">[26]</xref>. In this study, we downloaded the PMC-OA articles through the RESTful web service (<uri xlink:href="https://www.ncbi.nlm.nih.gov/research/bionlp/APIs/BioC-PubMed/">https://www.ncbi.nlm.nih.gov/research/bionlp/APIs/BioC-PubMed/</uri>). We parsed these articles to locate figures with their figure numbers and their captions. We then used the figure number and regular expressions to find where the figure is cross-referenced in the document. <xref rid="fig2" ref-type="fig">Fig. 2</xref> shows an example of a typical biomedical image in the article, “A rapid advice guideline for the diagnosis and treatment of 2019 novel coronavirus (2019-nCoV) infected pneumonia (standard version)” <xref rid="ref27" ref-type="bibr">[27]</xref>. The examples contain CXR, CT, a figure caption, and text that describes the case with rich information, such as fever, symptoms, and clinical findings.</p>
      <fig position="float" id="fig2">
        <label>Fig. 2.</label>
        <caption>
          <p>Examples of CT and CXR that are positive for COVID-19. The figures are from the article, “A rapid advice guideline for the diagnosis and treatment of 2019 novel coronavirus (2019-nCoV) infected pneumonia (standard version)” <xref rid="ref27" ref-type="bibr">[27]</xref>.</p>
        </caption>
        <graphic xlink:href="peng2-3035935" position="float"/>
      </fig>
    </sec>
    <sec id="sec2.4">
      <label>2.4</label>
      <title>Subfigure Separation</title>
      <p>Most of the figures in the PMC-OA articles are compound figures. A key challenge here is that one figure may have individual subfigures of the same category (e.g., four CT images) or several categories (e.g., one CXR and one CT image placed side by side). For example, <xref rid="fig2" ref-type="fig">Fig. 2</xref> contains a compound figure with three subfigures <xref rid="ref27" ref-type="bibr">[27]</xref>. <xref rid="fig2" ref-type="fig">Figs. 2a</xref> and <xref rid="fig2" ref-type="fig">2b</xref> are CT images, and <xref rid="fig2" ref-type="fig">Fig. 2c</xref> is a CXR. Notably, it is a requirement to decompose compound figures into subfigures before modality classification. In this study, we used a convolutional neural network developed by <xref rid="ref24" ref-type="bibr">[24]</xref> to separate compound figures. The model was pretrained on the ImageCLEF Medical dataset with an accuracy of 85.9 percent <xref rid="ref28" ref-type="bibr">[28]</xref>.</p>
      <p>We applied the model on the figures obtained in previous steps and filtered the subfigures with a size smaller than 224 x 224 pixels. We consider that subfigures with fewer pixels might be deformed, and most state-of-the-art neural networks in image analysis, such as Inception-v3 <xref rid="ref29" ref-type="bibr">[29]</xref> and DenseNet <xref rid="ref30" ref-type="bibr">[30]</xref>, require an input size of 224 or larger.</p>
    </sec>
    <sec id="sec2.5">
      <label>2.5</label>
      <title>Image Modality Classification</title>
      <p>A large portion of figures in the PMC-OA articles are not CXR or CT images. To distinguish them from other types of scientific figures, we designed a scientific figure classifier that was fine-tuned on a newly created dataset (<uri xlink:href="https://github.com/ncbi-nlp/COVID-19-CT-CXR">https://github.com/ncbi-nlp/COVID-19-CT-CXR</uri>). <xref rid="table2" ref-type="table">Table 2</xref> shows the breakdown of the figures by their category in the training and test set. This dataset consists of 2,700 figures in three categories: CXR, CT, and Other scientific figure types. A total of 500 CXRs are randomly picked from the NIH Chest X-ray <xref rid="ref11" ref-type="bibr">[11]</xref>, and 500 CT images are randomly picked from DeepLesion <xref rid="ref12" ref-type="bibr">[12]</xref>. Other scientific figures are randomly picked from DocFigure <xref rid="ref31" ref-type="bibr">[31]</xref>. The original DocFigure annotated figures of 28 categories, such as Heat map, Bar plots, and Histogram. Here, we combined these categories into one for simplicity of training the classifier. In addition, we curated 1,200 figures from PMC-OA, using the annotation tool developed by <xref rid="ref32" ref-type="bibr">[32]</xref>.</p>
      <table-wrap position="float" id="table2">
        <label>TABLE 2</label>
        <caption>
          <title>Summary of the Dataset for Image Modality Classification</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peng.t2-3035935" position="float"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col span="5"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Modality</th>
                <th colspan="1" rowspan="1">Training</th>
                <th colspan="1" rowspan="1">Test</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="1" rowspan="1">CXR</td>
                <td colspan="1" rowspan="1"/>
                <td colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">NIH Chest X-ray <xref rid="ref11" ref-type="bibr">[11]</xref></td>
                <td colspan="1" rowspan="1">399</td>
                <td colspan="1" rowspan="1">101</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">PMC-OA</td>
                <td colspan="1" rowspan="1">38</td>
                <td colspan="1" rowspan="1">7</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">CT</td>
                <td colspan="1" rowspan="1"/>
                <td colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">DeepLesion <xref rid="ref12" ref-type="bibr">[12]</xref></td>
                <td colspan="1" rowspan="1">415</td>
                <td colspan="1" rowspan="1">85</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">PMC-OA</td>
                <td colspan="1" rowspan="1">225</td>
                <td colspan="1" rowspan="1">21</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Other scientific document figures</td>
                <td colspan="1" rowspan="1"/>
                <td colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">DocFigure <xref rid="ref31" ref-type="bibr">[31]</xref></td>
                <td colspan="1" rowspan="1">386</td>
                <td colspan="1" rowspan="1">114</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">PMC-OA</td>
                <td colspan="1" rowspan="1">737</td>
                <td colspan="1" rowspan="1">172</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Total</td>
                <td colspan="1" rowspan="1">2,200</td>
                <td colspan="1" rowspan="1">500</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>Our framework uses DenseNet121 to classify image types <xref rid="ref33" ref-type="bibr">[33]</xref>. The weights (or parameters) were pretrained on ImageNet <xref rid="ref34" ref-type="bibr">[34]</xref>. We replaced the last classification layer with a fully connected layer with a softmax operation that outputs the approximate probability that an input image is a CXR, CT, or other scientific figure type. All images were resized to 224 x 224 pixels. The hyperparameters include a learning rate of 0.0001, a batch size of 16, and 50 training epochs. All experiments were conducted on a server with an NVIDIA V100 128G GPU from the NIH HPC Biowulf cluster (<uri xlink:href="http://hpc.nih.gov">http://hpc.nih.gov</uri>). We implemented the framework using the Keras deep-learning library with TensorFlow backend (<uri xlink:href="https://www.tensorflow.org/guide/keras">https://www.tensorflow.org/guide/keras</uri>).</p>
    </sec>
    <sec id="sec2.6">
      <label>2.6</label>
      <title>Qualification and Statistical Analysis</title>
      <p>The performance metrics include the area under the receiver operating characteristic curve (AUC), sensitivity, specificity (recall), precision (positive predictive value), and F1 score. For the classification problem, we chose the label with the highest probability when required in computing the metrics. Each of the models was fine-tuned and tested five times, using the same parameters, training, and testing images each time. The validation set was randomly selected from 10 percent of the training set. Fisher's exact test was used to determine whether there are nonrandom associations between COVID-19 and influenza's symptoms and clinical findings <xref rid="ref35" ref-type="bibr">[35]</xref>. We conduct above statistical analysis using numpy, scipy, matplotlib, and scikit-learn built on Python.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <label>3</label>
    <title>Results</title>
    <sec id="sec3.1">
      <label>3.1</label>
      <title>COVID-19-CT-CXR Characteristics</title>
      <p><xref rid="table3" ref-type="table">Table 3</xref> shows the breakdown of the figures by modality. We obtained 1,327 CT images and 263 CXR text-mined labeled as positive for COVID-19 from 1,831 PMC-OA articles. These images have different sizes. The minimum, maximum, and average heights are 224, 2,703, and 387.5 pixels, respectively. The minimum, maximum, and average widths are 224, 1,961, and 472.4, respectively. For each article, we also include major elements, such as DOI, title, journal, and publication date for reference. <xref rid="fig3" ref-type="fig">Fig. 3</xref> A shows the cumulative numbers of articles and figures on a weekly basis. We analyzed the proportional distribution of categories in COVID-19 relevant PMC-OA articles, and articles with figures, CT, and CXR. <xref rid="fig3" ref-type="fig">Fig. 3</xref> B shows that the “Case Report” category contains higher proportional articles with CXR/CT.</p>
      <table-wrap position="float" id="table3">
        <label>TABLE 3</label>
        <caption>
          <title>Summary of the COVID-19-CT-CXR Dataset</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peng.t3-3035935" position="float"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col span="5"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Characteristics</th>
                <th colspan="1" rowspan="1">
                  <inline-formula>
                    <tex-math notation="LaTeX" id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$n$\end{document}</tex-math>
                    <alternatives>
                      <mml:math id="M6">
                        <mml:mi>n</mml:mi>
                      </mml:math>
                      <inline-graphic xlink:href="peng-ieq3-3035935.jpg"/>
                    </alternatives>
                  </inline-formula>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="1" rowspan="1">PMC-OA articles with figures</td>
                <td colspan="1" rowspan="1">1,831</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Subfigures</td>
                <td colspan="1" rowspan="1">10,650</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">CXR</td>
                <td colspan="1" rowspan="1">263</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">CT</td>
                <td colspan="1" rowspan="1">1,327</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Others</td>
                <td colspan="1" rowspan="1">9,060</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <fig position="float" id="fig3">
        <label>Fig. 3.</label>
        <caption>
          <p>Characteristics of the COVID-19-CT-CXR. (A) The rapid growth of the number of COVID-19-relevant articles, CT, and CXR in PMC-OA from January 1, 2020 (Week 1). (B) The distribution of categories in COVID-19-relevant PMC-OA articles and articles with figures, CT, and CXR.</p>
        </caption>
        <graphic xlink:href="peng3-3035935" position="float"/>
      </fig>
    </sec>
    <sec id="sec3.2">
      <label>3.2</label>
      <title>Image Modality Classification</title>
      <p><xref rid="table4" ref-type="table">Table 4</xref> shows the performance of the model to classify image modality. The macro average <italic>F</italic>-score is 0.996. The <italic>F</italic>-score was 0.993 <inline-formula><tex-math notation="LaTeX" id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M8"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq4-3035935.jpg"/></alternatives></inline-formula> 0.004 for CT, 1.000 <inline-formula><tex-math notation="LaTeX" id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M10"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq5-3035935.jpg"/></alternatives></inline-formula> 0.000 for CXR, and 0.998 <inline-formula><tex-math notation="LaTeX" id="M11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M12"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq6-3035935.jpg"/></alternatives></inline-formula> 0.001 for other scientific figure types.</p>
      <table-wrap position="float" id="table4">
        <label>TABLE 4</label>
        <caption>
          <title>The Performance of Image Type Classification</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peng.t4-3035935" position="float"/>
          <table frame="box" rules="all" cellpadding="5">
            <colgroup span="1">
              <col span="5"/>
            </colgroup>
            <thead>
              <tr>
                <th colspan="1" rowspan="1">Metrics</th>
                <th colspan="1" rowspan="1">CT</th>
                <th colspan="1" rowspan="1">CXR</th>
                <th colspan="1" rowspan="1">Other scientific figures</th>
                <th colspan="1" rowspan="1">
                  <italic>Macro Avg</italic>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="1" rowspan="1">Precision</td>
                <td colspan="1" rowspan="1">0.989 <inline-formula><tex-math notation="LaTeX" id="M13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M14"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq7-3035935.jpg"/></alternatives></inline-formula> 0.004</td>
                <td colspan="1" rowspan="1">1.000 <inline-formula><tex-math notation="LaTeX" id="M15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M16"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq8-3035935.jpg"/></alternatives></inline-formula> 0.000</td>
                <td colspan="1" rowspan="1">0.999 <inline-formula><tex-math notation="LaTeX" id="M17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M18"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq9-3035935.jpg"/></alternatives></inline-formula> 0.001</td>
                <td colspan="1" rowspan="1">0.996 <inline-formula><tex-math notation="LaTeX" id="M19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M20"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq10-3035935.jpg"/></alternatives></inline-formula> 0.002</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Recall/Sensitivity</td>
                <td colspan="1" rowspan="1">0.998 <inline-formula><tex-math notation="LaTeX" id="M21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M22"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq11-3035935.jpg"/></alternatives></inline-formula> 0.004</td>
                <td colspan="1" rowspan="1">1.000 <inline-formula><tex-math notation="LaTeX" id="M23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M24"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq12-3035935.jpg"/></alternatives></inline-formula> 0.000</td>
                <td colspan="1" rowspan="1">0.996 <inline-formula><tex-math notation="LaTeX" id="M25">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M26"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq13-3035935.jpg"/></alternatives></inline-formula> 0.001</td>
                <td colspan="1" rowspan="1">0.998 <inline-formula><tex-math notation="LaTeX" id="M27">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M28"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq14-3035935.jpg"/></alternatives></inline-formula> 0.002</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1">Specificity</td>
                <td colspan="1" rowspan="1">0.997 <inline-formula><tex-math notation="LaTeX" id="M29">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M30"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq15-3035935.jpg"/></alternatives></inline-formula> 0.001</td>
                <td colspan="1" rowspan="1">1.000 <inline-formula><tex-math notation="LaTeX" id="M31">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M32"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq16-3035935.jpg"/></alternatives></inline-formula> 0.000</td>
                <td colspan="1" rowspan="1">0.999 <inline-formula><tex-math notation="LaTeX" id="M33">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M34"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq17-3035935.jpg"/></alternatives></inline-formula> 0.002</td>
                <td colspan="1" rowspan="1">0.999 <inline-formula><tex-math notation="LaTeX" id="M35">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M36"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq18-3035935.jpg"/></alternatives></inline-formula> 0.001</td>
              </tr>
              <tr>
                <td colspan="1" rowspan="1"><italic>F</italic>-score</td>
                <td colspan="1" rowspan="1">0.993 <inline-formula><tex-math notation="LaTeX" id="M37">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M38"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq19-3035935.jpg"/></alternatives></inline-formula> 0.004</td>
                <td colspan="1" rowspan="1">1.000 <inline-formula><tex-math notation="LaTeX" id="M39">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M40"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq20-3035935.jpg"/></alternatives></inline-formula> 0.000</td>
                <td colspan="1" rowspan="1">0.998 <inline-formula><tex-math notation="LaTeX" id="M41">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M42"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq21-3035935.jpg"/></alternatives></inline-formula> 0.001</td>
                <td colspan="1" rowspan="1">0.997 <inline-formula><tex-math notation="LaTeX" id="M43">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M44"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq22-3035935.jpg"/></alternatives></inline-formula> 0.002</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <p>The test set is the combination of NIH Chest X-ray, DeepLesion, DocFigure, and PMC-OA.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec3.3">
      <label>3.3</label>
      <title>Use Cases</title>
      <p>To demonstrate the utility of COVID-19-CT-CXR, we conducted four case studies. (1) We combined COVID-19-CT-CXR with previously curated data at <uri xlink:href="https://github.com/UCSD-AI4H/COVID-CT">https://github.com/UCSD-AI4H/COVID-CT</uri>
<xref rid="ref36" ref-type="bibr">[36]</xref> and fine-tuned a deep neural network to perform the classification of COVID-19 and non-COVID-19 CT. (2) We collected CT of influenza, using a similar method, and fine-tuned a deep neural network to distinguish among the diagnoses of COVID-19, influenza, and normal or other types of diseases on CT. (3) We fine-tuned an unsupervised one-class learning model, using only non-COVID-19 CXR to perform anomaly detection, to detect COVID-19 CXR. (4) We extracted 15 clinical symptoms and 26 clinical findings from the captions and relevant descriptions. We then compared their frequencies to those described in articles on influenza, another common infectious respiratory illness that may present similarly to COVID-19.</p>
      <sec id="sec3.3.1">
        <label>3.3.1</label>
        <title>Classification of COVID-19 and non-COVID-19 on CT</title>
        <p>In the context of the COVID-19 pandemic, it is important to separate patients likely to be infected with COVID-19 from other non-COVID-19 patients. As it is time-consuming for specialists to both accumulate experiences and read a large volume of CT scans to diagnose COVID-19, many studies use machine learning to separate COVID-19 patients from non-COVID-19 patients <xref rid="ref14" ref-type="bibr">[14]</xref>, <xref rid="ref37" ref-type="bibr">[37]</xref>, <xref rid="ref38" ref-type="bibr">[38]</xref>, <xref rid="ref39" ref-type="bibr">[39]</xref>, <xref rid="ref40" ref-type="bibr">[40]</xref>. In this work, we hypothesize that our creation of additional training data from existing articles can improve the performance of the system and reduce the effort of manual image annotation. To test this hypothesis, we compared the performance of deep neural networks fine-tuned on the existing benchmark <xref rid="ref36" ref-type="bibr">[36]</xref> and COVID-19-CT-CXR (<xref rid="table5" ref-type="table">Table 5</xref>). For a fair comparison, we added additional training examples only in the training set and used the same test set as described in <xref rid="ref14" ref-type="bibr">[14]</xref>.</p>
        <table-wrap position="float" id="table5">
          <label>TABLE 5</label>
          <caption>
            <title>Summary of the Dataset for Classification of COVID-19 and non-COVID-19 CT</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peng.t5-3035935" position="float"/>
            <table frame="box" rules="all" cellpadding="5">
              <colgroup span="1">
                <col span="5"/>
              </colgroup>
              <thead>
                <tr>
                  <th colspan="1" rowspan="1">Dataset</th>
                  <th colspan="1" rowspan="1"/>
                  <th colspan="1" rowspan="1">COVID-19</th>
                  <th colspan="1" rowspan="1">Non-COVID-19</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="1" rowspan="1">Training</td>
                  <td colspan="1" rowspan="1">
                    <xref rid="ref36" ref-type="bibr">[36]</xref>
                  </td>
                  <td colspan="1" rowspan="1">251</td>
                  <td colspan="1" rowspan="1">292</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1"/>
                  <td colspan="1" rowspan="1">COVID-19-CT</td>
                  <td colspan="1" rowspan="1">542</td>
                  <td colspan="1" rowspan="1">67</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Test</td>
                  <td colspan="1" rowspan="1">
                    <xref rid="ref36" ref-type="bibr">[36]</xref>
                  </td>
                  <td colspan="1" rowspan="1">98</td>
                  <td colspan="1" rowspan="1">105</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <p>In this experiment, DenseNet121 was pre-trained on ImageNet, fine-tuned, and evaluated on the training and test sets. We then replaced the last classification layer with a single neuron with sigmoid that outputs the approximate probability that an input image is COVID-19 or non-COVID-19. Other experimental settings are the same as that of fine-tuning the image modality classifier. <xref rid="fig4" ref-type="fig">Fig. 4</xref> shows that the model significantly outperforms the baseline when PMC-OA CT figures were added for fine-tuning. Specifically, we achieved the highest performance of 0.891 <inline-formula><tex-math notation="LaTeX" id="M45">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M46"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq23-3035935.jpg"/></alternatives></inline-formula> 0.012 in AUC, 0.780 <inline-formula><tex-math notation="LaTeX" id="M47">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M48"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq24-3035935.jpg"/></alternatives></inline-formula> 0.074 in recall, 0.816 <inline-formula><tex-math notation="LaTeX" id="M49">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M50"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq25-3035935.jpg"/></alternatives></inline-formula> 0.053 in precision, and 0.792 <inline-formula><tex-math notation="LaTeX" id="M51">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M52"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq26-3035935.jpg"/></alternatives></inline-formula> 0.015 in <italic>F</italic>-score (<xref rid="table6" ref-type="table">Table 6</xref>).</p>
        <table-wrap position="float" id="table6">
          <label>TABLE 6</label>
          <caption>
            <title>Performance Metrics for Classification of COVID-19 and non-COVID-19 CT</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peng.t6-3035935" position="float"/>
            <table frame="box" rules="all" cellpadding="5">
              <colgroup span="1">
                <col span="5"/>
              </colgroup>
              <thead>
                <tr>
                  <th colspan="1" rowspan="1">Metrics</th>
                  <th colspan="1" rowspan="1">Without using</th>
                  <th colspan="1" rowspan="1">Using COVID-19-CT</th>
                </tr>
                <tr>
                  <th colspan="1" rowspan="1"/>
                  <th colspan="1" rowspan="1">COVID-19-CT</th>
                  <th colspan="1" rowspan="1"/>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="1" rowspan="1">AUC</td>
                  <td colspan="1" rowspan="1">0.811 <inline-formula><tex-math notation="LaTeX" id="M53">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M54"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq27-3035935.jpg"/></alternatives></inline-formula> 0.017</td>
                  <td colspan="1" rowspan="1">0.891 <inline-formula><tex-math notation="LaTeX" id="M55">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M56"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq28-3035935.jpg"/></alternatives></inline-formula> 0.012</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Precision</td>
                  <td colspan="1" rowspan="1">0.742 <inline-formula><tex-math notation="LaTeX" id="M57">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M58"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq29-3035935.jpg"/></alternatives></inline-formula> 0.029</td>
                  <td colspan="1" rowspan="1">0.816 <inline-formula><tex-math notation="LaTeX" id="M59">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M60"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq30-3035935.jpg"/></alternatives></inline-formula> 0.053</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Recall/Sensitivity</td>
                  <td colspan="1" rowspan="1">0.714 <inline-formula><tex-math notation="LaTeX" id="M61">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M62"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq31-3035935.jpg"/></alternatives></inline-formula> 0.083</td>
                  <td colspan="1" rowspan="1">0.780 <inline-formula><tex-math notation="LaTeX" id="M63">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M64"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq32-3035935.jpg"/></alternatives></inline-formula> 0.074</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Specificity</td>
                  <td colspan="1" rowspan="1">0.764 <inline-formula><tex-math notation="LaTeX" id="M65">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M66"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq33-3035935.jpg"/></alternatives></inline-formula> 0.059</td>
                  <td colspan="1" rowspan="1">0.827 <inline-formula><tex-math notation="LaTeX" id="M67">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M68"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq34-3035935.jpg"/></alternatives></inline-formula> 0.073</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1"><italic>F</italic>-score</td>
                  <td colspan="1" rowspan="1">0.724 <inline-formula><tex-math notation="LaTeX" id="M69">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M70"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq35-3035935.jpg"/></alternatives></inline-formula> 0.034</td>
                  <td colspan="1" rowspan="1">0.792 <inline-formula><tex-math notation="LaTeX" id="M71">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M72"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq36-3035935.jpg"/></alternatives></inline-formula> 0.015</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <fig position="float" id="fig4">
          <label>Fig. 4.</label>
          <caption>
            <p>Comparison of AUC and <italic>F</italic>-score by models fine-tuned with and without using additional COVID-19 CT extracted from PMC-OA. <sup>*</sup>: <inline-formula><tex-math notation="LaTeX" id="M73">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$P \leq 0.05$\end{document}</tex-math><alternatives><mml:math id="M74"><mml:mrow><mml:mi>P</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>05</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="peng-ieq37-3035935.jpg"/></alternatives></inline-formula>; <sup>***</sup>: <inline-formula><tex-math notation="LaTeX" id="M75">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$P \leq 0.001$\end{document}</tex-math><alternatives><mml:math id="M76"><mml:mrow><mml:mi>P</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>001</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="peng-ieq38-3035935.jpg"/></alternatives></inline-formula> (t-test).</p>
          </caption>
          <graphic xlink:href="peng4-3035935" position="float"/>
        </fig>
      </sec>
      <sec id="sec3.3.2">
        <label>3.3.2</label>
        <title>Classification of COVID-19, Influenza, and Other Types of Disease on CT</title>
        <p>As the COVID-19 outbreak continues to evolve, there is an increasing number of studies that compare COVID-19 with other viral pneumonias, such as influenza <xref rid="ref41" ref-type="bibr">[41]</xref>. Distinguishing patients infected by COVID-19 and influenza is important for public health measures because the current treatment guidelines are different <xref rid="ref42" ref-type="bibr">[42]</xref>. This task is non- trivial because both viruses have a similar radiological presentation. To assist clinicians at triage, several studies have proposed to use deep learning to distinguish COVID-19 from influenza and no-infection with 3D CT scans <xref rid="ref43" ref-type="bibr">[43]</xref>. In this paper, we aim to establish a baseline model to distinguish COVID-19 from influenza on single CT figures. To collect CT figures with influenza, we searched the PMC using the query “<monospace>(Influenza[Title] OR (flu[Title] AND pneumonia[Title]) AND open access[Filter]</monospace>” and extracted the most recent 10,000 PMC-OA articles. We used the same method to extract CT and its caption and relevant text from the articles (called Influenza-CT). Taken together, we construct a dataset with 983 CT for training and 242 CT for testing (<xref rid="table7" ref-type="table">Table 7</xref>).</p>
        <table-wrap position="float" id="table7">
          <label>TABLE 7</label>
          <caption>
            <title>Summary of the Dataset for Classification of COVID-19, Influenza, and Others in CT</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peng.t7-3035935" position="float"/>
            <table frame="box" rules="all" cellpadding="5">
              <colgroup span="1">
                <col span="5"/>
              </colgroup>
              <thead>
                <tr>
                  <th colspan="1" rowspan="1">Dataset</th>
                  <th colspan="1" rowspan="1">COVID-19</th>
                  <th colspan="1" rowspan="1">Influenza</th>
                  <th colspan="1" rowspan="1">Normal or</th>
                </tr>
                <tr>
                  <th colspan="1" rowspan="1"/>
                  <th colspan="1" rowspan="1"/>
                  <th colspan="1" rowspan="1"/>
                  <th colspan="1" rowspan="1">other diseases</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="1" rowspan="1">Training</td>
                  <td colspan="1" rowspan="1">488</td>
                  <td colspan="1" rowspan="1">177</td>
                  <td colspan="1" rowspan="1">318</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Test</td>
                  <td colspan="1" rowspan="1">118</td>
                  <td colspan="1" rowspan="1">45</td>
                  <td colspan="1" rowspan="1">79</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <p>To obtain the baseline model, we use the same model and experimental settings as described in the “Image modality classification” section. <xref rid="fig5" ref-type="fig">Fig. 5</xref> shows the performance of the deep-learning model by its receiver operating characteristic (ROC) curves. The AUC was 0.855 <inline-formula><tex-math notation="LaTeX" id="M77">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M78"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq39-3035935.jpg"/></alternatives></inline-formula> 0.012 for COVID-19 detection and 0.889 <inline-formula><tex-math notation="LaTeX" id="M79">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M80"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq40-3035935.jpg"/></alternatives></inline-formula> 0.014 for influenza detection. <xref rid="table8" ref-type="table">Table 8</xref> shows more detail for the results. We achieved the highest precision (0.845 <inline-formula><tex-math notation="LaTeX" id="M81">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M82"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq41-3035935.jpg"/></alternatives></inline-formula> 0.026) for COVID-19 detection and high recall (0.711 <inline-formula><tex-math notation="LaTeX" id="M83">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M84"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq42-3035935.jpg"/></alternatives></inline-formula> 0.053) for influenza detection.</p>
        <table-wrap position="float" id="table8">
          <label>TABLE 8</label>
          <caption>
            <title>Performance Metrics for Classification of COVID-19, Influenza, and Normal or Other Types of Diseases in CT</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peng.t8-3035935" position="float"/>
            <table frame="box" rules="all" cellpadding="5">
              <colgroup span="1">
                <col span="5"/>
              </colgroup>
              <thead>
                <tr>
                  <th colspan="1" rowspan="1">Metrics</th>
                  <th colspan="1" rowspan="1">COVID-19</th>
                  <th colspan="1" rowspan="1">Influenza</th>
                  <th colspan="1" rowspan="1">Normal or other diseases</th>
                  <th colspan="1" rowspan="1">
                    <italic>Macro Avg</italic>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="1" rowspan="1">AUC</td>
                  <td colspan="1" rowspan="1">0.855 <inline-formula><tex-math notation="LaTeX" id="M85">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M86"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq43-3035935.jpg"/></alternatives></inline-formula> 0.012</td>
                  <td colspan="1" rowspan="1">0.889 <inline-formula><tex-math notation="LaTeX" id="M87">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M88"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq44-3035935.jpg"/></alternatives></inline-formula> 0.014</td>
                  <td colspan="1" rowspan="1">0.904 <inline-formula><tex-math notation="LaTeX" id="M89">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M90"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq45-3035935.jpg"/></alternatives></inline-formula> 0.011</td>
                  <td colspan="1" rowspan="1">0.879 <inline-formula><tex-math notation="LaTeX" id="M91">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M92"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq46-3035935.jpg"/></alternatives></inline-formula> 0.010</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Precision</td>
                  <td colspan="1" rowspan="1">0.845 <inline-formula><tex-math notation="LaTeX" id="M93">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M94"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq47-3035935.jpg"/></alternatives></inline-formula> 0.026</td>
                  <td colspan="1" rowspan="1">0.609 <inline-formula><tex-math notation="LaTeX" id="M95">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M96"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq48-3035935.jpg"/></alternatives></inline-formula> 0.033</td>
                  <td colspan="1" rowspan="1">0.642 <inline-formula><tex-math notation="LaTeX" id="M97">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M98"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq49-3035935.jpg"/></alternatives></inline-formula> 0.021</td>
                  <td colspan="1" rowspan="1">0.699 <inline-formula><tex-math notation="LaTeX" id="M99">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M100"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq50-3035935.jpg"/></alternatives></inline-formula> 0.019</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Recall/Sensitivity</td>
                  <td colspan="1" rowspan="1">0.597 <inline-formula><tex-math notation="LaTeX" id="M101">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M102"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq51-3035935.jpg"/></alternatives></inline-formula> 0.030</td>
                  <td colspan="1" rowspan="1">0.711 <inline-formula><tex-math notation="LaTeX" id="M103">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M104"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq52-3035935.jpg"/></alternatives></inline-formula> 0.053</td>
                  <td colspan="1" rowspan="1">0.861 <inline-formula><tex-math notation="LaTeX" id="M105">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M106"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq53-3035935.jpg"/></alternatives></inline-formula> 0.033</td>
                  <td colspan="1" rowspan="1">0.723 <inline-formula><tex-math notation="LaTeX" id="M107">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M108"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq54-3035935.jpg"/></alternatives></inline-formula> 0.022</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Specificity</td>
                  <td colspan="1" rowspan="1">0.895 <inline-formula><tex-math notation="LaTeX" id="M109">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M110"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq55-3035935.jpg"/></alternatives></inline-formula> 0.024</td>
                  <td colspan="1" rowspan="1">0.895 <inline-formula><tex-math notation="LaTeX" id="M111">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M112"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq56-3035935.jpg"/></alternatives></inline-formula> 0.013</td>
                  <td colspan="1" rowspan="1">0.767 <inline-formula><tex-math notation="LaTeX" id="M113">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M114"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq57-3035935.jpg"/></alternatives></inline-formula> 0.025</td>
                  <td colspan="1" rowspan="1">0.852 <inline-formula><tex-math notation="LaTeX" id="M115">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M116"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq58-3035935.jpg"/></alternatives></inline-formula> 0.009</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1"><italic>F</italic>-score</td>
                  <td colspan="1" rowspan="1">0.699 <inline-formula><tex-math notation="LaTeX" id="M117">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M118"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq59-3035935.jpg"/></alternatives></inline-formula> 0.018</td>
                  <td colspan="1" rowspan="1">0.655 <inline-formula><tex-math notation="LaTeX" id="M119">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M120"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq60-3035935.jpg"/></alternatives></inline-formula> 0.034</td>
                  <td colspan="1" rowspan="1">0.735 <inline-formula><tex-math notation="LaTeX" id="M121">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M122"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq61-3035935.jpg"/></alternatives></inline-formula> 0.015</td>
                  <td colspan="1" rowspan="1">0.696 <inline-formula><tex-math notation="LaTeX" id="M123">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M124"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq62-3035935.jpg"/></alternatives></inline-formula> 0.018</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <fig position="float" id="fig5">
          <label>Fig. 5.</label>
          <caption>
            <p>Receiver operating characteristic (ROC) curves of the classification of COVID-19, influenza, and normal or other types of diseases in CT. The model was fine-tuned and tested 5 times, using the same training and testing images each time. The mean ROC curve is shown together with its standard deviation (shaded area).</p>
          </caption>
          <graphic xlink:href="peng5-3035935" position="float"/>
        </fig>
      </sec>
      <sec id="sec3.3.3">
        <label>3.3.3</label>
        <title>Anomaly Detection of COVID-19 in CXR Using One-Class Learning</title>
        <p>As they lack annotated COVID-19 CXR for training powerful deep-learning classifiers, unsupervised and semi-supervised approaches are highly desired for automated COVID-19 diagnosis. The presence of COVID-19 can be considered a novel anomaly in CXR for the NIH Chest X-ray dataset, in which no COVID-19 cases are available. In this experiment, we performed anomaly detection <xref rid="ref44" ref-type="bibr">[44]</xref>, <xref rid="ref45" ref-type="bibr">[45]</xref> to detect COVID-19 CXR. We trained a one-class classifier, using only non-COVID-19 CXR, and used this classifier to distinguish COVID-19 CXR from non-COVID-19 CXR. The non-COVID-19 images were a subset extracted from the NIH Chest X-ray dataset by combining 14 abnormalities and a no-finding category. The detailed numbers of training and testing CXR are shown in <xref rid="table9" ref-type="table">Table 9</xref>. We adopted the generative adversarial one-class learning approach from <xref rid="ref46" ref-type="bibr">[46]</xref>. <xref rid="fig6" ref-type="fig">Fig. 6</xref> shows the performance of the unsupervised one-class learning by its ROC curves. <xref rid="table10" ref-type="table">Table 10</xref> shows more detail for the results. Our model achieved 0.828 <inline-formula><tex-math notation="LaTeX" id="M125">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M126"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq63-3035935.jpg"/></alternatives></inline-formula> 0.019 in AUC, 0.767 <inline-formula><tex-math notation="LaTeX" id="M127">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M128"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq64-3035935.jpg"/></alternatives></inline-formula> 0.020 in precision, 0.772 <inline-formula><tex-math notation="LaTeX" id="M129">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M130"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq65-3035935.jpg"/></alternatives></inline-formula> 0.017 in recall, and 0.769 <inline-formula><tex-math notation="LaTeX" id="M131">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M132"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq66-3035935.jpg"/></alternatives></inline-formula> 0.018 in <italic>F</italic>-score for COVID-19 anomaly detection.</p>
        <table-wrap position="float" id="table9">
          <label>TABLE 9</label>
          <caption>
            <title>Summary of Dataset Used for Anomaly Detection of COVID-19 in CXR in Unsupervised One-Class Classification</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peng.t9-3035935" position="float"/>
            <table frame="box" rules="all" cellpadding="5">
              <colgroup span="1">
                <col span="5"/>
              </colgroup>
              <thead>
                <tr>
                  <th colspan="1" rowspan="1">Dataset</th>
                  <th colspan="1" rowspan="1">COVID-19</th>
                  <th colspan="1" rowspan="1">Non-COVID-19</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="1" rowspan="1">Training</td>
                  <td colspan="1" rowspan="1">0</td>
                  <td colspan="1" rowspan="1">37,829</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Test</td>
                  <td colspan="1" rowspan="1">184</td>
                  <td colspan="1" rowspan="1">184</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <table-wrap position="float" id="table10">
          <label>TABLE 10</label>
          <caption>
            <title>Anomaly Detection Performance of COVID-19 Versus non-COVID-19 Using Unsupervised One-Class Learning</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peng.t10-3035935" position="float"/>
            <table frame="box" rules="all" cellpadding="5">
              <colgroup span="1">
                <col span="5"/>
              </colgroup>
              <thead>
                <tr>
                  <th colspan="1" rowspan="1">Metrics</th>
                  <th colspan="1" rowspan="1">COVID-19 vs Non-COVID-19</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="1" rowspan="1">AUC</td>
                  <td colspan="1" rowspan="1">0.828 <inline-formula><tex-math notation="LaTeX" id="M133">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M134"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq67-3035935.jpg"/></alternatives></inline-formula> 0.019</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Precision</td>
                  <td colspan="1" rowspan="1">0.767 <inline-formula><tex-math notation="LaTeX" id="M135">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M136"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq68-3035935.jpg"/></alternatives></inline-formula> 0.020</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Recall/Sensitivity</td>
                  <td colspan="1" rowspan="1">0.772 <inline-formula><tex-math notation="LaTeX" id="M137">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M138"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq69-3035935.jpg"/></alternatives></inline-formula> 0.017</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1">Specificity</td>
                  <td colspan="1" rowspan="1">0.765 <inline-formula><tex-math notation="LaTeX" id="M139">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M140"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq70-3035935.jpg"/></alternatives></inline-formula> 0.023</td>
                </tr>
                <tr>
                  <td colspan="1" rowspan="1"><italic>F</italic>-score</td>
                  <td colspan="1" rowspan="1">0.769 <inline-formula><tex-math notation="LaTeX" id="M141">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M142"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq71-3035935.jpg"/></alternatives></inline-formula> 0.018</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <fig position="float" id="fig6">
          <label>Fig. 6.</label>
          <caption>
            <p>Receiver operating characteristic (ROC) curves of the classification of COVID-19 anomaly detection in CXR. The model was fine-tuned and tested 5 times, using the same training and testing images each time. The mean ROC curve is shown together with its standard deviation (shaded area).</p>
          </caption>
          <graphic xlink:href="peng6-3035935" position="float"/>
        </fig>
      </sec>
      <sec id="sec3.3.4">
        <label>3.3.4</label>
        <title>Extraction of Clinical Symptoms and Findings Using Text-Mining</title>
        <p>In this case, we extracted clinical symptoms or signs from the figure captions and relevant text that describes the case. A total of 15 symptoms or signs were collected from <xref rid="ref3" ref-type="bibr">[3]</xref> and the CDC website (<uri xlink:href="https://www.cdc.gov/coronavirus/2019-ncov/symptoms-testing/symptoms.html">https://www.cdc.gov/coronavirus/2019-ncov/symptoms-testing/symptoms.html</uri>), including chest pain, constipation, cough, diarrhea, dizziness, dyspnea, fatigue, fever, headache, myalgia, proteinuria, runny nose, sputum production, throat pain, and vomiting.</p>
        <p>Extracting these symptoms from text is a challenging task because their mentions in the text can be positive or negative. For example, “fever” is negative in the sentence, “She experienced headache and pharyngalgia but no fever on 29 January.” To discriminate between positive and negative mentions, we applied our previously developed tool, NegBio, on the figure caption and referred text <xref rid="ref47" ref-type="bibr">[47]</xref>. In short, NegBio utilizes patterns in universal dependencies to identify the scope of triggers that are indicative of negation; thus, it is highly accurate for detecting negative symptom mentions. <xref rid="fig7" ref-type="fig">Fig. 7</xref> A shows the proportion of symptoms for COVID-19 and influenza. The most common symptoms are fever, cough, dyspnea, and myalgia.</p>
        <fig position="float" id="fig7">
          <label>Fig. 7.</label>
          <caption>
            <p>The frequencies of (A) 15 symptoms and (B) 20 clinical findings text mined from the figure captions and relevant text from the collection of COVID-19- and influenza-relevant articles. ****: <inline-formula><tex-math notation="LaTeX" id="M143">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$p \leq 0.0001$\end{document}</tex-math><alternatives><mml:math id="M144"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0001</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="peng-ieq72-3035935.jpg"/></alternatives></inline-formula> (Fisher exact test).</p>
          </caption>
          <graphic xlink:href="peng7-3035935" position="float"/>
        </fig>
        <p>We then extracted the radiographic findings from the figure caption and text. The findings (and their synonyms) are based on 20 common thoracic disease types, which are expanded from NIH Chest X-ray 14 labels <xref rid="ref11" ref-type="bibr">[11]</xref>. <xref rid="fig7" ref-type="fig">Fig. 7</xref> B shows the 20 findings in both COVID-19 and influenza datasets. Both illnesses can result in lung opacity, pneumonia, and consolidation. COVID-19 more likely results in ground-glass opacification (GGO), while influenza more likely results in infiltration than does COVID-19 (Fisher's exact test, <inline-formula><tex-math notation="LaTeX" id="M145">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$p&lt;0.0001$\end{document}</tex-math><alternatives><mml:math id="M146"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0001</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="peng-ieq73-3035935.jpg"/></alternatives></inline-formula>).</p>
      </sec>
    </sec>
  </sec>
  <sec id="sec4">
    <label>4</label>
    <title>Discussion</title>
    <p>In this abrupt outbreak of SARS-CoV-2, the demand for chest radiographs and CT scans is growing rapidly, but there is a shortage of experienced specialists, radiologists, and researchers. Further, we are still new to this virus and have yet to discover the full radiologic features and prognosis of this disease. The tremendous increase in the number of patients has led to a substantial increase of COVID-19-related PMC-OA articles over the past few months (Figur <xref rid="fig3" ref-type="fig">3</xref> A), especially in the case report and diagnosis-relevant articles (<xref rid="fig3" ref-type="fig">Fig. 3</xref> B). These articles contain rich chest radiographs and CT images that are helpful for scientists and clinicians in describing COVID-19 cases. Thus, it is important to analyze these images and text to construct a large-scale database. By using the quickly increasing dataset, AI methods can help to find significant features of COVID-19 and speed up the clinical workload. Among others, deep learning is undoubtedly a powerful approach in dealing with a pandemic outbreak of COVID-19.</p>
    <p>Although deep learning has shown promise in diagnosing/screening COVID-19, using CT, it remains difficult to collect large-scale labeled imaging data, especially in the public domain. In this work, we present a set of repeatable techniques to rapidly build a CT and CXR dataset of COVID-19 from PMC-OA COVID-19-relevant articles. The strength of the study lies in its multidisciplinary integration of medical imagining and natural-language processing. It provides a new way to annotate large-scale medical images required by deep-learning models.</p>
    <p>An additional strength includes a highly accurate model for image type classification. As a large portion of figures in the PMC-OA articles are not CXR or CT images, we provided a model to classify these two types from other scientific figure types. Our model achieved both high precision and high recall (<xref rid="table4" ref-type="table">Table 4</xref>).</p>
    <p>To assess the hypothesis that deep neural network fine-tuning on this additional dataset enables us to diagnose COVID-19 with almost no hand-labeled data, we conducted several experiments. First, we showed that this additional data enable significant performance gains to classify COVID-19 versus non-COVID-19 lung infection on CT (<xref rid="fig4" ref-type="fig">Fig. 4</xref> and Supplementary <xref rid="table6" ref-type="table">Table 6</xref>, which can be found on the Computer Society Digital Library at <uri xlink:href="http://doi.ieeecomputersociety.org/10.1109/TBDATA.2020.3035935">http://doi.ieeecomputersociety.org/10.1109/TBDATA.2020.3035935</uri>). For our own system, we show that our baseline performance compares favorably to the results in <xref rid="ref14" ref-type="bibr">[14]</xref>. Then, we added more automatically labeled training data and achieved the highest performance of 0.891 <inline-formula><tex-math notation="LaTeX" id="M147">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M148"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq74-3035935.jpg"/></alternatives></inline-formula> 0.012 in AUC. The comparison shows that, with additional data, both precision and recall substantially improve (7.4 and 6.6 percent, respectively). This observation indicates that additional COVID-19 CT helps to not only find more but also to restrict the positive predictions to those with the highest certainty in the model.</p>
    <p>In a more challenging scenario, we built a baseline system to distinguish COVID-19, influenza, and no-infection CT, which is a more clinically interesting but also more challenging task. We observed that we could achieve high AUCs for both COVID-19 and influenza detection. The recall of COVID-19 detection and the precision of influenza, however, are low (0.597 <inline-formula><tex-math notation="LaTeX" id="M149">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M150"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq75-3035935.jpg"/></alternatives></inline-formula> 0.030 and 0.609 <inline-formula><tex-math notation="LaTeX" id="M151">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\pm$\end{document}</tex-math><alternatives><mml:math id="M152"><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href="peng-ieq76-3035935.jpg"/></alternatives></inline-formula> 0.033, respectively). Although several studies have tackled this problem <xref rid="ref43" ref-type="bibr">[43]</xref>, to the best of our knowledge, there is no publicly available benchmarking. The differentiation between COVID-19 and influenza on CXR/CT without associated context is challenging. In the experiment on classification of COVID-19, influenza, and other types of disease on CT, we found that although many of the CT findings had overlapping findings, “mixed GGO (Ground glass opacity)” were mostly found in the COVID-19 dataset and “pleural thickening” and “linear opacities” were mostly found in the influenza dataset. It is also worthy to note that the images from PMC-OA may not represent the typical pool of influenza pneumonia real-world images, since researchers may report extreme cases instead of typical cases. While our work only scratches the surface of the classification of COVID-19, influenza, and normal or other types of diseases, we hope that it sheds light on the development of generalizable deep-learning models that can assist frontline radiologists.</p>
    <p>In addition, we presented a one-class learning model for anomaly detection of COVID-19 in CXR by learning only from non-COVID-19 radiographs. Compared to the CT-based method, the one-class model achieves comparable performance, showing great potential in discriminating COVID-19 from CXR. The performance of our model, however, is worse than that of <xref rid="ref45" ref-type="bibr">[45]</xref>, suggesting that this weakly labeled dataset should be used as additional training data obtained without additional annotation cost from existing entries in curated databases.</p>
    <p>The unique characteristic of our database is that figures are retrieved along with relevant text that describes these cases in detail. Thus, text mining can be applied to extract additional information that confirms the existing results and potentially identifies other findings that may have been overlooked. As proof of this concept, we extracted clinical symptoms and findings from the text. We found that the most common symptoms of COVID-19 were fever and cough (<xref rid="fig7" ref-type="fig">Fig. 7</xref> A), which are consistent with the clinical characteristics in <xref rid="ref15" ref-type="bibr">[15]</xref>. Other common symptoms include dyspnea (shortness of breath), fatigue, and throat pain. These symptoms are consistent with those reported by the CDC. When comparing the frequencies of these 20 clinical findings to those described in articles on influenza, <xref rid="fig7" ref-type="fig">Fig. 7</xref> shows that both conditions cause lung opacity, pneumonia, and consolidation. Further, GGO appears more frequently for COVID-19, whereas “infiltration” appears more frequently for influenza. This is because radiologists use the term <italic>GGO</italic> to describe most COVID-19 findings. In addition, the influenza articles are older than are the COVID articles, and, according to Fleischner Society recommendations, the use of the term <italic>infiltrate</italic> remains controversial, and it is recommended that it no longer be used in reports <xref rid="ref48" ref-type="bibr">[48]</xref>.</p>
    <p>In terms of limitations, first, the subfigure segmentation model needs to be improved. In this study, we applied a deep-learning model that was pretrained on an ImageCLEF Medical dataset to this task <xref rid="ref24" ref-type="bibr">[24]</xref>. Although this model is robust to variations in background color and spaces between subfigures, it sometimes fails to recognize similar subfigures that are aligned very closely. Unfortunately, these cases appear more frequently in our study than in others (e.g., several CT images are placed in a grid). Other errors occur when the model incorrectly treated the spine as spaces in the anteroposterior (AP) chest X-ray and split the large figure into two subfigures. In the future, the figure synthesis approach should be applied to augment the training datasets. Another limitation is that this work extracted only the passage that contains the referred figure. Sometimes, the case is not described in this passage. In the future, we plan to text mine the associated case description in the full text. Finally, while a figure is typically copyrighted with the original article and using previously published figures is not a common practice in scholarly publications, it is possible that one image is reused in different papers or reused in one paper for different purposes. In the future, we plan to develop a model to remove duplicated images in the collection.</p>
  </sec>
  <sec id="sec5">
    <label>5</label>
    <title>Conclusion</title>
    <p>We have developed a framework for rapidly constructing a CXR/CT database from PMC full-text articles. Our database is unique, as figures are retrieved along with relevant text that describes these cases in detail, and it can be extended easily in the future. Hence, the work is complementary to existing resources. Applications of this database show that our creation of additional training data from existing articles improves the system performance on COVID-19 versus non-COVID-19 classification in CT and CXR. We hope that the public dataset can facilitate deep-learning model development, educate medical students and residents, help to evaluate findings reported by radiologists, and provide additional insights for COVID-19 diagnosis. With an ongoing commitment to data sharing, we anticipate increasingly adding CXR and CT images to be made available as well in the coming months. The code that extracts the text from PMC, segments subfigures, and classifies image modality is openly available at <uri xlink:href="https://github.com/ncbi-nlp/COVID-19-CT-CXR">https://github.com/ncbi-nlp/COVID-19-CT-CXR</uri>.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>This work was supported in part by the Intramural Research Programs of the National Library of Medicine (NLM) and National Institutes of Health (NIH) Clinical Center. This work also was supported by NLM under Grant 4R00LM013001. This work utilized the computational resources of the NIH HPC Biowulf cluster (<uri xlink:href="http://hpc.nih.gov">http://hpc.nih.gov</uri>). This material is also based upon the work supported by Google Cloud.</p>
  </ack>
  <bio id="bio1">
    <graphic xlink:href="peng-3035935.gif" position="float"/>
    <p><xref rid="contrib1" ref-type="contrib">Yifan Peng</xref> received the PhD degree. He is currently an assistant professor with Weill Cornell Medicine. He was a research fellow with the National Center for Biotechnology Information (NCBI), National Library of Medicine (NLM), National Institutes of Health (NIH). His main research interests include biomedical and clinical natural language processing and medical image analysis. He has published many papers in top journals and conferences, including the <italic>Nucleic Acids Research</italic>, <italic>npj Digital Medicine</italic>, <italic>Journal of the American Medical Informatics Association</italic>, CVPR, and MICCAI. He is also an academic editor of the <italic>PLoS ONE</italic>.</p>
  </bio>
  <bio id="bio2">
    <graphic xlink:href="tang-3035935.gif" position="float"/>
    <p><xref rid="contrib2" ref-type="contrib">Yuxing Tang</xref> received the BS and MS degrees from the Department of Information and Telecommunication Engineering, Beijing Jiaotong University, Beijing, China, in 2009 and 2011, respectively, and the PhD degree in computer science from the Department of Mathematics and Computer Science, École Centrale de Lyon, Écully, France, in 2016. He is a postdoctoral fellow with the Imaging Biomarkers and Computer-Aided Diagnosis (CAD) Laboratory, National Institutes of Health (NIH) Clinical Center. His main research interests include computer vision and machine learning, in particular, deep learning techniques for visual category recognition, object detection, image segmentation and their application in medical imaging.</p>
  </bio>
  <bio id="bio3">
    <graphic xlink:href="lee-3035935.gif" position="float"/>
    <p><xref rid="contrib3" ref-type="contrib">Sungwon Lee</xref> received the MD and PhD degrees. She is currently a radiologist and research fellow with the National Institutes of Health (NIH). Her research interests include segmentation and classification of medical imaging, especially chest, body, and musculoskeletal images of CT and MRI.</p>
  </bio>
  <bio id="bio4">
    <graphic xlink:href="zhu-3035935.gif" position="float"/>
    <p><xref rid="contrib4" ref-type="contrib">Yingying Zhu</xref> received the PhD degree. She is currently a staff scientist with the Department of Radiology, Clinical Center, National Institutes of Health (NIH). Her main research interests include computer vision, medical image analysis, and machine learning. She has published many papers in top journals and conferences, including the <italic>IEEE Transaction on Medical Imaging</italic>, the <italic>Medical Image Analysis</italic>, <italic>IEEE Transactions on Pattern Analysis and Machine Intelligence</italic>, ECCV, CVPR, IPMI, and MICCAI.</p>
  </bio>
  <bio id="bio5">
    <graphic xlink:href="summe-3035935.gif" position="float"/>
    <p><xref rid="contrib5" ref-type="contrib">Ronald M. Summers</xref> received the MD and PhD degrees. He is currently a senior investigator with the NIH. He joined the Diagnostic Radiology Department, NIH Clinical Center, in 1994. He directs the Imaging Biomarkers and Computer-Aided Diagnosis (CAD) Laboratory. His research interests include virtual colonoscopy, CAD, multi-organ multi-atlas registration, and development of large radiologic image databases. His clinical areas of specialty are thoracic and gastrointestinal radiology and body cross-sectional imaging. His current research focuses on developing fully-automated interpretation of abdominal CT scans.</p>
  </bio>
  <bio id="bio6">
    <graphic xlink:href="lu-3035935.gif" position="float"/>
    <p><xref rid="contrib6" ref-type="contrib">Zhiyong Lu</xref> received the PhD degree. He is currently a deputy director for Literature Search at the National Center for Biotechnology (NCBI), leading its overall efforts of improving literature search and information access in NCBI's production resources. He is also an NIH senior investigator (early tenure) and directs the Text Mining / Natural Language Processing (NLP) Research Program, NCBI/NLM where they are developing computational methods and software tools for analyzing and making sense of unstructured text data in biomedical literature and clinical notes towards accelerated discovery and better health.</p>
  </bio>
  <ref-list>
    <title>References</title>
    <ref id="ref1">
      <label>[1]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>A. S.</given-names><surname>Fauci</surname></string-name>, <string-name><given-names>H. C.</given-names><surname>Lane</surname></string-name>, and <string-name><given-names>R. R.</given-names><surname>Redfield</surname></string-name></person-group>, “<article-title>COVID-19 - Navigating the uncharted</article-title>,” <source>New England J. Med.</source>, vol. <volume>382</volume>, pp. <fpage>1268</fpage>–<lpage>1269</lpage>, <month>Mar.</month>
<year>2020</year>.<pub-id pub-id-type="pmid">32109011</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>[2]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>N.</given-names><surname>Chen</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Epidemiological and clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in Wuhan, China: A descriptive study</article-title>,” <source>Lancet</source>, vol. <volume>395</volume>, pp. <fpage>507</fpage>–<lpage>513</lpage>, <month>Feb.</month>
<year>2020</year>.<pub-id pub-id-type="pmid">32007143</pub-id></mixed-citation>
    </ref>
    <ref id="ref3">
      <label>[3]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>W.-J.</given-names><surname>Guan</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Clinical characteristics of coronavirus disease 2019 in China</article-title>,” <source>New England J. Med.</source>, vol. <volume>382</volume>, pp. <fpage>1708</fpage>–<lpage>1720</lpage>, <month>Apr.</month>
<year>2020</year>.<pub-id pub-id-type="pmid">32109013</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <label>[4]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Wang</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Clinical characteristics of 138 hospitalized patients with 2019 novel coronavirus-infected pneumonia in Wuhan, China</article-title>,” <source>J. Amer. Med. Assoc.</source>, vol. <volume>323</volume>, pp. <fpage>1061</fpage>–<lpage>1069</lpage>, <month>Feb.</month>
<year>2020</year>.</mixed-citation>
    </ref>
    <ref id="ref5">
      <label>[5]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>H.</given-names><surname>Shi</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Radiological findings from 81 patients with COVID-19 pneumonia in Wuhan, China: A descriptive study</article-title>,” <source>Lancet Infect. Dis.</source>, vol. <volume>20</volume>, pp. <fpage>425</fpage>–<lpage>434</lpage>, <month>Apr.</month>
<year>2020</year>.<pub-id pub-id-type="pmid">32105637</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>[6]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>X.</given-names><surname>Xie</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Zhong</surname></string-name>, <string-name><given-names>W.</given-names><surname>Zhao</surname></string-name>, <string-name><given-names>C.</given-names><surname>Zheng</surname></string-name>, <string-name><given-names>F.</given-names><surname>Wang</surname></string-name>, and <string-name><given-names>J.</given-names><surname>Liu</surname></string-name></person-group>, “<article-title>Chest CT for typical 2019-nCoV pneumonia: Relationship to negative RT-PCR testing</article-title>,” <source>Radiology</source>, vol. <volume>12</volume>, <month>Feb.</month>
<year>2020</year>, Art. no. 200343.</mixed-citation>
    </ref>
    <ref id="ref7">
      <label>[7]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>X.</given-names><surname>Mei</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Artificial intelligence-enabled rapid diagnosis of patients with COVID-19</article-title>,” <source>Nat. Med.</source>, vol. <volume>26</volume>, no. <issue>8</issue>, pp. <fpage>1224</fpage>–<lpage>1228</lpage>, <month>Aug.</month>
<year>2020</year>.<pub-id pub-id-type="pmid">32427924</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>[8]</label>
      <mixed-citation publication-type="book" publication-format="print"><person-group person-group-type="author"><string-name><given-names>F.</given-names><surname>Shi</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for COVID-19</article-title>,” <source specific-use="IEEE">IEEE Rev. Biomed. Eng.</source>, to be published, doi: <pub-id pub-id-type="doi">10.1109/RBME.2020.2987975</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref9">
      <label>[9]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Irvin</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>CheXpert: A large chest radiograph dataset with uncertainty labels and expert comparison</article-title>,” in <source>Proc. AAAI Conf. Artif. Intell.</source>, <conf-date>2019</conf-date>, pp. <fpage>590</fpage>–<lpage>597</lpage>.</mixed-citation>
    </ref>
    <ref id="ref10">
      <label>[10]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>A. E. W.</given-names><surname>Johnson</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>MIMIC-CXR-JPG, A large publicly available database of labeled chest radiographs</article-title>,” <year>2019</year>, arXiv:1901.07042.</mixed-citation>
    </ref>
    <ref id="ref11">
      <label>[11]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>X.</given-names><surname>Wang</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Peng</surname></string-name>, <string-name><given-names>L.</given-names><surname>Lu</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Lu</surname></string-name>, <string-name><given-names>M.</given-names><surname>Bagheri</surname></string-name>, and <string-name><given-names>R. M.</given-names><surname>Summers</surname></string-name></person-group>, “<article-title>ChestX-Ray8: Hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</article-title>,” in <source specific-use="IEEE">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</source>, <conf-date>2017</conf-date>, pp. <fpage>3462</fpage>–<lpage>3471</lpage>.</mixed-citation>
    </ref>
    <ref id="ref12">
      <label>[12]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Yan</surname></string-name>, <string-name><given-names>X.</given-names><surname>Wang</surname></string-name>, <string-name><given-names>L.</given-names><surname>Lu</surname></string-name>, and <string-name><given-names>R. M.</given-names><surname>Summers</surname></string-name></person-group>, “<article-title>DeepLesion: Automated mining of large-scale lesion annotations and universal lesion detection with deep learning</article-title>,” <source>J. Med. Imag.</source>, vol. <volume>5</volume>, <month>Jul.</month>
<year>2018</year>, Art. no. 036501.</mixed-citation>
    </ref>
    <ref id="ref13">
      <label>[13]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J. P.</given-names><surname>Cohen</surname></string-name>, <string-name><given-names>P.</given-names><surname>Morrison</surname></string-name>, and <string-name><given-names>L.</given-names><surname>Dao</surname></string-name></person-group>, “<article-title>COVID-19 image data collection</article-title>,” <year>2020</year>, arXiv:2006.11988.</mixed-citation>
    </ref>
    <ref id="ref14">
      <label>[14]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>X.</given-names><surname>He</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Sample-efficient deep learning for COVID-19 diagnosis based on CT scans</article-title>,” to be published, doi: <pub-id pub-id-type="doi">10.1101/2020.04.13.20063941</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref15">
      <label>[15]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>K.</given-names><surname>Zhang</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Clinically applicable AI system for accurate diagnosis, quantitative measurements, and prognosis of COVID-19 pneumonia using computed tomography</article-title>,” <source>Cell</source>, vol. <volume>181</volume>, pp. <fpage>1423</fpage>–<lpage>1433</lpage>, <year>2020</year>.<pub-id pub-id-type="pmid">32416069</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>[16]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Q.</given-names><surname>Chen</surname></string-name>, <string-name><given-names>A.</given-names><surname>Allot</surname></string-name>, and <string-name><given-names>Z.</given-names><surname>Lu</surname></string-name></person-group>, “<article-title>Keep up with the latest coronavirus research</article-title>,” <source>Nature</source>, vol. <volume>579</volume>, <month>Mar.</month>
<year>2020</year>, Art. no. 193.</mixed-citation>
    </ref>
    <ref id="ref17">
      <label>[17]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>L. L.</given-names><surname>Wang</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>CORD-19: The COVID-19 open research dataset</article-title>,” <year>2020</year>, <italic>arXiv: 2004.10706</italic>. PMID: 32510522.</mixed-citation>
    </ref>
    <ref id="ref18">
      <label>[18]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S. R.</given-names><surname>Choudhury</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>A figure search engine architecture for a chemistry digital library</article-title>,” in <source specific-use="IEEE">Proc. 13th ACM/IEEE-CS Joint Conf. Digit. Libraries</source>, <conf-date>2013</conf-date>, pp. <fpage>369</fpage>–<lpage>370</lpage>.</mixed-citation>
    </ref>
    <ref id="ref19">
      <label>[19]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>C. L.</given-names><surname>Smith</surname></string-name>, <string-name><given-names>J. A.</given-names><surname>Blake</surname></string-name>, <string-name><given-names>J. A.</given-names><surname>Kadin</surname></string-name>, <string-name><given-names>J. E.</given-names><surname>Richardson</surname></string-name>, <string-name><given-names>C. J.</given-names><surname>Bult</surname></string-name>, and <string-name><given-names>M. G. D.</given-names><surname>Group</surname></string-name></person-group>, “<article-title>Mouse Genome database (MGD)-2018: Knowledgebase for the laboratory mouse</article-title>,” <source>Nucleic Acids Res.</source>, vol. <volume>46</volume>, pp. <fpage>D836</fpage>–<lpage>D842</lpage>, <month>Jan.</month>
<year>2018</year>.<pub-id pub-id-type="pmid">29092072</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>[20]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Z.</given-names><surname>Ahmed</surname></string-name>, <string-name><given-names>S.</given-names><surname>Zeeshan</surname></string-name>, and <string-name><given-names>T.</given-names><surname>Dandekar</surname></string-name></person-group>, “<article-title>Mining biomedical images towards valuable information retrieval in biomedical and life sciences</article-title>,” <source>Database</source>, vol. <volume>2016</volume>, <year>2016</year>, Art. no. baw118.</mixed-citation>
    </ref>
    <ref id="ref21">
      <label>[21]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>P.</given-names><surname>Li</surname></string-name>, <string-name><given-names>X.</given-names><surname>Jiang</surname></string-name>, and <string-name><given-names>H.</given-names><surname>Shatkay</surname></string-name></person-group>, “<article-title>Figure and caption extraction from biomedical documents</article-title>,” <source>Bioinformatics</source>, vol. <volume>35</volume>, pp. <fpage>4381</fpage>–<lpage>4388</lpage>, <month>Nov.</month>
<year>2019</year>.<pub-id pub-id-type="pmid">30949681</pub-id></mixed-citation>
    </ref>
    <ref id="ref22">
      <label>[22]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>N.</given-names><surname>Siegel</surname></string-name>, <string-name><given-names>N.</given-names><surname>Lourie</surname></string-name>, <string-name><given-names>R.</given-names><surname>Power</surname></string-name>, and <string-name><given-names>W.</given-names><surname>Ammar</surname></string-name></person-group>, “<article-title>Extracting scientific figures with distantly supervised neural networks</article-title>,” in <source specific-use="IEEE">Proc. 18th ACM/IEEE Joint Conf. Digit. Libraries</source>, <conf-date>2018</conf-date>, pp. <fpage>223</fpage>–<lpage>232</lpage>.</mixed-citation>
    </ref>
    <ref id="ref23">
      <label>[23]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>L. D.</given-names><surname>Lopez</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>A framework for biomedical figure segmentation towards image-based document retrieval</article-title>,” <source>BMC Syst. Biol.</source>, vol. <volume>7</volume>
<year>2013</year>, Art. no. S8.</mixed-citation>
    </ref>
    <ref id="ref24">
      <label>[24]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Tsutsui</surname></string-name> and <string-name><given-names>D.</given-names><surname>Crandall</surname></string-name></person-group>, “<article-title>A data driven approach for compound figure separation using convolutional neural networks</article-title>,” in <italic>Proc. IAPR Int. Conf. Document Anal. Recognit.</italic>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="ref25">
      <label>[25]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>D. C.</given-names><surname>Comeau</surname></string-name>, <string-name><given-names>C.-H.</given-names><surname>Wei</surname></string-name>, <string-name><given-names>R. I.</given-names><surname>Doğan</surname></string-name>, and <string-name><given-names>Z.</given-names><surname>Lu</surname></string-name></person-group>, “<article-title>PMC text mining subset in BioC: About three million full-text articles and growing</article-title>,” <source>Bioinformatics</source>, vol. <volume>35</volume>, pp. <fpage>3533</fpage>–<lpage>3535</lpage>, <month>Sep.</month>
<year>2019</year>.<pub-id pub-id-type="pmid">30715220</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <label>[26]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Ş.</given-names><surname>Kafkas</surname></string-name>, <string-name><given-names>X.</given-names><surname>Pi</surname></string-name>, <string-name><given-names>N.</given-names><surname>Marinos</surname></string-name>, <string-name><given-names>F.</given-names><surname>Talo’</surname></string-name>, <string-name><given-names>A.</given-names><surname>Morrison</surname></string-name>, and <string-name><given-names>J. R.</given-names><surname>McEntyre</surname></string-name></person-group>, “<article-title>Section level search functionality in europe PMC</article-title>,” <source>J. Biomed. Semantics</source>, vol. <volume>6</volume>, <year>2015</year>, Art. no. 7.</mixed-citation>
    </ref>
    <ref id="ref27">
      <label>[27]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y.-H. E. A.</given-names><surname>Jin</surname></string-name></person-group>, “<article-title>A rapid advice guideline for the diagnosis and treatment of 2019 novel coronavirus (2019-nCoV) infected pneumonia (standard version)</article-title>,” <source>Mil. Med. Res.</source>, vol. <volume>7</volume>, <month>Feb.</month>
<year>2020</year>, Art. no. 4.</mixed-citation>
    </ref>
    <ref id="ref28">
      <label>[28]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>A. G. S.</given-names><surname>De Herrera</surname></string-name>, <string-name><given-names>S.</given-names><surname>Bromuri</surname></string-name>, <string-name><given-names>R.</given-names><surname>Schaer</surname></string-name>, and <string-name><given-names>H.</given-names><surname>Müller</surname></string-name></person-group>, “<article-title>Overview of the medical tasks in ImageCLEF 2016</article-title>,” <source>CLEF Work. Notes. Evora, Portugal</source>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="ref29">
      <label>[29]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>C.</given-names><surname>Szegedy</surname></string-name>, <string-name><given-names>V.</given-names><surname>Vanhoucke</surname></string-name>, <string-name><given-names>S.</given-names><surname>Ioffe</surname></string-name>, <string-name><given-names>J.</given-names><surname>Shlens</surname></string-name>, and <string-name><given-names>Z.</given-names><surname>Wojna</surname></string-name></person-group>, “<article-title>Rethinking the inception architecture for computer vision</article-title>,” in <source specific-use="IEEE">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</source>, <conf-date>2016</conf-date>, pp. <fpage>2818</fpage>–<lpage>2826</lpage>.</mixed-citation>
    </ref>
    <ref id="ref30">
      <label>[30]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>F.</given-names><surname>Iandola</surname></string-name>, <string-name><given-names>M.</given-names><surname>Moskewicz</surname></string-name>, <string-name><given-names>S.</given-names><surname>Karayev</surname></string-name>, <string-name><given-names>R.</given-names><surname>Girshick</surname></string-name>, <string-name><given-names>T.</given-names><surname>Darrell</surname></string-name>, and <string-name><given-names>K.</given-names><surname>Keutzer</surname></string-name></person-group>, “<article-title>DenseNet: Implementing efficient convnet descriptor pyramids</article-title>,” <year>2014</year>, arXiv:1404.1869.</mixed-citation>
    </ref>
    <ref id="ref31">
      <label>[31]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>K. V.</given-names><surname>Jobin</surname></string-name>, <string-name><given-names>A.</given-names><surname>Mondal</surname></string-name>, and <string-name><given-names>C. V.</given-names><surname>Jawahar</surname></string-name></person-group>, “<article-title>DocFigure: A dataset for scientific document figure classification</article-title>,” in <source>Proc. Int. Conf. Document Anal. Recognit. Workshops</source>, <conf-date>2019</conf-date>, pp. <fpage>74</fpage>–<lpage>79</lpage>.</mixed-citation>
    </ref>
    <ref id="ref32">
      <label>[32]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y.-X.</given-names><surname>Tang</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Automated abnormality classification of chest radiographs using deep convolutional neural networks</article-title>,” <source>NPJ Digit. Med.</source>, vol. <volume>3</volume>, <year>2020</year>, Art. no. 70.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>[33]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>G.</given-names><surname>Huang</surname></string-name>, <string-name><given-names>Z.</given-names><surname>Liu</surname></string-name>, <string-name><given-names>L.</given-names><surname>van der Maaten</surname></string-name>, and <string-name><given-names>K. Q.</given-names><surname>Weinberger</surname></string-name></person-group>, “<article-title>Densely connected convolutional networks</article-title>,” in <italic>Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</italic>, 2017, pp. <fpage>4700</fpage>–<lpage>4708</lpage>.</mixed-citation>
    </ref>
    <ref id="ref34">
      <label>[34]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>O.</given-names><surname>Russakovsky</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>ImageNet large scale visual recognition challenge</article-title>,” <source>Int. J. Comput. Vis.</source>, vol. <volume>115</volume>, no. <issue>3</issue>, pp. <fpage>211</fpage>–<lpage>252</lpage>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>[35]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>R. A.</given-names><surname>Fisher</surname></string-name></person-group>, “<article-title>On the interpretation of <inline-formula><tex-math notation="LaTeX" id="M153">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\chi$\end{document}</tex-math><alternatives><mml:math id="M154"><mml:mi>χ</mml:mi></mml:math><inline-graphic xlink:href="peng-ieq77-3035935.jpg"/></alternatives></inline-formula>2 from contingency tables, and the calculation of P</article-title>,” <source>J. Roy. Statist. Soc.</source>, vol. <volume>85</volume>, no. <issue>1</issue>, <month>Jan.</month>
<year>1922</year>, Art. no. 87.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>[36]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Zhao</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Zhang</surname></string-name>, <string-name><given-names>X.</given-names><surname>He</surname></string-name>, and <string-name><given-names>P.</given-names><surname>Xie</surname></string-name></person-group>, “<article-title>COVID-CT-Dataset: A CT scan dataset about COVID-19</article-title>,” <year>2020</year>, <italic>arXiv:2003.13865</italic>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>[37]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Chen</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Deep learning-based model for detecting 2019 novel coronavirus pneumonia on high-resolution computed tomography</article-title>,” <italic>Scientific Rep.</italic>, vol. <volume>10</volume>, no. <issue>1</issue>, pp. <fpage>1</fpage>–<lpage>11</lpage>, 2020.</mixed-citation>
    </ref>
    <ref id="ref38">
      <label>[38]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>C.</given-names><surname>Jin</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Development and evaluation of an AI system for COVID-19 diagnosis</article-title>,” <italic>MedRxiv Reprint</italic>, to be published, doi: <pub-id pub-id-type="doi">10.1101/2020.03.20.20039834</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref39">
      <label>[39]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>S.</given-names><surname>Wang</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>A deep learning algorithm using CT images to screen for corona virus disease (COVID-19)</article-title>,” <italic>MedRxiv Preprint</italic>, to be published, doi: <pub-id pub-id-type="doi">10.1101/2020.02.14.20023028</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref40">
      <label>[40]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>C.</given-names><surname>Zheng</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Deep learning-based detection for COVID-19 from chest CT using weak label</article-title>,” <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="ref41">
      <label>[41]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>Luo</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Using a diagnostic model based on routine laboratory tests to distinguish patients infected with SARS-CoV-2 from those infected with influenza virus</article-title>,” <source>Int. J. Infect. Dis.</source>, vol. <volume>95</volume>, pp. <fpage>436</fpage>–<lpage>440</lpage>, <month>May</month>
<year>2020</year>.<pub-id pub-id-type="pmid">32371192</pub-id></mixed-citation>
    </ref>
    <ref id="ref42">
      <label>[42]</label>
      <mixed-citation publication-type="book" publication-format="print"><person-group person-group-type="author"><string-name><given-names>D.</given-names><surname>Kimberlin</surname></string-name></person-group>, <source>Red Book 2018–2021: Report of the Committee on Infectious Diseases</source>. <publisher-loc>Elk Grove Village, IL, USA</publisher-loc>: <publisher-name>Amer. Acad. Pediatrics</publisher-name>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="ref43">
      <label>[43]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>X.</given-names><surname>Xu</surname></string-name>, <etal>et al.</etal></person-group>, “<article-title>Deep learning system to screen coronavirus disease 2019 pneumonia</article-title>,” <italic>Engineering</italic>, to be published, doi: <pub-id pub-id-type="doi">10.1016/j.eng.2020.04.010</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref44">
      <label>[44]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>V.</given-names><surname>Chandola</surname></string-name>, <string-name><given-names>A.</given-names><surname>Banerjee</surname></string-name>, and <string-name><given-names>V.</given-names><surname>Kumar</surname></string-name></person-group>, “<article-title>Anomaly detection</article-title>,” <source>ACM Comput. Surv.</source>, vol. <volume>41</volume>, no. <issue>3</issue>, pp. <fpage>1</fpage>–<lpage>58</lpage>, <month>Jul.</month>
<year>2009</year>.</mixed-citation>
    </ref>
    <ref id="ref45">
      <label>[45]</label>
      <mixed-citation publication-type="periodical" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Zhang</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Xie</surname></string-name>, <string-name><given-names>Y.</given-names><surname>Li</surname></string-name>, <string-name><given-names>C.</given-names><surname>Shen</surname></string-name>, and <string-name><given-names>Y.</given-names><surname>Xia</surname></string-name></person-group>, “<article-title>COVID-19 screening on chest X-ray images using deep learning based anomaly detection</article-title>,” <year>2020</year>, <italic>arXiv:2003.12338</italic>.</mixed-citation>
    </ref>
    <ref id="ref46">
      <label>[46]</label>
      <mixed-citation publication-type="confproc" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y.-X.</given-names><surname>Tang</surname></string-name>, <string-name><given-names>Y.-B.</given-names><surname>Tang</surname></string-name>, <string-name><given-names>M.</given-names><surname>Han</surname></string-name>, <string-name><given-names>J.</given-names><surname>Xiao</surname></string-name>, and <string-name><given-names>R. M.</given-names><surname>Summers</surname></string-name></person-group>, “<article-title>Abnormal chest X-Ray identification with generative adversarial one-class classifier</article-title>,” in <source specific-use="IEEE">Proc. IEEE 16th Int. Symp. Biomed. Imag.</source>, <conf-date>2019</conf-date>, pp. <fpage>1358</fpage>–<lpage>1361</lpage>.</mixed-citation>
    </ref>
    <ref id="ref47">
      <label>[47]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>Y.</given-names><surname>Peng</surname></string-name>, <string-name><given-names>X.</given-names><surname>Wang</surname></string-name>, <string-name><given-names>L.</given-names><surname>Lu</surname></string-name>, <string-name><given-names>M.</given-names><surname>Bagheri</surname></string-name>, <string-name><given-names>R.</given-names><surname>Summers</surname></string-name>, and <string-name><given-names>Z.</given-names><surname>Lu</surname></string-name></person-group>, “<article-title>NegBio: A high-performance tool for negation and uncertainty detection in radiology reports</article-title>,” <source>AMIA Joint Summits Translational Sci. Proc.</source>, vol. <volume>2017</volume>, pp. <fpage>188</fpage>–<lpage>196</lpage>, <conf-date>2018</conf-date>. [Online]. Available: <uri xlink:href="https://arxiv.org/abs/1712.05898">https://arxiv.org/abs/1712.05898</uri></mixed-citation>
    </ref>
    <ref id="ref48">
      <label>[48]</label>
      <mixed-citation publication-type="journal" publication-format="print"><person-group person-group-type="author"><string-name><given-names>J.</given-names><surname>Bueno</surname></string-name>, <string-name><given-names>L.</given-names><surname>Landeras</surname></string-name>, and <string-name><given-names>J. H.</given-names><surname>Chung</surname></string-name></person-group>, “<article-title>Updated fleischner society guidelines for managing incidental pulmonary nodules: Common questions and challenging scenarios</article-title>,” <source>Radiographics</source>, vol. <volume>38</volume>, pp. <fpage>1337</fpage>–<lpage>1350</lpage>, <year>2018</year>.<pub-id pub-id-type="pmid">30207935</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
