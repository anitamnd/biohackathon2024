<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5196</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6698780</article-id>
    <article-id pub-id-type="doi">10.3389/fninf.2019.00059</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Technology Report</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PyParadigm—A Python Library to Build Screens in a Declarative Way</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Knorr</surname>
          <given-names>Felix G.</given-names>
        </name>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/680411/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Petzold</surname>
          <given-names>Johannes</given-names>
        </name>
        <xref ref-type="author-notes" rid="fn001">
          <sup>†</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/742993/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Marxen</surname>
          <given-names>Michael</given-names>
        </name>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/133374/overview"/>
      </contrib>
    </contrib-group>
    <aff><institution>Department of Psychiatry and Neuroimaging Center, Technische Universität Dresden</institution>, <addr-line>Dresden</addr-line>, <country>Germany</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Antonio Fernández-Caballero, University of Castilla La Mancha, Spain</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Jaakko Jarvi, University of Bergen, Norway; Adrián Riesco, Complutense University of Madrid, Spain</p>
      </fn>
      <corresp id="c001">*Correspondence: Felix G. Knorr <email>felix.knorr@tu-dresden.de</email></corresp>
      <fn fn-type="other" id="fn001">
        <p>†Johannes Petzold <ext-link ext-link-type="uri" xlink:href="https://orcid.org/0000-0003-4163-9014">orcid.org/0000-0003-4163-9014</ext-link></p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>09</day>
      <month>8</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>59</elocation-id>
    <history>
      <date date-type="received">
        <day>07</day>
        <month>2</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>7</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2019 Knorr, Petzold and Marxen.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <copyright-holder>Knorr, Petzold and Marxen</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>In experimental psychology, subjects are often confronted with computer-based experimental paradigms. Creating such paradigms can require a lot of effort. PyParadigm is a newly developed Python library to ease the development of such paradigms by employing a declarative approach to build user interfaces (UIs). Paradigm specifications in this approach requires much less code and training than in alternative libraries. Although PyParadigm was initially developed for the creation of experimental paradigms, it is generally suited to build UIs that display or interact with 2D objects.</p>
    </abstract>
    <kwd-group>
      <kwd>Python</kwd>
      <kwd>library</kwd>
      <kwd>experimental psychology</kwd>
      <kwd>paradigm</kwd>
      <kwd>declarative UI</kwd>
      <kwd>2D</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">Deutsche Forschungsgemeinschaft<named-content content-type="fundref-id">10.13039/501100001659</named-content></funding-source>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="3"/>
      <table-count count="1"/>
      <equation-count count="0"/>
      <ref-count count="6"/>
      <page-count count="6"/>
      <word-count count="3930"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>1. Introduction</title>
    <p>In experimental psychology, subjects are confronted with computer-based experimental paradigms. A paradigm usually consists of multiple different states in which stimuli are displayed, and the user's task is to react to the stimuli by using a response device, usually a keyboard or a pad with a few buttons. It can be thought of as something between a mini game and an interactive Powerpoint presentation. Most stimuli are either (colored) text, images, or geometric primitives, sometimes sounds are used as stimuli too. The primary goal of a paradigm is to quantify the users behavior in form of reaction times or made decisions, for example. The results need to be stored; a popular format would be CSV or TSV files.</p>
    <p>Creating such paradigms can require quite an effort and a number of software tools have been developed to this end. Two very popular commercial ones are E-Prime and Presentation. Both of them consist of a graphical user interface (GUI), which, in case of E-Prime, even allows to specify a paradigm by dragging and dropping visual elements into a sequence, and a run-time environment, which can execute previously defined paradigms, and must be present on the PC that executes the paradigm. However, in many cases, knowledge of an integrated scripting language is required. But if it is necessary to program anyway, using a fully fledged general purpose programming language has obvious advantages. There are many programming languages that could be used, but one of the favorites in the field is Python. Besides being free, it has a reputation of being simple to learn and easy to read. Additionally it is a popular tool for data analysis, and a large number of high quality, freely available libraries exist. Thus, it is a useful addition to a scientist's skill set.</p>
    <p>There are many popular libraries for python to create GUIs, the two most prominent ones probably being Qt and TKinter. A GUI normally runs in potentially multiple windows and consists of predefined elements like text fields and buttons, which are clicked using the mouse. Often deeply nested elements are required and elaborate methods are needed for a variety of graphical input options. An experimental paradigm, in contrast, runs in full-screen mode and requires often simpler and different types of graphical elements or input options. In addition, the temporal sequence of events is of primary importance.</p>
    <p>Consequently, a number of libraries specifically for creation of paradigms have been developed : PsychoPy (Peirce, <xref rid="B5" ref-type="bibr">2009</xref>), Expyriment (Krause and Lindemann, <xref rid="B3" ref-type="bibr">2014</xref>), and VisionEgg (Straw, <xref rid="B6" ref-type="bibr">2008</xref>). For a comparison (see <xref rid="T1" ref-type="table">Table 1</xref>). These libraries all work in a very similar way: Stimuli are loaded and then positioned on the screen using absolute or relative x and y coordinates. All of these libraries have a particular strength: PsychoPy has a GUI builder that will generate Python code, Expyriment can run on Android, and puts extra effort in synchronizing display time stamps with the screen refresh rate, and VisionEgg puts an emphasis on using the GPU and supports 3D graphics.</p>
    <table-wrap id="T1" position="float">
      <label>Table 1</label>
      <caption>
        <p>Comparison of the features the different paradigm programming libraries offer.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th rowspan="1" colspan="1"/>
            <th valign="top" align="center" rowspan="1" colspan="1">
              <bold>PsychoPy</bold>
            </th>
            <th valign="top" align="center" rowspan="1" colspan="1">
              <bold>VisionEgg</bold>
            </th>
            <th valign="top" align="center" rowspan="1" colspan="1">
              <bold>Expyriment</bold>
            </th>
            <th valign="top" align="center" rowspan="1" colspan="1">
              <bold>PyParadigm</bold>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Positioning with (x, y) coordinates</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" rowspan="1" colspan="1">
              <inline-formula>
                <mml:math id="M1">
                  <mml:mstyle mathcolor="#00a651">
                    <mml:mo>✓</mml:mo>
                  </mml:mstyle>
                </mml:math>
              </inline-formula>
              <sup>*</sup>
            </td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Positioning via layouts</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">GPU acceleration</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" rowspan="1" colspan="1">
              <inline-formula>
                <mml:math id="M2">
                  <mml:mstyle mathcolor="#00a651">
                    <mml:mo>✓</mml:mo>
                  </mml:mstyle>
                </mml:math>
              </inline-formula>
              <sup>*</sup>
            </td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">3D support</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">GUI builder</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Android support</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">v-sync timing synchronization</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Support for blocks, run, and trials</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Support for rendering numpy arrays</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Support for text input</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Direct interactivity with pygame</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#ee1c25" rowspan="1" colspan="1">✗</td>
            <td valign="top" align="center" style="color:#00a651" rowspan="1" colspan="1">✓</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <p><italic>A <sup>*</sup> means: yes, through pygame</italic>.</p>
      </table-wrap-foot>
    </table-wrap>
    <p>While all of these libraries have their own advantages, they are relatively complex, need a fair amount of training to master, and require more lines of code than needed in many cases. We developed PyParadigm with the goal of being able to write paradigms with a minimum of code and training. Less code means faster development, and less room for bugs. PyParadigm can also increase readability, once familiar with it (it takes ~ 1 h to go through our tutorial at: <ext-link ext-link-type="uri" xlink:href="https://pyparadigm.readthedocs.io/en/latest/tutorial.html">https://pyparadigm.readthedocs.io/en/latest/tutorial.html</ext-link>). The main idea in PyParadigm is that images shown as stimuli are specified declaratively—not by issuing commands to draw specific parts of images but by specifying their nested structure. PyParadigm is a very thin wrapper around the video game development library pygame and uses its <monospace>Surface</monospace> class to represent visual data. This means that it can freely interact with pygame directly where PyParadigm falls short. For example, freely moving visual stimuli cannot be programmed using the layouting mechanisms of PyParadigm. But they can be easily implemented using pygame and integrated into PyParadigm. Additionally, PyParadigm also accepts 2D-numpy arrays as image data, which makes it easy to write scripts that utilize image data, e.g., browsing 2D-slices of a 3D MRI volume using a moving marker.</p>
  </sec>
  <sec id="s2">
    <title>2. The Library</title>
    <p>In this section, we will present PyParadigm in depth. It is published on PyPi and can be installed via pip (Python 3 only): <italic>pip install pyparadigm</italic>. PyParadigm is split into four modules: (1) <italic>surface_composition</italic>, (2) <italic>eventlistener</italic>, (3) <italic>misc</italic>, and (4) <italic>extras</italic>.</p>
    <p>The surface_composition module is used to create images that are subsequently displayed on the screen. The eventlistener module handles keyboard input. The misc module contains functions to create the window, draw images within the window and a few others. The extras module contains code that has extra dependencies besides pygame, which are not installed automatically (currently numpy and matplotlib). The full documentation can be found at <ext-link ext-link-type="uri" xlink:href="https://pyparadigm.readthedocs.io">https://pyparadigm.readthedocs.io</ext-link>. In the following, you will be introduced to the important principles of PyParadigm, based on concrete examples which should enable you to write paradigms yourself with only little additional reference to the documentation or the tutorial.</p>
    <sec>
      <title>2.1. The Surface_Composition Module</title>
      <p>This module is the heart of PyParadigm. The idea is to describe an image with a hierarchical tree structure. Every element in the tree is assigned a part of the image to draw on, additionally it can assign any part of its space to its child elements, if it has any. The elements of which a screen is composed are not actual visual data that is stored in memory and copied onto the image, they are rendering instructions.</p>
      <p>There are a few important subgroups of elements: layouts, wrapper, and primitives. Layouts have the sole purpose of dividing their space among their children, and enable the creation of resolution independent visuals. There are 3 different layout types: <monospace>LinLayout</monospace> arranges its children in a line, that is either horizontal or vertical. By default the available space is split equally among the children. The <monospace>LLItem</monospace> class can be used to change the proportions of the children or insert empty cells, <monospace>GridLayout</monospace> arranges its children on a grid, proportions can be defined for rows and columns, <monospace>Overlay</monospace> draws its children on top of each other.</p>
      <p>Wrappers take a single child item (which can also be a layout) and modify the rendering. For example, they pad the element with a buffer space (<monospace>Padding</monospace>), reduce the available area to the biggest rectangle with defined side proportions (<monospace>RectangleShaper</monospace>), surround the area with a border (<monospace>Border</monospace>) or fill the background with a given color (<monospace>Fill</monospace>). One very special wrapper is the <monospace>Surface</monospace>, which will automatically wrap a <monospace>pygame.Surface</monospace>, i.e., an image that was loaded from disc or created otherwise. Images have a resolution, and cannot easily be scaled, because this might lead to bad image quality if the available space is bigger than the image, or distortions. Therefore, the default behavior is to scale images down, to the biggest possible rectangle that can be fit into the available space without distorting the image, if the available space is smaller than the image. If the available space is larger than the image it will be centered but not upscaled. The detailed behavior of how an image should be inserted can be specified through the various parameters of <monospace>Surface</monospace>, if it is used to wrap a <monospace>pygame.Surface</monospace> manually.</p>
      <p>Primitives do not accept any children and simply render something into the assigned area, using as much space as possible. Available primitives are <monospace>Circle</monospace>, <monospace>Cross</monospace>, <monospace>Line</monospace>, <monospace>Text</monospace>, and Rectangles (by using <monospace>Fill</monospace>).</p>
    </sec>
    <sec>
      <title>2.2. The Eventlistener Module</title>
      <p>Input processing works in the following way: if a key is pressed, this information goes to the operating system, where it is processed. Unless it is a control sequence, like <italic>Win + L</italic>, the command will be sent to the window that has input focus (in this case: the pygame display window). These events are gathered in an event-queue, which is controlled by pygame. To react to events they need to be polled from the queue, then their information needs to be parsed and, consequently, actions can be taken. This process needs to be repeated periodically. Pygame provides abstractions for this by means of the <monospace>EventListener</monospace> class. An <monospace>EventListener</monospace> object will offer multiple methods. Each of them will parse the event-queue repeatedly until the event-of-interest occurs. In this case, they will return the information that was contained in the event. Additionally a timeout can be specified, which will cause the method to return if no event-of-interest occurred during the provided timeout. Available methods are for example, <monospace>wait_for_keys()</monospace>, which will return when one of multiple provided keys was pressed once, <monospace>wait_for_unicode_char()</monospace>, which will return if the user presses any key, that represents a Unicode char. This is the method of choice to get text-input from the user since it returns the unicode character instead of a pygame key-code. For mouse input, a wrapper element for the render tree is provided, which will give all its space to its child, and calls a callback function, if a mouse event that corresponds to its area occurs.</p>
      <p>In case functionality is required that is not provided by the currently available methods, a handler function can be defined, and passed as argument to the <monospace>listen()</monospace> method. These functions will then be confronted with each event and can react to it in a customized way. The <monospace>EventListener</monospace> can take a list of handler functions on instantiation, which will always be used when the event loop is parsed.</p>
    </sec>
    <sec>
      <title>2.3. The Misc Module</title>
      <p>This module contains a collection of functions that are useful, but do not fit well into one of the other modules. It contains functions to create the display window, draw a <monospace>pygame.Surface</monospace> onto the screen, create a <monospace>pygame.Surface</monospace> of the size of the display window that is filled with a specified color, manipulate a string buffer according to a provided Unicode character and display multiple frames in a list successively.</p>
    </sec>
    <sec>
      <title>2.4. The Extras Module</title>
      <p>The <italic>extras</italic> module contains functions to use <italic>numpy</italic> arrays as images and may be extended by the user as needed. This module can be used, for example, to work interactively with data represented as numpy arrays, like browsing neuroimaging data, to extract information from volumes of choice. It could also be used to render stimuli that cannot be easily created with the <monospace>surface_composition</monospace> module because they based on a complex mathematical formula.</p>
    </sec>
  </sec>
  <sec id="s3">
    <title>3. Creating a Paradigm</title>
    <p>To demonstrate that it is very simple to create a paradigm with <italic>PyParadigm</italic>, we will walk the reader through the basic elements of a paradigm in this section. First we create the display window calling <monospace>init()</monospace>, and an <monospace>EventListener</monospace> instance. The rest of the main function below looks like a table of contents:</p>
    <p>
      <inline-graphic xlink:href="fninf-13-00059-i0001.jpg"/>
    </p>
    <p>An introduction is displayed; there is a training period followed by the task; lastly, the behavioral results are saved. The introduction could look something like this:</p>
    <p>
      <inline-graphic xlink:href="fninf-13-00059-i0002.jpg"/>
    </p>
    <p>First, the frames with the text that should be displayed are created, then <monospace>slide_show()</monospace> is used to display all of them. A lambda function is provided that will return once the subject presses the return key, to get to the next text page. <monospace>intro_text</monospace> is a list of strings, where every string contains the text for one frame.</p>
    <p>The <monospace>execute_task</monospace> function could look like this:</p>
    <p>
      <inline-graphic xlink:href="fninf-13-00059-i0003.jpg"/>
    </p>
    <p>It displays a text to prepare the subject that the task will start, calls the function that will execute a single block in a list comprehension with the parameters for each block, which might be defined as a global variable in the beginning of a script, and in the end displays another message.</p>
    <p>Here is an example for the <monospace>exec_block()</monospace> function:</p>
    <p>
      <inline-graphic xlink:href="fninf-13-00059-i0004.jpg"/>
    </p>
    <p>It manages the execution of a block, i.e., it calls a function to display a trial, stores an onset, waits for a response, stores the reaction time, and in the end returns the results. <monospace>ITIs</monospace> stands for inter trial interval and is a list of seconds which represents the duration that the subject has to wait for between two trials. The <italic>n</italic>th entry represents the waiting time after the <italic>n</italic>th trial, therefore the last value in the list should be zero.</p>
    <p>To be able to run this code, the user still has to provide a number of variables, like a subject id, which could be passed as an argument to the script, or be queried via the <monospace>input()</monospace> function. It also misses the code to actually render a trial (<monospace>make_trial_screen(p1, p2, p3)</monospace>). Possible examples for the <monospace>make_trial_screen(p1, p2, p3)</monospace> function will be provided in the next section.</p>
    <p>A fully functioning example for a real world paradigm can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/KnorrFG/set_switch_paradigm/tree/master/felix_2">https://github.com/KnorrFG/set_switch_paradigm/tree/master/felix_2</ext-link>. The implementation took roughly 1 week.</p>
  </sec>
  <sec id="s4">
    <title>4. Examples</title>
    <p>In this section, we provide some source code together with images of the resulting displays to illustrate the declarative nature and code efficiency of the library.</p>
    <sec>
      <title>4.1. Example 1</title>
      <p>In the first example, we create a screen for an inter-temporal choice task, in which subjects have to make a decision between receiving a small of money immediately or a larger amount after some waiting time.</p>
      <p>
        <inline-graphic xlink:href="fninf-13-00059-i0005.jpg"/>
      </p>
      <p>In the <monospace>make_offer()</monospace> function the screen is first divided horizontally into two parts, then the space for both is scaled down to 80% and filled with an offer box, which is a box (the <monospace>Border()</monospace> around the LinLayout) that contains two <monospace>Text</monospace> items, both of font size 50, and the amount has a bold type face. Also the space for the amount is twice as large as the space for the delay, which is implied by <monospace>LLitem(2)</monospace> and leads to the positioning seen in <xref ref-type="fig" rid="F1">Figure 1</xref>.</p>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p>An exemplary screen of an inter temporal choice paradigm, where the subject is tasked to decide between 10€ that are payed out immediately and 20€ that are payed out after 30 days.</p>
        </caption>
        <graphic xlink:href="fninf-13-00059-g0001"/>
      </fig>
    </sec>
    <sec>
      <title>4.2. Example 2</title>
      <p>In this example, two symbols are displayed, and the subjects have to press either the F-key or the J-key, depending on whether the symbols are identical. The output can be seen in <xref ref-type="fig" rid="F2">Figure 2</xref> and the source code below. First, the screen is divided vertically (<monospace>LinLayout(<inline-formula><mml:math id="M3"><mml:mstyle mathvariant="monospace" class="text" mathcolor="#8f5973"><mml:mo>“</mml:mo><mml:mtext>v</mml:mtext><mml:mo>”</mml:mo></mml:mstyle></mml:math></inline-formula>)</monospace>), then the instruction text is added, implicitly with a proportion of one, then the two symbols are added. They are wrapped in a horizontal <monospace>LinLayout</monospace>, which also contains three empty <monospace>LLItem</monospace>s to create the visible spacing. In the end, another empty <monospace>LLItem</monospace> is added to the outer layout, to shift everything upwards. This time, the color for the background image is provided as a hex-code, which is shorter than using <monospace>pygame.Color()</monospace>, also the outer <monospace>LinLayout</monospace> is now moved to the second argument of compose, which saves one indention level.</p>
      <p>
        <inline-graphic xlink:href="fninf-13-00059-i0006.jpg"/>
      </p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Screen of example 2.</p>
        </caption>
        <graphic xlink:href="fninf-13-00059-g0002"/>
      </fig>
    </sec>
    <sec>
      <title>4.3. Example 3</title>
      <p>Example 3 shows the training stage of a Stroop task, where subjects have to learn the color mappings by heart. The output is shown in <xref ref-type="fig" rid="F3">Figure 3</xref>.</p>
      <p>
        <inline-graphic xlink:href="fninf-13-00059-i0007.jpg"/>
      </p>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Screen of example 3.</p>
        </caption>
        <graphic xlink:href="fninf-13-00059-g0003"/>
      </fig>
      <p>Here, two screens are provided in the output, the left one is created by the call <monospace>stroop(<inline-formula><mml:math id="M4"><mml:mstyle mathvariant="monospace" class="text" mathcolor="#8f5973"><mml:mo>“</mml:mo><mml:mtext>color</mml:mtext><mml:mo>”</mml:mo></mml:mstyle></mml:math></inline-formula>, Color.green)</monospace> and the right one by <monospace>stroop(<inline-formula><mml:math id="M5"><mml:mstyle mathvariant="monospace" class="text" mathcolor="#8f5973"><mml:mo>“</mml:mo><mml:mtext>text</mml:mtext><mml:mo>”</mml:mo></mml:mstyle></mml:math></inline-formula>, Color.green)</monospace>. The basic layout is just 3 vertically aligned items of equal size. Then the text “target color:” is added. Next a box with the given color, or its name as text, is defined in the function <monospace>make_train_stim()</monospace>. At last the mapping, displaying which key to press for which color, is created in the bottom by <monospace>make_color_mapping()</monospace>. The mapping is created as a horizontal layout that has one horizontal layout as child for each possible color. The inner horizontal layout uses two empty <monospace>LLItem</monospace>s on the outsides as buffers, and has a text, and a colored square in the middle. This leads to a distribution of one empty <monospace>LLItem</monospace> on the outsides, but two empty <monospace>LLItem</monospace>s between 2 mappings.</p>
    </sec>
  </sec>
  <sec id="s5">
    <title>5. Limitations</title>
    <p>While PyParadigm is capable to create most psychological standard tests as it is, it still has some limitations. PyParadigm currently only supports keyboard and mouse input. So any external input device that does not create key-press events would require the creation of additional handler functions, probably using pygames <monospace>joystick</monospace> module.</p>
    <p>Another limitation is that we did not perform any measurements of input or display delays for two reasons: 1. these delays are highly dependent on the executing hardware, 2. compared to the variance in human behavior the variance in hardware delays is low and does usually not have a negative impact on statistical outcomes (Damian, <xref rid="B1" ref-type="bibr">2010</xref>). We rely on pygame's default plotting mechanisms, which usually means an instantaneous screen update when <monospace>display()</monospace> is called, but a delay of the screen update when the <monospace>pygame.DOUBLEBUF</monospace> is used for window creation. While this is no problem for most paradigms, it matters in studies using subliminal priming. Therefore, we cannot recommend using PyParadigm for such studies.</p>
    <p>Additionally, some people may expect some classes or functions to handle the structure of a paradigm, like runs and blogs that may or may not use different conditions. We found that there is no real advantage in using something like this opposed to simply using for-loops and <monospace>itertools.product</monospace>, which is part of the python standard library. However, if you prefer to use such functions, we recommend to use the library “experimentator” (Harrison, <xref rid="B2" ref-type="bibr">2018</xref>), which was explicitly built for this purpose. It is completely independent from PyParadigm, and since there are no overlapping functionalities, it should work together without any problems. However, we haven't tested this.</p>
    <p>pygame does not support the serial port, but there is a library, PySerial Liechti (<xref rid="B4" ref-type="bibr">2019</xref>), that can be utilized to this end.</p>
    <p>Although PyParadigm is based on pygame, which is tested thoroughly, the underlying technology is complex, and depends on the operating system, the hardware and the vendors drivers. Therefore, in some rare cases, PyParadigm might not function on some systems.</p>
  </sec>
  <sec sec-type="conclusions" id="s6">
    <title>6. Conclusion</title>
    <p>In this paper, we have presented our newly developed library, PyParadigm, an efficient, minimalistic and easy to learn approach to paradigm implementation. We demonstrated that the process of creating a paradigm is very straight forward. We introduced the principles of the different modules, gave a breakdown of how paradigm creation works in general, and provided three concrete examples for the <monospace>surface_composition</monospace> module. A real-world paradigm, which was used in a study, can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/KnorrFG/set_switch_paradigm/tree/master/felix_2">https://github.com/KnorrFG/set_switch_paradigm/tree/master/felix_2</ext-link> to browse the source. PyParadigm is designed to save developers time in creating paradigms and to minimize the required lines of code by using an efficient composition mechanism for 2D UIs. Critical feedback via <ext-link ext-link-type="uri" xlink:href="https://github.com/KnorrFG/pyparadigm">https://github.com/KnorrFG/pyparadigm</ext-link> and extensions of the package are very welcome.</p>
  </sec>
  <sec id="s7">
    <title>Author Contributions</title>
    <p>FK designed and implemented the library, and wrote the manuscript. JP tested all provided examples and ensured that all examples are understandable to a layperson as well as proofread and improved the manuscript. MM contributed to the design of the software and provided improvements to the manuscript.</p>
    <sec>
      <title>Conflict of Interest Statement</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> This research was supported by the Deutsche Forschungsgemeinschaft (DFG grant SFB 940/2). We acknowledge support by the Open Access Publication Funds of the SLUB/TU Dresden.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damian</surname><given-names>M. F.</given-names></name></person-group> (<year>2010</year>). <article-title>Does variability in human performance outweigh imprecision in response devices such as computer keyboards?</article-title>
<source>Behav. Res. Methods</source>
<volume>42</volume>, <fpage>205</fpage>–<lpage>211</lpage>. <pub-id pub-id-type="doi">10.3758/BRM.42.1.205</pub-id><?supplied-pmid 20160300?><pub-id pub-id-type="pmid">20160300</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>H. S.</given-names></name></person-group> (<year>2018</year>). <source>Experimentator</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://github.com/hsharrison/experimentator">https://github.com/hsharrison/experimentator</ext-link></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krause</surname><given-names>F.</given-names></name><name><surname>Lindemann</surname><given-names>O.</given-names></name></person-group> (<year>2014</year>). <article-title>Expyriment: a Python library for cognitive and neuroscientific experiments</article-title>. <source>Behav. Res. Methods</source>
<volume>46</volume>, <fpage>416</fpage>–<lpage>428</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-013-0390-6</pub-id><?supplied-pmid 24142834?><pub-id pub-id-type="pmid">24142834</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Liechti</surname><given-names>C.</given-names></name></person-group> (<year>2019</year>). <source>Python serial port access library. Contribute to pyserial/pyserial development by creating an account on GitHub</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://github.com/pyserial/pyserial">https://github.com/pyserial/pyserial</ext-link></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname><given-names>J. W.</given-names></name></person-group> (<year>2009</year>). <article-title>Generating stimuli for neuroscience using PsychoPy</article-title>. <source>Front. Neuroinform.</source>
<volume>2</volume>:<fpage>10</fpage>. <pub-id pub-id-type="doi">10.3389/neuro.11.010.2008</pub-id><?supplied-pmid 19198666?><pub-id pub-id-type="pmid">19198666</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Straw</surname><given-names>A. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Vision Egg: an open-source library for realtime visual stimulus generation</article-title>. <source>Front. Neuroinform.</source>
<volume>2</volume>:<fpage>4</fpage>. <pub-id pub-id-type="doi">10.3389/neuro.11.004.2008</pub-id><?supplied-pmid 19050754?><pub-id pub-id-type="pmid">19050754</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
