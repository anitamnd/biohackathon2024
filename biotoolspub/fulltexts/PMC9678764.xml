<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_ISCI105530 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEfx1 jpg ?>
<?FILEmmc1 pdf ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">iScience</journal-id>
    <journal-id journal-id-type="iso-abbrev">iScience</journal-id>
    <journal-title-group>
      <journal-title>iScience</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2589-0042</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9678764</article-id>
    <article-id pub-id-type="pii">S2589-0042(22)01802-8</article-id>
    <article-id pub-id-type="doi">10.1016/j.isci.2022.105530</article-id>
    <article-id pub-id-type="publisher-id">105530</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>layerUMAP: A tool for visualizing and understanding deep learning models in biological sequence classification using UMAP</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Jing</surname>
          <given-names>Runyu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Xue</surname>
          <given-names>Li</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" id="au3">
        <name>
          <surname>Li</surname>
          <given-names>Menglong</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au4">
        <name>
          <surname>Yu</surname>
          <given-names>Lezheng</given-names>
        </name>
        <email>xinyan_scu@126.com</email>
        <xref rid="aff4" ref-type="aff">4</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <contrib contrib-type="author" id="au5">
        <name>
          <surname>Luo</surname>
          <given-names>Jiesi</given-names>
        </name>
        <email>ljs@swmu.edu.cn</email>
        <xref rid="aff5" ref-type="aff">5</xref>
        <xref rid="fn1" ref-type="fn">6</xref>
        <xref rid="cor2" ref-type="corresp">∗∗</xref>
      </contrib>
      <aff id="aff1"><label>1</label>School of Cyber Science and Engineering, Sichuan University, Chengdu 610065, Sichuan, China</aff>
      <aff id="aff2"><label>2</label>School of Public Health, Southwest Medical University, Luzhou 646000, Sichuan, China</aff>
      <aff id="aff3"><label>3</label>College of Chemistry, Sichuan University, Chengdu 610065, Sichuan, China</aff>
      <aff id="aff4"><label>4</label>School of Chemistry and Materials Science, Guizhou Education University, Guiyang 550018, Guizhou, China</aff>
      <aff id="aff5"><label>5</label>Department of Pharmacology, School of Pharmacy, Southwest Medical University, Luzhou 646000, Sichuan, China</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>∗</label>Corresponding author <email>xinyan_scu@126.com</email></corresp>
      <corresp id="cor2"><label>∗∗</label>Corresponding author <email>ljs@swmu.edu.cn</email></corresp>
      <fn id="fn1">
        <label>6</label>
        <p id="ntpara0010">Lead contact</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>07</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <day>22</day>
      <month>12</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>07</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <volume>25</volume>
    <issue>12</issue>
    <elocation-id>105530</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>8</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>4</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Author(s)</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="abs0010">
      <title>Summary</title>
      <p>Despite the impressive success of deep learning techniques in various types of classification and prediction tasks, interpreting these models and explaining their predictions are still major challenges. In this article, we present an easy-to-use command line tool capable of visualizing and analyzing alternative representations of biological observations learned by deep learning models. This new tool, namely, layerUMAP, integrates autoBioSeqpy software and the UMAP library to address learned high-level representations. An important advantage of the tool is that it provides an interactive option that enables users to visualize the outputs of hidden layers along the depth of the model. We use two different classes of examples to illustrate the potential power of layerUMAP, and the results demonstrate that layerUMAP can provide insightful visual feedback about models and further guide us to develop better models.</p>
    </abstract>
    <abstract abstract-type="graphical" id="abs0015">
      <title>Graphical abstract</title>
      <fig id="undfig1" position="anchor">
        <graphic xlink:href="fx1"/>
      </fig>
    </abstract>
    <abstract abstract-type="author-highlights" id="abs0020">
      <title>Highlights</title>
      <p>
        <list list-type="simple" id="ulist0010">
          <list-item id="u0010">
            <label>•</label>
            <p id="p0010">We developed layerUMAP for the visualization and interpretation of deep learning models</p>
          </list-item>
          <list-item id="u0015">
            <label>•</label>
            <p id="p0015">LayerUMAP can investigate high-level representations learned by the models</p>
          </list-item>
          <list-item id="u0020">
            <label>•</label>
            <p id="p0020">LayerUMAP can dissect the deep learning model layer by layer interactively</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract abstract-type="teaser" id="abs0025">
      <p>Bioinformatics; Systems biology; Genomics; Transcriptomics; Artificial intelligence applications</p>
    </abstract>
    <kwd-group id="kwrds0010">
      <title>Subject areas</title>
      <kwd>Bioinformatics</kwd>
      <kwd>Systems biology</kwd>
      <kwd>Genomics</kwd>
      <kwd>Transcriptomics</kwd>
      <kwd>Artificial intelligence applications</kwd>
    </kwd-group>
  </article-meta>
  <notes>
    <p id="misc0010">Published: December 22, 2022</p>
  </notes>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p id="p0045">Deep learning (DL) models have recently achieved breakthrough performances on a variety of difficult tasks, including life science tasks.<xref rid="bib1" ref-type="bibr"><sup>1</sup></xref><sup>,</sup><xref rid="bib2" ref-type="bibr"><sup>2</sup></xref> Unfortunately, for nonexpert users, their accessibility is often fraught with technical challenges. As most DL methods are available as source code, running them requires setting up a sophisticated software and hardware environment.<xref rid="bib3" ref-type="bibr"><sup>3</sup></xref> The increasing use of next-generation sequencing analysis workflows in bioinformatics and computational biology and the willingness to propagate well-trained DL models are pushing computer scientists to design more user-friendly solutions. An increasing number of libraries or tools addressing this problem with different solutions have become available, including Kipoi,<xref rid="bib4" ref-type="bibr"><sup>4</sup></xref> DragoNN,<xref rid="bib5" ref-type="bibr"><sup>5</sup></xref> Selene,<xref rid="bib6" ref-type="bibr"><sup>6</sup></xref> pysster,<xref rid="bib7" ref-type="bibr"><sup>7</sup></xref> SECLAF,<xref rid="bib8" ref-type="bibr"><sup>8</sup></xref> Janggu,<xref rid="bib9" ref-type="bibr"><sup>9</sup></xref> BioSeq-BLM<xref rid="bib10" ref-type="bibr"><sup>10</sup></xref> and autoBioSeqpy.<xref rid="bib11" ref-type="bibr"><sup>11</sup></xref> Kipoi offers more than 2,000 individually trained models from 22 distinct studies, enabling users to perform a variety of canonical genomic predictive tasks using trained DL models.<xref rid="bib4" ref-type="bibr"><sup>4</sup></xref> Through its API, it is possible to share or reuse trained models on a local machine without any previous programming skills. DragoNN provides an early release DL toolkit that is equipped with both inference and training functionalities for regulatory genomics.<xref rid="bib5" ref-type="bibr"><sup>5</sup></xref> Selene is a PyTorch-based library for developing, training and applying DL model architectures to biological sequence classification and making predictions by writing a few simple command-line commands.<xref rid="bib6" ref-type="bibr"><sup>6</sup></xref>pysster is particularly suited for building and training CNNs for RNA sequence classification by learning structural motifs corresponding to sequence motifs.<xref rid="bib7" ref-type="bibr"><sup>7</sup></xref> The trained residue-sequence models of SECLAF have been made available in a preconfigured webserver.<xref rid="bib8" ref-type="bibr"><sup>8</sup></xref> Janggu combines dedicated dataset objects provided by Bioseq<xref rid="bib12" ref-type="bibr"><sup>12</sup></xref> and Cover<xref rid="bib9" ref-type="bibr"><sup>9</sup></xref> with popular DL libraries, such as Keras<xref rid="bib13" ref-type="bibr"><sup>13</sup></xref> and PyTorch,<xref rid="bib14" ref-type="bibr"><sup>14</sup></xref> to simplify DL applications in genomics with reusable components.<xref rid="bib9" ref-type="bibr"><sup>9</sup></xref> BioSeq-BLM utilizes browser user interfaces to train different models in a noncoding fashion, together with a set of 155 biological language representations that support the easy training and use of their models.<xref rid="bib10" ref-type="bibr"><sup>10</sup></xref>autoBioSeqpy is a contribution of our group to the field that increases the accessibility of DL for biological sequences. The main features and characteristics of autoBioSeqpy are summarized as follows: (1) Model development is separated into independent parts, enabling users to design and tune models flexibly according to their needs; (2) all parts, including dataset reading, sequence encoding, model training and evaluation, can be executed with command-line tools, enabling users to easily modify the parameters of the entire workflow; and (3) it provides documentation in a browser-based notebook interface, enabling users to further analyze the models.<xref rid="bib11" ref-type="bibr"><sup>11</sup></xref></p>
    <p id="p0050">The previously described tools have started to boost the use of DL solutions for biological sequence prediction tasks and facilitate the dissemination of DL models in a standardized manner. Despite this encouraging progress, there is still little insight into the inner operation and behavior of DL models or how they perform well. Typically, DL models are treated as “black box” function approximators that map a given input to a classification output. Because of this “black box” characteristic, the development of high-quality DL models usually relies on a time-consuming trial-and-error procedure.<xref rid="bib15" ref-type="bibr"><sup>15</sup></xref> Techniques for understanding the mechanism and the performance of DL models have therefore become a key ingredient of a robust validation procedure. Recently, UMAP<xref rid="bib16" ref-type="bibr"><sup>16</sup></xref> and t-SNE<xref rid="bib17" ref-type="bibr"><sup>17</sup></xref> have been frequently used together with deep learning methods to understand what a model might have learned. However, a user-friendly tool for integrating these techniques to visualize the hidden activities of deep learning models in a noncoding fashion and with a unified format is still missing. We present layerUMAP, a command-line tool included in the autoBioSeqpy software, written in Python, which makes use of UMAP to understand, diagnose and refine DL models. layerUMAP provides access to the hidden layers of trained models developed by autoBioSeqpy. Hence, users can easily perform two valuable visual feedback tasks: investigating high-level representations learned by the models and dissecting each model’s performance layer by layer. This is especially helpful for users to compare and select models based on their data, making the dissemination of DL models more effective. We demonstrate layerUMAP on two use cases: (1) Classifying Gram-negative bacterial secreted proteins from primary sequences and (2) identifying cell types from single-cell gene expression data. In these examples, different types of DL models are developed, including convolutional, recurrent, convolutional-recurrent and deep neural networks, which cover the most commonly used network architectures. This study highlights the use of layerUMAP for the improved visualization and interpretation of deep learning models.</p>
  </sec>
  <sec id="sec2">
    <title>Results</title>
    <p id="p0055">In this section, the metrics that were used to evaluate the predictions from the models are provided. The following subsections present the two case studies conducted in this work.</p>
    <sec id="sec2.1">
      <title>Case study 1: Classifying Gram-negative bacterial secreted proteins from primary sequences</title>
      <p id="p0060">We performed a grid search to exhaustively test hyperparameter combinations of the number of convolution layers (1, 2, 3, and 4), convolution filter length (3, 5, 7, 9, 11, and 13), number of convolution filters (50, 100, 150, 200, 250, and 300), number of BiLSTM layers (1, 2, 3, and 4), number of nodes in the BiLSTM layer (16, 32, 64, and 128), number of BiGRU layers (1, 2, 3, and 4) and number of nodes in the BiGRU layer (16, 32, 64, and 128). In the process of tuning the hyperparameters, we varied each hyperparameter individually while keeping the remaining hyperparameters constant. We measured the performance change with respect to the change in each hyperparameter by repeating the training procedure 10 times and obtained 10 trained models. During testing, the performance of each hyperparameter was evaluated using all 10 trained models, and the accuracy over these 10 models was used as the final score. The optimization results for various hyperparameters are shown in <xref rid="fig1" ref-type="fig">Figure 1</xref>. Because the performance of the convolution operation depends critically on the length and number of filters, we evaluated a range of filter lengths from 3 to 13 in steps of 2 and a range of filter numbers from 50 to 300 in steps of 50. <xref rid="fig1" ref-type="fig">Figure 1</xref>A shows that the accuracy of the CNN model varied substantially as the relevant hyperparameters were varied. The combination of hyperparameters that yielded the highest classification accuracy was filter length = 5 and number of filters = 300. We also found that the performance of the CNN model was significantly affected by the pooling strategy. Global max pooling yielded notably better results than max pooling (<xref rid="fig1" ref-type="fig">Figure 1</xref>B). This may have been because global max pooling extracts information from the convolved sequences more effectively than max pooling. For two special types of RNNs, we observed that LSTM and GRU performed poorly compared to BiLSTM and BiGRU, respectively, which is consistent with our previous findings<xref rid="bib11" ref-type="bibr"><sup>11</sup></xref> (<xref rid="fig1" ref-type="fig">Figure 1</xref>C). The bidirectional approach can learn the context features from input sequences in both directions (forward and backwards) and provide additional information about the residues in the sequence before and after the current position. Furthermore, we varied the input sizes of the BiLSTM and BiGRU layers from 16 to 32, 64, and 128 to examine their influence on the classification accuracy. With an input size of 64 (a hidden size of 128 for the bidirectional layer), both RNN models showed the best performance (<xref rid="fig1" ref-type="fig">Figure 1</xref>E). We varied the number of different types of network layers to further investigate the impact of network depth on model performance. When we increased the number of layers from 1 to 4, the performance improved with increasing depth, and the highest classification accuracy was reached with three recurrent layers for BiLSTM and BiGRU (<xref rid="fig1" ref-type="fig">Figure 1</xref>D). In contrast, for CNN, although increasing depth was initially beneficial, it had the opposite effect after two convolutional layers. These observations are summarized in a schematic illustration of the proposed deep learning architectures in <xref rid="fig1" ref-type="fig">Figure 1</xref>F.<fig id="fig1"><label>Figure 1</label><caption><p>Hyperparameter tuning and model architecture optimization</p><p>(A) 3D barplot showing the accuracy results of convolutional layers using different combinations of hyperparameters (i.e., number and length of filters).</p><p>(B) Accuracy comparisons of different pooling strategy.</p><p>(C) Accuracy comparisons of different types of RNN layers.</p><p>(D) Effect of the number of network layers on model’s accuracy.</p><p>(E) Dot plot showing the accuracy of BiLSTM and BiGRU layers for distinct input sizes.</p><p>(F) Layout of the optimized deep neural network architectures.</p></caption><graphic xlink:href="gr1"/></fig></p>
      <p id="p0065">We implemented and trained the above five DL models in autoBioSeqpy using the command-line command 1, as shown in the <xref rid="fig2" ref-type="fig">Figure 2</xref>. Here, we used the CNN model as an example. The classwise prediction quality of each model is shown in the confusion matrix in <xref rid="fig3" ref-type="fig">Figure 3</xref>A. CNN and CNN-BiGRU achieved a high accuracy of 97.9%. The other models also showed relatively high accuracies, of 97.7% for CNN-BiLSTM, 97.3% for BiLSTM and 95.8% for BiGRU.<fig id="fig2"><label>Figure 2</label><caption><p>Example commands illustrate how to use autoBioSeqpy and layerUMAP for deep learning model analysis</p></caption><graphic xlink:href="gr2"/></fig><fig id="fig3"><label>Figure 3</label><caption><p>Validation of the classification using layerUMAP</p><p>(A) The confusion matrix for the six-class classification task using five DL models. The matrices contain absolute values and are colored based on these absolute values.</p><p>(B) UMAP visualization of the last hidden layer representations for six secretory types. Points are colored using the fire theme based on the true six class labels that the network was trained to distinguish: 0 for ‘T1SS’, 1 for ‘T2SS’, 2 for ‘T3SS’, 3 for ‘T4SS’, 4 for ‘T5SS’ and 5 for ‘T7SS’.</p><p>(C and D) The trainable parameters and runtimes (seconds per epoch) required for DL models.</p><p>(E) Comparisons of classification accuracy for the test dataset.</p></caption><graphic xlink:href="gr3"/></fig></p>
    </sec>
    <sec id="sec2.2">
      <title>Case study 2: Identifying cell types from single-cell gene expression data</title>
      <p id="p0070">Here, we developed a novel deep learning model called RFCN for the type classification of single cells using residual fully connected networks. The overall model architecture is illustrated in <xref rid="fig4" ref-type="fig">Figure 4</xref>A. The input to the model is a matrix of gene expression values measured in a scRNA-seq experiment, with each column representing a gene and each row representing a cell. We applied the RFCN to three scRNA-seq datasets from pancreatic tissue, PBMCs and lung cancer cells and showed that the RFCN was able to classify individual cells with high accuracy (<xref rid="fig4" ref-type="fig">Figure 4</xref>B). Specifically, RFCN achieved overall accuracies of 98.09, 99.78 and 100% in cell type classification on the Zheng sorted, Pancreas and CellBench datasets, respectively. Instead of only considering the accuracy, we also evaluated the F1-score for each cell population. The median of these F1-scores was used as the final measure for the performance on the dataset. On all three datasets, RFCN also performed well, with a median F1-score &gt;0.98. We further visualized representations of cells learned by RFCN in the two-dimensional UMAP space using layerUMAP.<fig id="fig4"><label>Figure 4</label><caption><p>RFCN is a deep neural network model for cell type identification</p><p>(A) Schematic illustration of the RFCN architecture.</p><p>(B) Classification performance of RFCN on three scRNA-seq datasets.</p><p>(C) UMAP visualization of cell representations learned from the RFCN, in which the ontology labels are provided by the original publication.</p></caption><graphic xlink:href="gr4"/></fig></p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>Discussion</title>
    <p id="p0075">This section discusses the performance of the best model demonstrated in the ‘<xref rid="sec2" ref-type="sec">results</xref>’ section by using plots generated by layerUMAP. A practical explanation of the neural layers from the built model together with the related interpretation are presented according to the two case studies.</p>
    <sec id="sec3.1">
      <title>Case study 1: Classifying Gram-negative bacterial secreted proteins from primary sequences</title>
      <p id="p0080">To further validate these results, we visualized the last hidden layer representations of the DL models using the layerUMAP tool with the command-line command 2 (<xref rid="fig2" ref-type="fig">Figure 2</xref>). If the ‘--interactive’ option is not used, layerUMAP will output the projection of the last hidden layer of the trained model by default, and ‘tmpOut/parameters.txt’ is the parameter file, which can be generated by command-line command 1. The runtime of the above command was approximately 30 s, excluding the interaction time. Each point in <xref rid="fig3" ref-type="fig">Figure 3</xref>B represents a Gram-negative bacterial secreted protein projected from the 6-dimensional output of the model’s last hidden layer into two dimensions. Colored point clouds represent the different secretory types, showing how the model clusters the proteins. We see that points of the same category are clustered together and clearly separated from points of other categories. When we investigated the number of misclassified proteins across all classes for the best CNN model, we observed that a total of 14 proteins were not correctly recognized by the network: 1 originated from T1SS, three from T2SS, four from T4SS, two from T5SS and four from T7SS. All proteins originating from T3SS were classified correctly. Further investigating each cluster, we found that 4 T4SS, 2 T2SS and 1 T7SS protein were classified as T3SS proteins (Cluster 2); 2 T7SS and 1 T5SS protein were classified as T2SS proteins (Cluster 1); 1 T2SS and 1 T5SS protein were classified as T4SS proteins (Cluster 3); and 1 T1SS and 1 T7SS protein were classified as T5SS proteins (Cluster 4), which is consistent with the classification results of the CNN model. We next evaluated the models in terms of test accuracy, architectural complexity and computational complexity. Considering the number of parameters, the CNN-BiLSTM model was found to have the most complex architecture, with a total of 952.868 trainable parameters (<xref rid="fig3" ref-type="fig">Figure 3</xref>C). Although achieving comparable accuracies, the BiGRU model had fewer parameters than CNN-BiLSTM. CNN was the fastest model with respect to runtimes and finished an epoch in under 20 s, which was much less than the times required by other models (<xref rid="fig3" ref-type="fig">Figure 3</xref>D). With regard to test accuracy, CNN also outperformed the other competing models, yielding the highest classification accuracy (91.3%) (<xref rid="fig3" ref-type="fig">Figure 3</xref>E). The next-best-performing model was CNN-BiGRU (89.5%), followed by BiLSTM (86.6%). In conclusion, our results demonstrate that the proposed CNN architecture is the most appropriate model for distinguishing between different types of Gram-negative bacterial secreted proteins.</p>
      <p id="p0085">To further showcase the ability of layerUMAP to analyze and diagnose DL models, we performed a layer-by-layer dissection of the CNN architecture using the command-line command 3 (<xref rid="fig2" ref-type="fig">Figure 2</xref>). layerUMAP gives the user the flexibility to run UMAP routines using a range of options. For example, by using the layer names or indices, the user can explore the layers of interest in more depth. It is clear that the data containing more than three dimensions cannot be directly plotted into a 2D figure, which limits the visualization in a few layers, such as the reshape layers and convolution layers. To address this issue, we provided several dimensionality reduction options for reducing multi-dimensional data into lower-dimensional data. To facilitate understanding, we considered the dimensionality reduction of the convolution layer as an example to illustrate how layerUMAP performs these operations. As shown in <xref rid="fig5" ref-type="fig">Figure 5</xref>, by calculating the possible values (maximum, minimum or average) for each row or column, the feature matrix of the sample was compressed in two directions, namely, ‘Filtered sequence length’ and ‘Channel’. Samples generated in the ‘Filtered sequence length’ direction were mixed together due to the loss of much channel information, while the other direction retained more channel information, resulting in a better separation. In addition, each channel could be extracted independently for UMAP plotting, which facilitated the comparison of filters. Finally, we used layerUMAP to observe how the internal representations of samples evolved in different network layers (<xref rid="fig6" ref-type="fig">Figure 6</xref>). For the first two convolutional layers, we applied the dimensionality reduction procedure to the data by computing the maximum values in the ‘Channel’ direction.<fig id="fig5"><label>Figure 5</label><caption><p>UMAP visualization of multi-dimensional convolutional outputs</p></caption><graphic xlink:href="gr5"/></fig><fig id="fig6"><label>Figure 6</label><caption><p>UMAP visualization of inter-layer evolution for the CNN model</p></caption><graphic xlink:href="gr6"/></fig></p>
    </sec>
    <sec id="sec3.2">
      <title>Case study 2: Identifying cell types from single-cell gene expression data</title>
      <p id="p0090">To investigate the effects of two UMAP parameters (n_neighbors and min_dist) on the resulting embedding, we first performed a grid search in the parameter space using the command-line command 4 (<xref rid="fig2" ref-type="fig">Figure 2</xref>). The runtime of this command without interaction was approximately 24 min because we conducted a grid search with 'n_neighbors' and 'min_dist' in 126 iterations; when the grid search was turned off, the runtime was reduced to approximately 50 s. This 50-s process was roughly divided into two parts, one concerning the preparation of the temporary model and the generation of the output of the middle layer and the other calling the UMAP library and plotting. According to our tests, the first part took approximately 39 s, and the second part took approximately 11 s.</p>
      <p id="p0095">Using the Zheng sorted dataset as an example, we observed that the parameter ‘min_dist’ had a significant impact on the separation of cell populations. With an increasing value of min_dist, UMAP ultimately separated cell populations into distinct clusters that corresponded to their cell types (<xref rid="mmc1" ref-type="supplementary-material">Figure S1</xref>). Furthermore, we compared the effects of ten different metric parameters: chebyshev, braycurtis, canberra, correlation, cosine, euclidean, mahalanobis, manhattan, minkowski and wminkowski. Only wminkowski failed to separate cell populations (<xref rid="mmc1" ref-type="supplementary-material">Figure S2</xref>). The other metrics revealed relatively similar clusters, with a few differences. After optimizing the UMAP parameters, we used the command-line command 5 to visualize the classification results of the RFCN model (<xref rid="fig2" ref-type="fig">Figure 2</xref>). RFCN learned to embed cells of the same type close to each other while embedding cells of different types far from each other, agreeing well with the cell type annotations (<xref rid="fig4" ref-type="fig">Figure 4</xref>C).</p>
    </sec>
    <sec id="sec3.3">
      <title>Limitations of the study</title>
      <p id="p0100">layerUMAP was found to provide a convenient method for the hidden data visualization of a deep learning model. However, the architecture of a deep learning model can be very complex, e.g., with distillation and multitask learning structures. Currently, layerUMAP cannot capture the hidden outputs from the layers in a branch (if existing) of the built model, and users can only capture the outputs manually using the related Jupyter Notebook.</p>
    </sec>
    <sec id="sec3.4">
      <title>Conclusions</title>
      <p id="p0105">In recent years, there has been an explosion of deep learning applications in many aspects of biological research. A variety of biological data can be modeled using deep learning techniques, including DNA,<xref rid="bib18" ref-type="bibr"><sup>18</sup></xref><sup>,</sup><xref rid="bib19" ref-type="bibr"><sup>19</sup></xref><sup>,</sup><xref rid="bib20" ref-type="bibr"><sup>20</sup></xref> RNA,<xref rid="bib21" ref-type="bibr"><sup>21</sup></xref><sup>,</sup><xref rid="bib22" ref-type="bibr"><sup>22</sup></xref> and protein data.<xref rid="bib2" ref-type="bibr"><sup>2</sup></xref><sup>,</sup><xref rid="bib23" ref-type="bibr"><sup>23</sup></xref> Despite the great success of deep learning in solving various pattern recognition tasks in recent years, the problem of understanding the mechanisms of DL models remains largely unresolved and, thus, has become an issue in the development of DL. Without a deeper understanding of the method, the development of high-quality DL models relies on a substantial number of trial-and-error procedures, and the use of trained models could also potentially become a source of unreliable results. Because DL models consist of numerous layers, functional components and operations, interpreting them is still a technical challenge. To address this challenge, we have developed an interactive, visual analytics tool called layerUMAP, which aims to help DL users better design and diagnose DL models. We showed how layerUMAP can be used to understand the mechanism and the performance of a model and to inspect the model’s inner status at the layer level. We successfully applied this tool in our previous studies.<xref rid="bib24" ref-type="bibr"><sup>24</sup></xref><sup>,</sup><xref rid="bib25" ref-type="bibr"><sup>25</sup></xref> To further demonstrate the capabilities of layerUMAP, we presented two case studies in this article. We expect layerUMAP to provide insight into the mechanisms of DL models and to become a standard tool for the visual analysis of DL models.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>STAR★Methods</title>
    <sec id="sec4.1">
      <title>Key resources table</title>
      <p id="p0110">
        <table-wrap position="float" id="undtbl1">
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th>REAGENT or RESOURCE</th>
                <th>SOURCE</th>
                <th>IDENTIFIER</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="3">
                  <bold>Software and algorithms</bold>
                </td>
              </tr>
              <tr>
                <td colspan="3">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td>autoBioSeqpy</td>
                <td>Jing et al.<xref rid="bib11" ref-type="bibr"><sup>11</sup></xref></td>
                <td>
                  <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/acs.jcim.0c00409" id="intref0030">https://doi.org/10.1021/acs.jcim.0c00409</ext-link>
                  <break/>
                  <ext-link ext-link-type="uri" xlink:href="https://github.com/jingry/autoBioSeqpy/tree/2.0" id="intref0035">https://github.com/jingry/autoBioSeqpy/tree/2.0</ext-link>
                </td>
              </tr>
              <tr>
                <td>layerUMAP</td>
                <td>This paper</td>
                <td>
                  <ext-link ext-link-type="uri" xlink:href="https://github.com/jingry/autoBioSeqpy/blob/2.0/tool/layerUMAP.py" id="intref0040">https://github.com/jingry/autoBioSeqpy/blob/2.0/tool/layerUMAP.py</ext-link>
                  <break/>
                  <ext-link ext-link-type="uri" xlink:href="https://github.com/jingry/autoBioSeqpy/blob/2.0/examples/layerUMAP.zip" id="intref0045">https://github.com/jingry/autoBioSeqpy/blob/2.0/examples/layerUMAP.zip</ext-link>
                </td>
              </tr>
              <tr>
                <td colspan="3">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td colspan="3">
                  <bold>Deposited data</bold>
                </td>
              </tr>
              <tr>
                <td colspan="3">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td>Gram-negative bacterial secreted proteins dataset</td>
                <td>Yu et al.<xref rid="bib26" ref-type="bibr"><sup>26</sup></xref></td>
                <td>
                  <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.compbiomed.2013.06.001" id="intref0050">https://doi.org/10.1016/j.compbiomed.2013.06.001</ext-link>
                  <break/>
                  <ext-link ext-link-type="uri" xlink:href="http://cic.scu.edu.cn/bioinformatics/secretPv2_1/index.htm" id="intref0055">http://cic.scu.edu.cn/bioinformatics/secretPv2_1/index.htm</ext-link>
                </td>
              </tr>
              <tr>
                <td>scRNA-seq datasets</td>
                <td>Abdelaal et al.<xref rid="bib27" ref-type="bibr"><sup>27</sup></xref></td>
                <td>
                  <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s13059-019-1795-z" id="intref0060">https://doi.org/10.1186/s13059-019-1795-z</ext-link>
                  <break/>
                  <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/3357167" id="intref0065">https://zenodo.org/record/3357167</ext-link>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </p>
    </sec>
    <sec id="sec4.2">
      <title>Resource availability</title>
      <sec id="sec4.2.1">
        <title>Lead contact</title>
        <p id="p0115">Further information and requests for resources and reagents should be directed to and will be fulfilled by the lead contact, Jiesi Luo (<ext-link ext-link-type="uri" xlink:href="mailto:ljs@swmu.edu.cn" id="intref0070">ljs@swmu.edu.cn</ext-link>).</p>
      </sec>
      <sec id="sec4.2.2">
        <title>Materials availability</title>
        <p id="p0120">This study did not generate new unique reagents.</p>
      </sec>
    </sec>
    <sec id="sec4.3">
      <title>Method details</title>
      <sec id="sec4.3.1">
        <title>Overview of layerUMAP</title>
        <p id="p0125">As the main plugin of the autoBioSeqpy toolbox, layerUMAP enables visual analysis of trained DL models using a one-line command. It provides several parameters and options that can be easily set by users, including the following:<list list-type="simple" id="ulist0020"><list-item id="u0040"><label>•</label><p id="p0130">--paraFile: a path parameter containing information about the trained DL models;</p></list-item><list-item id="u0045"><label>•</label><p id="p0135">--outFigFolder: a path parameter specifying the output folder in which the result file named UMAP.pdf will be saved;</p></list-item><list-item id="u0050"><label>•</label><p id="p0140">--n_neighbors: a UMAP parameter controlling how UMAP balances local versus global structure in the data;</p></list-item><list-item id="u0055"><label>•</label><p id="p0145">--min_dist: a UMAP parameter controlling how tightly UMAP is allowed to pack points together;</p></list-item><list-item id="u0060"><label>•</label><p id="p0150">--metric: a UMAP parameter controlling how distance is computed in the ambient space of the input data;</p></list-item><list-item id="u0065"><label>•</label><p id="p0155">--grid_n_neighbors and--grid_min_dist: two parameters for performing grid searches for the--n_neighbors and--min_dist parameters, respectively. The values of the two parameters are passed to arrange () in NumPy (used as ‘start stop stepSize’). If ‘--grid_min_dist’ or ‘--grid_n_neighbors’ is used, ‘--min_dist’ or ‘--n_neighbors’ will be ignored, respectively;</p></list-item><list-item id="u0070"><label>•</label><p id="p0160">--theme: a parameter specifying the colour, background and theme for plotting;</p></list-item><list-item id="u0075"><label>•</label><p id="p0165">--figWidth and--figHeight: two parameters specifying the size of the output figures;</p></list-item><list-item id="u0080"><label>•</label><p id="p0170">--dimensionReduceMethod: a parameter for reducing the high-dimensional outputs to two dimensions, with possible values of ‘max’, ‘min’, ‘avg’ or ‘flatten’;</p></list-item><list-item id="u0085"><label>•</label><p id="p0175">--interactive: a parameter specifying a layer name or layer index for plotting.</p></list-item></list></p>
        <p id="p0180">To make the processes of layer selection and dimensionality reduction more user-friendly, an interactive option is provided in layerUMAP by setting ‘<italic>--interactive 1</italic>’ in the command. When the interactive option is turned on, users are asked to select which layer to use as the output layer by specifying the name or index of the layer in the list. If the output dimensionality is higher than the value of 2 required by UMAP, three options are provided for reducing the dimensionality: 1) selecting a 2-D slice from the N-D tensor, 2) splitting the N-D tensor into 2-D slices and plotting all slices, and 3) changing the N-D tensor to 2-D using the maximal, minimal, average, or flatten method. Users can specify the dimensions or axis to be preserved or reduced, except for the first dimension, which represents the number of instances. The visual output is generated in PDF format, and the number of pages will be greater than 1, depending on the parameters.</p>
      </sec>
      <sec id="sec4.3.2">
        <title>Dataset for case study 1</title>
        <p id="p0185">A large number of pathogenic and symbiotic bacteria have evolved specialized secretion systems to deliver bacterial proteins into eukaryotic cells to ensure their survival and replication.<xref rid="bib28" ref-type="bibr"><sup>28</sup></xref> To date, nine secretion systems have been found in Gram-negative bacteria and named from the type I (T1SS) to the type IX secretion system (T9SS) according to their outer membrane secretion mechanisms.<xref rid="bib29" ref-type="bibr"><sup>29</sup></xref><sup>,</sup><xref rid="bib30" ref-type="bibr"><sup>30</sup></xref> Correspondingly, proteins released through T1SS are called type I secreted proteins (T1SPs), and other types of proteins are named analogously. These secreted proteins play different roles in invaded eukaryotic cells and cause various diseases; therefore, it is crucial to explore their relationships and differences, which is beneficial for both disease pathogenesis and drug development.</p>
        <p id="p0190">The dataset used in this case was obtained from our previous work.<xref rid="bib26" ref-type="bibr"><sup>26</sup></xref> Each protein was categorized into one of six subsets, namely, from T1SP to T7SP, with the exception of T6SP. In more detail, we first collected information concerning protein or gene IDs and corresponding secretory types through a comprehensive literature search and then manually extracted protein sequences from three data sources, namely, Swiss-Prot,<xref rid="bib31" ref-type="bibr"><sup>31</sup></xref> TrEMBL<xref rid="bib32" ref-type="bibr"><sup>32</sup></xref> and RefSeq.<xref rid="bib33" ref-type="bibr"><sup>33</sup></xref> To ensure an accurate collection, only reviewed entries (that is, from Swiss-Prot) were used, and ‘hypothetical’, ‘probable’, ‘by similarity’ or ‘predicted’ proteins were not included. We discarded protein sequences shorter than 50 AAs and further filtered duplicate or homologous proteins with a sequence identity threshold of 25% using the BLASTCLUST program.<xref rid="bib34" ref-type="bibr"><sup>34</sup></xref> With this procedure, we ended up with 839 proteins, including 667 training proteins and 172 test proteins, whose secretory types are distributed as follows: T1SP (112, 25), T2SP (99, 29), T3SP (182, 28), T4SP (62, 22), T5SP (164, 35) and T7SP (48, 33).</p>
      </sec>
      <sec id="sec4.3.3">
        <title>Deep learning architectures for case study 1</title>
        <p id="p0195">We selected and trained five representative DL models constructed with different network architectures, including a convolutional neural network (CNN) and four recurrent neural network (RNN)-based variants, namely, bidirectional long short-term memory (BiLSTM), bidirectional gated recurrent unit (BiGRU), CNN-BiLSTM and CNN-BiGRU. We searched for the best model from each proposed architecture and explored different possibilities for developing better models by trying to tune the hyperparameters and optimize the architectures. It is generally accepted that CNNs perform well at capturing local patterns in sequences, whereas RNNs can capture long-distance dependencies in sequential data.<xref rid="bib35" ref-type="bibr"><sup>35</sup></xref> To fairly evaluate the abilities of CNNs and RNNs to learn sequence patterns within Gram-negative bacterial secreted proteins, we changed only the convolutional and recurrent layers in each proposed architecture while keeping the other types of network layers consistent. All models consume raw sequences as input and calculate the probability of a protein of interest being one of the six secretory types. More precisely, the input to each model is a sequence of one-hot encoded amino acids, where each residue is transformed into a 20-dimensional vector, and the output of each model consists of six scores that sum to one.</p>
        <p id="p0200">The CNN architecture consists of two convolutional layers, a pooling layer, a dropout layer, an activation layer and two fully connected layers. Both convolutional layers first perform 1D convolution operations with 300 filters of kernel length 5. Each convolutional layer applies a ReLU activation function to introduce nonlinearities. The third pooling layer computes the global maximum value in each feature map, increasing the translational invariance and reducing the number of parameters. The pooled output is then passed through a fully connected layer containing 650 nodes with a 0.5× dropout and finally through another fully connected layer with softmax activation, producing 6 secretory type predictions. We used the BiLSTM and BiGRU as RNN representation learners considering their successful applications to similar tasks in biological sequences.<xref rid="bib36" ref-type="bibr"><sup>36</sup></xref><sup>,</sup><xref rid="bib37" ref-type="bibr"><sup>37</sup></xref> Specifically, the two RNN architectures selected for training were a three-layer stacked BiLSTM with 128-dimensional hidden state vectors per layer and a three-layer stacked BiGRU, also with 128 dimensions per layer, both followed by GlobalMaxPooling layers and two fully connected layers, which were the same settings as in the CNN architecture. The principal network architectures of CNN-BiLSTM and CNN-BiGRU were adapted from the above three architectures. Two convolutional layers (filters 300, 300; kernel widths 5, 5) with ReLU activation, three BiLSTM or BiGRU layers (hidden state vectors 128, 128, 128), a GlobalMaxPooling layer, a fully connected layer (650 hidden units), dropout (rate = 0.5) and ReLU activation were used, followed by a fully connected layer with a softmax function to output individual probabilities for each label.</p>
        <p id="p0205">All models were trained for 50 epochs with a batch size of 40 and a learning rate of 0.001 on an NVIDIA GTX 1060 GPU to enable parallel calculation of the gradient. For general user applications, the CPU backend was found to be sufficient. The categorical cross-entropy loss between the predicted labels and the true observed labels was minimized using the Adam optimizer during training. As is conventional, the test set was used for hyperparameter tuning and model architecture optimization. The length of the input sequence was limited to 2000 amino acids, this limit was chosen to fit the longest sequence in the dataset.</p>
      </sec>
      <sec id="sec4.3.4">
        <title>Datasets for case study 2</title>
        <p id="p0210">The recent maturation of single-cell RNA sequencing (scRNA-seq) technology has revolutionized our ability to identify and characterize cell types, states, lineages and circuitries.<xref rid="bib38" ref-type="bibr"><sup>38</sup></xref><sup>,</sup><xref rid="bib39" ref-type="bibr"><sup>39</sup></xref> Rapid and continuous technological advances in scRNA-seq now enable routine profiling of millions of cells.<xref rid="bib40" ref-type="bibr"><sup>40</sup></xref> Such large and growing data have opened the way for substantial scientific discoveries<xref rid="bib38" ref-type="bibr"><sup>38</sup></xref> and have driven a global project, namely, the Human Cell Atlas (HCA),<xref rid="bib41" ref-type="bibr"><sup>41</sup></xref>which aims to build a comprehensive reference map of all human cells. Despite the unprecedented power of scRNA-seq, it remains a computationally challenging task to define and identify cell populations in a given dataset due to the high dimensionality and inherited high level of technical noise of scRNA-seq data.<xref rid="bib42" ref-type="bibr"><sup>42</sup></xref> Marker gene-based manual annotation after unsupervised clustering is still the standard practice for solving this task. However, the manual annotation process is cumbersome, time-consuming and potentially inaccurate. To address this pressing challenge, a growing number of supervised classification methods have been developed for cell type assignment by learning the identities of annotated cells from a reference atlas.</p>
        <p id="p0215">Abdelaal et al. benchmarked 22 classification methods for the automatic assignment of cell types using 27 publicly available scRNA-seq datasets of different sizes, technologies, species, and complexities.<xref rid="bib27" ref-type="bibr"><sup>27</sup></xref> In this case study, we selected three benchmark datasets from the study of<xref rid="bib27" ref-type="bibr"><sup>27</sup></xref> to develop a novel deep learning model for cell type classification. The CellBench dataset consists of 4,373 cells from five human lung cancer cell lines assayed by two different technologies (10X chromium and CEL-Seq2). The five cell populations are A549 (1,410), H1975 (517), H2228 (828), H838 (986), and HCC827 (632). The human pancreatic dataset comprises four individual scRNA-seq datasets (Baron Human, Muraro, Segerstolpe, and Xin) with a total of 10,150 cells. We selected the four major endocrine pancreatic cell types, namely, alpha (4,865), beta (3,702), delta (950) and gamma (633), across all four pancreatic datasets. The Zheng sorted dataset contains 20,000 cells in total and was obtained by downsampling 2,000 cells for each population from the full datasets. The 10 representative PBMC-sorted populations selected from the 10X Genomics website are CD14<sup>+</sup> monocytes, CD19<sup>+</sup> B cells, CD34<sup>+</sup> cells, CD4<sup>+</sup> helper T cells, CD4+/CD25+ regulatory T cells, CD4+/CD45RA+/CD25-naive T cells, CD4+/CD45RO + memory T cells, CD56<sup>+</sup> natural killer cells, CD8<sup>+</sup> cytotoxic T cells, and CD8+/CD45RA + naive cytotoxic T cells. All datasets were processed, aligned and merged using the following procedure. Uncertain cells annotated as ‘doublets’, ‘debris’, ‘unlabelled cell’, ‘not applicable’, and ‘unclassified cell’, as well as cell types with fewer than 10 cells across the entire dataset, were filtered out. Genes expressing zero counts in all cells and cells expressing a median absolute deviation (MAD) of less than 3 were removed. In addition, to correct batch effects and technical variations between different protocols, datasets were aligned using MNN<xref rid="bib43" ref-type="bibr"><sup>43</sup></xref> from the scran R package.</p>
      </sec>
      <sec id="sec4.3.5">
        <title>Deep learning architectures for case study 2</title>
        <p id="p0220">With reference to the ResNet architecture,<xref rid="bib44" ref-type="bibr"><sup>44</sup></xref> we developed a residual fully connected network for determining cell identities directly using scRNA-seq data. The input gene expression data are first fed into two fully connected layers with 5120 and 256 neurons. Afterwards, the output from these layers is concatenated and input into a residual block module, and this process is repeated 10 times. In the residual block, three fully connected layers (with 256, 1,024, and 256 hidden nodes) and layer normalization (LN) layer share the weights in each inner block iteration, where the three fully connected layers constitute a bottleneck structure and the LN layer is used to restrict the features to the same average and variance. Following the residual block module is a fully connected layer with 128 nodes and the last output layer with a softmax activation layer. We used the ReLU activation function and a dropout rate of 0.15 in all fully connected layers to avoid overfitting. Detailed pseudocode for the residual fully connected network is given in <xref rid="tbox1" ref-type="boxed-text">Algorithm 1</xref>.<boxed-text id="tbox1"><label>Algorithm 1</label><caption><title>Pseudocode of ResNet</title></caption><p id="p0265"><inline-formula><mml:math id="M1" altimg="si1.gif"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:mi>F</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mtext> ResidualFullConnModel</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>256</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>5120</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mo>:</mml:mo><mml:mtext>for i from </mml:mtext><mml:mn>1</mml:mn><mml:mtext> to </mml:mtext><mml:mn>10</mml:mn><mml:mtext>:</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>3</mml:mn><mml:mo>:</mml:mo><mml:mtext>    </mml:mtext><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>256</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>4</mml:mn><mml:mo>:</mml:mo><mml:mtext>    </mml:mtext><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1024</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>5</mml:mn><mml:mo>:</mml:mo><mml:mtext>    </mml:mtext><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mo>=</mml:mo><mml:mi>Re</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>256</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>6</mml:mn><mml:mo>:</mml:mo><mml:mtext>end for</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>7</mml:mn><mml:mo>:</mml:mo><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>128</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>8</mml:mn><mml:mo>:</mml:mo><mml:mtext>Returen </mml:mtext><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></inline-formula></p></boxed-text></p>
        <p id="p0225">Each input scRNA-seq dataset was divided into a testing set (10%) and a development set (90%). From the development set, a validation set of the same size as the testing set was selected, and the remaining cells were reserved for training. The model was trained to minimize a categorical cross-entropy loss using the Adam optimizer with a batch size of 128. The learning rate of the optimizer was set to 0.0005, and training was limited to 20 epochs.</p>
      </sec>
    </sec>
    <sec id="sec4.4">
      <title>Quantification and statistical analysis</title>
      <p id="p0230">Confusion matrix and total accuracy of deep learning model were provided by autoBioSeqpy. Heat maps, bar charts, 3D bar charts, line plots and matrix bubbles were generated using the Hiplot software.<xref rid="bib45" ref-type="bibr"><sup>45</sup></xref> Generation of UMAPs were performed using the command-line commands detailed above.</p>
    </sec>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sref1">
        <person-group person-group-type="author">
          <name>
            <surname>Alipanahi</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Delong</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Weirauch</surname>
            <given-names>M.T.</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>B.J.</given-names>
          </name>
        </person-group>
        <article-title>Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>33</volume>
        <year>2015</year>
        <fpage>831</fpage>
        <lpage>838</lpage>
        <pub-id pub-id-type="pmid">26213851</pub-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Jumper</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Evans</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Pritzel</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Figurnov</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Ronneberger</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Tunyasuvunakool</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Bates</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Žídek</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Potapenko</surname>
            <given-names>A.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>
        <source>Nature</source>
        <volume>596</volume>
        <year>2021</year>
        <fpage>583</fpage>
        <lpage>589</lpage>
        <pub-id pub-id-type="pmid">34265844</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Gómez-de-Mariscal</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>García-López-de-Haro</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Ouyang</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Donati</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Unser</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Muñoz-Barrutia</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sage</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>DeepImageJ: a user-friendly environment to run deep learning models in ImageJ</article-title>
        <source>Nat. Methods</source>
        <volume>18</volume>
        <year>2021</year>
        <fpage>1192</fpage>
        <lpage>1195</lpage>
        <pub-id pub-id-type="pmid">34594030</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Avsec</surname>
            <given-names>Ž.</given-names>
          </name>
          <name>
            <surname>Kreuzhuber</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Israeli</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Shrikumar</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Banerjee</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>D.S.</given-names>
          </name>
          <name>
            <surname>Beier</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Urban</surname>
            <given-names>L.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The Kipoi repository accelerates community exchange and reuse of predictive models for genomics</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>37</volume>
        <year>2019</year>
        <fpage>592</fpage>
        <lpage>600</lpage>
        <pub-id pub-id-type="pmid">31138913</pub-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Movva</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Greenside</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Marinov</surname>
            <given-names>G.K.</given-names>
          </name>
          <name>
            <surname>Nair</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Shrikumar</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kundaje</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Deciphering regulatory DNA sequences and noncoding genetic variants using neural network models of massively parallel reporter assays</article-title>
        <source>PLoS One</source>
        <volume>14</volume>
        <year>2019</year>
        <fpage>e0218073</fpage>
        <pub-id pub-id-type="pmid">31206543</pub-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sref6">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>K.M.</given-names>
          </name>
          <name>
            <surname>Cofer</surname>
            <given-names>E.M.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Troyanskaya</surname>
            <given-names>O.G.</given-names>
          </name>
        </person-group>
        <article-title>Selene: a PyTorch-based deep learning library for sequence data</article-title>
        <source>Nat. Methods</source>
        <volume>16</volume>
        <year>2019</year>
        <fpage>315</fpage>
        <lpage>318</lpage>
        <pub-id pub-id-type="pmid">30923381</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sref7">
        <person-group person-group-type="author">
          <name>
            <surname>Budach</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Marsico</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Pysster: classification of biological sequences by learning sequence and structure motifs with convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <volume>34</volume>
        <year>2018</year>
        <fpage>3035</fpage>
        <lpage>3037</lpage>
        <pub-id pub-id-type="pmid">29659719</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>Szalkai</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Grolmusz</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>SECLAF: a webserver and deep neural network design tool for hierarchical biological sequence classification</article-title>
        <source>Bioinformatics</source>
        <volume>34</volume>
        <year>2018</year>
        <fpage>2487</fpage>
        <lpage>2489</lpage>
        <pub-id pub-id-type="pmid">29490010</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sref9">
        <person-group person-group-type="author">
          <name>
            <surname>Kopp</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Monti</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Tamburrini</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Ohler</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Akalin</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for genomics using Janggu</article-title>
        <source>Nat. Commun.</source>
        <volume>11</volume>
        <year>2020</year>
        <fpage>3488</fpage>
        <pub-id pub-id-type="pmid">32661261</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sref10">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H.-L.</given-names>
          </name>
          <name>
            <surname>Pang</surname>
            <given-names>Y.-H.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>BioSeq-BLM: a platform for analyzing DNA, RNA and protein sequences based on biological language models</article-title>
        <source>Nucleic Acids Res.</source>
        <volume>49</volume>
        <year>2021</year>
        <fpage>e129</fpage>
        <pub-id pub-id-type="pmid">34581805</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sref11">
        <person-group person-group-type="author">
          <name>
            <surname>Jing</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Xue</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>autoBioSeqpy: a deep learning tool for the classification of biological sequences</article-title>
        <source>J. Chem. Inf. Model.</source>
        <volume>60</volume>
        <year>2020</year>
        <fpage>3755</fpage>
        <lpage>3764</lpage>
        <pub-id pub-id-type="pmid">32786512</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sref12">
        <person-group person-group-type="author">
          <name>
            <surname>Cock</surname>
            <given-names>P.J.A.</given-names>
          </name>
          <name>
            <surname>Antao</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>J.T.</given-names>
          </name>
          <name>
            <surname>Chapman</surname>
            <given-names>B.A.</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>C.J.</given-names>
          </name>
          <name>
            <surname>Dalke</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Friedberg</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Hamelryck</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Kauff</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Wilczynski</surname>
            <given-names>B.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Biopython: freely available Python tools for computational molecular biology and bioinformatics</article-title>
        <source>Bioinformatics</source>
        <volume>25</volume>
        <year>2009</year>
        <fpage>1422</fpage>
        <lpage>1423</lpage>
        <pub-id pub-id-type="pmid">19304878</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="other" id="sref13">
        <person-group person-group-type="author">
          <name>
            <surname>Chollet</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Keras: the Python deep learning API [WWW Document]</article-title>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras" id="intref0080">https://github.com/fchollet/keras</ext-link>
        <year>2015</year>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sref14">
        <person-group person-group-type="author">
          <name>
            <surname>Paszke</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Gross</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Massa</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Lerer</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bradbury</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Chanan</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Killeen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Gimelshein</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Antiga</surname>
            <given-names>L.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Pytorch: an imperative style, high-performance deep learning library</article-title>
        <comment>Preprint at</comment>
        <source>arXiv</source>
        <year>2019</year>
        <pub-id pub-id-type="doi">10.48550/arXiv.1912.01703</pub-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sref15">
        <person-group person-group-type="author">
          <name>
            <surname>Montavon</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Samek</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>K.R.</given-names>
          </name>
        </person-group>
        <article-title>Methods for interpreting and understanding deep neural networks</article-title>
        <source>Digit. Signal Process.</source>
        <volume>73</volume>
        <year>2018</year>
        <fpage>1</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sref16">
        <person-group person-group-type="author">
          <name>
            <surname>McInnes</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Healy</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Melville</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Umap: uniform manifold approximation and projection for dimension reduction</article-title>
        <comment>Preprint at</comment>
        <source>arXiv</source>
        <year>2018</year>
        <pub-id pub-id-type="doi">10.48550/arXiv.1802.03426</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sref17">
        <person-group person-group-type="author">
          <name>
            <surname>Van der Maaten</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Visualizing data using t-SNE</article-title>
        <source>J.Mach.Learn.Res.</source>
        <volume>9</volume>
        <year>2008</year>
        <fpage>2579</fpage>
        <lpage>2605</lpage>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sref18">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>N.Q.K.</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>Q.-T.</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>T.-T.-D.</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y.-Y.</given-names>
          </name>
        </person-group>
        <article-title>A transformer architecture based on BERT and 2D convolutional neural network to identify DNA enhancers from sequence information</article-title>
        <source>Brief. Bioinform.</source>
        <volume>22</volume>
        <year>2021</year>
        <fpage>bbab005</fpage>
        <pub-id pub-id-type="pmid">33539511</pub-id>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="journal" id="sref19">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>J.X.</given-names>
          </name>
          <name>
            <surname>Yordanov</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Gaunt</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M.X.</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y.-J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>J.Z.</given-names>
          </name>
          <name>
            <surname>Dalchau</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A deep learning model for predicting next-generation sequencing depth from DNA sequence</article-title>
        <source>Nat. Commun.</source>
        <volume>12</volume>
        <year>2021</year>
        <fpage>4387</fpage>
        <pub-id pub-id-type="pmid">34282137</pub-id>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sref20">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>N.Q.K.</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>Q.-T.</given-names>
          </name>
        </person-group>
        <article-title>Deep transformers and convolutional neural network in identifying DNA N6-methyladenine sites in cross-species genomes</article-title>
        <source>Methods</source>
        <volume>204</volume>
        <year>2022</year>
        <fpage>199</fpage>
        <lpage>206</lpage>
        <pub-id pub-id-type="pmid">34915158</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sref21">
        <person-group person-group-type="author">
          <name>
            <surname>Amin</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>McGrath</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Y.-P.P.</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of deep learning in non-coding RNA classification</article-title>
        <source>Nat. Mach. Intell.</source>
        <volume>1</volume>
        <year>2019</year>
        <fpage>246</fpage>
        <lpage>256</lpage>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sref22">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Jing</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Multi-models in predicting RNA solvent accessibility exhibit the contribution from none-sequential attributes and providing a globally stable modeling strategy</article-title>
        <source>Chemometr. Intell. Lab. Syst.</source>
        <volume>205</volume>
        <year>2020</year>
        <fpage>104100</fpage>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sref23">
        <person-group person-group-type="author">
          <name>
            <surname>Tng</surname>
            <given-names>S.S.</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>N.Q.K.</given-names>
          </name>
          <name>
            <surname>Yeh</surname>
            <given-names>H.-Y.</given-names>
          </name>
          <name>
            <surname>Chua</surname>
            <given-names>M.C.H.</given-names>
          </name>
        </person-group>
        <article-title>Improved prediction model of protein lysine Crotonylation sites using bidirectional recurrent neural networks</article-title>
        <source>J. Proteome Res.</source>
        <volume>21</volume>
        <year>2021</year>
        <fpage>265</fpage>
        <lpage>273</lpage>
        <pub-id pub-id-type="pmid">34812044</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sref24">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Xue</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Jing</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J.L.</given-names>
          </name>
        </person-group>
        <article-title>The applications of deep learning algorithms on in silico druggable proteins identification</article-title>
        <source>J. Adv. Res.</source>
        <volume>41</volume>
        <year>2022</year>
        <fpage>219</fpage>
        <lpage>231</lpage>
        <pub-id pub-id-type="pmid">36328750</pub-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sref25">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Jing</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>DeepT3_4: a hybrid deep neural network model for the distinction between bacterial type III and IV secreted effectors</article-title>
        <source>Front. Microbiol.</source>
        <volume>12</volume>
        <year>2021</year>
        <fpage>605782</fpage>
        <pub-id pub-id-type="pmid">33552038</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sref26">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Pu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>In silico identification of Gram-negative bacterial secreted proteins from primary sequence</article-title>
        <source>Comput. Biol. Med.</source>
        <volume>43</volume>
        <year>2013</year>
        <fpage>1177</fpage>
        <lpage>1181</lpage>
        <pub-id pub-id-type="pmid">23930811</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sref27">
        <person-group person-group-type="author">
          <name>
            <surname>Abdelaal</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Michielsen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Cats</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Hoogduin</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Mei</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Reinders</surname>
            <given-names>M.J.T.</given-names>
          </name>
          <name>
            <surname>Mahfouz</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>A comparison of automatic cell identification methods for single-cell RNA sequencing data</article-title>
        <source>Genome Biol.</source>
        <volume>20</volume>
        <year>2019</year>
        <fpage>194</fpage>
        <pub-id pub-id-type="pmid">31500660</pub-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sref28">
        <person-group person-group-type="author">
          <name>
            <surname>Hicks</surname>
            <given-names>S.W.</given-names>
          </name>
          <name>
            <surname>Charron</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Hang</surname>
            <given-names>H.C.</given-names>
          </name>
          <name>
            <surname>Galán</surname>
            <given-names>J.E.</given-names>
          </name>
        </person-group>
        <article-title>Subcellular targeting of Salmonella virulence proteins by host-mediated S-palmitoylation</article-title>
        <source>Cell Host Microbe</source>
        <volume>10</volume>
        <year>2011</year>
        <fpage>9</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="pmid">21767808</pub-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="journal" id="sref29">
        <person-group person-group-type="author">
          <name>
            <surname>Desvaux</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Hébraud</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Talon</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Henderson</surname>
            <given-names>I.R.</given-names>
          </name>
        </person-group>
        <article-title>Secretion and subcellular localizations of bacterial proteins: a semantic awareness issue</article-title>
        <source>Trends Microbiol.</source>
        <volume>17</volume>
        <year>2009</year>
        <fpage>139</fpage>
        <lpage>145</lpage>
        <pub-id pub-id-type="pmid">19299134</pub-id>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sref30">
        <person-group person-group-type="author">
          <name>
            <surname>Lasica</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Ksiazek</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Madej</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Potempa</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>The type IX secretion system (T9SS): highlights and recent insights into its structure and function</article-title>
        <source>Front. Cell. Infect. Microbiol.</source>
        <volume>7</volume>
        <year>2017</year>
        <fpage>215</fpage>
        <pub-id pub-id-type="pmid">28603700</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sref31">
        <person-group person-group-type="author">
          <name>
            <surname>Bairoch</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Apweiler</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>The SWISS-PROT protein sequence data bank and its supplement TrEMBL in 1999</article-title>
        <source>Nucleic Acids Res.</source>
        <volume>27</volume>
        <year>1999</year>
        <fpage>49</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="pmid">9847139</pub-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sref32">
        <person-group person-group-type="author">
          <collab>The UniProt Consortium</collab>
        </person-group>
        <article-title>The universal protein resource (UniProt)</article-title>
        <source>Nucleic Acids Res.</source>
        <volume>36</volume>
        <year>2007</year>
        <fpage>D190</fpage>
        <lpage>D195</lpage>
        <pub-id pub-id-type="pmid">18045787</pub-id>
      </element-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="journal" id="sref33">
        <person-group person-group-type="author">
          <name>
            <surname>Pruitt</surname>
            <given-names>K.D.</given-names>
          </name>
          <name>
            <surname>Tatusova</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Klimke</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Maglott</surname>
            <given-names>D.R.</given-names>
          </name>
        </person-group>
        <article-title>NCBI Reference Sequences: current status, policy and new initiatives</article-title>
        <source>Nucleic Acids Res.</source>
        <volume>37</volume>
        <year>2009</year>
        <fpage>D32</fpage>
        <lpage>D36</lpage>
        <pub-id pub-id-type="pmid">18927115</pub-id>
      </element-citation>
    </ref>
    <ref id="bib34">
      <label>34</label>
      <element-citation publication-type="journal" id="sref34">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>S.F.</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>T.L.</given-names>
          </name>
          <name>
            <surname>Schäffer</surname>
            <given-names>A.A.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Lipman</surname>
            <given-names>D.J.</given-names>
          </name>
        </person-group>
        <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>
        <source>Nucleic Acids Res.</source>
        <volume>25</volume>
        <year>1997</year>
        <fpage>3389</fpage>
        <lpage>3402</lpage>
        <pub-id pub-id-type="pmid">9254694</pub-id>
      </element-citation>
    </ref>
    <ref id="bib35">
      <label>35</label>
      <element-citation publication-type="journal" id="sref35">
        <person-group person-group-type="author">
          <name>
            <surname>Trieu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Martinez-Fundichely</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Khurana</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>DeepMILO: a deep learning approach to predict the impact of non-coding sequence variants on 3D chromatin structure</article-title>
        <source>Genome Biol.</source>
        <volume>21</volume>
        <year>2020</year>
        <fpage>79</fpage>
        <pub-id pub-id-type="pmid">32216817</pub-id>
      </element-citation>
    </ref>
    <ref id="bib36">
      <label>36</label>
      <element-citation publication-type="journal" id="sref36">
        <person-group person-group-type="author">
          <name>
            <surname>Alley</surname>
            <given-names>E.C.</given-names>
          </name>
          <name>
            <surname>Khimulya</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Biswas</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>AlQuraishi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Church</surname>
            <given-names>G.M.</given-names>
          </name>
        </person-group>
        <article-title>Unified rational protein engineering with sequence-based deep representation learning</article-title>
        <source>Nat. Methods</source>
        <volume>16</volume>
        <year>2019</year>
        <fpage>1315</fpage>
        <lpage>1322</lpage>
        <pub-id pub-id-type="pmid">31636460</pub-id>
      </element-citation>
    </ref>
    <ref id="bib37">
      <label>37</label>
      <element-citation publication-type="journal" id="sref37">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>K.E.</given-names>
          </name>
          <name>
            <surname>Fazal</surname>
            <given-names>F.M.</given-names>
          </name>
          <name>
            <surname>Parker</surname>
            <given-names>K.R.</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>H.Y.</given-names>
          </name>
        </person-group>
        <article-title>RNA-GPS predicts SARS-CoV-2 RNA residency to host mitochondria and nucleolus</article-title>
        <source>Cell Syst.</source>
        <volume>11</volume>
        <year>2020</year>
        <fpage>102</fpage>
        <lpage>108.e3</lpage>
        <pub-id pub-id-type="pmid">32673562</pub-id>
      </element-citation>
    </ref>
    <ref id="bib38">
      <label>38</label>
      <element-citation publication-type="journal" id="sref38">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Adiconis</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Simmons</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Kowalczyk</surname>
            <given-names>M.S.</given-names>
          </name>
          <name>
            <surname>Hession</surname>
            <given-names>C.C.</given-names>
          </name>
          <name>
            <surname>Marjanovic</surname>
            <given-names>N.D.</given-names>
          </name>
          <name>
            <surname>Hughes</surname>
            <given-names>T.K.</given-names>
          </name>
          <name>
            <surname>Wadsworth</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Burks</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>L.T.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic comparison of single-cell and single-nucleus RNA-sequencing methods</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>38</volume>
        <year>2020</year>
        <fpage>737</fpage>
        <lpage>746</lpage>
        <pub-id pub-id-type="pmid">32341560</pub-id>
      </element-citation>
    </ref>
    <ref id="bib39">
      <label>39</label>
      <element-citation publication-type="journal" id="sref39">
        <person-group person-group-type="author">
          <name>
            <surname>Miao</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Moreno</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Papatheodorou</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Brazma</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Teichmann</surname>
            <given-names>S.A.</given-names>
          </name>
        </person-group>
        <article-title>Putative cell type discovery from single-cell gene expression data</article-title>
        <source>Nat. Methods</source>
        <volume>17</volume>
        <year>2020</year>
        <fpage>621</fpage>
        <lpage>628</lpage>
        <pub-id pub-id-type="pmid">32424270</pub-id>
      </element-citation>
    </ref>
    <ref id="bib40">
      <label>40</label>
      <element-citation publication-type="journal" id="sref40">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Spielmann</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ibrahim</surname>
            <given-names>D.M.</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Mundlos</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Christiansen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Steemers</surname>
            <given-names>F.J.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The single-cell transcriptional landscape of mammalian organogenesis</article-title>
        <source>Nature</source>
        <volume>566</volume>
        <year>2019</year>
        <fpage>496</fpage>
        <lpage>502</lpage>
        <pub-id pub-id-type="pmid">30787437</pub-id>
      </element-citation>
    </ref>
    <ref id="bib41">
      <label>41</label>
      <element-citation publication-type="journal" id="sref41">
        <person-group person-group-type="author">
          <name>
            <surname>Regev</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Teichmann</surname>
            <given-names>S.A.</given-names>
          </name>
          <name>
            <surname>Lander</surname>
            <given-names>E.S.</given-names>
          </name>
          <name>
            <surname>Amit</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Benoist</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Birney</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Bodenmiller</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Carninci</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Clatworthy</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Science forum: the human cell atlas</article-title>
        <source>Elife</source>
        <volume>6</volume>
        <year>2017</year>
        <fpage>e27041</fpage>
        <pub-id pub-id-type="pmid">29206104</pub-id>
      </element-citation>
    </ref>
    <ref id="bib42">
      <label>42</label>
      <element-citation publication-type="journal" id="sref42">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Lyu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Susztak</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Iterative transfer learning with neural network for clustering and cell type classification in single-cell RNA-seq analysis</article-title>
        <source>Nat. Mach. Intell.</source>
        <volume>2</volume>
        <year>2020</year>
        <fpage>607</fpage>
        <lpage>618</lpage>
        <pub-id pub-id-type="pmid">33817554</pub-id>
      </element-citation>
    </ref>
    <ref id="bib43">
      <label>43</label>
      <element-citation publication-type="journal" id="sref43">
        <person-group person-group-type="author">
          <name>
            <surname>Haghverdi</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Lun</surname>
            <given-names>A.T.L.</given-names>
          </name>
          <name>
            <surname>Morgan</surname>
            <given-names>M.D.</given-names>
          </name>
          <name>
            <surname>Marioni</surname>
            <given-names>J.C.</given-names>
          </name>
        </person-group>
        <article-title>Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>36</volume>
        <year>2018</year>
        <fpage>421</fpage>
        <lpage>427</lpage>
        <pub-id pub-id-type="pmid">29608177</pub-id>
      </element-citation>
    </ref>
    <ref id="bib44">
      <label>44</label>
      <element-citation publication-type="book" id="sref44">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <part-title>Deep residual learning for image recognition</part-title>
        <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>
        <year>2016</year>
        <fpage>770</fpage>
        <lpage>778</lpage>
      </element-citation>
    </ref>
    <ref id="bib45">
      <label>45</label>
      <element-citation publication-type="journal" id="sref45">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Miao</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Si</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lou</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Bao</surname>
            <given-names>Z.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Hiplot: a comprehensive and easy-to-use web service for boosting publication-ready biomedical data visualization</article-title>
        <source>Brief. Bioinform.</source>
        <volume>23</volume>
        <year>2022</year>
        <fpage>bbac261</fpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbac261</pub-id>
        <pub-id pub-id-type="pmid">35788820</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="appsec2" sec-type="supplementary-material">
    <title>Supplemental information</title>
    <p id="p0260">
      <supplementary-material content-type="local-data" id="mmc1">
        <caption>
          <title>Document S1. Figures S1 and S2</title>
        </caption>
        <media xlink:href="mmc1.pdf"/>
      </supplementary-material>
    </p>
  </sec>
  <sec sec-type="data-availability" id="da0010">
    <title>Data and code availability</title>
    <p id="p0025">
      <list list-type="simple" id="ulist0015">
        <list-item id="u0025">
          <label>•</label>
          <p id="p0030">This paper analyses existing, publicly available data. Accession numbers are listed in the <xref rid="sec4.1" ref-type="sec">key resources table</xref>, and the weblinks are <ext-link ext-link-type="uri" xlink:href="http://cic.scu.edu.cn/bioinformatics/secretPv2_1/index.htm" id="intref0010">http://cic.scu.edu.cn/bioinformatics/secretPv2_1/index.htm</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/3357167" id="intref0015">https://zenodo.org/record/3357167</ext-link>.</p>
        </list-item>
        <list-item id="u0030">
          <label>•</label>
          <p id="p0035">The current version of layerUMAP is implemented in python and can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/jingry/autoBioSeqpy/blob/2.0/tool/layerUMAP.py" id="intref0020">https://github.com/jingry/autoBioSeqpy/blob/2.0/tool/layerUMAP.py</ext-link>. All deep learning models and commands for the case studies were integrated as a compressed file at <ext-link ext-link-type="uri" xlink:href="https://github.com/jingry/autoBioSeqpy/blob/2.0/examples/layerUMAP.zip" id="intref0025">https://github.com/jingry/autoBioSeqpy/blob/2.0/examples/layerUMAP.zip</ext-link>.</p>
        </list-item>
        <list-item id="u0035">
          <label>•</label>
          <p id="p0040">Any additional information required to reanalyze the data reported in this paper is available from the <xref rid="sec4.2.1" ref-type="sec">lead contact</xref> upon request.</p>
        </list-item>
      </list>
    </p>
  </sec>
  <ack id="ack0010">
    <title>Acknowledgments</title>
    <p id="p0235">This work has been supported by the <funding-source id="gs1">National Natural Science Foundation of China</funding-source> (No. 21803045 and No. 22173065), <funding-source id="gs2">Joint project of Luzhou Municipal People’s Government</funding-source> and Southwest Medical University (2020LZXNYDJ39), and <funding-source id="gs3"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100014895</institution-id><institution>Southwest Medical University Research Program</institution></institution-wrap></funding-source> (2020ZRQNB057). The numerical calculations in this paper have been done on Hefei advanced computing canter.</p>
    <sec id="sec5">
      <title>Author contributions</title>
      <p id="p0240">J.L. and L.Y conceived the study and wrote the manuscript. R.J. contributed to the design, implementation and testing of the tool. L.X. and J.L. performed the data analysis. All authors read and approved the final manuscript.</p>
    </sec>
    <sec sec-type="COI-statement" id="sec6">
      <title>Declaration of interests</title>
      <p id="p0245">The authors have declared no competing interests.</p>
    </sec>
    <sec sec-type="inclusion-and-diversity" id="sec7">
      <title>Inclusion and diversity</title>
      <p id="p0250">We support inclusive, diverse, and equitable conduct of research.</p>
    </sec>
  </ack>
  <fn-group>
    <fn id="appsec1" fn-type="supplementary-material">
      <p id="p0255">Supplemental information can be found online at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.isci.2022.105530" id="intref0075">https://doi.org/10.1016/j.isci.2022.105530</ext-link>.</p>
    </fn>
  </fn-group>
</back>
