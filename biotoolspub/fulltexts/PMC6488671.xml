<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6488671</article-id>
    <article-id pub-id-type="publisher-id">42966</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-019-42966-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SPARK-MSNA: Efficient algorithm on Apache Spark for aligning multiple similar DNA/RNA sequences with supervised learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6445-7833</contrib-id>
        <name>
          <surname>Vineetha</surname>
          <given-names>V.</given-names>
        </name>
        <address>
          <email>vineevishnu@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Biji</surname>
          <given-names>C. L.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nair</surname>
          <given-names>Achuthsankar S.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2179 5111</institution-id><institution-id institution-id-type="GRID">grid.413002.4</institution-id><institution>Department of Computational Biology and Bioinformatics, </institution><institution>University of Kerala, </institution></institution-wrap>Thiruvananthapuram, Kerala India </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>4</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>29</day>
      <month>4</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>9</volume>
    <elocation-id>6631</elocation-id>
    <history>
      <date date-type="received">
        <day>4</day>
        <month>7</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>4</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Multiple sequence alignment (MSA) is an integral part of molecular biology. But handling massive number of large sequences is still a bottleneck for most of the state-of-the-art software tools. Knowledge driven algorithms utilizing features of input sequences, such as high similarity in case of DNA sequences, can help in improving the efficiency of DNA MSA to assist in phylogenetic tree construction, comparative genomics etc. This article showcases the benefit of utilizing similarity features while performing the alignment. The algorithm uses suffix tree for identifying common substrings and uses a modified Needleman-Wunsch algorithm for pairwise alignments. In order to improve the efficiency of pairwise alignments, a knowledge base is created and a supervised learning with nearest neighbor algorithm is used to guide the alignment. The algorithm provided linear complexity <italic>O(m)</italic> compared to <italic>O</italic>(<italic>m</italic><sup>2</sup>). Comparing with state-of-the-art algorithms (e.g., HAlign II), SPARK-MSNA provided 50% improvement in memory utilization in processing human mitochondrial genome (mt. genomes, 100x, 1.1. GB) with a better alignment accuracy in terms of average SP score and comparable execution time. The algorithm is implemented on big data framework Apache Spark in order to improve the scalability. The source code &amp; test data are available at: <ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/spark-msna/">https://sourceforge.net/projects/spark-msna/</ext-link>.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Data mining</kwd>
      <kwd>Software</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par2">Sequence alignment is used in bioinformatics to identify degree of similarity between biological sequences (DNA, RNA or protein), in understanding functional, structural and evolutionary relationship between them. Sequence alignment is of vital importance in molecular biology for studies involving molecular function prediction, evolutionary tree reconstruction and disease analysis. Needleman-Wunsch(NW) algorithm<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, was one of the first implementations of dynamic programming in bioinformatics. It was an optimal sequence alignment algorithm with a tradeoff in computational time and space. For two sequences of length m and n, the time and space complexity is computed as <italic>O</italic>(<italic>m</italic> <italic>*</italic> <italic>n</italic>). By expanding the same algorithm for multiple sequence alignment (MSA), the complexity rises exponentially (<italic>O</italic>(<italic>m</italic><sup><italic>n</italic></sup>) for <italic>n</italic> sequences of length <italic>m</italic>). Because of this high computational cost involved, NW algorithm cannot be used in multiple sequence alignment especially for large number of long sequences. Most popular implementations of MSA such as CLUSTAL<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>, MAFFT<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, MUSCLE<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> use approximation methods such as progressive and iterative approaches for faster execution and less memory utilization. Most of the algorithms implemented so far were derivatives of NW algorithm.</p>
    <p id="Par3">The improvements in DNA sequencing technology has led to an unprecedented increase in the amount of DNA and genome data being available for studies. Therefore, it is important to improve the scalability and performance of MSA tools. Cloud computing and the recently emerged big data technologies such as the new programming paradigm called MapReduce<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, are effective ways to process huge volume of data of the order of petabytes and more. Implementation using big data frameworks for sequence alignment/mapping were reported in the literature for instance, Sadasivam <italic>et al</italic>., 2010<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> presented a Hadoop based implementation of MSA using NW algorithm and Zhao <italic>et al</italic>., 2015<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> presented Spark based implementation of local alignment.</p>
    <p id="Par4">Most of these research focused on improving the scalability of MSA using Big data frameworks, but not much research has happened in improving the MSA technique as such. These implementations are able to support large set of input sequences, but when it comes to massive DNA sequences, they are either unable to support or execute slowly when the count of sequences increase beyond 100. DNA sequences are highly similar compared to protein sequences. This similarity feature can be utilized to improve the alignment, and enable algorithm to tackle the volume and achieve better performance. Q. Zou <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> developed an algorithm which is proven to be highly efficient in performing MSA of similar DNA/RNA sequences. The algorithm uses centre star strategy along with trie tree data structure to improve the performance. Spark version of this algorithm HAlign II<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, to support large volume of sequences reported promising results for similar DNA/RNA sequence alignment. MASC (Multiple Sequence Alignment Based on a Suffix Tree and Center-Star Strategy) is the implementation of same algorithm on CUDA architecture to obtain much faster performance for ultra large data sets<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. PASTASPARK<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> is another prominent implementation of MSA on Spark framework, which performs alignment based on SATé (Simultaneous Alignment and Tree estimation) and transitivity.</p>
    <p id="Par5">MSA could be further enhanced with a bounded dynamic programming algorithm<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> at the pairwise alignment level. DDGARM, an improved NW algorithm<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> for pairwise alignment has proved that, for highly similar sequences, optimal alignment can be achieved by filling only 10% of the matrix. Our algorithm uses the concept of Q. Zou <italic>et al</italic>., on progressive alignment, with modified NW algorithm for improved pairwise alignment. Key characteristics of the proposed algorithm include, (a) Suffix tree data structure for storing input sequences and identifying common substrings between sequences, (b) A knowledge base and nearest neighbor learning layer to guide the pairwise alignment, (c) Modified Needleman-Wunsch algorithm to perform pairwise alignments at each stage in order to reduce the memory and execution time of alignments and (d) Parallelization using MapReduce method for suffix tree construction and pairwise alignment to further improve the execution time.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Progressive Alignment</title>
      <p id="Par6">Progressive method is one of the basic alignment strategies used for MSA. It is known to provide reasonably good result and is the most widely used heuristic method for MSA<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Hence it is chosen as the core of our algorithm. The basic flow of progressive strategy is to prepare a guide tree and use series of pairwise alignments to align the sequences based on the branching order in the guide tree. The guide tree is formed based on the pairwise distance of sequences. Guide tree is formed in the order from shortest to longest distant pair. Initially the most closely related sequence pair is aligned and then the remaining sequences are aligned to the previous alignment until all sequences are aligned. Pairwise alignment is performed at each stage and it is refined at the final step while summing up the alignments. In the refinement step, the early gaps are revisited to adjust the penalties based on aligned sequences from other pairwise alignments. There are many MSA algorithms which uses modified forms of progressive methods<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Details about progressive alignment method along with pseudo code is given in Supplementary Material (Data <xref rid="MOESM1" ref-type="media">S2)</xref>.</p>
      <p id="Par7">The guide tree construction and pairwise alignment are the major contributors for the execution time and memory utilization in progressive alignment method. Use of data structure such as suffix tree which enables efficient storage and quick search of common substrings of the sequences help in improving the complexity of guide tree step. Similarly, the pairwise alignments are performed using the dynamic programming approach which becomes the most time consuming process when the sequences involved in the MSA are quite large. Bounded dynamic programming algorithm is used to enhance the performance of pairwise alignments.</p>
      <p id="Par8">From the suffix tree, common substrings can be rapidly extracted for highly similar DNA sequences. This leaves only the unmatched regions to be aligned. The modified pairwise alignment algorithm also provides substantial improvement in execution time and memory utilization as the similarity among the sequences increases.</p>
    </sec>
    <sec id="Sec4">
      <title>Suffix Trees to enhance alignment of similar sequences</title>
      <p id="Par9">Suffix trees greatly improve the performance of search on indexed string and hence are widely used in problems involving pattern matching, finding sub strings etc. Many existing alignment algorithms use suffix tree to identify matching substrings and there exists different algorithms for the construction of suffix tree<sup><xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR21">21</xref></sup>. Ukkonen suffix tree construction<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> is followed in the implementation as it is superior in terms of time and space complexity<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>.</p>
      <p id="Par10">Each input sequence is partitioned in to equal size segments and these segments are used to construct the suffix tree. Suffix tree is characterized by a root and each edge is labeled by the nucleotide in the sequence. For any node <italic>v</italic>, the string formed by concatenating the edge labels from root to <italic>v</italic> is the path to that node, <italic>path(v)</italic>. Suffix tree is known to provide optimal search time<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>, which means, identifying the node <italic>v</italic>, which is closest to the root for a given pattern P, such that P is a prefix of <italic>path(v)</italic> can be performed in time linear to the length of P. All leaves in the subtree of the node <italic>v</italic> then represent the occurrences of the pattern P in string S.</p>
      <p id="Par11">If there are <italic>n</italic> DNA sequences with an average length of <italic>m</italic>, the time complexity for building a suffix tree for one sequence is <italic>O</italic>(<italic>m</italic>) (Lines 2–3 in Algorithm 1). After constructing the suffix tree, search the suffix tree for each segment of every sequence pair to identify the common substrings and matching segments. Searching the <italic>n</italic> sequences in the suffix tree costs <italic>O</italic>(<italic>nm</italic>) (Lines 5–7 in Algorithm 1). For the unmatched segments, record the percentage identity and difference in length if any. Since the sequences are partitioned to equal size segments, only the last segment of every sequence will be having different length. Only the unmatched segments are considered for pairwise alignments and the features ie; percentage identity and difference in length are used to extract learning from knowledge base. The guide tree for performing pairwise alignments are formed based on the similarity measure extracted for each sequence pair.</p>
    </sec>
    <sec id="Sec5">
      <title>Modified N-W algorithm for pairwise alignment</title>
      <p id="Par12">Our previous research had proved that, for pairwise alignments, optimal alignment can be achieved by populating only limited number of diagonals of the matrix<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. The number of diagonals to be filled to obtain optimal alignment is not fixed in all cases. Hence, there is a need to find the minimum number of diagonals to be filled as a pre-requisite. This is done using dot plot approach. With some modifications to the dotlet<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> algorithm, the number of diagonals to be filled can be obtained. Test results have proved that the similarity between sequences and the number of diagonals to be filled are inversely proportional. According to our previous research<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, sequences with % identity (more than 50%) and difference in length (less than 25%) are reported to get a 50% improvement in memory utilization and execution time in pairwise alignments.</p>
      <p id="Par13">In our approach, pairwise alignment is performed only for the unmatched segments. As the similarity between sequences increases, the number of segments to be aligned reduces. The modified alignment algorithm further reduces the complexity as similarity increases. The most distant segment pair from the input sequences are chosen to identify the number of diagonals to be filled. This improves the execution time and at the same time ensures that all pairwise alignments provide optimal alignment as it would be the highest of diagonals count for the given input set. Even though this step involves only one pairwise alignment, this could become costly for very large sequences. Hence, a knowledge base is built with training data and a learning layer with nearest neighbor algorithm is used to extract knowledge out of knowledge base. With more learnings, the knowledge base becomes more accurate and would result in faster learning.</p>
      <p id="Par14">In the traditional dynamic programming based pairwise alignment, the complexity is <italic>O</italic>(<italic>m</italic><sup>2</sup>)for sequence segments having length <italic>m</italic>. In our modified alignment approach, the complexity reduces to <italic>O</italic>(<italic>m</italic> <italic>*</italic> <italic>k</italic>) + <italic>O</italic>(2<italic>m</italic> <italic>*</italic> <italic>d</italic>), where k is the difference in length and d is the number of diagonals filled. In case of highly similar sequences, <italic>k</italic> → 0 and <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d\ll m$$\end{document}</tex-math><mml:math id="M2"><mml:mi>d</mml:mi><mml:mo>≪</mml:mo><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41598_2019_42966_Article_IEq1.gif"/></alternatives></inline-formula>, hence the complexity becomes <italic>O</italic>(<italic>m</italic>) compared to <italic>O</italic>(<italic>m</italic><sup>2</sup>) in the case of traditional dynamic programming approach where we fill the entire matrix. The worst case complexity would be <italic>O</italic>(<italic>m</italic><sup>2</sup>) as 2<italic>m</italic> <italic>*</italic> <italic>d</italic> becomes equal to <italic>m</italic><sup>2</sup>, when the similarity between sequences decreases.<fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>(Main flow):</p></caption><graphic position="anchor" xlink:href="41598_2019_42966_Figa_HTML" id="d29e532"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>Supervised learning layer</title>
      <p id="Par15">Bounded dynamic programming for pairwise alignment is the key in our approach to achieve better performance. From the experiment results<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, it is known that the number of diagonals to be filled depends on the similarity level and difference in length. Prior knowledge about the number of diagonals to be filled is a pre-requisite for the pairwise alignment step. Using training dataset, a knowledge base is built with the mapping of sequence similarity to number of diagonals. Sequence similarity measure (percentage identify and difference in length) for the most distant segments are used for extracting the knowledge from knowledge base. Nearest neighbor algorithm is used to identify the best matching entry from the knowledge base<sup><xref ref-type="bibr" rid="CR25">25</xref>,<xref ref-type="bibr" rid="CR26">26</xref></sup>. Less number of dimensions (percentage identity and length difference) for pattern recognition was the driving behind selecting nearest neighbor as the learning algorithm. More details about nearest neighbor algorithm is given in Supplementary Material (Data <xref rid="MOESM1" ref-type="media">S3)</xref>.<fig position="anchor" id="Figb"><label>Algorithm 2</label><caption><p>(Knowledge Base creation/learning).</p></caption><graphic position="anchor" xlink:href="41598_2019_42966_Figb_HTML" id="d29e560"/></fig><fig position="anchor" id="Figc"><label>Algorithm 3</label><caption><p>(Nearest Neighbor).</p></caption><graphic position="anchor" xlink:href="41598_2019_42966_Figc_HTML" id="d29e569"/></fig></p>
      <p id="Par16">The learning layer uses percentage identity and length difference as the features for classifying the input sequences. For each sequence pair, these features are extracted and the combination of highest value for difference in length and lowest value for identity are chosen for an input dataset. Then, it is matched with the knowledge base to identify the closest set. The algorithm initially checks for the exact match and in case of absence of exact match checks for the closest match (within a range of ±(2–3)%). Count of diagonals will be fetched for this closest match and that will be used for the pairwise alignment in the progressive MSA. Each time a new set of features are encountered, for which a closest match does not exist in the knowledge base, dotlet algorithm is executed to identify the number of diagonals. This learning is then entered in to the knowledge base for future alignments. More entries in the knowledge base would improve the performance and accuracy of the alignment. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows the flow of the algorithm with sample data.<fig id="Fig1"><label>Figure 1</label><caption><p>Sample flow of SPARK-MSNA algorithm.</p></caption><graphic xlink:href="41598_2019_42966_Fig1_HTML" id="d29e583"/></fig></p>
    </sec>
    <sec id="Sec7">
      <title>Parallel implementation with Spark</title>
      <p id="Par17">Parallel computation is implemented using MapReduce model at two stages in the algorithm. The suffix tree construction and the pairwise alignment of progressive method. MapReduce can be implemented using Hadoop or Spark. Due to the additional improvement in time provided by spark with its in-memory computation, spark is chosen as the MapReduce framework<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. More details about MapReduce programming model is given in Supplementary Material (Data <xref rid="MOESM1" ref-type="media">S4)</xref>.</p>
      <p id="Par18">Although usage of suffix tree with Ukkonen’s algorithm results in linear time complexity, this could be costlier when sequences involved are quite large in size. Performance is further improved with parallel construction using MapReduce programming model<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. The suffix tree is partitioned vertically and each partition is constructed independently. The prefixes generated from the vertical partitioning forms the key and its starting positions form the value. This key-value pair is processed using the map task and subtrees are constructed in parallel by compute nodes. Suffix tree construction from the subtree is combined with the map tasks in order to reduce the overhead of shuffle and reduce. Algorithm 4A shows the flow for the map function of suffix tree construction.</p>
      <p id="Par19">The pairwise alignment stage checks for matched segments and the unmatched segments alone are then taken for pairwise alignment. Pairwise alignment of segments is then executed in parallel using MapReduce model. Name of the sequence with segment index is the key and the sequence segment is the value for this map phase. Each compute node then performs the pairwise alignment using the modified pairwise algorithm. Result is then passed in the form of key-value pair where key is the sequence name with segment index and value is the aligned sequence. Aligned sequence segments for one pair of sequences are combined with the map task to avoid the overhead of reduce task. Algorithm 4B shows the flow of the map function for pairwise alignment.<fig position="anchor" id="Figd"><label>Algorithm 4A</label><caption><p>(Map function for Suffix tree construction).</p></caption><graphic position="anchor" xlink:href="41598_2019_42966_Figd_HTML" id="d29e612"/></fig><fig position="anchor" id="Fige"><label>Algorithm 4B</label><caption><p>(Map function for pairwise alignment).</p></caption><graphic position="anchor" xlink:href="41598_2019_42966_Fige_HTML" id="d29e621"/></fig></p>
      <p id="Par20">Parallel execution does not improve the complexity of the algorithm but it helps in improving the execution time. When we have number of compute nodes equal to or more than the number of partitions to be processed, the execution time is equivalent to that of processing single partition plus an additional overhead for the reduce phase to construct the final result. In case the number of compute nodes are less, partition groups are formed and process the partition groups in parallel, for improved performance compared to sequential run. Spark framework reduces the network overhead by utilizing the data locality concept of MapReduce, but merging the scattered intermediate results to form the final result will always be there. But in case of large datasets, this additional overhead is much lower compared to the sequential execution or traditional distributed computing (OpenMP/MPI). Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the flow chart of the algorithm.<fig id="Fig2"><label>Figure 2</label><caption><p>Flow chart of SPARK-MSNA algorithm.</p></caption><graphic xlink:href="41598_2019_42966_Fig2_HTML" id="d29e635"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec8" sec-type="results">
    <title>Results and Discussion</title>
    <sec id="Sec9">
      <title>Test results on simulated data</title>
      <p id="Par21">Performance of the algorithm was tested using simulated data and couple of actual data sets. MSA algorithms supporting massive genome sequences are still in the evolving phase and hence there is a lack of benchmark dataset when it comes to large scale DNA MSA algorithms. The Balibase<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> dataset which is considered as the golden benchmark for MSA is more suitable for protein sequences and does not provide benchmark for large DNA sequences. Details about real-world applications of MSA involving large genome sequences are given in Supplementary Material (Data <xref rid="MOESM1" ref-type="media">S1)</xref>. Simulated data with different levels of similarity was used to test the effectiveness of the algorithm. Test data was created by taking a portion of the human mitochondrial genome (NC_012920.1) as first sequence and then creating the second sequence with some random modifications in the first sequence. The similarity between sequences were first tested with traditional NW algorithm for correctness. Sequence datasets were prepared with 95%, 70%, 45%, 35% and 20% similarity and fixed size of 3.75 MB with maximum length 6580 bp and minimum length 6560 bp. Training data with 50 datasets of varying similarity range was prepared to build the knowledge base. Table <xref rid="Tab1" ref-type="table">1</xref> shows the snapshot of the knowledge base created for the test data.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Sample knowledge base constructed for testing.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Difference in Length of sequences (%)</th><th>Similarity (%)</th><th>percentage of diagonals filled in the 2 × 2 matrix</th></tr></thead><tbody><tr><td>0.30</td><td>99.20</td><td>0.15</td></tr><tr><td>0.20</td><td>99.30</td><td>0.14</td></tr><tr><td>0.40</td><td>98.00</td><td>0.16</td></tr><tr><td>0.30</td><td>98.10</td><td>0.15</td></tr><tr><td>0.10</td><td>95.90</td><td>0.18</td></tr><tr><td>0.23</td><td>97.30</td><td>0.17</td></tr><tr><td>0.34</td><td>98.20</td><td>0.16</td></tr><tr><td>0.35</td><td>96.40</td><td>0.18</td></tr><tr><td>0.70</td><td>99.00</td><td>0.4</td></tr><tr><td>1.20</td><td>99.00</td><td>0.3</td></tr><tr><td>5.80</td><td>75.00</td><td>6.2</td></tr><tr><td>25</td><td>50.00</td><td>20</td></tr></tbody></table></table-wrap></p>
      <p id="Par22">Prepared datasets were used to test the algorithm and identify the relationship of performance with similarity level. Testing was performed with and without knowledge base. Whenever the learning layer failed to match input data with existing entries in knowledge base, the algorithm performs dot plot step to gain the knowledge and make an entry in knowledge base. Table <xref rid="Tab2" ref-type="table">2</xref> shows the result of testing with simulated data. The results indicate that the algorithm delivers better performance as similarity between the input sequences increases. Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the decrease in execution time as similarity among input sequences increases. This is because, the number of segments to be aligned and the diagonals to be filled for alignment reduces as the similarity increases. With the knowledge base, the execution time and memory utilization reduces further as we do not have to perform the modified dotlet alignment to find out the number of diagonals to be filled. With large sequence data, the reduction in time due to removal of dotlet alignment would be more significant.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Execution time taken by SPARK-MSNA for datasets with different similarity. Datasets were of equal size (3.75MB).</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Similarity (%)</th><th>Execution time (without knowledge base)</th><th>Execution time (with knowledge base)</th></tr></thead><tbody><tr><td>Dataset 1</td><td>95</td><td>1 min 11 sec</td><td>50 sec</td></tr><tr><td>Dataset 2</td><td>70</td><td>1 min 31 sec</td><td>1 min 4 sec</td></tr><tr><td>Dataset 3</td><td>45</td><td>1 min 47 sec</td><td>1 min 14 sec</td></tr><tr><td>Dataset 4</td><td>35</td><td>2 min 5 sec</td><td>1 min 29 sec</td></tr><tr><td>Dataset 5</td><td>20</td><td>2 min 43 sec</td><td>1 min 55 sec</td></tr></tbody></table></table-wrap><fig id="Fig3"><label>Figure 3</label><caption><p>Execution time of SPARK-MSNA decreases as similarity of input sequences increase.</p></caption><graphic xlink:href="41598_2019_42966_Fig3_HTML" id="d29e904"/></fig></p>
    </sec>
    <sec id="Sec10">
      <title>Comparison with other tools</title>
      <p id="Par23">Most of the MSA algorithms compare the test results with other commonly used tools/algorithms. Test results of SPARK-MSNA are compared with HAlign, HAlign II and PASTASPARK. MAFFT &amp; MUSCLE are used for comparing results of small data sets. Even though MASC has reported highly competitive performance in handling large volume of data, the underlying architectures are different for both implementations, as MASC is implemented on CUDA processor. The algorithms HAlign<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> and HAlign II<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> have reported considerable improvement in performance specifically in addressing large scale DNA sequence data and our work has been inspired from HAlign; so, we have used same datasets used by HAlign to test the performance of our algorithm – human mitochondrial genomes (mt genomes) and 16 s rRNA. Dataset from PASTASPARK 200k RNASim is also included in the test data.</p>
      <p id="Par24">The human mitochondrial genome dataset is a sample for highly similar dataset. The dataset contains 672 human mitochondrial genomes with maximum length 16579 bp and minimum length 16556 bp. The percentage identity is &gt;97% for this dataset. 200k RNASim dataset is used as dataset with moderate level of similarity with minimum sequence length as 748 and maximum sequence length as 1836. 16 s rRNA dataset is used for testing the performance on less similar sequence set. It has minimum length 807 bp and maximum length 1629 bp. Details of test datasets are provided in Table <xref rid="MOESM1" ref-type="media">S1</xref> of Supplementary Material. In order to compare results with other tools, tests are performed on single node cluster and multi node cluster. Spark cluster was set up on single node with 3.6 GHz 4 core CPU, 64 bit Ubuntu OS and 64 GB memory. In order to test the improvement due to parallel implementation, SPARK-MSNA was tested with more number of nodes. Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the execution time taken by SPARK-MSNA with 1, 2, 4, 8, 16 and 32 nodes. Large data sets of 1.4 GB and 3.4 GB are used for testing the improvement in execution time with number of nodes. Multi node cluster set up is used to compare performance with HAlign II. A cluster of 12 servers with intel Xeon E5-2620 processor with 8 cores and Spark 2.3.0 were used for the testing. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the speedup of execution time due to additional nodes and Fig. <xref rid="Fig6" ref-type="fig">6</xref> shows the weak scalability of the algorithm. Table <xref rid="MOESM1" ref-type="media">S2</xref> of Supplementary Material shows the test results of various algorithms using test datasets. Figure <xref rid="Fig7" ref-type="fig">7</xref> shows the performance comparison of SPARK-MSNA with HAlign, HAlign II and PASTASPARK. MAFFT &amp; MUSCLE had limitations in processing datasets of size more than 1 GB. Considering the high volume of genome sequence data generated by NGS techniques and the predicted transition to personalized and precision medicine, there is a pressing need on MSA tools/algorithms to support data sets of hundreds of GBs/TBs. SPARK-MSNA provided better optimum results with better memory utilization &amp; average SP score compared to HAlign II with slightly high execution time.<fig id="Fig4"><label>Figure 4</label><caption><p>Improvement in execution time of SPARK-MSNA with more number of nodes.</p></caption><graphic xlink:href="41598_2019_42966_Fig4_HTML" id="d29e947"/></fig><fig id="Fig5"><label>Figure 5</label><caption><p>Speedup in execution time due to additional compute nodes.</p></caption><graphic xlink:href="41598_2019_42966_Fig5_HTML" id="d29e956"/></fig><fig id="Fig6"><label>Figure 6</label><caption><p>Weak scalability of SPARK-MSNA.</p></caption><graphic xlink:href="41598_2019_42966_Fig6_HTML" id="d29e965"/></fig><fig id="Fig7"><label>Figure 7</label><caption><p>Performance comparison of SPARK-MSNA with other algorithms.</p></caption><graphic xlink:href="41598_2019_42966_Fig7_HTML" id="d29e974"/></fig></p>
      <p id="Par25">Average SP score is used for comparing the alignment accuracy. SP score is calculated as the number of pairs of residues correctly aligned. The score is calculated as<disp-formula id="Equa"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\Sigma }_{i=1}^{{M}_{r}}{S}_{i}\,/\,{\Sigma }_{i=1}^{{M}_{r}}{S}_{ri}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:msubsup><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mspace width=".25em"/></mml:mrow></mml:msub><mml:mspace width="-.25em"/><mml:mo>/</mml:mo><mml:mspace width="-.25em"/><mml:msubsup><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2019_42966_Article_Equa.gif" position="anchor"/></alternatives></disp-formula>where, M is the length of the sequence, <italic>M</italic><sub><italic>r</italic></sub> is the length of the reference sequence, <italic>S</italic><sub>i</sub> is the score of the <italic>i</italic>th column and <italic>S</italic><sub><italic>ri</italic></sub> is the score of <italic>i</italic>th column in reference sequence. <italic>S</italic><sub>i</sub> is calculated as normalized total score of column <italic>i</italic>, with pair value calculated as 2 if residues are aligned, 1 if one of the alignments has a gap and 0 otherwise. The test results show that SPARK-MSNA performs better in terms of memory utilization and accuracy, but has increased execution time compared to HAlign II. Progressive alignment and the refinement step increases the execution time, but that helps in achieving a better alignment. The reduced matrix alignment guided by knowledge base leads to reduction in memory utilization. MAFFT and MUSCLE provide better average SP score compared to SPARK-MSNA, but they are unable to handle large volume of dataset. MAFFT and MUSCLE failed to deal with datasets of size more than 1 GB. PASTASPARK is able to handle the large volume of data, but the execution time is much higher compared to HAlign II and SPARK-MSNA.</p>
      <p id="Par26">The modified Needleman-Wunsch algorithm for pairwise alignment of unmatched segments plays a crucial role in reducing the memory utilization for SPARK-MSNA. In the pairwise alignment step, HAlign II uses complete 2 × 2 matrix for alignment, whereas, SPARK-MSNA uses limited diagonals (approx. 2% of diagonals) to calculate the alignment. This modification provides up to 50% reduction in the memory utilized (depending on sequence similarity)<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. The trade-off is between execution time and alignment accuracy. SPARK-MSNA provides a better balance between the two by providing an optimum performance in terms of computational time and memory while retaining an average SP Score close to MAFFT.</p>
      <p id="Par27">The knowledge base guides the bounded dynamic programming for pairwise alignment. Hence, a rich knowledge base results in better performance and better accuracy. For highly similar sequences, the improvement is highly significant as very less number of matrix cells (diagonals) are included in the alignment. As the similarity decreases, the number of matrix cells needed in the alignment increases and for highly different sequences, complete matrix is needed in the alignment, which makes it similar to normal dynamic programming. This is evident in the test result of 16 s rRNA dataset, where the memory utilization is similar to that of HAlign II.</p>
      <p id="Par28">In order to test the efficiency of knowledge base, we added the knowledge base layer (training layer) to HAlign II and tested the same using mt. genome and 16 s rRNA datasets. Table <xref rid="MOESM1" ref-type="media">S3</xref> of Supplementary Material shows the test results. Results show that, knowledge driven bounded dynamic programming helps in achieving improved execution time and memory utilization. Average SP score remains same as HAlign II as the underlying alignment strategy remains the same in both algorithms (Centre star). This shows the importance of knowledge driven algorithms, which can learn from their experiences are key to improving the performance of MSA.</p>
    </sec>
    <sec id="Sec11">
      <title>Complexity Analysis</title>
      <p id="Par29">The most important feature of SPARK-MSNA is the improved time and space complexity. The first stage of SPARK-MSNA is construction of Suffix tree. The Ukkonen’s algorithm using MapReduce model is adapted here. For one DNA sequence of length m, the time complexity for building suffix tree is <italic>O</italic>(<italic>m</italic>). For <italic>n</italic> sequences, the complexity is <italic>O</italic>(<italic>nm</italic>). The second stage is searching the suffix tree for all possible pair combinations of <italic>n</italic> DNA sequences. The search would incur a cost of <italic>O</italic>(<italic>m</italic>) for one sequence pair and we have <italic>nC</italic>2 pairs. So, the complexity of search becomes <italic>O</italic>(<italic>n</italic><sup>2</sup><italic>m</italic>). Building guide tree based on the similarity measure obtained from search is the next step. This incurs a linear cost of <italic>O</italic>(<italic>n</italic>). Due to less number of dimensions and cardinality involved in pattern matching, the complexity of learning layer becomes <italic>O</italic>(<italic>k</italic>).</p>
      <p id="Par30">Pairwise alignment of unmatched segments of sequence pairs is the next step. Since we are adopting the modified Needleman-Wunsch algorithm, the complexity becomes <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(kx)+O(2kd)$$\end{document}</tex-math><mml:math id="M6"><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>k</mml:mi><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math><inline-graphic xlink:href="41598_2019_42966_Article_IEq2.gif"/></alternatives></inline-formula>, where <italic>k</italic> is the segment length, <italic>x</italic> is the difference length of segments involved in pairwise alignment and <italic>d</italic> is the number of diagonals to be populated. For highly similar sequences, <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x\to 0\,and\,d\ll k$$\end{document}</tex-math><mml:math id="M8"><mml:mi>x</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn><mml:mspace width=".25em"/><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mspace width=".25em"/><mml:mi>d</mml:mi><mml:mo>≪</mml:mo><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41598_2019_42966_Article_IEq3.gif"/></alternatives></inline-formula>, hence the complexity will be <italic>O</italic>(<italic>k</italic>). In traditional dynamic programming approach, the complexity is <italic>O</italic>(<italic>k</italic><sup>2</sup>). The last step of summing up the alignment results to form the final alignment would incur a cost of <italic>O</italic>(<italic>nm</italic>). The learning step involves one pairwise alignment of the most distant segment pair and it incurs a cost of <italic>O</italic>(<italic>k</italic><sup>2</sup>), if the learning is not available in the knowledge base.</p>
      <p id="Par31">Building the knowledge base is not part of the main flow of the algorithm. It is part of the training phase and hence it does not add to the overall complexity of the algorithm. Whenever the appropriate learning is missing in the knowledge base, the learning step is implemented to enhance the knowledge base. Modified dotlet algorithm is performed to get the number of diagonals. The alignment is performed on the most distant segment of sequences and in such scenarios, there would be an additional <italic>O</italic>(<italic>m</italic><sup>2</sup>) added to the complexity of the algorithm, where <italic>m</italic> is the sequence length.</p>
      <p id="Par32">The overall complexity of SPARK-MSNA is <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(m)+O({n}^{2}m)+O(n)+O(k)+O(k)+O(nm)$$\end{document}</tex-math><mml:math id="M10"><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>m</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math><inline-graphic xlink:href="41598_2019_42966_Article_IEq4.gif"/></alternatives></inline-formula>. Considering <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\ll m$$\end{document}</tex-math><mml:math id="M12"><mml:mi>n</mml:mi><mml:mo>≪</mml:mo><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41598_2019_42966_Article_IEq5.gif"/></alternatives></inline-formula>, the best case complexity is <italic>O</italic>(<italic>m</italic>). As the similarity between sequences decreases, number of unmatched segments and the number of diagonals to be populated for alignment increases, this will make the worst case complexity as <italic>O</italic>(<italic>m</italic><sup>2</sup>). Same is the case when learning step is involved.</p>
    </sec>
  </sec>
  <sec id="Sec12" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par33">In this work, we have focused on improving the efficiency of MSA involving large DNA sequences by utilizing its similarity feature and improving the performance with learning layer and parallel execution. The test results and complexity shows that, SPARK-MSNA provides a better trade-off compared to other MSA tools/algorithms in handling similar large scale DNA/RNA sequences. SPARK-MSNA provides better alignment and memory utilization with a comparable execution time with large sequences. In best case scenario, SPARK-MSNA reduces the memory utilization up to 50% along with better alignment compared to HAlign II. In worst case scenario, where we cannot reduce the number of matrix cells to be processed in the pairwise alignments, the complexity remains similar to HAlign II. Test results with learning layer added to centre star approach shows that a knowledge driven approach helps in improving the performance in terms of execution time and memory. Knowledge driven algorithms, which can learn from experience and use the learnings in future alignments are instrumental in handling large scale datasets.</p>
    <p id="Par34">The proposed knowledge base uses only similarity feature for learning. Adding more features in knowledge base and alignment approach to utilize those additional features could provide a better result in future. RDD persistence using kyro serialization instead of raw data format for improved memory utilization is also planned as a future enhancement.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec13">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41598_2019_42966_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Material</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1038/s41598-019-42966-5.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>This work has been supported by State Inter University Centre of Excellence in Bioinformatics (SIUCEB), AiCADD and DBT-BIF.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author Contributions</title>
    <p>V.V. designed and prepared the source code of the algorithm and drafted the manuscript. B.C.L. and A.S.N. guided the research with contributions to the design of algorithm, helped designing the manuscript and revised it critically.</p>
  </notes>
  <notes notes-type="COI-statement">
    <sec id="FPar1">
      <title>Competing Interests</title>
      <p>The authors declare no competing interests.</p>
    </sec>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Needleman</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Wunsch</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>A general method applicable to the search for similarities in the amino acid sequence of two proteins</article-title>
        <source>Journal of Molecular Biology</source>
        <year>1970</year>
        <volume>48</volume>
        <fpage>443</fpage>
        <lpage>453</lpage>
        <pub-id pub-id-type="doi">10.1016/0022-2836(70)90057-4</pub-id>
        <pub-id pub-id-type="pmid">5420325</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thompson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Higgins</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Gibson</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>CLUSTAL W: improving the sensitivity of progressive multiple sequence alignment through sequence weighting, position-specific gap penalties and weight matrix choice</article-title>
        <source>Nucleic Acids Research</source>
        <year>1994</year>
        <volume>22</volume>
        <fpage>4673</fpage>
        <lpage>4680</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/22.22.4673</pub-id>
        <pub-id pub-id-type="pmid">7984417</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Katoh</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Standley</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>MAFFT Multiple Sequence Alignment Software Version 7: Improvements in Performance and Usability</article-title>
        <source>Molecular Biology and Evolution</source>
        <year>2013</year>
        <volume>30</volume>
        <fpage>772</fpage>
        <lpage>780</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/mst010</pub-id>
        <pub-id pub-id-type="pmid">23329690</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Edgar</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>MUSCLE: multiple sequence alignment with high accuracy and high throughput</article-title>
        <source>Nucleic Acids Research</source>
        <year>2004</year>
        <volume>32</volume>
        <fpage>1792</fpage>
        <lpage>1797</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh340</pub-id>
        <pub-id pub-id-type="pmid">15034147</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ghemawat</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>MapReduce</article-title>
        <source>Communications of the ACM</source>
        <year>2008</year>
        <volume>51</volume>
        <fpage>107</fpage>
        <pub-id pub-id-type="doi">10.1145/1327452.1327492</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sadasivam</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Baktavatchalam</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>A novel approach to Multiple Sequence Alignment using hadoop data grids</article-title>
        <source>International Journal of Bioinformatics Research and Applications</source>
        <year>2010</year>
        <volume>6</volume>
        <fpage>472</fpage>
        <pub-id pub-id-type="doi">10.1504/IJBRA.2010.037987</pub-id>
        <pub-id pub-id-type="pmid">21224205</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">Zhao, G., Ling, C. &amp; Sun, D. SparkSW: Scalable Distributed Computing System for Large-Scale Biological Sequence Alignment. <italic>2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing</italic>, 10.1109/ccgrid.2015.55 (2015).</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>HAlign: Fast multiple similar DNA/RNA sequence alignment based on the centre star strategy</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <fpage>2475</fpage>
        <lpage>2481</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv177</pub-id>
        <pub-id pub-id-type="pmid">25812743</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Wan, S. &amp; Zou, Q. HAlign-II: efficient ultra-large multiple sequence alignment and phylogenetic tree reconstruction with distributed and parallel computing. <italic>Algorithms for Molecular Biology</italic><bold>12</bold> (2017).</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Su</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Multiple Sequence Alignment Based on a Suffix Tree and Center-Star Strategy: A Linear Method for Multiple Nucleotide Sequence Alignment on Spark Parallel Framework</article-title>
        <source>Journal of Computational Biology</source>
        <year>2017</year>
        <volume>24</volume>
        <fpage>1230</fpage>
        <lpage>1242</lpage>
        <pub-id pub-id-type="doi">10.1089/cmb.2017.0040</pub-id>
        <pub-id pub-id-type="pmid">29116822</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abuín</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Pena</surname>
            <given-names>TF</given-names>
          </name>
          <name>
            <surname>Pichel</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>PASTASpark: multiple sequence alignment meets</article-title>
        <source>Big Data. Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>2948</fpage>
        <lpage>2950</lpage>
        <?supplied-pmid 28582480?>
        <pub-id pub-id-type="pmid">28582480</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bellman</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>On the Theory of Dynamic Programming</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year>1952</year>
        <volume>38</volume>
        <fpage>716</fpage>
        <lpage>719</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.38.8.716</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vineetha</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Nair</surname>
            <given-names>AS</given-names>
          </name>
        </person-group>
        <article-title>DDGARM: Dotlet Driven Global Alignment with Reduced Matrix</article-title>
        <source>International Journal of Advanced Research in Computer Science and Software Engineering</source>
        <year>2017</year>
        <volume>7</volume>
        <fpage>70</fpage>
        <lpage>74</lpage>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Feng</surname>
            <given-names>D-F</given-names>
          </name>
          <name>
            <surname>Doolittle</surname>
            <given-names>RF</given-names>
          </name>
        </person-group>
        <article-title>Progressive sequence alignment as a prerequisitetto correct phylogenetic trees</article-title>
        <source>Journal of Molecular Evolution</source>
        <year>1987</year>
        <volume>25</volume>
        <fpage>351</fpage>
        <lpage>360</lpage>
        <pub-id pub-id-type="doi">10.1007/BF02603120</pub-id>
        <pub-id pub-id-type="pmid">3118049</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ukkonen</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>On-line construction of suffix trees</article-title>
        <source>Algorithmica</source>
        <year>1995</year>
        <volume>14</volume>
        <fpage>249</fpage>
        <lpage>260</lpage>
        <pub-id pub-id-type="doi">10.1007/BF01206331</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mccreight</surname>
            <given-names>EM</given-names>
          </name>
        </person-group>
        <article-title>A Space-Economical Suffix Tree Construction Algorithm</article-title>
        <source>Journal of the ACM</source>
        <year>1976</year>
        <volume>23</volume>
        <issue>2</issue>
        <fpage>262</fpage>
        <lpage>272</lpage>
        <pub-id pub-id-type="doi">10.1145/321941.321946</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Farach-Colton</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ferragina</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Muthukrishnan</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>On the sorting-complexity of suffix tree construction</article-title>
        <source>Journal of the ACM</source>
        <year>2000</year>
        <volume>47</volume>
        <fpage>987</fpage>
        <lpage>1011</lpage>
        <pub-id pub-id-type="doi">10.1145/355541.355547</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hunt</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Atkinson</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Irving</surname>
            <given-names>RW</given-names>
          </name>
        </person-group>
        <article-title>A database index to large biological sequences</article-title>
        <source>work</source>
        <year>2001</year>
        <volume>26</volume>
        <fpage>27</fpage>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Bedathur, S. &amp; Haritsa, J. Engineering a fast online persistent suffix tree construction. <italic>Proceedings. 20th International Conference on Data Engineering</italic>, 10.1109/icde.2004.1320040.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheung</surname>
            <given-names>C-F</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>JX</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Constructing suffix tree for gigabyte sequences with megabyte memory</article-title>
        <source>IEEE Transactions on Knowledge and Data Engineering</source>
        <year>2005</year>
        <volume>17</volume>
        <fpage>90</fpage>
        <lpage>105</lpage>
        <pub-id pub-id-type="doi">10.1109/TKDE.2005.3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Phoophakdee, B. &amp; Zaki, M. J. Genome-scale disk-based suffix tree indexing. <italic>Proceedings of the 2007 ACM SIGMOD international conference on Management of data - SIGMOD</italic><italic>07</italic>, 10.1145/1247480.1247572 (2007).</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Gusfield, D. Linear-time construction of suffix trees. Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology (1997).</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Weiner, P. Linear pattern matching algorithms. Switching and Automata Theory. SWAT'08. IEEE Conference Record of 14th Annual Symposium on, 1–11 (1973).</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Junier</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Pagni</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Dotlet: diagonal plots in a Web browser</article-title>
        <source>Bioinformatics</source>
        <year>2000</year>
        <volume>16</volume>
        <fpage>178</fpage>
        <lpage>179</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/16.2.178</pub-id>
        <pub-id pub-id-type="pmid">10842741</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Muja, M. &amp; Lowe, D. G. Fast Approximate Nearest Neighbors With Automatic Algorithm Configuration. <italic>Proceedings of the Fourth International Conference on Computer Vision Theory and Applications</italic>, 10.5220/0001787803310340 (2009).</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanungo</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An efficient k-means clustering algorithm: analysis and implementation</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2002</year>
        <volume>24</volume>
        <fpage>881</fpage>
        <lpage>892</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2002.1017616</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Zaharia, M. <italic>et al</italic>. Spark: Cluster computing with working sets. <italic>HotCloud</italic>, 10.10-10, 95 (2010).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Satish, U. C., Kondikoppa, P., Park, S.-J., Patil, M. &amp; Shah, R. MapReduce based parallel suffix tree construction for human genome. <italic>2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS)</italic>, 10.1109/padsw.2014.7097867 (2014).</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thompson</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Koehl</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ripp</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Poch</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>BAliBASE 3.0: Latest developments of the multiple sequence alignment benchmark</article-title>
        <source>Proteins: Structure, Function, and Bioinformatics</source>
        <year>2005</year>
        <volume>61</volume>
        <fpage>127</fpage>
        <lpage>136</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20527</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
